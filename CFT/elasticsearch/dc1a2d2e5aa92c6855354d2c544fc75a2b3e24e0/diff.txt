diff --git a/core/src/main/java/org/elasticsearch/cache/recycler/PageCacheRecyclerModule.java b/core/src/main/java/org/elasticsearch/cache/recycler/PageCacheRecyclerModule.java
new file mode 100644
index 0000000..be2e6ff
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/cache/recycler/PageCacheRecyclerModule.java
@@ -0,0 +1,48 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.cache.recycler;
+
+import org.elasticsearch.common.Classes;
+import org.elasticsearch.common.inject.AbstractModule;
+import org.elasticsearch.common.settings.Settings;
+
+/**
+ */
+public class PageCacheRecyclerModule extends AbstractModule {
+
+    public static final String CACHE_IMPL = "cache.recycler.page_cache_impl";
+
+    private final Settings settings;
+
+    public PageCacheRecyclerModule(Settings settings) {
+        this.settings = settings;
+    }
+
+    @Override
+    protected void configure() {
+        String impl = settings.get(CACHE_IMPL);
+        if (impl == null) {
+            bind(PageCacheRecycler.class).asEagerSingleton();
+        } else {
+            Class<? extends PageCacheRecycler> implClass = Classes.loadClass(getClass().getClassLoader(), impl);
+            bind(PageCacheRecycler.class).to(implClass).asEagerSingleton();
+        }
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java
index e57d956..a97eab0 100644
--- a/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java
+++ b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java
@@ -52,9 +52,6 @@ public class ClusterModule extends AbstractModule implements SpawnModules {
 
     private Set<Class<? extends IndexTemplateFilter>> indexTemplateFilters = new HashSet<>();
 
-    // pkg private so tests can mock
-    Class<? extends ClusterInfoService> clusterInfoServiceImpl = InternalClusterInfoService.class;
-
     public ClusterModule(Settings settings) {
         this.settings = settings;
     }
@@ -91,7 +88,13 @@ public class ClusterModule extends AbstractModule implements SpawnModules {
         bind(NodeIndexDeletedAction.class).asEagerSingleton();
         bind(NodeMappingRefreshAction.class).asEagerSingleton();
         bind(MappingUpdatedAction.class).asEagerSingleton();
-        bind(ClusterInfoService.class).to(clusterInfoServiceImpl).asEagerSingleton();
+
+        String impl = settings.get(CLUSTER_SERVICE_IMPL);
+        Class<? extends ClusterInfoService> implClass = InternalClusterInfoService.class;
+        if (impl != null) {
+            implClass = Classes.loadClass(getClass().getClassLoader(), impl);
+        }
+        bind(ClusterInfoService.class).to(implClass).asEagerSingleton();
 
         Multibinder<IndexTemplateFilter> mbinder = Multibinder.newSetBinder(binder(), IndexTemplateFilter.class);
         for (Class<? extends IndexTemplateFilter> indexTemplateFilter : indexTemplateFilters) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationModule.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationModule.java
index 23c721d..62e14ec 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationModule.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationModule.java
@@ -21,6 +21,7 @@ package org.elasticsearch.cluster.routing.allocation;
 
 import org.elasticsearch.cluster.routing.allocation.allocator.BalancedShardsAllocator;
 import org.elasticsearch.cluster.routing.allocation.allocator.ShardsAllocator;
+import org.elasticsearch.cluster.routing.allocation.allocator.ShardsAllocators;
 import org.elasticsearch.cluster.routing.allocation.decider.AllocationDecider;
 import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;
 import org.elasticsearch.cluster.routing.allocation.decider.AwarenessAllocationDecider;
@@ -42,6 +43,7 @@ import org.elasticsearch.common.inject.multibindings.Multibinder;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.ExtensionPoint;
 import org.elasticsearch.gateway.GatewayAllocator;
 
 import java.util.Arrays;
@@ -84,55 +86,43 @@ public class AllocationModule extends AbstractModule {
             DiskThresholdDecider.class,
             SnapshotInProgressAllocationDecider.class));
 
+
     private final Settings settings;
-    private final Map<String, Class<? extends ShardsAllocator>> shardsAllocators = new HashMap<>();
-    private final Set<Class<? extends AllocationDecider>> allocationDeciders = new HashSet<>();
+    private final ExtensionPoint.TypeExtensionPoint<ShardsAllocator> shardsAllocators = new ExtensionPoint.TypeExtensionPoint<>("shards_allocator", ShardsAllocator.class);
+    private final ExtensionPoint.SetExtensionPoint<AllocationDecider> allocationDeciders = new ExtensionPoint.SetExtensionPoint<>("allocation_decider", AllocationDecider.class, AllocationDeciders.class);
 
     public AllocationModule(Settings settings) {
         this.settings = settings;
-        this.allocationDeciders.addAll(DEFAULT_ALLOCATION_DECIDERS);
-        registerShardAllocator(BALANCED_ALLOCATOR, BalancedShardsAllocator.class);
-        registerShardAllocator(EVEN_SHARD_COUNT_ALLOCATOR, BalancedShardsAllocator.class);
+        for (Class<? extends AllocationDecider> decider : DEFAULT_ALLOCATION_DECIDERS) {
+            allocationDeciders.registerExtension(decider);
+        }
+        shardsAllocators.registerExtension(BALANCED_ALLOCATOR, BalancedShardsAllocator.class);
+        shardsAllocators.registerExtension(EVEN_SHARD_COUNT_ALLOCATOR, BalancedShardsAllocator.class);
     }
 
     /** Register a custom allocation decider */
     public void registerAllocationDecider(Class<? extends AllocationDecider> allocationDecider) {
-        boolean isNew = allocationDeciders.add(allocationDecider);
-        if (isNew == false) {
-            throw new IllegalArgumentException("Cannot register AllocationDecider " + allocationDecider.getName() + " twice");
-        }
+        allocationDeciders.registerExtension(allocationDecider);
     }
 
     /** Register a custom shard allocator with the given name */
     public void registerShardAllocator(String name, Class<? extends ShardsAllocator> clazz) {
-        Class<? extends ShardsAllocator> existing = shardsAllocators.put(name, clazz);
-        if (existing != null) {
-            throw new IllegalArgumentException("Cannot register ShardAllocator [" + name + "] to " + clazz.getName() + ", already registered to " + existing.getName());
-        }
+        shardsAllocators.registerExtension(name, clazz);
     }
 
     @Override
     protected void configure() {
-
         // bind ShardsAllocator
-        final String shardsAllocatorType = settings.get(AllocationModule.SHARDS_ALLOCATOR_TYPE_KEY, AllocationModule.BALANCED_ALLOCATOR);
-        final Class<? extends ShardsAllocator> shardsAllocator = shardsAllocators.get(shardsAllocatorType);
-        if (shardsAllocator == null) {
-            throw new IllegalArgumentException("Unknown ShardsAllocator type [" + shardsAllocatorType + "]");
-        } else if (shardsAllocatorType.equals(EVEN_SHARD_COUNT_ALLOCATOR)) {
+        String shardsAllocatorType = shardsAllocators.bindType(binder(), settings, AllocationModule.SHARDS_ALLOCATOR_TYPE_KEY, AllocationModule.BALANCED_ALLOCATOR);
+        if (shardsAllocatorType.equals(EVEN_SHARD_COUNT_ALLOCATOR)) {
             final ESLogger logger = Loggers.getLogger(getClass(), settings);
             logger.warn("{} allocator has been removed in 2.0 using {} instead", AllocationModule.EVEN_SHARD_COUNT_ALLOCATOR, AllocationModule.BALANCED_ALLOCATOR);
         }
-        bind(ShardsAllocator.class).to(shardsAllocator).asEagerSingleton();
-
         // bind AllocationDeciders
-        Multibinder<AllocationDecider> allocationMultibinder = Multibinder.newSetBinder(binder(), AllocationDecider.class);
-        for (Class<? extends AllocationDecider> allocation : allocationDeciders) {
-            allocationMultibinder.addBinding().to(allocation).asEagerSingleton();
-        }
+        allocationDeciders.bind(binder());
 
         bind(GatewayAllocator.class).asEagerSingleton();
-        bind(AllocationDeciders.class).asEagerSingleton();
         bind(AllocationService.class).asEagerSingleton();
     }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/common/settings/Settings.java b/core/src/main/java/org/elasticsearch/common/settings/Settings.java
index 2671874..4d42257 100644
--- a/core/src/main/java/org/elasticsearch/common/settings/Settings.java
+++ b/core/src/main/java/org/elasticsearch/common/settings/Settings.java
@@ -1129,7 +1129,7 @@ public final class Settings implements ToXContent {
             }
             InputStream is = classLoader.getResourceAsStream(resourceName);
             if (is == null) {
-                return this;
+                throw new SettingsException("Failed to load settings from [" + resourceName + "]");
             }
 
             return loadFromStream(resourceName, is);
diff --git a/core/src/main/java/org/elasticsearch/common/util/BigArraysModule.java b/core/src/main/java/org/elasticsearch/common/util/BigArraysModule.java
new file mode 100644
index 0000000..8d86391
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/common/util/BigArraysModule.java
@@ -0,0 +1,50 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.common.util;
+
+import org.elasticsearch.common.Classes;
+import org.elasticsearch.common.inject.AbstractModule;
+import org.elasticsearch.common.settings.Settings;
+
+import static org.elasticsearch.common.inject.Modules.createModule;
+
+/**
+ */
+public class BigArraysModule extends AbstractModule {
+
+    public static final String IMPL = "common.util.big_arrays_impl";
+
+    private final Settings settings;
+
+    public BigArraysModule(Settings settings) {
+        this.settings = settings;
+    }
+
+    @Override
+    protected void configure() {
+        String impl = settings.get(IMPL);
+        if (impl == null) {
+            bind(BigArrays.class).asEagerSingleton();
+        } else {
+            Class<? extends BigArrays> implClass = Classes.loadClass(getClass().getClassLoader(), impl);
+            bind(BigArrays.class).to(implClass).asEagerSingleton();
+        }
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/common/util/ExtensionPoint.java b/core/src/main/java/org/elasticsearch/common/util/ExtensionPoint.java
new file mode 100644
index 0000000..435c3ae
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/common/util/ExtensionPoint.java
@@ -0,0 +1,194 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.common.util;
+
+import org.elasticsearch.common.inject.Binder;
+import org.elasticsearch.common.inject.multibindings.MapBinder;
+import org.elasticsearch.common.inject.multibindings.Multibinder;
+import org.elasticsearch.common.settings.Settings;
+
+import java.util.*;
+
+/**
+ * This class defines an official elasticsearch extension point. It registers
+ * all extensions by a single name and ensures that extensions are not registered
+ * more than once.
+ */
+public abstract class ExtensionPoint<T> {
+    protected final String name;
+    protected final Class<T> extensionClass;
+    protected final Class<?>[] singletons;
+
+    /**
+     * Creates a new extension point
+     *
+     * @param name           the human readable underscore case name of the extension poing. This is used in error messages etc.
+     * @param extensionClass the base class that should be extended
+     * @param singletons     a list of singletons to bind with this extension point - these are bound in {@link #bind(Binder)}
+     */
+    public ExtensionPoint(String name, Class<T> extensionClass, Class<?>... singletons) {
+        this.name = name;
+        this.extensionClass = extensionClass;
+        this.singletons = singletons;
+    }
+
+    /**
+     * Binds the extension as well as the singletons to the given guice binder.
+     *
+     * @param binder the binder to use
+     */
+    public final void bind(Binder binder) {
+        if (singletons == null || singletons.length == 0) {
+            throw new IllegalStateException("Can't bind empty or null singletons");
+        }
+        for (Class<?> c : singletons) {
+            binder.bind(c).asEagerSingleton();
+        }
+        bindExtensions(binder);
+    }
+
+    /**
+     * Subclasses can bind their type, map or set exentions here.
+     */
+    protected abstract void bindExtensions(Binder binder);
+
+    /**
+     * A map based extension point which allows to register keyed implementations ie. parsers or some kind of strategies.
+     */
+    public static class MapExtensionPoint<T> extends ExtensionPoint<T> {
+        private final Map<String, Class<? extends T>> extensions = new HashMap<>();
+        private final Set<String> reservedKeys;
+
+        /**
+         * Creates a new {@link org.elasticsearch.common.util.ExtensionPoint.MapExtensionPoint}
+         *
+         * @param name           the human readable underscore case name of the extension poing. This is used in error messages etc.
+         * @param extensionClass the base class that should be extended
+         * @param singletons     a list of singletons to bind with this extension point - these are bound in {@link #bind(Binder)}
+         * @param reservedKeys   a set of reserved keys by internal implementations
+         */
+        public MapExtensionPoint(String name, Class<T> extensionClass, Set<String> reservedKeys, Class<?>... singletons) {
+            super(name, extensionClass, singletons);
+            this.reservedKeys = reservedKeys;
+
+        }
+
+        /**
+         * Returns the extension for the given key or <code>null</code>
+         */
+        public Class<? extends T> getExtension(String type) {
+            return extensions.get(type);
+        }
+
+        /**
+         * Registers an extension class for a given key. This method will thr
+         *
+         * @param key       the extensions key
+         * @param extension the extension
+         * @throws IllegalArgumentException iff the key is already registered or if the key is a reserved key for an internal implementation
+         */
+        public final void registerExtension(String key, Class<? extends T> extension) {
+            if (extensions.containsKey(key) || reservedKeys.contains(key)) {
+                throw new IllegalArgumentException("Can't register the same [" + this.name + "] more than once for [" + key + "]");
+            }
+            extensions.put(key, extension);
+        }
+
+        @Override
+        protected final void bindExtensions(Binder binder) {
+            MapBinder<String, T> parserMapBinder = MapBinder.newMapBinder(binder, String.class, extensionClass);
+            for (Map.Entry<String, Class<? extends T>> clazz : extensions.entrySet()) {
+                parserMapBinder.addBinding(clazz.getKey()).to(clazz.getValue());
+            }
+        }
+    }
+
+    /**
+     * A Type extension point which basically allows to registerd keyed extensions like {@link org.elasticsearch.common.util.ExtensionPoint.MapExtensionPoint}
+     * but doesn't instantiate and bind all the registered key value pairs but instead replace a singleton based on a given setting via {@link #bindType(Binder, Settings, String, String)}
+     * Note: {@link #bind(Binder)} is not supported by this class
+     */
+    public static final class TypeExtensionPoint<T> extends MapExtensionPoint<T> {
+
+        public TypeExtensionPoint(String name, Class<T> extensionClass) {
+            super(name, extensionClass, Collections.EMPTY_SET);
+        }
+
+        /**
+         * Binds the extension class to the class that is registered for the give configured for the settings key in
+         * the settings object.
+         *
+         * @param binder       the binder to use
+         * @param settings     the settings to look up the key to find the implemetation to bind
+         * @param settingsKey  the key to use with the settings
+         * @param defaultValue the default value if they settings doesn't contain the key
+         * @return the actual bound type key
+         */
+        public String bindType(Binder binder, Settings settings, String settingsKey, String defaultValue) {
+            final String type = settings.get(settingsKey, defaultValue);
+            final Class<? extends T> instance = getExtension(type);
+            if (instance == null) {
+                throw new IllegalArgumentException("Unknown [" + this.name + "] type [" + type + "]");
+            }
+            binder.bind(extensionClass).to(instance).asEagerSingleton();
+            return type;
+        }
+
+    }
+
+    /**
+     * A set based extension point which allows to register extended classes that might be used to chain additional functionality etc.
+     */
+    public final static class SetExtensionPoint<T> extends ExtensionPoint<T> {
+        private final Set<Class<? extends T>> extensions = new HashSet<>();
+
+        /**
+         * Creates a new {@link org.elasticsearch.common.util.ExtensionPoint.SetExtensionPoint}
+         *
+         * @param name           the human readable underscore case name of the extension poing. This is used in error messages etc.
+         * @param extensionClass the base class that should be extended
+         * @param singletons     a list of singletons to bind with this extension point - these are bound in {@link #bind(Binder)}
+         */
+        public SetExtensionPoint(String name, Class<T> extensionClass, Class<?>... singletons) {
+            super(name, extensionClass, singletons);
+        }
+
+        /**
+         * Registers a new extension
+         *
+         * @param extension the extension to register
+         * @throws IllegalArgumentException iff the class is already registered
+         */
+        public final void registerExtension(Class<? extends T> extension) {
+            if (extensions.contains(extension)) {
+                throw new IllegalArgumentException("Can't register the same [" + this.name + "] more than once for [" + extension.getName() + "]");
+            }
+            extensions.add(extension);
+        }
+
+        @Override
+        protected final void bindExtensions(Binder binder) {
+            Multibinder<T> allocationMultibinder = Multibinder.newSetBinder(binder, extensionClass);
+            for (Class<? extends T> clazz : extensions) {
+                allocationMultibinder.addBinding().to(clazz);
+            }
+        }
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/index/cache/IndexCacheModule.java b/core/src/main/java/org/elasticsearch/index/cache/IndexCacheModule.java
index fc0b4d0..43ddbf7 100644
--- a/core/src/main/java/org/elasticsearch/index/cache/IndexCacheModule.java
+++ b/core/src/main/java/org/elasticsearch/index/cache/IndexCacheModule.java
@@ -20,21 +20,15 @@
 package org.elasticsearch.index.cache;
 
 import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.inject.Scopes;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
-import org.elasticsearch.index.cache.query.QueryCache;
-import org.elasticsearch.index.cache.query.index.IndexQueryCache;
-import org.elasticsearch.index.cache.query.none.NoneQueryCache;
+import org.elasticsearch.index.cache.bitset.BitsetFilterCacheModule;
+import org.elasticsearch.index.cache.query.QueryCacheModule;
 
+/**
+ *
+ */
 public class IndexCacheModule extends AbstractModule {
 
-    public static final String INDEX_QUERY_CACHE = "index";
-    public static final String NONE_QUERY_CACHE = "none";
-    public static final String QUERY_CACHE_TYPE = "index.queries.cache.type";
-    // for test purposes only
-    public static final String QUERY_CACHE_EVERYTHING = "index.queries.cache.everything";
-
     private final Settings settings;
 
     public IndexCacheModule(Settings settings) {
@@ -43,17 +37,9 @@ public class IndexCacheModule extends AbstractModule {
 
     @Override
     protected void configure() {
-        String queryCacheType = settings.get(QUERY_CACHE_TYPE, INDEX_QUERY_CACHE);
-        Class<? extends QueryCache> queryCacheImpl;
-        if (queryCacheType.equals(INDEX_QUERY_CACHE)) {
-            queryCacheImpl = IndexQueryCache.class;
-        } else if (queryCacheType.equals(NONE_QUERY_CACHE)) {
-            queryCacheImpl = NoneQueryCache.class;
-        } else {
-            throw new IllegalArgumentException("Unknown QueryCache type [" + queryCacheType + "]");
-        }
-        bind(QueryCache.class).to(queryCacheImpl).in(Scopes.SINGLETON);
-        bind(BitsetFilterCache.class).asEagerSingleton();
+        new QueryCacheModule(settings).configure(binder());
+        new BitsetFilterCacheModule(settings).configure(binder());
+
         bind(IndexCache.class).asEagerSingleton();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/cache/bitset/BitsetFilterCacheModule.java b/core/src/main/java/org/elasticsearch/index/cache/bitset/BitsetFilterCacheModule.java
new file mode 100644
index 0000000..3ecccf1
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/cache/bitset/BitsetFilterCacheModule.java
@@ -0,0 +1,36 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.cache.bitset;
+
+import org.elasticsearch.common.inject.AbstractModule;
+import org.elasticsearch.common.settings.Settings;
+
+/**
+ */
+public class BitsetFilterCacheModule extends AbstractModule {
+
+    public BitsetFilterCacheModule(Settings settings) {
+    }
+
+    @Override
+    protected void configure() {
+        bind(BitsetFilterCache.class).asEagerSingleton();
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/index/cache/query/QueryCacheModule.java b/core/src/main/java/org/elasticsearch/index/cache/query/QueryCacheModule.java
new file mode 100644
index 0000000..f5465c9
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/cache/query/QueryCacheModule.java
@@ -0,0 +1,56 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.cache.query;
+
+import org.elasticsearch.cluster.metadata.AliasOrIndex;
+import org.elasticsearch.common.Classes;
+import org.elasticsearch.common.inject.AbstractModule;
+import org.elasticsearch.common.inject.Scopes;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.index.cache.query.index.IndexQueryCache;
+
+/**
+ *
+ */
+public class QueryCacheModule extends AbstractModule {
+
+    public static final class QueryCacheSettings {
+        public static final String QUERY_CACHE_TYPE = "index.queries.cache.type";
+        // for test purposes only
+        public static final String QUERY_CACHE_EVERYTHING = "index.queries.cache.everything";
+    }
+
+    private final Settings settings;
+
+    public QueryCacheModule(Settings settings) {
+        this.settings = settings;
+    }
+
+    @Override
+    protected void configure() {
+        Class<? extends IndexQueryCache> queryCacheClass = IndexQueryCache.class;
+        String customQueryCache = settings.get(QueryCacheSettings.QUERY_CACHE_TYPE);
+        if (customQueryCache != null) {
+            // TODO: make this only useable from tests
+            queryCacheClass = Classes.loadClass(getClass().getClassLoader(), customQueryCache);
+        }
+        bind(QueryCache.class).to(queryCacheClass).in(Scopes.SINGLETON);
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java b/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
index 3a230d1..91ff1de 100644
--- a/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
+++ b/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.index.percolator;
 
 import org.apache.lucene.index.Term;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.BytesRef;
@@ -260,7 +261,9 @@ public class PercolatorQueriesRegistry extends AbstractIndexShardComponent imple
             try (Engine.Searcher searcher = shard.engine().acquireSearcher("percolator_load_queries")) {
                 Query query = new TermQuery(new Term(TypeFieldMapper.NAME, PercolatorService.TYPE_NAME));
                 QueriesLoaderCollector queryCollector = new QueriesLoaderCollector(PercolatorQueriesRegistry.this, logger, mapperService, indexFieldDataService);
-                searcher.searcher().search(query, queryCollector);
+                IndexSearcher indexSearcher = new IndexSearcher(searcher.reader());
+                indexSearcher.setQueryCache(null);
+                indexSearcher.search(query, queryCollector);
                 Map<BytesRef, Query> queries = queryCollector.queries();
                 for (Map.Entry<BytesRef, Query> entry : queries.entrySet()) {
                     Query previousQuery = percolateQueries.put(entry.getKey(), entry.getValue());
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java
index 4fd5233..837837a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.index.query.functionscore;
 
-import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
index dc1207a..bb68158 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
@@ -58,8 +58,8 @@ import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.VersionType;
 import org.elasticsearch.index.aliases.IndexAliasesService;
 import org.elasticsearch.index.cache.IndexCache;
-import org.elasticsearch.index.cache.IndexCacheModule;
 import org.elasticsearch.index.cache.bitset.ShardBitsetFilterCache;
+import org.elasticsearch.index.cache.query.QueryCacheModule.QueryCacheSettings;
 import org.elasticsearch.index.cache.query.QueryCacheStats;
 import org.elasticsearch.index.cache.request.ShardRequestCache;
 import org.elasticsearch.index.codec.CodecService;
@@ -249,7 +249,7 @@ public class IndexShard extends AbstractIndexShardComponent {
         final QueryCachingPolicy cachingPolicy;
         // the query cache is a node-level thing, however we want the most popular filters
         // to be computed on a per-shard basis
-        if (indexSettings.getAsBoolean(IndexCacheModule.QUERY_CACHE_EVERYTHING, false)) {
+        if (indexSettings.getAsBoolean(QueryCacheSettings.QUERY_CACHE_EVERYTHING, false)) {
             cachingPolicy = QueryCachingPolicy.ALWAYS_CACHE;
         } else {
             cachingPolicy = new UsageTrackingQueryCachingPolicy();
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardModule.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardModule.java
index 0851b1c..28a5973 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardModule.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardModule.java
@@ -40,13 +40,12 @@ import org.elasticsearch.index.translog.TranslogService;
  */
 public class IndexShardModule extends AbstractModule {
 
+    public static final String ENGINE_FACTORY = "index.engine.factory";
+
     private final ShardId shardId;
     private final Settings settings;
     private final boolean primary;
 
-    // pkg private so tests can mock
-    Class<? extends EngineFactory> engineFactoryImpl = InternalEngineFactory.class;
-
     public IndexShardModule(ShardId shardId, boolean primary, Settings settings) {
         this.settings = settings;
         this.shardId = shardId;
@@ -71,7 +70,13 @@ public class IndexShardModule extends AbstractModule {
             bind(TranslogService.class).asEagerSingleton();
         }
 
-        bind(EngineFactory.class).to(engineFactoryImpl);
+        Class<? extends InternalEngineFactory> engineFactoryClass = InternalEngineFactory.class;
+        String customEngineFactory = settings.get(ENGINE_FACTORY);
+        if (customEngineFactory != null) {
+            // TODO: make this only useable from tests
+            engineFactoryClass = Classes.loadClass(getClass().getClassLoader(), customEngineFactory);
+        }
+        bind(EngineFactory.class).to(engineFactoryClass);
         bind(StoreRecoveryService.class).asEagerSingleton();
         bind(ShardPercolateService.class).asEagerSingleton();
         bind(ShardTermVectorsService.class).asEagerSingleton();
diff --git a/core/src/main/java/org/elasticsearch/node/Node.java b/core/src/main/java/org/elasticsearch/node/Node.java
index 7b9ed73..f1db13e 100644
--- a/core/src/main/java/org/elasticsearch/node/Node.java
+++ b/core/src/main/java/org/elasticsearch/node/Node.java
@@ -23,6 +23,7 @@ import org.elasticsearch.Build;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionModule;
 import org.elasticsearch.cache.recycler.PageCacheRecycler;
+import org.elasticsearch.cache.recycler.PageCacheRecyclerModule;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.client.node.NodeClientModule;
 import org.elasticsearch.cluster.ClusterModule;
@@ -43,6 +44,7 @@ import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.network.NetworkModule;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.settings.SettingsModule;
+import org.elasticsearch.common.util.BigArraysModule;
 import org.elasticsearch.discovery.Discovery;
 import org.elasticsearch.discovery.DiscoveryModule;
 import org.elasticsearch.discovery.DiscoveryService;
@@ -69,6 +71,7 @@ import org.elasticsearch.monitor.MonitorModule;
 import org.elasticsearch.monitor.MonitorService;
 import org.elasticsearch.monitor.jvm.JvmInfo;
 import org.elasticsearch.node.internal.InternalSettingsPreparer;
+import org.elasticsearch.node.internal.NodeModule;
 import org.elasticsearch.node.settings.NodeSettingsService;
 import org.elasticsearch.percolator.PercolatorModule;
 import org.elasticsearch.percolator.PercolatorService;
@@ -158,7 +161,9 @@ public class Node implements Releasable {
         try {
             ModulesBuilder modules = new ModulesBuilder();
             modules.add(new Version.Module(version));
+            modules.add(new PageCacheRecyclerModule(settings));
             modules.add(new CircuitBreakerModule(settings));
+            modules.add(new BigArraysModule(settings));
             modules.add(new PluginsModule(settings, pluginsService));
             modules.add(new SettingsModule(settings));
             modules.add(new NodeModule(this));
diff --git a/core/src/main/java/org/elasticsearch/node/NodeModule.java b/core/src/main/java/org/elasticsearch/node/NodeModule.java
deleted file mode 100644
index befba85..0000000
--- a/core/src/main/java/org/elasticsearch/node/NodeModule.java
+++ /dev/null
@@ -1,61 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.node;
-
-import org.elasticsearch.cache.recycler.PageCacheRecycler;
-import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.util.BigArrays;
-import org.elasticsearch.node.Node;
-import org.elasticsearch.node.service.NodeService;
-import org.elasticsearch.node.settings.NodeSettingsService;
-
-/**
- *
- */
-public class NodeModule extends AbstractModule {
-
-    private final Node node;
-
-    // pkg private so tests can mock
-    Class<? extends PageCacheRecycler> pageCacheRecyclerImpl = PageCacheRecycler.class;
-    Class<? extends BigArrays> bigArraysImpl = BigArrays.class;
-
-    public NodeModule(Node node) {
-        this.node = node;
-    }
-
-    @Override
-    protected void configure() {
-        if (pageCacheRecyclerImpl == PageCacheRecycler.class) {
-            bind(PageCacheRecycler.class).asEagerSingleton();
-        } else {
-            bind(PageCacheRecycler.class).to(pageCacheRecyclerImpl).asEagerSingleton();
-        }
-        if (bigArraysImpl == BigArrays.class) {
-            bind(BigArrays.class).asEagerSingleton();
-        } else {
-            bind(BigArrays.class).to(bigArraysImpl).asEagerSingleton();
-        }
-
-        bind(Node.class).toInstance(node);
-        bind(NodeSettingsService.class).asEagerSingleton();
-        bind(NodeService.class).asEagerSingleton();
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/node/internal/NodeModule.java b/core/src/main/java/org/elasticsearch/node/internal/NodeModule.java
new file mode 100644
index 0000000..7ce0f4e
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/node/internal/NodeModule.java
@@ -0,0 +1,44 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.node.internal;
+
+import org.elasticsearch.common.inject.AbstractModule;
+import org.elasticsearch.node.Node;
+import org.elasticsearch.node.service.NodeService;
+import org.elasticsearch.node.settings.NodeSettingsService;
+
+/**
+ *
+ */
+public class NodeModule extends AbstractModule {
+
+    private final Node node;
+
+    public NodeModule(Node node) {
+        this.node = node;
+    }
+
+    @Override
+    protected void configure() {
+        bind(Node.class).toInstance(node);
+        bind(NodeSettingsService.class).asEagerSingleton();
+        bind(NodeService.class).asEagerSingleton();
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/search/SearchModule.java b/core/src/main/java/org/elasticsearch/search/SearchModule.java
index 95df2bb..fcebb12 100644
--- a/core/src/main/java/org/elasticsearch/search/SearchModule.java
+++ b/core/src/main/java/org/elasticsearch/search/SearchModule.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.search;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.Classes;
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.inject.multibindings.Multibinder;
@@ -150,25 +148,24 @@ import org.elasticsearch.search.suggest.SuggestPhase;
 import org.elasticsearch.search.suggest.Suggester;
 import org.elasticsearch.search.suggest.Suggesters;
 
-import java.util.List;
+import java.util.*;
 
 /**
  *
  */
 public class SearchModule extends AbstractModule {
 
-    private final Settings settings;
-    private final List<Class<? extends Aggregator.Parser>> aggParsers = Lists.newArrayList();
-    private final List<Class<? extends PipelineAggregator.Parser>> pipelineAggParsers = Lists.newArrayList();
-    private final List<Class<? extends Highlighter>> highlighters = Lists.newArrayList();
-    private final List<Class<? extends Suggester>> suggesters = Lists.newArrayList();
-    private final List<Class<? extends ScoreFunctionParser>> functionScoreParsers = Lists.newArrayList();
-    private final List<Class<? extends FetchSubPhase>> fetchSubPhases = Lists.newArrayList();
-    private final List<Class<? extends SignificanceHeuristicParser>> heuristicParsers = Lists.newArrayList();
-    private final List<Class<? extends MovAvgModel.AbstractModelParser>> modelParsers = Lists.newArrayList();
+    public static final String SEARCH_SERVICE_IMPL = "search.service_impl";
 
-    // pkg private so tests can mock
-    Class<? extends SearchService> searchServiceImpl = SearchService.class;
+    private final Settings settings;
+    private final Set<Class<? extends Aggregator.Parser>> aggParsers = new HashSet<>();
+    private final Set<Class<? extends PipelineAggregator.Parser>> pipelineAggParsers = new HashSet<>();
+    private final Highlighters highlighters = new Highlighters();
+    private final Suggesters suggesters = new Suggesters();
+    private final Set<Class<? extends ScoreFunctionParser>> functionScoreParsers = new HashSet<>();
+    private final Set<Class<? extends FetchSubPhase>> fetchSubPhases = new HashSet<>();
+    private final Set<Class<? extends SignificanceHeuristicParser>> heuristicParsers = new HashSet<>();
+    private final Set<Class<? extends MovAvgModel.AbstractModelParser>> modelParsers = new HashSet<>();
 
     public SearchModule(Settings settings) {
         this.settings = settings;
@@ -183,12 +180,12 @@ public class SearchModule extends AbstractModule {
         MovAvgModelStreams.registerStream(stream);
     }
 
-    public void registerHighlighter(Class<? extends Highlighter> clazz) {
-        highlighters.add(clazz);
+    public void registerHighlighter(String key, Class<? extends Highlighter> clazz) {
+        highlighters.registerExtension(key, clazz);
     }
 
-    public void registerSuggester(Class<? extends Suggester> suggester) {
-        suggesters.add(suggester);
+    public void registerSuggester(String key, Class<? extends Suggester> suggester) {
+        suggesters.registerExtension(key, suggester);
     }
 
     public void registerFunctionScoreParser(Class<? extends ScoreFunctionParser> parser) {
@@ -246,14 +243,7 @@ public class SearchModule extends AbstractModule {
     }
 
     protected void configureSuggesters() {
-        Multibinder<Suggester> suggesterMultibinder = Multibinder.newSetBinder(binder(), Suggester.class);
-        for (Class<? extends Suggester> clazz : suggesters) {
-            suggesterMultibinder.addBinding().to(clazz);
-        }
-
-        bind(SuggestParseElement.class).asEagerSingleton();
-        bind(SuggestPhase.class).asEagerSingleton();
-        bind(Suggesters.class).asEagerSingleton();
+        suggesters.bind(binder());
     }
 
     protected void configureFunctionScore() {
@@ -265,11 +255,7 @@ public class SearchModule extends AbstractModule {
     }
 
     protected void configureHighlighters() {
-        Multibinder<Highlighter> multibinder = Multibinder.newSetBinder(binder(), Highlighter.class);
-        for (Class<? extends Highlighter> highlighter : highlighters) {
-            multibinder.addBinding().to(highlighter);
-        }
-        bind(Highlighters.class).asEagerSingleton();
+       highlighters.bind(binder());
     }
 
     protected void configureAggs() {
@@ -347,11 +333,13 @@ public class SearchModule extends AbstractModule {
         bind(FetchPhase.class).asEagerSingleton();
         bind(SearchServiceTransportAction.class).asEagerSingleton();
         bind(MoreLikeThisFetchService.class).asEagerSingleton();
-
-        if (searchServiceImpl == SearchService.class) {
+        // search service -- testing only!
+        String impl = settings.get(SEARCH_SERVICE_IMPL);
+        if (impl == null) {
             bind(SearchService.class).asEagerSingleton();
         } else {
-            bind(SearchService.class).to(searchServiceImpl).asEagerSingleton();
+            Class<? extends SearchService> implClass = Classes.loadClass(getClass().getClassLoader(), impl);
+            bind(SearchService.class).to(implClass).asEagerSingleton();
         }
     }
 
@@ -412,4 +400,5 @@ public class SearchModule extends AbstractModule {
         BucketSelectorPipelineAggregator.registerStreams();
         SerialDiffPipelineAggregator.registerStreams();
     }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramBuilder.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramBuilder.java
index b373786..6b7305d 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramBuilder.java
@@ -40,7 +40,6 @@ public class DateHistogramBuilder extends ValuesSourceAggregationBuilder<DateHis
     private String timeZone;
     private String format;
     private String offset;
-    private float factor = 1.0f;
 
     /**
      * Sole constructor.
@@ -100,15 +99,6 @@ public class DateHistogramBuilder extends ValuesSourceAggregationBuilder<DateHis
     }
 
     /**
-     * Set a factor to apply to values of the field, typically used if times
-     * are stored in seconds instead of milliseconds.
-     */
-    public DateHistogramBuilder factor(float factor) {
-        this.factor = factor;
-        return this;
-    }
-
-    /**
      * Set the format to use for dates.
      */
     public DateHistogramBuilder format(String format) {
@@ -176,10 +166,6 @@ public class DateHistogramBuilder extends ValuesSourceAggregationBuilder<DateHis
             builder.field("offset", offset);
         }
 
-        if (factor != 1.0f) {
-            builder.field("factor", factor);
-        }
-
         if (format != null) {
             builder.field("format", format);
         }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/SignificanceHeuristicStreams.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/SignificanceHeuristicStreams.java
index 51dd11c..18a6f6b 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/SignificanceHeuristicStreams.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/SignificanceHeuristicStreams.java
@@ -64,6 +64,9 @@ public class SignificanceHeuristicStreams {
      * @param stream The stream to register
      */
     public static synchronized void registerStream(Stream stream) {
+        if (STREAMS.containsKey(stream.getName())) {
+            throw new IllegalArgumentException("Can't register stream with name [" + stream.getName() + "] more than once");
+        }
         HashMap<String, Stream> map = new HashMap<>();
         map.putAll(STREAMS);
         map.put(stream.getName(), stream);
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/models/MovAvgModelStreams.java b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/models/MovAvgModelStreams.java
index d12b0cd..faee8a9 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/models/MovAvgModelStreams.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/models/MovAvgModelStreams.java
@@ -64,6 +64,9 @@ public class MovAvgModelStreams {
      * @param stream The stream to register
      */
     public static synchronized void registerStream(Stream stream) {
+        if (STREAMS.containsKey(stream.getName())) {
+            throw new IllegalArgumentException("Can't register stream with name [" + stream.getName() + "] more than once");
+        }
         HashMap<String, Stream> map = new HashMap<>();
         map.putAll(STREAMS);
         map.put(stream.getName(), stream);
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/FastVectorHighlighter.java b/core/src/main/java/org/elasticsearch/search/highlight/FastVectorHighlighter.java
index 67b42a5..de73a89 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/FastVectorHighlighter.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/FastVectorHighlighter.java
@@ -50,11 +50,6 @@ public class FastVectorHighlighter implements Highlighter {
     }
 
     @Override
-    public String[] names() {
-        return new String[]{"fvh", "fast-vector-highlighter"};
-    }
-
-    @Override
     public HighlightField highlight(HighlighterContext highlighterContext) {
         SearchContextHighlight.Field field = highlighterContext.field;
         SearchContext context = highlighterContext.context;
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/Highlighter.java b/core/src/main/java/org/elasticsearch/search/highlight/Highlighter.java
index 26c3dc0..af4801f 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/Highlighter.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/Highlighter.java
@@ -25,8 +25,6 @@ import org.elasticsearch.index.mapper.FieldMapper;
  */
 public interface Highlighter {
 
-    String[] names();
-
     HighlightField highlight(HighlighterContext highlighterContext);
 
     boolean canHighlight(FieldMapper fieldMapper);
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/Highlighters.java b/core/src/main/java/org/elasticsearch/search/highlight/Highlighters.java
index 9f14b0f..349227f 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/Highlighters.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/Highlighters.java
@@ -18,44 +18,74 @@
  */
 package org.elasticsearch.search.highlight;
 
-import com.google.common.collect.ImmutableMap;
-import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.logging.DeprecationLogger;
+import org.elasticsearch.common.logging.ESLoggerFactory;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.ExtensionPoint;
 
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 
 /**
- *
+ * An extensions point and registry for all the highlighters a node supports.
  */
-public class Highlighters {
+public class Highlighters extends ExtensionPoint.MapExtensionPoint<Highlighter> {
+
+    @Deprecated // remove in 3.0
+    private static final String FAST_VECTOR_HIGHLIGHTER = "fast-vector-highlighter";
+    private static final String FVH = "fvh";
+    @Deprecated // remove in 3.0
+    private static final String HIGHLIGHTER = "highlighter";
+    private static final String PLAIN = "plain";
+    @Deprecated // remove in 3.0
+    private static final String POSTINGS_HIGHLIGHTER = "postings-highlighter";
+    private static final String POSTINGS = "postings";
+
 
     private final Map<String, Highlighter> parsers;
+    private final DeprecationLogger deprecationLogger = new DeprecationLogger(ESLoggerFactory.getLogger(Highlighters.class.getName()));
+
+    public Highlighters(){
+        this(Collections.EMPTY_MAP);
+    }
+
+    private Highlighters(Map<String, Highlighter> parsers) {
+        super("highlighter", Highlighter.class, new HashSet<>(Arrays.asList(FVH, FAST_VECTOR_HIGHLIGHTER, PLAIN, HIGHLIGHTER, POSTINGS, POSTINGS_HIGHLIGHTER)),
+                Highlighters.class);
+        this.parsers = Collections.unmodifiableMap(parsers);
+    }
 
     @Inject
-    public Highlighters(Settings settings, Set<Highlighter> parsers) {
+    public Highlighters(Settings settings, Map<String, Highlighter> parsers) {
+        this(addBuiltIns(settings, parsers));
+    }
+
+    private static Map<String, Highlighter> addBuiltIns(Settings settings, Map<String, Highlighter> parsers) {
         // build in highlighers
         Map<String, Highlighter> map = new HashMap<>();
-        add(map, new FastVectorHighlighter(settings));
-        add(map, new PlainHighlighter());
-        add(map, new PostingsHighlighter());
-        for (Highlighter highlighter : parsers) {
-            add(map, highlighter);
-        }
-        this.parsers = Collections.unmodifiableMap(map);
+        map.put(FVH,  new FastVectorHighlighter(settings));
+        map.put(FAST_VECTOR_HIGHLIGHTER, map.get(FVH));
+        map.put(PLAIN, new PlainHighlighter());
+        map.put(HIGHLIGHTER, map.get(PLAIN));
+        map.put(POSTINGS, new PostingsHighlighter());
+        map.put(POSTINGS_HIGHLIGHTER, map.get(POSTINGS));
+        map.putAll(parsers);
+        return map;
     }
 
     public Highlighter get(String type) {
-        return parsers.get(type);
-    }
-
-    private void add(Map<String, Highlighter> map, Highlighter highlighter) {
-        for (String type : highlighter.names()) {
-            map.put(type, highlighter);
+        switch (type) {
+            case FAST_VECTOR_HIGHLIGHTER:
+                deprecationLogger.deprecated("highlighter key [{}] is deprecated and will be removed in 3.x use [{}] instead", FAST_VECTOR_HIGHLIGHTER, FVH);
+                break;
+            case HIGHLIGHTER:
+                deprecationLogger.deprecated("highlighter key [{}] is deprecated and will be removed in 3.x use [{}] instead", HIGHLIGHTER, PLAIN);
+                break;
+            case POSTINGS_HIGHLIGHTER:
+                deprecationLogger.deprecated("highlighter key [{}] is deprecated and will be removed in 3.x use [{}] instead", POSTINGS_HIGHLIGHTER, POSTINGS);
+                break;
         }
+        return parsers.get(type);
     }
 
 }
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/PlainHighlighter.java b/core/src/main/java/org/elasticsearch/search/highlight/PlainHighlighter.java
index a9094f9..27f439a 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/PlainHighlighter.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/PlainHighlighter.java
@@ -48,11 +48,6 @@ public class PlainHighlighter implements Highlighter {
     private static final String CACHE_KEY = "highlight-plain";
 
     @Override
-    public String[] names() {
-        return new String[] { "plain", "highlighter" };
-    }
-
-    @Override
     public HighlightField highlight(HighlighterContext highlighterContext) {
         SearchContextHighlight.Field field = highlighterContext.field;
         SearchContext context = highlighterContext.context;
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/PostingsHighlighter.java b/core/src/main/java/org/elasticsearch/search/highlight/PostingsHighlighter.java
index 35f6560..270401a 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/PostingsHighlighter.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/PostingsHighlighter.java
@@ -41,11 +41,6 @@ public class PostingsHighlighter implements Highlighter {
     private static final String CACHE_KEY = "highlight-postings";
 
     @Override
-    public String[] names() {
-        return new String[]{"postings", "postings-highlighter"};
-    }
-
-    @Override
     public HighlightField highlight(HighlighterContext highlighterContext) {
 
         FieldMapper fieldMapper = highlighterContext.mapper;
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/Suggester.java b/core/src/main/java/org/elasticsearch/search/suggest/Suggester.java
index 51f5f21..7b3f7bd 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/Suggester.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/Suggester.java
@@ -29,8 +29,6 @@ public abstract class Suggester<T extends SuggestionSearchContext.SuggestionCont
     protected abstract Suggest.Suggestion<? extends Suggest.Suggestion.Entry<? extends Suggest.Suggestion.Entry.Option>>
         innerExecute(String name, T suggestion, IndexSearcher searcher, CharsRefBuilder spare) throws IOException;
 
-    public abstract String[] names();
-
     public abstract SuggestContextParser getContextParser();
 
     public Suggest.Suggestion<? extends Suggest.Suggestion.Entry<? extends Suggest.Suggestion.Entry.Option>>
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/Suggesters.java b/core/src/main/java/org/elasticsearch/search/suggest/Suggesters.java
index 264720b..1be80b5 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/Suggesters.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/Suggesters.java
@@ -18,45 +18,46 @@
  */
 package org.elasticsearch.search.suggest;
 
-import com.google.common.collect.ImmutableMap;
-import org.elasticsearch.common.collect.MapBuilder;
+import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.util.ExtensionPoint;
 import org.elasticsearch.script.ScriptService;
-import org.elasticsearch.search.aggregations.bucket.significant.heuristics.SignificanceHeuristicParser;
 import org.elasticsearch.search.suggest.completion.CompletionSuggester;
 import org.elasticsearch.search.suggest.phrase.PhraseSuggester;
 import org.elasticsearch.search.suggest.term.TermSuggester;
 
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 
 /**
  *
  */
-public class Suggesters {
+public final class Suggesters extends ExtensionPoint.MapExtensionPoint<Suggester> {
     private final Map<String, Suggester> parsers;
 
+    public Suggesters() {
+        this(Collections.EMPTY_MAP);
+    }
+
+    public Suggesters(Map<String, Suggester> suggesters) {
+        super("suggester", Suggester.class, new HashSet<>(Arrays.asList("phrase", "term", "completion")), Suggesters.class, SuggestParseElement.class, SuggestPhase.class);
+        this.parsers = Collections.unmodifiableMap(suggesters);
+    }
+
     @Inject
-    public Suggesters(Set<Suggester> suggesters, ScriptService scriptService) {
+    public Suggesters(Map<String, Suggester> suggesters, ScriptService scriptService) {
+        this(addBuildIns(suggesters, scriptService));
+    }
+
+    private static Map<String, Suggester> addBuildIns(Map<String, Suggester> suggesters, ScriptService scriptService) {
         final Map<String, Suggester> map = new HashMap<>();
-        add(map, new PhraseSuggester(scriptService));
-        add(map, new TermSuggester());
-        add(map, new CompletionSuggester());
-        for (Suggester suggester : suggesters) {
-           add(map, suggester);
-        }
-        this.parsers = Collections.unmodifiableMap(map);
+        map.put("phrase", new PhraseSuggester(scriptService));
+        map.put("term", new TermSuggester());
+        map.put("completion", new CompletionSuggester());
+        map.putAll(suggesters);
+        return map;
     }
 
     public Suggester get(String type) {
         return parsers.get(type);
     }
-
-    private void add(Map<String, Suggester> map, Suggester suggester) {
-        for (String type : suggester.names()) {
-            map.put(type, suggester);
-        }
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/completion/CompletionSuggester.java b/core/src/main/java/org/elasticsearch/search/suggest/completion/CompletionSuggester.java
index 4af360f..4a1d5d1 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/completion/CompletionSuggester.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/completion/CompletionSuggester.java
@@ -102,11 +102,6 @@ public class CompletionSuggester extends Suggester<CompletionSuggestionContext>
     }
 
     @Override
-    public String[] names() {
-        return new String[] { "completion" };
-    }
-
-    @Override
     public SuggestContextParser getContextParser() {
         return new CompletionSuggestParser(this);
     }
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggester.java b/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggester.java
index 30c1b63..e7d0eb3 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggester.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/phrase/PhraseSuggester.java
@@ -151,11 +151,6 @@ public final class PhraseSuggester extends Suggester<PhraseSuggestionContext> {
     }
     
     @Override
-    public String[] names() {
-        return new String[] {"phrase"};
-    }
-
-    @Override
     public SuggestContextParser getContextParser() {
         return new PhraseSuggestParser(this);
     }
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/term/TermSuggester.java b/core/src/main/java/org/elasticsearch/search/suggest/term/TermSuggester.java
index 70dfefe..4c1b176 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/term/TermSuggester.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/term/TermSuggester.java
@@ -66,11 +66,6 @@ public final class TermSuggester extends Suggester<TermSuggestionContext> {
     }
 
     @Override
-    public String[] names() {
-        return new String[] {"term"};
-    }
-
-    @Override
     public SuggestContextParser getContextParser() {
         return new TermSuggestParser(this);
     }
diff --git a/core/src/test/java/org/elasticsearch/cache/recycler/MockPageCacheRecycler.java b/core/src/test/java/org/elasticsearch/cache/recycler/MockPageCacheRecycler.java
deleted file mode 100644
index 1f8ec84..0000000
--- a/core/src/test/java/org/elasticsearch/cache/recycler/MockPageCacheRecycler.java
+++ /dev/null
@@ -1,152 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.cache.recycler;
-
-import com.google.common.base.Predicate;
-import com.google.common.collect.Maps;
-import com.google.common.collect.Sets;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.recycler.Recycler.V;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.node.NodeModule;
-import org.elasticsearch.plugins.AbstractPlugin;
-import org.elasticsearch.test.ESTestCase;
-import org.elasticsearch.test.InternalTestCluster;
-import org.elasticsearch.threadpool.ThreadPool;
-
-import java.lang.reflect.Array;
-import java.util.Arrays;
-import java.util.Map;
-import java.util.Random;
-import java.util.concurrent.ConcurrentMap;
-
-public class MockPageCacheRecycler extends PageCacheRecycler {
-
-    private static final ConcurrentMap<Object, Throwable> ACQUIRED_PAGES = Maps.newConcurrentMap();
-
-    public static void ensureAllPagesAreReleased() throws Exception {
-        final Map<Object, Throwable> masterCopy = Maps.newHashMap(ACQUIRED_PAGES);
-        if (!masterCopy.isEmpty()) {
-            // not empty, we might be executing on a shared cluster that keeps on obtaining
-            // and releasing pages, lets make sure that after a reasonable timeout, all master
-            // copy (snapshot) have been released
-            boolean success = ESTestCase.awaitBusy(new Predicate<Object>() {
-                @Override
-                public boolean apply(Object input) {
-                    return Sets.intersection(masterCopy.keySet(), ACQUIRED_PAGES.keySet()).isEmpty();
-                }
-            });
-            if (!success) {
-                masterCopy.keySet().retainAll(ACQUIRED_PAGES.keySet());
-                ACQUIRED_PAGES.keySet().removeAll(masterCopy.keySet()); // remove all existing master copy we will report on
-                if (!masterCopy.isEmpty()) {
-                    final Throwable t = masterCopy.entrySet().iterator().next().getValue();
-                    throw new RuntimeException(masterCopy.size() + " pages have not been released", t);
-                }
-            }
-        }
-    }
-
-    private final Random random;
-
-    @Inject
-    public MockPageCacheRecycler(Settings settings, ThreadPool threadPool) {
-        super(settings, threadPool);
-        final long seed = settings.getAsLong(InternalTestCluster.SETTING_CLUSTER_NODE_SEED, 0L);
-        random = new Random(seed);
-    }
-
-    private <T> V<T> wrap(final V<T> v) {
-        ACQUIRED_PAGES.put(v, new Throwable());
-        return new V<T>() {
-
-            @Override
-            public void close() {
-                final Throwable t = ACQUIRED_PAGES.remove(v);
-                if (t == null) {
-                    throw new IllegalStateException("Releasing a page that has not been acquired");
-                }
-                final T ref = v();
-                if (ref instanceof Object[]) {
-                    Arrays.fill((Object[])ref, 0, Array.getLength(ref), null);
-                } else if (ref instanceof byte[]) {
-                    Arrays.fill((byte[])ref, 0, Array.getLength(ref), (byte) random.nextInt(256));
-                } else if (ref instanceof long[]) {
-                    Arrays.fill((long[])ref, 0, Array.getLength(ref), random.nextLong());
-                } else if (ref instanceof int[]) {
-                    Arrays.fill((int[])ref, 0, Array.getLength(ref), random.nextInt());
-                } else if (ref instanceof double[]) {
-                    Arrays.fill((double[])ref, 0, Array.getLength(ref), random.nextDouble() - 0.5);
-                } else if (ref instanceof float[]) {
-                    Arrays.fill((float[])ref, 0, Array.getLength(ref), random.nextFloat() - 0.5f);
-                } else {
-                    for (int i = 0; i < Array.getLength(ref); ++i) {
-                            Array.set(ref, i, (byte) random.nextInt(256));
-                    }
-                }
-                v.close();
-            }
-
-            @Override
-            public T v() {
-                return v.v();
-            }
-
-            @Override
-            public boolean isRecycled() {
-                return v.isRecycled();
-            }
-
-        };
-    }
-
-    @Override
-    public V<byte[]> bytePage(boolean clear) {
-        final V<byte[]> page = super.bytePage(clear);
-        if (!clear) {
-            Arrays.fill(page.v(), 0, page.v().length, (byte)random.nextInt(1<<8));
-        }
-        return wrap(page);
-    }
-
-    @Override
-    public V<int[]> intPage(boolean clear) {
-        final V<int[]> page = super.intPage(clear);
-        if (!clear) {
-            Arrays.fill(page.v(), 0, page.v().length, random.nextInt());
-        }
-        return wrap(page);
-    }
-
-    @Override
-    public V<long[]> longPage(boolean clear) {
-        final V<long[]> page = super.longPage(clear);
-        if (!clear) {
-            Arrays.fill(page.v(), 0, page.v().length, random.nextLong());
-        }
-        return wrap(page);
-    }
-
-    @Override
-    public V<Object[]> objectPage() {
-        return wrap(super.objectPage());
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/cluster/MockInternalClusterInfoService.java b/core/src/test/java/org/elasticsearch/cluster/MockInternalClusterInfoService.java
deleted file mode 100644
index 9331834..0000000
--- a/core/src/test/java/org/elasticsearch/cluster/MockInternalClusterInfoService.java
+++ /dev/null
@@ -1,95 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.cluster;
-
-import org.elasticsearch.action.ActionListener;
-import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
-import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;
-import org.elasticsearch.action.admin.cluster.node.stats.TransportNodesStatsAction;
-import org.elasticsearch.action.admin.indices.stats.IndicesStatsResponse;
-import org.elasticsearch.action.admin.indices.stats.TransportIndicesStatsAction;
-import org.elasticsearch.cluster.routing.allocation.decider.MockDiskUsagesIT;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.node.settings.NodeSettingsService;
-import org.elasticsearch.plugins.AbstractPlugin;
-import org.elasticsearch.threadpool.ThreadPool;
-
-import java.util.concurrent.CountDownLatch;
-
-/**
- * Fake ClusterInfoService class that allows updating the nodes stats disk
- * usage with fake values
- */
-public class MockInternalClusterInfoService extends InternalClusterInfoService {
-
-    public static class Plugin extends AbstractPlugin {
-        @Override
-        public String name() {
-            return "mock-cluster-info-service";
-        }
-        @Override
-        public String description() {
-            return "a mock cluster info service for testing";
-        }
-        public void onModule(ClusterModule module) {
-            module.clusterInfoServiceImpl = MockInternalClusterInfoService.class;
-        }
-    }
-
-    private final ClusterName clusterName;
-    private volatile NodeStats[] stats = new NodeStats[3];
-
-    @Inject
-    public MockInternalClusterInfoService(Settings settings, NodeSettingsService nodeSettingsService,
-                                          TransportNodesStatsAction transportNodesStatsAction,
-                                          TransportIndicesStatsAction transportIndicesStatsAction,
-                                          ClusterService clusterService, ThreadPool threadPool) {
-        super(settings, nodeSettingsService, transportNodesStatsAction, transportIndicesStatsAction, clusterService, threadPool);
-        this.clusterName = ClusterName.clusterNameFromSettings(settings);
-        stats[0] = MockDiskUsagesIT.makeStats("node_t1", new DiskUsage("node_t1", "n1", 100, 100));
-        stats[1] = MockDiskUsagesIT.makeStats("node_t2", new DiskUsage("node_t2", "n2", 100, 100));
-        stats[2] = MockDiskUsagesIT.makeStats("node_t3", new DiskUsage("node_t3", "n3", 100, 100));
-    }
-
-    public void setN1Usage(String nodeName, DiskUsage newUsage) {
-        stats[0] = MockDiskUsagesIT.makeStats(nodeName, newUsage);
-    }
-
-    public void setN2Usage(String nodeName, DiskUsage newUsage) {
-        stats[1] = MockDiskUsagesIT.makeStats(nodeName, newUsage);
-    }
-
-    public void setN3Usage(String nodeName, DiskUsage newUsage) {
-        stats[2] = MockDiskUsagesIT.makeStats(nodeName, newUsage);
-    }
-
-    @Override
-    public CountDownLatch updateNodeStats(final ActionListener<NodesStatsResponse> listener) {
-        NodesStatsResponse response = new NodesStatsResponse(clusterName, stats);
-        listener.onResponse(response);
-        return new CountDownLatch(0);
-    }
-
-    @Override
-    public CountDownLatch updateIndicesStats(final ActionListener<IndicesStatsResponse> listener) {
-        // Not used, so noop
-        return new CountDownLatch(0);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationModuleTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationModuleTests.java
index 678bfa3..7b57ef0 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationModuleTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationModuleTests.java
@@ -59,8 +59,7 @@ public class AllocationModuleTests extends ModuleTestCase {
         try {
             module.registerAllocationDecider(EnableAllocationDecider.class);
         } catch (IllegalArgumentException e) {
-            assertTrue(e.getMessage().contains("Cannot register AllocationDecider"));
-            assertTrue(e.getMessage().contains("twice"));
+            assertEquals(e.getMessage(), "Can't register the same [allocation_decider] more than once for [" + EnableAllocationDecider.class.getName() + "]");
         }
     }
 
@@ -82,14 +81,14 @@ public class AllocationModuleTests extends ModuleTestCase {
         try {
             module.registerShardAllocator(AllocationModule.BALANCED_ALLOCATOR, FakeShardsAllocator.class);
         } catch (IllegalArgumentException e) {
-            assertTrue(e.getMessage().contains("already registered"));
+            assertEquals(e.getMessage(), "Can't register the same [shards_allocator] more than once for [balanced]");
         }
     }
 
     public void testUnknownShardsAllocator() {
         Settings settings = Settings.builder().put(AllocationModule.SHARDS_ALLOCATOR_TYPE_KEY, "dne").build();
         AllocationModule module = new AllocationModule(settings);
-        assertBindingFailure(module, "Unknown ShardsAllocator");
+        assertBindingFailure(module, "Unknown [shards_allocator]");
     }
 
     public void testEvenShardsAllocatorBackcompat() {
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java
index 79612d0..a24e980 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java
@@ -20,20 +20,28 @@
 package org.elasticsearch.cluster.routing.allocation.decider;
 
 import org.elasticsearch.Version;
+import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
 import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;
+import org.elasticsearch.action.admin.cluster.node.stats.TransportNodesStatsAction;
 import org.elasticsearch.action.admin.cluster.state.ClusterStateResponse;
+import org.elasticsearch.action.admin.indices.stats.IndicesStatsResponse;
+import org.elasticsearch.action.admin.indices.stats.TransportIndicesStatsAction;
 import org.elasticsearch.cluster.*;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.RoutingNode;
+import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.monitor.fs.FsInfo;
+import org.elasticsearch.node.settings.NodeSettingsService;
 import org.elasticsearch.test.ESIntegTestCase;
+import org.elasticsearch.threadpool.ThreadPool;
 import org.junit.Test;
 
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
+import java.util.concurrent.CountDownLatch;
 
 import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.newHashMap;
@@ -49,8 +57,8 @@ public class MockDiskUsagesIT extends ESIntegTestCase {
     protected Settings nodeSettings(int nodeOrdinal) {
         return Settings.builder()
                 .put(super.nodeSettings(nodeOrdinal))
-                    // Use the mock internal cluster info service, which has fake-able disk usages
-                .extendArray("plugin.types", MockInternalClusterInfoService.Plugin.class.getName())
+                        // Use the mock internal cluster info service, which has fake-able disk usages
+                .put(ClusterModule.CLUSTER_SERVICE_IMPL, MockInternalClusterInfoService.class.getName())
                         // Update more frequently
                 .put(InternalClusterInfoService.INTERNAL_CLUSTER_INFO_UPDATE_INTERVAL, "1s")
                 .build();
@@ -175,4 +183,50 @@ public class MockDiskUsagesIT extends ESIntegTestCase {
                 null);
     }
 
+    /**
+     * Fake ClusterInfoService class that allows updating the nodes stats disk
+     * usage with fake values
+     */
+    public static class MockInternalClusterInfoService extends InternalClusterInfoService {
+
+        private final ClusterName clusterName;
+        private volatile NodeStats[] stats = new NodeStats[3];
+
+        @Inject
+        public MockInternalClusterInfoService(Settings settings, NodeSettingsService nodeSettingsService,
+                                              TransportNodesStatsAction transportNodesStatsAction,
+                                              TransportIndicesStatsAction transportIndicesStatsAction,
+                                              ClusterService clusterService, ThreadPool threadPool) {
+            super(settings, nodeSettingsService, transportNodesStatsAction, transportIndicesStatsAction, clusterService, threadPool);
+            this.clusterName = ClusterName.clusterNameFromSettings(settings);
+            stats[0] = makeStats("node_t1", new DiskUsage("node_t1", "n1", 100, 100));
+            stats[1] = makeStats("node_t2", new DiskUsage("node_t2", "n2", 100, 100));
+            stats[2] = makeStats("node_t3", new DiskUsage("node_t3", "n3", 100, 100));
+        }
+
+        public void setN1Usage(String nodeName, DiskUsage newUsage) {
+            stats[0] = makeStats(nodeName, newUsage);
+        }
+
+        public void setN2Usage(String nodeName, DiskUsage newUsage) {
+            stats[1] = makeStats(nodeName, newUsage);
+        }
+
+        public void setN3Usage(String nodeName, DiskUsage newUsage) {
+            stats[2] = makeStats(nodeName, newUsage);
+        }
+
+        @Override
+        public CountDownLatch updateNodeStats(final ActionListener<NodesStatsResponse> listener) {
+            NodesStatsResponse response = new NodesStatsResponse(clusterName, stats);
+            listener.onResponse(response);
+            return new CountDownLatch(0);
+        }
+
+        @Override
+        public CountDownLatch updateIndicesStats(final ActionListener<IndicesStatsResponse> listener) {
+            // Not used, so noop
+            return new CountDownLatch(0);
+        }
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java b/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java
index d96b89d..60c3ca1 100644
--- a/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java
+++ b/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java
@@ -73,6 +73,37 @@ public abstract class ModuleTestCase extends ESTestCase {
     }
 
     /**
+     * Configures the module and checks a Map<String, Class> of the "to" class
+     * is bound to "theClas".
+     */
+    public void assertMapMultiBinding(Module module, Class to, Class theClass) {
+        List<Element> elements = Elements.getElements(module);
+        Set<Type> bindings = new HashSet<>();
+        boolean providerFound = false;
+        for (Element element : elements) {
+            if (element instanceof LinkedKeyBinding) {
+                LinkedKeyBinding binding = (LinkedKeyBinding)element;
+                if (to.equals(binding.getKey().getTypeLiteral().getType())) {
+                    bindings.add(binding.getLinkedKey().getTypeLiteral().getType());
+                }
+            } else if (element instanceof ProviderInstanceBinding) {
+                ProviderInstanceBinding binding = (ProviderInstanceBinding)element;
+                String setType = binding.getKey().getTypeLiteral().getType().toString();
+                if (setType.equals("java.util.Map<java.lang.String, " + to.getName() + ">")) {
+                    providerFound = true;
+                }
+            }
+        }
+
+        if (bindings.contains(theClass) == false) {
+            fail("Expected to find " + theClass.getName() + " as binding to " + to.getName() + ", found these classes:\n" + bindings);
+        }
+        assertTrue("Did not find provider for map of " + to.getName(), providerFound);
+    }
+
+
+
+    /**
      * Configures the module and checks a Set of the "to" class
      * is bound to "classes". There may be more classes bound
      * to "to" than just "classes".
diff --git a/core/src/test/java/org/elasticsearch/common/settings/loader/YamlSettingsLoaderTests.java b/core/src/test/java/org/elasticsearch/common/settings/loader/YamlSettingsLoaderTests.java
index e43f5e7..362188e 100644
--- a/core/src/test/java/org/elasticsearch/common/settings/loader/YamlSettingsLoaderTests.java
+++ b/core/src/test/java/org/elasticsearch/common/settings/loader/YamlSettingsLoaderTests.java
@@ -63,4 +63,17 @@ public class YamlSettingsLoaderTests extends ESTestCase {
                 .loadFromClasspath("org/elasticsearch/common/settings/loader/indentation-with-explicit-document-start-settings.yml")
                 .build();
     }
+
+    
+    @Test
+    public void testYamlSettingsNoFile() throws Exception {
+        String invalidResourceName = "org/elasticsearch/common/settings/loader/no-test-settings.yml";
+        try {
+            Settings defaultSettings = settingsBuilder().loadFromClasspath(invalidResourceName).build();
+            fail("For a not exiting file an exception should be thrown.");
+        } catch (Exception e) {
+            assertTrue(e instanceof SettingsException);
+            assertThat(e.getMessage(), equalTo("Failed to load settings from [" + invalidResourceName + "]"));
+        }
+    }
 }
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/common/util/BigArraysTests.java b/core/src/test/java/org/elasticsearch/common/util/BigArraysTests.java
index 7d36c09..01fae51 100644
--- a/core/src/test/java/org/elasticsearch/common/util/BigArraysTests.java
+++ b/core/src/test/java/org/elasticsearch/common/util/BigArraysTests.java
@@ -29,6 +29,7 @@ import org.elasticsearch.indices.breaker.HierarchyCircuitBreakerService;
 import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
 import org.elasticsearch.node.settings.NodeSettingsService;
 import org.elasticsearch.test.ESSingleNodeTestCase;
+import org.elasticsearch.test.cache.recycler.MockBigArrays;
 import org.junit.Before;
 
 import java.lang.reflect.InvocationTargetException;
diff --git a/core/src/test/java/org/elasticsearch/common/util/MockBigArrays.java b/core/src/test/java/org/elasticsearch/common/util/MockBigArrays.java
deleted file mode 100644
index 4eb4a37..0000000
--- a/core/src/test/java/org/elasticsearch/common/util/MockBigArrays.java
+++ /dev/null
@@ -1,560 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.common.util;
-
-import com.carrotsearch.randomizedtesting.RandomizedContext;
-import com.carrotsearch.randomizedtesting.SeedUtils;
-import com.google.common.base.Predicate;
-import com.google.common.collect.Maps;
-import com.google.common.collect.Sets;
-
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Accountables;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.cache.recycler.PageCacheRecycler;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.indices.breaker.CircuitBreakerService;
-import org.elasticsearch.plugins.AbstractPlugin;
-import org.elasticsearch.test.ESTestCase;
-
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Map;
-import java.util.Random;
-import java.util.Set;
-import java.util.WeakHashMap;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.atomic.AtomicBoolean;
-
-public class MockBigArrays extends BigArrays {
-
-    /**
-     * Tracking allocations is useful when debugging a leak but shouldn't be enabled by default as this would also be very costly
-     * since it creates a new Exception every time a new array is created.
-     */
-    private static final boolean TRACK_ALLOCATIONS = false;
-
-    private static final Set<BigArrays> INSTANCES = Collections.synchronizedSet(Collections.newSetFromMap(new WeakHashMap<BigArrays, Boolean>()));
-    private static final ConcurrentMap<Object, Object> ACQUIRED_ARRAYS = new ConcurrentHashMap<>();
-
-    public static void ensureAllArraysAreReleased() throws Exception {
-        final Map<Object, Object> masterCopy = Maps.newHashMap(ACQUIRED_ARRAYS);
-        if (!masterCopy.isEmpty()) {
-            // not empty, we might be executing on a shared cluster that keeps on obtaining
-            // and releasing arrays, lets make sure that after a reasonable timeout, all master
-            // copy (snapshot) have been released
-            boolean success = ESTestCase.awaitBusy(new Predicate<Object>() {
-                @Override
-                public boolean apply(Object input) {
-                    return Sets.intersection(masterCopy.keySet(), ACQUIRED_ARRAYS.keySet()).isEmpty();
-                }
-            });
-            if (!success) {
-                masterCopy.keySet().retainAll(ACQUIRED_ARRAYS.keySet());
-                ACQUIRED_ARRAYS.keySet().removeAll(masterCopy.keySet()); // remove all existing master copy we will report on
-                if (!masterCopy.isEmpty()) {
-                    final Object cause = masterCopy.entrySet().iterator().next().getValue();
-                    throw new RuntimeException(masterCopy.size() + " arrays have not been released", cause instanceof Throwable ? (Throwable) cause : null);
-                }
-            }
-        }
-    }
-
-    private final Random random;
-    private final PageCacheRecycler recycler;
-    private final CircuitBreakerService breakerService;
-
-    @Inject
-    public MockBigArrays(PageCacheRecycler recycler, CircuitBreakerService breakerService) {
-        this(recycler, breakerService, false);
-    }
-
-    public MockBigArrays(PageCacheRecycler recycler, CircuitBreakerService breakerService, boolean checkBreaker) {
-        super(recycler, breakerService, checkBreaker);
-        this.recycler = recycler;
-        this.breakerService = breakerService;
-        long seed;
-        try {
-            seed = SeedUtils.parseSeed(RandomizedContext.current().getRunnerSeedAsString());
-        } catch (IllegalStateException e) { // rest tests don't run randomized and have no context
-            seed = 0;
-        }
-        random = new Random(seed);
-        INSTANCES.add(this);
-    }
-
-
-    @Override
-    public BigArrays withCircuitBreaking() {
-        return new MockBigArrays(this.recycler, this.breakerService, true);
-    }
-
-    @Override
-    public ByteArray newByteArray(long size, boolean clearOnResize) {
-        final ByteArrayWrapper array = new ByteArrayWrapper(super.newByteArray(size, clearOnResize), clearOnResize);
-        if (!clearOnResize) {
-            array.randomizeContent(0, size);
-        }
-        return array;
-    }
-
-    @Override
-    public ByteArray resize(ByteArray array, long size) {
-        ByteArrayWrapper arr = (ByteArrayWrapper) array;
-        final long originalSize = arr.size();
-        array = super.resize(arr.in, size);
-        ACQUIRED_ARRAYS.remove(arr);
-        if (array instanceof ByteArrayWrapper) {
-            arr = (ByteArrayWrapper) array;
-        } else {
-            arr = new ByteArrayWrapper(array, arr.clearOnResize);
-        }
-        if (!arr.clearOnResize) {
-            arr.randomizeContent(originalSize, size);
-        }
-        return arr;
-    }
-
-    @Override
-    public IntArray newIntArray(long size, boolean clearOnResize) {
-        final IntArrayWrapper array = new IntArrayWrapper(super.newIntArray(size, clearOnResize), clearOnResize);
-        if (!clearOnResize) {
-            array.randomizeContent(0, size);
-        }
-        return array;
-    }
-
-    @Override
-    public IntArray resize(IntArray array, long size) {
-        IntArrayWrapper arr = (IntArrayWrapper) array;
-        final long originalSize = arr.size();
-        array = super.resize(arr.in, size);
-        ACQUIRED_ARRAYS.remove(arr);
-        if (array instanceof IntArrayWrapper) {
-            arr = (IntArrayWrapper) array;
-        } else {
-            arr = new IntArrayWrapper(array, arr.clearOnResize);
-        }
-        if (!arr.clearOnResize) {
-            arr.randomizeContent(originalSize, size);
-        }
-        return arr;
-    }
-
-    @Override
-    public LongArray newLongArray(long size, boolean clearOnResize) {
-        final LongArrayWrapper array = new LongArrayWrapper(super.newLongArray(size, clearOnResize), clearOnResize);
-        if (!clearOnResize) {
-            array.randomizeContent(0, size);
-        }
-        return array;
-    }
-
-    @Override
-    public LongArray resize(LongArray array, long size) {
-        LongArrayWrapper arr = (LongArrayWrapper) array;
-        final long originalSize = arr.size();
-        array = super.resize(arr.in, size);
-        ACQUIRED_ARRAYS.remove(arr);
-        if (array instanceof LongArrayWrapper) {
-            arr = (LongArrayWrapper) array;
-        } else {
-            arr = new LongArrayWrapper(array, arr.clearOnResize);
-        }
-        if (!arr.clearOnResize) {
-            arr.randomizeContent(originalSize, size);
-        }
-        return arr;
-    }
-
-    @Override
-    public FloatArray newFloatArray(long size, boolean clearOnResize) {
-        final FloatArrayWrapper array = new FloatArrayWrapper(super.newFloatArray(size, clearOnResize), clearOnResize);
-        if (!clearOnResize) {
-            array.randomizeContent(0, size);
-        }
-        return array;
-    }
-
-    @Override
-    public FloatArray resize(FloatArray array, long size) {
-        FloatArrayWrapper arr = (FloatArrayWrapper) array;
-        final long originalSize = arr.size();
-        array = super.resize(arr.in, size);
-        ACQUIRED_ARRAYS.remove(arr);
-        if (array instanceof FloatArrayWrapper) {
-            arr = (FloatArrayWrapper) array;
-        } else {
-            arr = new FloatArrayWrapper(array, arr.clearOnResize);
-        }
-        if (!arr.clearOnResize) {
-            arr.randomizeContent(originalSize, size);
-        }
-        return arr;
-    }
-
-    @Override
-    public DoubleArray newDoubleArray(long size, boolean clearOnResize) {
-        final DoubleArrayWrapper array = new DoubleArrayWrapper(super.newDoubleArray(size, clearOnResize), clearOnResize);
-        if (!clearOnResize) {
-            array.randomizeContent(0, size);
-        }
-        return array;
-    }
-
-    @Override
-    public DoubleArray resize(DoubleArray array, long size) {
-        DoubleArrayWrapper arr = (DoubleArrayWrapper) array;
-        final long originalSize = arr.size();
-        array = super.resize(arr.in, size);
-        ACQUIRED_ARRAYS.remove(arr);
-        if (array instanceof DoubleArrayWrapper) {
-            arr = (DoubleArrayWrapper) array;
-        } else {
-            arr = new DoubleArrayWrapper(array, arr.clearOnResize);
-        }
-        if (!arr.clearOnResize) {
-            arr.randomizeContent(originalSize, size);
-        }
-        return arr;
-    }
-
-    @Override
-    public <T> ObjectArray<T> newObjectArray(long size) {
-        return new ObjectArrayWrapper<>(super.<T>newObjectArray(size));
-    }
-
-    @Override
-    public <T> ObjectArray<T> resize(ObjectArray<T> array, long size) {
-        ObjectArrayWrapper<T> arr = (ObjectArrayWrapper<T>) array;
-        array = super.resize(arr.in, size);
-        ACQUIRED_ARRAYS.remove(arr);
-        if (array instanceof ObjectArrayWrapper) {
-            arr = (ObjectArrayWrapper<T>) array;
-        } else {
-            arr = new ObjectArrayWrapper<>(array);
-        }
-        return arr;
-    }
-
-    private static abstract class AbstractArrayWrapper {
-
-        final BigArray in;
-        boolean clearOnResize;
-        AtomicBoolean released;
-
-        AbstractArrayWrapper(BigArray in, boolean clearOnResize) {
-            ACQUIRED_ARRAYS.put(this, TRACK_ALLOCATIONS ? new RuntimeException() : Boolean.TRUE);
-            this.in = in;
-            this.clearOnResize = clearOnResize;
-            released = new AtomicBoolean(false);
-        }
-
-        protected abstract BigArray getDelegate();
-
-        protected abstract void randomizeContent(long from, long to);
-
-        public long size() {
-            return getDelegate().size();
-        }
-
-        public long ramBytesUsed() {
-            return in.ramBytesUsed();
-        }
-
-        public void close() {
-            if (!released.compareAndSet(false, true)) {
-                throw new IllegalStateException("Double release");
-            }
-            ACQUIRED_ARRAYS.remove(this);
-            randomizeContent(0, size());
-            getDelegate().close();
-        }
-
-    }
-
-    private class ByteArrayWrapper extends AbstractArrayWrapper implements ByteArray {
-
-        private final ByteArray in;
-
-        ByteArrayWrapper(ByteArray in, boolean clearOnResize) {
-            super(in, clearOnResize);
-            this.in = in;
-        }
-
-        @Override
-        protected BigArray getDelegate() {
-            return in;
-        }
-
-        @Override
-        protected void randomizeContent(long from, long to) {
-            fill(from, to, (byte) random.nextInt(1 << 8));
-        }
-
-        @Override
-        public byte get(long index) {
-            return in.get(index);
-        }
-
-        @Override
-        public byte set(long index, byte value) {
-            return in.set(index, value);
-        }
-
-        @Override
-        public boolean get(long index, int len, BytesRef ref) {
-            return in.get(index, len, ref);
-        }
-
-        @Override
-        public void set(long index, byte[] buf, int offset, int len) {
-            in.set(index, buf, offset, len);
-        }
-
-        @Override
-        public void fill(long fromIndex, long toIndex, byte value) {
-            in.fill(fromIndex, toIndex, value);
-        }
-
-        @Override
-        public Collection<Accountable> getChildResources() {
-            return Collections.singleton(Accountables.namedAccountable("delegate", in));
-        }
-    }
-
-    private class IntArrayWrapper extends AbstractArrayWrapper implements IntArray {
-
-        private final IntArray in;
-
-        IntArrayWrapper(IntArray in, boolean clearOnResize) {
-            super(in, clearOnResize);
-            this.in = in;
-        }
-
-        @Override
-        protected BigArray getDelegate() {
-            return in;
-        }
-
-        @Override
-        protected void randomizeContent(long from, long to) {
-            fill(from, to, random.nextInt());
-        }
-
-        @Override
-        public int get(long index) {
-            return in.get(index);
-        }
-
-        @Override
-        public int set(long index, int value) {
-            return in.set(index, value);
-        }
-
-        @Override
-        public int increment(long index, int inc) {
-            return in.increment(index, inc);
-        }
-
-        @Override
-        public void fill(long fromIndex, long toIndex, int value) {
-            in.fill(fromIndex, toIndex, value);
-        }
-        
-        @Override
-        public Collection<Accountable> getChildResources() {
-            return Collections.singleton(Accountables.namedAccountable("delegate", in));
-        }
-    }
-
-    private class LongArrayWrapper extends AbstractArrayWrapper implements LongArray {
-
-        private final LongArray in;
-
-        LongArrayWrapper(LongArray in, boolean clearOnResize) {
-            super(in, clearOnResize);
-            this.in = in;
-        }
-
-        @Override
-        protected BigArray getDelegate() {
-            return in;
-        }
-
-        @Override
-        protected void randomizeContent(long from, long to) {
-            fill(from, to, random.nextLong());
-        }
-
-        @Override
-        public long get(long index) {
-            return in.get(index);
-        }
-
-        @Override
-        public long set(long index, long value) {
-            return in.set(index, value);
-        }
-
-        @Override
-        public long increment(long index, long inc) {
-            return in.increment(index, inc);
-        }
-
-        @Override
-        public void fill(long fromIndex, long toIndex, long value) {
-            in.fill(fromIndex, toIndex, value);
-        }
-        
-        @Override
-        public Collection<Accountable> getChildResources() {
-            return Collections.singleton(Accountables.namedAccountable("delegate", in));
-        }
-
-    }
-
-    private class FloatArrayWrapper extends AbstractArrayWrapper implements FloatArray {
-
-        private final FloatArray in;
-
-        FloatArrayWrapper(FloatArray in, boolean clearOnResize) {
-            super(in, clearOnResize);
-            this.in = in;
-        }
-
-        @Override
-        protected BigArray getDelegate() {
-            return in;
-        }
-
-        @Override
-        protected void randomizeContent(long from, long to) {
-            fill(from, to, (random.nextFloat() - 0.5f) * 1000);
-        }
-
-        @Override
-        public float get(long index) {
-            return in.get(index);
-        }
-
-        @Override
-        public float set(long index, float value) {
-            return in.set(index, value);
-        }
-
-        @Override
-        public float increment(long index, float inc) {
-            return in.increment(index, inc);
-        }
-
-        @Override
-        public void fill(long fromIndex, long toIndex, float value) {
-            in.fill(fromIndex, toIndex, value);
-        }
-
-        @Override
-        public Collection<Accountable> getChildResources() {
-            return Collections.singleton(Accountables.namedAccountable("delegate", in));
-        }
-    }
-
-    private class DoubleArrayWrapper extends AbstractArrayWrapper implements DoubleArray {
-
-        private final DoubleArray in;
-
-        DoubleArrayWrapper(DoubleArray in, boolean clearOnResize) {
-            super(in, clearOnResize);
-            this.in = in;
-        }
-
-        @Override
-        protected BigArray getDelegate() {
-            return in;
-        }
-
-        @Override
-        protected void randomizeContent(long from, long to) {
-            fill(from, to, (random.nextDouble() - 0.5) * 1000);
-        }
-
-        @Override
-        public double get(long index) {
-            return in.get(index);
-        }
-
-        @Override
-        public double set(long index, double value) {
-            return in.set(index, value);
-        }
-
-        @Override
-        public double increment(long index, double inc) {
-            return in.increment(index, inc);
-        }
-
-        @Override
-        public void fill(long fromIndex, long toIndex, double value) {
-            in.fill(fromIndex, toIndex, value);
-        }
-
-        @Override
-        public Collection<Accountable> getChildResources() {
-            return Collections.singleton(Accountables.namedAccountable("delegate", in));
-        }
-    }
-
-    private class ObjectArrayWrapper<T> extends AbstractArrayWrapper implements ObjectArray<T> {
-
-        private final ObjectArray<T> in;
-
-        ObjectArrayWrapper(ObjectArray<T> in) {
-            super(in, false);
-            this.in = in;
-        }
-
-        @Override
-        protected BigArray getDelegate() {
-            return in;
-        }
-
-        @Override
-        public T get(long index) {
-            return in.get(index);
-        }
-
-        @Override
-        public T set(long index, T value) {
-            return in.set(index, value);
-        }
-
-        @Override
-        protected void randomizeContent(long from, long to) {
-            // will be cleared anyway
-        }
-
-        @Override
-        public Collection<Accountable> getChildResources() {
-            return Collections.singleton(Accountables.namedAccountable("delegate", in));
-        }
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/http/netty/NettyHttpChannelTests.java b/core/src/test/java/org/elasticsearch/http/netty/NettyHttpChannelTests.java
index 0a4b057..a2eb956 100644
--- a/core/src/test/java/org/elasticsearch/http/netty/NettyHttpChannelTests.java
+++ b/core/src/test/java/org/elasticsearch/http/netty/NettyHttpChannelTests.java
@@ -27,8 +27,8 @@ import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
 import org.elasticsearch.rest.RestResponse;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.test.ESTestCase;
-import org.elasticsearch.common.util.MockBigArrays;
-import org.elasticsearch.cache.recycler.MockPageCacheRecycler;
+import org.elasticsearch.test.cache.recycler.MockBigArrays;
+import org.elasticsearch.test.cache.recycler.MockPageCacheRecycler;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.jboss.netty.buffer.ChannelBuffer;
 import org.jboss.netty.buffer.ChannelBuffers;
diff --git a/core/src/test/java/org/elasticsearch/http/netty/NettyHttpServerPipeliningTest.java b/core/src/test/java/org/elasticsearch/http/netty/NettyHttpServerPipeliningTest.java
index de923f5..07678d9 100644
--- a/core/src/test/java/org/elasticsearch/http/netty/NettyHttpServerPipeliningTest.java
+++ b/core/src/test/java/org/elasticsearch/http/netty/NettyHttpServerPipeliningTest.java
@@ -29,8 +29,8 @@ import org.elasticsearch.http.netty.pipelining.OrderedDownstreamChannelEvent;
 import org.elasticsearch.http.netty.pipelining.OrderedUpstreamMessageEvent;
 import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
 import org.elasticsearch.test.ESTestCase;
-import org.elasticsearch.common.util.MockBigArrays;
-import org.elasticsearch.cache.recycler.MockPageCacheRecycler;
+import org.elasticsearch.test.cache.recycler.MockBigArrays;
+import org.elasticsearch.test.cache.recycler.MockPageCacheRecycler;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.jboss.netty.buffer.ChannelBuffer;
 import org.jboss.netty.buffer.ChannelBuffers;
diff --git a/core/src/test/java/org/elasticsearch/index/shard/MockEngineFactoryPlugin.java b/core/src/test/java/org/elasticsearch/index/shard/MockEngineFactoryPlugin.java
deleted file mode 100644
index 8ed6060..0000000
--- a/core/src/test/java/org/elasticsearch/index/shard/MockEngineFactoryPlugin.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.shard;
-
-import org.elasticsearch.common.inject.Module;
-import org.elasticsearch.plugins.AbstractPlugin;
-import org.elasticsearch.test.engine.MockEngineFactory;
-import org.elasticsearch.test.engine.MockEngineSupportModule;
-
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-
-// this must exist in the same package as IndexShardModule to allow access to setting the impl
-public class MockEngineFactoryPlugin extends AbstractPlugin {
-    @Override
-    public String name() {
-        return "mock-engine-factory";
-    }
-    @Override
-    public String description() {
-        return "a mock engine factory for testing";
-    }
-    @Override
-    public Collection<Class<? extends Module>> indexModules() {
-        List<Class<? extends Module>> modules = new ArrayList<>();
-        modules.add(MockEngineSupportModule.class);
-        return modules;
-    }
-    public void onModule(IndexShardModule module) {
-        module.engineFactoryImpl = MockEngineFactory.class;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/indices/memory/breaker/RandomExceptionCircuitBreakerIT.java b/core/src/test/java/org/elasticsearch/indices/memory/breaker/RandomExceptionCircuitBreakerIT.java
index 2e8c165..053b239 100644
--- a/core/src/test/java/org/elasticsearch/indices/memory/breaker/RandomExceptionCircuitBreakerIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/memory/breaker/RandomExceptionCircuitBreakerIT.java
@@ -35,11 +35,9 @@ import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache;
-import org.elasticsearch.plugins.AbstractPlugin;
 import org.elasticsearch.search.sort.SortOrder;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.engine.MockEngineSupport;
-import org.elasticsearch.test.engine.MockEngineSupportModule;
 import org.elasticsearch.test.engine.ThrowingLeafReaderWrapper;
 import org.junit.Test;
 
@@ -107,7 +105,7 @@ public class RandomExceptionCircuitBreakerIT extends ESIntegTestCase {
 
         Settings.Builder settings = settingsBuilder()
                 .put(indexSettings())
-                .extendArray("plugin.types", RandomExceptionDirectoryReaderWrapper.Plugin.class.getName())
+                .put(MockEngineSupport.READER_WRAPPER_TYPE, RandomExceptionDirectoryReaderWrapper.class.getName())
                 .put(EXCEPTION_TOP_LEVEL_RATIO_KEY, topLevelRate)
                 .put(EXCEPTION_LOW_LEVEL_RATIO_KEY, lowLevelRate)
                 .put(MockEngineSupport.WRAP_READER_RATIO, 1.0d);
@@ -201,21 +199,6 @@ public class RandomExceptionCircuitBreakerIT extends ESIntegTestCase {
 
     // TODO: Generalize this class and add it as a utility
     public static class RandomExceptionDirectoryReaderWrapper extends MockEngineSupport.DirectoryReaderWrapper {
-
-        public static class Plugin extends AbstractPlugin {
-            @Override
-            public String name() {
-                return "random-exception-reader-wrapper";
-            }
-            @Override
-            public String description() {
-                return "a mock reader wrapper that throws random exceptions for testing";
-            }
-            public void onModule(MockEngineSupportModule module) {
-                module.wrapperImpl = RandomExceptionDirectoryReaderWrapper.class;
-            }
-        }
-
         private final Settings settings;
 
         static class ThrowingSubReaderWrapper extends SubReaderWrapper implements ThrowingLeafReaderWrapper.Thrower {
diff --git a/core/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java b/core/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java
index b01ec78..8aeb6f6 100644
--- a/core/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/stats/IndexStatsIT.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.indices.stats;
 
-import org.elasticsearch.index.cache.IndexCacheModule;
 import org.elasticsearch.index.shard.MergeSchedulerConfig;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.Version;
@@ -40,7 +39,9 @@ import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.index.cache.query.QueryCacheModule;
 import org.elasticsearch.index.cache.query.QueryCacheStats;
+import org.elasticsearch.index.cache.query.QueryCacheModule.QueryCacheSettings;
 import org.elasticsearch.index.cache.query.index.IndexQueryCache;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.shard.MergePolicyConfig;
@@ -78,8 +79,8 @@ public class IndexStatsIT extends ESIntegTestCase {
         //Filter/Query cache is cleaned periodically, default is 60s, so make sure it runs often. Thread.sleep for 60s is bad
         return Settings.settingsBuilder().put(super.nodeSettings(nodeOrdinal))
                 .put(IndicesRequestCache.INDICES_CACHE_REQUEST_CLEAN_INTERVAL, "1ms")
-                .put(IndexCacheModule.QUERY_CACHE_EVERYTHING, true)
-                .put(IndexCacheModule.QUERY_CACHE_TYPE, IndexCacheModule.INDEX_QUERY_CACHE)
+                .put(QueryCacheSettings.QUERY_CACHE_EVERYTHING, true)
+                .put(QueryCacheModule.QueryCacheSettings.QUERY_CACHE_TYPE, IndexQueryCache.class)
                 .build();
     }
 
diff --git a/core/src/test/java/org/elasticsearch/node/NodeMocksPlugin.java b/core/src/test/java/org/elasticsearch/node/NodeMocksPlugin.java
deleted file mode 100644
index 8eed1e1..0000000
--- a/core/src/test/java/org/elasticsearch/node/NodeMocksPlugin.java
+++ /dev/null
@@ -1,41 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.node;
-
-import org.elasticsearch.cache.recycler.MockPageCacheRecycler;
-import org.elasticsearch.common.util.MockBigArrays;
-import org.elasticsearch.plugins.AbstractPlugin;
-
-public class NodeMocksPlugin extends AbstractPlugin {
-
-    @Override
-    public String name() {
-        return "node-mocks";
-    }
-
-    @Override
-    public String description() {
-        return "a plugin to setup mocks for node level classes";
-    }
-
-    public void onModule(NodeModule module) {
-        module.pageCacheRecyclerImpl = MockPageCacheRecycler.class;
-        module.bigArraysImpl = MockBigArrays.class;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/search/MockSearchService.java b/core/src/test/java/org/elasticsearch/search/MockSearchService.java
deleted file mode 100644
index 077f730..0000000
--- a/core/src/test/java/org/elasticsearch/search/MockSearchService.java
+++ /dev/null
@@ -1,92 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.search;
-
-import org.elasticsearch.cache.recycler.PageCacheRecycler;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.util.BigArrays;
-import org.elasticsearch.indices.IndicesService;
-import org.elasticsearch.indices.IndicesWarmer;
-import org.elasticsearch.indices.cache.request.IndicesRequestCache;
-import org.elasticsearch.node.settings.NodeSettingsService;
-import org.elasticsearch.plugins.AbstractPlugin;
-import org.elasticsearch.script.ScriptService;
-import org.elasticsearch.search.SearchService;
-import org.elasticsearch.search.dfs.DfsPhase;
-import org.elasticsearch.search.fetch.FetchPhase;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.query.QueryPhase;
-import org.elasticsearch.threadpool.ThreadPool;
-
-import java.util.HashMap;
-import java.util.Map;
-import java.util.concurrent.ConcurrentHashMap;
-
-public class MockSearchService extends SearchService {
-
-    public static class Plugin extends AbstractPlugin {
-        @Override
-        public String name() {
-            return "mock-search-service";
-        }
-        @Override
-        public String description() {
-            return "a mock search service for testing";
-        }
-        public void onModule(SearchModule module) {
-            module.searchServiceImpl = MockSearchService.class;
-        }
-    }
-
-    private static final Map<SearchContext, Throwable> ACTIVE_SEARCH_CONTEXTS = new ConcurrentHashMap<>();
-
-    /** Throw an {@link AssertionError} if there are still in-flight contexts. */
-    public static void assertNoInFLightContext() {
-        final Map<SearchContext, Throwable> copy = new HashMap<>(ACTIVE_SEARCH_CONTEXTS);
-        if (copy.isEmpty() == false) {
-            throw new AssertionError("There are still " + copy.size() + " in-flight contexts", copy.values().iterator().next());
-        }
-    }
-
-    @Inject
-    public MockSearchService(Settings settings, NodeSettingsService nodeSettingsService, ClusterService clusterService, IndicesService indicesService, IndicesWarmer indicesWarmer,
-            ThreadPool threadPool, ScriptService scriptService, PageCacheRecycler pageCacheRecycler, BigArrays bigArrays,
-            DfsPhase dfsPhase, QueryPhase queryPhase, FetchPhase fetchPhase, IndicesRequestCache indicesQueryCache) {
-        super(settings, nodeSettingsService, clusterService, indicesService, indicesWarmer, threadPool, scriptService, pageCacheRecycler, bigArrays, dfsPhase,
-                queryPhase, fetchPhase, indicesQueryCache);
-    }
- 
-    @Override
-    protected void putContext(SearchContext context) {
-        super.putContext(context);
-        ACTIVE_SEARCH_CONTEXTS.put(context, new RuntimeException());
-    }
-
-    @Override
-    protected SearchContext removeContext(long id) {
-        final SearchContext removed = super.removeContext(id);
-        if (removed != null) {
-            ACTIVE_SEARCH_CONTEXTS.remove(removed);
-        }
-        return removed;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/search/SearchModuleTests.java b/core/src/test/java/org/elasticsearch/search/SearchModuleTests.java
new file mode 100644
index 0000000..efdcf00
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/search/SearchModuleTests.java
@@ -0,0 +1,69 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.search;
+
+import org.elasticsearch.common.inject.ModuleTestCase;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.search.highlight.CustomHighlighter;
+import org.elasticsearch.search.highlight.Highlighter;
+import org.elasticsearch.search.highlight.PlainHighlighter;
+import org.elasticsearch.search.suggest.CustomSuggester;
+import org.elasticsearch.search.suggest.Suggester;
+import org.elasticsearch.search.suggest.phrase.PhraseSuggester;
+/**
+ */
+public class SearchModuleTests extends ModuleTestCase {
+
+   public void testDoubleRegister() {
+       SearchModule module = new SearchModule(Settings.EMPTY);
+       try {
+           module.registerHighlighter("fvh", PlainHighlighter.class);
+       } catch (IllegalArgumentException e) {
+           assertEquals(e.getMessage(), "Can't register the same [highlighter] more than once for [fvh]");
+       }
+
+       try {
+           module.registerSuggester("term", PhraseSuggester.class);
+       } catch (IllegalArgumentException e) {
+           assertEquals(e.getMessage(), "Can't register the same [suggester] more than once for [term]");
+       }
+   }
+
+    public void testRegisterSuggester() {
+        SearchModule module = new SearchModule(Settings.EMPTY);
+        module.registerSuggester("custom", CustomSuggester.class);
+        try {
+            module.registerSuggester("custom", CustomSuggester.class);
+        } catch (IllegalArgumentException e) {
+            assertEquals(e.getMessage(), "Can't register the same [suggester] more than once for [custom]");
+        }
+        assertMapMultiBinding(module, Suggester.class, CustomSuggester.class);
+    }
+
+    public void testRegisterHighlighter() {
+        SearchModule module = new SearchModule(Settings.EMPTY);
+        module.registerHighlighter("custom", CustomHighlighter.class);
+        try {
+            module.registerHighlighter("custom", CustomHighlighter.class);
+        } catch (IllegalArgumentException e) {
+            assertEquals(e.getMessage(), "Can't register the same [highlighter] more than once for [custom]");
+        }
+        assertMapMultiBinding(module, Highlighter.class, CustomHighlighter.class);
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/search/basic/SearchWithRandomExceptionsIT.java b/core/src/test/java/org/elasticsearch/search/basic/SearchWithRandomExceptionsIT.java
index 6437513..93fbd80 100644
--- a/core/src/test/java/org/elasticsearch/search/basic/SearchWithRandomExceptionsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/basic/SearchWithRandomExceptionsIT.java
@@ -35,12 +35,10 @@ import org.elasticsearch.common.settings.Settings.Builder;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.plugins.AbstractPlugin;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.sort.SortOrder;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.engine.MockEngineSupport;
-import org.elasticsearch.test.engine.MockEngineSupportModule;
 import org.elasticsearch.test.engine.ThrowingLeafReaderWrapper;
 import org.elasticsearch.test.junit.annotations.TestLogging;
 import org.elasticsearch.test.store.MockFSDirectoryService;
@@ -252,7 +250,7 @@ public class SearchWithRandomExceptionsIT extends ESIntegTestCase {
 
         Builder settings = settingsBuilder()
                 .put(indexSettings())
-                .extendArray("plugin.types", RandomExceptionDirectoryReaderWrapper.Plugin.class.getName())
+                .put(MockEngineSupport.READER_WRAPPER_TYPE, RandomExceptionDirectoryReaderWrapper.class.getName())
                 .put(EXCEPTION_TOP_LEVEL_RATIO_KEY, topLevelRate)
                 .put(EXCEPTION_LOW_LEVEL_RATIO_KEY, lowLevelRate)
                 .put(MockEngineSupport.WRAP_READER_RATIO, 1.0d);
@@ -312,21 +310,6 @@ public class SearchWithRandomExceptionsIT extends ESIntegTestCase {
 
 
     public static class RandomExceptionDirectoryReaderWrapper extends MockEngineSupport.DirectoryReaderWrapper {
-
-        public static class Plugin extends AbstractPlugin {
-            @Override
-            public String name() {
-                return "random-exception-reader-wrapper";
-            }
-            @Override
-            public String description() {
-                return "a mock reader wrapper that throws random exceptions for testing";
-            }
-            public void onModule(MockEngineSupportModule module) {
-                module.wrapperImpl = RandomExceptionDirectoryReaderWrapper.class;
-            }
-        }
-
         private final Settings settings;
 
         static class ThrowingSubReaderWrapper extends FilterDirectoryReader.SubReaderWrapper implements ThrowingLeafReaderWrapper.Thrower {
diff --git a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java b/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
index ec9fb42..4a1eed7 100644
--- a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
@@ -29,7 +29,8 @@ import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.common.lucene.search.function.CombineFunction;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.index.cache.IndexCacheModule;
+import org.elasticsearch.index.cache.query.QueryCacheModule;
+import org.elasticsearch.index.cache.query.QueryCacheModule.QueryCacheSettings;
 import org.elasticsearch.index.cache.query.index.IndexQueryCache;
 import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.query.HasChildQueryBuilder;
@@ -73,8 +74,8 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
     protected Settings nodeSettings(int nodeOrdinal) {
         return Settings.settingsBuilder().put(super.nodeSettings(nodeOrdinal))
                 // aggressive filter caching so that we can assert on the filter cache size
-                .put(IndexCacheModule.QUERY_CACHE_TYPE, IndexCacheModule.INDEX_QUERY_CACHE)
-                .put(IndexCacheModule.QUERY_CACHE_EVERYTHING, true)
+                .put(QueryCacheModule.QueryCacheSettings.QUERY_CACHE_TYPE, IndexQueryCache.class)
+                .put(QueryCacheSettings.QUERY_CACHE_EVERYTHING, true)
                 .build();
     }
 
diff --git a/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java b/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java
index 3a9135c..e193d2a 100644
--- a/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java
+++ b/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java
@@ -33,11 +33,6 @@ import java.util.Map;
 public class CustomHighlighter implements Highlighter {
 
     @Override
-    public String[] names() {
-        return new String[] { "test-custom" };
-    }
-
-    @Override
     public HighlightField highlight(HighlighterContext highlighterContext) {
         SearchContextHighlight.Field field = highlighterContext.field;
         CacheEntry cacheEntry = (CacheEntry) highlighterContext.hitContext.cache().get("test-custom");
diff --git a/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighterPlugin.java b/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighterPlugin.java
index e7c6979..705265e 100644
--- a/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighterPlugin.java
+++ b/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighterPlugin.java
@@ -35,6 +35,6 @@ public class CustomHighlighterPlugin extends AbstractPlugin {
     }
 
     public void onModule(SearchModule highlightModule) {
-        highlightModule.registerHighlighter(CustomHighlighter.class);
+        highlightModule.registerHighlighter("test-custom", CustomHighlighter.class);
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/search/scriptfilter/ScriptQuerySearchIT.java b/core/src/test/java/org/elasticsearch/search/scriptfilter/ScriptQuerySearchIT.java
index 45a487c..d82e12e 100644
--- a/core/src/test/java/org/elasticsearch/search/scriptfilter/ScriptQuerySearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/scriptfilter/ScriptQuerySearchIT.java
@@ -21,7 +21,8 @@ package org.elasticsearch.search.scriptfilter;
 
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.cache.IndexCacheModule;
+import org.elasticsearch.index.cache.query.QueryCacheModule;
+import org.elasticsearch.index.cache.query.QueryCacheModule.QueryCacheSettings;
 import org.elasticsearch.index.cache.query.index.IndexQueryCache;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.ScriptService.ScriptType;
@@ -49,8 +50,8 @@ public class ScriptQuerySearchIT extends ESIntegTestCase {
     protected Settings nodeSettings(int nodeOrdinal) {
         return Settings.settingsBuilder().put(super.nodeSettings(nodeOrdinal))
                 // aggressive filter caching so that we can assert on the number of iterations of the script filters
-                .put(IndexCacheModule.QUERY_CACHE_TYPE, IndexCacheModule.INDEX_QUERY_CACHE)
-                .put(IndexCacheModule.QUERY_CACHE_EVERYTHING, true)
+                .put(QueryCacheModule.QueryCacheSettings.QUERY_CACHE_TYPE, IndexQueryCache.class)
+                .put(QueryCacheSettings.QUERY_CACHE_EVERYTHING, true)
                 .build();
     }
 
diff --git a/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggester.java b/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggester.java
index 6e57390..e3dfe3b 100644
--- a/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggester.java
+++ b/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggester.java
@@ -56,11 +56,6 @@ public class CustomSuggester extends Suggester<CustomSuggester.CustomSuggestions
     }
 
     @Override
-    public String[] names() {
-        return new String[] {"custom"};
-    }
-
-    @Override
     public SuggestContextParser getContextParser() {
         return new SuggestContextParser() {
             @Override
diff --git a/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterPlugin.java b/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterPlugin.java
index 55dd7bf..9ba9c53 100644
--- a/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterPlugin.java
+++ b/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterPlugin.java
@@ -37,7 +37,7 @@ public class CustomSuggesterPlugin extends AbstractPlugin {
     }
 
     public void onModule(SearchModule searchModule) {
-        searchModule.registerSuggester(CustomSuggester.class);
+        searchModule.registerSuggester("custom", CustomSuggester.class);
     }
 
 }
diff --git a/core/src/test/java/org/elasticsearch/test/ESTestCase.java b/core/src/test/java/org/elasticsearch/test/ESTestCase.java
index 97d5a2e..8823e83 100644
--- a/core/src/test/java/org/elasticsearch/test/ESTestCase.java
+++ b/core/src/test/java/org/elasticsearch/test/ESTestCase.java
@@ -46,17 +46,18 @@ import org.elasticsearch.common.io.PathUtils;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.concurrent.EsAbortPolicy;
 import org.elasticsearch.common.util.concurrent.EsExecutors;
 import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;
 import org.elasticsearch.common.xcontent.XContentType;
 import org.elasticsearch.env.Environment;
 import org.elasticsearch.env.NodeEnvironment;
-import org.elasticsearch.common.util.MockBigArrays;
-import org.elasticsearch.cache.recycler.MockPageCacheRecycler;
+import org.elasticsearch.test.cache.recycler.MockBigArrays;
+import org.elasticsearch.test.cache.recycler.MockPageCacheRecycler;
 import org.elasticsearch.test.junit.listeners.AssertionErrorThreadDumpPrinter;
 import org.elasticsearch.test.junit.listeners.LoggingListener;
 import org.elasticsearch.test.junit.listeners.ReproduceInfoPrinter;
-import org.elasticsearch.search.MockSearchService;
+import org.elasticsearch.test.search.MockSearchService;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.junit.*;
 import org.junit.rules.RuleChain;
diff --git a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
index 2a17f9e..065732e 100644
--- a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
+++ b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
@@ -42,6 +42,7 @@ import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
 import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags;
 import org.elasticsearch.cache.recycler.PageCacheRecycler;
+import org.elasticsearch.cache.recycler.PageCacheRecyclerModule;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.client.transport.TransportClient;
 import org.elasticsearch.cluster.ClusterName;
@@ -71,16 +72,20 @@ import org.elasticsearch.common.transport.TransportAddress;
 import org.elasticsearch.common.unit.ByteSizeUnit;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.util.BigArraysModule;
 import org.elasticsearch.common.util.concurrent.EsExecutors;
 import org.elasticsearch.env.NodeEnvironment;
 import org.elasticsearch.http.HttpServerTransport;
 import org.elasticsearch.index.IndexService;
-import org.elasticsearch.index.cache.IndexCacheModule;
+import org.elasticsearch.index.cache.query.QueryCacheModule;
+import org.elasticsearch.index.cache.query.QueryCacheModule.QueryCacheSettings;
+import org.elasticsearch.index.cache.query.index.IndexQueryCache;
+import org.elasticsearch.index.cache.query.none.NoneQueryCache;
 import org.elasticsearch.index.engine.CommitStats;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.engine.EngineClosedException;
 import org.elasticsearch.index.shard.IndexShard;
-import org.elasticsearch.index.shard.MockEngineFactoryPlugin;
+import org.elasticsearch.index.shard.IndexShardModule;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.indices.breaker.CircuitBreakerService;
@@ -90,14 +95,16 @@ import org.elasticsearch.indices.fielddata.cache.IndicesFieldDataCache;
 import org.elasticsearch.indices.recovery.RecoverySettings;
 import org.elasticsearch.indices.store.IndicesStore;
 import org.elasticsearch.node.Node;
-import org.elasticsearch.node.NodeMocksPlugin;
 import org.elasticsearch.node.internal.InternalSettingsPreparer;
 import org.elasticsearch.node.service.NodeService;
 import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.search.SearchModule;
 import org.elasticsearch.search.SearchService;
+import org.elasticsearch.test.cache.recycler.MockBigArrays;
+import org.elasticsearch.test.cache.recycler.MockPageCacheRecycler;
 import org.elasticsearch.test.disruption.ServiceDisruptionScheme;
-import org.elasticsearch.search.MockSearchService;
+import org.elasticsearch.test.engine.MockEngineFactory;
+import org.elasticsearch.test.search.MockSearchService;
 import org.elasticsearch.test.store.MockFSIndexStore;
 import org.elasticsearch.test.transport.AssertingLocalTransport;
 import org.elasticsearch.test.transport.MockTransportService;
@@ -383,12 +390,11 @@ public final class InternalTestCluster extends TestCluster {
         Builder builder = Settings.settingsBuilder()
                 .put(SETTING_CLUSTER_NODE_SEED, seed);
         if (ENABLE_MOCK_MODULES && usually(random)) {
-            builder.extendArray("plugin.types",
-                MockTransportService.Plugin.class.getName(),
-                MockFSIndexStore.Plugin.class.getName(),
-                NodeMocksPlugin.class.getName(),
-                MockEngineFactoryPlugin.class.getName(),
-                MockSearchService.Plugin.class.getName());
+            builder.extendArray("plugin.types", MockTransportService.Plugin.class.getName(), MockFSIndexStore.Plugin.class.getName());
+            builder.put(IndexShardModule.ENGINE_FACTORY, MockEngineFactory.class);
+            builder.put(PageCacheRecyclerModule.CACHE_IMPL, MockPageCacheRecycler.class.getName());
+            builder.put(BigArraysModule.IMPL, MockBigArrays.class.getName());
+            builder.put(SearchModule.SEARCH_SERVICE_IMPL, MockSearchService.class.getName());
         }
         if (isLocalTransportConfigured()) {
             builder.extendArray("plugin.types", AssertingLocalTransport.Plugin.class.getName());
@@ -451,11 +457,11 @@ public final class InternalTestCluster extends TestCluster {
         }
 
         if (random.nextBoolean()) {
-            builder.put(IndexCacheModule.QUERY_CACHE_TYPE, random.nextBoolean() ? IndexCacheModule.INDEX_QUERY_CACHE : IndexCacheModule.NONE_QUERY_CACHE);
+            builder.put(QueryCacheModule.QueryCacheSettings.QUERY_CACHE_TYPE, random.nextBoolean() ? IndexQueryCache.class : NoneQueryCache.class);
         }
 
         if (random.nextBoolean()) {
-            builder.put(IndexCacheModule.QUERY_CACHE_EVERYTHING, random.nextBoolean());
+            builder.put(QueryCacheSettings.QUERY_CACHE_EVERYTHING, random.nextBoolean());
         }
 
         if (random.nextBoolean()) {
diff --git a/core/src/test/java/org/elasticsearch/test/cache/recycler/MockBigArrays.java b/core/src/test/java/org/elasticsearch/test/cache/recycler/MockBigArrays.java
new file mode 100644
index 0000000..4c67fbc
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/test/cache/recycler/MockBigArrays.java
@@ -0,0 +1,567 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.test.cache.recycler;
+
+import com.carrotsearch.randomizedtesting.RandomizedContext;
+import com.carrotsearch.randomizedtesting.SeedUtils;
+import com.google.common.base.Predicate;
+import com.google.common.collect.Maps;
+import com.google.common.collect.Sets;
+
+import org.apache.lucene.util.Accountable;
+import org.apache.lucene.util.Accountables;
+import org.apache.lucene.util.BytesRef;
+import org.elasticsearch.cache.recycler.PageCacheRecycler;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.util.BigArray;
+import org.elasticsearch.common.util.BigArrays;
+import org.elasticsearch.common.util.ByteArray;
+import org.elasticsearch.common.util.DoubleArray;
+import org.elasticsearch.common.util.FloatArray;
+import org.elasticsearch.common.util.IntArray;
+import org.elasticsearch.common.util.LongArray;
+import org.elasticsearch.common.util.ObjectArray;
+import org.elasticsearch.indices.breaker.CircuitBreakerService;
+import org.elasticsearch.test.ESTestCase;
+
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+import java.util.WeakHashMap;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.atomic.AtomicBoolean;
+
+public class MockBigArrays extends BigArrays {
+
+    /**
+     * Tracking allocations is useful when debugging a leak but shouldn't be enabled by default as this would also be very costly
+     * since it creates a new Exception every time a new array is created.
+     */
+    private static final boolean TRACK_ALLOCATIONS = false;
+
+    private static final Set<BigArrays> INSTANCES = Collections.synchronizedSet(Collections.newSetFromMap(new WeakHashMap<BigArrays, Boolean>()));
+    private static final ConcurrentMap<Object, Object> ACQUIRED_ARRAYS = new ConcurrentHashMap<>();
+
+    public static void ensureAllArraysAreReleased() throws Exception {
+        final Map<Object, Object> masterCopy = Maps.newHashMap(ACQUIRED_ARRAYS);
+        if (!masterCopy.isEmpty()) {
+            // not empty, we might be executing on a shared cluster that keeps on obtaining
+            // and releasing arrays, lets make sure that after a reasonable timeout, all master
+            // copy (snapshot) have been released
+            boolean success = ESTestCase.awaitBusy(new Predicate<Object>() {
+                @Override
+                public boolean apply(Object input) {
+                    return Sets.intersection(masterCopy.keySet(), ACQUIRED_ARRAYS.keySet()).isEmpty();
+                }
+            });
+            if (!success) {
+                masterCopy.keySet().retainAll(ACQUIRED_ARRAYS.keySet());
+                ACQUIRED_ARRAYS.keySet().removeAll(masterCopy.keySet()); // remove all existing master copy we will report on
+                if (!masterCopy.isEmpty()) {
+                    final Object cause = masterCopy.entrySet().iterator().next().getValue();
+                    throw new RuntimeException(masterCopy.size() + " arrays have not been released", cause instanceof Throwable ? (Throwable) cause : null);
+                }
+            }
+        }
+    }
+
+    private final Random random;
+    private final PageCacheRecycler recycler;
+    private final CircuitBreakerService breakerService;
+
+    @Inject
+    public MockBigArrays(PageCacheRecycler recycler, CircuitBreakerService breakerService) {
+        this(recycler, breakerService, false);
+    }
+
+    public MockBigArrays(PageCacheRecycler recycler, CircuitBreakerService breakerService, boolean checkBreaker) {
+        super(recycler, breakerService, checkBreaker);
+        this.recycler = recycler;
+        this.breakerService = breakerService;
+        long seed;
+        try {
+            seed = SeedUtils.parseSeed(RandomizedContext.current().getRunnerSeedAsString());
+        } catch (IllegalStateException e) { // rest tests don't run randomized and have no context
+            seed = 0;
+        }
+        random = new Random(seed);
+        INSTANCES.add(this);
+    }
+
+
+    @Override
+    public BigArrays withCircuitBreaking() {
+        return new MockBigArrays(this.recycler, this.breakerService, true);
+    }
+
+    @Override
+    public ByteArray newByteArray(long size, boolean clearOnResize) {
+        final ByteArrayWrapper array = new ByteArrayWrapper(super.newByteArray(size, clearOnResize), clearOnResize);
+        if (!clearOnResize) {
+            array.randomizeContent(0, size);
+        }
+        return array;
+    }
+
+    @Override
+    public ByteArray resize(ByteArray array, long size) {
+        ByteArrayWrapper arr = (ByteArrayWrapper) array;
+        final long originalSize = arr.size();
+        array = super.resize(arr.in, size);
+        ACQUIRED_ARRAYS.remove(arr);
+        if (array instanceof ByteArrayWrapper) {
+            arr = (ByteArrayWrapper) array;
+        } else {
+            arr = new ByteArrayWrapper(array, arr.clearOnResize);
+        }
+        if (!arr.clearOnResize) {
+            arr.randomizeContent(originalSize, size);
+        }
+        return arr;
+    }
+
+    @Override
+    public IntArray newIntArray(long size, boolean clearOnResize) {
+        final IntArrayWrapper array = new IntArrayWrapper(super.newIntArray(size, clearOnResize), clearOnResize);
+        if (!clearOnResize) {
+            array.randomizeContent(0, size);
+        }
+        return array;
+    }
+
+    @Override
+    public IntArray resize(IntArray array, long size) {
+        IntArrayWrapper arr = (IntArrayWrapper) array;
+        final long originalSize = arr.size();
+        array = super.resize(arr.in, size);
+        ACQUIRED_ARRAYS.remove(arr);
+        if (array instanceof IntArrayWrapper) {
+            arr = (IntArrayWrapper) array;
+        } else {
+            arr = new IntArrayWrapper(array, arr.clearOnResize);
+        }
+        if (!arr.clearOnResize) {
+            arr.randomizeContent(originalSize, size);
+        }
+        return arr;
+    }
+
+    @Override
+    public LongArray newLongArray(long size, boolean clearOnResize) {
+        final LongArrayWrapper array = new LongArrayWrapper(super.newLongArray(size, clearOnResize), clearOnResize);
+        if (!clearOnResize) {
+            array.randomizeContent(0, size);
+        }
+        return array;
+    }
+
+    @Override
+    public LongArray resize(LongArray array, long size) {
+        LongArrayWrapper arr = (LongArrayWrapper) array;
+        final long originalSize = arr.size();
+        array = super.resize(arr.in, size);
+        ACQUIRED_ARRAYS.remove(arr);
+        if (array instanceof LongArrayWrapper) {
+            arr = (LongArrayWrapper) array;
+        } else {
+            arr = new LongArrayWrapper(array, arr.clearOnResize);
+        }
+        if (!arr.clearOnResize) {
+            arr.randomizeContent(originalSize, size);
+        }
+        return arr;
+    }
+
+    @Override
+    public FloatArray newFloatArray(long size, boolean clearOnResize) {
+        final FloatArrayWrapper array = new FloatArrayWrapper(super.newFloatArray(size, clearOnResize), clearOnResize);
+        if (!clearOnResize) {
+            array.randomizeContent(0, size);
+        }
+        return array;
+    }
+
+    @Override
+    public FloatArray resize(FloatArray array, long size) {
+        FloatArrayWrapper arr = (FloatArrayWrapper) array;
+        final long originalSize = arr.size();
+        array = super.resize(arr.in, size);
+        ACQUIRED_ARRAYS.remove(arr);
+        if (array instanceof FloatArrayWrapper) {
+            arr = (FloatArrayWrapper) array;
+        } else {
+            arr = new FloatArrayWrapper(array, arr.clearOnResize);
+        }
+        if (!arr.clearOnResize) {
+            arr.randomizeContent(originalSize, size);
+        }
+        return arr;
+    }
+
+    @Override
+    public DoubleArray newDoubleArray(long size, boolean clearOnResize) {
+        final DoubleArrayWrapper array = new DoubleArrayWrapper(super.newDoubleArray(size, clearOnResize), clearOnResize);
+        if (!clearOnResize) {
+            array.randomizeContent(0, size);
+        }
+        return array;
+    }
+
+    @Override
+    public DoubleArray resize(DoubleArray array, long size) {
+        DoubleArrayWrapper arr = (DoubleArrayWrapper) array;
+        final long originalSize = arr.size();
+        array = super.resize(arr.in, size);
+        ACQUIRED_ARRAYS.remove(arr);
+        if (array instanceof DoubleArrayWrapper) {
+            arr = (DoubleArrayWrapper) array;
+        } else {
+            arr = new DoubleArrayWrapper(array, arr.clearOnResize);
+        }
+        if (!arr.clearOnResize) {
+            arr.randomizeContent(originalSize, size);
+        }
+        return arr;
+    }
+
+    @Override
+    public <T> ObjectArray<T> newObjectArray(long size) {
+        return new ObjectArrayWrapper<>(super.<T>newObjectArray(size));
+    }
+
+    @Override
+    public <T> ObjectArray<T> resize(ObjectArray<T> array, long size) {
+        ObjectArrayWrapper<T> arr = (ObjectArrayWrapper<T>) array;
+        array = super.resize(arr.in, size);
+        ACQUIRED_ARRAYS.remove(arr);
+        if (array instanceof ObjectArrayWrapper) {
+            arr = (ObjectArrayWrapper<T>) array;
+        } else {
+            arr = new ObjectArrayWrapper<>(array);
+        }
+        return arr;
+    }
+
+    private static abstract class AbstractArrayWrapper {
+
+        final BigArray in;
+        boolean clearOnResize;
+        AtomicBoolean released;
+
+        AbstractArrayWrapper(BigArray in, boolean clearOnResize) {
+            ACQUIRED_ARRAYS.put(this, TRACK_ALLOCATIONS ? new RuntimeException() : Boolean.TRUE);
+            this.in = in;
+            this.clearOnResize = clearOnResize;
+            released = new AtomicBoolean(false);
+        }
+
+        protected abstract BigArray getDelegate();
+
+        protected abstract void randomizeContent(long from, long to);
+
+        public long size() {
+            return getDelegate().size();
+        }
+
+        public long ramBytesUsed() {
+            return in.ramBytesUsed();
+        }
+
+        public void close() {
+            if (!released.compareAndSet(false, true)) {
+                throw new IllegalStateException("Double release");
+            }
+            ACQUIRED_ARRAYS.remove(this);
+            randomizeContent(0, size());
+            getDelegate().close();
+        }
+
+    }
+
+    private class ByteArrayWrapper extends AbstractArrayWrapper implements ByteArray {
+
+        private final ByteArray in;
+
+        ByteArrayWrapper(ByteArray in, boolean clearOnResize) {
+            super(in, clearOnResize);
+            this.in = in;
+        }
+
+        @Override
+        protected BigArray getDelegate() {
+            return in;
+        }
+
+        @Override
+        protected void randomizeContent(long from, long to) {
+            fill(from, to, (byte) random.nextInt(1 << 8));
+        }
+
+        @Override
+        public byte get(long index) {
+            return in.get(index);
+        }
+
+        @Override
+        public byte set(long index, byte value) {
+            return in.set(index, value);
+        }
+
+        @Override
+        public boolean get(long index, int len, BytesRef ref) {
+            return in.get(index, len, ref);
+        }
+
+        @Override
+        public void set(long index, byte[] buf, int offset, int len) {
+            in.set(index, buf, offset, len);
+        }
+
+        @Override
+        public void fill(long fromIndex, long toIndex, byte value) {
+            in.fill(fromIndex, toIndex, value);
+        }
+
+        @Override
+        public Collection<Accountable> getChildResources() {
+            return Collections.singleton(Accountables.namedAccountable("delegate", in));
+        }
+    }
+
+    private class IntArrayWrapper extends AbstractArrayWrapper implements IntArray {
+
+        private final IntArray in;
+
+        IntArrayWrapper(IntArray in, boolean clearOnResize) {
+            super(in, clearOnResize);
+            this.in = in;
+        }
+
+        @Override
+        protected BigArray getDelegate() {
+            return in;
+        }
+
+        @Override
+        protected void randomizeContent(long from, long to) {
+            fill(from, to, random.nextInt());
+        }
+
+        @Override
+        public int get(long index) {
+            return in.get(index);
+        }
+
+        @Override
+        public int set(long index, int value) {
+            return in.set(index, value);
+        }
+
+        @Override
+        public int increment(long index, int inc) {
+            return in.increment(index, inc);
+        }
+
+        @Override
+        public void fill(long fromIndex, long toIndex, int value) {
+            in.fill(fromIndex, toIndex, value);
+        }
+        
+        @Override
+        public Collection<Accountable> getChildResources() {
+            return Collections.singleton(Accountables.namedAccountable("delegate", in));
+        }
+    }
+
+    private class LongArrayWrapper extends AbstractArrayWrapper implements LongArray {
+
+        private final LongArray in;
+
+        LongArrayWrapper(LongArray in, boolean clearOnResize) {
+            super(in, clearOnResize);
+            this.in = in;
+        }
+
+        @Override
+        protected BigArray getDelegate() {
+            return in;
+        }
+
+        @Override
+        protected void randomizeContent(long from, long to) {
+            fill(from, to, random.nextLong());
+        }
+
+        @Override
+        public long get(long index) {
+            return in.get(index);
+        }
+
+        @Override
+        public long set(long index, long value) {
+            return in.set(index, value);
+        }
+
+        @Override
+        public long increment(long index, long inc) {
+            return in.increment(index, inc);
+        }
+
+        @Override
+        public void fill(long fromIndex, long toIndex, long value) {
+            in.fill(fromIndex, toIndex, value);
+        }
+        
+        @Override
+        public Collection<Accountable> getChildResources() {
+            return Collections.singleton(Accountables.namedAccountable("delegate", in));
+        }
+
+    }
+
+    private class FloatArrayWrapper extends AbstractArrayWrapper implements FloatArray {
+
+        private final FloatArray in;
+
+        FloatArrayWrapper(FloatArray in, boolean clearOnResize) {
+            super(in, clearOnResize);
+            this.in = in;
+        }
+
+        @Override
+        protected BigArray getDelegate() {
+            return in;
+        }
+
+        @Override
+        protected void randomizeContent(long from, long to) {
+            fill(from, to, (random.nextFloat() - 0.5f) * 1000);
+        }
+
+        @Override
+        public float get(long index) {
+            return in.get(index);
+        }
+
+        @Override
+        public float set(long index, float value) {
+            return in.set(index, value);
+        }
+
+        @Override
+        public float increment(long index, float inc) {
+            return in.increment(index, inc);
+        }
+
+        @Override
+        public void fill(long fromIndex, long toIndex, float value) {
+            in.fill(fromIndex, toIndex, value);
+        }
+
+        @Override
+        public Collection<Accountable> getChildResources() {
+            return Collections.singleton(Accountables.namedAccountable("delegate", in));
+        }
+    }
+
+    private class DoubleArrayWrapper extends AbstractArrayWrapper implements DoubleArray {
+
+        private final DoubleArray in;
+
+        DoubleArrayWrapper(DoubleArray in, boolean clearOnResize) {
+            super(in, clearOnResize);
+            this.in = in;
+        }
+
+        @Override
+        protected BigArray getDelegate() {
+            return in;
+        }
+
+        @Override
+        protected void randomizeContent(long from, long to) {
+            fill(from, to, (random.nextDouble() - 0.5) * 1000);
+        }
+
+        @Override
+        public double get(long index) {
+            return in.get(index);
+        }
+
+        @Override
+        public double set(long index, double value) {
+            return in.set(index, value);
+        }
+
+        @Override
+        public double increment(long index, double inc) {
+            return in.increment(index, inc);
+        }
+
+        @Override
+        public void fill(long fromIndex, long toIndex, double value) {
+            in.fill(fromIndex, toIndex, value);
+        }
+
+        @Override
+        public Collection<Accountable> getChildResources() {
+            return Collections.singleton(Accountables.namedAccountable("delegate", in));
+        }
+    }
+
+    private class ObjectArrayWrapper<T> extends AbstractArrayWrapper implements ObjectArray<T> {
+
+        private final ObjectArray<T> in;
+
+        ObjectArrayWrapper(ObjectArray<T> in) {
+            super(in, false);
+            this.in = in;
+        }
+
+        @Override
+        protected BigArray getDelegate() {
+            return in;
+        }
+
+        @Override
+        public T get(long index) {
+            return in.get(index);
+        }
+
+        @Override
+        public T set(long index, T value) {
+            return in.set(index, value);
+        }
+
+        @Override
+        protected void randomizeContent(long from, long to) {
+            // will be cleared anyway
+        }
+
+        @Override
+        public Collection<Accountable> getChildResources() {
+            return Collections.singleton(Accountables.namedAccountable("delegate", in));
+        }
+    }
+
+}
diff --git a/core/src/test/java/org/elasticsearch/test/cache/recycler/MockPageCacheRecycler.java b/core/src/test/java/org/elasticsearch/test/cache/recycler/MockPageCacheRecycler.java
new file mode 100644
index 0000000..482575d
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/test/cache/recycler/MockPageCacheRecycler.java
@@ -0,0 +1,151 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.test.cache.recycler;
+
+import com.google.common.base.Predicate;
+import com.google.common.collect.Maps;
+import com.google.common.collect.Sets;
+import org.elasticsearch.cache.recycler.PageCacheRecycler;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.recycler.Recycler.V;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.test.ESTestCase;
+import org.elasticsearch.test.InternalTestCluster;
+import org.elasticsearch.threadpool.ThreadPool;
+
+import java.lang.reflect.Array;
+import java.util.Arrays;
+import java.util.Map;
+import java.util.Random;
+import java.util.concurrent.ConcurrentMap;
+
+public class MockPageCacheRecycler extends PageCacheRecycler {
+
+    private static final ConcurrentMap<Object, Throwable> ACQUIRED_PAGES = Maps.newConcurrentMap();
+
+    public static void ensureAllPagesAreReleased() throws Exception {
+        final Map<Object, Throwable> masterCopy = Maps.newHashMap(ACQUIRED_PAGES);
+        if (!masterCopy.isEmpty()) {
+            // not empty, we might be executing on a shared cluster that keeps on obtaining
+            // and releasing pages, lets make sure that after a reasonable timeout, all master
+            // copy (snapshot) have been released
+            boolean success = ESTestCase.awaitBusy(new Predicate<Object>() {
+                @Override
+                public boolean apply(Object input) {
+                    return Sets.intersection(masterCopy.keySet(), ACQUIRED_PAGES.keySet()).isEmpty();
+                }
+            });
+            if (!success) {
+                masterCopy.keySet().retainAll(ACQUIRED_PAGES.keySet());
+                ACQUIRED_PAGES.keySet().removeAll(masterCopy.keySet()); // remove all existing master copy we will report on
+                if (!masterCopy.isEmpty()) {
+                    final Throwable t = masterCopy.entrySet().iterator().next().getValue();
+                    throw new RuntimeException(masterCopy.size() + " pages have not been released", t);
+                }
+            }
+        }
+    }
+
+    private final Random random;
+
+    @Inject
+    public MockPageCacheRecycler(Settings settings, ThreadPool threadPool) {
+        super(settings, threadPool);
+        final long seed = settings.getAsLong(InternalTestCluster.SETTING_CLUSTER_NODE_SEED, 0L);
+        random = new Random(seed);
+    }
+
+    private <T> V<T> wrap(final V<T> v) {
+        ACQUIRED_PAGES.put(v, new Throwable());
+        return new V<T>() {
+
+            @Override
+            public void close() {
+                final Throwable t = ACQUIRED_PAGES.remove(v);
+                if (t == null) {
+                    throw new IllegalStateException("Releasing a page that has not been acquired");
+                }
+                final T ref = v();
+                if (ref instanceof Object[]) {
+                    Arrays.fill((Object[])ref, 0, Array.getLength(ref), null);
+                } else if (ref instanceof byte[]) {
+                    Arrays.fill((byte[])ref, 0, Array.getLength(ref), (byte) random.nextInt(256));
+                } else if (ref instanceof long[]) {
+                    Arrays.fill((long[])ref, 0, Array.getLength(ref), random.nextLong());
+                } else if (ref instanceof int[]) {
+                    Arrays.fill((int[])ref, 0, Array.getLength(ref), random.nextInt());
+                } else if (ref instanceof double[]) {
+                    Arrays.fill((double[])ref, 0, Array.getLength(ref), random.nextDouble() - 0.5);
+                } else if (ref instanceof float[]) {
+                    Arrays.fill((float[])ref, 0, Array.getLength(ref), random.nextFloat() - 0.5f);
+                } else {
+                    for (int i = 0; i < Array.getLength(ref); ++i) {
+                            Array.set(ref, i, (byte) random.nextInt(256));
+                    }
+                }
+                v.close();
+            }
+
+            @Override
+            public T v() {
+                return v.v();
+            }
+
+            @Override
+            public boolean isRecycled() {
+                return v.isRecycled();
+            }
+
+        };
+    }
+
+    @Override
+    public V<byte[]> bytePage(boolean clear) {
+        final V<byte[]> page = super.bytePage(clear);
+        if (!clear) {
+            Arrays.fill(page.v(), 0, page.v().length, (byte)random.nextInt(1<<8));
+        }
+        return wrap(page);
+    }
+
+    @Override
+    public V<int[]> intPage(boolean clear) {
+        final V<int[]> page = super.intPage(clear);
+        if (!clear) {
+            Arrays.fill(page.v(), 0, page.v().length, random.nextInt());
+        }
+        return wrap(page);
+    }
+
+    @Override
+    public V<long[]> longPage(boolean clear) {
+        final V<long[]> page = super.longPage(clear);
+        if (!clear) {
+            Arrays.fill(page.v(), 0, page.v().length, random.nextLong());
+        }
+        return wrap(page);
+    }
+
+    @Override
+    public V<Object[]> objectPage() {
+        return wrap(super.objectPage());
+    }
+
+}
diff --git a/core/src/test/java/org/elasticsearch/test/engine/MockEngineFactory.java b/core/src/test/java/org/elasticsearch/test/engine/MockEngineFactory.java
index 3608495..602268d 100644
--- a/core/src/test/java/org/elasticsearch/test/engine/MockEngineFactory.java
+++ b/core/src/test/java/org/elasticsearch/test/engine/MockEngineFactory.java
@@ -18,41 +18,25 @@
  */
 package org.elasticsearch.test.engine;
 
-import org.apache.lucene.index.FilterDirectoryReader;
-import org.elasticsearch.common.inject.BindingAnnotation;
-import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.engine.EngineConfig;
 import org.elasticsearch.index.engine.EngineFactory;
+import org.elasticsearch.plugins.AbstractPlugin;
+import org.elasticsearch.transport.TransportModule;
 
-import java.lang.annotation.Retention;
-import java.lang.annotation.Target;
-
-import static java.lang.annotation.ElementType.FIELD;
-import static java.lang.annotation.ElementType.PARAMETER;
-import static java.lang.annotation.RetentionPolicy.RUNTIME;
-
+/**
+ *
+ */
 public final class MockEngineFactory implements EngineFactory {
-    @BindingAnnotation
-    @Target({FIELD, PARAMETER})
-    @Retention(RUNTIME)
-    public @interface MockReaderType {
-    }
-
-    private Class<? extends FilterDirectoryReader> wrapper;
-
-    @Inject
-    public MockEngineFactory(@MockReaderType Class wrapper) {
-        this.wrapper = wrapper;
-    }
 
     @Override
     public Engine newReadWriteEngine(EngineConfig config, boolean skipTranslogRecovery) {
-        return new MockInternalEngine(config, skipTranslogRecovery, wrapper);
+        return new MockInternalEngine(config, skipTranslogRecovery);
     }
 
     @Override
     public Engine newReadOnlyEngine(EngineConfig config) {
-        return new MockShadowEngine(config, wrapper);
+        return new MockShadowEngine(config);
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java b/core/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java
index 3649a7b..78b0439 100644
--- a/core/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java
+++ b/core/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.test.engine;
 
+import org.apache.lucene.index.AssertingDirectoryReader;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.FilterDirectoryReader;
 import org.apache.lucene.index.IndexReader;
@@ -28,6 +29,7 @@ import org.apache.lucene.search.QueryCachingPolicy;
 import org.apache.lucene.search.SearcherManager;
 import org.apache.lucene.util.LuceneTestCase;
 import org.elasticsearch.ElasticsearchException;
+import org.elasticsearch.common.Classes;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.settings.Settings;
@@ -78,7 +80,7 @@ public final class MockEngineSupport {
         }
     }
 
-    public MockEngineSupport(EngineConfig config, Class<? extends FilterDirectoryReader> wrapper) {
+    public MockEngineSupport(EngineConfig config) {
         Settings indexSettings = config.getIndexSettings();
         shardId = config.getShardId();
         filterCache = config.getQueryCache();
@@ -86,6 +88,13 @@ public final class MockEngineSupport {
         final long seed = indexSettings.getAsLong(ESIntegTestCase.SETTING_INDEX_SEED, 0l);
         Random random = new Random(seed);
         final double ratio = indexSettings.getAsDouble(WRAP_READER_RATIO, 0.0d); // DISABLED by default - AssertingDR is crazy slow
+        String readerWrapperType = indexSettings.get(READER_WRAPPER_TYPE);
+        Class<? extends AssertingDirectoryReader > wrapper;
+        if (readerWrapperType == null) {
+            wrapper = AssertingDirectoryReader.class;
+        } else {
+            wrapper = Classes.loadClass(getClass().getClassLoader(), readerWrapperType);
+        }
         boolean wrapReader = random.nextDouble() < ratio;
         if (logger.isTraceEnabled()) {
             logger.trace("Using [{}] for shard [{}] seed: [{}] wrapReader: [{}]", this.getClass().getName(), shardId, seed, wrapReader);
diff --git a/core/src/test/java/org/elasticsearch/test/engine/MockEngineSupportModule.java b/core/src/test/java/org/elasticsearch/test/engine/MockEngineSupportModule.java
deleted file mode 100644
index 4f353ee..0000000
--- a/core/src/test/java/org/elasticsearch/test/engine/MockEngineSupportModule.java
+++ /dev/null
@@ -1,32 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.test.engine;
-
-import org.apache.lucene.index.AssertingDirectoryReader;
-import org.apache.lucene.index.FilterDirectoryReader;
-import org.elasticsearch.common.inject.AbstractModule;
-
-public class MockEngineSupportModule extends AbstractModule {
-    public Class<? extends FilterDirectoryReader> wrapperImpl = AssertingDirectoryReader.class;
-
-    @Override
-    protected void configure() {
-        bind(Class.class).annotatedWith(MockEngineFactory.MockReaderType.class).toInstance(wrapperImpl);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/test/engine/MockInternalEngine.java b/core/src/test/java/org/elasticsearch/test/engine/MockInternalEngine.java
index 616d873..ed4dc95 100644
--- a/core/src/test/java/org/elasticsearch/test/engine/MockInternalEngine.java
+++ b/core/src/test/java/org/elasticsearch/test/engine/MockInternalEngine.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.test.engine;
 
-import org.apache.lucene.index.FilterDirectoryReader;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.SearcherManager;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -31,19 +30,17 @@ import java.io.IOException;
 final class MockInternalEngine extends InternalEngine {
     private MockEngineSupport support;
     private final boolean randomizeFlushOnClose;
-    private Class<? extends FilterDirectoryReader> wrapperClass;
 
-    MockInternalEngine(EngineConfig config, boolean skipInitialTranslogRecovery, Class<? extends FilterDirectoryReader> wrapper) throws EngineException {
+
+    MockInternalEngine(EngineConfig config, boolean skipInitialTranslogRecovery) throws EngineException {
         super(config, skipInitialTranslogRecovery);
         randomizeFlushOnClose = IndexMetaData.isOnSharedFilesystem(config.getIndexSettings()) == false;
-        wrapperClass = wrapper;
-
     }
 
     private synchronized MockEngineSupport support() {
         // lazy initialized since we need it already on super() ctor execution :(
         if (support == null) {
-            support = new MockEngineSupport(config(), wrapperClass);
+            support = new MockEngineSupport(config());
         }
         return support;
     }
diff --git a/core/src/test/java/org/elasticsearch/test/engine/MockShadowEngine.java b/core/src/test/java/org/elasticsearch/test/engine/MockShadowEngine.java
index f05f69b..1ed920b 100644
--- a/core/src/test/java/org/elasticsearch/test/engine/MockShadowEngine.java
+++ b/core/src/test/java/org/elasticsearch/test/engine/MockShadowEngine.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.test.engine;
 
-import org.apache.lucene.index.AssertingDirectoryReader;
-import org.apache.lucene.index.FilterDirectoryReader;
 import org.apache.lucene.search.AssertingIndexSearcher;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.SearcherManager;
@@ -34,9 +32,9 @@ import java.util.Map;
 final class MockShadowEngine extends ShadowEngine {
     private final MockEngineSupport support;
 
-    MockShadowEngine(EngineConfig config, Class<? extends FilterDirectoryReader> wrapper) {
+    MockShadowEngine(EngineConfig config) {
         super(config);
-        this.support = new MockEngineSupport(config, wrapper);
+        this.support = new MockEngineSupport(config);
     }
 
     @Override
diff --git a/core/src/test/java/org/elasticsearch/test/search/MockSearchService.java b/core/src/test/java/org/elasticsearch/test/search/MockSearchService.java
new file mode 100644
index 0000000..dd6c972
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/test/search/MockSearchService.java
@@ -0,0 +1,77 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.test.search;
+
+import org.elasticsearch.cache.recycler.PageCacheRecycler;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.BigArrays;
+import org.elasticsearch.indices.IndicesService;
+import org.elasticsearch.indices.IndicesWarmer;
+import org.elasticsearch.indices.cache.request.IndicesRequestCache;
+import org.elasticsearch.node.settings.NodeSettingsService;
+import org.elasticsearch.script.ScriptService;
+import org.elasticsearch.search.SearchService;
+import org.elasticsearch.search.dfs.DfsPhase;
+import org.elasticsearch.search.fetch.FetchPhase;
+import org.elasticsearch.search.internal.SearchContext;
+import org.elasticsearch.search.query.QueryPhase;
+import org.elasticsearch.threadpool.ThreadPool;
+
+import java.util.HashMap;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+
+public class MockSearchService extends SearchService {
+
+    private static final Map<SearchContext, Throwable> ACTIVE_SEARCH_CONTEXTS = new ConcurrentHashMap<>();
+
+    /** Throw an {@link AssertionError} if there are still in-flight contexts. */
+    public static void assertNoInFLightContext() {
+        final Map<SearchContext, Throwable> copy = new HashMap<>(ACTIVE_SEARCH_CONTEXTS);
+        if (copy.isEmpty() == false) {
+            throw new AssertionError("There are still " + copy.size() + " in-flight contexts", copy.values().iterator().next());
+        }
+    }
+
+    @Inject
+    public MockSearchService(Settings settings, NodeSettingsService nodeSettingsService, ClusterService clusterService, IndicesService indicesService, IndicesWarmer indicesWarmer,
+            ThreadPool threadPool, ScriptService scriptService, PageCacheRecycler pageCacheRecycler, BigArrays bigArrays,
+            DfsPhase dfsPhase, QueryPhase queryPhase, FetchPhase fetchPhase, IndicesRequestCache indicesQueryCache) {
+        super(settings, nodeSettingsService, clusterService, indicesService, indicesWarmer, threadPool, scriptService, pageCacheRecycler, bigArrays, dfsPhase,
+                queryPhase, fetchPhase, indicesQueryCache);
+    }
+ 
+    @Override
+    protected void putContext(SearchContext context) {
+        super.putContext(context);
+        ACTIVE_SEARCH_CONTEXTS.put(context, new RuntimeException());
+    }
+
+    @Override
+    protected SearchContext removeContext(long id) {
+        final SearchContext removed = super.removeContext(id);
+        if (removed != null) {
+            ACTIVE_SEARCH_CONTEXTS.remove(removed);
+        }
+        return removed;
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/transport/NettySizeHeaderFrameDecoderTests.java b/core/src/test/java/org/elasticsearch/transport/NettySizeHeaderFrameDecoderTests.java
index 3ffc945..1c5f34b 100644
--- a/core/src/test/java/org/elasticsearch/transport/NettySizeHeaderFrameDecoderTests.java
+++ b/core/src/test/java/org/elasticsearch/transport/NettySizeHeaderFrameDecoderTests.java
@@ -29,8 +29,8 @@ import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
 import org.elasticsearch.node.settings.NodeSettingsService;
 import org.elasticsearch.test.ESTestCase;
-import org.elasticsearch.common.util.MockBigArrays;
-import org.elasticsearch.cache.recycler.MockPageCacheRecycler;
+import org.elasticsearch.test.cache.recycler.MockBigArrays;
+import org.elasticsearch.test.cache.recycler.MockPageCacheRecycler;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.netty.NettyTransport;
 import org.junit.After;
diff --git a/core/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java b/core/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java
index 1c4cac7..704dbe9 100644
--- a/core/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java
+++ b/core/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortTests.java
@@ -31,7 +31,7 @@ import org.elasticsearch.common.transport.InetSocketTransportAddress;
 import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
 import org.elasticsearch.test.ESTestCase;
-import org.elasticsearch.common.util.MockBigArrays;
+import org.elasticsearch.test.cache.recycler.MockBigArrays;
 import org.elasticsearch.test.junit.rule.RepeatOnExceptionRule;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.BindTransportException;
diff --git a/docs/reference/cluster/stats.asciidoc b/docs/reference/cluster/stats.asciidoc
index 00f73cc..8093dd3 100644
--- a/docs/reference/cluster/stats.asciidoc
+++ b/docs/reference/cluster/stats.asciidoc
@@ -15,6 +15,7 @@ Will return, for example:
 ["source","js",subs="attributes,callouts"]
 --------------------------------------------------
 {
+   "timestamp": 1439326129256,
    "cluster_name": "elasticsearch",
    "status": "green",
    "indices": {
@@ -61,12 +62,35 @@ Will return, for example:
          "memory_size_in_bytes": 0,
          "evictions": 0
       },
+      "id_cache": {
+         "memory_size": "0b",
+         "memory_size_in_bytes": 0
+      },
       "completion": {
          "size": "0b",
          "size_in_bytes": 0
       },
       "segments": {
-         "count": 2
+         "count": 2,
+         "memory": "6.4kb",
+         "memory_in_bytes": 6596,
+         "index_writer_memory": "0b",
+         "index_writer_memory_in_bytes": 0,
+         "index_writer_max_memory": "275.7mb",
+         "index_writer_max_memory_in_bytes": 289194639,
+         "version_map_memory": "0b",
+         "version_map_memory_in_bytes": 0,
+         "fixed_bit_set": "0b",
+         "fixed_bit_set_memory_in_bytes": 0
+      },
+      "percolate": {
+         "total": 0,
+         "get_time": "0s",
+         "time_in_millis": 0,
+         "current": 0,
+         "memory_size_in_bytes": -1,
+         "memory_size": "-1b",
+         "queries": 0
       }
    },
    "nodes": {
diff --git a/plugins/analysis-icu/src/test/java/org/elasticsearch/index/analysis/SimpleIcuAnalysisTests.java b/plugins/analysis-icu/src/test/java/org/elasticsearch/index/analysis/SimpleIcuAnalysisTests.java
index 3516a13..8369809 100644
--- a/plugins/analysis-icu/src/test/java/org/elasticsearch/index/analysis/SimpleIcuAnalysisTests.java
+++ b/plugins/analysis-icu/src/test/java/org/elasticsearch/index/analysis/SimpleIcuAnalysisTests.java
@@ -33,8 +33,7 @@ public class SimpleIcuAnalysisTests extends ESTestCase {
     @Test
     public void testDefaultsIcuAnalysis() {
         Settings settings = settingsBuilder()
-                .put("path.home", createTempDir())
-                .loadFromClasspath("org/elasticsearch/index/analysis/phonetic-1.yml").build();
+                .put("path.home", createTempDir()).build();
         AnalysisService analysisService = createAnalysisService(settings);
 
         TokenizerFactory tokenizerFactory = analysisService.tokenizer("icu_tokenizer");
diff --git a/plugins/cloud-aws/README.md b/plugins/cloud-aws/README.md
index 08957b0..1f5f539 100644
--- a/plugins/cloud-aws/README.md
+++ b/plugins/cloud-aws/README.md
@@ -187,7 +187,7 @@ The following settings are supported:
 * `region`: The region where bucket is located. Defaults to US Standard
 * `endpoint`: The endpoint to the S3 API. Defaults to AWS's default S3 endpoint. Note that setting a region overrides the endpoint setting.
 * `protocol`: The protocol to use (`http` or `https`). Defaults to value of `cloud.aws.protocol` or `cloud.aws.s3.protocol`.
-* `base_path`: Specifies the path within bucket to repository data. Defaults to root directory.
+* `base_path`: Specifies the path within bucket to repository data. Defaults to value of `repositories.s3.base_path` or to root directory if not set.
 * `access_key`: The access key to use for authentication. Defaults to value of `cloud.aws.access_key`.
 * `secret_key`: The secret key to use for authentication. Defaults to value of `cloud.aws.secret_key`.
 * `chunk_size`: Big files can be broken down into chunks during snapshotting if needed. The chunk size can be specified in bytes or by using size value notation, i.e. `1g`, `10m`, `5k`. Defaults to `100m`.
diff --git a/plugins/cloud-aws/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java b/plugins/cloud-aws/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java
index ecd3919..4be35ba 100644
--- a/plugins/cloud-aws/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java
+++ b/plugins/cloud-aws/src/main/java/org/elasticsearch/repositories/s3/S3Repository.java
@@ -123,7 +123,7 @@ public class S3Repository extends BlobStoreRepository {
                 bucket, region, endpoint, protocol, chunkSize, serverSideEncryption, bufferSize, maxRetries);
 
         blobStore = new S3BlobStore(settings, s3Service.client(endpoint, protocol, region, repositorySettings.settings().get("access_key"), repositorySettings.settings().get("secret_key"), maxRetries), bucket, region, serverSideEncryption, bufferSize, maxRetries);
-        String basePath = repositorySettings.settings().get("base_path", null);
+        String basePath = repositorySettings.settings().get("base_path", settings.get("repositories.s3.base_path"));
         if (Strings.hasLength(basePath)) {
             BlobPath path = new BlobPath();
             for(String elem : Strings.splitStringToArray(basePath, '/')) {
diff --git a/plugins/cloud-aws/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java b/plugins/cloud-aws/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java
index 25dd8b9..23441d5 100644
--- a/plugins/cloud-aws/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java
+++ b/plugins/cloud-aws/src/test/java/org/elasticsearch/repositories/s3/AbstractS3SnapshotRestoreTest.java
@@ -64,6 +64,7 @@ abstract public class AbstractS3SnapshotRestoreTest extends AbstractAwsTest {
                 .put(MockFSDirectoryService.RANDOM_NO_DELETE_OPEN_FILE, false)
                 .put("cloud.enabled", true)
                 .put("plugin.types", CloudAwsPlugin.class.getName())
+                .put("repositories.s3.base_path", basePath)
                 .build();
     }
 
@@ -85,11 +86,17 @@ abstract public class AbstractS3SnapshotRestoreTest extends AbstractAwsTest {
     @Test @AwaitsFix(bugUrl = "https://github.com/elastic/elasticsearch-cloud-aws/issues/211")
     public void testSimpleWorkflow() {
         Client client = client();
+        Settings.Builder settings = Settings.settingsBuilder()
+                .put("chunk_size", randomIntBetween(1000, 10000));
+
+        // We sometime test getting the base_path from node settings using repositories.s3.base_path
+        if (usually()) {
+            settings.put("base_path", basePath);
+        }
+
         logger.info("-->  creating s3 repository with bucket[{}] and path [{}]", internalCluster().getInstance(Settings.class).get("repositories.s3.bucket"), basePath);
         PutRepositoryResponse putRepositoryResponse = client.admin().cluster().preparePutRepository("test-repo")
-                .setType("s3").setSettings(Settings.settingsBuilder()
-                        .put("base_path", basePath)
-                        .put("chunk_size", randomIntBetween(1000, 10000))
+                .setType("s3").setSettings(settings
                         ).get();
         assertThat(putRepositoryResponse.isAcknowledged(), equalTo(true));
 
@@ -342,7 +349,7 @@ abstract public class AbstractS3SnapshotRestoreTest extends AbstractAwsTest {
         PutRepositoryResponse putRepositoryResponse = client.admin().cluster().preparePutRepository("test-repo")
                 .setType("s3").setSettings(Settings.settingsBuilder()
                         .put("base_path", basePath)
-                        ).get();
+                ).get();
         assertThat(putRepositoryResponse.isAcknowledged(), equalTo(true));
 
         logger.info("--> restore non existing snapshot");
diff --git a/qa/smoke-test-shaded/pom.xml b/qa/smoke-test-shaded/pom.xml
index 0b968e1..711259e 100644
--- a/qa/smoke-test-shaded/pom.xml
+++ b/qa/smoke-test-shaded/pom.xml
@@ -23,7 +23,7 @@
         <dependency>
             <groupId>org.elasticsearch.distribution.shaded</groupId>
             <artifactId>elasticsearch</artifactId>
-            <version>2.0.0-SNAPSHOT</version>
+            <version>${elasticsearch.version}</version>
         </dependency>
         <dependency>
             <groupId>org.hamcrest</groupId>

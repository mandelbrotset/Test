diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java b/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java
index cb4bee3..6cac629 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java
@@ -21,8 +21,8 @@ package org.apache.lucene.queryparser.classic;
 
 import org.apache.lucene.search.ConstantScoreQuery;
 import org.apache.lucene.search.Query;
-import org.elasticsearch.index.query.ExistsQueryBuilder;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.ExistsQueryParser;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
  *
@@ -32,7 +32,7 @@ public class ExistsFieldQueryExtension implements FieldQueryExtension {
     public static final String NAME = "_exists_";
 
     @Override
-    public Query query(QueryShardContext context, String queryText) {
-        return new ConstantScoreQuery(ExistsQueryBuilder.newFilter(context, queryText));
+    public Query query(QueryParseContext parseContext, String queryText) {
+        return new ConstantScoreQuery(ExistsQueryParser.newFilter(parseContext, queryText, null));
     }
 }
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java b/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java
index 299a37a..003ff18 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java
@@ -20,12 +20,12 @@
 package org.apache.lucene.queryparser.classic;
 
 import org.apache.lucene.search.Query;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
  *
  */
 public interface FieldQueryExtension {
 
-    Query query(QueryShardContext context, String queryText);
+    Query query(QueryParseContext parseContext, String queryText);
 }
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java b/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
index 6974dc0..c8d3d31 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
@@ -39,7 +39,7 @@ import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.core.DateFieldMapper;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.support.QueryParsers;
 
 import com.google.common.base.Objects;
@@ -70,7 +70,7 @@ public class MapperQueryParser extends QueryParser {
                 .build();
     }
 
-    private final QueryShardContext context;
+    private final QueryParseContext parseContext;
 
     private QueryParserSettings settings;
 
@@ -85,9 +85,9 @@ public class MapperQueryParser extends QueryParser {
 
     private String quoteFieldSuffix;
 
-    public MapperQueryParser(QueryShardContext context) {
+    public MapperQueryParser(QueryParseContext parseContext) {
         super(null, null);
-        this.context = context;
+        this.parseContext = parseContext;
     }
 
     public void reset(QueryParserSettings settings) {
@@ -162,7 +162,7 @@ public class MapperQueryParser extends QueryParser {
     public Query getFieldQuery(String field, String queryText, boolean quoted) throws ParseException {
         FieldQueryExtension fieldQueryExtension = fieldQueryExtensions.get(field);
         if (fieldQueryExtension != null) {
-            return fieldQueryExtension.query(context, queryText);
+            return fieldQueryExtension.query(parseContext, queryText);
         }
         Collection<String> fields = extractMultiFields(field);
         if (fields != null) {
@@ -226,27 +226,27 @@ public class MapperQueryParser extends QueryParser {
             if (quoted) {
                 setAnalyzer(quoteAnalyzer);
                 if (quoteFieldSuffix != null) {
-                    currentFieldType = context.fieldMapper(field + quoteFieldSuffix);
+                    currentFieldType = parseContext.fieldMapper(field + quoteFieldSuffix);
                 }
             }
             if (currentFieldType == null) {
-                currentFieldType = context.fieldMapper(field);
+                currentFieldType = parseContext.fieldMapper(field);
             }
             if (currentFieldType != null) {
                 if (quoted) {
                     if (!forcedQuoteAnalyzer) {
-                        setAnalyzer(context.getSearchQuoteAnalyzer(currentFieldType));
+                        setAnalyzer(parseContext.getSearchQuoteAnalyzer(currentFieldType));
                     }
                 } else {
                     if (!forcedAnalyzer) {
-                        setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                        setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                     }
                 }
                 if (currentFieldType != null) {
                     Query query = null;
                     if (currentFieldType.useTermQueryWithQueryString()) {
                         try {
-                            query = currentFieldType.termQuery(queryText, context);
+                            query = currentFieldType.termQuery(queryText, parseContext);
                         } catch (RuntimeException e) {
                             if (settings.lenient()) {
                                 return null;
@@ -357,7 +357,7 @@ public class MapperQueryParser extends QueryParser {
     }
 
     private Query getRangeQuerySingle(String field, String part1, String part2, boolean startInclusive, boolean endInclusive) {
-        currentFieldType = context.fieldMapper(field);
+        currentFieldType = parseContext.fieldMapper(field);
         if (currentFieldType != null) {
             if (lowercaseExpandedTerms && !currentFieldType.isNumeric()) {
                 part1 = part1 == null ? null : part1.toLowerCase(locale);
@@ -422,7 +422,7 @@ public class MapperQueryParser extends QueryParser {
     }
 
     private Query getFuzzyQuerySingle(String field, String termStr, String minSimilarity) throws ParseException {
-        currentFieldType = context.fieldMapper(field);
+        currentFieldType = parseContext.fieldMapper(field);
         if (currentFieldType != null) {
             try {
                 return currentFieldType.fuzzyQuery(termStr, Fuzziness.build(minSimilarity), fuzzyPrefixLength, settings.fuzzyMaxExpansions(), FuzzyQuery.defaultTranspositions);
@@ -492,14 +492,14 @@ public class MapperQueryParser extends QueryParser {
         currentFieldType = null;
         Analyzer oldAnalyzer = getAnalyzer();
         try {
-            currentFieldType = context.fieldMapper(field);
+            currentFieldType = parseContext.fieldMapper(field);
             if (currentFieldType != null) {
                 if (!forcedAnalyzer) {
-                    setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                    setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                 }
                 Query query = null;
                 if (currentFieldType.useTermQueryWithQueryString()) {
-                    query = currentFieldType.prefixQuery(termStr, multiTermRewriteMethod, context);
+                    query = currentFieldType.prefixQuery(termStr, multiTermRewriteMethod, parseContext);
                 }
                 if (query == null) {
                     query = getPossiblyAnalyzedPrefixQuery(currentFieldType.names().indexName(), termStr);
@@ -584,7 +584,7 @@ public class MapperQueryParser extends QueryParser {
                     return newMatchAllDocsQuery();
                 }
                 // effectively, we check if a field exists or not
-                return fieldQueryExtensions.get(ExistsFieldQueryExtension.NAME).query(context, actualField);
+                return fieldQueryExtensions.get(ExistsFieldQueryExtension.NAME).query(parseContext, actualField);
             }
         }
         if (lowercaseExpandedTerms) {
@@ -633,10 +633,10 @@ public class MapperQueryParser extends QueryParser {
         currentFieldType = null;
         Analyzer oldAnalyzer = getAnalyzer();
         try {
-            currentFieldType = context.fieldMapper(field);
+            currentFieldType = parseContext.fieldMapper(field);
             if (currentFieldType != null) {
                 if (!forcedAnalyzer) {
-                    setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                    setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                 }
                 indexedNameField = currentFieldType.names().indexName();
                 return getPossiblyAnalyzedWildcardQuery(indexedNameField, termStr);
@@ -774,14 +774,14 @@ public class MapperQueryParser extends QueryParser {
         currentFieldType = null;
         Analyzer oldAnalyzer = getAnalyzer();
         try {
-            currentFieldType = context.fieldMapper(field);
+            currentFieldType = parseContext.fieldMapper(field);
             if (currentFieldType != null) {
                 if (!forcedAnalyzer) {
-                    setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                    setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                 }
                 Query query = null;
                 if (currentFieldType.useTermQueryWithQueryString()) {
-                    query = currentFieldType.regexpQuery(termStr, RegExp.ALL, maxDeterminizedStates, multiTermRewriteMethod, context);
+                    query = currentFieldType.regexpQuery(termStr, RegExp.ALL, maxDeterminizedStates, multiTermRewriteMethod, parseContext);
                 }
                 if (query == null) {
                     query = super.getRegexpQuery(field, termStr);
@@ -829,7 +829,7 @@ public class MapperQueryParser extends QueryParser {
     private Collection<String> extractMultiFields(String field) {
         Collection<String> fields = null;
         if (field != null) {
-            fields = context.simpleMatchToIndexNames(field);
+            fields = parseContext.simpleMatchToIndexNames(field);
         } else {
             fields = settings.fields();
         }
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java b/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java
index f9fc8c9..ed1b704 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java
@@ -21,8 +21,8 @@ package org.apache.lucene.queryparser.classic;
 
 import org.apache.lucene.search.ConstantScoreQuery;
 import org.apache.lucene.search.Query;
-import org.elasticsearch.index.query.MissingQueryBuilder;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.MissingQueryParser;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
  *
@@ -32,11 +32,8 @@ public class MissingFieldQueryExtension implements FieldQueryExtension {
     public static final String NAME = "_missing_";
 
     @Override
-    public Query query(QueryShardContext context, String queryText) {
-        Query query = MissingQueryBuilder.newFilter(context, queryText, MissingQueryBuilder.DEFAULT_EXISTENCE_VALUE, MissingQueryBuilder.DEFAULT_NULL_VALUE);
-        if (query != null) {
-            return new ConstantScoreQuery(query);
-        }
-        return null;
+    public Query query(QueryParseContext parseContext, String queryText) {
+        return new ConstantScoreQuery(MissingQueryParser.newFilter(parseContext, queryText,
+                MissingQueryParser.DEFAULT_EXISTENCE_VALUE, MissingQueryParser.DEFAULT_NULL_VALUE, null));
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/ElasticsearchException.java b/core/src/main/java/org/elasticsearch/ElasticsearchException.java
index d1693e5..4f47805 100644
--- a/core/src/main/java/org/elasticsearch/ElasticsearchException.java
+++ b/core/src/main/java/org/elasticsearch/ElasticsearchException.java
@@ -580,7 +580,6 @@ public class ElasticsearchException extends RuntimeException implements ToXConte
                 org.elasticsearch.index.engine.RecoveryEngineException.class,
                 org.elasticsearch.common.blobstore.BlobStoreException.class,
                 org.elasticsearch.index.snapshots.IndexShardRestoreException.class,
-                org.elasticsearch.index.query.QueryShardException.class,
                 org.elasticsearch.index.query.QueryParsingException.class,
                 org.elasticsearch.action.support.replication.TransportReplicationAction.RetryOnPrimaryException.class,
                 org.elasticsearch.index.engine.DeleteByQueryFailedEngineException.class,
diff --git a/core/src/main/java/org/elasticsearch/action/ActionModule.java b/core/src/main/java/org/elasticsearch/action/ActionModule.java
index a4b7162..c613f61 100644
--- a/core/src/main/java/org/elasticsearch/action/ActionModule.java
+++ b/core/src/main/java/org/elasticsearch/action/ActionModule.java
@@ -19,9 +19,7 @@
 
 package org.elasticsearch.action;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
-
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthAction;
 import org.elasticsearch.action.admin.cluster.health.TransportClusterHealthAction;
 import org.elasticsearch.action.admin.cluster.node.hotthreads.NodesHotThreadsAction;
@@ -85,7 +83,11 @@ import org.elasticsearch.action.admin.indices.flush.FlushAction;
 import org.elasticsearch.action.admin.indices.flush.TransportFlushAction;
 import org.elasticsearch.action.admin.indices.get.GetIndexAction;
 import org.elasticsearch.action.admin.indices.get.TransportGetIndexAction;
-import org.elasticsearch.action.admin.indices.mapping.get.*;
+import org.elasticsearch.action.admin.indices.mapping.get.GetFieldMappingsAction;
+import org.elasticsearch.action.admin.indices.mapping.get.GetMappingsAction;
+import org.elasticsearch.action.admin.indices.mapping.get.TransportGetFieldMappingsAction;
+import org.elasticsearch.action.admin.indices.mapping.get.TransportGetFieldMappingsIndexAction;
+import org.elasticsearch.action.admin.indices.mapping.get.TransportGetMappingsAction;
 import org.elasticsearch.action.admin.indices.mapping.put.PutMappingAction;
 import org.elasticsearch.action.admin.indices.mapping.put.TransportPutMappingAction;
 import org.elasticsearch.action.admin.indices.open.OpenIndexAction;
@@ -96,14 +98,14 @@ import org.elasticsearch.action.admin.indices.recovery.RecoveryAction;
 import org.elasticsearch.action.admin.indices.recovery.TransportRecoveryAction;
 import org.elasticsearch.action.admin.indices.refresh.RefreshAction;
 import org.elasticsearch.action.admin.indices.refresh.TransportRefreshAction;
-import org.elasticsearch.action.admin.indices.shards.IndicesShardStoresAction;
-import org.elasticsearch.action.admin.indices.shards.TransportIndicesShardStoresAction;
 import org.elasticsearch.action.admin.indices.segments.IndicesSegmentsAction;
 import org.elasticsearch.action.admin.indices.segments.TransportIndicesSegmentsAction;
 import org.elasticsearch.action.admin.indices.settings.get.GetSettingsAction;
 import org.elasticsearch.action.admin.indices.settings.get.TransportGetSettingsAction;
 import org.elasticsearch.action.admin.indices.settings.put.TransportUpdateSettingsAction;
 import org.elasticsearch.action.admin.indices.settings.put.UpdateSettingsAction;
+import org.elasticsearch.action.admin.indices.shards.IndicesShardStoresAction;
+import org.elasticsearch.action.admin.indices.shards.TransportIndicesShardStoresAction;
 import org.elasticsearch.action.admin.indices.stats.IndicesStatsAction;
 import org.elasticsearch.action.admin.indices.stats.TransportIndicesStatsAction;
 import org.elasticsearch.action.admin.indices.template.delete.DeleteIndexTemplateAction;
@@ -139,7 +141,11 @@ import org.elasticsearch.action.explain.ExplainAction;
 import org.elasticsearch.action.explain.TransportExplainAction;
 import org.elasticsearch.action.fieldstats.FieldStatsAction;
 import org.elasticsearch.action.fieldstats.TransportFieldStatsTransportAction;
-import org.elasticsearch.action.get.*;
+import org.elasticsearch.action.get.GetAction;
+import org.elasticsearch.action.get.MultiGetAction;
+import org.elasticsearch.action.get.TransportGetAction;
+import org.elasticsearch.action.get.TransportMultiGetAction;
+import org.elasticsearch.action.get.TransportShardMultiGetAction;
 import org.elasticsearch.action.index.IndexAction;
 import org.elasticsearch.action.index.TransportIndexAction;
 import org.elasticsearch.action.indexedscripts.delete.DeleteIndexedScriptAction;
@@ -148,16 +154,38 @@ import org.elasticsearch.action.indexedscripts.get.GetIndexedScriptAction;
 import org.elasticsearch.action.indexedscripts.get.TransportGetIndexedScriptAction;
 import org.elasticsearch.action.indexedscripts.put.PutIndexedScriptAction;
 import org.elasticsearch.action.indexedscripts.put.TransportPutIndexedScriptAction;
-import org.elasticsearch.action.percolate.*;
-import org.elasticsearch.action.search.*;
-import org.elasticsearch.action.search.type.*;
+import org.elasticsearch.action.percolate.MultiPercolateAction;
+import org.elasticsearch.action.percolate.PercolateAction;
+import org.elasticsearch.action.percolate.TransportMultiPercolateAction;
+import org.elasticsearch.action.percolate.TransportPercolateAction;
+import org.elasticsearch.action.percolate.TransportShardMultiPercolateAction;
+import org.elasticsearch.action.search.ClearScrollAction;
+import org.elasticsearch.action.search.MultiSearchAction;
+import org.elasticsearch.action.search.SearchAction;
+import org.elasticsearch.action.search.SearchScrollAction;
+import org.elasticsearch.action.search.TransportClearScrollAction;
+import org.elasticsearch.action.search.TransportMultiSearchAction;
+import org.elasticsearch.action.search.TransportSearchAction;
+import org.elasticsearch.action.search.TransportSearchScrollAction;
+import org.elasticsearch.action.search.type.TransportSearchDfsQueryAndFetchAction;
+import org.elasticsearch.action.search.type.TransportSearchDfsQueryThenFetchAction;
+import org.elasticsearch.action.search.type.TransportSearchQueryAndFetchAction;
+import org.elasticsearch.action.search.type.TransportSearchQueryThenFetchAction;
+import org.elasticsearch.action.search.type.TransportSearchScanAction;
+import org.elasticsearch.action.search.type.TransportSearchScrollQueryAndFetchAction;
+import org.elasticsearch.action.search.type.TransportSearchScrollQueryThenFetchAction;
+import org.elasticsearch.action.search.type.TransportSearchScrollScanAction;
 import org.elasticsearch.action.suggest.SuggestAction;
 import org.elasticsearch.action.suggest.TransportSuggestAction;
 import org.elasticsearch.action.support.ActionFilter;
 import org.elasticsearch.action.support.ActionFilters;
 import org.elasticsearch.action.support.AutoCreateIndex;
 import org.elasticsearch.action.support.TransportAction;
-import org.elasticsearch.action.termvectors.*;
+import org.elasticsearch.action.termvectors.MultiTermVectorsAction;
+import org.elasticsearch.action.termvectors.TermVectorsAction;
+import org.elasticsearch.action.termvectors.TransportMultiTermVectorsAction;
+import org.elasticsearch.action.termvectors.TransportShardMultiTermsVectorAction;
+import org.elasticsearch.action.termvectors.TransportTermVectorsAction;
 import org.elasticsearch.action.termvectors.dfs.TransportDfsOnlyAction;
 import org.elasticsearch.action.update.TransportUpdateAction;
 import org.elasticsearch.action.update.UpdateAction;
@@ -165,6 +193,7 @@ import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.inject.multibindings.MapBinder;
 import org.elasticsearch.common.inject.multibindings.Multibinder;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -174,7 +203,7 @@ import java.util.Map;
 public class ActionModule extends AbstractModule {
 
     private final Map<String, ActionEntry> actions = Maps.newHashMap();
-    private final List<Class<? extends ActionFilter>> actionFilters = Lists.newArrayList();
+    private final List<Class<? extends ActionFilter>> actionFilters = new ArrayList<>();
 
     static class ActionEntry<Request extends ActionRequest, Response extends ActionResponse> {
         public final GenericAction<Request, Response> action;
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponse.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponse.java
index 7172c25..755fb33 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponse.java
@@ -31,16 +31,19 @@ import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.xcontent.*;
+import org.elasticsearch.common.xcontent.StatusToXContent;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentBuilderString;
+import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.rest.RestStatus;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.action.admin.cluster.health.ClusterIndexHealth.readClusterIndexHealth;
 
 /**
@@ -152,7 +155,7 @@ public class ClusterHealthResponse extends ActionResponse implements Iterable<Cl
      * All the validation failures, including index level validation failures.
      */
     public List<String> getAllValidationFailures() {
-        List<String> allFailures = newArrayList(getValidationFailures());
+        List<String> allFailures = new ArrayList<>(getValidationFailures());
         for (ClusterIndexHealth indexHealth : indices.values()) {
             allFailures.addAll(indexHealth.getValidationFailures());
         }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/hotthreads/TransportNodesHotThreadsAction.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/hotthreads/TransportNodesHotThreadsAction.java
index 7f2c199..59fd913 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/hotthreads/TransportNodesHotThreadsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/hotthreads/TransportNodesHotThreadsAction.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.admin.cluster.node.hotthreads;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.support.ActionFilters;
 import org.elasticsearch.action.support.nodes.BaseNodeRequest;
@@ -36,6 +35,7 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
@@ -54,7 +54,7 @@ public class TransportNodesHotThreadsAction extends TransportNodesAction<NodesHo
 
     @Override
     protected NodesHotThreadsResponse newResponse(NodesHotThreadsRequest request, AtomicReferenceArray responses) {
-        final List<NodeHotThreads> nodes = Lists.newArrayList();
+        final List<NodeHotThreads> nodes = new ArrayList<>();
         for (int i = 0; i < responses.length(); i++) {
             Object resp = responses.get(i);
             if (resp instanceof NodeHotThreads) {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/TransportNodesStatsAction.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/TransportNodesStatsAction.java
index 90ad866..b3d1bd4 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/TransportNodesStatsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/TransportNodesStatsAction.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.admin.cluster.node.stats;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.action.support.ActionFilters;
 import org.elasticsearch.action.support.nodes.BaseNodeRequest;
 import org.elasticsearch.action.support.nodes.TransportNodesAction;
@@ -35,6 +34,7 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
@@ -56,7 +56,7 @@ public class TransportNodesStatsAction extends TransportNodesAction<NodesStatsRe
 
     @Override
     protected NodesStatsResponse newResponse(NodesStatsRequest nodesInfoRequest, AtomicReferenceArray responses) {
-        final List<NodeStats> nodeStats = Lists.newArrayList();
+        final List<NodeStats> nodeStats = new ArrayList<>();
         for (int i = 0; i < responses.length(); i++) {
             Object resp = responses.get(i);
             if (resp instanceof NodeStats) {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java
index d6a0cd5..3e8a122 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java
@@ -21,8 +21,8 @@ package org.elasticsearch.action.admin.cluster.snapshots.status;
 
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
-import org.elasticsearch.cluster.metadata.SnapshotId;
 import org.elasticsearch.cluster.SnapshotsInProgress.State;
+import org.elasticsearch.cluster.metadata.SnapshotId;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.io.stream.Streamable;
@@ -32,11 +32,11 @@ import org.elasticsearch.common.xcontent.XContentBuilderString;
 import org.elasticsearch.common.xcontent.XContentFactory;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Sets.newHashSet;
 
 /**
@@ -109,7 +109,7 @@ public class SnapshotStatus implements ToXContent, Streamable {
         }
 
         for (String index : indices) {
-            List<SnapshotIndexShardStatus> shards = newArrayList();
+            List<SnapshotIndexShardStatus> shards = new ArrayList<>();
             for (SnapshotIndexShardStatus shard : this.shards) {
                 if (shard.getIndex().equals(index)) {
                     shards.add(shard);
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportNodesSnapshotsStatus.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportNodesSnapshotsStatus.java
index 8c535ec..25701a8 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportNodesSnapshotsStatus.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportNodesSnapshotsStatus.java
@@ -20,12 +20,15 @@
 package org.elasticsearch.action.admin.cluster.snapshots.status;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.ActionRequest;
 import org.elasticsearch.action.FailedNodeException;
 import org.elasticsearch.action.support.ActionFilters;
-import org.elasticsearch.action.support.nodes.*;
+import org.elasticsearch.action.support.nodes.BaseNodeRequest;
+import org.elasticsearch.action.support.nodes.BaseNodeResponse;
+import org.elasticsearch.action.support.nodes.BaseNodesRequest;
+import org.elasticsearch.action.support.nodes.BaseNodesResponse;
+import org.elasticsearch.action.support.nodes.TransportNodesAction;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
@@ -42,6 +45,7 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicReferenceArray;
@@ -82,8 +86,8 @@ public class TransportNodesSnapshotsStatus extends TransportNodesAction<Transpor
 
     @Override
     protected NodesSnapshotStatus newResponse(Request request, AtomicReferenceArray responses) {
-        final List<NodeSnapshotStatus> nodesList = Lists.newArrayList();
-        final List<FailedNodeException> failures = Lists.newArrayList();
+        final List<NodeSnapshotStatus> nodesList = new ArrayList<>();
+        final List<FailedNodeException> failures = new ArrayList<>();
         for (int i = 0; i < responses.length(); i++) {
             Object resp = responses.get(i);
             if (resp instanceof NodeSnapshotStatus) { // will also filter out null response for unallocated ones
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/TransportClusterStatsAction.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/TransportClusterStatsAction.java
index 82a2989..26e7826 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/TransportClusterStatsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/TransportClusterStatsAction.java
@@ -106,7 +106,7 @@ public class TransportClusterStatsAction extends TransportNodesAction<ClusterSta
             for (IndexShard indexShard : indexService) {
                 if (indexShard.routingEntry() != null && indexShard.routingEntry().active()) {
                     // only report on fully started shards
-                    shardsStats.add(new ShardStats(indexShard, indexShard.routingEntry(), SHARD_STATS_FLAGS));
+                    shardsStats.add(new ShardStats(indexShard, SHARD_STATS_FLAGS));
                 }
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/alias/IndicesAliasesRequest.java b/core/src/main/java/org/elasticsearch/action/admin/indices/alias/IndicesAliasesRequest.java
index fd6819c..779f9a3 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/alias/IndicesAliasesRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/alias/IndicesAliasesRequest.java
@@ -21,8 +21,6 @@ package org.elasticsearch.action.admin.indices.alias;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.AliasesRequest;
 import org.elasticsearch.action.CompositeIndicesRequest;
@@ -54,7 +52,7 @@ import static org.elasticsearch.cluster.metadata.AliasAction.readAliasAction;
  */
 public class IndicesAliasesRequest extends AcknowledgedRequest<IndicesAliasesRequest> implements CompositeIndicesRequest {
 
-    private List<AliasActions> allAliasActions = Lists.newArrayList();
+    private List<AliasActions> allAliasActions = new ArrayList<>();
 
     //indices options that require every specified index to exist, expand wildcards only to open indices and
     //don't allow that no indices are resolved from wildcard expressions
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/analyze/TransportAnalyzeAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/analyze/TransportAnalyzeAction.java
index 9d34c6f..3e7a03a 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/analyze/TransportAnalyzeAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/analyze/TransportAnalyzeAction.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.action.admin.indices.analyze;
 
-import com.google.common.collect.Lists;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
@@ -39,7 +38,13 @@ import org.elasticsearch.cluster.routing.ShardsIterator;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.IndexService;
-import org.elasticsearch.index.analysis.*;
+import org.elasticsearch.index.analysis.CharFilterFactory;
+import org.elasticsearch.index.analysis.CharFilterFactoryFactory;
+import org.elasticsearch.index.analysis.CustomAnalyzer;
+import org.elasticsearch.index.analysis.TokenFilterFactory;
+import org.elasticsearch.index.analysis.TokenFilterFactoryFactory;
+import org.elasticsearch.index.analysis.TokenizerFactory;
+import org.elasticsearch.index.analysis.TokenizerFactoryFactory;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.internal.AllFieldMapper;
 import org.elasticsearch.index.shard.ShardId;
@@ -49,6 +54,7 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -210,7 +216,7 @@ public class TransportAnalyzeAction extends TransportSingleShardAction<AnalyzeRe
             throw new IllegalArgumentException("failed to find analyzer");
         }
 
-        List<AnalyzeResponse.AnalyzeToken> tokens = Lists.newArrayList();
+        List<AnalyzeResponse.AnalyzeToken> tokens = new ArrayList<>();
         TokenStream stream = null;
         int lastPosition = -1;
         int lastOffset = 0;
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/cache/clear/TransportClearIndicesCacheAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/cache/clear/TransportClearIndicesCacheAction.java
index e77b700..2f8d7f8 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/cache/clear/TransportClearIndicesCacheAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/cache/clear/TransportClearIndicesCacheAction.java
@@ -40,11 +40,10 @@ import org.elasticsearch.indices.cache.request.IndicesRequestCache;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * Indices clear cache action.
  */
@@ -76,7 +75,7 @@ public class TransportClearIndicesCacheAction extends TransportBroadcastAction<C
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/flush/TransportFlushAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/flush/TransportFlushAction.java
index c6c3c31..323a6cc 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/flush/TransportFlushAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/flush/TransportFlushAction.java
@@ -38,11 +38,10 @@ import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * Flush Action.
  */
@@ -71,7 +70,7 @@ public class TransportFlushAction extends TransportBroadcastAction<FlushRequest,
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsIndexAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsIndexAction.java
index 8e51133..265d326 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsIndexAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsIndexAction.java
@@ -22,7 +22,6 @@ package org.elasticsearch.action.admin.indices.mapping.get;
 import com.google.common.base.Predicate;
 import com.google.common.collect.Collections2;
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.admin.indices.mapping.get.GetFieldMappingsResponse.FieldMappingMetaData;
 import org.elasticsearch.action.support.ActionFilters;
@@ -55,6 +54,8 @@ import java.io.IOException;
 import java.util.Collection;
 import java.util.Iterator;
 
+import static org.elasticsearch.common.util.CollectionUtils.newLinkedList;
+
 /**
  * Transport action used to retrieve the mappings related to fields that belong to a specific index
  */
@@ -178,7 +179,7 @@ public class TransportGetFieldMappingsIndexAction extends TransportSingleShardAc
             } else if (Regex.isSimpleMatchPattern(field)) {
                 // go through the field mappers 3 times, to make sure we give preference to the resolve order: full name, index name, name.
                 // also make sure we only store each mapper once.
-                Collection<FieldMapper> remainingFieldMappers = Lists.newLinkedList(allFieldMappers);
+                Collection<FieldMapper> remainingFieldMappers = newLinkedList(allFieldMappers);
                 for (Iterator<FieldMapper> it = remainingFieldMappers.iterator(); it.hasNext(); ) {
                     final FieldMapper fieldMapper = it.next();
                     if (Regex.simpleMatch(field, fieldMapper.fieldType().names().fullName())) {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java
index 6b54169..bc5cb57 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java
@@ -38,11 +38,10 @@ import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * Optimize index/indices action.
  */
@@ -71,7 +70,7 @@ public class TransportOptimizeAction extends TransportBroadcastAction<OptimizeRe
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportRefreshAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportRefreshAction.java
index 32e9e50..2eead86 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportRefreshAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportRefreshAction.java
@@ -38,11 +38,10 @@ import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * Refresh action.
  */
@@ -71,7 +70,7 @@ public class TransportRefreshAction extends TransportBroadcastAction<RefreshRequ
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndexSegments.java b/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndexSegments.java
index 453a6f1..52c3143 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndexSegments.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndexSegments.java
@@ -19,9 +19,9 @@
 
 package org.elasticsearch.action.admin.indices.segments;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
@@ -39,7 +39,7 @@ public class IndexSegments implements Iterable<IndexShardSegments> {
         for (ShardSegments shard : shards) {
             List<ShardSegments> lst = tmpIndexShards.get(shard.getShardRouting().id());
             if (lst == null) {
-                lst = Lists.newArrayList();
+                lst = new ArrayList<>();
                 tmpIndexShards.put(shard.getShardRouting().id(), lst);
             }
             lst.add(shard);
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndicesSegmentResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndicesSegmentResponse.java
index 6b0dc86..033ecf7 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndicesSegmentResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/segments/IndicesSegmentResponse.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.admin.indices.segments;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 import org.apache.lucene.util.Accountable;
@@ -35,6 +34,7 @@ import org.elasticsearch.common.xcontent.XContentBuilderString;
 import org.elasticsearch.index.engine.Segment;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Collection;
 import java.util.List;
 import java.util.Map;
@@ -67,7 +67,7 @@ public class IndicesSegmentResponse extends BroadcastResponse implements ToXCont
         }
 
         for (String index : indices) {
-            List<ShardSegments> shards = Lists.newArrayList();
+            List<ShardSegments> shards = new ArrayList<>();
             for (ShardSegments shard : this.shards) {
                 if (shard.getShardRouting().index().equals(index)) {
                     shards.add(shard);
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/segments/TransportIndicesSegmentsAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/segments/TransportIndicesSegmentsAction.java
index ee7cc5a..5a6ff58 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/segments/TransportIndicesSegmentsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/segments/TransportIndicesSegmentsAction.java
@@ -44,11 +44,10 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  *
  */
@@ -87,7 +86,7 @@ public class TransportIndicesSegmentsAction extends TransportBroadcastAction<Ind
         int successfulShards = 0;
         int failedShards = 0;
         List<ShardOperationFailedException> shardFailures = null;
-        final List<ShardSegments> shards = newArrayList();
+        final List<ShardSegments> shards = new ArrayList<>();
         for (int i = 0; i < shardsResponses.length(); i++) {
             Object shardResponse = shardsResponses.get(i);
             if (shardResponse == null) {
@@ -95,7 +94,7 @@ public class TransportIndicesSegmentsAction extends TransportBroadcastAction<Ind
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndexStats.java b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndexStats.java
index 7cda8d0..6f701e4 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndexStats.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndexStats.java
@@ -19,9 +19,9 @@
 
 package org.elasticsearch.action.admin.indices.stats;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
@@ -57,7 +57,7 @@ public class IndexStats implements Iterable<IndexShardStats> {
         for (ShardStats shard : shards) {
             List<ShardStats> lst = tmpIndexShards.get(shard.getShardRouting().id());
             if (lst == null) {
-                lst = Lists.newArrayList();
+                lst = new ArrayList<>();
                 tmpIndexShards.put(shard.getShardRouting().id(), lst);
             }
             lst.add(shard);
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java
index 2d9bf1e..d9b8e9d 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.action.admin.indices.stats;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 import org.elasticsearch.action.ShardOperationFailedException;
@@ -35,6 +34,7 @@ import org.elasticsearch.common.xcontent.XContentBuilderString;
 import org.elasticsearch.common.xcontent.XContentFactory;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -94,7 +94,7 @@ public class IndicesStatsResponse extends BroadcastResponse implements ToXConten
         }
 
         for (String index : indices) {
-            List<ShardStats> shards = Lists.newArrayList();
+            List<ShardStats> shards = new ArrayList<>();
             for (ShardStats shard : this.shards) {
                 if (shard.getShardRouting().index().equals(index)) {
                     shards.add(shard);
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/ShardStats.java b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/ShardStats.java
index 5f4dd98..b3c87de 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/ShardStats.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/ShardStats.java
@@ -29,6 +29,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentBuilderString;
 import org.elasticsearch.index.engine.CommitStats;
 import org.elasticsearch.index.shard.IndexShard;
+import org.elasticsearch.index.shard.ShardPath;
 
 import java.io.IOException;
 
@@ -37,20 +38,23 @@ import static org.elasticsearch.cluster.routing.ShardRouting.readShardRoutingEnt
 /**
  */
 public class ShardStats extends BroadcastShardResponse implements ToXContent {
-
     private ShardRouting shardRouting;
-
-    CommonStats commonStats;
-
+    private CommonStats commonStats;
     @Nullable
-    CommitStats commitStats;
+    private CommitStats commitStats;
+    private String dataPath;
+    private String statePath;
+    private boolean isCustomDataPath;
 
     ShardStats() {
     }
 
-    public ShardStats(IndexShard indexShard, ShardRouting shardRouting, CommonStatsFlags flags) {
+    public ShardStats(IndexShard indexShard, CommonStatsFlags flags) {
         super(indexShard.shardId());
-        this.shardRouting = shardRouting;
+        this.shardRouting = indexShard.routingEntry();
+        this.dataPath = indexShard.shardPath().getRootDataPath().toString();
+        this.statePath = indexShard.shardPath().getRootStatePath().toString();
+        this.isCustomDataPath = indexShard.shardPath().isCustomDataPath();
         this.commonStats = new CommonStats(indexShard, flags);
         this.commitStats = indexShard.commitStats();
     }
@@ -70,6 +74,18 @@ public class ShardStats extends BroadcastShardResponse implements ToXContent {
         return this.commitStats;
     }
 
+    public String getDataPath() {
+        return dataPath;
+    }
+
+    public String getStatePath() {
+        return statePath;
+    }
+
+    public boolean isCustomDataPath() {
+        return isCustomDataPath;
+    }
+
     public static ShardStats readShardStats(StreamInput in) throws IOException {
         ShardStats stats = new ShardStats();
         stats.readFrom(in);
@@ -82,6 +98,9 @@ public class ShardStats extends BroadcastShardResponse implements ToXContent {
         shardRouting = readShardRoutingEntry(in);
         commonStats = CommonStats.readCommonStats(in);
         commitStats = CommitStats.readOptionalCommitStatsFrom(in);
+        statePath = in.readString();
+        dataPath = in.readString();
+        isCustomDataPath = in.readBoolean();
     }
 
     @Override
@@ -90,6 +109,9 @@ public class ShardStats extends BroadcastShardResponse implements ToXContent {
         shardRouting.writeTo(out);
         commonStats.writeTo(out);
         out.writeOptionalStreamable(commitStats);
+        out.writeString(statePath);
+        out.writeString(dataPath);
+        out.writeBoolean(isCustomDataPath);
     }
 
     @Override
@@ -105,12 +127,21 @@ public class ShardStats extends BroadcastShardResponse implements ToXContent {
         if (commitStats != null) {
             commitStats.toXContent(builder, params);
         }
+        builder.startObject(Fields.SHARD_PATH);
+        builder.field(Fields.STATE_PATH, statePath);
+        builder.field(Fields.DATA_PATH, dataPath);
+        builder.field(Fields.IS_CUSTOM_DATA_PATH, isCustomDataPath);
+        builder.endObject();
         return builder;
     }
 
     static final class Fields {
         static final XContentBuilderString ROUTING = new XContentBuilderString("routing");
         static final XContentBuilderString STATE = new XContentBuilderString("state");
+        static final XContentBuilderString STATE_PATH = new XContentBuilderString("state_path");
+        static final XContentBuilderString DATA_PATH = new XContentBuilderString("data_path");
+        static final XContentBuilderString IS_CUSTOM_DATA_PATH = new XContentBuilderString("is_custom_data_path");
+        static final XContentBuilderString SHARD_PATH = new XContentBuilderString("shard_path");
         static final XContentBuilderString PRIMARY = new XContentBuilderString("primary");
         static final XContentBuilderString NODE = new XContentBuilderString("node");
         static final XContentBuilderString RELOCATING_NODE = new XContentBuilderString("relocating_node");
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java
index b298cdf..9ce5291 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.admin.indices.stats;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.action.ShardOperationFailedException;
 import org.elasticsearch.action.support.ActionFilters;
 import org.elasticsearch.action.support.DefaultShardOperationFailedException;
@@ -46,11 +45,10 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  */
 public class TransportIndicesStatsAction extends TransportBroadcastAction<IndicesStatsRequest, IndicesStatsResponse, TransportIndicesStatsAction.IndexShardStatsRequest, ShardStats> {
@@ -90,7 +88,7 @@ public class TransportIndicesStatsAction extends TransportBroadcastAction<Indice
         int successfulShards = 0;
         int failedShards = 0;
         List<ShardOperationFailedException> shardFailures = null;
-        final List<ShardStats> shards = Lists.newArrayList();
+        final List<ShardStats> shards = new ArrayList<>();
         for (int i = 0; i < shardsResponses.length(); i++) {
             Object shardResponse = shardsResponses.get(i);
             if (shardResponse == null) {
@@ -98,7 +96,7 @@ public class TransportIndicesStatsAction extends TransportBroadcastAction<Indice
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
@@ -189,7 +187,7 @@ public class TransportIndicesStatsAction extends TransportBroadcastAction<Indice
             flags.set(CommonStatsFlags.Flag.Recovery);
         }
 
-        return new ShardStats(indexShard, indexShard.routingEntry(), flags);
+        return new ShardStats(indexShard, flags);
     }
 
     static class IndexShardStatsRequest extends BroadcastShardRequest {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/template/get/GetIndexTemplatesResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/template/get/GetIndexTemplatesResponse.java
index 2ce6d8d..dfe9985 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/template/get/GetIndexTemplatesResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/template/get/GetIndexTemplatesResponse.java
@@ -18,13 +18,13 @@
  */
 package org.elasticsearch.action.admin.indices.template.get;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.action.ActionResponse;
 import org.elasticsearch.cluster.metadata.IndexTemplateMetaData;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -49,7 +49,7 @@ public class GetIndexTemplatesResponse extends ActionResponse {
     public void readFrom(StreamInput in) throws IOException {
         super.readFrom(in);
         int size = in.readVInt();
-        indexTemplates = Lists.newArrayListWithExpectedSize(size);
+        indexTemplates = new ArrayList<>(size);
         for (int i = 0 ; i < size ; i++) {
             indexTemplates.add(0, IndexTemplateMetaData.Builder.readFrom(in));
         }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/template/get/TransportGetIndexTemplatesAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/template/get/TransportGetIndexTemplatesAction.java
index f5f33c6..23f2399 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/template/get/TransportGetIndexTemplatesAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/template/get/TransportGetIndexTemplatesAction.java
@@ -19,7 +19,6 @@
 package org.elasticsearch.action.admin.indices.template.get;
 
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-import com.google.common.collect.Lists;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.ActionFilters;
 import org.elasticsearch.action.support.master.TransportMasterNodeReadAction;
@@ -35,6 +34,8 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.List;
 
 /**
@@ -69,9 +70,9 @@ public class TransportGetIndexTemplatesAction extends TransportMasterNodeReadAct
 
         // If we did not ask for a specific name, then we return all templates
         if (request.names().length == 0) {
-            results = Lists.newArrayList(state.metaData().templates().values().toArray(IndexTemplateMetaData.class));
+            results = Arrays.asList(state.metaData().templates().values().toArray(IndexTemplateMetaData.class));
         } else {
-            results = Lists.newArrayList();
+            results = new ArrayList<>();
         }
 
         for (String name : request.names()) {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/IndexUpgradeStatus.java b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/IndexUpgradeStatus.java
index 33a6032..b85359c 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/IndexUpgradeStatus.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/IndexUpgradeStatus.java
@@ -19,9 +19,9 @@
 
 package org.elasticsearch.action.admin.indices.upgrade.get;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
@@ -39,7 +39,7 @@ public class IndexUpgradeStatus implements Iterable<IndexShardUpgradeStatus> {
         for (ShardUpgradeStatus shard : shards) {
             List<ShardUpgradeStatus> lst = tmpIndexShards.get(shard.getShardRouting().id());
             if (lst == null) {
-                lst = Lists.newArrayList();
+                lst = new ArrayList<>();
                 tmpIndexShards.put(shard.getShardRouting().id(), lst);
             }
             lst.add(shard);
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/TransportUpgradeStatusAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/TransportUpgradeStatusAction.java
index a169bc4..72cc227 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/TransportUpgradeStatusAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/TransportUpgradeStatusAction.java
@@ -43,11 +43,10 @@ import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  *
  */
@@ -86,7 +85,7 @@ public class TransportUpgradeStatusAction extends TransportBroadcastAction<Upgra
         int successfulShards = 0;
         int failedShards = 0;
         List<ShardOperationFailedException> shardFailures = null;
-        final List<ShardUpgradeStatus> shards = newArrayList();
+        final List<ShardUpgradeStatus> shards = new ArrayList<>();
         for (int i = 0; i < shardsResponses.length(); i++) {
             Object shardResponse = shardsResponses.get(i);
             if (shardResponse == null) {
@@ -94,7 +93,7 @@ public class TransportUpgradeStatusAction extends TransportBroadcastAction<Upgra
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/UpgradeStatusResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/UpgradeStatusResponse.java
index 8952070..16e24ee 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/UpgradeStatusResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/UpgradeStatusResponse.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.admin.indices.upgrade.get;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 import org.elasticsearch.action.ShardOperationFailedException;
@@ -31,6 +30,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentBuilderString;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -63,7 +63,7 @@ public class UpgradeStatusResponse extends BroadcastResponse implements ToXConte
         }
 
         for (String index : indices) {
-            List<ShardUpgradeStatus> shards = Lists.newArrayList();
+            List<ShardUpgradeStatus> shards = new ArrayList<>();
             for (ShardUpgradeStatus shard : this.shards) {
                 if (shard.getShardRouting().index().equals(index)) {
                     shards.add(shard);
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
index 39a7360..23d40a5 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
@@ -33,7 +33,10 @@ import org.elasticsearch.cluster.block.ClusterBlockException;
 import org.elasticsearch.cluster.block.ClusterBlockLevel;
 import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
 import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.cluster.routing.*;
+import org.elasticsearch.cluster.routing.GroupShardsIterator;
+import org.elasticsearch.cluster.routing.IndexRoutingTable;
+import org.elasticsearch.cluster.routing.RoutingTable;
+import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
@@ -42,12 +45,12 @@ import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.newHashMap;
 import static com.google.common.collect.Sets.newHashSet;
 
@@ -84,7 +87,7 @@ public class TransportUpgradeAction extends TransportBroadcastAction<UpgradeRequ
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
index af44093..6fefa0d 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
@@ -42,7 +42,6 @@ import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.query.IndexQueryParserService;
-import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.indices.IndicesService;
@@ -55,14 +54,13 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ThreadLocalRandom;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  *
  */
@@ -137,7 +135,7 @@ public class TransportValidateQueryAction extends TransportBroadcastAction<Valid
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
@@ -145,7 +143,7 @@ public class TransportValidateQueryAction extends TransportBroadcastAction<Valid
                 valid = valid && validateQueryResponse.isValid();
                 if (request.explain() || request.rewrite()) {
                     if (queryExplanations == null) {
-                        queryExplanations = newArrayList();
+                        queryExplanations = new ArrayList<>();
                     }
                     queryExplanations.add(new QueryExplanation(
                             validateQueryResponse.getIndex(),
@@ -190,15 +188,15 @@ public class TransportValidateQueryAction extends TransportBroadcastAction<Valid
             }
             if (request.rewrite()) {
                 explanation = getRewrittenQuery(searcher.searcher(), searchContext.query());
-            }
-        } catch (QueryShardException|QueryParsingException e) {
+            }   
+        } catch (QueryParsingException e) {
             valid = false;
             error = e.getDetailedMessage();
         } catch (AssertionError|IOException e) {
             valid = false;
             error = e.getMessage();
         } finally {
-            SearchContext.current().close();
+            searchContext.close();
             SearchContext.removeCurrent();
         }
 
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java
index 515ecd1..4acdfdc 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.action.admin.indices.validate.query;
 
+import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.QuerySourceBuilder;
 import org.elasticsearch.action.support.broadcast.BroadcastOperationRequestBuilder;
 import org.elasticsearch.client.ElasticsearchClient;
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/delete/TransportDeleteWarmerAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/delete/TransportDeleteWarmerAction.java
index 54a0c4d..8df668d 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/delete/TransportDeleteWarmerAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/delete/TransportDeleteWarmerAction.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.action.admin.indices.warmer.delete;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.ActionFilters;
 import org.elasticsearch.action.support.master.TransportMasterNodeAction;
@@ -39,6 +38,7 @@ import org.elasticsearch.search.warmer.IndexWarmersMetaData;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 
@@ -92,6 +92,14 @@ public class TransportDeleteWarmerAction extends TransportMasterNodeAction<Delet
                 MetaData.Builder mdBuilder = MetaData.builder(currentState.metaData());
 
                 boolean globalFoundAtLeastOne = false;
+                boolean deleteAll = false;
+                for (int i=0; i<request.names().length; i++){
+                    if (request.names()[i].equals(MetaData.ALL)) {
+                        deleteAll = true;
+                        break;
+                    }
+                }
+
                 for (String index : concreteIndices) {
                     IndexMetaData indexMetaData = currentState.metaData().index(index);
                     if (indexMetaData == null) {
@@ -99,11 +107,11 @@ public class TransportDeleteWarmerAction extends TransportMasterNodeAction<Delet
                     }
                     IndexWarmersMetaData warmers = indexMetaData.custom(IndexWarmersMetaData.TYPE);
                     if (warmers != null) {
-                        List<IndexWarmersMetaData.Entry> entries = Lists.newArrayList();
+                        List<IndexWarmersMetaData.Entry> entries = new ArrayList<>();
                         for (IndexWarmersMetaData.Entry entry : warmers.entries()) {
                             boolean keepWarmer = true;
                             for (String warmer : request.names()) {
-                                if (Regex.simpleMatch(warmer, entry.name()) || warmer.equals("_all")) {
+                                if (Regex.simpleMatch(warmer, entry.name()) || warmer.equals(MetaData.ALL)) {
                                     globalFoundAtLeastOne = true;
                                     keepWarmer =  false;
                                     // don't add it...
@@ -123,7 +131,7 @@ public class TransportDeleteWarmerAction extends TransportMasterNodeAction<Delet
                     }
                 }
 
-                if (!globalFoundAtLeastOne) {
+                if (globalFoundAtLeastOne == false && deleteAll == false) {
                     throw new IndexWarmerMissingException(request.names());
                 }
 
@@ -137,11 +145,13 @@ public class TransportDeleteWarmerAction extends TransportMasterNodeAction<Delet
                         if (warmers != null) {
                             for (IndexWarmersMetaData.Entry entry : warmers.entries()) {
                                 for (String warmer : request.names()) {
-                                    if (Regex.simpleMatch(warmer, entry.name()) || warmer.equals("_all")) {
+                                    if (Regex.simpleMatch(warmer, entry.name()) || warmer.equals(MetaData.ALL)) {
                                         logger.info("[{}] delete warmer [{}]", index, entry.name());
                                     }
                                 }
                             }
+                        } else if(deleteAll){
+                            logger.debug("no warmers to delete on index [{}]", index);
                         }
                     }
                 }
diff --git a/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java b/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java
index 79abded..9a8419f 100644
--- a/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/bulk/BulkRequest.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.action.bulk;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.action.ActionRequest;
 import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.CompositeIndicesRequest;
@@ -57,7 +55,7 @@ public class BulkRequest extends ActionRequest<BulkRequest> implements Composite
 
     private static final int REQUEST_OVERHEAD = 50;
 
-    final List<ActionRequest> requests = Lists.newArrayList();
+    final List<ActionRequest> requests = new ArrayList<>();
     List<Object> payloads = null;
 
     protected TimeValue timeout = BulkShardRequest.DEFAULT_TIMEOUT;
@@ -186,7 +184,7 @@ public class BulkRequest extends ActionRequest<BulkRequest> implements Composite
     @Override
     @SuppressWarnings("unchecked")
     public List<? extends IndicesRequest> subRequests() {
-        List<IndicesRequest> indicesRequests = Lists.newArrayList();
+        List<IndicesRequest> indicesRequests = new ArrayList<>();
         for (ActionRequest request : requests) {
             assert request instanceof IndicesRequest;
             indicesRequests.add((IndicesRequest) request);
diff --git a/core/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java b/core/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java
index 07427ac..fd78241 100644
--- a/core/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java
+++ b/core/src/main/java/org/elasticsearch/action/bulk/TransportBulkAction.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.bulk;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.ElasticsearchParseException;
@@ -57,7 +56,13 @@ import org.elasticsearch.indices.IndexClosedException;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Set;
 import java.util.concurrent.atomic.AtomicInteger;
 
 /**
@@ -251,7 +256,7 @@ public class TransportBulkAction extends HandledTransportAction<BulkRequest, Bul
                 ShardId shardId = clusterService.operationRouting().indexShards(clusterState, concreteIndex, indexRequest.type(), indexRequest.id(), indexRequest.routing()).shardId();
                 List<BulkItemRequest> list = requestsByShard.get(shardId);
                 if (list == null) {
-                    list = Lists.newArrayList();
+                    list = new ArrayList<>();
                     requestsByShard.put(shardId, list);
                 }
                 list.add(new BulkItemRequest(i, request));
@@ -265,7 +270,7 @@ public class TransportBulkAction extends HandledTransportAction<BulkRequest, Bul
                     for (ShardIterator shardIt : groupShards) {
                         List<BulkItemRequest> list = requestsByShard.get(shardIt.shardId());
                         if (list == null) {
-                            list = Lists.newArrayList();
+                            list = new ArrayList<>();
                             requestsByShard.put(shardIt.shardId(), list);
                         }
                         list.add(new BulkItemRequest(i, new DeleteRequest(deleteRequest)));
@@ -274,7 +279,7 @@ public class TransportBulkAction extends HandledTransportAction<BulkRequest, Bul
                     ShardId shardId = clusterService.operationRouting().deleteShards(clusterState, concreteIndex, deleteRequest.type(), deleteRequest.id(), deleteRequest.routing()).shardId();
                     List<BulkItemRequest> list = requestsByShard.get(shardId);
                     if (list == null) {
-                        list = Lists.newArrayList();
+                        list = new ArrayList<>();
                         requestsByShard.put(shardId, list);
                     }
                     list.add(new BulkItemRequest(i, request));
@@ -292,7 +297,7 @@ public class TransportBulkAction extends HandledTransportAction<BulkRequest, Bul
                 ShardId shardId = clusterService.operationRouting().indexShards(clusterState, concreteIndex, updateRequest.type(), updateRequest.id(), updateRequest.routing()).shardId();
                 List<BulkItemRequest> list = requestsByShard.get(shardId);
                 if (list == null) {
-                    list = Lists.newArrayList();
+                    list = new ArrayList<>();
                     requestsByShard.put(shardId, list);
                 }
                 list.add(new BulkItemRequest(i, request));
diff --git a/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java b/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
index fa2fd31..d9c89e7 100644
--- a/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
@@ -41,7 +41,7 @@ import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.IndexService;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.script.ScriptService;
@@ -54,13 +54,13 @@ import org.elasticsearch.search.query.QueryPhaseExecutionException;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.action.exists.ExistsRequest.DEFAULT_MIN_SCORE;
 
 public class TransportExistsAction extends TransportBroadcastAction<ExistsRequest, ExistsResponse, ShardExistsRequest, ShardExistsResponse> {
@@ -131,7 +131,7 @@ public class TransportExistsAction extends TransportBroadcastAction<ExistsReques
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
@@ -166,17 +166,16 @@ public class TransportExistsAction extends TransportBroadcastAction<ExistsReques
             BytesReference source = request.querySource();
             if (source != null && source.length() > 0) {
                 try {
-                    QueryShardContext.setTypes(request.types());
+                    QueryParseContext.setTypes(request.types());
                     context.parsedQuery(indexService.queryParserService().parseQuery(source));
                 } finally {
-                    QueryShardContext.removeTypes();
+                    QueryParseContext.removeTypes();
                 }
             }
             context.preProcess();
             try {
-                Lucene.EarlyTerminatingCollector existsCollector = Lucene.createExistsCollector();
-                Lucene.exists(context.searcher(), context.query(), existsCollector);
-                return new ShardExistsResponse(request.shardId(), existsCollector.exists());
+                boolean exists = Lucene.exists(context, context.query(), Lucene.createExistsCollector());
+                return new ShardExistsResponse(request.shardId(), exists);
             } catch (Exception e) {
                 throw new QueryPhaseExecutionException(context, "failed to execute exists", e);
             }
diff --git a/core/src/main/java/org/elasticsearch/action/percolate/MultiPercolateRequest.java b/core/src/main/java/org/elasticsearch/action/percolate/MultiPercolateRequest.java
index 2778e03..7453737 100644
--- a/core/src/main/java/org/elasticsearch/action/percolate/MultiPercolateRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/percolate/MultiPercolateRequest.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.action.percolate;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.action.ActionRequest;
 import org.elasticsearch.action.ActionRequestValidationException;
@@ -35,6 +34,7 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -50,7 +50,7 @@ public class MultiPercolateRequest extends ActionRequest<MultiPercolateRequest>
     private String[] indices;
     private String documentType;
     private IndicesOptions indicesOptions = IndicesOptions.strictExpandOpenAndForbidClosed();
-    private List<PercolateRequest> requests = Lists.newArrayList();
+    private List<PercolateRequest> requests = new ArrayList<>();
 
     /**
      * Embeds a percolate request to this multi percolate request
@@ -163,7 +163,7 @@ public class MultiPercolateRequest extends ActionRequest<MultiPercolateRequest>
 
     @Override
     public List<? extends IndicesRequest> subRequests() {
-        List<IndicesRequest> indicesRequests = Lists.newArrayList();
+        List<IndicesRequest> indicesRequests = new ArrayList<>();
         for (PercolateRequest percolateRequest : this.requests) {
             indicesRequests.addAll(percolateRequest.subRequests());
         }
diff --git a/core/src/main/java/org/elasticsearch/action/percolate/PercolateRequest.java b/core/src/main/java/org/elasticsearch/action/percolate/PercolateRequest.java
index 9c9a385..47f39ce 100644
--- a/core/src/main/java/org/elasticsearch/action/percolate/PercolateRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/percolate/PercolateRequest.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.action.percolate;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchGenerationException;
 import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.CompositeIndicesRequest;
@@ -35,6 +34,7 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentType;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -79,7 +79,7 @@ public class PercolateRequest extends BroadcastRequest<PercolateRequest> impleme
 
     @Override
     public List<? extends IndicesRequest> subRequests() {
-        List<IndicesRequest> requests = Lists.newArrayList();
+        List<IndicesRequest> requests = new ArrayList<>();
         requests.add(this);
         if (getRequest != null) {
             requests.add(getRequest);
diff --git a/core/src/main/java/org/elasticsearch/action/percolate/PercolateSourceBuilder.java b/core/src/main/java/org/elasticsearch/action/percolate/PercolateSourceBuilder.java
index af8aa43..967d5a0 100644
--- a/core/src/main/java/org/elasticsearch/action/percolate/PercolateSourceBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/percolate/PercolateSourceBuilder.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.action.percolate;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.ElasticsearchGenerationException;
 import org.elasticsearch.action.support.ToXContentToBytes;
 import org.elasticsearch.client.Requests;
@@ -38,6 +36,7 @@ import org.elasticsearch.search.sort.ScoreSortBuilder;
 import org.elasticsearch.search.sort.SortBuilder;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
@@ -99,7 +98,7 @@ public class PercolateSourceBuilder extends ToXContentToBytes {
      */
     public PercolateSourceBuilder addSort(SortBuilder sort) {
         if (sorts == null) {
-            sorts = Lists.newArrayList();
+            sorts = new ArrayList<>();
         }
         sorts.add(sort);
         return this;
@@ -127,7 +126,7 @@ public class PercolateSourceBuilder extends ToXContentToBytes {
      */
     public PercolateSourceBuilder addAggregation(AbstractAggregationBuilder aggregationBuilder) {
         if (aggregations == null) {
-            aggregations = Lists.newArrayList();
+            aggregations = new ArrayList<>();
         }
         aggregations.add(aggregationBuilder);
         return this;
diff --git a/core/src/main/java/org/elasticsearch/action/percolate/TransportPercolateAction.java b/core/src/main/java/org/elasticsearch/action/percolate/TransportPercolateAction.java
index bb160f8..2194975 100644
--- a/core/src/main/java/org/elasticsearch/action/percolate/TransportPercolateAction.java
+++ b/core/src/main/java/org/elasticsearch/action/percolate/TransportPercolateAction.java
@@ -43,13 +43,12 @@ import org.elasticsearch.percolator.PercolatorService;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  *
  */
@@ -126,7 +125,7 @@ public class TransportPercolateAction extends TransportBroadcastAction<Percolate
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
@@ -135,7 +134,7 @@ public class TransportPercolateAction extends TransportBroadcastAction<Percolate
                 if (!percolateShardResponse.isEmpty()) {
                     if (shardResults == null) {
                         percolatorTypeId = percolateShardResponse.percolatorTypeId();
-                        shardResults = newArrayList();
+                        shardResults = new ArrayList<>();
                     }
                     shardResults.add(percolateShardResponse);
                 }
diff --git a/core/src/main/java/org/elasticsearch/action/search/ClearScrollRequest.java b/core/src/main/java/org/elasticsearch/action/search/ClearScrollRequest.java
index 4ffd5e2..17343e8 100644
--- a/core/src/main/java/org/elasticsearch/action/search/ClearScrollRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/search/ClearScrollRequest.java
@@ -25,10 +25,10 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.action.ValidateActions.addValidationError;
 
 /**
@@ -47,7 +47,7 @@ public class ClearScrollRequest extends ActionRequest<ClearScrollRequest> {
 
     public void addScrollId(String scrollId) {
         if (scrollIds == null) {
-            scrollIds = newArrayList();
+            scrollIds = new ArrayList<>();
         }
         scrollIds.add(scrollId);
     }
diff --git a/core/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java b/core/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java
index 06e7d03..df2e242 100644
--- a/core/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.action.search;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.action.ActionRequest;
 import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.CompositeIndicesRequest;
@@ -41,16 +39,14 @@ import java.util.List;
 import java.util.Map;
 
 import static org.elasticsearch.action.ValidateActions.addValidationError;
-import static org.elasticsearch.common.xcontent.support.XContentMapValues.nodeBooleanValue;
-import static org.elasticsearch.common.xcontent.support.XContentMapValues.nodeStringArrayValue;
-import static org.elasticsearch.common.xcontent.support.XContentMapValues.nodeStringValue;
+import static org.elasticsearch.common.xcontent.support.XContentMapValues.*;
 
 /**
  * A multi search API request.
  */
 public class MultiSearchRequest extends ActionRequest<MultiSearchRequest> implements CompositeIndicesRequest {
 
-    private List<SearchRequest> requests = Lists.newArrayList();
+    private List<SearchRequest> requests = new ArrayList<>();
 
     private IndicesOptions indicesOptions = IndicesOptions.strictExpandOpenAndForbidClosed();
 
diff --git a/core/src/main/java/org/elasticsearch/action/search/TransportClearScrollAction.java b/core/src/main/java/org/elasticsearch/action/search/TransportClearScrollAction.java
index 78410a1..8e49f45 100644
--- a/core/src/main/java/org/elasticsearch/action/search/TransportClearScrollAction.java
+++ b/core/src/main/java/org/elasticsearch/action/search/TransportClearScrollAction.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.action.search;
 
 import org.elasticsearch.action.ActionListener;
+import org.elasticsearch.action.search.type.ScrollIdForNode;
 import org.elasticsearch.action.support.ActionFilters;
 import org.elasticsearch.action.support.HandledTransportAction;
 import org.elasticsearch.cluster.ClusterService;
@@ -27,7 +28,6 @@ import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.util.concurrent.CountDown;
@@ -69,7 +69,7 @@ public class TransportClearScrollAction extends HandledTransportAction<ClearScro
         final DiscoveryNodes nodes;
         final CountDown expectedOps;
         final ClearScrollRequest request;
-        final List<Tuple<String, Long>[]> contexts = new ArrayList<>();
+        final List<ScrollIdForNode[]> contexts = new ArrayList<>();
         final ActionListener<ClearScrollResponse> listener;
         final AtomicReference<Throwable> expHolder;
         final AtomicInteger numberOfFreedSearchContexts = new AtomicInteger(0);
@@ -81,7 +81,7 @@ public class TransportClearScrollAction extends HandledTransportAction<ClearScro
                 expectedOps = nodes.size();
             } else {
                 for (String parsedScrollId : request.getScrollIds()) {
-                    Tuple<String, Long>[] context = parseScrollId(parsedScrollId).getContext();
+                    ScrollIdForNode[] context = parseScrollId(parsedScrollId).getContext();
                     expectedOps += context.length;
                     this.contexts.add(context);
                 }
@@ -114,15 +114,15 @@ public class TransportClearScrollAction extends HandledTransportAction<ClearScro
                     });
                 }
             } else {
-                for (Tuple<String, Long>[] context : contexts) {
-                    for (Tuple<String, Long> target : context) {
-                        final DiscoveryNode node = nodes.get(target.v1());
+                for (ScrollIdForNode[] context : contexts) {
+                    for (ScrollIdForNode target : context) {
+                        final DiscoveryNode node = nodes.get(target.getNode());
                         if (node == null) {
                             onFreedContext(false);
                             continue;
                         }
 
-                        searchServiceTransportAction.sendFreeContext(node, target.v2(), request, new ActionListener<SearchServiceTransportAction.SearchFreeContextResponse>() {
+                        searchServiceTransportAction.sendFreeContext(node, target.getScrollId(), request, new ActionListener<SearchServiceTransportAction.SearchFreeContextResponse>() {
                             @Override
                             public void onResponse(SearchServiceTransportAction.SearchFreeContextResponse freed) {
                                 onFreedContext(freed.isFreed());
diff --git a/core/src/main/java/org/elasticsearch/action/search/type/ParsedScrollId.java b/core/src/main/java/org/elasticsearch/action/search/type/ParsedScrollId.java
index 57d5a03..222727d 100644
--- a/core/src/main/java/org/elasticsearch/action/search/type/ParsedScrollId.java
+++ b/core/src/main/java/org/elasticsearch/action/search/type/ParsedScrollId.java
@@ -19,9 +19,6 @@
 
 package org.elasticsearch.action.search.type;
 
-import org.elasticsearch.Version;
-import org.elasticsearch.common.collect.Tuple;
-
 import java.util.Map;
 
 /**
@@ -39,11 +36,11 @@ public class ParsedScrollId {
 
     private final String type;
 
-    private final Tuple<String, Long>[] context;
+    private final ScrollIdForNode[] context;
 
     private final Map<String, String> attributes;
 
-    public ParsedScrollId(String source, String type, Tuple<String, Long>[] context, Map<String, String> attributes) {
+    public ParsedScrollId(String source, String type, ScrollIdForNode[] context, Map<String, String> attributes) {
         this.source = source;
         this.type = type;
         this.context = context;
@@ -58,7 +55,7 @@ public class ParsedScrollId {
         return type;
     }
 
-    public Tuple<String, Long>[] getContext() {
+    public ScrollIdForNode[] getContext() {
         return context;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/action/search/type/ScrollIdForNode.java b/core/src/main/java/org/elasticsearch/action/search/type/ScrollIdForNode.java
new file mode 100644
index 0000000..38c79c9
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/action/search/type/ScrollIdForNode.java
@@ -0,0 +1,38 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.action.search.type;
+
+public class ScrollIdForNode {
+    private final String node;
+    private final long scrollId;
+
+    public ScrollIdForNode(String node, long scrollId) {
+        this.node = node;
+        this.scrollId = scrollId;
+    }
+
+    public String getNode() {
+        return node;
+    }
+
+    public long getScrollId() {
+        return scrollId;
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java b/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java
index 0f8da3a..bb9e858 100644
--- a/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java
+++ b/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java
@@ -30,7 +30,6 @@ import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.common.Base64;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.util.concurrent.AtomicArray;
 import org.elasticsearch.search.SearchPhaseResult;
 import org.elasticsearch.search.internal.InternalScrollSearchRequest;
@@ -103,14 +102,14 @@ public abstract class TransportSearchHelper {
             throw new IllegalArgumentException("Malformed scrollId [" + scrollId + "]");
         }
 
-        @SuppressWarnings({"unchecked"}) Tuple<String, Long>[] context = new Tuple[contextSize];
+        ScrollIdForNode[] context = new ScrollIdForNode[contextSize];
         for (int i = 0; i < contextSize; i++) {
             String element = elements[index++];
             int sep = element.indexOf(':');
             if (sep == -1) {
                 throw new IllegalArgumentException("Malformed scrollId [" + scrollId + "]");
             }
-            context[i] = new Tuple<>(element.substring(sep + 1), Long.parseLong(element.substring(0, sep)));
+            context[i] = new ScrollIdForNode(element.substring(sep + 1), Long.parseLong(element.substring(0, sep)));
         }
         Map<String, String> attributes;
         int attributesSize = Integer.parseInt(elements[index++]);
diff --git a/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollQueryAndFetchAction.java b/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollQueryAndFetchAction.java
index 1683a6b..bb2c82d 100644
--- a/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollQueryAndFetchAction.java
+++ b/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollQueryAndFetchAction.java
@@ -25,7 +25,6 @@ import org.elasticsearch.action.search.*;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
@@ -115,15 +114,15 @@ public class TransportSearchScrollQueryAndFetchAction extends AbstractComponent
                 return;
             }
 
-            Tuple<String, Long>[] context = scrollId.getContext();
+            ScrollIdForNode[] context = scrollId.getContext();
             for (int i = 0; i < context.length; i++) {
-                Tuple<String, Long> target = context[i];
-                DiscoveryNode node = nodes.get(target.v1());
+                ScrollIdForNode target = context[i];
+                DiscoveryNode node = nodes.get(target.getNode());
                 if (node != null) {
-                    executePhase(i, node, target.v2());
+                    executePhase(i, node, target.getScrollId());
                 } else {
                     if (logger.isDebugEnabled()) {
-                        logger.debug("Node [" + target.v1() + "] not available for scroll request [" + scrollId.getSource() + "]");
+                        logger.debug("Node [" + target.getNode() + "] not available for scroll request [" + scrollId.getSource() + "]");
                     }
                     successfulOps.decrementAndGet();
                     if (counter.decrementAndGet() == 0) {
@@ -132,11 +131,11 @@ public class TransportSearchScrollQueryAndFetchAction extends AbstractComponent
                 }
             }
 
-            for (Tuple<String, Long> target : scrollId.getContext()) {
-                DiscoveryNode node = nodes.get(target.v1());
+            for (ScrollIdForNode target : scrollId.getContext()) {
+                DiscoveryNode node = nodes.get(target.getNode());
                 if (node == null) {
                     if (logger.isDebugEnabled()) {
-                        logger.debug("Node [" + target.v1() + "] not available for scroll request [" + scrollId.getSource() + "]");
+                        logger.debug("Node [" + target.getNode() + "] not available for scroll request [" + scrollId.getSource() + "]");
                     }
                     successfulOps.decrementAndGet();
                     if (counter.decrementAndGet() == 0) {
diff --git a/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollQueryThenFetchAction.java b/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollQueryThenFetchAction.java
index 84d631e..9c77426 100644
--- a/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollQueryThenFetchAction.java
+++ b/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollQueryThenFetchAction.java
@@ -26,7 +26,6 @@ import org.elasticsearch.action.search.*;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
@@ -124,15 +123,15 @@ public class TransportSearchScrollQueryThenFetchAction extends AbstractComponent
             }
             final AtomicInteger counter = new AtomicInteger(scrollId.getContext().length);
 
-            Tuple<String, Long>[] context = scrollId.getContext();
+            ScrollIdForNode[] context = scrollId.getContext();
             for (int i = 0; i < context.length; i++) {
-                Tuple<String, Long> target = context[i];
-                DiscoveryNode node = nodes.get(target.v1());
+                ScrollIdForNode target = context[i];
+                DiscoveryNode node = nodes.get(target.getNode());
                 if (node != null) {
-                    executeQueryPhase(i, counter, node, target.v2());
+                    executeQueryPhase(i, counter, node, target.getScrollId());
                 } else {
                     if (logger.isDebugEnabled()) {
-                        logger.debug("Node [" + target.v1() + "] not available for scroll request [" + scrollId.getSource() + "]");
+                        logger.debug("Node [" + target.getNode() + "] not available for scroll request [" + scrollId.getSource() + "]");
                     }
                     successfulOps.decrementAndGet();
                     if (counter.decrementAndGet() == 0) {
diff --git a/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollScanAction.java b/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollScanAction.java
index 0be39ab..16ab26f 100644
--- a/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollScanAction.java
+++ b/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollScanAction.java
@@ -28,7 +28,6 @@ import org.elasticsearch.action.search.ShardSearchFailure;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
@@ -125,15 +124,15 @@ public class TransportSearchScrollScanAction extends AbstractComponent {
                 return;
             }
 
-            Tuple<String, Long>[] context = scrollId.getContext();
+            ScrollIdForNode[] context = scrollId.getContext();
             for (int i = 0; i < context.length; i++) {
-                Tuple<String, Long> target = context[i];
-                DiscoveryNode node = nodes.get(target.v1());
+                ScrollIdForNode target = context[i];
+                DiscoveryNode node = nodes.get(target.getNode());
                 if (node != null) {
-                    executePhase(i, node, target.v2());
+                    executePhase(i, node, target.getScrollId());
                 } else {
                     if (logger.isDebugEnabled()) {
-                        logger.debug("Node [" + target.v1() + "] not available for scroll request [" + scrollId.getSource() + "]");
+                        logger.debug("Node [" + target.getScrollId() + "] not available for scroll request [" + scrollId.getSource() + "]");
                     }
                     successfulOps.decrementAndGet();
                     if (counter.decrementAndGet() == 0) {
@@ -142,11 +141,11 @@ public class TransportSearchScrollScanAction extends AbstractComponent {
                 }
             }
 
-            for (Tuple<String, Long> target : scrollId.getContext()) {
-                DiscoveryNode node = nodes.get(target.v1());
+            for (ScrollIdForNode target : scrollId.getContext()) {
+                DiscoveryNode node = nodes.get(target.getNode());
                 if (node == null) {
                     if (logger.isDebugEnabled()) {
-                        logger.debug("Node [" + target.v1() + "] not available for scroll request [" + scrollId.getSource() + "]");
+                        logger.debug("Node [" + target.getNode() + "] not available for scroll request [" + scrollId.getSource() + "]");
                     }
                     successfulOps.decrementAndGet();
                     if (counter.decrementAndGet() == 0) {
diff --git a/core/src/main/java/org/elasticsearch/action/suggest/TransportSuggestAction.java b/core/src/main/java/org/elasticsearch/action/suggest/TransportSuggestAction.java
index 2269856..c584c88 100644
--- a/core/src/main/java/org/elasticsearch/action/suggest/TransportSuggestAction.java
+++ b/core/src/main/java/org/elasticsearch/action/suggest/TransportSuggestAction.java
@@ -48,14 +48,13 @@ import org.elasticsearch.search.suggest.SuggestionSearchContext;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * Defines the transport of a suggestion request across the cluster
  */
@@ -115,7 +114,7 @@ public class TransportSuggestAction extends TransportBroadcastAction<SuggestRequ
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
diff --git a/core/src/main/java/org/elasticsearch/action/support/AbstractListenableActionFuture.java b/core/src/main/java/org/elasticsearch/action/support/AbstractListenableActionFuture.java
index 7d4497d..790689b 100644
--- a/core/src/main/java/org/elasticsearch/action/support/AbstractListenableActionFuture.java
+++ b/core/src/main/java/org/elasticsearch/action/support/AbstractListenableActionFuture.java
@@ -19,13 +19,13 @@
 
 package org.elasticsearch.action.support;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.ListenableActionFuture;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.threadpool.ThreadPool;
 
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -66,7 +66,7 @@ public abstract class AbstractListenableActionFuture<T, L> extends AdapterAction
                     ((List) this.listeners).add(listener);
                 } else {
                     Object orig = listeners;
-                    listeners = Lists.newArrayListWithCapacity(2);
+                    listeners = new ArrayList<>(2);
                     ((List) listeners).add(orig);
                     ((List) listeners).add(listener);
                 }
diff --git a/core/src/main/java/org/elasticsearch/action/support/broadcast/TransportBroadcastAction.java b/core/src/main/java/org/elasticsearch/action/support/broadcast/TransportBroadcastAction.java
index dcb6952..2386a82 100644
--- a/core/src/main/java/org/elasticsearch/action/support/broadcast/TransportBroadcastAction.java
+++ b/core/src/main/java/org/elasticsearch/action/support/broadcast/TransportBroadcastAction.java
@@ -47,7 +47,6 @@ import java.util.concurrent.atomic.AtomicReferenceArray;
 public abstract class TransportBroadcastAction<Request extends BroadcastRequest, Response extends BroadcastResponse, ShardRequest extends BroadcastShardRequest, ShardResponse extends BroadcastShardResponse>
         extends HandledTransportAction<Request, Response> {
 
-    protected final ThreadPool threadPool;
     protected final ClusterService clusterService;
     protected final TransportService transportService;
 
@@ -59,7 +58,6 @@ public abstract class TransportBroadcastAction<Request extends BroadcastRequest,
         super(settings, actionName, threadPool, transportService, actionFilters, indexNameExpressionResolver, request);
         this.clusterService = clusterService;
         this.transportService = transportService;
-        this.threadPool = threadPool;
         this.transportShardAction = actionName + "[s]";
 
         transportService.registerRequestHandler(transportShardAction, shardRequest, shardExecutor, new ShardTransportHandler());
diff --git a/core/src/main/java/org/elasticsearch/action/support/replication/ReplicationRequest.java b/core/src/main/java/org/elasticsearch/action/support/replication/ReplicationRequest.java
index 39a3dae..93907cf 100644
--- a/core/src/main/java/org/elasticsearch/action/support/replication/ReplicationRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/support/replication/ReplicationRequest.java
@@ -46,7 +46,6 @@ public abstract class ReplicationRequest<T extends ReplicationRequest> extends A
     protected TimeValue timeout = DEFAULT_TIMEOUT;
     protected String index;
 
-    private boolean threadedOperation = true;
     private WriteConsistencyLevel consistencyLevel = WriteConsistencyLevel.DEFAULT;
     private volatile boolean canHaveDuplicates = false;
 
@@ -76,7 +75,6 @@ public abstract class ReplicationRequest<T extends ReplicationRequest> extends A
         super(originalRequest);
         this.timeout = request.timeout();
         this.index = request.index();
-        this.threadedOperation = request.operationThreaded();
         this.consistencyLevel = request.consistencyLevel();
     }
 
@@ -92,23 +90,6 @@ public abstract class ReplicationRequest<T extends ReplicationRequest> extends A
     }
 
     /**
-     * Controls if the operation will be executed on a separate thread when executed locally.
-     */
-    public final boolean operationThreaded() {
-        return threadedOperation;
-    }
-
-    /**
-     * Controls if the operation will be executed on a separate thread when executed locally. Defaults
-     * to <tt>true</tt> when running in embedded mode.
-     */
-    @SuppressWarnings("unchecked")
-    public final T operationThreaded(boolean threadedOperation) {
-        this.threadedOperation = threadedOperation;
-        return (T) this;
-    }
-
-    /**
      * A timeout to wait if the index operation can't be performed immediately. Defaults to <tt>1m</tt>.
      */
     @SuppressWarnings("unchecked")
diff --git a/core/src/main/java/org/elasticsearch/action/support/replication/ReplicationRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/support/replication/ReplicationRequestBuilder.java
index 7762eae..bafb33b 100644
--- a/core/src/main/java/org/elasticsearch/action/support/replication/ReplicationRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/support/replication/ReplicationRequestBuilder.java
@@ -36,16 +36,6 @@ public abstract class ReplicationRequestBuilder<Request extends ReplicationReque
     }
 
     /**
-     * Controls if the operation will be executed on a separate thread when executed locally. Defaults
-     * to <tt>true</tt> when running in embedded mode.
-     */
-    @SuppressWarnings("unchecked")
-    public final RequestBuilder setOperationThreaded(boolean threadedOperation) {
-        request.operationThreaded(threadedOperation);
-        return (RequestBuilder) this;
-    }
-
-    /**
      * A timeout to wait if the index operation can't be performed immediately. Defaults to <tt>1m</tt>.
      */
     @SuppressWarnings("unchecked")
diff --git a/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java b/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
index bc4094a..155c307 100644
--- a/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
+++ b/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
@@ -211,8 +211,6 @@ public abstract class TransportReplicationAction<Request extends ReplicationRequ
     class OperationTransportHandler implements TransportRequestHandler<Request> {
         @Override
         public void messageReceived(final Request request, final TransportChannel channel) throws Exception {
-            // if we have a local operation, execute it on a thread since we don't spawn
-            request.operationThreaded(true);
             execute(request, new ActionListener<Response>() {
                 @Override
                 public void onResponse(Response result) {
@@ -440,21 +438,17 @@ public abstract class TransportReplicationAction<Request extends ReplicationRequ
         protected void routeRequestOrPerformLocally(final ShardRouting primary, final ShardIterator shardsIt) {
             if (primary.currentNodeId().equals(observer.observedState().nodes().localNodeId())) {
                 try {
-                    if (internalRequest.request().operationThreaded()) {
-                        threadPool.executor(executor).execute(new AbstractRunnable() {
-                            @Override
-                            public void onFailure(Throwable t) {
-                                finishAsFailed(t);
-                            }
+                    threadPool.executor(executor).execute(new AbstractRunnable() {
+                        @Override
+                        public void onFailure(Throwable t) {
+                            finishAsFailed(t);
+                        }
 
-                            @Override
-                            protected void doRun() throws Exception {
-                                performOnPrimary(primary, shardsIt);
-                            }
-                        });
-                    } else {
-                        performOnPrimary(primary, shardsIt);
-                    }
+                        @Override
+                        protected void doRun() throws Exception {
+                            performOnPrimary(primary, shardsIt);
+                        }
+                    });
                 } catch (Throwable t) {
                     finishAsFailed(t);
                 }
@@ -506,9 +500,6 @@ public abstract class TransportReplicationAction<Request extends ReplicationRequ
                 finishAsFailed(failure);
                 return;
             }
-            // make it threaded operation so we fork on the discovery listener thread
-            internalRequest.request().operationThreaded(true);
-
             observer.waitForNextChange(new ClusterStateObserver.Listener() {
                 @Override
                 public void onNewClusterState(ClusterState state) {
@@ -904,43 +895,33 @@ public abstract class TransportReplicationAction<Request extends ReplicationRequ
 
                         });
             } else {
-                if (replicaRequest.operationThreaded()) {
-                    try {
-                        threadPool.executor(executor).execute(new AbstractRunnable() {
-                            @Override
-                            protected void doRun() {
-                                try {
-                                    shardOperationOnReplica(shard.shardId(), replicaRequest);
-                                    onReplicaSuccess();
-                                } catch (Throwable e) {
-                                    onReplicaFailure(nodeId, e);
-                                    failReplicaIfNeeded(shard.index(), shard.id(), e);
-                                }
+                try {
+                    threadPool.executor(executor).execute(new AbstractRunnable() {
+                        @Override
+                        protected void doRun() {
+                            try {
+                                shardOperationOnReplica(shard.shardId(), replicaRequest);
+                                onReplicaSuccess();
+                            } catch (Throwable e) {
+                                onReplicaFailure(nodeId, e);
+                                failReplicaIfNeeded(shard.index(), shard.id(), e);
                             }
+                        }
 
-                            // we must never reject on because of thread pool capacity on replicas
-                            @Override
-                            public boolean isForceExecution() {
-                                return true;
-                            }
+                        // we must never reject on because of thread pool capacity on replicas
+                        @Override
+                        public boolean isForceExecution() {
+                            return true;
+                        }
 
-                            @Override
-                            public void onFailure(Throwable t) {
-                                onReplicaFailure(nodeId, t);
-                            }
-                        });
-                    } catch (Throwable e) {
-                        failReplicaIfNeeded(shard.index(), shard.id(), e);
-                        onReplicaFailure(nodeId, e);
-                    }
-                } else {
-                    try {
-                        shardOperationOnReplica(shard.shardId(), replicaRequest);
-                        onReplicaSuccess();
-                    } catch (Throwable e) {
-                        failReplicaIfNeeded(shard.index(), shard.id(), e);
-                        onReplicaFailure(nodeId, e);
-                    }
+                        @Override
+                        public void onFailure(Throwable t) {
+                            onReplicaFailure(nodeId, t);
+                        }
+                    });
+                } catch (Throwable e) {
+                    failReplicaIfNeeded(shard.index(), shard.id(), e);
+                    onReplicaFailure(nodeId, e);
                 }
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/action/termvectors/dfs/TransportDfsOnlyAction.java b/core/src/main/java/org/elasticsearch/action/termvectors/dfs/TransportDfsOnlyAction.java
index d3bf24d..32e9d05 100644
--- a/core/src/main/java/org/elasticsearch/action/termvectors/dfs/TransportDfsOnlyAction.java
+++ b/core/src/main/java/org/elasticsearch/action/termvectors/dfs/TransportDfsOnlyAction.java
@@ -42,13 +42,12 @@ import org.elasticsearch.search.dfs.DfsSearchResult;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * Get the dfs only with no fetch phase. This is for internal use only.
  */
@@ -115,7 +114,7 @@ public class TransportDfsOnlyAction extends TransportBroadcastAction<DfsOnlyRequ
             } else if (shardResponse instanceof BroadcastShardOperationFailedException) {
                 failedShards++;
                 if (shardFailures == null) {
-                    shardFailures = newArrayList();
+                    shardFailures = new ArrayList<>();
                 }
                 shardFailures.add(new DefaultShardOperationFailedException((BroadcastShardOperationFailedException) shardResponse));
             } else {
diff --git a/core/src/main/java/org/elasticsearch/action/update/UpdateHelper.java b/core/src/main/java/org/elasticsearch/action/update/UpdateHelper.java
index c9401ca..fba2f23 100644
--- a/core/src/main/java/org/elasticsearch/action/update/UpdateHelper.java
+++ b/core/src/main/java/org/elasticsearch/action/update/UpdateHelper.java
@@ -131,7 +131,6 @@ public class UpdateHelper extends AbstractComponent {
                     .routing(request.routing())
                     .parent(request.parent())
                     .consistencyLevel(request.consistencyLevel());
-            indexRequest.operationThreaded(false);
             if (request.versionType() != VersionType.INTERNAL) {
                 // in all but the internal versioning mode, we want to create the new document using the given version.
                 indexRequest.version(request.version()).versionType(request.versionType());
@@ -227,13 +226,11 @@ public class UpdateHelper extends AbstractComponent {
                     .consistencyLevel(request.consistencyLevel())
                     .timestamp(timestamp).ttl(ttl)
                     .refresh(request.refresh());
-            indexRequest.operationThreaded(false);
             return new Result(indexRequest, Operation.INDEX, updatedSourceAsMap, updateSourceContentType);
         } else if ("delete".equals(operation)) {
             DeleteRequest deleteRequest = Requests.deleteRequest(request.index()).type(request.type()).id(request.id()).routing(routing).parent(parent)
                     .version(updateVersion).versionType(request.versionType())
                     .consistencyLevel(request.consistencyLevel());
-            deleteRequest.operationThreaded(false);
             return new Result(deleteRequest, Operation.DELETE, updatedSourceAsMap, updateSourceContentType);
         } else if ("none".equals(operation)) {
             UpdateResponse update = new UpdateResponse(getResult.getIndex(), getResult.getType(), getResult.getId(), getResult.getVersion(), false);
diff --git a/core/src/main/java/org/elasticsearch/action/update/UpdateRequest.java b/core/src/main/java/org/elasticsearch/action/update/UpdateRequest.java
index a5874dc..06df386 100644
--- a/core/src/main/java/org/elasticsearch/action/update/UpdateRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/update/UpdateRequest.java
@@ -78,7 +78,7 @@ public class UpdateRequest extends InstanceShardOperationRequest<UpdateRequest>
 
     private boolean scriptedUpsert = false;
     private boolean docAsUpsert = false;
-    private boolean detectNoop = false;
+    private boolean detectNoop = true;
 
     @Nullable
     private IndexRequest doc;
@@ -243,7 +243,7 @@ public class UpdateRequest extends InstanceShardOperationRequest<UpdateRequest>
      * The script to execute. Note, make sure not to send different script each
      * times and instead use script params if possible with the same
      * (automatically compiled) script.
-     * 
+     *
      * @deprecated Use {@link #script(Script)} instead
      */
     @Deprecated
@@ -256,7 +256,7 @@ public class UpdateRequest extends InstanceShardOperationRequest<UpdateRequest>
      * The script to execute. Note, make sure not to send different script each
      * times and instead use script params if possible with the same
      * (automatically compiled) script.
-     * 
+     *
      * @deprecated Use {@link #script(Script)} instead
      */
     @Deprecated
@@ -267,7 +267,7 @@ public class UpdateRequest extends InstanceShardOperationRequest<UpdateRequest>
 
     /**
      * The language of the script to execute.
-     * 
+     *
      * @deprecated Use {@link #script(Script)} instead
      */
     @Deprecated
@@ -286,7 +286,7 @@ public class UpdateRequest extends InstanceShardOperationRequest<UpdateRequest>
 
     /**
      * Add a script parameter.
-     * 
+     *
      * @deprecated Use {@link #script(Script)} instead
      */
     @Deprecated
@@ -311,7 +311,7 @@ public class UpdateRequest extends InstanceShardOperationRequest<UpdateRequest>
 
     /**
      * Sets the script parameters to use with the script.
-     * 
+     *
      * @deprecated Use {@link #script(Script)} instead
      */
     @Deprecated
@@ -338,7 +338,7 @@ public class UpdateRequest extends InstanceShardOperationRequest<UpdateRequest>
      * The script to execute. Note, make sure not to send different script each
      * times and instead use script params if possible with the same
      * (automatically compiled) script.
-     * 
+     *
      * @deprecated Use {@link #script(Script)} instead
      */
     @Deprecated
@@ -360,7 +360,7 @@ public class UpdateRequest extends InstanceShardOperationRequest<UpdateRequest>
      *            The script type
      * @param scriptParams
      *            The script parameters
-     * 
+     *
      * @deprecated Use {@link #script(Script)} instead
      */
     @Deprecated
@@ -623,7 +623,7 @@ public class UpdateRequest extends InstanceShardOperationRequest<UpdateRequest>
     }
 
     /**
-     * Should this update attempt to detect if it is a noop?
+     * Should this update attempt to detect if it is a noop? Defaults to true.
      * @return this for chaining
      */
     public UpdateRequest detectNoop(boolean detectNoop) {
@@ -631,6 +631,9 @@ public class UpdateRequest extends InstanceShardOperationRequest<UpdateRequest>
         return this;
     }
 
+    /**
+     * Should this update attempt to detect if it is a noop? Defaults to true.
+     */
     public boolean detectNoop() {
         return detectNoop;
     }
@@ -699,16 +702,15 @@ public class UpdateRequest extends InstanceShardOperationRequest<UpdateRequest>
         this.docAsUpsert = shouldUpsertDoc;
         return this;
     }
-    
+
     public boolean scriptedUpsert(){
         return this.scriptedUpsert;
     }
-    
+
     public UpdateRequest scriptedUpsert(boolean scriptedUpsert) {
         this.scriptedUpsert = scriptedUpsert;
         return this;
     }
-    
 
     @Override
     public void readFrom(StreamInput in) throws IOException {
diff --git a/core/src/main/java/org/elasticsearch/action/update/UpdateRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/update/UpdateRequestBuilder.java
index d4d0ae1..918d2d7 100644
--- a/core/src/main/java/org/elasticsearch/action/update/UpdateRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/update/UpdateRequestBuilder.java
@@ -308,6 +308,7 @@ public class UpdateRequestBuilder extends InstanceShardOperationRequestBuilder<U
 
     /**
      * Sets whether to perform extra effort to detect noop updates via docAsUpsert.
+     * Defautls to true.
      */
     public UpdateRequestBuilder setDetectNoop(boolean detectNoop) {
         request.detectNoop(detectNoop);
@@ -322,4 +323,14 @@ public class UpdateRequestBuilder extends InstanceShardOperationRequestBuilder<U
         request.scriptedUpsert(scriptedUpsert);
         return this;
     }
+
+    /**
+     * Set the new ttl of the document. Note that if detectNoop is true (the default)
+     * and the source of the document isn't changed then the ttl update won't take
+     * effect.
+     */
+    public UpdateRequestBuilder setTtl(Long ttl) {
+        request.doc().ttl(ttl);
+        return this;
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java b/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java
index 4ffc2ab..8e93ded 100644
--- a/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java
+++ b/core/src/main/java/org/elasticsearch/client/transport/TransportClientNodesService.java
@@ -21,7 +21,6 @@ package org.elasticsearch.client.transport;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.Version;
@@ -43,9 +42,20 @@ import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.concurrent.ConcurrentCollections;
 import org.elasticsearch.common.util.concurrent.FutureUtils;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.*;
-
-import java.util.*;
+import org.elasticsearch.transport.BaseTransportResponseHandler;
+import org.elasticsearch.transport.ConnectTransportException;
+import org.elasticsearch.transport.FutureTransportResponseHandler;
+import org.elasticsearch.transport.TransportException;
+import org.elasticsearch.transport.TransportRequestOptions;
+import org.elasticsearch.transport.TransportService;
+
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Set;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ScheduledFuture;
@@ -143,7 +153,7 @@ public class TransportClientNodesService extends AbstractComponent {
             if (closed) {
                 throw new IllegalStateException("transport client is closed, can't add an address");
             }
-            List<TransportAddress> filtered = Lists.newArrayListWithExpectedSize(transportAddresses.length);
+            List<TransportAddress> filtered = new ArrayList<>(transportAddresses.length);
             for (TransportAddress transportAddress : transportAddresses) {
                 boolean found = false;
                 for (DiscoveryNode otherNode : listedNodes) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/ClusterChangedEvent.java b/core/src/main/java/org/elasticsearch/cluster/ClusterChangedEvent.java
index 1ceb822..209781d 100644
--- a/core/src/main/java/org/elasticsearch/cluster/ClusterChangedEvent.java
+++ b/core/src/main/java/org/elasticsearch/cluster/ClusterChangedEvent.java
@@ -21,11 +21,11 @@ package org.elasticsearch.cluster;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
 
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 
@@ -93,7 +93,7 @@ public class ClusterChangedEvent {
             String index = cursor.value;
             if (!previousState.metaData().hasIndex(index)) {
                 if (created == null) {
-                    created = Lists.newArrayList();
+                    created = new ArrayList<>();
                 }
                 created.add(index);
             }
@@ -126,7 +126,7 @@ public class ClusterChangedEvent {
             String index = cursor.value;
             if (!state.metaData().hasIndex(index)) {
                 if (deleted == null) {
-                    deleted = Lists.newArrayList();
+                    deleted = new ArrayList<>();
                 }
                 deleted.add(index);
             }
diff --git a/core/src/main/java/org/elasticsearch/cluster/DiffableUtils.java b/core/src/main/java/org/elasticsearch/cluster/DiffableUtils.java
index 4e912a3..60095de 100644
--- a/core/src/main/java/org/elasticsearch/cluster/DiffableUtils.java
+++ b/core/src/main/java/org/elasticsearch/cluster/DiffableUtils.java
@@ -27,11 +27,11 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.newHashMap;
 
 public final class DiffableUtils {
@@ -232,13 +232,13 @@ public final class DiffableUtils {
         protected final Map<String, T> adds;
 
         protected MapDiff() {
-            deletes = newArrayList();
+            deletes = new ArrayList<>();
             diffs = newHashMap();
             adds = newHashMap();
         }
 
         protected MapDiff(StreamInput in, KeyedReader<T> reader) throws IOException {
-            deletes = newArrayList();
+            deletes = new ArrayList<>();
             diffs = newHashMap();
             adds = newHashMap();
             int deletesCount = in.readVInt();
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java
index d5b398c..f12824d 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java
@@ -28,7 +28,7 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.query.IndexQueryParserService;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.indices.InvalidAliasNameException;
 
 import java.io.IOException;
@@ -142,10 +142,10 @@ public class AliasValidator extends AbstractComponent {
     }
 
     private void validateAliasFilter(XContentParser parser, IndexQueryParserService indexQueryParserService) throws IOException {
-        QueryShardContext context = indexQueryParserService.getShardContext();
+        QueryParseContext context = indexQueryParserService.getParseContext();
         try {
             context.reset(parser);
-            context.parseContext().parseInnerFilter();
+            context.parseInnerFilter();
         } finally {
             context.reset(null);
             parser.close();
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolver.java b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolver.java
index 2f28dca..eb5b716 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolver.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexNameExpressionResolver.java
@@ -41,10 +41,17 @@ import org.joda.time.DateTimeZone;
 import org.joda.time.format.DateTimeFormat;
 import org.joda.time.format.DateTimeFormatter;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Set;
 import java.util.concurrent.Callable;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.filterEntries;
 import static com.google.common.collect.Maps.newHashMap;
 
@@ -268,7 +275,7 @@ public class IndexNameExpressionResolver extends AbstractComponent {
                 if (filteringRequired) {
                     // If filtering required - add it to the list of filters
                     if (filteringAliases == null) {
-                        filteringAliases = newArrayList();
+                        filteringAliases = new ArrayList<>();
                     }
                     filteringAliases.add(alias);
                 } else {
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
index 32098e5..001bf42 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
@@ -23,7 +23,10 @@ import com.carrotsearch.hppc.ObjectHashSet;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
 import com.google.common.base.Predicate;
-import com.google.common.collect.*;
+import com.google.common.collect.Collections2;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableSet;
+import com.google.common.collect.UnmodifiableIterator;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.cluster.Diff;
 import org.elasticsearch.cluster.Diffable;
@@ -45,7 +48,12 @@ import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.settings.loader.SettingsLoader;
-import org.elasticsearch.common.xcontent.*;
+import org.elasticsearch.common.xcontent.FromXContentBuilder;
+import org.elasticsearch.common.xcontent.ToXContent;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.XContentType;
 import org.elasticsearch.discovery.DiscoverySettings;
 import org.elasticsearch.index.IndexNotFoundException;
 import org.elasticsearch.indices.recovery.RecoverySettings;
@@ -55,7 +63,18 @@ import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.search.warmer.IndexWarmersMetaData;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.EnumSet;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.SortedMap;
+import java.util.TreeMap;
 
 import static org.elasticsearch.common.settings.Settings.*;
 
@@ -246,7 +265,7 @@ public class MetaData implements Iterable<IndexMetaData>, Diffable<MetaData>, Fr
         Iterable<String> intersection = HppcMaps.intersection(ObjectHashSet.from(concreteIndices), indices.keys());
         for (String index : intersection) {
             IndexMetaData indexMetaData = indices.get(index);
-            List<AliasMetaData> filteredValues = Lists.newArrayList();
+            List<AliasMetaData> filteredValues = new ArrayList<>();
             for (ObjectCursor<AliasMetaData> cursor : indexMetaData.getAliases().values()) {
                 AliasMetaData value = cursor.value;
                 if (matchAllAliases || Regex.simpleMatch(aliases, value.alias())) {
@@ -295,7 +314,7 @@ public class MetaData implements Iterable<IndexMetaData>, Diffable<MetaData>, Fr
         Iterable<String> intersection = HppcMaps.intersection(ObjectHashSet.from(concreteIndices), indices.keys());
         for (String index : intersection) {
             IndexMetaData indexMetaData = indices.get(index);
-            List<AliasMetaData> filteredValues = Lists.newArrayList();
+            List<AliasMetaData> filteredValues = new ArrayList<>();
             for (ObjectCursor<AliasMetaData> cursor : indexMetaData.getAliases().values()) {
                 AliasMetaData value = cursor.value;
                 if (Regex.simpleMatch(aliases, value.alias())) {
@@ -978,14 +997,14 @@ public class MetaData implements Iterable<IndexMetaData>, Diffable<MetaData>, Fr
             // TODO: I think we can remove these arrays. it isn't worth the effort, for operations on all indices.
             // When doing an operation across all indices, most of the time is spent on actually going to all shards and
             // do the required operations, the bottleneck isn't resolving expressions into concrete indices.
-            List<String> allIndicesLst = Lists.newArrayList();
+            List<String> allIndicesLst = new ArrayList<>();
             for (ObjectCursor<IndexMetaData> cursor : indices.values()) {
                 allIndicesLst.add(cursor.value.index());
             }
             String[] allIndices = allIndicesLst.toArray(new String[allIndicesLst.size()]);
 
-            List<String> allOpenIndicesLst = Lists.newArrayList();
-            List<String> allClosedIndicesLst = Lists.newArrayList();
+            List<String> allOpenIndicesLst = new ArrayList<>();
+            List<String> allClosedIndicesLst = new ArrayList<>();
             for (ObjectCursor<IndexMetaData> cursor : indices.values()) {
                 IndexMetaData indexMetaData = cursor.value;
                 if (indexMetaData.state() == IndexMetaData.State.OPEN) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java
index ff878a4..bebb8e5 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java
@@ -22,7 +22,6 @@ package org.elasticsearch.cluster.metadata;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
 import com.google.common.base.Charsets;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.ElasticsearchException;
@@ -80,7 +79,12 @@ import java.io.UnsupportedEncodingException;
 import java.nio.file.DirectoryStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Comparator;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Set;
 import java.util.concurrent.Semaphore;
 import java.util.concurrent.TimeUnit;
 
@@ -248,7 +252,7 @@ public class MetaDataCreateIndexService extends AbstractComponent {
 
                     Map<String, AliasMetaData> templatesAliases = Maps.newHashMap();
 
-                    List<String> templateNames = Lists.newArrayList();
+                    List<String> templateNames = new ArrayList<>();
 
                     for (Map.Entry<String, String> entry : request.mappings().entrySet()) {
                         mappings.put(entry.getKey(), parseMapping(entry.getValue()));
@@ -494,7 +498,7 @@ public class MetaDataCreateIndexService extends AbstractComponent {
     }
 
     private List<IndexTemplateMetaData> findTemplates(CreateIndexClusterStateUpdateRequest request, ClusterState state, IndexTemplateFilter indexTemplateFilter) throws IOException {
-        List<IndexTemplateMetaData> templates = Lists.newArrayList();
+        List<IndexTemplateMetaData> templates = new ArrayList<>();
         for (ObjectCursor<IndexTemplateMetaData> cursor : state.metaData().templates().values()) {
             IndexTemplateMetaData template = cursor.value;
             if (indexTemplateFilter.apply(request, template)) {
@@ -527,7 +531,7 @@ public class MetaDataCreateIndexService extends AbstractComponent {
 
     List<String> getIndexSettingsValidationErrors(Settings settings) {
         String customPath = settings.get(IndexMetaData.SETTING_DATA_PATH, null);
-        List<String> validationErrors = Lists.newArrayList();
+        List<String> validationErrors = new ArrayList<>();
         if (customPath != null && env.sharedDataFile() == null) {
             validationErrors.add("path.shared_data must be set in order to use custom data paths");
         } else if (customPath != null) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexAliasesService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexAliasesService.java
index d5512f6..787640d 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexAliasesService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexAliasesService.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.cluster.metadata;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.admin.indices.alias.IndicesAliasesClusterStateUpdateRequest;
@@ -34,10 +33,11 @@ import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.IndexNotFoundException;
-import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.IndexService;
+import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.indices.IndicesService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -69,7 +69,7 @@ public class MetaDataIndexAliasesService extends AbstractComponent {
 
             @Override
             public ClusterState execute(final ClusterState currentState) {
-                List<String> indicesToClose = Lists.newArrayList();
+                List<String> indicesToClose = new ArrayList<>();
                 Map<String, IndexService> indices = Maps.newHashMap();
                 try {
                     for (AliasAction aliasAction : request.actions()) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java
index 66ad39f..7e26c2c 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexTemplateService.java
@@ -19,7 +19,6 @@
 package org.elasticsearch.cluster.metadata;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 import org.elasticsearch.action.admin.indices.alias.Alias;
@@ -39,6 +38,7 @@ import org.elasticsearch.indices.IndexTemplateAlreadyExistsException;
 import org.elasticsearch.indices.IndexTemplateMissingException;
 import org.elasticsearch.indices.InvalidIndexTemplateException;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
@@ -179,7 +179,7 @@ public class MetaDataIndexTemplateService extends AbstractComponent {
     }
 
     private void validate(PutRequest request) {
-        List<String> validationErrors = Lists.newArrayList();
+        List<String> validationErrors = new ArrayList<>();
         if (request.name.contains(" ")) {
             validationErrors.add("name must not contain a space");
         }
@@ -240,7 +240,7 @@ public class MetaDataIndexTemplateService extends AbstractComponent {
         String template;
         Settings settings = Settings.Builder.EMPTY_SETTINGS;
         Map<String, String> mappings = Maps.newHashMap();
-        List<Alias> aliases = Lists.newArrayList();
+        List<Alias> aliases = new ArrayList<>();
         Map<String, IndexMetaData.Custom> customs = Maps.newHashMap();
 
         TimeValue masterTimeout = MasterNodeRequest.DEFAULT_MASTER_NODE_TIMEOUT;
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
index 04d52b0..5839502 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.cluster.metadata;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 import org.elasticsearch.Version;
@@ -47,7 +46,12 @@ import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.indices.InvalidTypeNameException;
 import org.elasticsearch.percolator.PercolatorService;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
 
 import static com.google.common.collect.Maps.newHashMap;
 /**
@@ -226,7 +230,7 @@ public class MetaDataMappingService extends AbstractComponent {
             if (task instanceof RefreshTask) {
                 RefreshTask refreshTask = (RefreshTask) task;
                 try {
-                    List<String> updatedTypes = Lists.newArrayList();
+                    List<String> updatedTypes = new ArrayList<>();
                     for (String type : refreshTask.types) {
                         if (processedRefreshes.contains(type)) {
                             continue;
@@ -342,7 +346,7 @@ public class MetaDataMappingService extends AbstractComponent {
 
             @Override
             public ClusterState execute(final ClusterState currentState) throws Exception {
-                List<String> indicesToClose = Lists.newArrayList();
+                List<String> indicesToClose = new ArrayList<>();
                 try {
                     for (String index : request.indices()) {
                         if (!currentState.metaData().hasIndex(index)) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
index 1b95aed..eebd770 100644
--- a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
+++ b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
@@ -35,12 +35,11 @@ import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.transport.TransportAddress;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * This class holds all {@link DiscoveryNode} in the cluster and provides convenience methods to
  * access, modify merge / diff discovery nodes.
@@ -414,8 +413,8 @@ public class DiscoveryNodes extends AbstractDiffable<DiscoveryNodes> implements
      * Returns the changes comparing this nodes to the provided nodes.
      */
     public Delta delta(DiscoveryNodes other) {
-        List<DiscoveryNode> removed = newArrayList();
-        List<DiscoveryNode> added = newArrayList();
+        List<DiscoveryNode> removed = new ArrayList<>();
+        List<DiscoveryNode> added = new ArrayList<>();
         for (DiscoveryNode node : other) {
             if (!this.nodeExists(node.id())) {
                 removed.add(node);
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java b/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
index 85a14e2..e8311b5 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
@@ -25,7 +25,6 @@ import com.carrotsearch.hppc.cursors.IntObjectCursor;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Sets;
 import com.google.common.collect.UnmodifiableIterator;
-
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -42,8 +41,6 @@ import java.util.List;
 import java.util.Set;
 import java.util.concurrent.ThreadLocalRandom;
 
-import static com.google.common.collect.Lists.*;
-
 /**
  * The {@link IndexRoutingTable} represents routing information for a single
  * index. The routing table maintains a list of all shards in the index. A
@@ -265,7 +262,7 @@ public class IndexRoutingTable extends AbstractDiffable<IndexRoutingTable> imple
      * @return a {@link List} of shards that match one of the given {@link ShardRoutingState states}
      */
     public List<ShardRouting> shardsWithState(ShardRoutingState state) {
-        List<ShardRouting> shards = newArrayList();
+        List<ShardRouting> shards = new ArrayList<>();
         for (IndexShardRoutingTable shardRoutingTable : this) {
             shards.addAll(shardRoutingTable.shardsWithState(state));
         }
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java b/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
index bc13e08..5cc35ae 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
@@ -30,11 +30,15 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.index.shard.ShardId;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
 import java.util.concurrent.ThreadLocalRandom;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * {@link IndexShardRoutingTable} encapsulates all instances of a single shard.
  * Each Elasticsearch index consists of multiple shards, each shard encapsulates
@@ -554,7 +558,7 @@ public class IndexShardRoutingTable implements Iterable<ShardRouting> {
     }
 
     public List<ShardRouting> replicaShardsWithState(ShardRoutingState... states) {
-        List<ShardRouting> shards = newArrayList();
+        List<ShardRouting> shards = new ArrayList<>();
         for (ShardRouting shardEntry : replicas) {
             for (ShardRoutingState state : states) {
                 if (shardEntry.state() == state) {
@@ -569,7 +573,7 @@ public class IndexShardRoutingTable implements Iterable<ShardRouting> {
         if (state == ShardRoutingState.INITIALIZING) {
             return allInitializingShards;
         }
-        List<ShardRouting> shards = newArrayList();
+        List<ShardRouting> shards = new ArrayList<>();
         for (ShardRouting shardEntry : this) {
             if (shardEntry.state() == state) {
                 shards.add(shardEntry);
@@ -585,12 +589,12 @@ public class IndexShardRoutingTable implements Iterable<ShardRouting> {
 
         public Builder(IndexShardRoutingTable indexShard) {
             this.shardId = indexShard.shardId;
-            this.shards = newArrayList(indexShard.shards);
+            this.shards = new ArrayList<>(indexShard.shards);
         }
 
         public Builder(ShardId shardId) {
             this.shardId = shardId;
-            this.shards = newArrayList();
+            this.shards = new ArrayList<>();
         }
 
         public Builder addShard(ShardRouting shardEntry) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java b/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java
index 6db6852..411a1ed 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.cluster.routing;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -36,6 +35,7 @@ import org.elasticsearch.index.IndexNotFoundException;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.index.shard.ShardNotFoundException;
 
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Map;
@@ -90,7 +90,7 @@ public class OperationRouting extends AbstractComponent {
                 set.add(iterator);
             }
         }
-        return new GroupShardsIterator(Lists.newArrayList(set));
+        return new GroupShardsIterator(new ArrayList<>(set));
     }
 
     private static final Map<String, Set<String>> EMPTY_ROUTING = Collections.emptyMap();
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java
index b96eece..43ad6af 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNode.java
@@ -27,8 +27,6 @@ import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * A {@link RoutingNode} represents a cluster node associated with a single {@link DiscoveryNode} including all shards
  * that are hosted on that nodes. Each {@link RoutingNode} has a unique node id that can be used to identify the node.
@@ -118,7 +116,7 @@ public class RoutingNode implements Iterable<ShardRouting> {
      * @return List of shards 
      */
     public List<ShardRouting> shardsWithState(ShardRoutingState... states) {
-        List<ShardRouting> shards = newArrayList();
+        List<ShardRouting> shards = new ArrayList<>();
         for (ShardRouting shardEntry : this) {
             for (ShardRoutingState state : states) {
                 if (shardEntry.state() == state) {
@@ -136,7 +134,7 @@ public class RoutingNode implements Iterable<ShardRouting> {
      * @return a list of shards
      */
     public List<ShardRouting> shardsWithState(String index, ShardRoutingState... states) {
-        List<ShardRouting> shards = newArrayList();
+        List<ShardRouting> shards = new ArrayList<>();
 
         for (ShardRouting shardEntry : this) {
             if (!shardEntry.index().equals(index)) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
index 8c07429..0836909 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
@@ -22,19 +22,25 @@ package org.elasticsearch.cluster.routing;
 import com.carrotsearch.hppc.ObjectIntHashMap;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.google.common.base.Predicate;
-import com.google.common.collect.*;
+import com.google.common.collect.Iterables;
+import com.google.common.collect.Iterators;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.block.ClusterBlocks;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.index.shard.ShardId;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.newHashMap;
 import static com.google.common.collect.Sets.newHashSet;
 
@@ -97,7 +103,7 @@ public class RoutingNodes implements Iterable<RoutingNode> {
                     if (shard.assignedToNode()) {
                         List<ShardRouting> entries = nodesToShards.get(shard.currentNodeId());
                         if (entries == null) {
-                            entries = newArrayList();
+                            entries = new ArrayList<>();
                             nodesToShards.put(shard.currentNodeId(), entries);
                         }
                         final ShardRouting sr = getRouting(shard, readOnly);
@@ -107,7 +113,7 @@ public class RoutingNodes implements Iterable<RoutingNode> {
                             entries = nodesToShards.get(shard.relocatingNodeId());
                             relocatingShards++;
                             if (entries == null) {
-                                entries = newArrayList();
+                                entries = new ArrayList<>();
                                 nodesToShards.put(shard.relocatingNodeId(), entries);
                             }
                             // add the counterpart shard with relocatingNodeId reflecting the source from which
@@ -285,7 +291,7 @@ public class RoutingNodes implements Iterable<RoutingNode> {
     }
 
     public List<ShardRouting> shards(Predicate<ShardRouting> predicate) {
-        List<ShardRouting> shards = newArrayList();
+        List<ShardRouting> shards = new ArrayList<>();
         for (RoutingNode routingNode : this) {
             for (ShardRouting shardRouting : routingNode) {
                 if (predicate.apply(shardRouting)) {
@@ -298,7 +304,7 @@ public class RoutingNodes implements Iterable<RoutingNode> {
 
     public List<ShardRouting> shardsWithState(ShardRoutingState... state) {
         // TODO these are used on tests only - move into utils class
-        List<ShardRouting> shards = newArrayList();
+        List<ShardRouting> shards = new ArrayList<>();
         for (RoutingNode routingNode : this) {
             shards.addAll(routingNode.shardsWithState(state));
         }
@@ -313,7 +319,7 @@ public class RoutingNodes implements Iterable<RoutingNode> {
 
     public List<ShardRouting> shardsWithState(String index, ShardRoutingState... state) {
         // TODO these are used on tests only - move into utils class
-        List<ShardRouting> shards = newArrayList();
+        List<ShardRouting> shards = new ArrayList<>();
         for (RoutingNode routingNode : this) {
             shards.addAll(routingNode.shardsWithState(index, state));
         }
@@ -452,7 +458,7 @@ public class RoutingNodes implements Iterable<RoutingNode> {
         }
         List<ShardRouting> shards = assignedShards.get(shard.shardId());
         if (shards == null) {
-            shards = Lists.newArrayList();
+            shards = new ArrayList<>();
             assignedShards.put(shard.shardId(), shards);
         }
         assert  assertInstanceNotInList(shard, shards);
@@ -724,7 +730,7 @@ public class RoutingNodes implements Iterable<RoutingNode> {
         }
         // Assert that the active shard routing are identical.
         Set<Map.Entry<String, Integer>> entries = indicesAndShards.entrySet();
-        final List<ShardRouting> shards = newArrayList();
+        final List<ShardRouting> shards = new ArrayList<>();
         for (Map.Entry<String, Integer> e : entries) {
             String index = e.getKey();
             for (int i = 0; i < e.getValue(); i++) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
index 4fda839..97749e6 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
@@ -21,8 +21,12 @@ package org.elasticsearch.cluster.routing;
 
 import com.carrotsearch.hppc.IntSet;
 import com.google.common.base.Predicate;
-import com.google.common.collect.*;
-import org.elasticsearch.cluster.*;
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.Iterables;
+import com.google.common.collect.UnmodifiableIterator;
+import org.elasticsearch.cluster.Diff;
+import org.elasticsearch.cluster.Diffable;
+import org.elasticsearch.cluster.DiffableUtils;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.common.io.stream.StreamInput;
@@ -35,7 +39,6 @@ import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.newHashMap;
 
 /**
@@ -107,7 +110,7 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
     }
 
     public List<ShardRouting> shardsWithState(ShardRoutingState state) {
-        List<ShardRouting> shards = newArrayList();
+        List<ShardRouting> shards = new ArrayList<>();
         for (IndexRoutingTable indexRoutingTable : this) {
             shards.addAll(indexRoutingTable.shardsWithState(state));
         }
@@ -120,7 +123,7 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
      * @return All the shards
      */
     public List<ShardRouting> allShards() {
-        List<ShardRouting> shards = Lists.newArrayList();
+        List<ShardRouting> shards = new ArrayList<>();
         String[] indices = indicesRouting.keySet().toArray(new String[indicesRouting.keySet().size()]);
         for (String index : indices) {
             List<ShardRouting> allShardsIndex = allShards(index);
@@ -137,7 +140,7 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
      * @throws IndexNotFoundException If the index passed does not exists
      */
     public List<ShardRouting> allShards(String index)  {
-        List<ShardRouting> shards = Lists.newArrayList();
+        List<ShardRouting> shards = new ArrayList<>();
         IndexRoutingTable indexRoutingTable = index(index);
         if (indexRoutingTable == null) {
             throw new IndexNotFoundException(index);
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTableValidation.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTableValidation.java
index bd1e283..acd207f 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTableValidation.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTableValidation.java
@@ -21,17 +21,15 @@ package org.elasticsearch.cluster.routing;
 
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.io.stream.Streamable;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
-import static com.google.common.collect.Lists.newArrayListWithCapacity;
 import static com.google.common.collect.Maps.newHashMap;
 
 /**
@@ -57,7 +55,7 @@ public class RoutingTableValidation implements Streamable {
         if (failures().isEmpty() && indicesFailures().isEmpty()) {
             return ImmutableList.of();
         }
-        List<String> allFailures = newArrayList(failures());
+        List<String> allFailures = new ArrayList<>(failures());
         for (Map.Entry<String, List<String>> entry : indicesFailures().entrySet()) {
             for (String failure : entry.getValue()) {
                 allFailures.add("Index [" + entry.getKey() + "]: " + failure);
@@ -94,7 +92,7 @@ public class RoutingTableValidation implements Streamable {
     public void addFailure(String failure) {
         valid = false;
         if (failures == null) {
-            failures = newArrayList();
+            failures = new ArrayList<>();
         }
         failures.add(failure);
     }
@@ -106,7 +104,7 @@ public class RoutingTableValidation implements Streamable {
         }
         List<String> indexFailures = indicesFailures.get(index);
         if (indexFailures == null) {
-            indexFailures = Lists.newArrayList();
+            indexFailures = new ArrayList<>();
             indicesFailures.put(index, indexFailures);
         }
         indexFailures.add(failure);
@@ -124,7 +122,7 @@ public class RoutingTableValidation implements Streamable {
         if (size == 0) {
             failures = ImmutableList.of();
         } else {
-            failures = Lists.newArrayListWithCapacity(size);
+            failures = new ArrayList<>(size);
             for (int i = 0; i < size; i++) {
                 failures.add(in.readString());
             }
@@ -137,7 +135,7 @@ public class RoutingTableValidation implements Streamable {
             for (int i = 0; i < size; i++) {
                 String index = in.readString();
                 int size2 = in.readVInt();
-                List<String> indexFailures = newArrayListWithCapacity(size2);
+                List<String> indexFailures = new ArrayList<>(size2);
                 for (int j = 0; j < size2; j++) {
                     indexFailures.add(in.readString());
                 }
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationExplanation.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationExplanation.java
index 4bd19ca..f8126f5 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationExplanation.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationExplanation.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.cluster.routing.allocation;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.io.stream.StreamInput;
@@ -28,6 +27,7 @@ import org.elasticsearch.common.io.stream.Streamable;
 import org.elasticsearch.index.shard.ShardId;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -88,7 +88,7 @@ public class AllocationExplanation implements Streamable {
     public AllocationExplanation add(ShardId shardId, NodeExplanation nodeExplanation) {
         List<NodeExplanation> list = explanations.get(shardId);
         if (list == null) {
-            list = Lists.newArrayList();
+            list = new ArrayList<>();
             explanations.put(shardId, list);
         }
         list.add(nodeExplanation);
@@ -121,7 +121,7 @@ public class AllocationExplanation implements Streamable {
         for (int i = 0; i < size; i++) {
             ShardId shardId = ShardId.readShardId(in);
             int size2 = in.readVInt();
-            List<NodeExplanation> ne = Lists.newArrayListWithCapacity(size2);
+            List<NodeExplanation> ne = new ArrayList<>(size2);
             for (int j = 0; j < size2; j++) {
                 DiscoveryNode node = null;
                 if (in.readBoolean()) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java
index e5a4685..191ec95 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/AllocationService.java
@@ -21,12 +21,16 @@ package org.elasticsearch.cluster.routing.allocation;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
 import org.elasticsearch.cluster.ClusterInfoService;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
-import org.elasticsearch.cluster.routing.*;
+import org.elasticsearch.cluster.routing.IndexRoutingTable;
+import org.elasticsearch.cluster.routing.RoutingNode;
+import org.elasticsearch.cluster.routing.RoutingNodes;
+import org.elasticsearch.cluster.routing.RoutingTable;
+import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.cluster.routing.UnassignedInfo;
 import org.elasticsearch.cluster.routing.allocation.allocator.ShardsAllocators;
 import org.elasticsearch.cluster.routing.allocation.command.AllocationCommands;
 import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;
@@ -36,7 +40,6 @@ import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 
 import java.util.ArrayList;
-import java.util.Iterator;
 import java.util.List;
 
 
@@ -235,7 +238,7 @@ public class AllocationService extends AbstractComponent {
         }
 
         // go over and remove dangling replicas that are initializing for primary shards
-        List<ShardRouting> shardsToFail = Lists.newArrayList();
+        List<ShardRouting> shardsToFail = new ArrayList<>();
         for (ShardRouting shardEntry : routingNodes.unassigned()) {
             if (shardEntry.primary()) {
                 for (ShardRouting routing : routingNodes.assignedShards(shardEntry)) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java
index 8601bf1..95f1a29 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java
@@ -25,10 +25,9 @@ import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * Class used to encapsulate a number of {@link RerouteExplanation}
  * explanations.
@@ -37,7 +36,7 @@ public class RoutingExplanations implements ToXContent {
     private final List<RerouteExplanation> explanations;
 
     public RoutingExplanations() {
-        this.explanations = newArrayList();
+        this.explanations = new ArrayList<>();
     }
 
     public RoutingExplanations add(RerouteExplanation explanation) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocationCommands.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocationCommands.java
index 33a4418..3e17ce6 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocationCommands.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/command/AllocationCommands.java
@@ -20,8 +20,8 @@
 package org.elasticsearch.cluster.routing.allocation.command;
 
 import org.elasticsearch.ElasticsearchParseException;
-import org.elasticsearch.cluster.routing.allocation.RoutingExplanations;
 import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
+import org.elasticsearch.cluster.routing.allocation.RoutingExplanations;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
@@ -30,13 +30,12 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * A simple {@link AllocationCommand} composite managing several
  * {@link AllocationCommand} implementations
@@ -73,7 +72,7 @@ public class AllocationCommands {
         registerFactory(MoveAllocationCommand.NAME, new MoveAllocationCommand.Factory());
     }
 
-    private final List<AllocationCommand> commands = newArrayList();
+    private final List<AllocationCommand> commands = new ArrayList<>();
 
     /**
      * Creates a new set of {@link AllocationCommands}
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/Decision.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/Decision.java
index 76922ae..02fc2fe 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/Decision.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/Decision.java
@@ -19,13 +19,13 @@
 
 package org.elasticsearch.cluster.routing.allocation.decider;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
 
@@ -226,7 +226,7 @@ public abstract class Decision implements ToXContent {
      */
     public static class Multi extends Decision {
 
-        private final List<Decision> decisions = Lists.newArrayList();
+        private final List<Decision> decisions = new ArrayList<>();
 
         /**
          * Add a decision to this {@link Multi}decision instance
diff --git a/core/src/main/java/org/elasticsearch/common/Strings.java b/core/src/main/java/org/elasticsearch/common/Strings.java
index 58210e0..302c5b2 100644
--- a/core/src/main/java/org/elasticsearch/common/Strings.java
+++ b/core/src/main/java/org/elasticsearch/common/Strings.java
@@ -943,7 +943,8 @@ public class Strings {
         boolean changed = false;
         for (int i = 0; i < value.length(); i++) {
             char c = value.charAt(i);
-            if (c == '_') {
+            //e.g. _name stays as-is, _first_name becomes _firstName
+            if (c == '_' && i > 0) {
                 if (!changed) {
                     if (sb != null) {
                         sb.setLength(0);
diff --git a/core/src/main/java/org/elasticsearch/common/ValidationException.java b/core/src/main/java/org/elasticsearch/common/ValidationException.java
index 1328876..f3fbe5e 100644
--- a/core/src/main/java/org/elasticsearch/common/ValidationException.java
+++ b/core/src/main/java/org/elasticsearch/common/ValidationException.java
@@ -36,7 +36,7 @@ public class ValidationException extends IllegalArgumentException {
      * Add a new validation error to the accumulating validation errors
      * @param error the error to add
      */
-    public void addValidationError(String error) {
+    public final void addValidationError(String error) {
         validationErrors.add(error);
     }
 
@@ -44,7 +44,7 @@ public class ValidationException extends IllegalArgumentException {
      * Add a sequence of validation errors to the accumulating validation errors
      * @param errors the errors to add
      */
-    public void addValidationErrors(Iterable<String> errors) {
+    public final void addValidationErrors(Iterable<String> errors) {
         for (String error : errors) {
             validationErrors.add(error);
         }
@@ -52,14 +52,13 @@ public class ValidationException extends IllegalArgumentException {
 
     /**
      * Returns the validation errors accumulated
-     * @return
      */
-    public List<String> validationErrors() {
+    public final List<String> validationErrors() {
         return validationErrors;
     }
 
     @Override
-    public String getMessage() {
+    public final String getMessage() {
         StringBuilder sb = new StringBuilder();
         sb.append("Validation Failed: ");
         int index = 0;
diff --git a/core/src/main/java/org/elasticsearch/common/inject/BindingProcessor.java b/core/src/main/java/org/elasticsearch/common/inject/BindingProcessor.java
index 9966a4e..58ea0be 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/BindingProcessor.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/BindingProcessor.java
@@ -17,10 +17,33 @@
 package org.elasticsearch.common.inject;
 
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
-import org.elasticsearch.common.inject.internal.*;
-import org.elasticsearch.common.inject.spi.*;
-
+import org.elasticsearch.common.inject.internal.Annotations;
+import org.elasticsearch.common.inject.internal.BindingImpl;
+import org.elasticsearch.common.inject.internal.Errors;
+import org.elasticsearch.common.inject.internal.ErrorsException;
+import org.elasticsearch.common.inject.internal.ExposedBindingImpl;
+import org.elasticsearch.common.inject.internal.InstanceBindingImpl;
+import org.elasticsearch.common.inject.internal.InternalFactory;
+import org.elasticsearch.common.inject.internal.LinkedBindingImpl;
+import org.elasticsearch.common.inject.internal.LinkedProviderBindingImpl;
+import org.elasticsearch.common.inject.internal.ProviderInstanceBindingImpl;
+import org.elasticsearch.common.inject.internal.ProviderMethod;
+import org.elasticsearch.common.inject.internal.Scoping;
+import org.elasticsearch.common.inject.internal.UntargettedBindingImpl;
+import org.elasticsearch.common.inject.spi.BindingTargetVisitor;
+import org.elasticsearch.common.inject.spi.ConstructorBinding;
+import org.elasticsearch.common.inject.spi.ConvertedConstantBinding;
+import org.elasticsearch.common.inject.spi.ExposedBinding;
+import org.elasticsearch.common.inject.spi.InjectionPoint;
+import org.elasticsearch.common.inject.spi.InstanceBinding;
+import org.elasticsearch.common.inject.spi.LinkedKeyBinding;
+import org.elasticsearch.common.inject.spi.PrivateElements;
+import org.elasticsearch.common.inject.spi.ProviderBinding;
+import org.elasticsearch.common.inject.spi.ProviderInstanceBinding;
+import org.elasticsearch.common.inject.spi.ProviderKeyBinding;
+import org.elasticsearch.common.inject.spi.UntargettedBinding;
+
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
 
@@ -32,9 +55,9 @@ import java.util.Set;
  */
 class BindingProcessor extends AbstractProcessor {
 
-    private final List<CreationListener> creationListeners = Lists.newArrayList();
+    private final List<CreationListener> creationListeners = new ArrayList<>();
     private final Initializer initializer;
-    private final List<Runnable> uninitializedBindings = Lists.newArrayList();
+    private final List<Runnable> uninitializedBindings = new ArrayList<>();
 
     BindingProcessor(Errors errors, Initializer initializer) {
         super(errors);
diff --git a/core/src/main/java/org/elasticsearch/common/inject/DeferredLookups.java b/core/src/main/java/org/elasticsearch/common/inject/DeferredLookups.java
index 1631d69..c6ca9ba 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/DeferredLookups.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/DeferredLookups.java
@@ -16,12 +16,12 @@
 
 package org.elasticsearch.common.inject;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.spi.Element;
 import org.elasticsearch.common.inject.spi.MembersInjectorLookup;
 import org.elasticsearch.common.inject.spi.ProviderLookup;
 
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -32,7 +32,7 @@ import java.util.List;
  */
 class DeferredLookups implements Lookups {
     private final InjectorImpl injector;
-    private final List<Element> lookups = Lists.newArrayList();
+    private final List<Element> lookups = new ArrayList<>();
 
     public DeferredLookups(InjectorImpl injector) {
         this.injector = injector;
diff --git a/core/src/main/java/org/elasticsearch/common/inject/EncounterImpl.java b/core/src/main/java/org/elasticsearch/common/inject/EncounterImpl.java
index 4a06a48..2a3c419 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/EncounterImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/EncounterImpl.java
@@ -17,12 +17,12 @@
 package org.elasticsearch.common.inject;
 
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.spi.InjectionListener;
 import org.elasticsearch.common.inject.spi.Message;
 import org.elasticsearch.common.inject.spi.TypeEncounter;
 
+import java.util.ArrayList;
 import java.util.List;
 
 import static com.google.common.base.Preconditions.checkState;
@@ -64,7 +64,7 @@ final class EncounterImpl<T> implements TypeEncounter<T> {
         checkState(valid, "Encounters may not be used after hear() returns.");
 
         if (membersInjectors == null) {
-            membersInjectors = Lists.newArrayList();
+            membersInjectors = new ArrayList<>();
         }
 
         membersInjectors.add(membersInjector);
@@ -75,7 +75,7 @@ final class EncounterImpl<T> implements TypeEncounter<T> {
         checkState(valid, "Encounters may not be used after hear() returns.");
 
         if (injectionListeners == null) {
-            injectionListeners = Lists.newArrayList();
+            injectionListeners = new ArrayList<>();
         }
 
         injectionListeners.add(injectionListener);
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java b/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java
index fb14444..38b8494 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java
@@ -17,9 +17,13 @@
 package org.elasticsearch.common.inject;
 
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
-import org.elasticsearch.common.inject.internal.*;
+import org.elasticsearch.common.inject.internal.BindingImpl;
+import org.elasticsearch.common.inject.internal.Errors;
+import org.elasticsearch.common.inject.internal.InstanceBindingImpl;
+import org.elasticsearch.common.inject.internal.InternalFactory;
+import org.elasticsearch.common.inject.internal.MatcherAndConverter;
+import org.elasticsearch.common.inject.internal.SourceProvider;
 import org.elasticsearch.common.inject.spi.InjectionPoint;
 import org.elasticsearch.common.inject.spi.TypeListenerBinding;
 
@@ -43,8 +47,8 @@ class InheritingState implements State {
     private final Map<Key<?>, Binding<?>> explicitBindings
             = Collections.unmodifiableMap(explicitBindingsMutable);
     private final Map<Class<? extends Annotation>, Scope> scopes = Maps.newHashMap();
-    private final List<MatcherAndConverter> converters = Lists.newArrayList();
-    private final List<TypeListenerBinding> listenerBindings = Lists.newArrayList();
+    private final List<MatcherAndConverter> converters = new ArrayList<>();
+    private final List<TypeListenerBinding> listenerBindings = new ArrayList<>();
     private WeakKeySet blacklistedKeys = new WeakKeySet();
     private final Object lock;
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/Initializer.java b/core/src/main/java/org/elasticsearch/common/inject/Initializer.java
index 038f9b6..6ee855b 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/Initializer.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/Initializer.java
@@ -16,12 +16,12 @@
 
 package org.elasticsearch.common.inject;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.internal.ErrorsException;
 import org.elasticsearch.common.inject.spi.InjectionPoint;
 
+import java.util.ArrayList;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.CountDownLatch;
@@ -95,7 +95,7 @@ class Initializer {
     void injectAll(final Errors errors) {
         // loop over a defensive copy since ensureInjected() mutates the set. Unfortunately, that copy
         // is made complicated by a bug in IBM's JDK, wherein entrySet().toArray(Object[]) doesn't work
-        for (InjectableReference<?> reference : Lists.newArrayList(pendingInjection.values())) {
+        for (InjectableReference<?> reference : new ArrayList<>(pendingInjection.values())) {
             try {
                 reference.get(errors);
             } catch (ErrorsException e) {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InjectionRequestProcessor.java b/core/src/main/java/org/elasticsearch/common/inject/InjectionRequestProcessor.java
index 35e69d3..b645f41 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InjectionRequestProcessor.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InjectionRequestProcessor.java
@@ -17,7 +17,6 @@
 package org.elasticsearch.common.inject;
 
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.internal.ErrorsException;
 import org.elasticsearch.common.inject.internal.InternalContext;
@@ -25,6 +24,7 @@ import org.elasticsearch.common.inject.spi.InjectionPoint;
 import org.elasticsearch.common.inject.spi.InjectionRequest;
 import org.elasticsearch.common.inject.spi.StaticInjectionRequest;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
 
@@ -37,7 +37,7 @@ import java.util.Set;
  */
 class InjectionRequestProcessor extends AbstractProcessor {
 
-    private final List<StaticInjection> staticInjections = Lists.newArrayList();
+    private final List<StaticInjection> staticInjections = new ArrayList<>();
     private final Initializer initializer;
 
     InjectionRequestProcessor(Errors errors, Initializer initializer) {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InjectorImpl.java b/core/src/main/java/org/elasticsearch/common/inject/InjectorImpl.java
index 6f2540c..a804851 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InjectorImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InjectorImpl.java
@@ -18,15 +18,37 @@ package org.elasticsearch.common.inject;
 
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.elasticsearch.common.Classes;
-import org.elasticsearch.common.inject.internal.*;
-import org.elasticsearch.common.inject.spi.*;
+import org.elasticsearch.common.inject.internal.Annotations;
+import org.elasticsearch.common.inject.internal.BindingImpl;
+import org.elasticsearch.common.inject.internal.Errors;
+import org.elasticsearch.common.inject.internal.ErrorsException;
+import org.elasticsearch.common.inject.internal.InstanceBindingImpl;
+import org.elasticsearch.common.inject.internal.InternalContext;
+import org.elasticsearch.common.inject.internal.InternalFactory;
+import org.elasticsearch.common.inject.internal.LinkedBindingImpl;
+import org.elasticsearch.common.inject.internal.LinkedProviderBindingImpl;
+import org.elasticsearch.common.inject.internal.MatcherAndConverter;
+import org.elasticsearch.common.inject.internal.Nullable;
+import org.elasticsearch.common.inject.internal.Scoping;
+import org.elasticsearch.common.inject.internal.SourceProvider;
+import org.elasticsearch.common.inject.internal.ToStringBuilder;
+import org.elasticsearch.common.inject.spi.BindingTargetVisitor;
+import org.elasticsearch.common.inject.spi.ConvertedConstantBinding;
+import org.elasticsearch.common.inject.spi.Dependency;
+import org.elasticsearch.common.inject.spi.InjectionPoint;
+import org.elasticsearch.common.inject.spi.ProviderBinding;
+import org.elasticsearch.common.inject.spi.ProviderKeyBinding;
 import org.elasticsearch.common.inject.util.Providers;
 
 import java.lang.annotation.Annotation;
-import java.lang.reflect.*;
+import java.lang.reflect.GenericArrayType;
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.Modifier;
+import java.lang.reflect.ParameterizedType;
+import java.lang.reflect.Type;
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
@@ -681,7 +703,7 @@ class InjectorImpl implements Injector, Lookups {
         <T> void put(TypeLiteral<T> type, Binding<T> binding) {
             List<Binding<?>> bindingsForType = multimap.get(type);
             if (bindingsForType == null) {
-                bindingsForType = Lists.newArrayList();
+                bindingsForType = new ArrayList<>();
                 multimap.put(type, bindingsForType);
             }
             bindingsForType.add(binding);
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java b/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
index f463a24..5ac7934 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
@@ -17,10 +17,23 @@
 package org.elasticsearch.common.inject;
 
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
-import org.elasticsearch.common.inject.internal.*;
-import org.elasticsearch.common.inject.spi.*;
-
+import org.elasticsearch.common.inject.internal.Errors;
+import org.elasticsearch.common.inject.internal.ErrorsException;
+import org.elasticsearch.common.inject.internal.InternalContext;
+import org.elasticsearch.common.inject.internal.InternalFactory;
+import org.elasticsearch.common.inject.internal.PrivateElementsImpl;
+import org.elasticsearch.common.inject.internal.ProviderInstanceBindingImpl;
+import org.elasticsearch.common.inject.internal.Scoping;
+import org.elasticsearch.common.inject.internal.SourceProvider;
+import org.elasticsearch.common.inject.internal.Stopwatch;
+import org.elasticsearch.common.inject.spi.Dependency;
+import org.elasticsearch.common.inject.spi.Element;
+import org.elasticsearch.common.inject.spi.Elements;
+import org.elasticsearch.common.inject.spi.InjectionPoint;
+import org.elasticsearch.common.inject.spi.PrivateElements;
+import org.elasticsearch.common.inject.spi.TypeListenerBinding;
+
+import java.util.ArrayList;
 import java.util.List;
 import java.util.logging.Logger;
 
@@ -59,8 +72,8 @@ class InjectorShell {
     }
 
     static class Builder {
-        private final List<Element> elements = Lists.newArrayList();
-        private final List<Module> modules = Lists.newArrayList();
+        private final List<Element> elements = new ArrayList<>();
+        private final List<Module> modules = new ArrayList<>();
 
         /**
          * lazily constructed
@@ -148,7 +161,7 @@ class InjectorShell {
             bindingProcessor.process(injector, elements);
             stopwatch.resetAndLog("Binding creation");
 
-            List<InjectorShell> injectorShells = Lists.newArrayList();
+            List<InjectorShell> injectorShells = new ArrayList<>();
             injectorShells.add(new InjectorShell(this, elements, injector));
 
             // recursively build child shells
diff --git a/core/src/main/java/org/elasticsearch/common/inject/MembersInjectorStore.java b/core/src/main/java/org/elasticsearch/common/inject/MembersInjectorStore.java
index 99d0924..cd7c168 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/MembersInjectorStore.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/MembersInjectorStore.java
@@ -17,7 +17,6 @@
 package org.elasticsearch.common.inject;
 
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.internal.ErrorsException;
 import org.elasticsearch.common.inject.internal.FailableCache;
@@ -25,6 +24,7 @@ import org.elasticsearch.common.inject.spi.InjectionPoint;
 import org.elasticsearch.common.inject.spi.TypeListenerBinding;
 
 import java.lang.reflect.Field;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
 
@@ -106,7 +106,7 @@ class MembersInjectorStore {
      */
     ImmutableList<SingleMemberInjector> getInjectors(
             Set<InjectionPoint> injectionPoints, Errors errors) {
-        List<SingleMemberInjector> injectors = Lists.newArrayList();
+        List<SingleMemberInjector> injectors = new ArrayList<>();
         for (InjectionPoint injectionPoint : injectionPoints) {
             try {
                 Errors errorsForMember = injectionPoint.isOptional()
diff --git a/core/src/main/java/org/elasticsearch/common/inject/ModulesBuilder.java b/core/src/main/java/org/elasticsearch/common/inject/ModulesBuilder.java
index c65a07d..41cdecf 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/ModulesBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/ModulesBuilder.java
@@ -19,8 +19,7 @@
 
 package org.elasticsearch.common.inject;
 
-import com.google.common.collect.Lists;
-
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 
@@ -29,7 +28,7 @@ import java.util.List;
  */
 public class ModulesBuilder implements Iterable<Module> {
 
-    private final List<Module> modules = Lists.newArrayList();
+    private final List<Module> modules = new ArrayList<>();
 
     public ModulesBuilder add(Module... newModules) {
         for (Module module : newModules) {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/PrivateElementProcessor.java b/core/src/main/java/org/elasticsearch/common/inject/PrivateElementProcessor.java
index 9b0fd3d..2b7dc69 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/PrivateElementProcessor.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/PrivateElementProcessor.java
@@ -16,10 +16,10 @@
 
 package org.elasticsearch.common.inject;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.spi.PrivateElements;
 
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -30,7 +30,7 @@ import java.util.List;
 class PrivateElementProcessor extends AbstractProcessor {
 
     private final Stage stage;
-    private final List<InjectorShell.Builder> injectorShellBuilders = Lists.newArrayList();
+    private final List<InjectorShell.Builder> injectorShellBuilders = new ArrayList<>();
 
     PrivateElementProcessor(Errors errors, Stage stage) {
         super(errors);
diff --git a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/AssistedConstructor.java b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/AssistedConstructor.java
index 173abae..3973d9e 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/AssistedConstructor.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/AssistedConstructor.java
@@ -16,7 +16,6 @@
 
 package org.elasticsearch.common.inject.assistedinject;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.TypeLiteral;
 
@@ -24,7 +23,11 @@ import java.lang.annotation.Annotation;
 import java.lang.reflect.Constructor;
 import java.lang.reflect.InvocationTargetException;
 import java.lang.reflect.Type;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
 
 /**
  * Internal respresentation of a constructor annotated with
@@ -45,7 +48,7 @@ class AssistedConstructor<T> {
 
         Annotation[][] annotations = constructor.getParameterAnnotations();
 
-        List<Type> typeList = Lists.newArrayList();
+        List<Type> typeList = new ArrayList<>();
         allParameters = new ArrayList<>();
 
         // categorize params as @Assisted or @Injected
diff --git a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java
index e36fabb..cee7682 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java
@@ -18,16 +18,25 @@ package org.elasticsearch.common.inject.assistedinject;
 
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
-import org.elasticsearch.common.inject.*;
+import org.elasticsearch.common.inject.ConfigurationException;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.inject.Injector;
+import org.elasticsearch.common.inject.Key;
+import org.elasticsearch.common.inject.Provider;
+import org.elasticsearch.common.inject.TypeLiteral;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.spi.Dependency;
 import org.elasticsearch.common.inject.spi.HasDependencies;
 import org.elasticsearch.common.inject.spi.Message;
 
 import java.lang.annotation.Annotation;
-import java.lang.reflect.*;
+import java.lang.reflect.Constructor;
+import java.lang.reflect.InvocationHandler;
+import java.lang.reflect.Method;
+import java.lang.reflect.Proxy;
+import java.lang.reflect.Type;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -209,7 +218,7 @@ public class FactoryProvider<F> implements Provider<F>, HasDependencies {
 
     private static Map<Method, AssistedConstructor<?>> createMethodMapping(
             TypeLiteral<?> factoryType, TypeLiteral<?> implementationType) {
-        List<AssistedConstructor<?>> constructors = Lists.newArrayList();
+        List<AssistedConstructor<?>> constructors = new ArrayList<>();
 
         for (Constructor<?> constructor : implementationType.getRawType().getDeclaredConstructors()) {
             if (constructor.getAnnotation(AssistedInject.class) != null) {
@@ -248,7 +257,7 @@ public class FactoryProvider<F> implements Provider<F>, HasDependencies {
                         method, implementationType);
             }
 
-            List<Type> parameterTypes = Lists.newArrayList();
+            List<Type> parameterTypes = new ArrayList<>();
             for (TypeLiteral<?> parameterType : factoryType.getParameterTypes(method)) {
                 parameterTypes.add(parameterType.getType());
             }
@@ -281,7 +290,7 @@ public class FactoryProvider<F> implements Provider<F>, HasDependencies {
 
     @Override
     public Set<Dependency<?>> getDependencies() {
-        List<Dependency<?>> dependencies = Lists.newArrayList();
+        List<Dependency<?>> dependencies = new ArrayList<>();
         for (AssistedConstructor<?> constructor : factoryMethodToConstructor.values()) {
             for (Parameter parameter : constructor.getAllParameters()) {
                 if (!parameter.isProvidedByFactory()) {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
index 2bfbcef..03b1948 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
@@ -19,8 +19,17 @@ package org.elasticsearch.common.inject.assistedinject;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.Iterables;
-import com.google.common.collect.Lists;
-import org.elasticsearch.common.inject.*;
+import org.elasticsearch.common.inject.AbstractModule;
+import org.elasticsearch.common.inject.Binder;
+import org.elasticsearch.common.inject.Binding;
+import org.elasticsearch.common.inject.ConfigurationException;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.inject.Injector;
+import org.elasticsearch.common.inject.Key;
+import org.elasticsearch.common.inject.Module;
+import org.elasticsearch.common.inject.Provider;
+import org.elasticsearch.common.inject.ProvisionException;
+import org.elasticsearch.common.inject.TypeLiteral;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.internal.ErrorsException;
 import org.elasticsearch.common.inject.spi.Message;
@@ -30,6 +39,7 @@ import java.lang.annotation.Annotation;
 import java.lang.reflect.InvocationHandler;
 import java.lang.reflect.Method;
 import java.lang.reflect.Proxy;
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 
@@ -118,7 +128,7 @@ final class FactoryProvider2<F> implements InvocationHandler, Provider<F> {
                 List<TypeLiteral<?>> params = factoryType.getParameterTypes(method);
                 Annotation[][] paramAnnotations = method.getParameterAnnotations();
                 int p = 0;
-                List<Key<?>> keys = Lists.newArrayList();
+                List<Key<?>> keys = new ArrayList<>();
                 for (TypeLiteral<?> param : params) {
                     Key<?> paramKey = getKey(param, method, paramAnnotations[p++], errors);
                     keys.add(assistKey(method, paramKey, errors));
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/Errors.java b/core/src/main/java/org/elasticsearch/common/inject/internal/Errors.java
index e898007..d3a73b3 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/Errors.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/Errors.java
@@ -18,10 +18,20 @@ package org.elasticsearch.common.inject.internal;
 
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
 import org.apache.lucene.util.CollectionUtil;
-import org.elasticsearch.common.inject.*;
-import org.elasticsearch.common.inject.spi.*;
+import org.elasticsearch.common.inject.ConfigurationException;
+import org.elasticsearch.common.inject.CreationException;
+import org.elasticsearch.common.inject.Key;
+import org.elasticsearch.common.inject.MembersInjector;
+import org.elasticsearch.common.inject.Provider;
+import org.elasticsearch.common.inject.ProvisionException;
+import org.elasticsearch.common.inject.Scope;
+import org.elasticsearch.common.inject.TypeLiteral;
+import org.elasticsearch.common.inject.spi.Dependency;
+import org.elasticsearch.common.inject.spi.InjectionListener;
+import org.elasticsearch.common.inject.spi.InjectionPoint;
+import org.elasticsearch.common.inject.spi.Message;
+import org.elasticsearch.common.inject.spi.TypeListenerBinding;
 
 import java.io.PrintWriter;
 import java.io.Serializable;
@@ -31,7 +41,12 @@ import java.lang.reflect.Constructor;
 import java.lang.reflect.Field;
 import java.lang.reflect.Member;
 import java.lang.reflect.Type;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Comparator;
+import java.util.Formatter;
+import java.util.List;
+import java.util.Locale;
 
 /**
  * A collection of error messages. If this type is passed as a method parameter, the method is
@@ -361,7 +376,7 @@ public final class Errors implements Serializable {
     }
 
     private Message merge(Message message) {
-        List<Object> sources = Lists.newArrayList();
+        List<Object> sources = new ArrayList<>();
         sources.addAll(getSources());
         sources.addAll(message.getSources());
         return new Message(sources, message.getMessage(), message.getCause());
@@ -384,7 +399,7 @@ public final class Errors implements Serializable {
     }
 
     public List<Object> getSources() {
-        List<Object> sources = Lists.newArrayList();
+        List<Object> sources = new ArrayList<>();
         for (Errors e = this; e != null; e = e.parent) {
             if (e.source != SourceProvider.UNKNOWN_SOURCE) {
                 sources.add(0, e.source);
@@ -421,7 +436,7 @@ public final class Errors implements Serializable {
 
     public Errors addMessage(Message message) {
         if (root.errors == null) {
-            root.errors = Lists.newArrayList();
+            root.errors = new ArrayList<>();
         }
         root.errors.add(message);
         return this;
@@ -439,7 +454,7 @@ public final class Errors implements Serializable {
             return ImmutableList.of();
         }
 
-        List<Message> result = Lists.newArrayList(root.errors);
+        List<Message> result = new ArrayList<>(root.errors);
         CollectionUtil.timSort(result, new Comparator<Message>() {
             @Override
             public int compare(Message a, Message b) {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/Join.java b/core/src/main/java/org/elasticsearch/common/inject/internal/Join.java
index fd8348d..6500599 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/Join.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/Join.java
@@ -16,7 +16,7 @@
 
 package org.elasticsearch.common.inject.internal;
 
-import com.google.common.collect.Lists;
+import org.elasticsearch.common.util.CollectionUtils;
 
 import java.io.IOException;
 import java.util.Arrays;
@@ -98,7 +98,7 @@ public final class Join {
     public static String join(
             String delimiter, @Nullable Object firstToken, Object... otherTokens) {
         checkNotNull(otherTokens);
-        return join(delimiter, Lists.newArrayList(firstToken, otherTokens));
+        return join(delimiter, CollectionUtils.asArrayList(firstToken, otherTokens));
     }
 
     /**
@@ -208,7 +208,7 @@ public final class Join {
     public static <T extends Appendable> T join(T appendable, String delimiter,
                                                 @Nullable Object firstToken, Object... otherTokens) {
         checkNotNull(otherTokens);
-        return join(appendable, delimiter, Lists.newArrayList(firstToken, otherTokens));
+        return join(appendable, delimiter, CollectionUtils.asArrayList(firstToken, otherTokens));
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java b/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
index 0e6a33f..59b5aaa 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
@@ -18,7 +18,6 @@ package org.elasticsearch.common.inject.internal;
 
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Injector;
@@ -28,6 +27,7 @@ import org.elasticsearch.common.inject.spi.Element;
 import org.elasticsearch.common.inject.spi.ElementVisitor;
 import org.elasticsearch.common.inject.spi.PrivateElements;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -47,8 +47,8 @@ public final class PrivateElementsImpl implements PrivateElements {
 
     private final Object source;
 
-    private List<Element> elementsMutable = Lists.newArrayList();
-    private List<ExposureBuilder<?>> exposureBuilders = Lists.newArrayList();
+    private List<Element> elementsMutable = new ArrayList<>();
+    private List<ExposureBuilder<?>> exposureBuilders = new ArrayList<>();
 
     /**
      * lazily instantiated
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java b/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java
index 4670530..9884b88 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java
@@ -17,8 +17,12 @@
 package org.elasticsearch.common.inject.internal;
 
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
-import org.elasticsearch.common.inject.*;
+import org.elasticsearch.common.inject.Binder;
+import org.elasticsearch.common.inject.Key;
+import org.elasticsearch.common.inject.Module;
+import org.elasticsearch.common.inject.Provider;
+import org.elasticsearch.common.inject.Provides;
+import org.elasticsearch.common.inject.TypeLiteral;
 import org.elasticsearch.common.inject.spi.Dependency;
 import org.elasticsearch.common.inject.spi.Message;
 import org.elasticsearch.common.inject.util.Modules;
@@ -26,6 +30,7 @@ import org.elasticsearch.common.inject.util.Modules;
 import java.lang.annotation.Annotation;
 import java.lang.reflect.Member;
 import java.lang.reflect.Method;
+import java.util.ArrayList;
 import java.util.List;
 
 import static com.google.common.base.Preconditions.checkNotNull;
@@ -74,7 +79,7 @@ public final class ProviderMethodsModule implements Module {
     }
 
     public List<ProviderMethod<?>> getProviderMethods(Binder binder) {
-        List<ProviderMethod<?>> result = Lists.newArrayList();
+        List<ProviderMethod<?>> result = new ArrayList<>();
         for (Class<?> c = delegate.getClass(); c != Object.class; c = c.getSuperclass()) {
             for (Method method : c.getDeclaredMethods()) {
                 if (method.getAnnotation(Provides.class) != null) {
@@ -90,8 +95,8 @@ public final class ProviderMethodsModule implements Module {
         Errors errors = new Errors(method);
 
         // prepare the parameter providers
-        List<Dependency<?>> dependencies = Lists.newArrayList();
-        List<Provider<?>> parameterProviders = Lists.newArrayList();
+        List<Dependency<?>> dependencies = new ArrayList<>();
+        List<Provider<?>> parameterProviders = new ArrayList<>();
         List<TypeLiteral<?>> parameterTypes = typeLiteral.getParameterTypes(method);
         Annotation[][] parameterAnnotations = method.getParameterAnnotations();
         for (int i = 0; i < parameterTypes.size(); i++) {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java b/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java
index 4c34be0..f0fa05c 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java
@@ -18,8 +18,8 @@ package org.elasticsearch.common.inject.internal;
 
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Iterables;
-import com.google.common.collect.Lists;
 
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -58,7 +58,7 @@ public class SourceProvider {
      * Returns the class names as Strings
      */
     private static List<String> asStrings(Class... classes) {
-        List<String> strings = Lists.newArrayList();
+        List<String> strings = new ArrayList<>();
         for (Class c : classes) {
             strings.add(c.getName());
         }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java b/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java
index fac73d3..0fb64a4 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java
@@ -18,8 +18,15 @@ package org.elasticsearch.common.inject.multibindings;
 
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
-import org.elasticsearch.common.inject.*;
+import org.elasticsearch.common.inject.Binder;
+import org.elasticsearch.common.inject.Binding;
+import org.elasticsearch.common.inject.ConfigurationException;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.inject.Injector;
+import org.elasticsearch.common.inject.Key;
+import org.elasticsearch.common.inject.Module;
+import org.elasticsearch.common.inject.Provider;
+import org.elasticsearch.common.inject.TypeLiteral;
 import org.elasticsearch.common.inject.binder.LinkedBindingBuilder;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.spi.Dependency;
@@ -29,6 +36,7 @@ import org.elasticsearch.common.inject.util.Types;
 
 import java.lang.annotation.Annotation;
 import java.lang.reflect.Type;
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.LinkedHashSet;
 import java.util.List;
@@ -229,8 +237,8 @@ public abstract class Multibinder<T> {
          */
         @Inject
         void initialize(Injector injector) {
-            providers = Lists.newArrayList();
-            List<Dependency<?>> dependencies = Lists.newArrayList();
+            providers = new ArrayList<>();
+            List<Dependency<?>> dependencies = new ArrayList<>();
             for (Binding<?> entry : injector.findBindingsByType(elementType)) {
 
                 if (keyMatches(entry.getKey())) {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/Dependency.java b/core/src/main/java/org/elasticsearch/common/inject/spi/Dependency.java
index f0891f5..8f1ce52 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/Dependency.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/Dependency.java
@@ -18,9 +18,9 @@ package org.elasticsearch.common.inject.spi;
 
 import com.google.common.base.Objects;
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.inject.Key;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
 
@@ -60,7 +60,7 @@ public final class Dependency<T> {
      * Returns the dependencies from the given injection points.
      */
     public static Set<Dependency<?>> forInjectionPoints(Set<InjectionPoint> injectionPoints) {
-        List<Dependency<?>> dependencies = Lists.newArrayList();
+        List<Dependency<?>> dependencies = new ArrayList<>();
         for (InjectionPoint injectionPoint : injectionPoints) {
             dependencies.addAll(injectionPoint.getDependencies());
         }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java b/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java
index c6dc1e4..9652236 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java
@@ -17,19 +17,41 @@
 package org.elasticsearch.common.inject.spi;
 
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
-import org.elasticsearch.common.inject.*;
+import org.elasticsearch.common.inject.AbstractModule;
+import org.elasticsearch.common.inject.Binder;
+import org.elasticsearch.common.inject.Binding;
+import org.elasticsearch.common.inject.Key;
+import org.elasticsearch.common.inject.MembersInjector;
+import org.elasticsearch.common.inject.Module;
+import org.elasticsearch.common.inject.PrivateBinder;
+import org.elasticsearch.common.inject.PrivateModule;
+import org.elasticsearch.common.inject.Provider;
+import org.elasticsearch.common.inject.Scope;
+import org.elasticsearch.common.inject.Stage;
+import org.elasticsearch.common.inject.TypeLiteral;
 import org.elasticsearch.common.inject.binder.AnnotatedBindingBuilder;
 import org.elasticsearch.common.inject.binder.AnnotatedConstantBindingBuilder;
 import org.elasticsearch.common.inject.binder.AnnotatedElementBuilder;
-import org.elasticsearch.common.inject.internal.*;
+import org.elasticsearch.common.inject.internal.AbstractBindingBuilder;
+import org.elasticsearch.common.inject.internal.BindingBuilder;
+import org.elasticsearch.common.inject.internal.ConstantBindingBuilderImpl;
+import org.elasticsearch.common.inject.internal.Errors;
+import org.elasticsearch.common.inject.internal.ExposureBuilder;
+import org.elasticsearch.common.inject.internal.PrivateElementsImpl;
+import org.elasticsearch.common.inject.internal.ProviderMethodsModule;
+import org.elasticsearch.common.inject.internal.SourceProvider;
 import org.elasticsearch.common.inject.matcher.Matcher;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 
 import java.lang.annotation.Annotation;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.List;
+import java.util.Set;
 
 import static com.google.common.base.Preconditions.checkArgument;
 
@@ -121,7 +143,7 @@ public final class Elements {
         private RecordingBinder(Stage stage) {
             this.stage = stage;
             this.modules = Sets.newHashSet();
-            this.elements = Lists.newArrayList();
+            this.elements = new ArrayList<>();
             this.source = null;
             this.sourceProvider = new SourceProvider().plusSkippedClasses(
                     Elements.class, RecordingBinder.class, AbstractModule.class,
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionPoint.java b/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionPoint.java
index 8aef647..aa7e079 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionPoint.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionPoint.java
@@ -18,16 +18,29 @@ package org.elasticsearch.common.inject.spi;
 
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.inject.ConfigurationException;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.Key;
 import org.elasticsearch.common.inject.TypeLiteral;
-import org.elasticsearch.common.inject.internal.*;
+import org.elasticsearch.common.inject.internal.Annotations;
+import org.elasticsearch.common.inject.internal.Errors;
+import org.elasticsearch.common.inject.internal.ErrorsException;
+import org.elasticsearch.common.inject.internal.MoreTypes;
+import org.elasticsearch.common.inject.internal.Nullability;
 
 import java.lang.annotation.Annotation;
-import java.lang.reflect.*;
-import java.util.*;
+import java.lang.reflect.AnnotatedElement;
+import java.lang.reflect.Constructor;
+import java.lang.reflect.Field;
+import java.lang.reflect.Member;
+import java.lang.reflect.Method;
+import java.lang.reflect.Modifier;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Set;
 
 import static org.elasticsearch.common.inject.internal.MoreTypes.getRawType;
 
@@ -93,7 +106,7 @@ public final class InjectionPoint {
         Errors errors = new Errors(member);
         Iterator<Annotation[]> annotationsIterator = Arrays.asList(parameterAnnotations).iterator();
 
-        List<Dependency<?>> dependencies = Lists.newArrayList();
+        List<Dependency<?>> dependencies = new ArrayList<>();
         int index = 0;
 
         for (TypeLiteral<?> parameterType : type.getParameterTypes(member)) {
@@ -240,7 +253,7 @@ public final class InjectionPoint {
      *                                of the valid injection points.
      */
     public static Set<InjectionPoint> forStaticMethodsAndFields(TypeLiteral type) {
-        List<InjectionPoint> sink = Lists.newArrayList();
+        List<InjectionPoint> sink = new ArrayList<>();
         Errors errors = new Errors();
 
         addInjectionPoints(type, Factory.FIELDS, true, sink, errors);
@@ -280,7 +293,7 @@ public final class InjectionPoint {
      *                                of the valid injection points.
      */
     public static Set<InjectionPoint> forInstanceMethodsAndFields(TypeLiteral<?> type) {
-        List<InjectionPoint> sink = Lists.newArrayList();
+        List<InjectionPoint> sink = new ArrayList<>();
         Errors errors = new Errors();
 
         // TODO (crazybob): Filter out overridden members.
diff --git a/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java b/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java
index ae22058..2849cc4 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java
@@ -17,13 +17,24 @@
 package org.elasticsearch.common.inject.util;
 
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
-import org.elasticsearch.common.inject.*;
-import org.elasticsearch.common.inject.spi.*;
+import org.elasticsearch.common.inject.AbstractModule;
+import org.elasticsearch.common.inject.Binder;
+import org.elasticsearch.common.inject.Binding;
+import org.elasticsearch.common.inject.Key;
+import org.elasticsearch.common.inject.Module;
+import org.elasticsearch.common.inject.PrivateBinder;
+import org.elasticsearch.common.inject.Scope;
+import org.elasticsearch.common.inject.spi.DefaultBindingScopingVisitor;
+import org.elasticsearch.common.inject.spi.DefaultElementVisitor;
+import org.elasticsearch.common.inject.spi.Element;
+import org.elasticsearch.common.inject.spi.Elements;
+import org.elasticsearch.common.inject.spi.PrivateElements;
+import org.elasticsearch.common.inject.spi.ScopeBinding;
 
 import java.lang.annotation.Annotation;
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 import java.util.Map;
@@ -168,7 +179,7 @@ public final class Modules {
                     // overridden binding once so things still blow up if the module binds the same thing
                     // multiple times.
                     final Map<Scope, Object> scopeInstancesInUse = Maps.newHashMap();
-                    final List<ScopeBinding> scopeBindings = Lists.newArrayList();
+                    final List<ScopeBinding> scopeBindings = new ArrayList<>();
                     new ModuleWriter(binder()) {
                         @Override
                         public <T> Void visit(Binding<T> binding) {
diff --git a/core/src/main/java/org/elasticsearch/common/io/Streams.java b/core/src/main/java/org/elasticsearch/common/io/Streams.java
index 166e796..e6265ab 100644
--- a/core/src/main/java/org/elasticsearch/common/io/Streams.java
+++ b/core/src/main/java/org/elasticsearch/common/io/Streams.java
@@ -21,10 +21,17 @@ package org.elasticsearch.common.io;
 
 import com.google.common.base.Charsets;
 import com.google.common.base.Preconditions;
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.util.Callback;
 
-import java.io.*;
+import java.io.BufferedReader;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.OutputStream;
+import java.io.Reader;
+import java.io.StringWriter;
+import java.io.Writer;
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -216,7 +223,7 @@ public abstract class Streams {
     }
 
     public static List<String> readAllLines(InputStream input) throws IOException {
-        final List<String> lines = Lists.newArrayList();
+        final List<String> lines = new ArrayList<>();
         readAllLines(input, new Callback<String>() {
             @Override
             public void handle(String line) {
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java b/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java
index 5f3bd01..0dac786 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java
@@ -68,4 +68,4 @@ public abstract class FilterStreamInput extends StreamInput {
     public void setVersion(Version version) {
         delegate.setVersion(version);
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
index c2bbaa3..1b22a69 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
@@ -33,7 +33,6 @@ import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.text.StringAndBytesText;
 import org.elasticsearch.common.text.Text;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.joda.time.DateTime;
 import org.joda.time.DateTimeZone;
 
@@ -46,18 +45,8 @@ import static org.elasticsearch.ElasticsearchException.readStackTrace;
 
 public abstract class StreamInput extends InputStream {
 
-    private final NamedWriteableRegistry namedWriteableRegistry;
-
     private Version version = Version.CURRENT;
 
-    protected StreamInput() {
-        this.namedWriteableRegistry = new NamedWriteableRegistry();
-    }
-
-    protected StreamInput(NamedWriteableRegistry namedWriteableRegistry) {
-        this.namedWriteableRegistry = namedWriteableRegistry;
-    }
-
     public Version getVersion() {
         return this.version;
     }
@@ -572,13 +561,6 @@ public abstract class StreamInput extends InputStream {
         throw new UnsupportedOperationException();
     }
 
-    /**
-     * Reads a {@link QueryBuilder} from the current stream
-     */
-    public QueryBuilder readQuery() throws IOException {
-        return readNamedWriteable(QueryBuilder.class);
-    }
-
     public static StreamInput wrap(BytesReference reference) {
         if (reference.hasArray() == false) {
             reference = reference.toBytesArray();
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java b/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
index 9e449d6..8ce9e24 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
@@ -32,7 +32,6 @@ import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.text.Text;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.joda.time.ReadableInstant;
 
 import java.io.EOFException;
@@ -625,11 +624,4 @@ public abstract class StreamOutput extends OutputStream {
         writeString(namedWriteable.getWriteableName());
         namedWriteable.writeTo(this);
     }
-
-    /**
-     * Writes a {@link QueryBuilder} to the current stream
-     */
-    public void writeQuery(QueryBuilder queryBuilder) throws IOException {
-        writeNamedWriteable(queryBuilder);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/logging/Loggers.java b/core/src/main/java/org/elasticsearch/common/logging/Loggers.java
index 93d4cc3..1dafcff 100644
--- a/core/src/main/java/org/elasticsearch/common/logging/Loggers.java
+++ b/core/src/main/java/org/elasticsearch/common/logging/Loggers.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.common.logging;
 
-import com.google.common.collect.Lists;
 import org.apache.lucene.util.SuppressForbidden;
 import org.elasticsearch.common.Classes;
 import org.elasticsearch.common.settings.Settings;
@@ -28,10 +27,11 @@ import org.elasticsearch.index.shard.ShardId;
 
 import java.net.InetAddress;
 import java.net.UnknownHostException;
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static java.util.Arrays.asList;
+import static org.elasticsearch.common.util.CollectionUtils.asArrayList;
 
 /**
  * A set of utilities around Logging.
@@ -59,16 +59,16 @@ public class Loggers {
     }
 
     public static ESLogger getLogger(Class clazz, Settings settings, ShardId shardId, String... prefixes) {
-        return getLogger(clazz, settings, shardId.index(), Lists.asList(Integer.toString(shardId.id()), prefixes).toArray(new String[0]));
+        return getLogger(clazz, settings, shardId.index(), asArrayList(Integer.toString(shardId.id()), prefixes).toArray(new String[0]));
     }
 
     /** Just like {@link #getLogger(Class, org.elasticsearch.common.settings.Settings,ShardId,String...)} but String loggerName instead of Class. */
     public static ESLogger getLogger(String loggerName, Settings settings, ShardId shardId, String... prefixes) {
-        return getLogger(loggerName, settings, Lists.asList(shardId.index().name(), Integer.toString(shardId.id()), prefixes).toArray(new String[0]));
+        return getLogger(loggerName, settings, asArrayList(shardId.index().name(), Integer.toString(shardId.id()), prefixes).toArray(new String[0]));
     }
 
     public static ESLogger getLogger(Class clazz, Settings settings, Index index, String... prefixes) {
-        return getLogger(clazz, settings, Lists.asList(SPACE, index.name(), prefixes).toArray(new String[0]));
+        return getLogger(clazz, settings, asArrayList(SPACE, index.name(), prefixes).toArray(new String[0]));
     }
 
     public static ESLogger getLogger(Class clazz, Settings settings, String... prefixes) {
@@ -86,7 +86,7 @@ public class Loggers {
 
     @SuppressForbidden(reason = "do not know what this method does")
     public static ESLogger getLogger(String loggerName, Settings settings, String... prefixes) {
-        List<String> prefixesList = newArrayList();
+        List<String> prefixesList = new ArrayList<>();
         if (settings.getAsBoolean("logger.logHostAddress", false)) {
             final InetAddress addr = getHostAddress();
             if (addr != null) {
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java
index 4c1e7c4..600c238 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java
@@ -20,46 +20,14 @@
 package org.elasticsearch.common.lucene;
 
 import com.google.common.collect.Iterables;
-
 import org.apache.lucene.analysis.core.KeywordAnalyzer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.codecs.CodecUtil;
 import org.apache.lucene.codecs.DocValuesFormat;
 import org.apache.lucene.codecs.PostingsFormat;
-import org.apache.lucene.index.CorruptIndexException;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexCommit;
-import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.index.IndexFormatTooNewException;
-import org.apache.lucene.index.IndexFormatTooOldException;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.NoMergePolicy;
-import org.apache.lucene.index.SegmentCommitInfo;
-import org.apache.lucene.index.SegmentInfos;
-import org.apache.lucene.search.Collector;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.FieldDoc;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.LeafCollector;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.SimpleCollector;
-import org.apache.lucene.search.SortField;
-import org.apache.lucene.search.TimeLimitingCollector;
-import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.search.TopFieldDocs;
-import org.apache.lucene.search.TwoPhaseIterator;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.IOContext;
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.store.Lock;
-import org.apache.lucene.store.LockObtainFailedException;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.*;
+import org.apache.lucene.store.*;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.Counter;
@@ -75,14 +43,11 @@ import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.index.analysis.AnalyzerScope;
 import org.elasticsearch.index.analysis.NamedAnalyzer;
 import org.elasticsearch.index.fielddata.IndexFieldData;
+import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 import java.text.ParseException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 
 import static org.elasticsearch.common.lucene.search.NoopCollector.NOOP_COLLECTOR;
 
@@ -380,6 +345,24 @@ public class Lucene {
     }
 
     /**
+     * Performs an exists (count > 0) query on the searcher from the <code>searchContext</code> for <code>query</code>
+     * using the given <code>collector</code>
+     *
+     * The <code>collector</code> can be instantiated using <code>Lucene.createExistsCollector()</code>
+     */
+    public static boolean exists(SearchContext searchContext, Query query, EarlyTerminatingCollector collector) throws IOException {
+        collector.reset();
+        try {
+            searchContext.searcher().search(query, collector);
+        } catch (EarlyTerminationException e) {
+            // ignore, just early termination...
+        } finally {
+            searchContext.clearReleasables(SearchContext.Lifetime.COLLECTION);
+        }
+        return collector.exists();
+    }
+
+    /**
      * Creates an {@link org.elasticsearch.common.lucene.Lucene.EarlyTerminatingCollector}
      * with a threshold of <code>1</code>
      */
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/all/AllEntries.java b/core/src/main/java/org/elasticsearch/common/lucene/all/AllEntries.java
index fb6ebc2..5106cda 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/all/AllEntries.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/all/AllEntries.java
@@ -19,12 +19,12 @@
 
 package org.elasticsearch.common.lucene.all;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.io.FastCharArrayWriter;
 import org.elasticsearch.common.io.FastStringReader;
 
 import java.io.IOException;
 import java.io.Reader;
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
@@ -66,7 +66,7 @@ public class AllEntries extends Reader {
         }
     }
 
-    private final List<Entry> entries = Lists.newArrayList();
+    private final List<Entry> entries = new ArrayList<>();
 
     private Entry current;
 
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/index/FilterableTermsEnum.java b/core/src/main/java/org/elasticsearch/common/lucene/index/FilterableTermsEnum.java
index 52b102e..8e8c47c 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/index/FilterableTermsEnum.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/index/FilterableTermsEnum.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.common.lucene.index;
 
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.PostingsEnum;
@@ -37,6 +35,7 @@ import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.Nullable;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -79,7 +78,7 @@ public class FilterableTermsEnum extends TermsEnum {
             numDocs = reader.maxDoc();
         }
         List<LeafReaderContext> leaves = reader.leaves();
-        List<Holder> enums = Lists.newArrayListWithExpectedSize(leaves.size());
+        List<Holder> enums = new ArrayList<>(leaves.size());
         final Weight weight;
         if (filter == null) {
             weight = null;
diff --git a/core/src/main/java/org/elasticsearch/common/settings/Settings.java b/core/src/main/java/org/elasticsearch/common/settings/Settings.java
index 13383d6..096432d 100644
--- a/core/src/main/java/org/elasticsearch/common/settings/Settings.java
+++ b/core/src/main/java/org/elasticsearch/common/settings/Settings.java
@@ -24,7 +24,6 @@ import com.google.common.base.Predicate;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSortedMap;
 import com.google.common.collect.Iterables;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.Booleans;
@@ -35,17 +34,31 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.property.PropertyPlaceholder;
 import org.elasticsearch.common.settings.loader.SettingsLoader;
 import org.elasticsearch.common.settings.loader.SettingsLoaderFactory;
-import org.elasticsearch.common.unit.*;
+import org.elasticsearch.common.unit.ByteSizeUnit;
+import org.elasticsearch.common.unit.ByteSizeValue;
+import org.elasticsearch.common.unit.MemorySizeValue;
+import org.elasticsearch.common.unit.RatioValue;
+import org.elasticsearch.common.unit.SizeValue;
+import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
-import java.net.URL;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Properties;
+import java.util.Set;
 import java.util.concurrent.TimeUnit;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
@@ -180,7 +193,7 @@ public final class Settings implements ToXContent {
             }
         }
         if (isArray && (maxIndex + 1) == map.size()) {
-            ArrayList<Object> newValue = Lists.newArrayListWithExpectedSize(maxIndex + 1);
+            ArrayList<Object> newValue = new ArrayList<>(maxIndex + 1);
             for (int i = 0; i <= maxIndex; i++) {
                 Object obj = map.get(Integer.toString(i));
                 if (obj == null) {
@@ -558,7 +571,7 @@ public final class Settings implements ToXContent {
      * @throws org.elasticsearch.common.settings.SettingsException
      */
     public String[] getAsArray(String settingPrefix, String[] defaultArray, Boolean commaDelimited) throws SettingsException {
-        List<String> result = Lists.newArrayList();
+        List<String> result = new ArrayList<>();
 
         if (get(settingPrefix) != null) {
             if (commaDelimited) {
diff --git a/core/src/main/java/org/elasticsearch/common/settings/SettingsFilter.java b/core/src/main/java/org/elasticsearch/common/settings/SettingsFilter.java
index 56739c0..d2bde25 100644
--- a/core/src/main/java/org/elasticsearch/common/settings/SettingsFilter.java
+++ b/core/src/main/java/org/elasticsearch/common/settings/SettingsFilter.java
@@ -25,14 +25,13 @@ import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.xcontent.ToXContent.Params;
 import org.elasticsearch.rest.RestRequest;
 
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Map.Entry;
 import java.util.concurrent.CopyOnWriteArrayList;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  *
  */
@@ -89,7 +88,7 @@ public class SettingsFilter extends AbstractComponent {
     public static Settings filterSettings(String patterns, Settings settings) {
         String[] patternArray = Strings.delimitedListToStringArray(patterns, ",");
         Settings.Builder builder = Settings.settingsBuilder().put(settings);
-        List<String> simpleMatchPatternList = newArrayList();
+        List<String> simpleMatchPatternList = new ArrayList<>();
         for (String pattern : patternArray) {
             if (Regex.isSimpleMatchPattern(pattern)) {
                 simpleMatchPatternList.add(pattern);
diff --git a/core/src/main/java/org/elasticsearch/common/settings/loader/SettingsLoader.java b/core/src/main/java/org/elasticsearch/common/settings/loader/SettingsLoader.java
index 86e905e..3760f3f 100644
--- a/core/src/main/java/org/elasticsearch/common/settings/loader/SettingsLoader.java
+++ b/core/src/main/java/org/elasticsearch/common/settings/loader/SettingsLoader.java
@@ -22,10 +22,10 @@ package org.elasticsearch.common.settings.loader;
 import org.elasticsearch.common.Nullable;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.newHashMap;
 
 /**
@@ -42,7 +42,7 @@ public interface SettingsLoader {
                 return settings;
             }
             StringBuilder sb = new StringBuilder();
-            List<String> path = newArrayList();
+            List<String> path = new ArrayList<>();
             serializeMap(settings, sb, path, map);
             return settings;
         }
diff --git a/core/src/main/java/org/elasticsearch/common/settings/loader/XContentSettingsLoader.java b/core/src/main/java/org/elasticsearch/common/settings/loader/XContentSettingsLoader.java
index 23c5d44..945e829 100644
--- a/core/src/main/java/org/elasticsearch/common/settings/loader/XContentSettingsLoader.java
+++ b/core/src/main/java/org/elasticsearch/common/settings/loader/XContentSettingsLoader.java
@@ -25,10 +25,10 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentType;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.newHashMap;
 
 /**
@@ -56,7 +56,7 @@ public abstract class XContentSettingsLoader implements SettingsLoader {
     public Map<String, String> load(XContentParser jp) throws IOException {
         StringBuilder sb = new StringBuilder();
         Map<String, String> settings = newHashMap();
-        List<String> path = newArrayList();
+        List<String> path = new ArrayList<>();
         XContentParser.Token token = jp.nextToken();
         if (token == null) {
             return settings;
diff --git a/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java b/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
index bc48042..cfcd209 100644
--- a/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
+++ b/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
@@ -19,26 +19,22 @@
 package org.elasticsearch.common.unit;
 
 import com.google.common.base.Preconditions;
-
+import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.util.automaton.LevenshteinAutomata;
 import org.elasticsearch.common.ParseField;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentBuilderString;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
-import java.util.Locale;
-import java.util.Objects;
 
 /**
  * A unit class that encapsulates all in-exact search
  * parsing and conversion from similarities to edit distances
  * etc.
  */
-public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
+public final class Fuzziness implements ToXContent {
 
     public static final XContentBuilderString X_FIELD_NAME = new XContentBuilderString("fuzziness");
     public static final Fuzziness ZERO = new Fuzziness(0);
@@ -49,20 +45,13 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
 
     private final String fuzziness;
 
-    /** the prototype constant is intended for deserialization when used with
-     * {@link org.elasticsearch.common.io.stream.StreamableReader#readFrom(StreamInput)} */
-    static final Fuzziness PROTOTYPE = AUTO;
-
     private Fuzziness(int fuzziness) {
         Preconditions.checkArgument(fuzziness >= 0 && fuzziness <= 2, "Valid edit distances are [0, 1, 2] but was [" + fuzziness + "]");
         this.fuzziness = Integer.toString(fuzziness);
     }
 
     private Fuzziness(String fuzziness) {
-        if (fuzziness == null) {
-            throw new IllegalArgumentException("fuzziness can't be null!");
-        }
-        this.fuzziness = fuzziness.toUpperCase(Locale.ROOT);
+        this.fuzziness = fuzziness;
     }
 
     /**
@@ -132,7 +121,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public int asDistance(String text) {
-        if (this.equals(AUTO)) { //AUTO
+        if (this == AUTO) { //AUTO
             final int len = termLen(text);
             if (len <= 2) {
                 return 0;
@@ -146,7 +135,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public TimeValue asTimeValue() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return TimeValue.timeValueMillis(1);
         } else {
             return TimeValue.parseTimeValue(fuzziness.toString(), null, "fuzziness");
@@ -154,7 +143,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public long asLong() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -165,7 +154,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public int asInt() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -176,7 +165,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public short asShort() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -187,7 +176,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public byte asByte() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -198,14 +187,14 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public double asDouble() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1d;
         }
         return Double.parseDouble(fuzziness.toString());
     }
 
     public float asFloat() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1f;
         }
         return Float.parseFloat(fuzziness.toString());
@@ -218,35 +207,4 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     public String asString() {
         return fuzziness.toString();
     }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (obj == null || getClass() != obj.getClass()) {
-            return false;
-        }
-        Fuzziness other = (Fuzziness) obj;
-        return Objects.equals(fuzziness, other.fuzziness);
-    }
-
-    @Override
-    public int hashCode() {
-        return fuzziness.hashCode();
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeString(fuzziness);
-    }
-
-    @Override
-    public Fuzziness readFrom(StreamInput in) throws IOException {
-        return new Fuzziness(in.readString());
-    }
-
-    public static Fuzziness readFuzzinessFrom(StreamInput in) throws IOException {
-        return PROTOTYPE.readFrom(in);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java b/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java
index 48150c7..17d78dc 100644
--- a/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java
+++ b/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java
@@ -23,14 +23,25 @@ import com.carrotsearch.hppc.DoubleArrayList;
 import com.carrotsearch.hppc.FloatArrayList;
 import com.carrotsearch.hppc.LongArrayList;
 import com.carrotsearch.hppc.ObjectArrayList;
+import com.google.common.base.Function;
 import com.google.common.base.Preconditions;
-import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Iterators;
-import com.google.common.collect.Lists;
-import org.apache.lucene.util.*;
-import org.elasticsearch.common.inject.Module;
-
-import java.util.*;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.BytesRefArray;
+import org.apache.lucene.util.BytesRefBuilder;
+import org.apache.lucene.util.InPlaceMergeSorter;
+import org.apache.lucene.util.IntroSorter;
+
+import java.util.AbstractList;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.RandomAccess;
 
 /** Collections-related utility methods. */
 public enum CollectionUtils {
@@ -368,8 +379,102 @@ public enum CollectionUtils {
         return Iterators.<T>concat(iterators);
     }
 
-    public static <E> ArrayList<E> newArrayList(E... elements) {
-        return Lists.newArrayList(elements);
+    public static <E> ArrayList<E> iterableAsArrayList(Iterable<? extends E> elements) {
+        if (elements == null) {
+            throw new NullPointerException("elements");
+        }
+        if (elements instanceof Collection) {
+            return new ArrayList<>((Collection)elements);
+        } else {
+            ArrayList<E> list = new ArrayList<>();
+            for (E element : elements) {
+                list.add(element);
+            }
+            return list;
+        }
+    }
+
+    public static <E, T> List<T> eagerTransform(List<E> list, Function<E, T> transform) {
+        if (list == null) {
+            throw new NullPointerException("list");
+        }
+        if (transform == null) {
+            throw new NullPointerException("transform");
+        }
+        List<T> result = new ArrayList<>(list.size());
+        for (E element : list) {
+            result.add(transform.apply(element));
+        }
+        return result;
+    }
+
+    public static <E> ArrayList<E> arrayAsArrayList(E... elements) {
+        if (elements == null) {
+            throw new NullPointerException("elements");
+        }
+        return new ArrayList<>(Arrays.asList(elements));
+    }
+
+    public static <E> ArrayList<E> asArrayList(E first, E... other) {
+        if (other == null) {
+            throw new NullPointerException("other");
+        }
+        ArrayList<E> list = new ArrayList<>(1 + other.length);
+        list.add(first);
+        list.addAll(Arrays.asList(other));
+        return list;
+    }
+
+    public static<E> ArrayList<E> asArrayList(E first, E second, E... other) {
+        if (other == null) {
+            throw new NullPointerException("other");
+        }
+        ArrayList<E> list = new ArrayList<>(1 + 1 + other.length);
+        list.add(first);
+        list.add(second);
+        list.addAll(Arrays.asList(other));
+        return list;
+    }
+
+    public static <E> ArrayList<E> newSingletonArrayList(E element) {
+        return new ArrayList<>(Collections.singletonList(element));
+    }
+
+    public static <E> LinkedList<E> newLinkedList(Iterable<E> elements) {
+        if (elements == null) {
+            throw new NullPointerException("elements");
+        }
+        LinkedList<E> linkedList = new LinkedList<>();
+        for (E element : elements) {
+            linkedList.add(element);
+        }
+        return linkedList;
     }
 
+    public static <E> List<List<E>> eagerPartition(List<E> list, int size) {
+        if (list == null) {
+            throw new NullPointerException("list");
+        }
+        if (size <= 0) {
+            throw new IllegalArgumentException("size <= 0");
+        }
+        List<List<E>> result = new ArrayList<>((int) Math.ceil(list.size() / size));
+
+        List<E> accumulator = new ArrayList<>(size);
+        int count = 0;
+        for (E element : list) {
+            if (count == size) {
+                result.add(accumulator);
+                accumulator = new ArrayList<>(size);
+                count = 0;
+            }
+            accumulator.add(element);
+            count++;
+        }
+        if (count > 0) {
+            result.add(accumulator);
+        }
+
+        return result;
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java b/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java
index 3425d15..82ed6f2 100644
--- a/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java
+++ b/core/src/main/java/org/elasticsearch/common/util/MultiDataPathUpgrader.java
@@ -198,7 +198,7 @@ public class MultiDataPathUpgrader {
                 }
             }
         }
-        return new ShardPath(target.path, target.path, IndexMetaData.INDEX_UUID_NA_VALUE /* we don't know */, shard);
+        return new ShardPath(false, target.path, target.path, IndexMetaData.INDEX_UUID_NA_VALUE /* we don't know */, shard);
     }
 
     private ShardFileInfo[] getShardFileInfo(ShardId shard, NodeEnvironment.NodePath[] paths) throws IOException {
diff --git a/core/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java b/core/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java
index 38c0cb2..aad6cee 100644
--- a/core/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java
+++ b/core/src/main/java/org/elasticsearch/common/util/concurrent/PrioritizedEsThreadPoolExecutor.java
@@ -18,14 +18,20 @@
  */
 package org.elasticsearch.common.util.concurrent;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.Priority;
 import org.elasticsearch.common.unit.TimeValue;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Queue;
-import java.util.concurrent.*;
+import java.util.concurrent.Callable;
+import java.util.concurrent.FutureTask;
+import java.util.concurrent.PriorityBlockingQueue;
+import java.util.concurrent.RunnableFuture;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.ScheduledFuture;
+import java.util.concurrent.ThreadFactory;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicLong;
 
 /**
@@ -46,9 +52,9 @@ public class PrioritizedEsThreadPoolExecutor extends EsThreadPoolExecutor {
     }
 
     public Pending[] getPending() {
-        List<Pending> pending = Lists.newArrayList();
-        addPending(Lists.newArrayList(current), pending, true);
-        addPending(Lists.newArrayList(getQueue()), pending, false);
+        List<Pending> pending = new ArrayList<>();
+        addPending(new ArrayList<>(current), pending, true);
+        addPending(new ArrayList<>(getQueue()), pending, false);
         return pending.toArray(new Pending[pending.size()]);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapValues.java b/core/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapValues.java
index 1067d59..fc10ab4 100644
--- a/core/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapValues.java
+++ b/core/src/main/java/org/elasticsearch/common/xcontent/support/XContentMapValues.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.common.xcontent.support;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.Strings;
@@ -40,7 +39,7 @@ public class XContentMapValues {
      * as a single list.
      */
     public static List<Object> extractRawValues(String path, Map<String, Object> map) {
-        List<Object> values = Lists.newArrayList();
+        List<Object> values = new ArrayList<>();
         String[] pathElements = Strings.splitStringToArray(path, '.');
         if (pathElements.length == 0) {
             return values;
diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java b/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java
index d1b7906..b62db46 100644
--- a/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java
+++ b/core/src/main/java/org/elasticsearch/discovery/zen/ZenDiscovery.java
@@ -20,11 +20,17 @@
 package org.elasticsearch.discovery.zen;
 
 import com.google.common.base.Objects;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.Version;
-import org.elasticsearch.cluster.*;
+import org.elasticsearch.cluster.ClusterChangedEvent;
+import org.elasticsearch.cluster.ClusterName;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.ClusterStateNonMasterUpdateTask;
+import org.elasticsearch.cluster.ClusterStateUpdateTask;
+import org.elasticsearch.cluster.ProcessedClusterStateNonMasterUpdateTask;
+import org.elasticsearch.cluster.ProcessedClusterStateUpdateTask;
 import org.elasticsearch.cluster.block.ClusterBlocks;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
@@ -33,9 +39,6 @@ import org.elasticsearch.cluster.node.DiscoveryNodes;
 import org.elasticsearch.cluster.routing.RoutingService;
 import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
 import org.elasticsearch.cluster.service.InternalClusterService;
-import org.elasticsearch.cluster.settings.ClusterDynamicSettings;
-import org.elasticsearch.cluster.settings.DynamicSettings;
-import org.elasticsearch.cluster.settings.Validator;
 import org.elasticsearch.common.Priority;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.component.Lifecycle;
@@ -61,7 +64,13 @@ import org.elasticsearch.discovery.zen.publish.PublishClusterStateAction;
 import org.elasticsearch.node.service.NodeService;
 import org.elasticsearch.node.settings.NodeSettingsService;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.*;
+import org.elasticsearch.transport.EmptyTransportResponseHandler;
+import org.elasticsearch.transport.TransportChannel;
+import org.elasticsearch.transport.TransportException;
+import org.elasticsearch.transport.TransportRequest;
+import org.elasticsearch.transport.TransportRequestHandler;
+import org.elasticsearch.transport.TransportResponse;
+import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -75,7 +84,6 @@ import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.concurrent.atomic.AtomicReference;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.common.unit.TimeValue.timeValueSeconds;
 
 /**
@@ -163,7 +171,7 @@ public class ZenDiscovery extends AbstractLifecycleComponent<Discovery> implemen
         pingTimeout = settings.getAsTime("discovery.zen.ping_timeout", pingTimeout);
         this.pingTimeout = settings.getAsTime(SETTING_PING_TIMEOUT, pingTimeout);
 
-        this.joinTimeout = settings.getAsTime(SETTING_JOIN_TIMEOUT, TimeValue.timeValueMillis(pingTimeout.millis() * 20));
+        this.joinTimeout = settings.getAsTime(SETTING_JOIN_TIMEOUT, TimeValue.timeValueMillis(this.pingTimeout.millis() * 20));
         this.joinRetryAttempts = settings.getAsInt(SETTING_JOIN_RETRY_ATTEMPTS, 3);
         this.joinRetryDelay = settings.getAsTime(SETTING_JOIN_RETRY_DELAY, TimeValue.timeValueMillis(100));
         this.maxPingsFromAnotherMaster = settings.getAsInt(SETTING_MAX_PINGS_FROM_ANOTHER_MASTER, 3);
@@ -903,7 +911,7 @@ public class ZenDiscovery extends AbstractLifecycleComponent<Discovery> implemen
         }
 
         // filter responses
-        List<ZenPing.PingResponse> pingResponses = Lists.newArrayList();
+        List<ZenPing.PingResponse> pingResponses = new ArrayList<>();
         for (ZenPing.PingResponse pingResponse : fullPingResponses) {
             DiscoveryNode node = pingResponse.node();
             if (masterElectionFilterClientNodes && (node.clientNode() || (!node.masterNode() && !node.dataNode()))) {
@@ -928,7 +936,7 @@ public class ZenDiscovery extends AbstractLifecycleComponent<Discovery> implemen
         }
 
         final DiscoveryNode localNode = clusterService.localNode();
-        List<DiscoveryNode> pingMasters = newArrayList();
+        List<DiscoveryNode> pingMasters = new ArrayList<>();
         for (ZenPing.PingResponse pingResponse : pingResponses) {
             if (pingResponse.master() != null) {
                 // We can't include the local node in pingMasters list, otherwise we may up electing ourselves without
diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/elect/ElectMasterService.java b/core/src/main/java/org/elasticsearch/discovery/zen/elect/ElectMasterService.java
index ce65861..80b3ec0 100644
--- a/core/src/main/java/org/elasticsearch/discovery/zen/elect/ElectMasterService.java
+++ b/core/src/main/java/org/elasticsearch/discovery/zen/elect/ElectMasterService.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.discovery.zen.elect;
 
 import com.carrotsearch.hppc.ObjectContainer;
-import com.google.common.collect.Lists;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterState;
@@ -29,8 +28,13 @@ import org.elasticsearch.cluster.settings.Validator;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.CollectionUtils;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Comparator;
+import java.util.Iterator;
+import java.util.List;
 
 /**
  *
@@ -98,7 +102,7 @@ public class ElectMasterService extends AbstractComponent {
      * @return
      */
     public List<DiscoveryNode> sortByMasterLikelihood(Iterable<DiscoveryNode> nodes) {
-        ArrayList<DiscoveryNode> sortedNodes = Lists.newArrayList(nodes);
+        ArrayList<DiscoveryNode> sortedNodes = CollectionUtils.iterableAsArrayList(nodes);
         CollectionUtil.introSort(sortedNodes, nodeComparator);
         return sortedNodes;
     }
@@ -111,7 +115,7 @@ public class ElectMasterService extends AbstractComponent {
         if (sortedNodes == null) {
             return new DiscoveryNode[0];
         }
-        List<DiscoveryNode> nextPossibleMasters = Lists.newArrayListWithCapacity(numberOfPossibleMasters);
+        List<DiscoveryNode> nextPossibleMasters = new ArrayList<>(numberOfPossibleMasters);
         int counter = 0;
         for (DiscoveryNode nextPossibleMaster : sortedNodes) {
             if (++counter >= numberOfPossibleMasters) {
@@ -142,7 +146,7 @@ public class ElectMasterService extends AbstractComponent {
     }
 
     private List<DiscoveryNode> sortedMasterNodes(Iterable<DiscoveryNode> nodes) {
-        List<DiscoveryNode> possibleNodes = Lists.newArrayList(nodes);
+        List<DiscoveryNode> possibleNodes = CollectionUtils.iterableAsArrayList(nodes);
         if (possibleNodes.isEmpty()) {
             return null;
         }
diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java b/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java
index 06820a9..741f877 100644
--- a/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java
+++ b/core/src/main/java/org/elasticsearch/discovery/zen/ping/unicast/UnicastZenPing.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.discovery.zen.ping.unicast;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.google.common.collect.Lists;
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.Version;
@@ -35,6 +34,7 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.TransportAddress;
 import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.util.CollectionUtils;
 import org.elasticsearch.common.util.concurrent.AbstractRunnable;
 import org.elasticsearch.common.util.concurrent.ConcurrentCollections;
 import org.elasticsearch.common.util.concurrent.EsExecutors;
@@ -43,17 +43,36 @@ import org.elasticsearch.discovery.zen.elect.ElectMasterService;
 import org.elasticsearch.discovery.zen.ping.PingContextProvider;
 import org.elasticsearch.discovery.zen.ping.ZenPing;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.*;
+import org.elasticsearch.transport.BaseTransportResponseHandler;
+import org.elasticsearch.transport.ConnectTransportException;
+import org.elasticsearch.transport.RemoteTransportException;
+import org.elasticsearch.transport.TransportChannel;
+import org.elasticsearch.transport.TransportException;
+import org.elasticsearch.transport.TransportRequest;
+import org.elasticsearch.transport.TransportRequestHandler;
+import org.elasticsearch.transport.TransportRequestOptions;
+import org.elasticsearch.transport.TransportResponse;
+import org.elasticsearch.transport.TransportService;
 
 import java.io.Closeable;
 import java.io.IOException;
-import java.util.*;
-import java.util.concurrent.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Queue;
+import java.util.Set;
+import java.util.concurrent.CopyOnWriteArrayList;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.RejectedExecutionException;
+import java.util.concurrent.ThreadFactory;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicReference;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.common.unit.TimeValue.readTimeValue;
 import static org.elasticsearch.common.util.concurrent.ConcurrentCollections.newConcurrentMap;
 import static org.elasticsearch.discovery.zen.ping.ZenPing.PingResponse.readPingResponse;
@@ -122,7 +141,7 @@ public class UnicastZenPing extends AbstractLifecycleComponent<ZenPing> implemen
         for (int i = 0; i < hostArr.length; i++) {
             hostArr[i] = hostArr[i].trim();
         }
-        List<String> hosts = Lists.newArrayList(hostArr);
+        List<String> hosts = CollectionUtils.arrayAsArrayList(hostArr);
         final int limitPortCounts;
         if (hosts.isEmpty()) {
             // if unicast hosts are not specified, fill with simple defaults on the local machine
@@ -135,7 +154,7 @@ public class UnicastZenPing extends AbstractLifecycleComponent<ZenPing> implemen
 
         logger.debug("using initial hosts {}, with concurrent_connects [{}]", hosts, concurrentConnects);
 
-        List<DiscoveryNode> configuredTargetNodes = Lists.newArrayList();
+        List<DiscoveryNode> configuredTargetNodes = new ArrayList<>();
         for (String host : hosts) {
             try {
                 TransportAddress[] addresses = transportService.addressesFromString(host, limitPortCounts);
@@ -325,7 +344,7 @@ public class UnicastZenPing extends AbstractLifecycleComponent<ZenPing> implemen
         List<DiscoveryNode> sortedNodesToPing = electMasterService.sortByMasterLikelihood(nodesToPingSet);
 
         // new add the the unicast targets first
-        ArrayList<DiscoveryNode> nodesToPing = Lists.newArrayList(configuredTargetNodes);
+        List<DiscoveryNode> nodesToPing = CollectionUtils.arrayAsArrayList(configuredTargetNodes);
         nodesToPing.addAll(sortedNodesToPing);
 
         final CountDownLatch latch = new CountDownLatch(nodesToPing.size());
@@ -485,7 +504,7 @@ public class UnicastZenPing extends AbstractLifecycleComponent<ZenPing> implemen
             }
         });
 
-        List<PingResponse> pingResponses = newArrayList(temporalResponses);
+        List<PingResponse> pingResponses = CollectionUtils.iterableAsArrayList(temporalResponses);
         pingResponses.add(createPingResponse(contextProvider.nodes()));
 
 
diff --git a/core/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java b/core/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java
index b927cbb..43398c5 100644
--- a/core/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java
+++ b/core/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java
@@ -41,9 +41,11 @@ import org.elasticsearch.env.NodeEnvironment;
 import java.nio.file.DirectoryStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.util.*;
-
-import static com.google.common.collect.Lists.newArrayList;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
 
 /**
  *
@@ -221,7 +223,7 @@ public class GatewayMetaState extends AbstractComponent implements ClusterStateL
      */
     private void pre20Upgrade() throws Exception {
         MetaData metaData = loadMetaState();
-        List<IndexMetaData> updateIndexMetaData = newArrayList();
+        List<IndexMetaData> updateIndexMetaData = new ArrayList<>();
         for (IndexMetaData indexMetaData : metaData) {
             IndexMetaData newMetaData = metaDataIndexUpgradeService.upgradeIndexMetaData(indexMetaData);
             if (indexMetaData != newMetaData) {
diff --git a/core/src/main/java/org/elasticsearch/gateway/PrimaryShardAllocator.java b/core/src/main/java/org/elasticsearch/gateway/PrimaryShardAllocator.java
index b4bf636..695de26 100644
--- a/core/src/main/java/org/elasticsearch/gateway/PrimaryShardAllocator.java
+++ b/core/src/main/java/org/elasticsearch/gateway/PrimaryShardAllocator.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.gateway;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -34,7 +33,12 @@ import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.settings.IndexSettings;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
 
 /**
  * The primary shard allocator allocates primary shard that were not created as
@@ -234,7 +238,7 @@ public abstract class PrimaryShardAllocator extends AbstractComponent {
         // Now that we have a map of nodes to versions along with the
         // number of allocations found (and not ignored), we need to sort
         // it so the node with the highest version is at the beginning
-        List<DiscoveryNode> nodesWithHighestVersion = Lists.newArrayList();
+        List<DiscoveryNode> nodesWithHighestVersion = new ArrayList<>();
         nodesWithHighestVersion.addAll(nodesWithVersion.keySet());
         CollectionUtil.timSort(nodesWithHighestVersion, new Comparator<DiscoveryNode>() {
             @Override
diff --git a/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayMetaState.java b/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayMetaState.java
index a9362a5..accccc4 100644
--- a/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayMetaState.java
+++ b/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayMetaState.java
@@ -19,12 +19,15 @@
 
 package org.elasticsearch.gateway;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.ActionFuture;
 import org.elasticsearch.action.FailedNodeException;
 import org.elasticsearch.action.support.ActionFilters;
-import org.elasticsearch.action.support.nodes.*;
+import org.elasticsearch.action.support.nodes.BaseNodeRequest;
+import org.elasticsearch.action.support.nodes.BaseNodeResponse;
+import org.elasticsearch.action.support.nodes.BaseNodesRequest;
+import org.elasticsearch.action.support.nodes.BaseNodesResponse;
+import org.elasticsearch.action.support.nodes.TransportNodesAction;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
@@ -40,6 +43,7 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
@@ -86,8 +90,8 @@ public class TransportNodesListGatewayMetaState extends TransportNodesAction<Tra
 
     @Override
     protected NodesGatewayMetaState newResponse(Request request, AtomicReferenceArray responses) {
-        final List<NodeGatewayMetaState> nodesList = Lists.newArrayList();
-        final List<FailedNodeException> failures = Lists.newArrayList();
+        final List<NodeGatewayMetaState> nodesList = new ArrayList<>();
+        final List<FailedNodeException> failures = new ArrayList<>();
         for (int i = 0; i < responses.length(); i++) {
             Object resp = responses.get(i);
             if (resp instanceof NodeGatewayMetaState) { // will also filter out null response for unallocated ones
diff --git a/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayStartedShards.java b/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayStartedShards.java
index f431fcd..11cbbef 100644
--- a/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayStartedShards.java
+++ b/core/src/main/java/org/elasticsearch/gateway/TransportNodesListGatewayStartedShards.java
@@ -19,13 +19,15 @@
 
 package org.elasticsearch.gateway;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.FailedNodeException;
 import org.elasticsearch.action.support.ActionFilters;
-import org.elasticsearch.action.support.nodes.*;
+import org.elasticsearch.action.support.nodes.BaseNodeRequest;
+import org.elasticsearch.action.support.nodes.BaseNodeResponse;
+import org.elasticsearch.action.support.nodes.BaseNodesRequest;
+import org.elasticsearch.action.support.nodes.BaseNodesResponse;
+import org.elasticsearch.action.support.nodes.TransportNodesAction;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.ClusterState;
@@ -45,6 +47,7 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
@@ -97,8 +100,8 @@ public class TransportNodesListGatewayStartedShards extends TransportNodesAction
 
     @Override
     protected NodesGatewayStartedShards newResponse(Request request, AtomicReferenceArray responses) {
-        final List<NodeGatewayStartedShards> nodesList = Lists.newArrayList();
-        final List<FailedNodeException> failures = Lists.newArrayList();
+        final List<NodeGatewayStartedShards> nodesList = new ArrayList<>();
+        final List<FailedNodeException> failures = new ArrayList<>();
         for (int i = 0; i < responses.length(); i++) {
             Object resp = responses.get(i);
             if (resp instanceof NodeGatewayStartedShards) { // will also filter out null response for unallocated ones
diff --git a/core/src/main/java/org/elasticsearch/index/IndexService.java b/core/src/main/java/org/elasticsearch/index/IndexService.java
index 7be71c8..f38a894 100644
--- a/core/src/main/java/org/elasticsearch/index/IndexService.java
+++ b/core/src/main/java/org/elasticsearch/index/IndexService.java
@@ -22,14 +22,12 @@ package org.elasticsearch.index;
 import com.google.common.base.Function;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.Iterators;
-
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.inject.*;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.env.NodeEnvironment;
@@ -40,7 +38,6 @@ import org.elasticsearch.index.cache.IndexCache;
 import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
 import org.elasticsearch.index.deletionpolicy.DeletionPolicyModule;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
-import org.elasticsearch.index.shard.StoreRecoveryService;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.settings.IndexSettings;
@@ -102,7 +99,25 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
     private final NodeEnvironment nodeEnv;
     private final IndicesService indicesServices;
 
-    private volatile ImmutableMap<Integer, Tuple<IndexShard, Injector>> shards = ImmutableMap.of();
+    private volatile ImmutableMap<Integer, IndexShardInjectorPair> shards = ImmutableMap.of();
+
+    private static class IndexShardInjectorPair {
+        private final IndexShard indexShard;
+        private final Injector injector;
+
+        public IndexShardInjectorPair(IndexShard indexShard, Injector injector) {
+            this.indexShard = indexShard;
+            this.injector = injector;
+        }
+
+        public IndexShard getIndexShard() {
+            return indexShard;
+        }
+
+        public Injector getInjector() {
+            return injector;
+        }
+    }
 
     private final AtomicBoolean closed = new AtomicBoolean(false);
     private final AtomicBoolean deleted = new AtomicBoolean(false);
@@ -147,10 +162,10 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
 
     @Override
     public Iterator<IndexShard> iterator() {
-        return Iterators.transform(shards.values().iterator(), new Function<Tuple<IndexShard, Injector>, IndexShard>() {
+        return Iterators.transform(shards.values().iterator(), new Function<IndexShardInjectorPair, IndexShard>() {
             @Override
-            public IndexShard apply(Tuple<IndexShard, Injector> input) {
-                return input.v1();
+            public IndexShard apply(IndexShardInjectorPair input) {
+                return input.getIndexShard();
             }
         });
     }
@@ -164,9 +179,9 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
      */
     @Nullable
     public IndexShard shard(int shardId) {
-        Tuple<IndexShard, Injector> indexShardInjectorTuple = shards.get(shardId);
-        if (indexShardInjectorTuple != null) {
-            return indexShardInjectorTuple.v1();
+        IndexShardInjectorPair indexShardInjectorPair = shards.get(shardId);
+        if (indexShardInjectorPair != null) {
+            return indexShardInjectorPair.getIndexShard();
         }
         return null;
     }
@@ -244,11 +259,11 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
      * Return the shard injector for the provided id, or throw an exception if there is no such shard.
      */
     public Injector shardInjectorSafe(int shardId)  {
-        Tuple<IndexShard, Injector> tuple = shards.get(shardId);
-        if (tuple == null) {
+        IndexShardInjectorPair indexShardInjectorPair = shards.get(shardId);
+        if (indexShardInjectorPair == null) {
             throw new ShardNotFoundException(new ShardId(index, shardId));
         }
-        return tuple.v2();
+        return indexShardInjectorPair.getInjector();
     }
 
     public String indexUUID() {
@@ -286,6 +301,7 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
         Injector shardInjector = null;
         try {
             lock = nodeEnv.shardLock(shardId, TimeUnit.SECONDS.toMillis(5));
+            indicesLifecycle.beforeIndexShardCreated(shardId, indexSettings);
             ShardPath path;
             try {
                 path = ShardPath.loadShardPath(logger, nodeEnv, shardId, indexSettings);
@@ -310,7 +326,6 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
                 throw new IndexShardAlreadyExistsException(shardId + " already exists");
             }
 
-            indicesLifecycle.beforeIndexShardCreated(shardId, indexSettings);
             logger.debug("creating shard_id {}", shardId);
             // if we are on a shared FS we only own the shard (ie. we can safely delete it) if we are the primary.
             final boolean canDeleteShardContent = IndexMetaData.isOnSharedFilesystem(indexSettings) == false ||
@@ -348,7 +363,7 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
             indicesLifecycle.indexShardStateChanged(indexShard, null, "shard created");
             indicesLifecycle.afterIndexShardCreated(indexShard);
 
-            shards = newMapBuilder(shards).put(shardId.id(), new Tuple<>(indexShard, shardInjector)).immutableMap();
+            shards = newMapBuilder(shards).put(shardId.id(), new IndexShardInjectorPair(indexShard, shardInjector)).immutableMap();
             success = true;
             return indexShard;
         } catch (IOException e) {
@@ -374,10 +389,10 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
             return;
         }
         logger.debug("[{}] closing... (reason: [{}])", shardId, reason);
-        HashMap<Integer, Tuple<IndexShard, Injector>> tmpShardsMap = newHashMap(shards);
-        Tuple<IndexShard, Injector> tuple = tmpShardsMap.remove(shardId);
-        indexShard = tuple.v1();
-        shardInjector = tuple.v2();
+        HashMap<Integer, IndexShardInjectorPair> tmpShardsMap = newHashMap(shards);
+        IndexShardInjectorPair indexShardInjectorPair = tmpShardsMap.remove(shardId);
+        indexShard = indexShardInjectorPair.getIndexShard();
+        shardInjector = indexShardInjectorPair.getInjector();
         shards = ImmutableMap.copyOf(tmpShardsMap);
         closeShardInjector(reason, sId, shardInjector, indexShard);
         logger.debug("[{}] closed (reason: [{}])", shardId, reason);
diff --git a/core/src/main/java/org/elasticsearch/index/analysis/AnalysisModule.java b/core/src/main/java/org/elasticsearch/index/analysis/AnalysisModule.java
index 38f846a..21667cf 100644
--- a/core/src/main/java/org/elasticsearch/index/analysis/AnalysisModule.java
+++ b/core/src/main/java/org/elasticsearch/index/analysis/AnalysisModule.java
@@ -19,15 +19,12 @@
 
 package org.elasticsearch.index.analysis;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
-import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.inject.Scopes;
 import org.elasticsearch.common.inject.assistedinject.FactoryProvider;
 import org.elasticsearch.common.inject.multibindings.MapBinder;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.settings.NoClassSettingsException;
 import org.elasticsearch.index.analysis.compound.DictionaryCompoundWordTokenFilterFactory;
 import org.elasticsearch.index.analysis.compound.HyphenationCompoundWordTokenFilterFactory;
 import org.elasticsearch.indices.analysis.IndicesAnalysisService;
@@ -108,7 +105,7 @@ public class AnalysisModule extends AbstractModule {
 
     private final IndicesAnalysisService indicesAnalysisService;
 
-    private final LinkedList<AnalysisBinderProcessor> processors = Lists.newLinkedList();
+    private final LinkedList<AnalysisBinderProcessor> processors = new LinkedList<>();
 
     private final Map<String, Class<? extends CharFilterFactory>> charFilters = Maps.newHashMap();
     private final Map<String, Class<? extends TokenFilterFactory>> tokenFilters = Maps.newHashMap();
diff --git a/core/src/main/java/org/elasticsearch/index/analysis/AnalysisService.java b/core/src/main/java/org/elasticsearch/index/analysis/AnalysisService.java
index 55d6f57..5b7f542 100644
--- a/core/src/main/java/org/elasticsearch/index/analysis/AnalysisService.java
+++ b/core/src/main/java/org/elasticsearch/index/analysis/AnalysisService.java
@@ -217,22 +217,22 @@ public class AnalysisService extends AbstractIndexComponent implements Closeable
         Map<String, NamedAnalyzer> analyzers = newHashMap();
         for (AnalyzerProvider analyzerFactory : analyzerProviders.values()) {
             /*
-             * Lucene defaults positionOffsetGap to 0 in all analyzers but
-             * Elasticsearch defaults them to 0 only before version 2.1
-             * and 100 afterwards so we override the positionOffsetGap if it
+             * Lucene defaults positionIncrementGap to 0 in all analyzers but
+             * Elasticsearch defaults them to 0 only before version 2.0
+             * and 100 afterwards so we override the positionIncrementGap if it
              * doesn't match here.
              */
-            int overridePositionOffsetGap = StringFieldMapper.Defaults.positionOffsetGap(Version.indexCreated(indexSettings));
+            int overridePositionIncrementGap = StringFieldMapper.Defaults.positionIncrementGap(Version.indexCreated(indexSettings));
             if (analyzerFactory instanceof CustomAnalyzerProvider) {
                 ((CustomAnalyzerProvider) analyzerFactory).build(this);
                 /*
                  * Custom analyzers already default to the correct, version
-                 * dependent positionOffsetGap and the user is be able to
-                 * configure the positionOffsetGap directly on the analyzer so
-                 * we disable overriding the positionOffsetGap to preserve the
+                 * dependent positionIncrementGap and the user is be able to
+                 * configure the positionIncrementGap directly on the analyzer so
+                 * we disable overriding the positionIncrementGap to preserve the
                  * user's setting.
                  */
-                overridePositionOffsetGap = Integer.MIN_VALUE;
+                overridePositionIncrementGap = Integer.MIN_VALUE;
             }
             Analyzer analyzerF = analyzerFactory.get();
             if (analyzerF == null) {
@@ -242,12 +242,12 @@ public class AnalysisService extends AbstractIndexComponent implements Closeable
             if (analyzerF instanceof NamedAnalyzer) {
                 // if we got a named analyzer back, use it...
                 analyzer = (NamedAnalyzer) analyzerF;
-                if (overridePositionOffsetGap >= 0 && analyzer.getPositionIncrementGap(analyzer.name()) != overridePositionOffsetGap) {
-                    // unless the positionOffsetGap needs to be overridden
-                    analyzer = new NamedAnalyzer(analyzer, overridePositionOffsetGap);
+                if (overridePositionIncrementGap >= 0 && analyzer.getPositionIncrementGap(analyzer.name()) != overridePositionIncrementGap) {
+                    // unless the positionIncrementGap needs to be overridden
+                    analyzer = new NamedAnalyzer(analyzer, overridePositionIncrementGap);
                 }
             } else {
-                analyzer = new NamedAnalyzer(analyzerFactory.name(), analyzerFactory.scope(), analyzerF, overridePositionOffsetGap);
+                analyzer = new NamedAnalyzer(analyzerFactory.name(), analyzerFactory.scope(), analyzerF, overridePositionIncrementGap);
             }
             analyzers.put(analyzerFactory.name(), analyzer);
             analyzers.put(Strings.toCamelCase(analyzerFactory.name()), analyzer);
diff --git a/core/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzer.java b/core/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzer.java
index 97cd57e..b68a321 100644
--- a/core/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzer.java
+++ b/core/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzer.java
@@ -44,11 +44,11 @@ public final class CustomAnalyzer extends Analyzer {
     }
 
     public CustomAnalyzer(TokenizerFactory tokenizerFactory, CharFilterFactory[] charFilters, TokenFilterFactory[] tokenFilters,
-                          int positionOffsetGap, int offsetGap) {
+                          int positionIncrementGap, int offsetGap) {
         this.tokenizerFactory = tokenizerFactory;
         this.charFilters = charFilters;
         this.tokenFilters = tokenFilters;
-        this.positionIncrementGap = positionOffsetGap;
+        this.positionIncrementGap = positionIncrementGap;
         this.offsetGap = offsetGap;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzerProvider.java b/core/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzerProvider.java
index d3599db..43f0008 100644
--- a/core/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzerProvider.java
+++ b/core/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzerProvider.java
@@ -27,10 +27,9 @@ import org.elasticsearch.index.Index;
 import org.elasticsearch.index.mapper.core.StringFieldMapper;
 import org.elasticsearch.index.settings.IndexSettings;
 
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * A custom analyzer that is built out of a single {@link org.apache.lucene.analysis.Tokenizer} and a list
  * of {@link org.apache.lucene.analysis.TokenFilter}s.
@@ -59,7 +58,7 @@ public class CustomAnalyzerProvider extends AbstractIndexAnalyzerProvider<Custom
             throw new IllegalArgumentException("Custom Analyzer [" + name() + "] failed to find tokenizer under name [" + tokenizerName + "]");
         }
 
-        List<CharFilterFactory> charFilters = newArrayList();
+        List<CharFilterFactory> charFilters = new ArrayList<>();
         String[] charFilterNames = analyzerSettings.getAsArray("char_filter");
         for (String charFilterName : charFilterNames) {
             CharFilterFactory charFilter = analysisService.charFilter(charFilterName);
@@ -69,7 +68,7 @@ public class CustomAnalyzerProvider extends AbstractIndexAnalyzerProvider<Custom
             charFilters.add(charFilter);
         }
 
-        List<TokenFilterFactory> tokenFilters = newArrayList();
+        List<TokenFilterFactory> tokenFilters = new ArrayList<>();
         String[] tokenFilterNames = analyzerSettings.getAsArray("filter");
         for (String tokenFilterName : tokenFilterNames) {
             TokenFilterFactory tokenFilter = analysisService.tokenFilter(tokenFilterName);
@@ -79,14 +78,28 @@ public class CustomAnalyzerProvider extends AbstractIndexAnalyzerProvider<Custom
             tokenFilters.add(tokenFilter);
         }
 
-        int positionOffsetGapDefault = StringFieldMapper.Defaults.positionOffsetGap(Version.indexCreated(indexSettings));
-        int positionOffsetGap = analyzerSettings.getAsInt("position_offset_gap", positionOffsetGapDefault);
-        int offsetGap = analyzerSettings.getAsInt("offset_gap", -1);
+        int positionIncrementGap = StringFieldMapper.Defaults.positionIncrementGap(Version.indexCreated(indexSettings));
+
+        if (analyzerSettings.getAsMap().containsKey("position_offset_gap")){
+            if (Version.indexCreated(indexSettings).before(Version.V_2_0_0)){
+                if (analyzerSettings.getAsMap().containsKey("position_increment_gap")){
+                    throw new IllegalArgumentException("Custom Analyzer [" + name() +
+                            "] defined both [position_offset_gap] and [position_increment_gap], use only [position_increment_gap]");
+                }
+                positionIncrementGap = analyzerSettings.getAsInt("position_offset_gap", positionIncrementGap);
+            }else {
+                throw new IllegalArgumentException("Option [position_offset_gap] in Custom Analyzer [" + name() +
+                        "] has been renamed, please use [position_increment_gap] instead.");
+            }
+        }
+
+        positionIncrementGap = analyzerSettings.getAsInt("position_increment_gap", positionIncrementGap);
 
+        int offsetGap = analyzerSettings.getAsInt("offset_gap", -1);;
         this.customAnalyzer = new CustomAnalyzer(tokenizer,
                 charFilters.toArray(new CharFilterFactory[charFilters.size()]),
                 tokenFilters.toArray(new TokenFilterFactory[tokenFilters.size()]),
-                positionOffsetGap,
+                positionIncrementGap,
                 offsetGap
         );
     }
diff --git a/core/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java b/core/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java
index fde961c..f3a5039 100644
--- a/core/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java
+++ b/core/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java
@@ -31,10 +31,10 @@ public class NamedAnalyzer extends DelegatingAnalyzerWrapper {
     private final String name;
     private final AnalyzerScope scope;
     private final Analyzer analyzer;
-    private final int positionOffsetGap;
+    private final int positionIncrementGap;
 
-    public NamedAnalyzer(NamedAnalyzer analyzer, int positionOffsetGap) {
-        this(analyzer.name(), analyzer.scope(), analyzer.analyzer(), positionOffsetGap);
+    public NamedAnalyzer(NamedAnalyzer analyzer, int positionIncrementGap) {
+        this(analyzer.name(), analyzer.scope(), analyzer.analyzer(), positionIncrementGap);
     }
 
     public NamedAnalyzer(String name, Analyzer analyzer) {
@@ -45,12 +45,12 @@ public class NamedAnalyzer extends DelegatingAnalyzerWrapper {
         this(name, scope, analyzer, Integer.MIN_VALUE);
     }
 
-    public NamedAnalyzer(String name, AnalyzerScope scope, Analyzer analyzer, int positionOffsetGap) {
+    public NamedAnalyzer(String name, AnalyzerScope scope, Analyzer analyzer, int positionIncrementGap) {
         super(ERROR_STRATEGY);
         this.name = name;
         this.scope = scope;
         this.analyzer = analyzer;
-        this.positionOffsetGap = positionOffsetGap;
+        this.positionIncrementGap = positionIncrementGap;
     }
 
     /**
@@ -81,8 +81,8 @@ public class NamedAnalyzer extends DelegatingAnalyzerWrapper {
 
     @Override
     public int getPositionIncrementGap(String fieldName) {
-        if (positionOffsetGap != Integer.MIN_VALUE) {
-            return positionOffsetGap;
+        if (positionIncrementGap != Integer.MIN_VALUE) {
+            return positionIncrementGap;
         }
         return super.getPositionIncrementGap(fieldName);
     }
diff --git a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
index 597cf9b..5bd733c 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
@@ -19,11 +19,25 @@
 
 package org.elasticsearch.index.engine;
 
-import com.google.common.collect.Lists;
-import org.apache.lucene.index.*;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriter.IndexReaderWarmer;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.LiveIndexWriterConfig;
+import org.apache.lucene.index.MergePolicy;
+import org.apache.lucene.index.MultiReader;
+import org.apache.lucene.index.SegmentCommitInfo;
+import org.apache.lucene.index.SegmentInfos;
+import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.*;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.SearcherFactory;
+import org.apache.lucene.search.SearcherManager;
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.LockObtainFailedException;
@@ -49,8 +63,11 @@ import org.elasticsearch.index.indexing.ShardIndexingService;
 import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.merge.MergeStats;
 import org.elasticsearch.index.merge.OnGoingMerge;
-import org.elasticsearch.index.shard.*;
 import org.elasticsearch.index.search.nested.IncludeNestedDocsQuery;
+import org.elasticsearch.index.shard.ElasticsearchMergePolicy;
+import org.elasticsearch.index.shard.MergeSchedulerConfig;
+import org.elasticsearch.index.shard.ShardId;
+import org.elasticsearch.index.shard.TranslogRecoveryPerformer;
 import org.elasticsearch.index.translog.Translog;
 import org.elasticsearch.index.translog.TranslogConfig;
 import org.elasticsearch.index.translog.TranslogCorruptedException;
@@ -59,7 +76,12 @@ import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.threadpool.ThreadPool;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.locks.Lock;
@@ -1085,7 +1107,7 @@ public class InternalEngine extends Engine {
                         newSearcher = searcher;
                     } else {
                         // figure out the newSearcher, with only the new readers that are relevant for us
-                        List<IndexReader> readers = Lists.newArrayList();
+                        List<IndexReader> readers = new ArrayList<>();
                         for (LeafReaderContext newReaderContext : reader.leaves()) {
                             if (isMergedSegment(newReaderContext.reader())) {
                                 // merged segments are already handled by IndexWriterConfig.setMergedSegmentWarmer
diff --git a/core/src/main/java/org/elasticsearch/index/get/GetResult.java b/core/src/main/java/org/elasticsearch/index/get/GetResult.java
index 996de8c..7bee6e4 100644
--- a/core/src/main/java/org/elasticsearch/index/get/GetResult.java
+++ b/core/src/main/java/org/elasticsearch/index/get/GetResult.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.index.get;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.compress.CompressorFactory;
@@ -34,6 +33,7 @@ import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.search.lookup.SourceLookup;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
@@ -208,8 +208,8 @@ public class GetResult implements Streamable, Iterable<GetField>, ToXContent {
     }
 
     public XContentBuilder toXContentEmbedded(XContentBuilder builder, Params params) throws IOException {
-        List<GetField> metaFields = Lists.newArrayList();
-        List<GetField> otherFields = Lists.newArrayList();
+        List<GetField> metaFields = new ArrayList<>();
+        List<GetField> otherFields = new ArrayList<>();
         if (fields != null && !fields.isEmpty()) {
             for (GetField field : fields.values()) {
                 if (field.getValues().isEmpty()) {
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapperForType.java b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapperForType.java
new file mode 100644
index 0000000..1957f7e
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapperForType.java
@@ -0,0 +1,38 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.mapper;
+
+public class DocumentMapperForType {
+    private final DocumentMapper documentMapper;
+    private final Mapping mapping;
+
+    public DocumentMapperForType(DocumentMapper documentMapper, Mapping mapping) {
+        this.mapping = mapping;
+        this.documentMapper = documentMapper;
+    }
+
+    public DocumentMapper getDocumentMapper() {
+        return documentMapper;
+    }
+
+    public Mapping getMapping() {
+        return mapping;
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java b/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
index e55f3b1..65113e6 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
@@ -33,7 +33,7 @@ import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.index.analysis.NamedAnalyzer;
 import org.elasticsearch.index.fielddata.FieldDataType;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.similarity.SimilarityProvider;
 
 import java.io.IOException;
@@ -425,7 +425,7 @@ public abstract class MappedFieldType extends FieldType {
     }
 
     /**
-     * Should the field query {@link #termQuery(Object, org.elasticsearch.index.query.QueryShardContext)}  be used when detecting this
+     * Should the field query {@link #termQuery(Object, org.elasticsearch.index.query.QueryParseContext)}  be used when detecting this
      * field in query string.
      */
     public boolean useTermQueryWithQueryString() {
@@ -437,11 +437,11 @@ public abstract class MappedFieldType extends FieldType {
         return new Term(names().indexName(), indexedValueForSearch(value));
     }
 
-    public Query termQuery(Object value, @Nullable QueryShardContext context) {
+    public Query termQuery(Object value, @Nullable QueryParseContext context) {
         return new TermQuery(createTerm(value));
     }
 
-    public Query termsQuery(List values, @Nullable QueryShardContext context) {
+    public Query termsQuery(List values, @Nullable QueryParseContext context) {
         BytesRef[] bytesRefs = new BytesRef[values.size()];
         for (int i = 0; i < bytesRefs.length; i++) {
             bytesRefs[i] = indexedValueForSearch(values.get(i));
@@ -460,7 +460,7 @@ public abstract class MappedFieldType extends FieldType {
         return new FuzzyQuery(createTerm(value), fuzziness.asDistance(BytesRefs.toString(value)), prefixLength, maxExpansions, transpositions);
     }
 
-    public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+    public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
         PrefixQuery query = new PrefixQuery(createTerm(value));
         if (method != null) {
             query.setRewriteMethod(method);
@@ -468,7 +468,7 @@ public abstract class MappedFieldType extends FieldType {
         return query;
     }
 
-    public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+    public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
         RegexpQuery query = new RegexpQuery(createTerm(value), flags, maxDeterminizedStates);
         if (method != null) {
             query.setRewriteMethod(method);
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
index db2d0b2..4300e4c 100755
--- a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
@@ -26,24 +26,18 @@ import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Iterators;
-
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.DelegatingAnalyzerWrapper;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.*;
 import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.ElasticsearchGenerationException;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.compress.CompressedXContent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.Queries;
@@ -65,12 +59,7 @@ import org.elasticsearch.script.ScriptService;
 
 import java.io.Closeable;
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 
@@ -395,16 +384,16 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
      * Returns the document mapper created, including a mapping update if the
      * type has been dynamically created.
      */
-    public Tuple<DocumentMapper, Mapping> documentMapperWithAutoCreate(String type) {
+    public DocumentMapperForType documentMapperWithAutoCreate(String type) {
         DocumentMapper mapper = mappers.get(type);
         if (mapper != null) {
-            return Tuple.tuple(mapper, null);
+            return new DocumentMapperForType(mapper, null);
         }
         if (!dynamic) {
             throw new TypeMissingException(index, type, "trying to auto create mapping, but dynamic mapping is disabled");
         }
         mapper = parse(type, null, true);
-        return Tuple.tuple(mapper, mapper.mapping());
+        return new DocumentMapperForType(mapper, mapper.mapping());
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/ParseContext.java b/core/src/main/java/org/elasticsearch/index/mapper/ParseContext.java
index 5c07e8a..edf7562 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/ParseContext.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/ParseContext.java
@@ -19,10 +19,8 @@
 
 package org.elasticsearch.index.mapper;
 
-import com.carrotsearch.hppc.ObjectObjectMap;
 import com.carrotsearch.hppc.ObjectObjectHashMap;
-import com.google.common.collect.Lists;
-
+import com.carrotsearch.hppc.ObjectObjectMap;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexableField;
@@ -56,7 +54,7 @@ public abstract class ParseContext {
         private ObjectObjectMap<Object, IndexableField> keyedFields;
 
         private Document(String path, Document parent) {
-            fields = Lists.newArrayList();
+            fields = new ArrayList<>();
             this.path = path;
             this.prefix = path.isEmpty() ? "" : path + ".";
             this.parent = parent;
@@ -378,7 +376,7 @@ public abstract class ParseContext {
 
         private Document document;
 
-        private List<Document> documents = Lists.newArrayList();
+        private List<Document> documents = new ArrayList<>();
 
         @Nullable
         private final Settings indexSettings;
@@ -411,7 +409,7 @@ public abstract class ParseContext {
             this.parser = parser;
             this.document = document;
             if (document != null) {
-                this.documents = Lists.newArrayList();
+                this.documents = new ArrayList<>();
                 this.documents.add(document);
             } else {
                 this.documents = null;
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/core/CompletionFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/core/CompletionFieldMapper.java
index 6297c6a..dab41b4 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/core/CompletionFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/core/CompletionFieldMapper.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.index.mapper.core;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 import org.apache.lucene.analysis.Analyzer;
@@ -53,6 +52,7 @@ import org.elasticsearch.search.suggest.context.ContextMapping;
 import org.elasticsearch.search.suggest.context.ContextMapping.ContextConfig;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Locale;
@@ -334,7 +334,7 @@ public class CompletionFieldMapper extends FieldMapper {
         String surfaceForm = null;
         BytesRef payload = null;
         long weight = -1;
-        List<String> inputs = Lists.newArrayListWithExpectedSize(4);
+        List<String> inputs = new ArrayList<>(4);
 
         SortedMap<String, ContextConfig> contextConfig = null;
 
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/core/StringFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/core/StringFieldMapper.java
index 60ef42a..cb89cb4 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/core/StringFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/core/StringFieldMapper.java
@@ -53,7 +53,7 @@ import static org.elasticsearch.index.mapper.core.TypeParsers.parseMultiField;
 public class StringFieldMapper extends FieldMapper implements AllFieldMapper.IncludeInAll {
 
     public static final String CONTENT_TYPE = "string";
-    private static final int POSITION_OFFSET_GAP_USE_ANALYZER = -1;
+    private static final int POSITION_INCREMENT_GAP_USE_ANALYZER = -1;
 
     public static class Defaults {
         public static final MappedFieldType FIELD_TYPE = new StringFieldType();
@@ -64,23 +64,25 @@ public class StringFieldMapper extends FieldMapper implements AllFieldMapper.Inc
 
         // NOTE, when adding defaults here, make sure you add them in the builder
         public static final String NULL_VALUE = null;
+
         /**
-         * Post 2.0 default for position_offset_gap. Set to 100 so that
+         * Post 2.0 default for position_increment_gap. Set to 100 so that
          * phrase queries of reasonably high slop will not match across field
          * values.
          */
-        public static final int POSITION_OFFSET_GAP = 100;
-        public static final int POSITION_OFFSET_GAP_PRE_2_0 = 0;
+        public static final int POSITION_INCREMENT_GAP = 100;
+        public static final int POSITION_INCREMENT_GAP_PRE_2_0 = 0;
+
         public static final int IGNORE_ABOVE = -1;
 
         /**
-         * The default position_offset_gap for a particular version of Elasticsearch.
+         * The default position_increment_gap for a particular version of Elasticsearch.
          */
-        public static int positionOffsetGap(Version version) {
+        public static int positionIncrementGap(Version version) {
             if (version.before(Version.V_2_0_0_beta1)) {
-                return POSITION_OFFSET_GAP_PRE_2_0;
+                return POSITION_INCREMENT_GAP_PRE_2_0;
             }
-            return POSITION_OFFSET_GAP;
+            return POSITION_INCREMENT_GAP;
         }
     }
 
@@ -90,10 +92,10 @@ public class StringFieldMapper extends FieldMapper implements AllFieldMapper.Inc
 
         /**
          * The distance between tokens from different values in the same field.
-         * POSITION_OFFSET_GAP_USE_ANALYZER means default to the analyzer's
-         * setting which in turn defaults to Defaults.POSITION_OFFSET_GAP.
+         * POSITION_INCREMENT_GAP_USE_ANALYZER means default to the analyzer's
+         * setting which in turn defaults to Defaults.POSITION_INCREMENT_GAP.
          */
-        protected int positionOffsetGap = POSITION_OFFSET_GAP_USE_ANALYZER;
+        protected int positionIncrementGap = POSITION_INCREMENT_GAP_USE_ANALYZER;
 
         protected int ignoreAbove = Defaults.IGNORE_ABOVE;
 
@@ -108,8 +110,8 @@ public class StringFieldMapper extends FieldMapper implements AllFieldMapper.Inc
             return this;
         }
 
-        public Builder positionOffsetGap(int positionOffsetGap) {
-            this.positionOffsetGap = positionOffsetGap;
+        public Builder positionIncrementGap(int positionIncrementGap) {
+            this.positionIncrementGap = positionIncrementGap;
             return this;
         }
 
@@ -125,10 +127,10 @@ public class StringFieldMapper extends FieldMapper implements AllFieldMapper.Inc
 
         @Override
         public StringFieldMapper build(BuilderContext context) {
-            if (positionOffsetGap != POSITION_OFFSET_GAP_USE_ANALYZER) {
-                fieldType.setIndexAnalyzer(new NamedAnalyzer(fieldType.indexAnalyzer(), positionOffsetGap));
-                fieldType.setSearchAnalyzer(new NamedAnalyzer(fieldType.searchAnalyzer(), positionOffsetGap));
-                fieldType.setSearchQuoteAnalyzer(new NamedAnalyzer(fieldType.searchQuoteAnalyzer(), positionOffsetGap));
+            if (positionIncrementGap != POSITION_INCREMENT_GAP_USE_ANALYZER) {
+                fieldType.setIndexAnalyzer(new NamedAnalyzer(fieldType.indexAnalyzer(), positionIncrementGap));
+                fieldType.setSearchAnalyzer(new NamedAnalyzer(fieldType.searchAnalyzer(), positionIncrementGap));
+                fieldType.setSearchQuoteAnalyzer(new NamedAnalyzer(fieldType.searchQuoteAnalyzer(), positionIncrementGap));
             }
             // if the field is not analyzed, then by default, we should omit norms and have docs only
             // index options, as probably what the user really wants
@@ -147,7 +149,7 @@ public class StringFieldMapper extends FieldMapper implements AllFieldMapper.Inc
             }
             setupFieldType(context);
             StringFieldMapper fieldMapper = new StringFieldMapper(
-                    name, fieldType, defaultFieldType, positionOffsetGap, ignoreAbove,
+                    name, fieldType, defaultFieldType, positionIncrementGap, ignoreAbove,
                     context.indexSettings(), multiFieldsBuilder.build(this, context), copyTo);
             fieldMapper.includeInAll(includeInAll);
             return fieldMapper;
@@ -176,14 +178,15 @@ public class StringFieldMapper extends FieldMapper implements AllFieldMapper.Inc
                     }
                     builder.searchQuotedAnalyzer(analyzer);
                     iterator.remove();
-                } else if (propName.equals("position_offset_gap")) {
-                    int newPositionOffsetGap = XContentMapValues.nodeIntegerValue(propNode, -1);
-                    if (newPositionOffsetGap < 0) {
-                        throw new MapperParsingException("positions_offset_gap less than 0 aren't allowed.");
+                } else if (propName.equals("position_increment_gap") ||
+                        parserContext.indexVersionCreated().before(Version.V_2_0_0) && propName.equals("position_offset_gap")) {
+                    int newPositionIncrementGap = XContentMapValues.nodeIntegerValue(propNode, -1);
+                    if (newPositionIncrementGap < 0) {
+                        throw new MapperParsingException("positions_increment_gap less than 0 aren't allowed.");
                     }
-                    builder.positionOffsetGap(newPositionOffsetGap);
+                    builder.positionIncrementGap(newPositionIncrementGap);
                     // we need to update to actual analyzers if they are not set in this case...
-                    // so we can inject the position offset gap...
+                    // so we can inject the position increment gap...
                     if (builder.fieldType().indexAnalyzer() == null) {
                         builder.fieldType().setIndexAnalyzer(parserContext.analysisService().defaultIndexAnalyzer());
                     }
@@ -240,17 +243,17 @@ public class StringFieldMapper extends FieldMapper implements AllFieldMapper.Inc
     }
 
     private Boolean includeInAll;
-    private int positionOffsetGap;
+    private int positionIncrementGap;
     private int ignoreAbove;
 
     protected StringFieldMapper(String simpleName, MappedFieldType fieldType, MappedFieldType defaultFieldType,
-                                int positionOffsetGap, int ignoreAbove,
+                                int positionIncrementGap, int ignoreAbove,
                                 Settings indexSettings, MultiFields multiFields, CopyTo copyTo) {
         super(simpleName, fieldType, defaultFieldType, indexSettings, multiFields, copyTo);
         if (fieldType.tokenized() && fieldType.indexOptions() != NONE && fieldType().hasDocValues()) {
             throw new MapperParsingException("Field [" + fieldType.names().fullName() + "] cannot be analyzed and have doc values");
         }
-        this.positionOffsetGap = positionOffsetGap;
+        this.positionIncrementGap = positionIncrementGap;
         this.ignoreAbove = ignoreAbove;
     }
 
@@ -278,8 +281,8 @@ public class StringFieldMapper extends FieldMapper implements AllFieldMapper.Inc
         return true;
     }
 
-    public int getPositionOffsetGap() {
-        return this.positionOffsetGap;
+    public int getPositionIncrementGap() {
+        return this.positionIncrementGap;
     }
 
     public int getIgnoreAbove() {
@@ -381,8 +384,8 @@ public class StringFieldMapper extends FieldMapper implements AllFieldMapper.Inc
             builder.field("include_in_all", false);
         }
 
-        if (includeDefaults || positionOffsetGap != POSITION_OFFSET_GAP_USE_ANALYZER) {
-            builder.field("position_offset_gap", positionOffsetGap);
+        if (includeDefaults || positionIncrementGap != POSITION_INCREMENT_GAP_USE_ANALYZER) {
+            builder.field("position_increment_gap", positionIncrementGap);
         }
         NamedAnalyzer searchQuoteAnalyzer = fieldType().searchQuoteAnalyzer();
         if (searchQuoteAnalyzer != null && !searchQuoteAnalyzer.name().equals(fieldType().searchAnalyzer().name())) {
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java
index e538a00..f872207 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java
@@ -40,7 +40,7 @@ import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.similarity.SimilarityLookupService;
 
 import java.io.IOException;
@@ -186,7 +186,7 @@ public class AllFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, QueryShardContext context) {
+        public Query termQuery(Object value, QueryParseContext context) {
             return queryStringTermQuery(createTerm(value));
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
index f6e09b2..63fa41f 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
@@ -49,7 +49,7 @@ import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.Collection;
@@ -167,7 +167,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.termQuery(value, context);
             }
@@ -176,7 +176,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termsQuery(List values, @Nullable QueryShardContext context) {
+        public Query termsQuery(List values, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.termsQuery(values, context);
             }
@@ -184,7 +184,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+        public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.prefixQuery(value, method, context);
             }
@@ -201,7 +201,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+        public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.regexpQuery(value, flags, maxDeterminizedStates, method, context);
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java
index 1b7168a..3f395a8 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java
@@ -38,7 +38,7 @@ import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.Iterator;
@@ -157,7 +157,7 @@ public class IndexFieldMapper extends MetadataFieldMapper {
          * indices
          */
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             if (context == null) {
                 return super.termQuery(value, context);
             }
@@ -171,7 +171,7 @@ public class IndexFieldMapper extends MetadataFieldMapper {
         
 
         @Override
-        public Query termsQuery(List values, QueryShardContext context) {
+        public Query termsQuery(List values, QueryParseContext context) {
             if (context == null) {
                 return super.termsQuery(values, context);
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java
index 7cd4ac0..5fcd10c 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -189,12 +189,12 @@ public class ParentFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             return termsQuery(Collections.singletonList(value), context);
         }
 
         @Override
-        public Query termsQuery(List values, @Nullable QueryShardContext context) {
+        public Query termsQuery(List values, @Nullable QueryParseContext context) {
             if (context == null) {
                 return super.termsQuery(values, context);
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java
index 12e40de..480d2a4 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.List;
@@ -137,7 +137,7 @@ public class TypeFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             if (indexOptions() == IndexOptions.NONE) {
                 return new ConstantScoreQuery(new PrefixQuery(new Term(UidFieldMapper.NAME, Uid.typePrefixAsBytes(BytesRefs.toBytesRef(value)))));
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/object/ObjectMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/object/ObjectMapper.java
index 70c3276..3ff0611 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/object/ObjectMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/object/ObjectMapper.java
@@ -58,7 +58,6 @@ import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.common.xcontent.support.XContentMapValues.nodeBooleanValue;
 import static org.elasticsearch.index.mapper.MapperBuilders.object;
 import static org.elasticsearch.index.mapper.core.TypeParsers.parsePathType;
@@ -129,7 +128,7 @@ public class ObjectMapper extends Mapper implements AllFieldMapper.IncludeInAll,
 
         protected Boolean includeInAll;
 
-        protected final List<Mapper.Builder> mappersBuilders = newArrayList();
+        protected final List<Mapper.Builder> mappersBuilders = new ArrayList<>();
 
         public Builder(String name) {
             super(name);
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java
index 2ba2ada..cb0815a 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java
@@ -19,9 +19,7 @@
 
 package org.elasticsearch.index.mapper.object;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
-
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.joda.FormatDateTimeFormatter;
@@ -29,14 +27,22 @@ import org.elasticsearch.common.joda.Joda;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.*;
+import org.elasticsearch.index.mapper.ContentPath;
+import org.elasticsearch.index.mapper.Mapper;
+import org.elasticsearch.index.mapper.MapperParsingException;
+import org.elasticsearch.index.mapper.MergeResult;
+import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.core.DateFieldMapper;
 import org.elasticsearch.index.settings.IndexSettings;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.common.xcontent.support.XContentMapValues.nodeBooleanValue;
 import static org.elasticsearch.index.mapper.core.TypeParsers.parseDateTimeFormatter;
 
@@ -57,11 +63,11 @@ public class RootObjectMapper extends ObjectMapper {
 
     public static class Builder extends ObjectMapper.Builder<Builder, RootObjectMapper> {
 
-        protected final List<DynamicTemplate> dynamicTemplates = newArrayList();
+        protected final List<DynamicTemplate> dynamicTemplates = new ArrayList<>();
 
         // we use this to filter out seen date formats, because we might get duplicates during merging
         protected Set<String> seenDateFormats = Sets.newHashSet();
-        protected List<FormatDateTimeFormatter> dynamicDateTimeFormatters = newArrayList();
+        protected List<FormatDateTimeFormatter> dynamicDateTimeFormatters = new ArrayList<>();
 
         protected boolean dateDetection = Defaults.DATE_DETECTION;
         protected boolean numericDetection = Defaults.NUMERIC_DETECTION;
@@ -144,7 +150,7 @@ public class RootObjectMapper extends ObjectMapper {
 
         protected boolean processField(ObjectMapper.Builder builder, String fieldName, Object fieldNode) {
             if (fieldName.equals("date_formats") || fieldName.equals("dynamic_date_formats")) {
-                List<FormatDateTimeFormatter> dateTimeFormatters = newArrayList();
+                List<FormatDateTimeFormatter> dateTimeFormatters = new ArrayList<>();
                 if (fieldNode instanceof List) {
                     for (Object node1 : (List) fieldNode) {
                         if (node1.toString().startsWith("epoch_")) {
@@ -262,7 +268,7 @@ public class RootObjectMapper extends ObjectMapper {
         RootObjectMapper mergeWithObject = (RootObjectMapper) mergeWith;
         if (!mergeResult.simulate()) {
             // merge them
-            List<DynamicTemplate> mergedTemplates = Lists.newArrayList(Arrays.asList(this.dynamicTemplates));
+            List<DynamicTemplate> mergedTemplates = new ArrayList<>(Arrays.asList(this.dynamicTemplates));
             for (DynamicTemplate template : mergeWithObject.dynamicTemplates) {
                 boolean replaced = false;
                 for (int i = 0; i < mergedTemplates.size(); i++) {
diff --git a/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java b/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
index 52930e8..91ff1de 100644
--- a/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
+++ b/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
@@ -42,7 +42,7 @@ import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 import org.elasticsearch.index.percolator.stats.ShardPercolateService;
 import org.elasticsearch.index.query.IndexQueryParserService;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.shard.AbstractIndexShardComponent;
@@ -185,13 +185,12 @@ public class PercolatorQueriesRegistry extends AbstractIndexShardComponent imple
         }
     }
 
-    //norelease this method parses from xcontent to lucene query, need to re-investigate how to split context here
     private Query parseQuery(String type, XContentParser parser) {
         String[] previousTypes = null;
         if (type != null) {
-            QueryShardContext.setTypesWithPrevious(new String[]{type});
+            QueryParseContext.setTypesWithPrevious(new String[]{type});
         }
-        QueryShardContext context = queryParserService.getShardContext();
+        QueryParseContext context = queryParserService.getParseContext();
         try {
             context.reset(parser);
             // This means that fields in the query need to exist in the mapping prior to registering this query
@@ -210,10 +209,10 @@ public class PercolatorQueriesRegistry extends AbstractIndexShardComponent imple
             context.setMapUnmappedFieldAsString(mapUnmappedFieldsAsString ? true : false);
             return queryParserService.parseInnerQuery(context);
         } catch (IOException e) {
-            throw new QueryParsingException(context.parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(context, "Failed to parse", e);
         } finally {
             if (type != null) {
-                QueryShardContext.setTypes(previousTypes);
+                QueryParseContext.setTypes(previousTypes);
             }
             context.reset(null);
         }
diff --git a/core/src/main/java/org/elasticsearch/index/query/AbstractQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/AbstractQueryBuilder.java
deleted file mode 100644
index b248dc1..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/AbstractQueryBuilder.java
+++ /dev/null
@@ -1,311 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.action.support.ToXContentToBytes;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentType;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-import java.util.Objects;
-
-/**
- * Base class for all classes producing lucene queries.
- * Supports conversion to BytesReference and creation of lucene Query objects.
- */
-public abstract class AbstractQueryBuilder<QB extends AbstractQueryBuilder> extends ToXContentToBytes implements QueryBuilder<QB> {
-
-    /** Default for boost to apply to resulting Lucene query. Defaults to 1.0*/
-    public static final float DEFAULT_BOOST = 1.0f;
-
-    protected String queryName;
-    protected float boost = DEFAULT_BOOST;
-
-    protected AbstractQueryBuilder() {
-        super(XContentType.JSON);
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject();
-        doXContent(builder, params);
-        builder.endObject();
-        return builder;
-    }
-
-    protected abstract void doXContent(XContentBuilder builder, Params params) throws IOException;
-
-    protected void printBoostAndQueryName(XContentBuilder builder) throws IOException {
-        builder.field("boost", boost);
-        if (queryName != null) {
-            builder.field("_name", queryName);
-        }
-    }
-
-    @Override
-    public final Query toQuery(QueryShardContext context) throws IOException {
-        Query query = doToQuery(context);
-        if (query != null) {
-            query.setBoost(boost);
-            if (queryName != null) {
-                context.addNamedQuery(queryName, query);
-            }
-        }
-        return query;
-    }
-
-    @Override
-    public final Query toFilter(QueryShardContext context) throws IOException {
-        Query result = null;
-            final boolean originalIsFilter = context.isFilter;
-            try {
-                context.isFilter = true;
-                result = toQuery(context);
-            } finally {
-                context.isFilter = originalIsFilter;
-            }
-        return result;
-    }
-
-    //norelease to be made abstract once all query builders override doToQuery providing their own specific implementation.
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return context.indexQueryParserService().indicesQueriesRegistry().queryParsers().get(getName()).parse(context);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // default impl does not validate, subclasses should override.
-        //norelease to be possibly made abstract once all queries support validation
-        return null;
-    }
-
-    /**
-     * Returns the query name for the query.
-     */
-    @SuppressWarnings("unchecked")
-    @Override
-    public final QB queryName(String queryName) {
-        this.queryName = queryName;
-        return (QB) this;
-    }
-
-    /**
-     * Sets the query name for the query.
-     */
-    @Override
-    public final String queryName() {
-        return queryName;
-    }
-
-    /**
-     * Returns the boost for this query.
-     */
-    @Override
-    public final float boost() {
-        return this.boost;
-    }
-
-    /**
-     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
-     * weightings) have their score multiplied by the boost provided.
-     */
-    @SuppressWarnings("unchecked")
-    @Override
-    public final QB boost(float boost) {
-        this.boost = boost;
-        return (QB) this;
-    }
-
-    @Override
-    public final QB readFrom(StreamInput in) throws IOException {
-        QB queryBuilder = doReadFrom(in);
-        queryBuilder.boost = in.readFloat();
-        queryBuilder.queryName = in.readOptionalString();
-        return queryBuilder;
-    }
-
-    //norelease make this abstract once all builders implement doReadFrom themselves
-    protected QB doReadFrom(StreamInput in) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public final void writeTo(StreamOutput out) throws IOException {
-        doWriteTo(out);
-        out.writeFloat(boost);
-        out.writeOptionalString(queryName);
-    }
-
-    //norelease make this abstract once all builders implement doWriteTo themselves
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    protected final QueryValidationException addValidationError(String validationError, QueryValidationException validationException) {
-        return QueryValidationException.addValidationError(getName(), validationError, validationException);
-    }
-
-    @Override
-    public final boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (obj == null || getClass() != obj.getClass()) {
-            return false;
-        }
-        @SuppressWarnings("unchecked")
-        QB other = (QB) obj;
-        return Objects.equals(queryName, other.queryName) &&
-                Objects.equals(boost, other.boost) &&
-                doEquals(other);
-    }
-
-    /**
-     * Indicates whether some other {@link QueryBuilder} object of the same type is "equal to" this one.
-     */
-    //norelease to be made abstract once all queries are refactored
-    protected boolean doEquals(QB other) {
-        return super.equals(other);
-    }
-
-    @Override
-    public final int hashCode() {
-        return Objects.hash(getClass(), queryName, boost, doHashCode());
-    }
-
-    //norelease to be made abstract once all queries are refactored
-    protected int doHashCode() {
-        return super.hashCode();
-    }
-
-    /**
-     * This helper method checks if the object passed in is a string, if so it
-     * converts it to a {@link BytesRef}.
-     * @param obj the input object
-     * @return the same input object or a {@link BytesRef} representation if input was of type string
-     */
-    protected static Object convertToBytesRefIfString(Object obj) {
-        if (obj instanceof String) {
-            return BytesRefs.toBytesRef(obj);
-        }
-        return obj;
-    }
-
-    /**
-     * This helper method checks if the object passed in is a {@link BytesRef}, if so it
-     * converts it to a utf8 string.
-     * @param obj the input object
-     * @return the same input object or a utf8 string if input was of type {@link BytesRef}
-     */
-    protected static Object convertToStringIfBytesRef(Object obj) {
-        if (obj instanceof BytesRef) {
-            return ((BytesRef) obj).utf8ToString();
-        }
-        return obj;
-    }
-
-    /**
-     * Helper method to convert collection of {@link QueryBuilder} instances to lucene
-     * {@link Query} instances. {@link QueryBuilder} that return <tt>null</tt> calling
-     * their {@link QueryBuilder#toQuery(QueryShardContext)} method are not added to the
-     * resulting collection.
-     *
-     * @throws IOException
-     * @throws QueryShardException
-     */
-    protected static Collection<Query> toQueries(Collection<QueryBuilder> queryBuilders, QueryShardContext context) throws QueryShardException,
-            IOException {
-        List<Query> queries = new ArrayList<>(queryBuilders.size());
-        for (QueryBuilder queryBuilder : queryBuilders) {
-            Query query = queryBuilder.toQuery(context);
-            if (query != null) {
-                queries.add(query);
-            }
-        }
-        return queries;
-    }
-
-    protected QueryValidationException validateInnerQueries(List<QueryBuilder> queryBuilders, QueryValidationException initialValidationException) {
-        QueryValidationException validationException = initialValidationException;
-        for (QueryBuilder queryBuilder : queryBuilders) {
-            validationException = validateInnerQuery(queryBuilder, validationException);
-        }
-        return validationException;
-    }
-
-    protected QueryValidationException validateInnerQuery(QueryBuilder queryBuilder, QueryValidationException initialValidationException) {
-        QueryValidationException validationException = initialValidationException;
-        if (queryBuilder != null) {
-            QueryValidationException queryValidationException = queryBuilder.validate();
-            if (queryValidationException != null) {
-                validationException = QueryValidationException.addValidationErrors(queryValidationException.validationErrors(), validationException);
-            }
-        } else {
-            validationException = addValidationError("inner query cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    public String getName() {
-        //default impl returns the same as writeable name, but we keep the distinction between the two just to make sure
-        return getWriteableName();
-    }
-
-    protected final void writeQueries(StreamOutput out, List<? extends QueryBuilder> queries) throws IOException {
-        out.writeVInt(queries.size());
-        for (QueryBuilder query : queries) {
-            out.writeQuery(query);
-        }
-    }
-
-    protected final List<QueryBuilder> readQueries(StreamInput in) throws IOException {
-        List<QueryBuilder> queries = new ArrayList<>();
-        int size = in.readVInt();
-        for (int i = 0; i < size; i++) {
-            queries.add(in.readQuery());
-        }
-        return queries;
-    }
-
-    protected final void writeOptionalQuery(StreamOutput out, QueryBuilder query) throws IOException {
-        if (query == null) {
-            out.writeBoolean(false);
-        } else {
-            out.writeBoolean(true);
-            out.writeQuery(query);
-        }
-    }
-
-    protected final QueryBuilder readOptionalQuery(StreamInput in) throws IOException {
-        if (in.readBoolean()) {
-            return in.readQuery();
-        }
-        return null;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/AndQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/AndQueryBuilder.java
index 1f9c842..1d55663 100644
--- a/core/src/main/java/org/elasticsearch/index/query/AndQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/AndQueryBuilder.java
@@ -19,44 +19,30 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Lists;
-
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collections;
-import java.util.List;
-import java.util.Objects;
 
 /**
  * A filter that matches documents matching boolean combinations of other filters.
  * @deprecated Use {@link BoolQueryBuilder} instead
  */
 @Deprecated
-public class AndQueryBuilder extends AbstractQueryBuilder<AndQueryBuilder> {
-
-    public static final String NAME = "and";
+public class AndQueryBuilder extends QueryBuilder {
 
-    private final ArrayList<QueryBuilder> filters = Lists.newArrayList();
+    private ArrayList<QueryBuilder> filters = new ArrayList<>();
 
-    static final AndQueryBuilder PROTOTYPE = new AndQueryBuilder();
+    private String queryName;
 
-    /**
-     * @param filters nested filters, no <tt>null</tt> values are allowed
-     */
     public AndQueryBuilder(QueryBuilder... filters) {
-        Collections.addAll(this.filters, filters);
+        for (QueryBuilder filter : filters) {
+            this.filters.add(filter);
+        }
     }
 
     /**
      * Adds a filter to the list of filters to "and".
-     * @param filterBuilder nested filter, no <tt>null</tt> value allowed
      */
     public AndQueryBuilder add(QueryBuilder filterBuilder) {
         filters.add(filterBuilder);
@@ -64,79 +50,24 @@ public class AndQueryBuilder extends AbstractQueryBuilder<AndQueryBuilder> {
     }
 
     /**
-     * @return the list of queries added to "and".
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
      */
-    public List<QueryBuilder> innerQueries() {
-        return this.filters;
+    public AndQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(AndQueryParser.NAME);
         builder.startArray("filters");
         for (QueryBuilder filter : filters) {
             filter.toXContent(builder, params);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        if (filters.isEmpty()) {
-            // no filters provided, this should be ignored upstream
-            return null;
-        }
-
-        BooleanQuery query = new BooleanQuery();
-        for (QueryBuilder f : filters) {
-            Query innerQuery = f.toFilter(context);
-            // ignore queries that are null
-            if (innerQuery != null) {
-                query.add(innerQuery, Occur.MUST);
-            }
-        }
-        if (query.clauses().isEmpty()) {
-            // no inner lucene query exists, ignore upstream
-            return null;
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQueries(filters, null);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(filters);
-    }
-
-    @Override
-    protected boolean doEquals(AndQueryBuilder other) {
-        return Objects.equals(filters, other.filters);
-    }
-
-    @Override
-    protected AndQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        AndQueryBuilder andQueryBuilder = new AndQueryBuilder();
-        List<QueryBuilder> queryBuilders = readQueries(in);
-        for (QueryBuilder queryBuilder : queryBuilders) {
-            andQueryBuilder.add(queryBuilder);
-        }
-        return andQueryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, filters);
+        builder.endObject();
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/AndQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/AndQueryParser.java
index 35fbb94..bb0e1cb 100644
--- a/core/src/main/java/org/elasticsearch/index/query/AndQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/AndQueryParser.java
@@ -19,20 +19,22 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 import java.util.ArrayList;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
- * Parser for and query
- * @deprecated use bool query instead
+ *
  */
 @Deprecated
-public class AndQueryParser extends BaseQueryParser<AndQueryBuilder> {
+public class AndQueryParser implements QueryParser {
+
+    public static final String NAME = "and";
 
     @Inject
     public AndQueryParser() {
@@ -40,25 +42,26 @@ public class AndQueryParser extends BaseQueryParser<AndQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{AndQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public AndQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        final ArrayList<QueryBuilder> queries = newArrayList();
+        ArrayList<Query> queries = new ArrayList<>();
         boolean queriesFound = false;
 
         String queryName = null;
         String currentFieldName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         XContentParser.Token token = parser.currentToken();
         if (token == XContentParser.Token.START_ARRAY) {
             while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                 queriesFound = true;
-                QueryBuilder filter = parseContext.parseInnerFilterToQueryBuilder();
-                queries.add(filter);
+                Query filter = parseContext.parseInnerFilter();
+                if (filter != null) {
+                    queries.add(filter);
+                }
             }
         } else {
             while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -70,15 +73,23 @@ public class AndQueryParser extends BaseQueryParser<AndQueryBuilder> {
                     if ("filters".equals(currentFieldName)) {
                         queriesFound = true;
                         while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                            QueryBuilder filter = parseContext.parseInnerFilterToQueryBuilder();
-                            queries.add(filter);
+                            Query filter = parseContext.parseInnerFilter();
+                            if (filter != null) {
+                                queries.add(filter);
+                            }
+                        }
+                    } else {
+                        queriesFound = true;
+                        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
+                            Query filter = parseContext.parseInnerFilter();
+                            if (filter != null) {
+                                queries.add(filter);
+                            }
                         }
                     }
                 } else if (token.isValue()) {
                     if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
-                    } else if ("boost".equals(currentFieldName)) {
-                        boost = parser.floatValue();
                     } else {
                         throw new QueryParsingException(parseContext, "[and] query does not support [" + currentFieldName + "]");
                     }
@@ -90,17 +101,18 @@ public class AndQueryParser extends BaseQueryParser<AndQueryBuilder> {
             throw new QueryParsingException(parseContext, "[and] query requires 'filters' to be set on it'");
         }
 
-        AndQueryBuilder andQuery = new AndQueryBuilder();
-        for (QueryBuilder query : queries) {
-            andQuery.add(query);
+        if (queries.isEmpty()) {
+            // no filters provided, this should be ignored upstream
+            return null;
         }
-        andQuery.queryName(queryName);
-        andQuery.boost(boost);
-        return andQuery;
-    }
 
-    @Override
-    public AndQueryBuilder getBuilderPrototype() {
-        return AndQueryBuilder.PROTOTYPE;
+        BooleanQuery query = new BooleanQuery();
+        for (Query f : queries) {
+            query.add(f, Occur.MUST);
+        }
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/BaseQueryParser.java
deleted file mode 100644
index 4ff02df..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParser.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-/**
- * Class used during the query parsers refactoring. Will be removed once we can parse search requests on the coordinating node.
- * All query parsers that have a refactored "fromXContent" method can be changed to extend this instead of {@link BaseQueryParserTemp}.
- * Keeps old {@link QueryParser#parse(QueryShardContext)} method as a stub delegating to
- * {@link QueryParser#fromXContent(QueryParseContext)} and {@link QueryBuilder#toQuery(QueryShardContext)}}
- */
-//norelease needs to be removed once we parse search requests on the coordinating node, as the parse method is not needed anymore at that point.
-public abstract class BaseQueryParser<QB extends QueryBuilder<QB>> implements QueryParser<QB> {
-
-    @Override
-    public final Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        return fromXContent(context.parseContext()).toQuery(context);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParserTemp.java b/core/src/main/java/org/elasticsearch/index/query/BaseQueryParserTemp.java
deleted file mode 100644
index 4dc3eae..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParserTemp.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-/**
- * This class with method impl is an intermediate step in the query parsers refactoring.
- * Provides a fromXContent default implementation for query parsers that don't have yet a
- * specific fromXContent implementation that returns a QueryBuilder.
- */
-//norelease to be removed once all queries are moved over to extend BaseQueryParser
-public abstract class BaseQueryParserTemp implements QueryParser {
-
-    @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-        Query query = parse(parseContext.shardContext());
-        return new QueryWrappingQueryBuilder(query);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BaseTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BaseTermQueryBuilder.java
deleted file mode 100644
index 6444184..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/BaseTermQueryBuilder.java
+++ /dev/null
@@ -1,171 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-
-import java.io.IOException;
-import java.util.Objects;
-
-public abstract class BaseTermQueryBuilder<QB extends BaseTermQueryBuilder<QB>> extends AbstractQueryBuilder<QB> {
-
-    /** Name of field to match against. */
-    protected final String fieldName;
-
-    /** Value to find matches for. */
-    protected final Object value;
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, String value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, int value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, long value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, float value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, double value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, boolean value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     * In case value is assigned to a string, we internally convert it to a {@link BytesRef}
-     * because in {@link TermQueryParser} and {@link SpanTermQueryParser} string values are parsed to {@link BytesRef}
-     * and we want internal representation of query to be equal regardless of whether it was created from XContent or via Java API.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, Object value) {
-        this.fieldName = fieldName;
-        this.value = convertToBytesRefIfString(value);
-    }
-
-    /** Returns the field name used in this query. */
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    /**
-     *  Returns the value used in this query.
-     *  If necessary, converts internal {@link BytesRef} representation back to string.
-     */
-    public Object value() {
-        return convertToStringIfBytesRef(this.value);
-    }
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(getName());
-        builder.startObject(fieldName);
-        builder.field("value", convertToStringIfBytesRef(this.value));
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    /** Returns a {@link QueryValidationException} if fieldName is null or empty, or if value is null. */
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (fieldName == null || fieldName.isEmpty()) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (value == null) {
-            validationException = addValidationError("value cannot be null.", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected final int doHashCode() {
-        return Objects.hash(fieldName, value);
-    }
-
-    @Override
-    protected final boolean doEquals(BaseTermQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-               Objects.equals(value, other.value);
-    }
-
-    @Override
-    protected final QB doReadFrom(StreamInput in) throws IOException {
-        return createBuilder(in.readString(), in.readGenericValue());
-    }
-
-    protected abstract QB createBuilder(String fieldName, Object value);
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeGenericValue(value);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java
index 32d9c85..c377667 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java
@@ -19,35 +19,17 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Objects;
-
-import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfNeeded;
 
 /**
  * A Query that matches documents matching boolean combinations of other queries.
  */
-public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
-
-    public static final String NAME = "bool";
-
-    public static final boolean ADJUST_PURE_NEGATIVE_DEFAULT = true;
-
-    public static final boolean DISABLE_COORD_DEFAULT = false;
-
-    static final BoolQueryBuilder PROTOTYPE = new BoolQueryBuilder();
+public class BoolQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<BoolQueryBuilder> {
 
     private final List<QueryBuilder> mustClauses = new ArrayList<>();
 
@@ -57,15 +39,19 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
 
     private final List<QueryBuilder> shouldClauses = new ArrayList<>();
 
-    private boolean disableCoord = DISABLE_COORD_DEFAULT;
+    private float boost = -1;
 
-    private boolean adjustPureNegative = ADJUST_PURE_NEGATIVE_DEFAULT;
+    private Boolean disableCoord;
 
     private String minimumShouldMatch;
+    
+    private Boolean adjustPureNegative;
+
+    private String queryName;
 
     /**
      * Adds a query that <b>must</b> appear in the matching documents and will
-     * contribute to scoring. No <tt>null</tt> value allowed.
+     * contribute to scoring.
      */
     public BoolQueryBuilder must(QueryBuilder queryBuilder) {
         mustClauses.add(queryBuilder);
@@ -73,15 +59,8 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the queries that <b>must</b> appear in the matching documents.
-     */
-    public List<QueryBuilder> must() {
-        return this.mustClauses;
-    }
-
-    /**
      * Adds a query that <b>must</b> appear in the matching documents but will
-     * not contribute to scoring. No <tt>null</tt> value allowed.
+     * not contribute to scoring.
      */
     public BoolQueryBuilder filter(QueryBuilder queryBuilder) {
         filterClauses.add(queryBuilder);
@@ -89,15 +68,8 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the queries that <b>must</b> appear in the matching documents but don't conntribute to scoring
-     */
-    public List<QueryBuilder> filter() {
-        return this.filterClauses;
-    }
-
-    /**
-     * Adds a query that <b>must not</b> appear in the matching documents.
-     * No <tt>null</tt> value allowed.
+     * Adds a query that <b>must not</b> appear in the matching documents and
+     * will not contribute to scoring.
      */
     public BoolQueryBuilder mustNot(QueryBuilder queryBuilder) {
         mustNotClauses.add(queryBuilder);
@@ -105,16 +77,9 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the queries that <b>must not</b> appear in the matching documents.
-     */
-    public List<QueryBuilder> mustNot() {
-        return this.mustNotClauses;
-    }
-
-    /**
-     * Adds a clause that <i>should</i> be matched by the returned documents. For a boolean query with no
+     * Adds a query that <i>should</i> appear in the matching documents. For a boolean query with no
      * <tt>MUST</tt> clauses one or more <code>SHOULD</code> clauses must match a document
-     * for the BooleanQuery to match. No <tt>null</tt> value allowed.
+     * for the BooleanQuery to match.
      *
      * @see #minimumNumberShouldMatch(int)
      */
@@ -124,13 +89,13 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the list of clauses that <b>should</b> be matched by the returned documents.
-     *
-     * @see #should(QueryBuilder)
-     *  @see #minimumNumberShouldMatch(int)
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public List<QueryBuilder> should() {
-        return this.shouldClauses;
+    @Override
+    public BoolQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
@@ -142,13 +107,6 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * @return whether the <tt>Similarity#coord(int,int)</tt> in scoring are disabled. Defaults to <tt>false</tt>.
-     */
-    public boolean disableCoord() {
-        return this.disableCoord;
-    }
-
-    /**
      * Specifies a minimum number of the optional (should) boolean clauses which must be satisfied.
      * <p/>
      * <p>By default no optional clauses are necessary for a match
@@ -166,23 +124,6 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
         return this;
     }
 
-
-    /**
-     * Specifies a minimum number of the optional (should) boolean clauses which must be satisfied.
-     * @see BoolQueryBuilder#minimumNumberShouldMatch(int)
-     */
-    public BoolQueryBuilder minimumNumberShouldMatch(String minimumNumberShouldMatch) {
-        this.minimumShouldMatch = minimumNumberShouldMatch;
-        return this;
-    }
-
-    /**
-     * @return the string representation of the minimumShouldMatch settings for this query
-     */
-    public String minimumNumberShouldMatch() {
-        return this.minimumShouldMatch;
-    }
-
     /**
      * Sets the minimum should match using the special syntax (for example, supporting percentage).
      */
@@ -198,7 +139,7 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     public boolean hasClauses() {
         return !(mustClauses.isEmpty() && shouldClauses.isEmpty() && mustNotClauses.isEmpty() && filterClauses.isEmpty());
     }
-
+    
     /**
      * If a boolean query contains only negative ("must not") clauses should the
      * BooleanQuery be enhanced with a {@link MatchAllDocsQuery} in order to act
@@ -210,29 +151,39 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * @return the setting for the adjust_pure_negative setting in this query
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public boolean adjustPureNegative() {
-        return this.adjustPureNegative;
+    public BoolQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject("bool");
         doXArrayContent("must", mustClauses, builder, params);
         doXArrayContent("filter", filterClauses, builder, params);
         doXArrayContent("must_not", mustNotClauses, builder, params);
         doXArrayContent("should", shouldClauses, builder, params);
-        builder.field("disable_coord", disableCoord);
-        builder.field("adjust_pure_negative", adjustPureNegative);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        if (disableCoord != null) {
+            builder.field("disable_coord", disableCoord);
+        }
         if (minimumShouldMatch != null) {
             builder.field("minimum_should_match", minimumShouldMatch);
         }
-        printBoostAndQueryName(builder);
+        if (adjustPureNegative != null) {
+            builder.field("adjust_pure_negative", adjustPureNegative);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         builder.endObject();
     }
 
-    private static void doXArrayContent(String field, List<QueryBuilder> clauses, XContentBuilder builder, Params params) throws IOException {
+    private void doXArrayContent(String field, List<QueryBuilder> clauses, XContentBuilder builder, Params params) throws IOException {
         if (clauses.isEmpty()) {
             return;
         }
@@ -248,103 +199,4 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
         }
     }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        BooleanQuery booleanQuery = new BooleanQuery(disableCoord);
-        addBooleanClauses(context, booleanQuery, mustClauses, BooleanClause.Occur.MUST);
-        addBooleanClauses(context, booleanQuery, mustNotClauses, BooleanClause.Occur.MUST_NOT);
-        addBooleanClauses(context, booleanQuery, shouldClauses, BooleanClause.Occur.SHOULD);
-        addBooleanClauses(context, booleanQuery, filterClauses, BooleanClause.Occur.FILTER);
-
-        if (booleanQuery.clauses().isEmpty()) {
-            return new MatchAllDocsQuery();
-        }
-
-        Queries.applyMinimumShouldMatch(booleanQuery, minimumShouldMatch);
-        return adjustPureNegative ? fixNegativeQueryIfNeeded(booleanQuery) : booleanQuery;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        validationException = validateInnerQueries(mustClauses, validationException);
-        validationException = validateInnerQueries(shouldClauses, validationException);
-        validationException = validateInnerQueries(mustNotClauses, validationException);
-        validationException = validateInnerQueries(filterClauses, validationException);
-        return validationException;
-    }
-
-    private void addBooleanClauses(QueryShardContext context, BooleanQuery booleanQuery, List<QueryBuilder> clauses, Occur occurs) throws IOException {
-        for (QueryBuilder query : clauses) {
-            Query luceneQuery = null;
-            switch (occurs) {
-            case SHOULD:
-                if (context.isFilter() && minimumShouldMatch == null) {
-                    minimumShouldMatch = "1";
-                }
-                luceneQuery = query.toQuery(context);
-                break;
-            case FILTER:
-            case MUST_NOT:
-                luceneQuery = query.toFilter(context);
-                break;
-            case MUST:
-                luceneQuery = query.toQuery(context);
-            }
-            if (luceneQuery != null) {
-                booleanQuery.add(new BooleanClause(luceneQuery, occurs));
-            }
-        }
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(adjustPureNegative, disableCoord,
-                minimumShouldMatch, mustClauses, shouldClauses, mustNotClauses, filterClauses);
-    }
-
-    @Override
-    protected boolean doEquals(BoolQueryBuilder other) {
-        return Objects.equals(adjustPureNegative, other.adjustPureNegative) &&
-                Objects.equals(disableCoord, other.disableCoord) &&
-                Objects.equals(minimumShouldMatch, other.minimumShouldMatch) &&
-                Objects.equals(mustClauses, other.mustClauses) &&
-                Objects.equals(shouldClauses, other.shouldClauses) &&
-                Objects.equals(mustNotClauses, other.mustNotClauses) &&
-                Objects.equals(filterClauses, other.filterClauses);
-    }
-
-    @Override
-    protected BoolQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder();
-        List<QueryBuilder> queryBuilders = readQueries(in);
-        boolQueryBuilder.mustClauses.addAll(queryBuilders);
-        queryBuilders = readQueries(in);
-        boolQueryBuilder.mustNotClauses.addAll(queryBuilders);
-        queryBuilders = readQueries(in);
-        boolQueryBuilder.shouldClauses.addAll(queryBuilders);
-        queryBuilders = readQueries(in);
-        boolQueryBuilder.filterClauses.addAll(queryBuilders);
-        boolQueryBuilder.adjustPureNegative = in.readBoolean();
-        boolQueryBuilder.disableCoord = in.readBoolean();
-        boolQueryBuilder.minimumShouldMatch = in.readOptionalString();
-        return boolQueryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, mustClauses);
-        writeQueries(out, mustNotClauses);
-        writeQueries(out, shouldClauses);
-        writeQueries(out, filterClauses);
-        out.writeBoolean(adjustPureNegative);
-        out.writeBoolean(disableCoord);
-        out.writeOptionalString(minimumShouldMatch);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java
index 60b5973..66ea85e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java
@@ -19,20 +19,27 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
+import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfNeeded;
 
 /**
- * Parser for bool query
+ *
  */
-public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
+public class BoolQueryParser implements QueryParser {
+
+    public static final String NAME = "bool";
 
     @Inject
     public BoolQueryParser(Settings settings) {
@@ -41,27 +48,23 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{BoolQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public BoolQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        boolean disableCoord = BoolQueryBuilder.DISABLE_COORD_DEFAULT;
-        boolean adjustPureNegative = BoolQueryBuilder.ADJUST_PURE_NEGATIVE_DEFAULT;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        boolean disableCoord = false;
+        float boost = 1.0f;
         String minimumShouldMatch = null;
 
-        final List<QueryBuilder> mustClauses = newArrayList();
-        final List<QueryBuilder> mustNotClauses = newArrayList();
-        final List<QueryBuilder> shouldClauses = newArrayList();
-        final List<QueryBuilder> filterClauses = newArrayList();
+        List<BooleanClause> clauses = new ArrayList<>();
+        boolean adjustPureNegative = true;
         String queryName = null;
-
+        
         String currentFieldName = null;
         XContentParser.Token token;
-        QueryBuilder query;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -70,21 +73,32 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
             } else if (token == XContentParser.Token.START_OBJECT) {
                 switch (currentFieldName) {
                 case "must":
-                    query = parseContext.parseInnerQueryBuilder();
-                    mustClauses.add(query);
+                    Query query = parseContext.parseInnerQuery();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST));
+                    }
                     break;
                 case "should":
-                    query = parseContext.parseInnerQueryBuilder();
-                    shouldClauses.add(query);
+                    query = parseContext.parseInnerQuery();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.SHOULD));
+                        if (parseContext.isFilter() && minimumShouldMatch == null) {
+                            minimumShouldMatch = "1";
+                        }
+                    }
                     break;
                 case "filter":
-                    query = parseContext.parseInnerFilterToQueryBuilder();
-                    filterClauses.add(query);
+                    query = parseContext.parseInnerFilter();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.FILTER));
+                    }
                     break;
                 case "must_not":
                 case "mustNot":
-                    query = parseContext.parseInnerFilterToQueryBuilder();
-                    mustNotClauses.add(query);
+                    query = parseContext.parseInnerFilter();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST_NOT));
+                    }
                     break;
                 default:
                     throw new QueryParsingException(parseContext, "[bool] query does not support [" + currentFieldName + "]");
@@ -93,21 +107,32 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
                 while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                     switch (currentFieldName) {
                     case "must":
-                        query = parseContext.parseInnerQueryBuilder();
-                        mustClauses.add(query);
+                        Query query = parseContext.parseInnerQuery();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST));
+                        }
                         break;
                     case "should":
-                        query = parseContext.parseInnerQueryBuilder();
-                        shouldClauses.add(query);
+                        query = parseContext.parseInnerQuery();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.SHOULD));
+                            if (parseContext.isFilter() && minimumShouldMatch == null) {
+                                minimumShouldMatch = "1";
+                            }
+                        }
                         break;
                     case "filter":
-                        query = parseContext.parseInnerFilterToQueryBuilder();
-                        filterClauses.add(query);
+                        query = parseContext.parseInnerFilter();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.FILTER));
+                        }
                         break;
                     case "must_not":
                     case "mustNot":
-                        query = parseContext.parseInnerFilterToQueryBuilder();
-                        mustNotClauses.add(query);
+                        query = parseContext.parseInnerFilter();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST_NOT));
+                        }
                         break;
                     default:
                         throw new QueryParsingException(parseContext, "bool query does not support [" + currentFieldName + "]");
@@ -131,29 +156,21 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
                 }
             }
         }
-        BoolQueryBuilder boolQuery = new BoolQueryBuilder();
-        for (QueryBuilder queryBuilder : mustClauses) {
-            boolQuery.must(queryBuilder);
-        }
-        for (QueryBuilder queryBuilder : mustNotClauses) {
-            boolQuery.mustNot(queryBuilder);
+
+        if (clauses.isEmpty()) {
+            return new MatchAllDocsQuery();
         }
-        for (QueryBuilder queryBuilder : shouldClauses) {
-            boolQuery.should(queryBuilder);
+
+        BooleanQuery booleanQuery = new BooleanQuery(disableCoord);
+        for (BooleanClause clause : clauses) {
+            booleanQuery.add(clause);
         }
-        for (QueryBuilder queryBuilder : filterClauses) {
-            boolQuery.filter(queryBuilder);
+        booleanQuery.setBoost(boost);
+        Queries.applyMinimumShouldMatch(booleanQuery, minimumShouldMatch);
+        Query query = adjustPureNegative ? fixNegativeQueryIfNeeded(booleanQuery) : booleanQuery;
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
         }
-        boolQuery.boost(boost);
-        boolQuery.disableCoord(disableCoord);
-        boolQuery.adjustPureNegative(adjustPureNegative);
-        boolQuery.minimumNumberShouldMatch(minimumShouldMatch);
-        boolQuery.queryName(queryName);
-        return boolQuery;
-    }
-
-    @Override
-    public BoolQueryBuilder getBuilderPrototype() {
-        return BoolQueryBuilder.PROTOTYPE;
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoostableQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BoostableQueryBuilder.java
new file mode 100644
index 0000000..31572ce
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/query/BoostableQueryBuilder.java
@@ -0,0 +1,33 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query;
+
+/**
+ * Query builder which allow setting some boost
+ */
+public interface BoostableQueryBuilder<B extends BoostableQueryBuilder<B>> {
+
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    B boost(float boost);
+
+}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java
index 69ab70a..9d67469 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java
@@ -19,14 +19,9 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.queries.BoostingQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * The BoostingQuery class can be used to effectively demote results that match a given query.
@@ -40,132 +35,63 @@ import java.util.Objects;
  * multiplied by the supplied "boost" parameter, so this should be less than 1 to achieve a
  * demoting effect
  */
-public class BoostingQueryBuilder extends AbstractQueryBuilder<BoostingQueryBuilder> {
+public class BoostingQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<BoostingQueryBuilder> {
 
-    public static final String NAME = "boosting";
+    private QueryBuilder positiveQuery;
 
-    private final QueryBuilder positiveQuery;
-
-    private final QueryBuilder negativeQuery;
+    private QueryBuilder negativeQuery;
 
     private float negativeBoost = -1;
 
-    static final BoostingQueryBuilder PROTOTYPE = new BoostingQueryBuilder(null, null);
+    private float boost = -1;
+
+    public BoostingQueryBuilder() {
 
-    /**
-     * Create a new {@link BoostingQueryBuilder}
-     *
-     * @param positiveQuery the positive query for this boosting query.
-     * @param negativeQuery the negative query for this boosting query.
-     */
-    public BoostingQueryBuilder(QueryBuilder positiveQuery, QueryBuilder negativeQuery) {
-        this.positiveQuery = positiveQuery;
-        this.negativeQuery = negativeQuery;
     }
 
-    /**
-     * Get the positive query for this boosting query.
-     */
-    public QueryBuilder positiveQuery() {
-        return this.positiveQuery;
+    public BoostingQueryBuilder positive(QueryBuilder positiveQuery) {
+        this.positiveQuery = positiveQuery;
+        return this;
     }
 
-    /**
-     * Get the negative query for this boosting query.
-     */
-    public QueryBuilder negativeQuery() {
-        return this.negativeQuery;
+    public BoostingQueryBuilder negative(QueryBuilder negativeQuery) {
+        this.negativeQuery = negativeQuery;
+        return this;
     }
 
-    /**
-     * Set the negative boost factor.
-     */
     public BoostingQueryBuilder negativeBoost(float negativeBoost) {
         this.negativeBoost = negativeBoost;
         return this;
     }
 
-    /**
-     * Get the negative boost factor.
-     */
-    public float negativeBoost() {
-        return this.negativeBoost;
-    }
-
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("positive");
-        positiveQuery.toXContent(builder, params);
-        builder.field("negative");
-        negativeQuery.toXContent(builder, params);
-        builder.field("negative_boost", negativeBoost);
-        printBoostAndQueryName(builder);
-        builder.endObject();
+    public BoostingQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (negativeBoost < 0) {
-            validationException = addValidationError("query requires negativeBoost to be set to positive value", validationException);
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
+        if (positiveQuery == null) {
+            throw new IllegalArgumentException("boosting query requires positive query to be set");
         }
         if (negativeQuery == null) {
-            validationException = addValidationError("inner clause [negative] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(negativeQuery, validationException);
+            throw new IllegalArgumentException("boosting query requires negative query to be set");
         }
-        if (positiveQuery == null) {
-            validationException = addValidationError("inner clause [positive] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(positiveQuery, validationException);
+        if (negativeBoost == -1) {
+            throw new IllegalArgumentException("boosting query requires negativeBoost to be set");
         }
-        return validationException;
-    }
+        builder.startObject(BoostingQueryParser.NAME);
+        builder.field("positive");
+        positiveQuery.toXContent(builder, params);
+        builder.field("negative");
+        negativeQuery.toXContent(builder, params);
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
+        builder.field("negative_boost", negativeBoost);
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query positive = positiveQuery.toQuery(context);
-        Query negative = negativeQuery.toQuery(context);
-        // make upstream queries ignore this query by returning `null`
-        // if either inner query builder returns null
-        if (positive == null || negative == null) {
-            return null;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-
-        return new BoostingQuery(positive, negative, negativeBoost);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(negativeBoost, positiveQuery, negativeQuery);
-    }
-
-    @Override
-    protected boolean doEquals(BoostingQueryBuilder other) {
-        return Objects.equals(negativeBoost, other.negativeBoost) &&
-                Objects.equals(positiveQuery, other.positiveQuery) &&
-                Objects.equals(negativeQuery, other.negativeQuery);
-    }
-
-    @Override
-    protected BoostingQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder positiveQuery = in.readQuery();
-        QueryBuilder negativeQuery = in.readQuery();
-        BoostingQueryBuilder boostingQuery = new BoostingQueryBuilder(positiveQuery, negativeQuery);
-        boostingQuery.negativeBoost = in.readFloat();
-        return boostingQuery;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(positiveQuery);
-        out.writeQuery(negativeQuery);
-        out.writeFloat(negativeBoost);
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java
index 699d23d..c160b2f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java
@@ -19,15 +19,19 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.queries.BoostingQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
 /**
- * Parser for boosting query
+ *
  */
-public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
+public class BoostingQueryParser implements QueryParser {
+
+    public static final String NAME = "boosting";
 
     @Inject
     public BoostingQueryParser() {
@@ -35,20 +39,19 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{BoostingQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public BoostingQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder positiveQuery = null;
+        Query positiveQuery = null;
         boolean positiveQueryFound = false;
-        QueryBuilder negativeQuery = null;
+        Query negativeQuery = null;
         boolean negativeQueryFound = false;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = -1;
         float negativeBoost = -1;
-        String queryName = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -57,10 +60,10 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("positive".equals(currentFieldName)) {
-                    positiveQuery = parseContext.parseInnerQueryBuilder();
+                    positiveQuery = parseContext.parseInnerQuery();
                     positiveQueryFound = true;
                 } else if ("negative".equals(currentFieldName)) {
-                    negativeQuery = parseContext.parseInnerQueryBuilder();
+                    negativeQuery = parseContext.parseInnerQuery();
                     negativeQueryFound = true;
                 } else {
                     throw new QueryParsingException(parseContext, "[boosting] query does not support [" + currentFieldName + "]");
@@ -68,8 +71,6 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
             } else if (token.isValue()) {
                 if ("negative_boost".equals(currentFieldName) || "negativeBoost".equals(currentFieldName)) {
                     negativeBoost = parser.floatValue();
-                } else if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else {
@@ -78,25 +79,25 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
             }
         }
 
-        if (!positiveQueryFound) {
+        if (positiveQuery == null && !positiveQueryFound) {
             throw new QueryParsingException(parseContext, "[boosting] query requires 'positive' query to be set'");
         }
-        if (!negativeQueryFound) {
+        if (negativeQuery == null && !negativeQueryFound) {
             throw new QueryParsingException(parseContext, "[boosting] query requires 'negative' query to be set'");
         }
-        if (negativeBoost < 0) {
-            throw new QueryParsingException(parseContext, "[boosting] query requires 'negative_boost' to be set to be a positive value'");
+        if (negativeBoost == -1) {
+            throw new QueryParsingException(parseContext, "[boosting] query requires 'negative_boost' to be set'");
         }
 
-        BoostingQueryBuilder boostingQuery = new BoostingQueryBuilder(positiveQuery, negativeQuery);
-        boostingQuery.negativeBoost(negativeBoost);
-        boostingQuery.boost(boost);
-        boostingQuery.queryName(queryName);
-        return boostingQuery;
-    }
+        // parsers returned null
+        if (positiveQuery == null || negativeQuery == null) {
+            return null;
+        }
 
-    @Override
-    public BoostingQueryBuilder getBuilderPrototype() {
-        return BoostingQueryBuilder.PROTOTYPE;
+        BoostingQuery boostingQuery = new BoostingQuery(positiveQuery, negativeQuery, negativeBoost);
+        if (boost != -1) {
+            boostingQuery.setBoost(boost);
+        }
+        return boostingQuery;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java
index 853c583..ae9c10d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java
@@ -19,31 +19,18 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.queries.ExtendedCommonTermsQuery;
-import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
 import org.apache.lucene.search.similarities.Similarity;
-import org.apache.lucene.util.BytesRefBuilder;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * CommonTermsQuery query is a query that executes high-frequency terms in a
  * optional sub-query to prevent slow queries due to "common" terms like
- * stopwords. This query basically builds 2 queries off the
- * {@link org.apache.lucene.queries.CommonTermsQuery#add(Term) added} terms
- * where low-frequency terms are added to a required boolean clause
+ * stopwords. This query basically builds 2 queries off the {@link #add(Term)
+ * added} terms where low-frequency terms are added to a required boolean clause
  * and high-frequency terms are added to an optional boolean clause. The
  * optional clause is only executed if the required "low-frequency' clause
  * matches. Scores produced by this query will be slightly different to plain
@@ -55,52 +42,46 @@ import java.util.Objects;
  * execution times significantly if applicable.
  * <p>
  */
-public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQueryBuilder> {
+public class CommonTermsQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<CommonTermsQueryBuilder> {
 
-    public static final String NAME = "common";
-
-    public static final float DEFAULT_CUTOFF_FREQ = 0.01f;
-
-    public static final Operator DEFAULT_HIGH_FREQ_OCCUR = Operator.OR;
-
-    public static final Operator DEFAULT_LOW_FREQ_OCCUR = Operator.OR;
-
-    public static final boolean DEFAULT_DISABLE_COORD = true;
+    public static enum Operator {
+        OR, AND
+    }
 
-    private final String fieldName;
+    private final String name;
 
     private final Object text;
 
-    private Operator highFreqOperator = DEFAULT_HIGH_FREQ_OCCUR;
+    private Operator highFreqOperator = null;
 
-    private Operator lowFreqOperator = DEFAULT_LOW_FREQ_OCCUR;
+    private Operator lowFreqOperator = null;
 
     private String analyzer = null;
 
+    private Float boost = null;
+
     private String lowFreqMinimumShouldMatch = null;
 
     private String highFreqMinimumShouldMatch = null;
 
-    private boolean disableCoord = DEFAULT_DISABLE_COORD;
+    private Boolean disableCoord = null;
 
-    private float cutoffFrequency = DEFAULT_CUTOFF_FREQ;
+    private Float cutoffFrequency = null;
 
-    static final CommonTermsQueryBuilder PROTOTYPE = new CommonTermsQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * Constructs a new common terms query.
      */
-    public CommonTermsQueryBuilder(String fieldName, Object text) {
-        this.fieldName = fieldName;
+    public CommonTermsQueryBuilder(String name, Object text) {
+        if (name == null) {
+            throw new IllegalArgumentException("Field name must not be null");
+        }
+        if (text == null) {
+            throw new IllegalArgumentException("Query must not be null");
+        }
         this.text = text;
-    }
-
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public Object value() {
-        return this.text;
+        this.name = name;
     }
 
     /**
@@ -109,27 +90,19 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
      * <tt>AND</tt>.
      */
     public CommonTermsQueryBuilder highFreqOperator(Operator operator) {
-        this.highFreqOperator = (operator == null) ? DEFAULT_HIGH_FREQ_OCCUR : operator;
+        this.highFreqOperator = operator;
         return this;
     }
 
-    public Operator highFreqOperator() {
-        return highFreqOperator;
-    }
-
     /**
      * Sets the operator to use for terms with a low document frequency (less
      * than {@link #cutoffFrequency(float)}. Defaults to <tt>AND</tt>.
      */
     public CommonTermsQueryBuilder lowFreqOperator(Operator operator) {
-        this.lowFreqOperator = (operator == null) ? DEFAULT_LOW_FREQ_OCCUR : operator;
+        this.lowFreqOperator = operator;
         return this;
     }
 
-    public Operator lowFreqOperator() {
-        return lowFreqOperator;
-    }
-
     /**
      * Explicitly set the analyzer to use. Defaults to use explicit mapping
      * config for the field, or, if not set, the default search analyzer.
@@ -139,8 +112,13 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
         return this;
     }
 
-    public String analyzer() {
-        return this.analyzer;
+    /**
+     * Set the boost to apply to the query.
+     */
+    @Override
+    public CommonTermsQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
@@ -148,17 +126,13 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
      * in [0..1] (or absolute number >=1) representing the maximum threshold of
      * a terms document frequency to be considered a low frequency term.
      * Defaults to
-     * <tt>{@value #DEFAULT_CUTOFF_FREQ}</tt>
+     * <tt>{@value CommonTermsQueryParser#DEFAULT_MAX_TERM_DOC_FREQ}</tt>
      */
     public CommonTermsQueryBuilder cutoffFrequency(float cutoffFrequency) {
         this.cutoffFrequency = cutoffFrequency;
         return this;
     }
 
-    public float cutoffFrequency() {
-        return this.cutoffFrequency;
-    }
-
     /**
      * Sets the minimum number of high frequent query terms that need to match in order to
      * produce a hit when there are no low frequen terms.
@@ -168,10 +142,6 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
         return this;
     }
 
-    public String highFreqMinimumShouldMatch() {
-        return this.highFreqMinimumShouldMatch;
-    }
-
     /**
      * Sets the minimum number of low frequent query terms that need to match in order to
      * produce a hit.
@@ -180,32 +150,44 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
         this.lowFreqMinimumShouldMatch = lowFreqMinimumShouldMatch;
         return this;
     }
-
-    public String lowFreqMinimumShouldMatch() {
-        return this.lowFreqMinimumShouldMatch;
-    }
-
+    
     public CommonTermsQueryBuilder disableCoord(boolean disableCoord) {
         this.disableCoord = disableCoord;
         return this;
     }
 
-    public boolean disableCoord() {
-        return this.disableCoord;
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public CommonTermsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(CommonTermsQueryParser.NAME);
+        builder.startObject(name);
+
         builder.field("query", text);
-        builder.field("disable_coord", disableCoord);
-        builder.field("high_freq_operator", highFreqOperator.toString());
-        builder.field("low_freq_operator", lowFreqOperator.toString());
+        if (disableCoord != null) {
+            builder.field("disable_coord", disableCoord);
+        }
+        if (highFreqOperator != null) {
+            builder.field("high_freq_operator", highFreqOperator.toString());
+        }
+        if (lowFreqOperator != null) {
+            builder.field("low_freq_operator", lowFreqOperator.toString());
+        }
         if (analyzer != null) {
             builder.field("analyzer", analyzer);
         }
-        builder.field("cutoff_frequency", cutoffFrequency);
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
+        if (cutoffFrequency != null) {
+            builder.field("cutoff_frequency", cutoffFrequency);
+        }
         if (lowFreqMinimumShouldMatch != null || highFreqMinimumShouldMatch != null) {
             builder.startObject("minimum_should_match");
             if (lowFreqMinimumShouldMatch != null) {
@@ -216,125 +198,11 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
             }
             builder.endObject();
         }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        String field;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            field = fieldType.names().indexName();
-        } else {
-            field = fieldName;
-        }
-
-        Analyzer analyzerObj;
-        if (analyzer == null) {
-            if (fieldType != null) {
-                analyzerObj = context.getSearchAnalyzer(fieldType);
-            } else {
-                analyzerObj = context.mapperService().searchAnalyzer();
-            }
-        } else {
-            analyzerObj = context.mapperService().analysisService().analyzer(analyzer);
-            if (analyzerObj == null) {
-                throw new QueryShardException(context, "[common] analyzer [" + analyzer + "] not found");
-            }
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
 
-        Occur highFreqOccur = highFreqOperator.toBooleanClauseOccur();
-        Occur lowFreqOccur = lowFreqOperator.toBooleanClauseOccur();
-
-        ExtendedCommonTermsQuery commonsQuery = new ExtendedCommonTermsQuery(highFreqOccur, lowFreqOccur, cutoffFrequency, disableCoord, fieldType);
-        return parseQueryString(commonsQuery, text, field, analyzerObj, lowFreqMinimumShouldMatch, highFreqMinimumShouldMatch);
-    }
-
-    static Query parseQueryString(ExtendedCommonTermsQuery query, Object queryString, String field, Analyzer analyzer,
-                                         String lowFreqMinimumShouldMatch, String highFreqMinimumShouldMatch) throws IOException {
-        // Logic similar to QueryParser#getFieldQuery
-        int count = 0;
-        try (TokenStream source = analyzer.tokenStream(field, queryString.toString())) {
-            source.reset();
-            CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);
-            BytesRefBuilder builder = new BytesRefBuilder();
-            while (source.incrementToken()) {
-                // UTF-8
-                builder.copyChars(termAtt);
-                query.add(new Term(field, builder.toBytesRef()));
-                count++;
-            }
-        }
-
-        if (count == 0) {
-            return null;
-        }
-        query.setLowFreqMinimumNumberShouldMatch(lowFreqMinimumShouldMatch);
-        query.setHighFreqMinimumNumberShouldMatch(highFreqMinimumShouldMatch);
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.text == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected CommonTermsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        CommonTermsQueryBuilder commonTermsQueryBuilder = new CommonTermsQueryBuilder(in.readString(), in.readGenericValue());
-        commonTermsQueryBuilder.highFreqOperator = Operator.readOperatorFrom(in);
-        commonTermsQueryBuilder.lowFreqOperator = Operator.readOperatorFrom(in);
-        commonTermsQueryBuilder.analyzer = in.readOptionalString();
-        commonTermsQueryBuilder.lowFreqMinimumShouldMatch = in.readOptionalString();
-        commonTermsQueryBuilder.highFreqMinimumShouldMatch = in.readOptionalString();
-        commonTermsQueryBuilder.disableCoord = in.readBoolean();
-        commonTermsQueryBuilder.cutoffFrequency = in.readFloat();
-        return commonTermsQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(this.fieldName);
-        out.writeGenericValue(this.text);
-        highFreqOperator.writeTo(out);
-        lowFreqOperator.writeTo(out);
-        out.writeOptionalString(analyzer);
-        out.writeOptionalString(lowFreqMinimumShouldMatch);
-        out.writeOptionalString(highFreqMinimumShouldMatch);
-        out.writeBoolean(disableCoord);
-        out.writeFloat(cutoffFrequency);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, text, highFreqOperator, lowFreqOperator, analyzer,
-                lowFreqMinimumShouldMatch, highFreqMinimumShouldMatch, disableCoord, cutoffFrequency);
-    }
-
-    @Override
-    protected boolean doEquals(CommonTermsQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(text, other.text) &&
-                Objects.equals(highFreqOperator, other.highFreqOperator) &&
-                Objects.equals(lowFreqOperator, other.lowFreqOperator) &&
-                Objects.equals(analyzer, other.analyzer) &&
-                Objects.equals(lowFreqMinimumShouldMatch, other.lowFreqMinimumShouldMatch) &&
-                Objects.equals(highFreqMinimumShouldMatch, other.highFreqMinimumShouldMatch) &&
-                Objects.equals(disableCoord, other.disableCoord) &&
-                Objects.equals(cutoffFrequency, other.cutoffFrequency);
+        builder.endObject();
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java
index 65f4fa3..c18229e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java
@@ -19,15 +19,36 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.queries.ExtendedCommonTermsQuery;
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.util.BytesRefBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
 
 /**
- * Parser for common terms query
+ *
  */
-public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuilder> {
+public class CommonTermsQueryParser implements QueryParser {
+
+    public static final String NAME = "common";
+
+    static final float DEFAULT_MAX_TERM_DOC_FREQ = 0.01f;
+
+    static final Occur DEFAULT_HIGH_FREQ_OCCUR = Occur.SHOULD;
+
+    static final Occur DEFAULT_LOW_FREQ_OCCUR = Occur.SHOULD;
+
+    static final boolean DEFAULT_DISABLE_COORD = true;
+
 
     @Inject
     public CommonTermsQueryParser() {
@@ -35,26 +56,26 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
 
     @Override
     public String[] names() {
-        return new String[] { CommonTermsQueryBuilder.NAME };
+        return new String[] { NAME };
     }
 
     @Override
-    public CommonTermsQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
         XContentParser.Token token = parser.nextToken();
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new QueryParsingException(parseContext, "[common] query malformed, no field");
         }
         String fieldName = parser.currentName();
-        Object text = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        String analyzer = null;
+        Object value = null;
+        float boost = 1.0f;
+        String queryAnalyzer = null;
         String lowFreqMinimumShouldMatch = null;
         String highFreqMinimumShouldMatch = null;
-        boolean disableCoord = CommonTermsQueryBuilder.DEFAULT_DISABLE_COORD;
-        Operator highFreqOperator = CommonTermsQueryBuilder.DEFAULT_HIGH_FREQ_OCCUR;
-        Operator lowFreqOperator = CommonTermsQueryBuilder.DEFAULT_LOW_FREQ_OCCUR;
-        float cutoffFrequency = CommonTermsQueryBuilder.DEFAULT_CUTOFF_FREQ;
+        boolean disableCoord = DEFAULT_DISABLE_COORD;
+        Occur highFreqOccur = DEFAULT_HIGH_FREQ_OCCUR;
+        Occur lowFreqOccur = DEFAULT_LOW_FREQ_OCCUR;
+        float maxTermFrequency = DEFAULT_MAX_TERM_DOC_FREQ;
         String queryName = null;
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
@@ -84,21 +105,41 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
                     }
                 } else if (token.isValue()) {
                     if ("query".equals(currentFieldName)) {
-                        text = parser.objectText();
+                        value = parser.objectText();
                     } else if ("analyzer".equals(currentFieldName)) {
-                        analyzer = parser.text();
+                        String analyzer = parser.text();
+                        if (parseContext.analysisService().analyzer(analyzer) == null) {
+                            throw new QueryParsingException(parseContext, "[common] analyzer [" + parser.text() + "] not found");
+                        }
+                        queryAnalyzer = analyzer;
                     } else if ("disable_coord".equals(currentFieldName) || "disableCoord".equals(currentFieldName)) {
                         disableCoord = parser.booleanValue();
                     } else if ("boost".equals(currentFieldName)) {
                         boost = parser.floatValue();
                     } else if ("high_freq_operator".equals(currentFieldName) || "highFreqOperator".equals(currentFieldName)) {
-                        highFreqOperator = Operator.fromString(parser.text());
+                        String op = parser.text();
+                        if ("or".equalsIgnoreCase(op)) {
+                            highFreqOccur = BooleanClause.Occur.SHOULD;
+                        } else if ("and".equalsIgnoreCase(op)) {
+                            highFreqOccur = BooleanClause.Occur.MUST;
+                        } else {
+                            throw new QueryParsingException(parseContext,
+                                    "[common] query requires operator to be either 'and' or 'or', not [" + op + "]");
+                        }
                     } else if ("low_freq_operator".equals(currentFieldName) || "lowFreqOperator".equals(currentFieldName)) {
-                        lowFreqOperator = Operator.fromString(parser.text());
+                        String op = parser.text();
+                        if ("or".equalsIgnoreCase(op)) {
+                            lowFreqOccur = BooleanClause.Occur.SHOULD;
+                        } else if ("and".equalsIgnoreCase(op)) {
+                            lowFreqOccur = BooleanClause.Occur.MUST;
+                        } else {
+                            throw new QueryParsingException(parseContext,
+                                    "[common] query requires operator to be either 'and' or 'or', not [" + op + "]");
+                        }
                     } else if ("minimum_should_match".equals(currentFieldName) || "minimumShouldMatch".equals(currentFieldName)) {
                         lowFreqMinimumShouldMatch = parser.text();
                     } else if ("cutoff_frequency".equals(currentFieldName)) {
-                        cutoffFrequency = parser.floatValue();
+                        maxTermFrequency = parser.floatValue();
                     } else if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
                     } else {
@@ -108,7 +149,7 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
             }
             parser.nextToken();
         } else {
-            text = parser.objectText();
+            value = parser.objectText();
             // move to the next token
             token = parser.nextToken();
             if (token != XContentParser.Token.END_OBJECT) {
@@ -118,23 +159,66 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
             }
         }
 
-        if (text == null) {
+        if (value == null) {
             throw new QueryParsingException(parseContext, "No text specified for text query");
         }
-        return new CommonTermsQueryBuilder(fieldName, text)
-                .lowFreqMinimumShouldMatch(lowFreqMinimumShouldMatch)
-                .highFreqMinimumShouldMatch(highFreqMinimumShouldMatch)
-                .analyzer(analyzer)
-                .highFreqOperator(highFreqOperator)
-                .lowFreqOperator(lowFreqOperator)
-                .disableCoord(disableCoord)
-                .cutoffFrequency(cutoffFrequency)
-                .boost(boost)
-                .queryName(queryName);
+        String field;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            field = fieldType.names().indexName();
+        } else {
+            field = fieldName;
+        }
+
+        Analyzer analyzer = null;
+        if (queryAnalyzer == null) {
+            if (fieldType != null) {
+                analyzer = fieldType.searchAnalyzer();
+            }
+            if (analyzer == null && fieldType != null) {
+                analyzer = parseContext.getSearchAnalyzer(fieldType);
+            }
+            if (analyzer == null) {
+                analyzer = parseContext.mapperService().searchAnalyzer();
+            }
+        } else {
+            analyzer = parseContext.mapperService().analysisService().analyzer(queryAnalyzer);
+            if (analyzer == null) {
+                throw new IllegalArgumentException("No analyzer found for [" + queryAnalyzer + "]");
+            }
+        }
+
+        ExtendedCommonTermsQuery commonsQuery = new ExtendedCommonTermsQuery(highFreqOccur, lowFreqOccur, maxTermFrequency, disableCoord, fieldType);
+        commonsQuery.setBoost(boost);
+        Query query = parseQueryString(commonsQuery, value.toString(), field, parseContext, analyzer, lowFreqMinimumShouldMatch, highFreqMinimumShouldMatch);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 
-    @Override
-    public CommonTermsQueryBuilder getBuilderPrototype() {
-        return CommonTermsQueryBuilder.PROTOTYPE;
+
+    private final Query parseQueryString(ExtendedCommonTermsQuery query, String queryString, String field, QueryParseContext parseContext,
+            Analyzer analyzer, String lowFreqMinimumShouldMatch, String highFreqMinimumShouldMatch) throws IOException {
+        // Logic similar to QueryParser#getFieldQuery
+        int count = 0;
+        try (TokenStream source = analyzer.tokenStream(field, queryString.toString())) {
+            source.reset();
+            CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);
+            BytesRefBuilder builder = new BytesRefBuilder();
+            while (source.incrementToken()) {
+                // UTF-8
+                builder.copyChars(termAtt);
+                query.add(new Term(field, builder.toBytesRef()));
+                count++;
+            }
+        }
+
+        if (count == 0) {
+            return null;
+        }
+        query.setLowFreqMinimumNumberShouldMatch(lowFreqMinimumShouldMatch);
+        query.setHighFreqMinimumNumberShouldMatch(highFreqMinimumShouldMatch);
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java
index 10b14e0..bdcbe9c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java
@@ -19,10 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
@@ -32,84 +28,41 @@ import java.util.Objects;
  * A query that wraps a filter and simply returns a constant score equal to the
  * query boost for every document in the filter.
  */
-public class ConstantScoreQueryBuilder extends AbstractQueryBuilder<ConstantScoreQueryBuilder> {
-
-    public static final String NAME = "constant_score";
+public class ConstantScoreQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<ConstantScoreQueryBuilder> {
 
     private final QueryBuilder filterBuilder;
 
-    static final ConstantScoreQueryBuilder PROTOTYPE = new ConstantScoreQueryBuilder(null);
+    private float boost = -1;
 
     /**
-     * A query that wraps another query and simply returns a constant score equal to the
+     * A query that wraps a query and simply returns a constant score equal to the
      * query boost for every document in the query.
      *
      * @param filterBuilder The query to wrap in a constant score query
      */
     public ConstantScoreQueryBuilder(QueryBuilder filterBuilder) {
-        this.filterBuilder = filterBuilder;
+        this.filterBuilder = Objects.requireNonNull(filterBuilder);
     }
 
     /**
-     * @return the query that was wrapped in this constant score query
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public QueryBuilder innerQuery() {
-        return this.filterBuilder;
+    @Override
+    public ConstantScoreQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(ConstantScoreQueryParser.NAME);
         builder.field("filter");
         filterBuilder.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerFilter = filterBuilder.toFilter(context);
-        if (innerFilter == null ) {
-            // return null so that parent queries (e.g. bool) also ignore this
-            return null;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return new ConstantScoreQuery(innerFilter);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (filterBuilder == null) {
-            validationException = addValidationError("inner clause [filter] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(filterBuilder, validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(filterBuilder);
-    }
-
-    @Override
-    protected boolean doEquals(ConstantScoreQueryBuilder other) {
-        return Objects.equals(filterBuilder, other.filterBuilder);
-    }
-
-    @Override
-    protected ConstantScoreQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder innerFilterBuilder = in.readQuery();
-        return new ConstantScoreQueryBuilder(innerFilterBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(filterBuilder);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java
index ba261e8..d8a34b9 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
@@ -27,10 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for constant_score query
+ *
  */
-public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQueryBuilder> {
+public class ConstantScoreQueryParser implements QueryParser {
 
+    public static final String NAME = "constant_score";
     private static final ParseField INNER_QUERY_FIELD = new ParseField("filter", "query");
 
     @Inject
@@ -39,17 +42,16 @@ public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQuery
 
     @Override
     public String[] names() {
-        return new String[]{ConstantScoreQueryBuilder.NAME, Strings.toCamelCase(ConstantScoreQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public ConstantScoreQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder query = null;
+        Query filter = null;
         boolean queryFound = false;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -60,15 +62,13 @@ public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQuery
                 // skip
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, INNER_QUERY_FIELD)) {
-                    query = parseContext.parseInnerFilterToQueryBuilder();
+                    filter = parseContext.parseInnerFilter();
                     queryFound = true;
                 } else {
                     throw new QueryParsingException(parseContext, "[constant_score] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
+                if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[constant_score] query does not support [" + currentFieldName + "]");
@@ -79,14 +79,12 @@ public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQuery
             throw new QueryParsingException(parseContext, "[constant_score] requires a 'filter' element");
         }
 
-        ConstantScoreQueryBuilder constantScoreBuilder = new ConstantScoreQueryBuilder(query);
-        constantScoreBuilder.boost(boost);
-        constantScoreBuilder.queryName(queryName);
-        return constantScoreBuilder;
-    }
+        if (filter == null) {
+            return null;
+        }
 
-    @Override
-    public ConstantScoreQueryBuilder getBuilderPrototype() {
-        return ConstantScoreQueryBuilder.PROTOTYPE;
+        filter = new ConstantScoreQuery(filter);
+        filter.setBoost(boost);
+        return filter;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java
index 9b43de6..3724a05 100644
--- a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java
@@ -19,34 +19,25 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.DisjunctionMaxQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-import java.util.Objects;
 
 /**
  * A query that generates the union of documents produced by its sub-queries, and that scores each document
  * with the maximum score for that document as produced by any sub-query, plus a tie breaking increment for any
  * additional matching sub-queries.
  */
-public class DisMaxQueryBuilder extends AbstractQueryBuilder<DisMaxQueryBuilder> {
+public class DisMaxQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<DisMaxQueryBuilder> {
 
-    public static final String NAME = "dis_max";
+    private ArrayList<QueryBuilder> queries = new ArrayList<>();
 
-    private final ArrayList<QueryBuilder> queries = new ArrayList<>();
+    private float boost = -1;
 
-    /** Default multiplication factor for breaking ties in document scores.*/
-    public static float DEFAULT_TIE_BREAKER = 0.0f;
-    private float tieBreaker = DEFAULT_TIE_BREAKER;
+    private float tieBreaker = -1;
 
-    static final DisMaxQueryBuilder PROTOTYPE = new DisMaxQueryBuilder();
+    private String queryName;
 
     /**
      * Add a sub-query to this disjunction.
@@ -57,10 +48,13 @@ public class DisMaxQueryBuilder extends AbstractQueryBuilder<DisMaxQueryBuilder>
     }
 
     /**
-     * @return an immutable list copy of the current sub-queries of this disjunction
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public List<QueryBuilder> innerQueries() {
-        return this.queries;
+    @Override
+    public DisMaxQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
@@ -75,70 +69,30 @@ public class DisMaxQueryBuilder extends AbstractQueryBuilder<DisMaxQueryBuilder>
     }
 
     /**
-     * @return the tie breaker score
-     * @see DisMaxQueryBuilder#tieBreaker(float)
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public float tieBreaker() {
-        return this.tieBreaker;
+    public DisMaxQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("tie_breaker", tieBreaker);
+        builder.startObject(DisMaxQueryParser.NAME);
+        if (tieBreaker != -1) {
+            builder.field("tie_breaker", tieBreaker);
+        }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         builder.startArray("queries");
         for (QueryBuilder queryBuilder : queries) {
             queryBuilder.toXContent(builder, params);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // return null if there are no queries at all
-        Collection<Query> luceneQueries = toQueries(queries, context);
-        if (luceneQueries.isEmpty()) {
-            return null;
-        }
-
-        return new DisjunctionMaxQuery(luceneQueries, tieBreaker);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQueries(queries, null);
-    }
-
-    @Override
-    protected DisMaxQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        DisMaxQueryBuilder disMax = new DisMaxQueryBuilder();
-        List<QueryBuilder> queryBuilders = readQueries(in);
-        disMax.queries.addAll(queryBuilders);
-        disMax.tieBreaker = in.readFloat();
-        return disMax;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, queries);
-        out.writeFloat(tieBreaker);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queries, tieBreaker);
-    }
-
-    @Override
-    protected boolean doEquals(DisMaxQueryBuilder other) {
-        return Objects.equals(queries, other.queries) &&
-               Objects.equals(tieBreaker, other.tieBreaker);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java
index 704328f..dc901d6 100644
--- a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java
@@ -19,19 +19,22 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.DisjunctionMaxQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
- * Parser for dis_max query
+ *
  */
-public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
+public class DisMaxQueryParser implements QueryParser {
+
+    public static final String NAME = "dis_max";
 
     @Inject
     public DisMaxQueryParser() {
@@ -39,17 +42,17 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{DisMaxQueryBuilder.NAME, Strings.toCamelCase(DisMaxQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public DisMaxQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        float tieBreaker = DisMaxQueryBuilder.DEFAULT_TIE_BREAKER;
+        float boost = 1.0f;
+        float tieBreaker = 0.0f;
 
-        final List<QueryBuilder> queries = newArrayList();
+        List<Query> queries = new ArrayList<>();
         boolean queriesFound = false;
         String queryName = null;
 
@@ -61,8 +64,10 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("queries".equals(currentFieldName)) {
                     queriesFound = true;
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    queries.add(query);
+                    Query query = parseContext.parseInnerQuery();
+                    if (query != null) {
+                        queries.add(query);
+                    }
                 } else {
                     throw new QueryParsingException(parseContext, "[dis_max] query does not support [" + currentFieldName + "]");
                 }
@@ -70,8 +75,10 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
                 if ("queries".equals(currentFieldName)) {
                     queriesFound = true;
                     while (token != XContentParser.Token.END_ARRAY) {
-                        QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                        queries.add(query);
+                        Query query = parseContext.parseInnerQuery();
+                        if (query != null) {
+                            queries.add(query);
+                        }
                         token = parser.nextToken();
                     }
                 } else {
@@ -94,18 +101,15 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
             throw new QueryParsingException(parseContext, "[dis_max] requires 'queries' field");
         }
 
-        DisMaxQueryBuilder disMaxQuery = new DisMaxQueryBuilder();
-        disMaxQuery.tieBreaker(tieBreaker);
-        disMaxQuery.queryName(queryName);
-        disMaxQuery.boost(boost);
-        for (QueryBuilder query : queries) {
-            disMaxQuery.add(query);
+        if (queries.isEmpty()) {
+            return null;
         }
-        return disMaxQuery;
-    }
 
-    @Override
-    public DisMaxQueryBuilder getBuilderPrototype() {
-        return DisMaxQueryBuilder.PROTOTYPE;
+        DisjunctionMaxQuery query = new DisjunctionMaxQuery(queries, tieBreaker);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/EmptyQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/EmptyQueryBuilder.java
deleted file mode 100644
index c59d8d3..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/EmptyQueryBuilder.java
+++ /dev/null
@@ -1,118 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.action.support.ToXContentToBytes;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentType;
-
-import java.io.IOException;
-
-/**
- * A {@link QueryBuilder} that is a stand in replacement for an empty query clause in the DSL.
- * The current DSL allows parsing inner queries / filters like "{ }", in order to have a
- * valid non-null representation of these clauses that actually do nothing we can use this class.
- *
- * This builder has no corresponding parser and it is not registered under the query name. It is
- * intended to be used internally as a stand-in for nested queries that are left empty and should
- * be ignored upstream.
- */
-public class EmptyQueryBuilder extends ToXContentToBytes implements QueryBuilder<EmptyQueryBuilder> {
-
-    public static final String NAME = "empty_query";
-
-    /** the one and only empty query builder */
-    public static final EmptyQueryBuilder PROTOTYPE = new EmptyQueryBuilder();
-
-    // prevent instances other than prototype
-    private EmptyQueryBuilder() {
-        super(XContentType.JSON);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public String getName() {
-        return getWriteableName();
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject();
-        builder.endObject();
-        return builder;
-    }
-
-    @Override
-    public Query toQuery(QueryShardContext context) throws IOException {
-        // empty
-        return null;
-    }
-
-    @Override
-    public Query toFilter(QueryShardContext context) throws IOException {
-        // empty
-        return null;
-    }
-
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-    }
-
-    @Override
-    public EmptyQueryBuilder readFrom(StreamInput in) throws IOException {
-        return EmptyQueryBuilder.PROTOTYPE;
-    }
-
-    @Override
-    public EmptyQueryBuilder queryName(String queryName) {
-        //no-op
-        return this;
-    }
-
-    @Override
-    public String queryName() {
-        return null;
-    }
-
-    @Override
-    public float boost() {
-        return -1;
-    }
-
-    @Override
-    public EmptyQueryBuilder boost(float boost) {
-        //no-op
-        return this;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java
index 6808793..9980d81 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java
@@ -19,126 +19,38 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.*;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
-import java.util.Collection;
-import java.util.Objects;
 
 /**
  * Constructs a query that only match on documents that the field has a value in them.
  */
-public class ExistsQueryBuilder extends AbstractQueryBuilder<ExistsQueryBuilder> {
+public class ExistsQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "exists";
+    private String name;
 
-    private final String fieldName;
+    private String queryName;
 
-    static final ExistsQueryBuilder PROTOTYPE = new ExistsQueryBuilder(null);
-
-    public ExistsQueryBuilder(String fieldName) {
-        this.fieldName = fieldName;
+    public ExistsQueryBuilder(String name) {
+        this.name = name;
     }
 
     /**
-     * @return the field name that has to exist for this query to match
+     * Sets the query name for the query that can be used when searching for matched_queries per hit.
      */
-    public String fieldName() {
-        return this.fieldName;
+    public ExistsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("field", fieldName);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return newFilter(context, fieldName);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
-
-    public static Query newFilter(QueryShardContext context, String fieldPattern) {
-        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType)context.mapperService().fullName(FieldNamesFieldMapper.NAME);
-        if (fieldNamesFieldType == null) {
-            // can only happen when no types exist, so no docs exist either
-            return Queries.newMatchNoDocsQuery();
-        }
-
-        ObjectMapper objectMapper = context.getObjectMapper(fieldPattern);
-        if (objectMapper != null) {
-            // automatic make the object mapper pattern
-            fieldPattern = fieldPattern + ".*";
-        }
-
-        Collection<String> fields = context.simpleMatchToIndexNames(fieldPattern);
-        if (fields.isEmpty()) {
-            // no fields exists, so we should not match anything
-            return Queries.newMatchNoDocsQuery();
-        }
-
-        BooleanQuery boolFilter = new BooleanQuery();
-        for (String field : fields) {
-            MappedFieldType fieldType = context.fieldMapper(field);
-            Query filter = null;
-            if (fieldNamesFieldType.isEnabled()) {
-                final String f;
-                if (fieldType != null) {
-                    f = fieldType.names().indexName();
-                } else {
-                    f = field;
-                }
-                filter = fieldNamesFieldType.termQuery(f, context);
-            }
-            // if _field_names are not indexed, we need to go the slow way
-            if (filter == null && fieldType != null) {
-                filter = fieldType.rangeQuery(null, null, true, true);
-            }
-            if (filter == null) {
-                filter = new TermRangeQuery(field, null, null, true, true);
-            }
-            boolFilter.add(filter, BooleanClause.Occur.SHOULD);
+        builder.startObject(ExistsQueryParser.NAME);
+        builder.field("field", name);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return new ConstantScoreQuery(boolFilter);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName);
-    }
-
-    @Override
-    protected boolean doEquals(ExistsQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName);
-    }
-
-    @Override
-    protected ExistsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new ExistsQueryBuilder(in.readString());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java
index bd584bc..0ce578c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java
@@ -19,15 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.*;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
+import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
+import java.util.Collection;
 
 /**
- * Parser for exists query
+ *
  */
-public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
+public class ExistsQueryParser implements QueryParser {
+
+    public static final String NAME = "exists";
 
     @Inject
     public ExistsQueryParser() {
@@ -35,16 +43,15 @@ public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{ExistsQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public ExistsQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldPattern = null;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
 
         XContentParser.Token token;
         String currentFieldName = null;
@@ -56,8 +63,6 @@ public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
                     fieldPattern = parser.text();
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[exists] query does not support [" + currentFieldName + "]");
                 }
@@ -68,14 +73,55 @@ public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
             throw new QueryParsingException(parseContext, "exists must be provided with a [field]");
         }
 
-        ExistsQueryBuilder builder = new ExistsQueryBuilder(fieldPattern);
-        builder.queryName(queryName);
-        builder.boost(boost);
-        return builder;
+        return newFilter(parseContext, fieldPattern, queryName);
     }
 
-    @Override
-    public ExistsQueryBuilder getBuilderPrototype() {
-        return ExistsQueryBuilder.PROTOTYPE;
+    public static Query newFilter(QueryParseContext parseContext, String fieldPattern, String queryName) {
+        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType)parseContext.mapperService().fullName(FieldNamesFieldMapper.NAME);
+        if (fieldNamesFieldType == null) {
+            // can only happen when no types exist, so no docs exist either
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        ObjectMapper objectMapper = parseContext.getObjectMapper(fieldPattern);
+        if (objectMapper != null) {
+            // automatic make the object mapper pattern
+            fieldPattern = fieldPattern + ".*";
+        }
+
+        Collection<String> fields = parseContext.simpleMatchToIndexNames(fieldPattern);
+        if (fields.isEmpty()) {
+            // no fields exists, so we should not match anything
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        BooleanQuery boolFilter = new BooleanQuery();
+        for (String field : fields) {
+            MappedFieldType fieldType = parseContext.fieldMapper(field);
+            Query filter = null;
+            if (fieldNamesFieldType.isEnabled()) {
+                final String f;
+                if (fieldType != null) {
+                    f = fieldType.names().indexName();
+                } else {
+                    f = field;
+                }
+                filter = fieldNamesFieldType.termQuery(f, parseContext);
+            }
+            // if _field_names are not indexed, we need to go the slow way
+            if (filter == null && fieldType != null) {
+                filter = fieldType.rangeQuery(null, null, true, true);
+            }
+            if (filter == null) {
+                filter = new TermRangeQuery(field, null, null, true, true);
+            }
+            boolFilter.add(filter, BooleanClause.Occur.SHOULD);
+        }
+
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, boolFilter);
+        }
+        return new ConstantScoreQuery(boolFilter);
     }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FQueryFilterBuilder.java b/core/src/main/java/org/elasticsearch/index/query/FQueryFilterBuilder.java
deleted file mode 100644
index 85fdad1..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/FQueryFilterBuilder.java
+++ /dev/null
@@ -1,111 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-
-import java.io.IOException;
-import java.util.Objects;
-
-/**
- * A filter that simply wraps a query. Same as the {@link QueryFilterBuilder} except that it allows also to
- * associate a name with the query filter.
- * @deprecated Useless now that queries and filters are merged: pass the
- *             query as a filter directly.
- */
-@Deprecated
-public class FQueryFilterBuilder extends AbstractQueryBuilder<FQueryFilterBuilder> {
-
-    public static final String NAME = "fquery";
-
-    static final FQueryFilterBuilder PROTOTYPE = new FQueryFilterBuilder(null);
-
-    private final QueryBuilder queryBuilder;
-
-    /**
-     * A filter that simply wraps a query.
-     *
-     * @param queryBuilder The query to wrap as a filter
-     */
-    public FQueryFilterBuilder(QueryBuilder queryBuilder) {
-        this.queryBuilder = queryBuilder;
-    }
-
-    /**
-     * @return the query builder that is wrapped by this {@link FQueryFilterBuilder}
-     */
-    public QueryBuilder innerQuery() {
-        return this.queryBuilder;
-    }
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(FQueryFilterBuilder.NAME);
-        builder.field("query");
-        queryBuilder.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerQuery = this.queryBuilder.toQuery(context);
-        if (innerQuery == null) {
-            return null;
-        }
-        return new ConstantScoreQuery(innerQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQuery(queryBuilder, null);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queryBuilder);
-    }
-
-    @Override
-    protected boolean doEquals(FQueryFilterBuilder other) {
-        return Objects.equals(queryBuilder, other.queryBuilder);
-    }
-
-    @Override
-    protected FQueryFilterBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder innerQueryBuilder = in.readQuery();
-        FQueryFilterBuilder fquery = new FQueryFilterBuilder(innerQueryBuilder);
-        return fquery;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(queryBuilder);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/FQueryFilterParser.java b/core/src/main/java/org/elasticsearch/index/query/FQueryFilterParser.java
index 46ab50f..4c0f782 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FQueryFilterParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FQueryFilterParser.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
@@ -27,11 +29,11 @@ import java.io.IOException;
 /**
  * The "fquery" filter is the same as the {@link QueryFilterParser} except that it allows also to
  * associate a name with the query filter.
- * @deprecated Useless now that queries and filters are merged: pass the
- *             query as a filter directly.
  */
 @Deprecated
-public class FQueryFilterParser extends BaseQueryParser<FQueryFilterBuilder> {
+public class FQueryFilterParser implements QueryParser {
+
+    public static final String NAME = "fquery";
 
     @Inject
     public FQueryFilterParser() {
@@ -39,17 +41,16 @@ public class FQueryFilterParser extends BaseQueryParser<FQueryFilterBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{FQueryFilterBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public FQueryFilterBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder wrappedQuery = null;
+        Query query = null;
         boolean queryFound = false;
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
         String currentFieldName = null;
         XContentParser.Token token;
@@ -61,15 +62,13 @@ public class FQueryFilterParser extends BaseQueryParser<FQueryFilterBuilder> {
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("query".equals(currentFieldName)) {
                     queryFound = true;
-                    wrappedQuery = parseContext.parseInnerQueryBuilder();
+                    query = parseContext.parseInnerQuery();
                 } else {
                     throw new QueryParsingException(parseContext, "[fquery] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[fquery] query does not support [" + currentFieldName + "]");
                 }
@@ -78,14 +77,13 @@ public class FQueryFilterParser extends BaseQueryParser<FQueryFilterBuilder> {
         if (!queryFound) {
             throw new QueryParsingException(parseContext, "[fquery] requires 'query' element");
         }
-        FQueryFilterBuilder queryBuilder = new FQueryFilterBuilder(wrappedQuery);
-        queryBuilder.queryName(queryName);
-        queryBuilder.boost(boost);
-        return queryBuilder;
-    }
-
-    @Override
-    public FQueryFilterBuilder getBuilderPrototype() {
-        return FQueryFilterBuilder.PROTOTYPE;
+        if (query == null) {
+            return null;
+        }
+        query = new ConstantScoreQuery(query);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java
index a577225..c118416 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java
@@ -19,113 +19,52 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class FieldMaskingSpanQueryBuilder extends AbstractQueryBuilder<FieldMaskingSpanQueryBuilder> implements SpanQueryBuilder<FieldMaskingSpanQueryBuilder>{
-
-    public static final String NAME = "field_masking_span";
+public class FieldMaskingSpanQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<FieldMaskingSpanQueryBuilder> {
 
     private final SpanQueryBuilder queryBuilder;
 
-    private final String fieldName;
+    private final String field;
 
-    static final FieldMaskingSpanQueryBuilder PROTOTYPE = new FieldMaskingSpanQueryBuilder(null, null);
+    private float boost = -1;
 
-    /**
-     * Constructs a new {@link FieldMaskingSpanQueryBuilder} given an inner {@link SpanQueryBuilder} for
-     * a given field
-     * @param queryBuilder inner {@link SpanQueryBuilder}
-     * @param fieldName the field name
-     */
-    public FieldMaskingSpanQueryBuilder(SpanQueryBuilder queryBuilder, String fieldName) {
+    private String queryName;
+
+
+    public FieldMaskingSpanQueryBuilder(SpanQueryBuilder queryBuilder, String field) {
         this.queryBuilder = queryBuilder;
-        this.fieldName = fieldName;
+        this.field = field;
     }
 
-    /**
-     * @return the field name for this query
-     */
-    public String fieldName() {
-        return this.fieldName;
+    @Override
+    public FieldMaskingSpanQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
-     * @return the inner {@link QueryBuilder}
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public SpanQueryBuilder innerQuery() {
-        return this.queryBuilder;
+    public FieldMaskingSpanQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(FieldMaskingSpanQueryParser.NAME);
         builder.field("query");
         queryBuilder.toXContent(builder, params);
-        builder.field("field", fieldName);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected SpanQuery doToQuery(QueryShardContext context) throws IOException {
-        String fieldInQuery = fieldName;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            fieldInQuery = fieldType.names().indexName();
-        }
-        Query innerQuery = queryBuilder.toQuery(context);
-        assert innerQuery instanceof SpanQuery;
-        return new FieldMaskingSpanQuery((SpanQuery)innerQuery, fieldInQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (queryBuilder == null) {
-            validationException = addValidationError("inner clause [query] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(queryBuilder, validationException);
+        builder.field("field", field);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        if (fieldName == null || fieldName.isEmpty()) {
-            validationException = addValidationError("field name is null or empty", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    protected FieldMaskingSpanQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder innerQueryBuilder = in.readQuery();
-        return new FieldMaskingSpanQueryBuilder((SpanQueryBuilder) innerQueryBuilder, in.readString());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(queryBuilder);
-        out.writeString(fieldName);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queryBuilder, fieldName);
-    }
-
-    @Override
-    protected boolean doEquals(FieldMaskingSpanQueryBuilder other) {
-        return Objects.equals(queryBuilder, other.queryBuilder) &&
-               Objects.equals(fieldName, other.fieldName);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java
index ad77039..2980be1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java
@@ -19,15 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.FieldMapper;
+import org.elasticsearch.index.mapper.MappedFieldType;
+
 import java.io.IOException;
 
 /**
- * Parser for field_masking_span query
+ *
  */
-public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpanQueryBuilder> {
+public class FieldMaskingSpanQueryParser implements QueryParser {
+
+    public static final String NAME = "field_masking_span";
 
     @Inject
     public FieldMaskingSpanQueryParser() {
@@ -35,16 +43,16 @@ public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpa
 
     @Override
     public String[] names() {
-        return new String[]{FieldMaskingSpanQueryBuilder.NAME, Strings.toCamelCase(FieldMaskingSpanQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public FieldMaskingSpanQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
-        SpanQueryBuilder inner = null;
+        SpanQuery inner = null;
         String field = null;
         String queryName = null;
 
@@ -55,11 +63,11 @@ public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpa
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("query".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
-                        throw new QueryParsingException(parseContext, "[field_masking_span] query must be of type span query");
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
+                        throw new QueryParsingException(parseContext, "[field_masking_span] query] must be of type span query");
                     }
-                    inner = (SpanQueryBuilder) query;
+                    inner = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[field_masking_span] query does not support ["
                             + currentFieldName + "]");
@@ -83,14 +91,16 @@ public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpa
             throw new QueryParsingException(parseContext, "field_masking_span must have [field] set for it");
         }
 
-        FieldMaskingSpanQueryBuilder queryBuilder = new FieldMaskingSpanQueryBuilder(inner, field);
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
+        MappedFieldType fieldType = parseContext.fieldMapper(field);
+        if (fieldType != null) {
+            field = fieldType.names().indexName();
+        }
 
-    @Override
-    public FieldMaskingSpanQueryBuilder getBuilderPrototype() {
-        return FieldMaskingSpanQueryBuilder.PROTOTYPE;
+        FieldMaskingSpanQuery query = new FieldMaskingSpanQuery(inner, field);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/FilteredQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/FilteredQueryBuilder.java
index 471f138..93507cf 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FilteredQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FilteredQueryBuilder.java
@@ -19,140 +19,72 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
+import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A query that applies a filter to the results of another query.
  * @deprecated Use {@link BoolQueryBuilder} instead.
  */
 @Deprecated
-public class FilteredQueryBuilder extends AbstractQueryBuilder<FilteredQueryBuilder> {
+public class FilteredQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<FilteredQueryBuilder> {
 
-    /** Name of the query in the REST API. */
-    public static final String NAME = "filtered";
-    /** The query to filter. */
     private final QueryBuilder queryBuilder;
-    /** The filter to apply to the query. */
+
     private final QueryBuilder filterBuilder;
 
-    static final FilteredQueryBuilder PROTOTYPE = new FilteredQueryBuilder(null, null);
+    private float boost = -1;
 
-    /**
-     * Returns a {@link MatchAllQueryBuilder} instance that will be used as
-     * default queryBuilder if none is supplied by the user. Feel free to
-     * set queryName and boost on that instance - it's always a new one.
-     * */
-    private static QueryBuilder generateDefaultQuery() {
-        return new MatchAllQueryBuilder();
-    }
-
-    /**
-     * A query that applies a filter to the results of a match_all query.
-     * @param filterBuilder The filter to apply on the query (Can be null)
-     * */
-    public FilteredQueryBuilder(QueryBuilder filterBuilder) {
-        this(generateDefaultQuery(), filterBuilder);
-    }
+    private String queryName;
 
     /**
      * A query that applies a filter to the results of another query.
      *
-     * @param queryBuilder  The query to apply the filter to
+     * @param queryBuilder  The query to apply the filter to (Can be null)
      * @param filterBuilder The filter to apply on the query (Can be null)
      */
-    public FilteredQueryBuilder(QueryBuilder queryBuilder, QueryBuilder filterBuilder) {
-        this.queryBuilder = (queryBuilder != null) ? queryBuilder : generateDefaultQuery();
-        this.filterBuilder = (filterBuilder != null) ? filterBuilder : EmptyQueryBuilder.PROTOTYPE;
-    }
-
-    /** Returns the query to apply the filter to. */
-    public QueryBuilder innerQuery() {
-        return queryBuilder;
-    }
-
-    /** Returns the filter to apply to the query results. */
-    public QueryBuilder innerFilter() {
-        return filterBuilder;
+    public FilteredQueryBuilder(@Nullable QueryBuilder queryBuilder, @Nullable QueryBuilder filterBuilder) {
+        this.queryBuilder = queryBuilder;
+        this.filterBuilder = filterBuilder;
     }
 
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    protected boolean doEquals(FilteredQueryBuilder other) {
-        return Objects.equals(queryBuilder, other.queryBuilder) &&
-                Objects.equals(filterBuilder, other.filterBuilder);
+    public FilteredQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    public int doHashCode() {
-        return Objects.hash(queryBuilder, filterBuilder);
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public FilteredQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public Query doToQuery(QueryShardContext context) throws QueryShardException, IOException {
-        Query query = queryBuilder.toQuery(context);
-        Query filter = filterBuilder.toFilter(context);
-
-        if (query == null) {
-            // Most likely this query was generated from the JSON query DSL - it parsed to an EmptyQueryBuilder so we ignore
-            // the whole filtered query as there is nothing to filter on. See FilteredQueryParser for an example.
-            return null;
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(FilteredQueryParser.NAME);
+        if (queryBuilder != null) {
+            builder.field("query");
+            queryBuilder.toXContent(builder, params);
         }
-
-        if (filter == null || Queries.isConstantMatchAllQuery(filter)) {
-            // no filter, or match all filter
-            return query;
-        } else if (Queries.isConstantMatchAllQuery(query)) {
-            // if its a match_all query, use constant_score
-            return new ConstantScoreQuery(filter);
+        if (filterBuilder != null) {
+            builder.field("filter");
+            filterBuilder.toXContent(builder, params);
+        }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-
-        // use a BooleanQuery
-        return Queries.filtered(query, filter);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        validationException = validateInnerQuery(queryBuilder, validationException);
-        validationException = validateInnerQuery(filterBuilder, validationException);
-        return validationException;
-
-    }
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("query");
-        queryBuilder.toXContent(builder, params);
-        builder.field("filter");
-        filterBuilder.toXContent(builder, params);
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public FilteredQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder query = in.readQuery();
-        QueryBuilder filter = in.readQuery();
-        FilteredQueryBuilder qb = new FilteredQueryBuilder(query, filter);
-        return qb;
-    }
-
-    @Override
-    public void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(queryBuilder);
-        out.writeQuery(filterBuilder);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FilteredQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/FilteredQueryParser.java
index 6b94d6d..774ff74 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FilteredQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FilteredQueryParser.java
@@ -19,17 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
 /**
- * Parser for filtered query.
- * @deprecated Use {@link BoolQueryParser} instead.
+ *
  */
 @Deprecated
-public class FilteredQueryParser extends BaseQueryParser<FilteredQueryBuilder> {
+public class FilteredQueryParser implements QueryParser {
+
+    public static final String NAME = "filtered";
 
     @Inject
     public FilteredQueryParser() {
@@ -37,16 +43,17 @@ public class FilteredQueryParser extends BaseQueryParser<FilteredQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{FilteredQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public FilteredQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder query = null;
-        QueryBuilder filter = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        Query query = Queries.newMatchAllQuery();
+        Query filter = null;
+        boolean filterFound = false;
+        float boost = 1.0f;
         String queryName = null;
 
         String currentFieldName = null;
@@ -59,9 +66,10 @@ public class FilteredQueryParser extends BaseQueryParser<FilteredQueryBuilder> {
                 // skip
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("query".equals(currentFieldName)) {
-                    query = parseContext.parseInnerQueryBuilder();
+                    query = parseContext.parseInnerQuery();
                 } else if ("filter".equals(currentFieldName)) {
-                    filter = parseContext.parseInnerFilterToQueryBuilder();
+                    filterFound = true;
+                    filter = parseContext.parseInnerFilter();
                 } else {
                     throw new QueryParsingException(parseContext, "[filtered] query does not support [" + currentFieldName + "]");
                 }
@@ -78,15 +86,39 @@ public class FilteredQueryParser extends BaseQueryParser<FilteredQueryBuilder> {
             }
         }
 
-        FilteredQueryBuilder qb = new FilteredQueryBuilder(query, filter);
-        qb.boost(boost);
-        qb.queryName(queryName);
-        return qb;
-    }
+        // parsed internally, but returned null during parsing...
+        if (query == null) {
+            return null;
+        }
 
-    @Override
-    public FilteredQueryBuilder getBuilderPrototype() {
-        return FilteredQueryBuilder.PROTOTYPE;
-    }
+        if (filter == null) {
+            if (!filterFound) {
+                // we allow for null filter, so it makes compositions on the client side to be simpler
+                return query;
+            } else {
+                // even if the filter is not found, and its null, we should simply ignore it, and go
+                // by the query
+                return query;
+            }
+        }
+        if (Queries.isConstantMatchAllQuery(filter)) {
+            // this is an instance of match all filter, just execute the query
+            return query;
+        }
+
+        // if its a match_all query, use constant_score
+        if (Queries.isConstantMatchAllQuery(query)) {
+            Query q = new ConstantScoreQuery(filter);
+            q.setBoost(boost);
+            return q;
+        }
 
+        BooleanQuery filteredQuery = Queries.filtered(query, filter);
+
+        filteredQuery.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, filteredQuery);
+        }
+        return filteredQuery;
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java
index 237b415..23557b1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java
@@ -19,273 +19,177 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that does fuzzy matching for a specific value.
  */
-public class FuzzyQueryBuilder extends AbstractQueryBuilder<FuzzyQueryBuilder> implements MultiTermQueryBuilder<FuzzyQueryBuilder> {
+public class FuzzyQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<FuzzyQueryBuilder> {
 
-    public static final String NAME = "fuzzy";
-
-    /** Default maximum edit distance. Defaults to AUTO. */
-    public static final Fuzziness DEFAULT_FUZZINESS = Fuzziness.AUTO;
-
-    /** Default number of initial characters which will not be fuzzified. Defaults to 0. */
-    public static final int DEFAULT_PREFIX_LENGTH = FuzzyQuery.defaultPrefixLength;
-
-    /** Default maximum number of terms that the fuzzy query will expand to. Defaults to 50. */
-    public static final int DEFAULT_MAX_EXPANSIONS = FuzzyQuery.defaultMaxExpansions;
-
-    /** Default as to whether transpositions should be treated as a primitive edit operation, 
-     * instead of classic Levenshtein algorithm. Defaults to false. */
-    public static final boolean DEFAULT_TRANSPOSITIONS = false;
-
-    private final String fieldName;
+    private final String name;
 
     private final Object value;
 
-    private Fuzziness fuzziness = DEFAULT_FUZZINESS;
+    private float boost = -1;
 
-    private int prefixLength = DEFAULT_PREFIX_LENGTH;
+    private Fuzziness fuzziness;
 
-    private int maxExpansions = DEFAULT_MAX_EXPANSIONS;
+    private Integer prefixLength;
 
+    private Integer maxExpansions;
+    
     //LUCENE 4 UPGRADE  we need a testcase for this + documentation
-    private boolean transpositions = DEFAULT_TRANSPOSITIONS;
+    private Boolean transpositions;
 
     private String rewrite;
 
-    static final FuzzyQueryBuilder PROTOTYPE = new FuzzyQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, String value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, Object value) {
+        this.name = name;
+        this.value = value;
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, int value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, String value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, long value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, int value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, float value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, long value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, double value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, float value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, boolean value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, double value) {
+        this(name, (Object) value);
     }
 
+    // NO COMMIT: not sure we should also allow boolean?
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
+     * @param name  The name of the field
+     * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, Object value) {
-        this.fieldName = fieldName;
-        this.value = convertToBytesRefIfString(value);
+    public FuzzyQueryBuilder(String name, boolean value) {
+        this(name, (Object) value);
     }
 
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public Object value() {
-        return convertToStringIfBytesRef(this.value);
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public FuzzyQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     public FuzzyQueryBuilder fuzziness(Fuzziness fuzziness) {
-        this.fuzziness = (fuzziness == null) ? DEFAULT_FUZZINESS : fuzziness;
+        this.fuzziness = fuzziness;
         return this;
     }
-    
-    public Fuzziness fuzziness() {
-        return this.fuzziness;
-    }
 
     public FuzzyQueryBuilder prefixLength(int prefixLength) {
         this.prefixLength = prefixLength;
         return this;
     }
-    
-    public int prefixLength() {
-        return this.prefixLength;
-    }
 
     public FuzzyQueryBuilder maxExpansions(int maxExpansions) {
         this.maxExpansions = maxExpansions;
         return this;
     }
-
-    public int maxExpansions() {
-        return this.maxExpansions;
-    }
-
+    
     public FuzzyQueryBuilder transpositions(boolean transpositions) {
       this.transpositions = transpositions;
       return this;
     }
 
-    public boolean transpositions() {
-        return this.transpositions;
-    }
-
     public FuzzyQueryBuilder rewrite(String rewrite) {
         this.rewrite = rewrite;
         return this;
     }
 
-    public String rewrite() {
-        return this.rewrite;
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public FuzzyQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("value", convertToStringIfBytesRef(this.value));
-        fuzziness.toXContent(builder, params);
-        builder.field("prefix_length", prefixLength);
-        builder.field("max_expansions", maxExpansions);
-        builder.field("transpositions", transpositions);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
+        builder.startObject(FuzzyQueryParser.NAME);
+        builder.startObject(name);
+        builder.field("value", value);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public Query doToQuery(QueryShardContext context) throws QueryParsingException, IOException {
-        Query query = null;
-        if (rewrite == null && context.isFilter()) {
-            rewrite = QueryParsers.CONSTANT_SCORE.getPreferredName();
+        if (transpositions != null) {
+            builder.field("transpositions", transpositions);
         }
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            query = fieldType.fuzzyQuery(value, fuzziness, prefixLength, maxExpansions, transpositions);
+        if (fuzziness != null) {
+            fuzziness.toXContent(builder, params);
         }
-        if (query == null) {
-            int maxEdits = fuzziness.asDistance(BytesRefs.toString(value));
-            query = new FuzzyQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), maxEdits, prefixLength, maxExpansions, transpositions);
+        if (prefixLength != null) {
+            builder.field("prefix_length", prefixLength);
         }
-        if (query instanceof MultiTermQuery) {
-            MultiTermQuery.RewriteMethod rewriteMethod = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-            QueryParsers.setRewriteMethod((MultiTermQuery) query, rewriteMethod);
+        if (maxExpansions != null) {
+            builder.field("max_expansions", maxExpansions);
         }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
+        if (rewrite != null) {
+            builder.field("rewrite", rewrite);
         }
-        if (this.value == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    public FuzzyQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        FuzzyQueryBuilder fuzzyQueryBuilder = new FuzzyQueryBuilder(in.readString(), in.readGenericValue());
-        fuzzyQueryBuilder.fuzziness = Fuzziness.readFuzzinessFrom(in);
-        fuzzyQueryBuilder.prefixLength = in.readVInt();
-        fuzzyQueryBuilder.maxExpansions = in.readVInt();
-        fuzzyQueryBuilder.transpositions = in.readBoolean();
-        fuzzyQueryBuilder.rewrite = in.readOptionalString();
-        return fuzzyQueryBuilder;
-    }
-
-    @Override
-    public void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(this.fieldName);
-        out.writeGenericValue(this.value);
-        this.fuzziness.writeTo(out);
-        out.writeVInt(this.prefixLength);
-        out.writeVInt(this.maxExpansions);
-        out.writeBoolean(this.transpositions);
-        out.writeOptionalString(this.rewrite);
-    }
-
-    @Override
-    public int doHashCode() {
-        return Objects.hash(fieldName, value, fuzziness, prefixLength, maxExpansions, transpositions, rewrite);
-    }
-
-    @Override
-    public boolean doEquals(FuzzyQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(fuzziness, other.fuzziness) &&
-                Objects.equals(prefixLength, other.prefixLength) &&
-                Objects.equals(maxExpansions, other.maxExpansions) &&
-                Objects.equals(transpositions, other.transpositions) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java
index 694a303..aefdb4c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java
@@ -19,48 +19,60 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
-public class FuzzyQueryParser extends BaseQueryParser {
+/**
+ *
+ */
+public class FuzzyQueryParser implements QueryParser {
 
+    public static final String NAME = "fuzzy";
+    private static final Fuzziness DEFAULT_FUZZINESS = Fuzziness.AUTO;
     private static final ParseField FUZZINESS = Fuzziness.FIELD.withDeprecation("min_similarity");
 
+
     @Inject
     public FuzzyQueryParser() {
     }
 
     @Override
     public String[] names() {
-        return new String[]{ FuzzyQueryBuilder.NAME };
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.nextToken();
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new QueryParsingException(parseContext, "[fuzzy] query malformed, no field");
         }
-        
         String fieldName = parser.currentName();
-        Object value = null;
-
-        Fuzziness fuzziness = FuzzyQueryBuilder.DEFAULT_FUZZINESS;
-        int prefixLength = FuzzyQueryBuilder.DEFAULT_PREFIX_LENGTH;
-        int maxExpansions = FuzzyQueryBuilder.DEFAULT_MAX_EXPANSIONS;
-        boolean transpositions = FuzzyQueryBuilder.DEFAULT_TRANSPOSITIONS;
-        String rewrite = null;
 
+        Object value = null;
+        float boost = 1.0f;
+        Fuzziness fuzziness = DEFAULT_FUZZINESS;
+        int prefixLength = FuzzyQuery.defaultPrefixLength;
+        int maxExpansions = FuzzyQuery.defaultMaxExpansions;
+        boolean transpositions = FuzzyQuery.defaultTranspositions;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-
+        MultiTermQuery.RewriteMethod rewriteMethod = null;
+        if (parseContext.isFilter()) {
+            rewriteMethod = MultiTermQuery.CONSTANT_SCORE_REWRITE;
+        }
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
             String currentFieldName = null;
@@ -81,9 +93,9 @@ public class FuzzyQueryParser extends BaseQueryParser {
                     } else if ("max_expansions".equals(currentFieldName) || "maxExpansions".equals(currentFieldName)) {
                         maxExpansions = parser.intValue();
                     } else if ("transpositions".equals(currentFieldName)) {
-                        transpositions = parser.booleanValue();
+                      transpositions = parser.booleanValue();
                     } else if ("rewrite".equals(currentFieldName)) {
-                        rewrite = parser.textOrNull();
+                        rewriteMethod = QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), parser.textOrNull(), null);
                     } else if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
                     } else {
@@ -99,20 +111,26 @@ public class FuzzyQueryParser extends BaseQueryParser {
         }
 
         if (value == null) {
-            throw new QueryParsingException(parseContext, "no value specified for fuzzy query");
+            throw new QueryParsingException(parseContext, "No value specified for fuzzy query");
         }
-        return new FuzzyQueryBuilder(fieldName, value)
-                .fuzziness(fuzziness)
-                .prefixLength(prefixLength)
-                .maxExpansions(maxExpansions)
-                .transpositions(transpositions)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
+        
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.fuzzyQuery(value, fuzziness, prefixLength, maxExpansions, transpositions);
+        }
+        if (query == null) {
+            int maxEdits = fuzziness.asDistance(BytesRefs.toString(value));
+            query = new FuzzyQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), maxEdits, prefixLength, maxExpansions, transpositions);
+        }
+        if (query instanceof MultiTermQuery) {
+            QueryParsers.setRewriteMethod((MultiTermQuery) query, rewriteMethod);
+        }
+        query.setBoost(boost);
 
-    @Override
-    public FuzzyQueryBuilder getBuilderPrototype() {
-        return FuzzyQueryBuilder.PROTOTYPE;
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java
index 594cc6e..99b348e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java
@@ -25,9 +25,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 
-public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBoundingBoxQueryBuilder> {
-
-    public static final String NAME = "geo_bbox";
+public class GeoBoundingBoxQueryBuilder extends QueryBuilder {
 
     public static final String TOP_LEFT = GeoBoundingBoxQueryParser.TOP_LEFT;
     public static final String BOTTOM_RIGHT = GeoBoundingBoxQueryParser.BOTTOM_RIGHT;
@@ -36,17 +34,16 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
     private static final int LEFT = 1;
     private static final int BOTTOM = 2;
     private static final int RIGHT = 3;
-
+    
     private final String name;
 
     private double[] box = {Double.NaN, Double.NaN, Double.NaN, Double.NaN};
 
+    private String queryName;
     private String type;
     private Boolean coerce;
     private Boolean ignoreMalformed;
 
-    static final GeoBoundingBoxQueryBuilder PROTOTYPE = new GeoBoundingBoxQueryBuilder(null);
-
     public GeoBoundingBoxQueryBuilder(String name) {
         this.name = name;
     }
@@ -110,7 +107,7 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
     public GeoBoundingBoxQueryBuilder bottomLeft(String geohash) {
         return bottomLeft(GeoHashUtils.decode(geohash));
     }
-
+    
     /**
      * Adds top right point.
      *
@@ -131,6 +128,14 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
         return topRight(GeoHashUtils.decode(geohash));
     }
 
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoBoundingBoxQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     public GeoBoundingBoxQueryBuilder coerce(boolean coerce) {
         this.coerce = coerce;
         return this;
@@ -162,14 +167,17 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
         } else if(Double.isNaN(box[LEFT])) {
             throw new IllegalArgumentException("geo_bounding_box requires left longitude to be set");
         }
-
-        builder.startObject(NAME);
+                
+        builder.startObject(GeoBoundingBoxQueryParser.NAME);
 
         builder.startObject(name);
         builder.array(TOP_LEFT, box[LEFT], box[TOP]);
         builder.array(BOTTOM_RIGHT, box[RIGHT], box[BOTTOM]);
         builder.endObject();
 
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (type != null) {
             builder.field("type", type);
         }
@@ -180,13 +188,6 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
             builder.field("ignore_malformed", ignoreMalformed);
         }
 
-        printBoostAndQueryName(builder);
-
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java
index 1476c2e..6dead6e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java
@@ -37,7 +37,7 @@ import java.io.IOException;
 /**
  *
  */
-public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
+public class GeoBoundingBoxQueryParser implements QueryParser {
 
     public static final String NAME = "geo_bbox";
 
@@ -64,12 +64,11 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{GeoBoundingBoxQueryBuilder.NAME, "geoBbox", "geo_bounding_box", "geoBoundingBox"};
+        return new String[]{NAME, "geoBbox", "geo_bounding_box", "geoBoundingBox"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
@@ -78,17 +77,16 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
         double bottom = Double.NaN;
         double left = Double.NaN;
         double right = Double.NaN;
-
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        
         String queryName = null;
         String currentFieldName = null;
         XContentParser.Token token;
-        final boolean indexCreatedBeforeV2_0 = parseContext.shardContext().indexVersionCreated().before(Version.V_2_0_0);
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
         boolean coerce = false;
         boolean ignoreMalformed = false;
 
         GeoPoint sparse = new GeoPoint();
-
+        
         String type = "memory";
 
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -141,11 +139,9 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
                     coerce = parser.booleanValue();
-                    if (coerce) {
+                    if (coerce == true) {
                         ignoreMalformed = true;
                     }
                 } else if ("type".equals(currentFieldName)) {
@@ -189,7 +185,7 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
             }
         }
 
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
             throw new QueryParsingException(parseContext, "failed to parse [{}] query. could not find [{}] field [{}]", NAME, GeoPointFieldMapper.CONTENT_TYPE, fieldName);
         }
@@ -202,22 +198,15 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
         if ("indexed".equals(type)) {
             filter = IndexedGeoBoundingBoxQuery.create(topLeft, bottomRight, geoFieldType);
         } else if ("memory".equals(type)) {
-            IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+            IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
             filter = new InMemoryGeoBoundingBoxQuery(topLeft, bottomRight, indexFieldData);
         } else {
             throw new QueryParsingException(parseContext, "failed to parse [{}] query. geo bounding box type [{}] is not supported. either [indexed] or [memory] are allowed", NAME, type);
         }
-        if (filter != null) {
-            filter.setBoost(boost);
-        }
+
         if (queryName != null) {
-            context.addNamedQuery(queryName, filter);
+            parseContext.addNamedQuery(queryName, filter);
         }
         return filter;
-    }
-
-    @Override
-    public GeoBoundingBoxQueryBuilder getBuilderPrototype() {
-        return GeoBoundingBoxQueryBuilder.PROTOTYPE;
-    }
+    }    
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java
index 6f883bd..77c8f94 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java
@@ -26,9 +26,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import java.io.IOException;
 import java.util.Locale;
 
-public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQueryBuilder> {
-
-    public static final String NAME = "geo_distance";
+public class GeoDistanceQueryBuilder extends QueryBuilder {
 
     private final String name;
 
@@ -44,7 +42,7 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
 
     private String optimizeBbox;
 
-    static final GeoDistanceQueryBuilder PROTOTYPE = new GeoDistanceQueryBuilder(null);
+    private String queryName;
 
     private Boolean coerce;
 
@@ -95,6 +93,14 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
         return this;
     }
 
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoDistanceQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     public GeoDistanceQueryBuilder coerce(boolean coerce) {
         this.coerce = coerce;
         return this;
@@ -107,7 +113,7 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(GeoDistanceQueryParser.NAME);
         if (geohash != null) {
             builder.field(name, geohash);
         } else {
@@ -120,18 +126,15 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
         if (optimizeBbox != null) {
             builder.field("optimize_bbox", optimizeBbox);
         }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (coerce != null) {
             builder.field("coerce", coerce);
         }
         if (ignoreMalformed != null) {
             builder.field("ignore_malformed", ignoreMalformed);
         }
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java
index 647e1d0..8201381 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java
@@ -43,7 +43,9 @@ import java.io.IOException;
  * }
  * </pre>
  */
-public class GeoDistanceQueryParser extends BaseQueryParserTemp {
+public class GeoDistanceQueryParser implements QueryParser {
+
+    public static final String NAME = "geo_distance";
 
     @Inject
     public GeoDistanceQueryParser() {
@@ -51,17 +53,15 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{GeoDistanceQueryBuilder.NAME, "geoDistance"};
+        return new String[]{NAME, "geoDistance"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token;
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
         String currentFieldName = null;
         GeoPoint point = new GeoPoint();
@@ -71,7 +71,7 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         DistanceUnit unit = DistanceUnit.DEFAULT;
         GeoDistance geoDistance = GeoDistance.DEFAULT;
         String optimizeBbox = "memory";
-        final boolean indexCreatedBeforeV2_0 = parseContext.shardContext().indexVersionCreated().before(Version.V_2_0_0);
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
         boolean coerce = false;
         boolean ignoreMalformed = false;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -124,8 +124,6 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
                     fieldName = currentFieldName.substring(0, currentFieldName.length() - GeoPointFieldMapper.Names.GEOHASH_SUFFIX.length());
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if ("optimize_bbox".equals(currentFieldName) || "optimizeBbox".equals(currentFieldName)) {
                     optimizeBbox = parser.textOrNull();
                 } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
@@ -145,10 +143,10 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed on 2.x created indexes
         if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
             if (point.lat() > 90.0 || point.lat() < -90.0) {
-                throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), GeoDistanceQueryBuilder.NAME);
+                throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), NAME);
             }
             if (point.lon() > 180.0 || point.lon() < -180) {
-                throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), GeoDistanceQueryBuilder.NAME);
+                throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), NAME);
             }
         }
 
@@ -165,7 +163,7 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         }
         distance = geoDistance.normalize(distance, DistanceUnit.DEFAULT);
 
-        MappedFieldType fieldType = parseContext.shardContext().fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
             throw new QueryParsingException(parseContext, "failed to find geo_point field [" + fieldName + "]");
         }
@@ -175,17 +173,11 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
 
 
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
         Query query = new GeoDistanceRangeQuery(point, null, distance, true, false, geoDistance, geoFieldType, indexFieldData, optimizeBbox);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
-        query.setBoost(boost);
         return query;
     }
-
-    @Override
-    public GeoDistanceQueryBuilder getBuilderPrototype() {
-        return GeoDistanceQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java
index 4f426e8..6aa6f0f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java
@@ -25,9 +25,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import java.io.IOException;
 import java.util.Locale;
 
-public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistanceRangeQueryBuilder> {
-
-    public static final String NAME = "geo_distance_range";
+public class GeoDistanceRangeQueryBuilder extends QueryBuilder {
 
     private final String name;
 
@@ -44,14 +42,14 @@ public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistan
 
     private GeoDistance geoDistance;
 
+    private String queryName;
+
     private String optimizeBbox;
 
     private Boolean coerce;
 
     private Boolean ignoreMalformed;
 
-    static final GeoDistanceRangeQueryBuilder PROTOTYPE = new GeoDistanceRangeQueryBuilder(null);
-
     public GeoDistanceRangeQueryBuilder(String name) {
         this.name = name;
     }
@@ -141,9 +139,17 @@ public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistan
         return this;
     }
 
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoDistanceRangeQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(GeoDistanceRangeQueryParser.NAME);
         if (geohash != null) {
             builder.field(name, geohash);
         } else {
@@ -159,18 +165,15 @@ public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistan
         if (optimizeBbox != null) {
             builder.field("optimize_bbox", optimizeBbox);
         }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (coerce != null) {
             builder.field("coerce", coerce);
         }
         if (ignoreMalformed != null) {
             builder.field("ignore_malformed", ignoreMalformed);
         }
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java
index dd1879c..f60d944 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java
@@ -43,7 +43,9 @@ import java.io.IOException;
  * }
  * </pre>
  */
-public class GeoDistanceRangeQueryParser extends BaseQueryParserTemp {
+public class GeoDistanceRangeQueryParser implements QueryParser {
+
+    public static final String NAME = "geo_distance_range";
 
     @Inject
     public GeoDistanceRangeQueryParser() {
@@ -51,17 +53,15 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{GeoDistanceRangeQueryBuilder.NAME, "geoDistanceRange"};
+        return new String[]{NAME, "geoDistanceRange"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token;
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
         String currentFieldName = null;
         GeoPoint point = new GeoPoint();
@@ -73,7 +73,7 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParserTemp {
         DistanceUnit unit = DistanceUnit.DEFAULT;
         GeoDistance geoDistance = GeoDistance.DEFAULT;
         String optimizeBbox = "memory";
-        final boolean indexCreatedBeforeV2_0 = parseContext.shardContext().indexVersionCreated().before(Version.V_2_0_0);
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
         boolean coerce = false;
         boolean ignoreMalformed = false;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -154,8 +154,6 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParserTemp {
                     fieldName = currentFieldName.substring(0, currentFieldName.length() - GeoPointFieldMapper.Names.GEOHASH_SUFFIX.length());
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if ("optimize_bbox".equals(currentFieldName) || "optimizeBbox".equals(currentFieldName)) {
                     optimizeBbox = parser.textOrNull();
                 } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
@@ -175,10 +173,10 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParserTemp {
         // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed on 2.x created indexes
         if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
             if (point.lat() > 90.0 || point.lat() < -90.0) {
-                throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), GeoDistanceQueryBuilder.NAME);
+                throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), NAME);
             }
             if (point.lon() > 180.0 || point.lon() < -180) {
-                throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), GeoDistanceQueryBuilder.NAME);
+                throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), NAME);
             }
         }
 
@@ -205,7 +203,7 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParserTemp {
             to = geoDistance.normalize(to, DistanceUnit.DEFAULT);
         }
 
-        MappedFieldType fieldType = parseContext.shardContext().fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
             throw new QueryParsingException(parseContext, "failed to find geo_point field [" + fieldName + "]");
         }
@@ -214,17 +212,11 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParserTemp {
         }
         GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
 
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
         Query query = new GeoDistanceRangeQuery(point, from, to, includeLower, includeUpper, geoDistance, geoFieldType, indexFieldData, optimizeBbox);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
-        query.setBoost(boost);
         return query;
     }
-
-    @Override
-    public GeoDistanceRangeQueryBuilder getBuilderPrototype() {
-        return GeoDistanceRangeQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java
index 8857217..400384b 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java
@@ -19,26 +19,23 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.geo.GeoHashUtils;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
-public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQueryBuilder> {
-
-    public static final String NAME = "geo_polygon";
+public class GeoPolygonQueryBuilder extends QueryBuilder {
 
     public static final String POINTS = GeoPolygonQueryParser.POINTS;
-
+    
     private final String name;
 
-    private final List<GeoPoint> shell = Lists.newArrayList();
+    private final List<GeoPoint> shell = new ArrayList<>();
 
-    static final GeoPolygonQueryBuilder PROTOTYPE = new GeoPolygonQueryBuilder(null);
+    private String queryName;
 
     private Boolean coerce;
 
@@ -53,7 +50,7 @@ public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQuery
      *
      * @param lat The latitude
      * @param lon The longitude
-     * @return the current builder
+     * @return
      */
     public GeoPolygonQueryBuilder addPoint(double lat, double lon) {
         return addPoint(new GeoPoint(lat, lon));
@@ -67,6 +64,14 @@ public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQuery
         shell.add(point);
         return this;
     }
+    
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoPolygonQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
 
     public GeoPolygonQueryBuilder coerce(boolean coerce) {
         this.coerce = coerce;
@@ -80,7 +85,7 @@ public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQuery
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(GeoPolygonQueryParser.NAME);
 
         builder.startObject(name);
         builder.startArray(POINTS);
@@ -90,18 +95,16 @@ public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQuery
         builder.endArray();
         builder.endObject();
 
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (coerce != null) {
             builder.field("coerce", coerce);
         }
         if (ignoreMalformed != null) {
             builder.field("ignore_malformed", ignoreMalformed);
         }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java
index ecd5359..e4cf677 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Lists;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.geo.GeoPoint;
@@ -33,6 +32,7 @@ import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
 import org.elasticsearch.index.search.geo.GeoPolygonQuery;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -47,8 +47,9 @@ import java.util.List;
  * }
  * </pre>
  */
-public class GeoPolygonQueryParser extends BaseQueryParserTemp {
+public class GeoPolygonQueryParser implements QueryParser {
 
+    public static final String NAME = "geo_polygon";
     public static final String POINTS = "points";
 
     @Inject
@@ -57,20 +58,18 @@ public class GeoPolygonQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{GeoPolygonQueryBuilder.NAME, "geoPolygon"};
+        return new String[]{NAME, "geoPolygon"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
 
-        List<GeoPoint> shell = Lists.newArrayList();
+        List<GeoPoint> shell = new ArrayList<>();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        final boolean indexCreatedBeforeV2_0 = parseContext.shardContext().indexVersionCreated().before(Version.V_2_0_0);
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
         boolean coerce = false;
         boolean ignoreMalformed = false;
         String queryName = null;
@@ -108,8 +107,6 @@ public class GeoPolygonQueryParser extends BaseQueryParserTemp {
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
                     coerce = parser.booleanValue();
                     if (coerce == true) {
@@ -144,10 +141,10 @@ public class GeoPolygonQueryParser extends BaseQueryParserTemp {
         if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
             for (GeoPoint point : shell) {
                 if (point.lat() > 90.0 || point.lat() < -90.0) {
-                    throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), GeoPolygonQueryBuilder.NAME);
+                    throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), NAME);
                 }
                 if (point.lon() > 180.0 || point.lon() < -180) {
-                    throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), GeoPolygonQueryBuilder.NAME);
+                    throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), NAME);
                 }
             }
         }
@@ -158,7 +155,7 @@ public class GeoPolygonQueryParser extends BaseQueryParserTemp {
             }
         }
 
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
             throw new QueryParsingException(parseContext, "failed to find geo_point field [" + fieldName + "]");
         }
@@ -166,17 +163,11 @@ public class GeoPolygonQueryParser extends BaseQueryParserTemp {
             throw new QueryParsingException(parseContext, "field [" + fieldName + "] is not a geo_point field");
         }
 
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
         Query query = new GeoPolygonQuery(indexFieldData, shell.toArray(new GeoPoint[shell.size()]));
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
-        query.setBoost(boost);
         return query;
     }
-
-    @Override
-    public GeoPolygonQueryBuilder getBuilderPrototype() {
-        return GeoPolygonQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
index 9180d0e..3887874 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
@@ -29,11 +29,7 @@ import java.io.IOException;
 /**
  * {@link QueryBuilder} that builds a GeoShape Filter
  */
-public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuilder> {
-
-    public static final String NAME = "geo_shape";
-
-    static final GeoShapeQueryBuilder PROTOTYPE = new GeoShapeQueryBuilder(null, null);
+public class GeoShapeQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<GeoShapeQueryBuilder> {
 
     private final String name;
 
@@ -41,6 +37,8 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
 
     private SpatialStrategy strategy = null;
 
+    private String queryName;
+
     private final String indexedShapeId;
     private final String indexedShapeType;
 
@@ -49,6 +47,8 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
 
     private ShapeRelation relation = null;
 
+    private float boost = -1;
+    
     /**
      * Creates a new GeoShapeQueryBuilder whose Filter will be against the
      * given field name using the given Shape
@@ -93,6 +93,17 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
     }
 
     /**
+     * Sets the name of the filter
+     *
+     * @param queryName Name of the filter
+     * @return this
+     */
+    public GeoShapeQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
+    /**
      * Defines which spatial strategy will be used for building the geo shape filter. When not set, the strategy that
      * will be used will be the one that is associated with the geo shape field in the mappings.
      *
@@ -138,8 +149,14 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
     }
 
     @Override
+    public GeoShapeQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(GeoShapeQueryParser.NAME);
 
         builder.startObject(name);
 
@@ -168,13 +185,14 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
 
         builder.endObject();
 
-        printBoostAndQueryName(builder);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+
+        if (name != null) {
+            builder.field("_name", queryName);
+        }
 
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java
index 693db14..286fa1c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java
@@ -31,6 +31,7 @@ import org.elasticsearch.common.geo.ShapeRelation;
 import org.elasticsearch.common.geo.builders.ShapeBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.geo.GeoShapeFieldMapper;
 import org.elasticsearch.index.search.shape.ShapeFetchService;
@@ -38,7 +39,9 @@ import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 
-public class GeoShapeQueryParser extends BaseQueryParserTemp {
+public class GeoShapeQueryParser implements QueryParser {
+
+    public static final String NAME = "geo_shape";
 
     private ShapeFetchService fetchService;
 
@@ -49,12 +52,11 @@ public class GeoShapeQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{GeoShapeQueryBuilder.NAME, Strings.toCamelCase(GeoShapeQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
@@ -137,7 +139,7 @@ public class GeoShapeQueryParser extends BaseQueryParserTemp {
             throw new QueryParsingException(parseContext, "No Shape Relation defined");
         }
 
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
             throw new QueryParsingException(parseContext, "Failed to find geo_shape field [" + fieldName + "]");
         }
@@ -158,7 +160,7 @@ public class GeoShapeQueryParser extends BaseQueryParserTemp {
             // this strategy doesn't support disjoint anymore: but it did before, including creating lucene fieldcache (!)
             // in this case, execute disjoint as exists && !intersects
             BooleanQuery bool = new BooleanQuery();
-            Query exists = ExistsQueryBuilder.newFilter(context, fieldName);
+            Query exists = ExistsQueryParser.newFilter(parseContext, fieldName, null);
             Filter intersects = strategy.makeFilter(getArgs(shape, ShapeRelation.INTERSECTS));
             bool.add(exists, BooleanClause.Occur.MUST);
             bool.add(intersects, BooleanClause.Occur.MUST_NOT);
@@ -168,7 +170,7 @@ public class GeoShapeQueryParser extends BaseQueryParserTemp {
         }
         query.setBoost(boost);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
         return query;
     }
@@ -188,11 +190,7 @@ public class GeoShapeQueryParser extends BaseQueryParserTemp {
             return new SpatialArgs(SpatialOperation.IsWithin, shape.build());
         default:
             throw new IllegalArgumentException("");
-        }
-    }
 
-    @Override
-    public GeoShapeQueryBuilder getBuilderPrototype() {
-        return GeoShapeQueryBuilder.PROTOTYPE;
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java b/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java
index 5ea66b9..814aca4 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java
@@ -31,7 +31,9 @@ import org.elasticsearch.common.unit.DistanceUnit;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentParser.Token;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.core.StringFieldMapper;
 import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
 
 import java.io.IOException;
@@ -69,7 +71,7 @@ public class GeohashCellQuery {
      * @param geohashes   optional array of additional geohashes
      * @return a new GeoBoundinboxfilter
      */
-    public static Query create(QueryShardContext context, GeoPointFieldMapper.GeoPointFieldType fieldType, String geohash, @Nullable List<CharSequence> geohashes) {
+    public static Query create(QueryParseContext context, GeoPointFieldMapper.GeoPointFieldType fieldType, String geohash, @Nullable List<CharSequence> geohashes) {
         MappedFieldType geoHashMapper = fieldType.geohashFieldType();
         if (geoHashMapper == null) {
             throw new IllegalArgumentException("geohash filter needs geohash_prefix to be enabled");
@@ -88,7 +90,7 @@ public class GeohashCellQuery {
      * <code>geohash</code> to be set. the default for a neighbor filteing is
      * <code>false</code>.
      */
-    public static class Builder extends AbstractQueryBuilder<Builder> {
+    public static class Builder extends QueryBuilder {
         // we need to store the geohash rather than the corresponding point,
         // because a transformation from a geohash to a point an back to the
         // geohash will extend the accuracy of the hash to max precision
@@ -97,7 +99,6 @@ public class GeohashCellQuery {
         private String geohash;
         private int levels = -1;
         private boolean neighbors;
-        private static final Builder PROTOTYPE = new Builder(null);
 
 
         public Builder(String field) {
@@ -164,17 +165,12 @@ public class GeohashCellQuery {
                 builder.field(PRECISION, levels);
             }
             builder.field(field, geohash);
-            printBoostAndQueryName(builder);
-            builder.endObject();
-        }
 
-        @Override
-        public String getWriteableName() {
-            return NAME;
+            builder.endObject();
         }
     }
 
-    public static class Parser extends BaseQueryParserTemp {
+    public static class Parser implements QueryParser {
 
         @Inject
         public Parser() {
@@ -186,16 +182,14 @@ public class GeohashCellQuery {
         }
 
         @Override
-        public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-            QueryParseContext parseContext = context.parseContext();
+        public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
             XContentParser parser = parseContext.parser();
 
             String fieldName = null;
             String geohash = null;
             int levels = -1;
             boolean neighbors = false;
-            String queryName = null;
-            float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+
 
             XContentParser.Token token;
             if ((token = parser.currentToken()) != Token.START_OBJECT) {
@@ -219,17 +213,11 @@ public class GeohashCellQuery {
                     } else if (NEIGHBORS.equals(field)) {
                         parser.nextToken();
                         neighbors = parser.booleanValue();
-                    } else if ("_name".equals(field)) {
-                        parser.nextToken();
-                        queryName = parser.text();
-                    } else if ("boost".equals(field)) {
-                        parser.nextToken();
-                        boost = parser.floatValue();
                     } else {
                         fieldName = field;
                         token = parser.nextToken();
                         if(token == Token.VALUE_STRING) {
-                            // A string indicates either a geohash or a lat/lon string
+                            // A string indicates either a gehash or a lat/lon string
                             String location = parser.text();
                             if(location.indexOf(",")>0) {
                                 geohash = GeoUtils.parseGeoPoint(parser).geohash();
@@ -249,7 +237,7 @@ public class GeohashCellQuery {
                 throw new QueryParsingException(parseContext, "failed to parse [{}] query. missing geohash value", NAME);
             }
 
-            MappedFieldType fieldType = context.fieldMapper(fieldName);
+            MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
             if (fieldType == null) {
                 throw new QueryParsingException(parseContext, "failed to parse [{}] query. missing [{}] field [{}]", NAME, GeoPointFieldMapper.CONTENT_TYPE, fieldName);
             }
@@ -270,22 +258,12 @@ public class GeohashCellQuery {
 
             Query filter;
             if (neighbors) {
-                filter = create(context, geoFieldType, geohash, GeoHashUtils.addNeighbors(geohash, new ArrayList<CharSequence>(8)));
+                filter = create(parseContext, geoFieldType, geohash, GeoHashUtils.addNeighbors(geohash, new ArrayList<CharSequence>(8)));
             } else {
-                filter = create(context, geoFieldType, geohash, null);
+                filter = create(parseContext, geoFieldType, geohash, null);
             }
-            if (queryName != null) {
-                context.addNamedQuery(queryName, filter);
-            }
-            if (filter != null) {
-                filter.setBoost(boost);
-            }
-            return filter;
-        }
 
-        @Override
-        public GeohashCellQuery.Builder getBuilderPrototype() {
-            return Builder.PROTOTYPE;
+            return filter;
         }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java
index 64b852d..74a6a5c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java
@@ -23,14 +23,14 @@ import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 
 import java.io.IOException;
 
-public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuilder> {
-
-    public static final String NAME = "has_child";
+public class HasChildQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<HasChildQueryBuilder> {
 
     private final QueryBuilder queryBuilder;
 
     private String childType;
 
+    private float boost = 1.0f;
+
     private String scoreType;
 
     private Integer minChildren;
@@ -39,9 +39,9 @@ public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuil
 
     private Integer shortCircuitCutoff;
 
-    private QueryInnerHitBuilder innerHit = null;
+    private String queryName;
 
-    static final HasChildQueryBuilder PROTOTYPE = new HasChildQueryBuilder(null, null);
+    private QueryInnerHitBuilder innerHit = null;
 
     public HasChildQueryBuilder(String type, QueryBuilder queryBuilder) {
         this.childType = type;
@@ -49,6 +49,16 @@ public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuil
     }
 
     /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public HasChildQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
      * Defines how the scores from the matching child documents are mapped into the parent document.
      */
     public HasChildQueryBuilder scoreType(String scoreType) {
@@ -82,6 +92,14 @@ public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuil
     }
 
     /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public HasChildQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
+    /**
      * Sets inner hit definition in the scope of this query and reusing the defined type and query.
      */
     public HasChildQueryBuilder innerHit(QueryInnerHitBuilder innerHit) {
@@ -91,10 +109,13 @@ public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuil
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(HasChildQueryParser.NAME);
         builder.field("query");
         queryBuilder.toXContent(builder, params);
         builder.field("child_type", childType);
+        if (boost != 1.0f) {
+            builder.field("boost", boost);
+        }
         if (scoreType != null) {
             builder.field("score_type", scoreType);
         }
@@ -107,7 +128,9 @@ public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuil
         if (shortCircuitCutoff != null) {
             builder.field("short_circuit_cutoff", shortCircuitCutoff);
         }
-        printBoostAndQueryName(builder);
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (innerHit != null) {
             builder.startObject("inner_hits");
             builder.value(innerHit);
@@ -115,9 +138,4 @@ public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuil
         }
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java
index 3ae7b89..87a7668 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java
@@ -21,14 +21,16 @@ package org.elasticsearch.index.query;
 
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.MultiDocValues;
-import org.apache.lucene.search.*;
+import org.apache.lucene.search.Filter;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.join.BitDocIdSetFilter;
-import org.elasticsearch.common.ParseField;
 import org.apache.lucene.search.join.JoinUtil;
 import org.apache.lucene.search.join.ScoreMode;
 import org.elasticsearch.Version;
+import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -42,16 +44,17 @@ import org.elasticsearch.index.search.child.ChildrenConstantScoreQuery;
 import org.elasticsearch.index.search.child.ChildrenQuery;
 import org.elasticsearch.index.search.child.ScoreType;
 import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
 import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.internal.SubSearchContext;
 
 import java.io.IOException;
 
 /**
  *
  */
-public class HasChildQueryParser extends BaseQueryParserTemp {
+public class HasChildQueryParser implements QueryParser {
 
+    public static final String NAME = "has_child";
     private static final ParseField QUERY_FIELD = new ParseField("query", "filter");
 
     private final InnerHitsQueryParserHelper innerHitsQueryParserHelper;
@@ -63,23 +66,22 @@ public class HasChildQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[] { HasChildQueryBuilder.NAME, Strings.toCamelCase(HasChildQueryBuilder.NAME) };
+        return new String[] { NAME, Strings.toCamelCase(NAME) };
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         boolean queryFound = false;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String childType = null;
         ScoreType scoreType = ScoreType.NONE;
         int minChildren = 0;
         int maxChildren = 0;
         int shortCircuitParentDocSet = 8192;
         String queryName = null;
-        Tuple<String, SubSearchContext> innerHits = null;
+        InnerHitsSubSearchContext innerHits = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -138,7 +140,7 @@ public class HasChildQueryParser extends BaseQueryParserTemp {
         }
         innerQuery.setBoost(boost);
 
-        DocumentMapper childDocMapper = context.mapperService().documentMapper(childType);
+        DocumentMapper childDocMapper = parseContext.mapperService().documentMapper(childType);
         if (childDocMapper == null) {
             throw new QueryParsingException(parseContext, "[has_child] No mapping for for type [" + childType + "]");
         }
@@ -148,14 +150,14 @@ public class HasChildQueryParser extends BaseQueryParserTemp {
         }
 
         if (innerHits != null) {
-            ParsedQuery parsedQuery = new ParsedQuery(innerQuery, context.copyNamedQueries());
-            InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.v2(), parsedQuery, null, context.mapperService(), childDocMapper);
-            String name = innerHits.v1() != null ? innerHits.v1() : childType;
-            context.addInnerHits(name, parentChildInnerHits);
+            ParsedQuery parsedQuery = new ParsedQuery(innerQuery, parseContext.copyNamedQueries());
+            InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, parseContext.mapperService(), childDocMapper);
+            String name = innerHits.getName() != null ? innerHits.getName() : childType;
+            parseContext.addInnerHits(name, parentChildInnerHits);
         }
 
         String parentType = parentFieldMapper.type();
-        DocumentMapper parentDocMapper = context.mapperService().documentMapper(parentType);
+        DocumentMapper parentDocMapper = parseContext.mapperService().documentMapper(parentType);
         if (parentDocMapper == null) {
             throw new QueryParsingException(parseContext, "[has_child]  Type [" + childType + "] points to a non existent parent type ["
                     + parentType + "]");
@@ -167,15 +169,15 @@ public class HasChildQueryParser extends BaseQueryParserTemp {
 
         BitDocIdSetFilter nonNestedDocsFilter = null;
         if (parentDocMapper.hasNestedObjects()) {
-            nonNestedDocsFilter = context.bitsetFilter(Queries.newNonNestedFilter());
+            nonNestedDocsFilter = parseContext.bitsetFilter(Queries.newNonNestedFilter());
         }
 
         // wrap the query with type query
         innerQuery = Queries.filtered(innerQuery, childDocMapper.typeFilter());
 
         final Query query;
-        final ParentChildIndexFieldData parentChildIndexFieldData = context.getForField(parentFieldMapper.fieldType());
-        if (context.indexVersionCreated().onOrAfter(Version.V_2_0_0_beta1)) {
+        final ParentChildIndexFieldData parentChildIndexFieldData = parseContext.getForField(parentFieldMapper.fieldType());
+        if (parseContext.indexVersionCreated().onOrAfter(Version.V_2_0_0_beta1)) {
             query = joinUtilHelper(parentType, parentChildIndexFieldData, parentDocMapper.typeFilter(), scoreType, innerQuery, minChildren, maxChildren);
         } else {
             // TODO: use the query API
@@ -189,7 +191,7 @@ public class HasChildQueryParser extends BaseQueryParserTemp {
             }
         }
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
         query.setBoost(boost);
         return query;
@@ -252,11 +254,9 @@ public class HasChildQueryParser extends BaseQueryParserTemp {
                 throw new IllegalArgumentException("Search context is required to be set");
             }
 
+            IndexSearcher indexSearcher = searchContext.searcher();
             String joinField = ParentFieldMapper.joinField(parentType);
-            IndexReader indexReader = searchContext.searcher().getIndexReader();
-            IndexSearcher indexSearcher = new IndexSearcher(indexReader);
-            indexSearcher.setQueryCache(null);
-            IndexParentChildFieldData indexParentChildFieldData = parentChildIndexFieldData.loadGlobal(indexReader);
+            IndexParentChildFieldData indexParentChildFieldData = parentChildIndexFieldData.loadGlobal(indexSearcher.getIndexReader());
             MultiDocValues.OrdinalMap ordinalMap = ParentChildIndexFieldData.getOrdinalMap(indexParentChildFieldData, parentType);
             return JoinUtil.createJoinQuery(joinField, innerQuery, toQuery, indexSearcher, scoreMode, ordinalMap, minChildren, maxChildren);
         }
@@ -287,9 +287,4 @@ public class HasChildQueryParser extends BaseQueryParserTemp {
             return "LateParsingQuery {parentType=" + parentType + "}";
         }
     }
-
-    @Override
-    public HasChildQueryBuilder getBuilderPrototype() {
-        return HasChildQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java
index 67bfe07..743ad76 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java
@@ -26,14 +26,14 @@ import java.io.IOException;
 /**
  * Builder for the 'has_parent' query.
  */
-public class HasParentQueryBuilder extends AbstractQueryBuilder<HasParentQueryBuilder> {
+public class HasParentQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<HasParentQueryBuilder> {
 
-    public static final String NAME = "has_parent";
     private final QueryBuilder queryBuilder;
     private final String parentType;
     private String scoreType;
+    private float boost = 1.0f;
+    private String queryName;
     private QueryInnerHitBuilder innerHit = null;
-    static final HasParentQueryBuilder PROTOTYPE = new HasParentQueryBuilder(null, null);
 
     /**
      * @param parentType  The parent type
@@ -44,6 +44,12 @@ public class HasParentQueryBuilder extends AbstractQueryBuilder<HasParentQueryBu
         this.queryBuilder = parentQuery;
     }
 
+    @Override
+    public HasParentQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
     /**
      * Defines how the parent score is mapped into the child documents.
      */
@@ -53,6 +59,14 @@ public class HasParentQueryBuilder extends AbstractQueryBuilder<HasParentQueryBu
     }
 
     /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public HasParentQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
+    /**
      * Sets inner hit definition in the scope of this query and reusing the defined type and query.
      */
     public HasParentQueryBuilder innerHit(QueryInnerHitBuilder innerHit) {
@@ -62,14 +76,19 @@ public class HasParentQueryBuilder extends AbstractQueryBuilder<HasParentQueryBu
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(HasParentQueryParser.NAME);
         builder.field("query");
         queryBuilder.toXContent(builder, params);
         builder.field("parent_type", parentType);
         if (scoreType != null) {
             builder.field("score_type", scoreType);
         }
-        printBoostAndQueryName(builder);
+        if (boost != 1.0f) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (innerHit != null) {
             builder.startObject("inner_hits");
             builder.value(innerHit);
@@ -77,10 +96,5 @@ public class HasParentQueryBuilder extends AbstractQueryBuilder<HasParentQueryBu
         }
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
 
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java
index 00f8884..67422d0 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java
@@ -18,15 +18,10 @@
  */
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.Query;
+import org.apache.lucene.search.*;
 import org.elasticsearch.Version;
-import org.apache.lucene.search.QueryWrapperFilter;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -39,7 +34,7 @@ import org.elasticsearch.index.search.child.ParentConstantScoreQuery;
 import org.elasticsearch.index.search.child.ParentQuery;
 import org.elasticsearch.index.search.child.ScoreType;
 import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.internal.SubSearchContext;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
 
 import java.io.IOException;
 import java.util.HashSet;
@@ -47,8 +42,9 @@ import java.util.Set;
 
 import static org.elasticsearch.index.query.HasChildQueryParser.joinUtilHelper;
 
-public class HasParentQueryParser extends BaseQueryParserTemp {
+public class HasParentQueryParser implements QueryParser {
 
+    public static final String NAME = "has_parent";
     private static final ParseField QUERY_FIELD = new ParseField("query", "filter");
 
     private final InnerHitsQueryParserHelper innerHitsQueryParserHelper;
@@ -60,20 +56,19 @@ public class HasParentQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{HasParentQueryBuilder.NAME, Strings.toCamelCase(HasParentQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         boolean queryFound = false;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String parentType = null;
         boolean score = false;
         String queryName = null;
-        Tuple<String, SubSearchContext> innerHits = null;
+        InnerHitsSubSearchContext innerHits = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -134,40 +129,40 @@ public class HasParentQueryParser extends BaseQueryParserTemp {
         }
 
         innerQuery.setBoost(boost);
-        Query query = createParentQuery(innerQuery, parentType, score, context, innerHits);
+        Query query = createParentQuery(innerQuery, parentType, score, parseContext, innerHits);
         if (query == null) {
             return null;
         }
 
         query.setBoost(boost);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
         return query;
     }
 
-    static Query createParentQuery(Query innerQuery, String parentType, boolean score, QueryShardContext context, Tuple<String, SubSearchContext> innerHits) throws IOException {
-        DocumentMapper parentDocMapper = context.mapperService().documentMapper(parentType);
+    static Query createParentQuery(Query innerQuery, String parentType, boolean score, QueryParseContext parseContext, InnerHitsSubSearchContext innerHits) throws IOException {
+        DocumentMapper parentDocMapper = parseContext.mapperService().documentMapper(parentType);
         if (parentDocMapper == null) {
-            throw new QueryParsingException(context.parseContext(), "[has_parent] query configured 'parent_type' [" + parentType
+            throw new QueryParsingException(parseContext, "[has_parent] query configured 'parent_type' [" + parentType
                     + "] is not a valid type");
         }
 
         if (innerHits != null) {
-            ParsedQuery parsedQuery = new ParsedQuery(innerQuery, context.copyNamedQueries());
-            InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.v2(), parsedQuery, null, context.mapperService(), parentDocMapper);
-            String name = innerHits.v1() != null ? innerHits.v1() : parentType;
-            context.addInnerHits(name, parentChildInnerHits);
+            ParsedQuery parsedQuery = new ParsedQuery(innerQuery, parseContext.copyNamedQueries());
+            InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, parseContext.mapperService(), parentDocMapper);
+            String name = innerHits.getName() != null ? innerHits.getName() : parentType;
+            parseContext.addInnerHits(name, parentChildInnerHits);
         }
 
         Set<String> parentTypes = new HashSet<>(5);
         parentTypes.add(parentDocMapper.type());
         ParentChildIndexFieldData parentChildIndexFieldData = null;
-        for (DocumentMapper documentMapper : context.mapperService().docMappers(false)) {
+        for (DocumentMapper documentMapper : parseContext.mapperService().docMappers(false)) {
             ParentFieldMapper parentFieldMapper = documentMapper.parentFieldMapper();
             if (parentFieldMapper.active()) {
-                DocumentMapper parentTypeDocumentMapper = context.mapperService().documentMapper(parentFieldMapper.type());
-                parentChildIndexFieldData = context.getForField(parentFieldMapper.fieldType());
+                DocumentMapper parentTypeDocumentMapper = parseContext.mapperService().documentMapper(parentFieldMapper.type());
+                parentChildIndexFieldData = parseContext.getForField(parentFieldMapper.fieldType());
                 if (parentTypeDocumentMapper == null) {
                     // Only add this, if this parentFieldMapper (also a parent)  isn't a child of another parent.
                     parentTypes.add(parentFieldMapper.type());
@@ -175,19 +170,19 @@ public class HasParentQueryParser extends BaseQueryParserTemp {
             }
         }
         if (parentChildIndexFieldData == null) {
-            throw new QueryParsingException(context.parseContext(), "[has_parent] no _parent field configured");
+            throw new QueryParsingException(parseContext, "[has_parent] no _parent field configured");
         }
 
         Query parentFilter = null;
         if (parentTypes.size() == 1) {
-            DocumentMapper documentMapper = context.mapperService().documentMapper(parentTypes.iterator().next());
+            DocumentMapper documentMapper = parseContext.mapperService().documentMapper(parentTypes.iterator().next());
             if (documentMapper != null) {
                 parentFilter = documentMapper.typeFilter();
             }
         } else {
             BooleanQuery parentsFilter = new BooleanQuery();
             for (String parentTypeStr : parentTypes) {
-                DocumentMapper documentMapper = context.mapperService().documentMapper(parentTypeStr);
+                DocumentMapper documentMapper = parseContext.mapperService().documentMapper(parentTypeStr);
                 if (documentMapper != null) {
                     parentsFilter.add(documentMapper.typeFilter(), BooleanClause.Occur.SHOULD);
                 }
@@ -202,7 +197,7 @@ public class HasParentQueryParser extends BaseQueryParserTemp {
         // wrap the query with type query
         innerQuery = Queries.filtered(innerQuery, parentDocMapper.typeFilter());
         Filter childrenFilter = new QueryWrapperFilter(Queries.not(parentFilter));
-        if (context.indexVersionCreated().onOrAfter(Version.V_2_0_0_beta1)) {
+        if (parseContext.indexVersionCreated().onOrAfter(Version.V_2_0_0_beta1)) {
             ScoreType scoreMode = score ? ScoreType.MAX : ScoreType.NONE;
             return joinUtilHelper(parentType, parentChildIndexFieldData, childrenFilter, scoreMode, innerQuery, 0, Integer.MAX_VALUE);
         } else {
@@ -214,9 +209,4 @@ public class HasParentQueryParser extends BaseQueryParserTemp {
         }
     }
 
-    @Override
-    public HasParentQueryBuilder getBuilderPrototype() {
-        return HasParentQueryBuilder.PROTOTYPE;
-    }
-
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
index 461a800..02c2a17 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
@@ -19,62 +19,44 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Sets;
-
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.List;
 
 /**
  * A query that will return only documents matching specific ids (and a type).
  */
-public class IdsQueryBuilder extends AbstractQueryBuilder<IdsQueryBuilder> {
+public class IdsQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<IdsQueryBuilder> {
 
-    public static final String NAME = "ids";
+    private final List<String> types;
 
-    private final Set<String> ids = Sets.newHashSet();
+    private List<String> values = new ArrayList<>();
 
-    private final String[] types;
+    private float boost = -1;
 
-    static final IdsQueryBuilder PROTOTYPE = new IdsQueryBuilder();
+    private String queryName;
 
-    /**
-     * Creates a new IdsQueryBuilder by optionally providing the types of the documents to look for
-     */
-    public IdsQueryBuilder(@Nullable String... types) {
-        this.types = types;
-    }
-
-    /**
-     * Returns the types used in this query
-     */
-    public String[] types() {
-        return this.types;
+    public IdsQueryBuilder(String... types) {
+        this.types = types == null ? null : Arrays.asList(types);
     }
 
     /**
-     * Adds ids to the query.
+     * Adds ids to the filter.
      */
     public IdsQueryBuilder addIds(String... ids) {
-        Collections.addAll(this.ids, ids);
+        values.addAll(Arrays.asList(ids));
         return this;
     }
 
     /**
-     * Adds ids to the query.
+     * Adds ids to the filter.
      */
     public IdsQueryBuilder addIds(Collection<String> ids) {
-        this.ids.addAll(ids);
+        values.addAll(ids);
         return this;
     }
 
@@ -93,83 +75,48 @@ public class IdsQueryBuilder extends AbstractQueryBuilder<IdsQueryBuilder> {
     }
 
     /**
-     * Returns the ids for the query.
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public Set<String> ids() {
-        return this.ids;
+    @Override
+    public IdsQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public IdsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(IdsQueryParser.NAME);
         if (types != null) {
-            if (types.length == 1) {
-                builder.field("type", types[0]);
+            if (types.size() == 1) {
+                builder.field("type", types.get(0));
             } else {
-                builder.array("types", types);
+                builder.startArray("types");
+                for (Object type : types) {
+                    builder.value(type);
+                }
+                builder.endArray();
             }
         }
         builder.startArray("values");
-        for (String value : ids) {
+        for (Object value : values) {
             builder.value(value);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query query;
-        if (this.ids.isEmpty()) {
-             query = Queries.newMatchNoDocsQuery();
-        } else {
-            Collection<String> typesForQuery;
-            if (types == null || types.length == 0) {
-                typesForQuery = context.queryTypes();
-            } else if (types.length == 1 && MetaData.ALL.equals(types[0])) {
-                typesForQuery = context.mapperService().types();
-            } else {
-                typesForQuery = Sets.newHashSet(types);
-            }
-
-            query = new TermsQuery(UidFieldMapper.NAME, Uid.createUidsForTypesAndIds(typesForQuery, ids));
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // all fields can be empty or null
-        return null;
-    }
-
-    @Override
-    protected IdsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        IdsQueryBuilder idsQueryBuilder = new IdsQueryBuilder(in.readStringArray());
-        idsQueryBuilder.addIds(in.readStringArray());
-        return idsQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeStringArray(types);
-        out.writeStringArray(ids.toArray(new String[ids.size()]));
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(ids, Arrays.hashCode(types));
-    }
-
-    @Override
-    protected boolean doEquals(IdsQueryBuilder other) {
-        return Objects.equals(ids, other.ids) &&
-               Arrays.equals(types, other.types);
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
index 3403517..340eb81 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
@@ -20,17 +20,28 @@
 package org.elasticsearch.index.query;
 
 import com.google.common.collect.ImmutableList;
+import com.google.common.collect.Iterables;
+
+import org.apache.lucene.queries.TermsQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.Uid;
+import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Collection;
 import java.util.List;
 
 /**
- * Parser for ids query
+ *
  */
-public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
+public class IdsQueryParser implements QueryParser {
+
+    public static final String NAME = "ids";
 
     @Inject
     public IdsQueryParser() {
@@ -38,21 +49,18 @@ public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{IdsQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
-    /**
-     * @return a QueryBuilder representation of the query passed in as XContent in the parse context
-     */
     @Override
-    public IdsQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        List<String> ids = new ArrayList<>();
-        List<String> types = new ArrayList<>();
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        String queryName = null;
 
+        List<BytesRef> ids = new ArrayList<>();
+        Collection<String> types = null;
         String currentFieldName = null;
+        float boost = 1.0f;
+        String queryName = null;
         XContentParser.Token token;
         boolean idsProvided = false;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -64,17 +72,18 @@ public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         if ((token == XContentParser.Token.VALUE_STRING) ||
                                 (token == XContentParser.Token.VALUE_NUMBER)) {
-                            String id = parser.textOrNull();
-                            if (id == null) {
+                            BytesRef value = parser.utf8BytesOrNull();
+                            if (value == null) {
                                 throw new QueryParsingException(parseContext, "No value specified for term filter");
                             }
-                            ids.add(id);
+                            ids.add(value);
                         } else {
                             throw new QueryParsingException(parseContext, "Illegal value for id, expecting a string or number, got: "
                                     + token);
                         }
                     }
                 } else if ("types".equals(currentFieldName) || "type".equals(currentFieldName)) {
+                    types = new ArrayList<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         String value = parser.textOrNull();
                         if (value == null) {
@@ -97,18 +106,26 @@ public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
                 }
             }
         }
+
         if (!idsProvided) {
             throw new QueryParsingException(parseContext, "[ids] query, no ids values provided");
         }
 
-        IdsQueryBuilder query = new IdsQueryBuilder(types.toArray(new String[types.size()]));
-        query.addIds(ids.toArray(new String[ids.size()]));
-        query.boost(boost).queryName(queryName);
-        return query;
-    }
+        if (ids.isEmpty()) {
+            return Queries.newMatchNoDocsQuery();
+        }
 
-    @Override
-    public IdsQueryBuilder getBuilderPrototype() {
-        return IdsQueryBuilder.PROTOTYPE;
+        if (types == null || types.isEmpty()) {
+            types = parseContext.queryTypes();
+        } else if (types.size() == 1 && Iterables.getFirst(types, null).equals("_all")) {
+            types = parseContext.mapperService().types();
+        }
+
+        TermsQuery query = new TermsQuery(UidFieldMapper.NAME, Uid.createUidsForTypesAndIds(types, ids));
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java b/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
index c2ee7d8..810504a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
@@ -22,15 +22,11 @@ package org.elasticsearch.index.query;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.util.CloseableThreadLocal;
 import org.elasticsearch.Version;
-import org.elasticsearch.action.support.IndicesOptions;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
@@ -43,15 +39,12 @@ import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.internal.AllFieldMapper;
-import org.elasticsearch.index.search.termslookup.TermsLookupFetchService;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.similarity.SimilarityService;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
 import org.elasticsearch.indices.query.IndicesQueriesRegistry;
 import org.elasticsearch.script.ScriptService;
 
 import java.io.IOException;
-import java.util.List;
 
 public class IndexQueryParserService extends AbstractIndexComponent {
 
@@ -60,10 +53,10 @@ public class IndexQueryParserService extends AbstractIndexComponent {
     public static final String PARSE_STRICT = "index.query.parse.strict";
     public static final String ALLOW_UNMAPPED = "index.query.parse.allow_unmapped_fields";
 
-    private CloseableThreadLocal<QueryShardContext> cache = new CloseableThreadLocal<QueryShardContext>() {
+    private CloseableThreadLocal<QueryParseContext> cache = new CloseableThreadLocal<QueryParseContext>() {
         @Override
-        protected QueryShardContext initialValue() {
-            return new QueryShardContext(index, IndexQueryParserService.this);
+        protected QueryParseContext initialValue() {
+            return new QueryParseContext(index, IndexQueryParserService.this);
         }
     };
 
@@ -79,10 +72,6 @@ public class IndexQueryParserService extends AbstractIndexComponent {
 
     final IndexFieldDataService fieldDataService;
 
-    final ClusterService clusterService;
-
-    final IndexNameExpressionResolver indexNameExpressionResolver;
-
     final BitsetFilterCache bitsetFilterCache;
 
     private final IndicesQueriesRegistry indicesQueriesRegistry;
@@ -92,16 +81,13 @@ public class IndexQueryParserService extends AbstractIndexComponent {
     private final ParseFieldMatcher parseFieldMatcher;
     private final boolean defaultAllowUnmappedFields;
 
-    private TermsLookupFetchService termsLookupFetchService;
-
     @Inject
     public IndexQueryParserService(Index index, @IndexSettings Settings indexSettings,
                                    IndicesQueriesRegistry indicesQueriesRegistry,
                                    ScriptService scriptService, AnalysisService analysisService,
                                    MapperService mapperService, IndexCache indexCache, IndexFieldDataService fieldDataService,
                                    BitsetFilterCache bitsetFilterCache,
-                                   @Nullable SimilarityService similarityService, ClusterService clusterService,
-                                   IndexNameExpressionResolver indexNameExpressionResolver) {
+                                   @Nullable SimilarityService similarityService) {
         super(index, indexSettings);
         this.scriptService = scriptService;
         this.analysisService = analysisService;
@@ -110,8 +96,6 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         this.indexCache = indexCache;
         this.fieldDataService = fieldDataService;
         this.bitsetFilterCache = bitsetFilterCache;
-        this.clusterService = clusterService;
-        this.indexNameExpressionResolver = indexNameExpressionResolver;
 
         this.defaultField = indexSettings.get(DEFAULT_FIELD, AllFieldMapper.NAME);
         this.queryStringLenient = indexSettings.getAsBoolean(QUERY_STRING_LENIENT, false);
@@ -120,11 +104,6 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         this.indicesQueriesRegistry = indicesQueriesRegistry;
     }
 
-    @Inject(optional=true)
-    public void setTermsLookupFetchService(@Nullable  TermsLookupFetchService termsLookupFetchService) {
-        this.termsLookupFetchService = termsLookupFetchService;
-    }
-
     public void close() {
         cache.close();
     }
@@ -137,8 +116,8 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         return this.queryStringLenient;
     }
 
-    IndicesQueriesRegistry indicesQueriesRegistry() {
-        return indicesQueriesRegistry;
+    public QueryParser queryParser(String name) {
+        return indicesQueriesRegistry.queryParsers().get(name);
     }
 
     public ParsedQuery parse(QueryBuilder queryBuilder) {
@@ -147,10 +126,10 @@ public class IndexQueryParserService extends AbstractIndexComponent {
             BytesReference bytes = queryBuilder.buildAsBytes();
             parser = XContentFactory.xContent(bytes).createParser(bytes);
             return parse(cache.get(), parser);
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -167,10 +146,10 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         try {
             parser = XContentFactory.xContent(source, offset, length).createParser(source, offset, length);
             return parse(cache.get(), parser);
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -182,8 +161,7 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         return parse(cache.get(), source);
     }
 
-    //norelease
-    public ParsedQuery parse(QueryShardContext context, BytesReference source) {
+    public ParsedQuery parse(QueryParseContext context, BytesReference source) {
         XContentParser parser = null;
         try {
             parser = XContentFactory.xContent(source).createParser(source);
@@ -191,7 +169,7 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(context.parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(context, "Failed to parse", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -199,15 +177,15 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         }
     }
 
-    public ParsedQuery parse(String source) throws QueryParsingException, QueryShardException {
+    public ParsedQuery parse(String source) throws QueryParsingException {
         XContentParser parser = null;
         try {
             parser = XContentFactory.xContent(source).createParser(source);
             return innerParse(cache.get(), parser);
-        } catch (QueryShardException|QueryParsingException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse [" + source + "]", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse [" + source + "]", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -219,12 +197,11 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         return parse(cache.get(), parser);
     }
 
-    //norelease
-    public ParsedQuery parse(QueryShardContext context, XContentParser parser) {
+    public ParsedQuery parse(QueryParseContext context, XContentParser parser) {
         try {
             return innerParse(context, parser);
         } catch (IOException e) {
-            throw new QueryParsingException(context.parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(context, "Failed to parse", e);
         }
     }
 
@@ -232,12 +209,11 @@ public class IndexQueryParserService extends AbstractIndexComponent {
      * Parses an inner filter, returning null if the filter should be ignored.
      */
     @Nullable
-    //norelease
     public ParsedQuery parseInnerFilter(XContentParser parser) throws IOException {
-        QueryShardContext context = cache.get();
+        QueryParseContext context = cache.get();
         context.reset(parser);
         try {
-            Query filter = context.parseContext().parseInnerFilter();
+            Query filter = context.parseInnerFilter();
             if (filter == null) {
                 return null;
             }
@@ -248,22 +224,27 @@ public class IndexQueryParserService extends AbstractIndexComponent {
     }
 
     @Nullable
-    public QueryBuilder parseInnerQueryBuilder(QueryParseContext parseContext) throws IOException {
-        parseContext.parseFieldMatcher(parseFieldMatcher);
-        return parseContext.parseInnerQueryBuilder();
+    public Query parseInnerQuery(XContentParser parser) throws IOException {
+        QueryParseContext context = cache.get();
+        context.reset(parser);
+        try {
+            return context.parseInnerQuery();
+        } finally {
+            context.reset(null);
+        }
     }
 
     @Nullable
-    //norelease
-    public Query parseInnerQuery(QueryShardContext context) throws IOException {
-        Query query = context.parseContext().parseInnerQueryBuilder().toQuery(context);
+    public Query parseInnerQuery(QueryParseContext parseContext) throws IOException {
+        parseContext.parseFieldMatcher(parseFieldMatcher);
+        Query query = parseContext.parseInnerQuery();
         if (query == null) {
             query = Queries.newMatchNoDocsQuery();
         }
         return query;
     }
 
-    public QueryShardContext getShardContext() {
+    public QueryParseContext getParseContext() {
         return cache.get();
     }
 
@@ -295,56 +276,37 @@ public class IndexQueryParserService extends AbstractIndexComponent {
                         XContentParser qSourceParser = XContentFactory.xContent(querySource).createParser(querySource);
                         parsedQuery = parse(qSourceParser);
                     } else {
-                        throw new QueryParsingException(getShardContext().parseContext(), "request does not support [" + fieldName + "]");
+                        throw new QueryParsingException(getParseContext(), "request does not support [" + fieldName + "]");
                     }
                 }
             }
             if (parsedQuery != null) {
                 return parsedQuery;
             }
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Throwable e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse", e);
         }
 
-        throw new QueryParsingException(getShardContext().parseContext(), "Required query is missing");
+        throw new QueryParsingException(getParseContext(), "Required query is missing");
     }
 
-    //norelease
-    private ParsedQuery innerParse(QueryShardContext context, XContentParser parser) throws IOException, QueryShardException {
-        context.reset(parser);
+    private ParsedQuery innerParse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
+        parseContext.reset(parser);
         try {
-            context.parseFieldMatcher(parseFieldMatcher);
-            return innerParse(context, context.parseContext().parseInnerQueryBuilder());
+            parseContext.parseFieldMatcher(parseFieldMatcher);
+            Query query = parseContext.parseInnerQuery();
+            if (query == null) {
+                query = Queries.newMatchNoDocsQuery();
+            }
+            return new ParsedQuery(query, parseContext.copyNamedQueries());
         } finally {
-            context.reset(null);
+            parseContext.reset(null);
         }
     }
 
-    private static ParsedQuery innerParse(QueryShardContext context, QueryBuilder queryBuilder) throws IOException, QueryShardException {
-        Query query = queryBuilder.toQuery(context);
-        if (query == null) {
-            query = Queries.newMatchNoDocsQuery();
-        }
-        return new ParsedQuery(query, context.copyNamedQueries());
-    }
-
     public ParseFieldMatcher parseFieldMatcher() {
         return parseFieldMatcher;
     }
-
-    public boolean matchesIndices(String... indices) {
-        final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices);
-        for (String index : concreteIndices) {
-            if (Regex.simpleMatch(index, this.index.name())) {
-                return true;
-            }
-        }
-        return false;
-    }
-
-    public List<Object> handleTermsLookup(TermsLookup termsLookup) {
-        return this.termsLookupFetchService.fetch(termsLookup);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java
index e481ed7..7c2af81 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java
@@ -19,135 +19,69 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Arrays;
-import java.util.Objects;
 
 /**
  * A query that will execute the wrapped query only for the specified indices, and "match_all" when
  * it does not match those indices (by default).
  */
-public class IndicesQueryBuilder extends AbstractQueryBuilder<IndicesQueryBuilder> {
+public class IndicesQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "indices";
-
-    private final QueryBuilder innerQuery;
+    private final QueryBuilder queryBuilder;
 
     private final String[] indices;
 
-    private QueryBuilder noMatchQuery = defaultNoMatchQuery();
-
-    static final IndicesQueryBuilder PROTOTYPE = new IndicesQueryBuilder();
+    private String sNoMatchQuery;
+    private QueryBuilder noMatchQuery;
 
-    private IndicesQueryBuilder() {
-        this.innerQuery = null;
-        this.indices = null;
-    }
+    private String queryName;
 
-    public IndicesQueryBuilder(QueryBuilder innerQuery, String... indices) {
-        this.innerQuery = Objects.requireNonNull(innerQuery);
+    public IndicesQueryBuilder(QueryBuilder queryBuilder, String... indices) {
+        this.queryBuilder = queryBuilder;
         this.indices = indices;
     }
 
-    public QueryBuilder innerQuery() {
-        return this.innerQuery;
-    }
-
-    public String[] indices() {
-        return this.indices;
+    /**
+     * Sets the no match query, can either be <tt>all</tt> or <tt>none</tt>.
+     */
+    public IndicesQueryBuilder noMatchQuery(String type) {
+        this.sNoMatchQuery = type;
+        return this;
     }
 
     /**
      * Sets the query to use when it executes on an index that does not match the indices provided.
      */
     public IndicesQueryBuilder noMatchQuery(QueryBuilder noMatchQuery) {
-        this.noMatchQuery = (noMatchQuery != null) ? noMatchQuery : defaultNoMatchQuery();
+        this.noMatchQuery = noMatchQuery;
         return this;
     }
 
     /**
-     * Sets the no match query, can either be <tt>all</tt> or <tt>none</tt>.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public IndicesQueryBuilder noMatchQuery(String type) {
-        this.noMatchQuery = IndicesQueryParser.parseNoMatchQuery(type);
+    public IndicesQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
         return this;
     }
 
-    public QueryBuilder noMatchQuery() {
-        return this.noMatchQuery;
-    }
-
-    static QueryBuilder defaultNoMatchQuery() {
-        return QueryBuilders.matchAllQuery();
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(IndicesQueryParser.NAME);
         builder.field("indices", indices);
         builder.field("query");
-        innerQuery.toXContent(builder, params);
-        builder.field("no_match_query");
-        noMatchQuery.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        if (context.matchesIndices(indices)) {
-            return innerQuery.toQuery(context);
+        queryBuilder.toXContent(builder, params);
+        if (noMatchQuery != null) {
+            builder.field("no_match_query");
+            noMatchQuery.toXContent(builder, params);
+        } else if (sNoMatchQuery != null) {
+            builder.field("no_match_query", sNoMatchQuery);
         }
-        return noMatchQuery.toQuery(context);
-    }
-    
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.innerQuery == null) {
-            validationException = addValidationError("inner query cannot be null", validationException);
-        }
-        if (this.indices == null || this.indices.length == 0) {
-            validationException = addValidationError("list of indices cannot be null or empty", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        validationException = validateInnerQuery(innerQuery, validationException);
-        validationException = validateInnerQuery(noMatchQuery, validationException);
-        return validationException;
-    }
-
-    @Override
-    protected IndicesQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        IndicesQueryBuilder indicesQueryBuilder = new IndicesQueryBuilder(in.readQuery(), in.readStringArray());
-        indicesQueryBuilder.noMatchQuery = in.readQuery();
-        return indicesQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(innerQuery);
-        out.writeStringArray(indices);
-        out.writeQuery(noMatchQuery);
-    }
-    
-    @Override
-    public int doHashCode() {
-        return Objects.hash(innerQuery, noMatchQuery, Arrays.hashCode(indices));
-    }
-    
-    @Override
-    protected boolean doEquals(IndicesQueryBuilder other) {
-        return Objects.equals(innerQuery, other.innerQuery) &&
-                Arrays.equals(indices, other.indices) &&  // otherwise we are comparing pointers
-                Objects.equals(noMatchQuery, other.noMatchQuery);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java
index b7a93ac..a18c865 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java
@@ -19,60 +19,78 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.elasticsearch.action.support.IndicesOptions;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
+import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
+import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.query.support.XContentStructure;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collection;
 
 /**
- * Parser for {@link IndicesQueryBuilder}.
  */
-public class IndicesQueryParser extends BaseQueryParser {
+public class IndicesQueryParser implements QueryParser {
 
+    public static final String NAME = "indices";
     private static final ParseField QUERY_FIELD = new ParseField("query", "filter");
     private static final ParseField NO_MATCH_QUERY = new ParseField("no_match_query", "no_match_filter");
 
+    @Nullable
+    private final ClusterService clusterService;
+    private final IndexNameExpressionResolver indexNameExpressionResolver;
+
     @Inject
-    public IndicesQueryParser() {
+    public IndicesQueryParser(@Nullable ClusterService clusterService, IndexNameExpressionResolver indexNameExpressionResolver) {
+        this.clusterService = clusterService;
+        this.indexNameExpressionResolver = indexNameExpressionResolver;
     }
 
     @Override
     public String[] names() {
-        return new String[]{IndicesQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder innerQuery = null;
-        Collection<String> indices = new ArrayList<>();
-        QueryBuilder noMatchQuery = IndicesQueryBuilder.defaultNoMatchQuery();
-
+        Query noMatchQuery = null;
+        boolean queryFound = false;
+        boolean indicesFound = false;
+        boolean currentIndexMatchesIndices = false;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
 
         String currentFieldName = null;
         XContentParser.Token token;
+        XContentStructure.InnerQuery innerQuery = null;
+        XContentStructure.InnerQuery innerNoMatchQuery = null;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, QUERY_FIELD)) {
-                    innerQuery = parseContext.parseInnerQueryBuilder();
+                    innerQuery = new XContentStructure.InnerQuery(parseContext, null);
+                    queryFound = true;
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, NO_MATCH_QUERY)) {
-                    noMatchQuery = parseContext.parseInnerQueryBuilder();
+                    innerNoMatchQuery = new XContentStructure.InnerQuery(parseContext, null);
                 } else {
                     throw new QueryParsingException(parseContext, "[indices] query does not support [" + currentFieldName + "]");
                 }
             } else if (token == XContentParser.Token.START_ARRAY) {
                 if ("indices".equals(currentFieldName)) {
-                    if (indices.isEmpty() == false) {
+                    if (indicesFound) {
                         throw new QueryParsingException(parseContext, "[indices] indices or index already specified");
                     }
+                    indicesFound = true;
+                    Collection<String> indices = new ArrayList<>();
                     while (parser.nextToken() != XContentParser.Token.END_ARRAY) {
                         String value = parser.textOrNull();
                         if (value == null) {
@@ -80,50 +98,67 @@ public class IndicesQueryParser extends BaseQueryParser {
                         }
                         indices.add(value);
                     }
+                    currentIndexMatchesIndices = matchesIndices(parseContext.index().name(), indices.toArray(new String[indices.size()]));
                 } else {
                     throw new QueryParsingException(parseContext, "[indices] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("index".equals(currentFieldName)) {
-                    if (indices.isEmpty() == false) {
+                    if (indicesFound) {
                         throw new QueryParsingException(parseContext, "[indices] indices or index already specified");
                     }
-                    indices.add(parser.text());
+                    indicesFound = true;
+                    currentIndexMatchesIndices = matchesIndices(parseContext.index().name(), parser.text());
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, NO_MATCH_QUERY)) {
-                    noMatchQuery = parseNoMatchQuery(parser.text());
+                    String type = parser.text();
+                    if ("all".equals(type)) {
+                        noMatchQuery = Queries.newMatchAllQuery();
+                    } else if ("none".equals(type)) {
+                        noMatchQuery = Queries.newMatchNoDocsQuery();
+                    }
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[indices] query does not support [" + currentFieldName + "]");
                 }
             }
         }
-        
-        if (innerQuery == null) {
+        if (!queryFound) {
             throw new QueryParsingException(parseContext, "[indices] requires 'query' element");
         }
-        if (indices.isEmpty()) {
+        if (!indicesFound) {
             throw new QueryParsingException(parseContext, "[indices] requires 'indices' or 'index' element");
         }
-        return new IndicesQueryBuilder(innerQuery, indices.toArray(new String[indices.size()]))
-                .noMatchQuery(noMatchQuery)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    static QueryBuilder parseNoMatchQuery(String type) {
-        if ("all".equals(type)) {
-            return QueryBuilders.matchAllQuery();
-        } else if ("none".equals(type)) {
-            return new MatchNoneQueryBuilder();
+        Query chosenQuery;
+        if (currentIndexMatchesIndices) {
+            chosenQuery = innerQuery.asQuery();
+        } else {
+            // If noMatchQuery is set, it means "no_match_query" was "all" or "none"
+            if (noMatchQuery != null) {
+                chosenQuery = noMatchQuery;
+            } else {
+                // There might be no "no_match_query" set, so default to the match_all if not set
+                if (innerNoMatchQuery == null) {
+                    chosenQuery = Queries.newMatchAllQuery();
+                } else {
+                    chosenQuery = innerNoMatchQuery.asQuery();
+                }
+            }
+        }
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, chosenQuery);
         }
-        throw new IllegalArgumentException("query type can only be [all] or [none] but not " + "[" + type + "]");
+        return chosenQuery;
     }
 
-    @Override
-    public IndicesQueryBuilder getBuilderPrototype() {
-        return IndicesQueryBuilder.PROTOTYPE;
+    protected boolean matchesIndices(String currentIndex, String... indices) {
+        final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices);
+        for (String index : concreteIndices) {
+            if (Regex.simpleMatch(index, currentIndex)) {
+                return true;
+            }
+        }
+        return false;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java
index b217a5e..9d44f39 100644
--- a/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java
@@ -19,11 +19,7 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
 import org.elasticsearch.action.search.SearchRequestBuilder;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
@@ -32,62 +28,18 @@ import java.io.IOException;
  * @deprecated Use {@link SearchRequestBuilder#setTerminateAfter(int)} instead.
  */
 @Deprecated
-public class LimitQueryBuilder extends AbstractQueryBuilder<LimitQueryBuilder> {
+public class LimitQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "limit";
     private final int limit;
-    static final LimitQueryBuilder PROTOTYPE = new LimitQueryBuilder(-1);
 
     public LimitQueryBuilder(int limit) {
         this.limit = limit;
     }
 
-    public int limit() {
-        return limit;
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(LimitQueryParser.NAME);
         builder.field("value", limit);
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // this filter is deprecated and parses to a filter that matches everything
-        return Queries.newMatchAllQuery();
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
-
-    @Override
-    protected boolean doEquals(LimitQueryBuilder other) {
-        return Integer.compare(other.limit, limit) == 0;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return this.limit;
-    }
-
-    @Override
-    protected LimitQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new LimitQueryBuilder(in.readInt());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeInt(limit);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/LimitQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/LimitQueryParser.java
index ed47198..3419f61 100644
--- a/core/src/main/java/org/elasticsearch/index/query/LimitQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/LimitQueryParser.java
@@ -19,17 +19,17 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
-/**
- * Parser for limit query
- * @deprecated use terminate_after feature instead
- */
 @Deprecated
-public class LimitQueryParser extends BaseQueryParser<LimitQueryBuilder> {
+public class LimitQueryParser implements QueryParser {
+
+    public static final String NAME = "limit";
 
     @Inject
     public LimitQueryParser() {
@@ -37,16 +37,14 @@ public class LimitQueryParser extends BaseQueryParser<LimitQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{LimitQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public LimitQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         int limit = -1;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String currentFieldName = null;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -55,10 +53,6 @@ public class LimitQueryParser extends BaseQueryParser<LimitQueryBuilder> {
             } else if (token.isValue()) {
                 if ("value".equals(currentFieldName)) {
                     limit = parser.intValue();
-                } else if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[limit] query does not support [" + currentFieldName + "]");
                 }
@@ -69,11 +63,7 @@ public class LimitQueryParser extends BaseQueryParser<LimitQueryBuilder> {
             throw new QueryParsingException(parseContext, "No value specified for limit query");
         }
 
-        return new LimitQueryBuilder(limit).boost(boost).queryName(queryName);
-    }
-
-    @Override
-    public LimitQueryBuilder getBuilderPrototype() {
-        return LimitQueryBuilder.PROTOTYPE;
+        // this filter is deprecated and parses to a filter that matches everything
+        return Queries.newMatchAllQuery();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java
index 00c5019..b09bc9f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java
@@ -19,10 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
@@ -30,52 +26,26 @@ import java.io.IOException;
 /**
  * A query that matches on all documents.
  */
-public class MatchAllQueryBuilder extends AbstractQueryBuilder<MatchAllQueryBuilder> {
+public class MatchAllQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MatchAllQueryBuilder> {
 
-    public static final String NAME = "match_all";
-
-    static final MatchAllQueryBuilder PROTOTYPE = new MatchAllQueryBuilder();
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return Queries.newMatchAllQuery();
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
+    private float boost = -1;
 
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    protected boolean doEquals(MatchAllQueryBuilder other) {
-        return true;
+    public MatchAllQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     @Override
-    protected int doHashCode() {
-        return 0;
-    }
-
-    @Override
-    protected MatchAllQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new MatchAllQueryBuilder();
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        //nothing to write really
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(MatchAllQueryParser.NAME);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java
index 4066c75..933d3d3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java
@@ -19,16 +19,21 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
 /**
- * Parser for match_all query
+ *
  */
-public class MatchAllQueryParser extends BaseQueryParser<MatchAllQueryBuilder> {
+public class MatchAllQueryParser implements QueryParser {
+
+    public static final String NAME = "match_all";
 
     @Inject
     public MatchAllQueryParser() {
@@ -36,38 +41,35 @@ public class MatchAllQueryParser extends BaseQueryParser<MatchAllQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{MatchAllQueryBuilder.NAME, Strings.toCamelCase(MatchAllQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public MatchAllQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
+        float boost = 1.0f;
         String currentFieldName = null;
+
         XContentParser.Token token;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         while (((token = parser.nextToken()) != XContentParser.Token.END_OBJECT && token != XContentParser.Token.END_ARRAY)) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
+                if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[match_all] query does not support [" + currentFieldName + "]");
                 }
             }
         }
-        MatchAllQueryBuilder queryBuilder = new MatchAllQueryBuilder();
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
 
-    @Override
-    public MatchAllQueryBuilder getBuilderPrototype() {
-        return MatchAllQueryBuilder.PROTOTYPE;
+        if (boost == 1.0f) {
+            return Queries.newMatchAllQuery();
+        }
+
+        MatchAllDocsQuery query = new MatchAllDocsQuery();
+        query.setBoost(boost);
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryBuilder.java
deleted file mode 100644
index 247f514..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryBuilder.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-
-import java.io.IOException;
-
-/**
- * A query that matches no document.
- */
-public class MatchNoneQueryBuilder extends AbstractQueryBuilder<MatchNoneQueryBuilder> {
-
-    public static final String NAME = "match_none";
-
-    public static final MatchNoneQueryBuilder PROTOTYPE = new MatchNoneQueryBuilder();
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return Queries.newMatchNoDocsQuery();
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
-
-    @Override
-    protected boolean doEquals(MatchNoneQueryBuilder other) {
-        return true;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return 0;
-    }
-
-    @Override
-    protected MatchNoneQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new MatchNoneQueryBuilder();
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        //nothing to write really
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryParser.java
deleted file mode 100644
index 3536a5d..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryParser.java
+++ /dev/null
@@ -1,55 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.xcontent.XContentParser;
-
-import java.io.IOException;
-
-public class MatchNoneQueryParser extends BaseQueryParser {
-
-    @Inject
-    public MatchNoneQueryParser() {
-    }
-
-    @Override
-    public String[] names() {
-        return new String[]{MatchNoneQueryBuilder.NAME, Strings.toCamelCase(MatchNoneQueryBuilder.NAME)};
-    }
-
-    @Override
-    public MatchNoneQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException {
-        XContentParser parser = parseContext.parser();
-
-        XContentParser.Token token = parser.nextToken();
-        if (token != XContentParser.Token.END_OBJECT) {
-            throw new QueryParsingException(parseContext, "[match_none] query malformed");
-        }
-
-        return new MatchNoneQueryBuilder();
-    }
-
-    @Override
-    public MatchNoneQueryBuilder getBuilderPrototype() {
-        return MatchNoneQueryBuilder.PROTOTYPE;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java
index 5fbfff7..6f73f08 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java
@@ -29,9 +29,12 @@ import java.util.Locale;
  * Match query is a query that analyzes the text and constructs a query as the result of the analysis. It
  * can construct different queries based on the type provided.
  */
-public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
+public class MatchQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MatchQueryBuilder> {
 
-    public static final String NAME = "match";
+    public enum Operator {
+        OR,
+        AND
+    }
 
     public enum Type {
         /**
@@ -63,6 +66,8 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
 
     private String analyzer;
 
+    private Float boost;
+
     private Integer slop;
 
     private Fuzziness fuzziness;
@@ -83,7 +88,7 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
 
     private Float cutoff_Frequency = null;
 
-    static final MatchQueryBuilder PROTOTYPE = new MatchQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * Constructs a new text query.
@@ -119,6 +124,15 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
     }
 
     /**
+     * Set the boost to apply to the query.
+     */
+    @Override
+    public MatchQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
      * Set the phrase slop if evaluated to a phrase query type.
      */
     public MatchQueryBuilder slop(int slop) {
@@ -187,9 +201,17 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
         return this;
     }
 
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public MatchQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(MatchQueryParser.NAME);
         builder.startObject(name);
 
         builder.field("query", text);
@@ -202,6 +224,9 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
         if (analyzer != null) {
             builder.field("analyzer", analyzer);
         }
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
         if (slop != null) {
             builder.field("slop", slop);
         }
@@ -233,13 +258,12 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
         if (cutoff_Frequency != null) {
             builder.field("cutoff_frequency", cutoff_Frequency);
         }
-        printBoostAndQueryName(builder);
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+
+
         builder.endObject();
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java
index 5d9ba66..62177ab 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.index.query;
 
 import org.apache.lucene.queries.ExtendedCommonTermsQuery;
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
@@ -34,7 +35,9 @@ import java.io.IOException;
 /**
  *
  */
-public class MatchQueryParser extends BaseQueryParserTemp {
+public class MatchQueryParser implements QueryParser {
+
+    public static final String NAME = "match";
 
     @Inject
     public MatchQueryParser() {
@@ -43,13 +46,12 @@ public class MatchQueryParser extends BaseQueryParserTemp {
     @Override
     public String[] names() {
         return new String[]{
-                MatchQueryBuilder.NAME, "match_phrase", "matchPhrase", "match_phrase_prefix", "matchPhrasePrefix", "matchFuzzy", "match_fuzzy", "fuzzy_match"
+                NAME, "match_phrase", "matchPhrase", "match_phrase_prefix", "matchPhrasePrefix", "matchFuzzy", "match_fuzzy", "fuzzy_match"
         };
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         MatchQuery.Type type = MatchQuery.Type.BOOLEAN;
@@ -68,8 +70,8 @@ public class MatchQueryParser extends BaseQueryParserTemp {
         String fieldName = parser.currentName();
 
         Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        MatchQuery matchQuery = new MatchQuery(context);
+        float boost = 1.0f;
+        MatchQuery matchQuery = new MatchQuery(parseContext);
         String minimumShouldMatch = null;
         String queryName = null;
 
@@ -95,7 +97,7 @@ public class MatchQueryParser extends BaseQueryParserTemp {
                         }
                     } else if ("analyzer".equals(currentFieldName)) {
                         String analyzer = parser.text();
-                        if (context.analysisService().analyzer(analyzer) == null) {
+                        if (parseContext.analysisService().analyzer(analyzer) == null) {
                             throw new QueryParsingException(parseContext, "[match] analyzer [" + parser.text() + "] not found");
                         }
                         matchQuery.setAnalyzer(analyzer);
@@ -110,7 +112,15 @@ public class MatchQueryParser extends BaseQueryParserTemp {
                     } else if ("max_expansions".equals(currentFieldName) || "maxExpansions".equals(currentFieldName)) {
                         matchQuery.setMaxExpansions(parser.intValue());
                     } else if ("operator".equals(currentFieldName)) {
-                        matchQuery.setOccur(Operator.fromString(parser.text()).toBooleanClauseOccur());
+                        String op = parser.text();
+                        if ("or".equalsIgnoreCase(op)) {
+                            matchQuery.setOccur(BooleanClause.Occur.SHOULD);
+                        } else if ("and".equalsIgnoreCase(op)) {
+                            matchQuery.setOccur(BooleanClause.Occur.MUST);
+                        } else {
+                            throw new QueryParsingException(parseContext, "text query requires operator to be either 'and' or 'or', not ["
+                                    + op + "]");
+                        }
                     } else if ("minimum_should_match".equals(currentFieldName) || "minimumShouldMatch".equals(currentFieldName)) {
                         minimumShouldMatch = parser.textOrNull();
                     } else if ("fuzzy_rewrite".equals(currentFieldName) || "fuzzyRewrite".equals(currentFieldName)) {
@@ -164,13 +174,8 @@ public class MatchQueryParser extends BaseQueryParserTemp {
         }
         query.setBoost(boost);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
         return query;
     }
-
-    @Override
-    public MatchQueryBuilder getBuilderPrototype() {
-        return MatchQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java
index 253af16..ac3f279 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java
@@ -19,45 +19,25 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.*;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
-import java.util.Collection;
-import java.util.Objects;
 
 /**
- * Constructs a filter that have only null values or no value in the original field.
+ * Constructs a filter that only match on documents that the field has a value in them.
  */
-public class MissingQueryBuilder extends AbstractQueryBuilder<MissingQueryBuilder> {
+public class MissingQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "missing";
+    private String name;
 
-    public static final boolean DEFAULT_NULL_VALUE = false;
+    private String queryName;
 
-    public static final boolean DEFAULT_EXISTENCE_VALUE = true;
+    private Boolean nullValue;
 
-    private final String fieldPattern;
+    private Boolean existence;
 
-    private boolean nullValue = DEFAULT_NULL_VALUE;
-
-    private boolean existence = DEFAULT_EXISTENCE_VALUE;
-
-    static final MissingQueryBuilder PROTOTYPE = new MissingQueryBuilder(null);
-
-    public MissingQueryBuilder(String fieldPattern) {
-        this.fieldPattern = fieldPattern;
-    }
-
-    public String fieldPattern() {
-        return this.fieldPattern;
+    public MissingQueryBuilder(String name) {
+        this.name = name;
     }
 
     /**
@@ -70,15 +50,7 @@ public class MissingQueryBuilder extends AbstractQueryBuilder<MissingQueryBuilde
     }
 
     /**
-     * Returns true if the missing filter will include documents where the field contains a null value, otherwise
-     * these documents will not be included.
-     */
-    public boolean nullValue() {
-        return this.nullValue;
-    }
-
-    /**
-     * Should the missing filter include documents where the field doesn't exist in the docs.
+     * Should the missing filter include documents where the field doesn't exists in the docs.
      * Defaults to <tt>true</tt>.
      */
     public MissingQueryBuilder existence(boolean existence) {
@@ -87,157 +59,26 @@ public class MissingQueryBuilder extends AbstractQueryBuilder<MissingQueryBuilde
     }
 
     /**
-     * Returns true if the missing filter will include documents where the field has no values, otherwise
-     * these documents will not be included.
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
      */
-    public boolean existence() {
-        return this.existence;
+    public MissingQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("field", fieldPattern);
-        builder.field("null_value", nullValue);
-        builder.field("existence", existence);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return newFilter(context, fieldPattern, existence, nullValue);
-    }
-
-    public static Query newFilter(QueryShardContext context, String fieldPattern, boolean existence, boolean nullValue) {
-        if (!existence && !nullValue) {
-            throw new QueryShardException(context, "missing must have either existence, or null_value, or both set to true");
-        }
-
-        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType) context.mapperService().fullName(FieldNamesFieldMapper.NAME);
-        if (fieldNamesFieldType == null) {
-            // can only happen when no types exist, so no docs exist either
-            return Queries.newMatchNoDocsQuery();
-        }
-
-        ObjectMapper objectMapper = context.getObjectMapper(fieldPattern);
-        if (objectMapper != null) {
-            // automatic make the object mapper pattern
-            fieldPattern = fieldPattern + ".*";
-        }
-
-        Collection<String> fields = context.simpleMatchToIndexNames(fieldPattern);
-        if (fields.isEmpty()) {
-            if (existence) {
-                // if we ask for existence of fields, and we found none, then we should match on all
-                return Queries.newMatchAllQuery();
-            }
-            return null;
-        }
-
-        Query existenceFilter = null;
-        Query nullFilter = null;
-
-        if (existence) {
-            BooleanQuery boolFilter = new BooleanQuery();
-            for (String field : fields) {
-                MappedFieldType fieldType = context.fieldMapper(field);
-                Query filter = null;
-                if (fieldNamesFieldType.isEnabled()) {
-                    final String f;
-                    if (fieldType != null) {
-                        f = fieldType.names().indexName();
-                    } else {
-                        f = field;
-                    }
-                    filter = fieldNamesFieldType.termQuery(f, context);
-                }
-                // if _field_names are not indexed, we need to go the slow way
-                if (filter == null && fieldType != null) {
-                    filter = fieldType.rangeQuery(null, null, true, true);
-                }
-                if (filter == null) {
-                    filter = new TermRangeQuery(field, null, null, true, true);
-                }
-                boolFilter.add(filter, BooleanClause.Occur.SHOULD);
-            }
-
-            existenceFilter = boolFilter;
-            existenceFilter = Queries.not(existenceFilter);;
-        }
-
-        if (nullValue) {
-            for (String field : fields) {
-                MappedFieldType fieldType = context.fieldMapper(field);
-                if (fieldType != null) {
-                    nullFilter = fieldType.nullValueQuery();
-                }
-            }
-        }
-
-        Query filter;
-        if (nullFilter != null) {
-            if (existenceFilter != null) {
-                BooleanQuery combined = new BooleanQuery();
-                combined.add(existenceFilter, BooleanClause.Occur.SHOULD);
-                combined.add(nullFilter, BooleanClause.Occur.SHOULD);
-                // cache the not filter as well, so it will be faster
-                filter = combined;
-            } else {
-                filter = nullFilter;
-            }
-        } else {
-            filter = existenceFilter;
+        builder.startObject(MissingQueryParser.NAME);
+        builder.field("field", name);
+        if (nullValue != null) {
+            builder.field("null_value", nullValue);
         }
-
-        if (filter == null) {
-            return null;
-        }
-
-        return new ConstantScoreQuery(filter);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldPattern)) {
-            validationException = addValidationError("missing must be provided with a [field]", validationException);
+        if (existence != null) {
+            builder.field("existence", existence);
         }
-        if (!existence && !nullValue) {
-            validationException = addValidationError("missing must have either existence, or null_value, or both set to true", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    protected MissingQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        MissingQueryBuilder missingQueryBuilder = new MissingQueryBuilder(in.readString());
-        missingQueryBuilder.nullValue = in.readBoolean();
-        missingQueryBuilder.existence = in.readBoolean();
-        return missingQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldPattern);
-        out.writeBoolean(nullValue);
-        out.writeBoolean(existence);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldPattern, nullValue, existence);
-    }
-
-    @Override
-    protected boolean doEquals(MissingQueryBuilder other) {
-        return Objects.equals(fieldPattern, other.fieldPattern) &&
-                Objects.equals(nullValue, other.nullValue) &&
-                Objects.equals(existence, other.existence);
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java
index 1dd6bd1..6ef19d7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java
@@ -19,15 +19,29 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermRangeQuery;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
+import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
+import java.util.Collection;
 
 /**
- * Parser for missing query
+ *
  */
-public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
+public class MissingQueryParser implements QueryParser {
+
+    public static final String NAME = "missing";
+    public static final boolean DEFAULT_NULL_VALUE = false;
+    public static final boolean DEFAULT_EXISTENCE_VALUE = true;
 
     @Inject
     public MissingQueryParser() {
@@ -35,18 +49,17 @@ public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{MissingQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public MissingQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldPattern = null;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        boolean nullValue = MissingQueryBuilder.DEFAULT_NULL_VALUE;
-        boolean existence = MissingQueryBuilder.DEFAULT_EXISTENCE_VALUE;
+        boolean nullValue = DEFAULT_NULL_VALUE;
+        boolean existence = DEFAULT_EXISTENCE_VALUE;
 
         XContentParser.Token token;
         String currentFieldName = null;
@@ -62,8 +75,6 @@ public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
                     existence = parser.booleanValue();
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[missing] query does not support [" + currentFieldName + "]");
                 }
@@ -73,15 +84,98 @@ public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
         if (fieldPattern == null) {
             throw new QueryParsingException(parseContext, "missing must be provided with a [field]");
         }
-        return new MissingQueryBuilder(fieldPattern)
-                .nullValue(nullValue)
-                .existence(existence)
-                .boost(boost)
-                .queryName(queryName);
+
+        return newFilter(parseContext, fieldPattern, existence, nullValue, queryName);
     }
 
-    @Override
-    public MissingQueryBuilder getBuilderPrototype() {
-        return MissingQueryBuilder.PROTOTYPE;
+    public static Query newFilter(QueryParseContext parseContext, String fieldPattern, boolean existence, boolean nullValue, String queryName) {
+        if (!existence && !nullValue) {
+            throw new QueryParsingException(parseContext, "missing must have either existence, or null_value, or both set to true");
+        }
+
+        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType)parseContext.mapperService().fullName(FieldNamesFieldMapper.NAME);
+        if (fieldNamesFieldType == null) {
+            // can only happen when no types exist, so no docs exist either
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        ObjectMapper objectMapper = parseContext.getObjectMapper(fieldPattern);
+        if (objectMapper != null) {
+            // automatic make the object mapper pattern
+            fieldPattern = fieldPattern + ".*";
+        }
+
+        Collection<String> fields = parseContext.simpleMatchToIndexNames(fieldPattern);
+        if (fields.isEmpty()) {
+            if (existence) {
+                // if we ask for existence of fields, and we found none, then we should match on all
+                return Queries.newMatchAllQuery();
+            }
+            return null;
+        }
+
+        Query existenceFilter = null;
+        Query nullFilter = null;
+
+        if (existence) {
+            BooleanQuery boolFilter = new BooleanQuery();
+            for (String field : fields) {
+                MappedFieldType fieldType = parseContext.fieldMapper(field);
+                Query filter = null;
+                if (fieldNamesFieldType.isEnabled()) {
+                    final String f;
+                    if (fieldType != null) {
+                        f = fieldType.names().indexName();
+                    } else {
+                        f = field;
+                    }
+                    filter = fieldNamesFieldType.termQuery(f, parseContext);
+                }
+                // if _field_names are not indexed, we need to go the slow way
+                if (filter == null && fieldType != null) {
+                    filter = fieldType.rangeQuery(null, null, true, true);
+                }
+                if (filter == null) {
+                    filter = new TermRangeQuery(field, null, null, true, true);
+                }
+                boolFilter.add(filter, BooleanClause.Occur.SHOULD);
+            }
+
+            existenceFilter = boolFilter;
+            existenceFilter = Queries.not(existenceFilter);;
+        }
+
+        if (nullValue) {
+            for (String field : fields) {
+                MappedFieldType fieldType = parseContext.fieldMapper(field);
+                if (fieldType != null) {
+                    nullFilter = fieldType.nullValueQuery();
+                }
+            }
+        }
+
+        Query filter;
+        if (nullFilter != null) {
+            if (existenceFilter != null) {
+                BooleanQuery combined = new BooleanQuery();
+                combined.add(existenceFilter, BooleanClause.Occur.SHOULD);
+                combined.add(nullFilter, BooleanClause.Occur.SHOULD);
+                // cache the not filter as well, so it will be faster
+                filter = combined;
+            } else {
+                filter = nullFilter;
+            }
+        } else {
+            filter = existenceFilter;
+        }
+
+        if (filter == null) {
+            return null;
+        }
+
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, existenceFilter);
+        }
+        return new ConstantScoreQuery(filter);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
index fbd13ea..19d65d9 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
@@ -23,11 +23,7 @@ import org.elasticsearch.action.get.MultiGetRequest;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.lucene.uid.Versions;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.common.xcontent.XContentType;
+import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.index.VersionType;
 import org.elasticsearch.search.fetch.source.FetchSourceContext;
 
@@ -41,7 +37,7 @@ import java.util.Locale;
  * A more like this query that finds documents that are "like" the provided {@link #likeText(String)}
  * which is checked against the fields the query is constructed with.
  */
-public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQueryBuilder> {
+public class MoreLikeThisQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MoreLikeThisQueryBuilder> {
 
     /**
      * A single get item. Pure delegate to multi get.
@@ -132,8 +128,6 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         }
     }
 
-    public static final String NAME = "mlt";
-
     private final String[] fields;
     private List<Item> docs = new ArrayList<>();
     private List<Item> unlikeDocs = new ArrayList<>();
@@ -147,10 +141,10 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
     private int minWordLength = -1;
     private int maxWordLength = -1;
     private float boostTerms = -1;
+    private float boost = -1;
     private String analyzer;
     private Boolean failOnUnsupportedField;
-
-    static final MoreLikeThisQueryBuilder PROTOTYPE = new MoreLikeThisQueryBuilder();
+    private String queryName;
 
     /**
      * Constructs a new more like this query which uses the "_all" field.
@@ -346,6 +340,12 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         return this;
     }
 
+    @Override
+    public MoreLikeThisQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
     /**
      * Whether to fail or return no result when this query is run against a field which is not supported such as binary/numeric fields.
      */
@@ -354,10 +354,18 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         return this;
     }
 
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public MoreLikeThisQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
         String likeFieldName = MoreLikeThisQueryParser.Fields.LIKE.getPreferredName();
-        builder.startObject(NAME);
+        builder.startObject(MoreLikeThisQueryParser.NAME);
         if (fields != null) {
             builder.startArray("fields");
             for (String field : fields) {
@@ -404,21 +412,21 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         if (boostTerms != -1) {
             builder.field(MoreLikeThisQueryParser.Fields.BOOST_TERMS.getPreferredName(), boostTerms);
         }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
         if (analyzer != null) {
             builder.field("analyzer", analyzer);
         }
         if (failOnUnsupportedField != null) {
             builder.field(MoreLikeThisQueryParser.Fields.FAIL_ON_UNSUPPORTED_FIELD.getPreferredName(), failOnUnsupportedField);
         }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (include != null) {
             builder.field("include", include);
         }
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
index 6f505c5..98c3e2b 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
@@ -19,9 +19,7 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
-
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.queries.TermsQuery;
 import org.apache.lucene.search.BooleanClause;
@@ -45,7 +43,9 @@ import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.Iterator;
+import java.util.LinkedList;
 import java.util.List;
 import java.util.Set;
 
@@ -54,8 +54,9 @@ import static org.elasticsearch.index.mapper.Uid.createUidAsBytes;
 /**
  *
  */
-public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
+public class MoreLikeThisQueryParser implements QueryParser {
 
+    public static final String NAME = "mlt";
     private MoreLikeThisFetchService fetchService = null;
 
     public static class Fields {
@@ -88,16 +89,15 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{MoreLikeThisQueryBuilder.NAME, "more_like_this", "moreLikeThis"};
+        return new String[]{NAME, "more_like_this", "moreLikeThis"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         MoreLikeThisQuery mltQuery = new MoreLikeThisQuery();
-        mltQuery.setSimilarity(context.searchSimilarity());
+        mltQuery.setSimilarity(parseContext.searchSimilarity());
         Analyzer analyzer = null;
         List<String> moreLikeFields = null;
         boolean failOnUnsupportedField = true;
@@ -144,7 +144,7 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.MINIMUM_SHOULD_MATCH)) {
                     mltQuery.setMinimumShouldMatch(parser.text());
                 } else if ("analyzer".equals(currentFieldName)) {
-                    analyzer = context.analysisService().analyzer(parser.text());
+                    analyzer = parseContext.analysisService().analyzer(parser.text());
                 } else if ("boost".equals(currentFieldName)) {
                     mltQuery.setBoost(parser.floatValue());
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.FAIL_ON_UNSUPPORTED_FIELD)) {
@@ -164,10 +164,10 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
                     }
                     mltQuery.setStopWords(stopWords);
                 } else if ("fields".equals(currentFieldName)) {
-                    moreLikeFields = Lists.newLinkedList();
+                    moreLikeFields = new LinkedList<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         String field = parser.text();
-                        MappedFieldType fieldType = context.fieldMapper(field);
+                        MappedFieldType fieldType = parseContext.fieldMapper(field);
                         moreLikeFields.add(fieldType == null ? field : fieldType.names().indexName());
                     }
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.DOCUMENT_IDS)) {
@@ -216,14 +216,14 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
 
         // set analyzer
         if (analyzer == null) {
-            analyzer = context.mapperService().searchAnalyzer();
+            analyzer = parseContext.mapperService().searchAnalyzer();
         }
         mltQuery.setAnalyzer(analyzer);
 
         // set like text fields
         boolean useDefaultField = (moreLikeFields == null);
         if (useDefaultField) {
-            moreLikeFields = Lists.newArrayList(context.defaultField());
+            moreLikeFields = Collections.singletonList(parseContext.defaultField());
         }
         // possibly remove unsupported fields
         removeUnsupportedFields(moreLikeFields, analyzer, failOnUnsupportedField);
@@ -234,7 +234,7 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
 
         // support for named query
         if (queryName != null) {
-            context.addNamedQuery(queryName, mltQuery);
+            parseContext.addNamedQuery(queryName, mltQuery);
         }
 
         // handle like texts
@@ -258,12 +258,12 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
                     item.index(parseContext.index().name());
                 }
                 if (item.type() == null) {
-                    if (context.queryTypes().size() > 1) {
+                    if (parseContext.queryTypes().size() > 1) {
                         throw new QueryParsingException(parseContext,
                                     "ambiguous type for item with id: " + item.id()
                                 + " and index: " + item.index());
                     } else {
-                        item.type(context.queryTypes().iterator().next());
+                        item.type(parseContext.queryTypes().iterator().next());
                     }
                 }
                 // default fields if not present but don't override for artificial docs
@@ -356,9 +356,4 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
             boolQuery.add(query, BooleanClause.Occur.MUST_NOT);
         }
     }
-
-    @Override
-    public MoreLikeThisQueryBuilder getBuilderPrototype() {
-        return MoreLikeThisQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java
index 76349d0..9059865 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java
@@ -20,8 +20,6 @@
 package org.elasticsearch.index.query;
 
 import com.carrotsearch.hppc.ObjectFloatHashMap;
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.ParseFieldMatcher;
@@ -30,6 +28,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.search.MatchQuery;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 import java.util.Locale;
@@ -37,9 +36,7 @@ import java.util.Locale;
 /**
  * Same as {@link MatchQueryBuilder} but supports multiple fields.
  */
-public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQueryBuilder> {
-
-    public static final String NAME = "multi_match";
+public class MultiMatchQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MultiMatchQueryBuilder> {
 
     private final Object text;
 
@@ -48,10 +45,12 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
 
     private MultiMatchQueryBuilder.Type type;
 
-    private Operator operator;
+    private MatchQueryBuilder.Operator operator;
 
     private String analyzer;
 
+    private Float boost;
+
     private Integer slop;
 
     private Fuzziness fuzziness;
@@ -74,7 +73,8 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
 
     private MatchQueryBuilder.ZeroTermsQuery zeroTermsQuery = null;
 
-    static final MultiMatchQueryBuilder PROTOTYPE = new MultiMatchQueryBuilder(null);
+    private String queryName;
+
 
     public enum Type {
 
@@ -141,7 +141,7 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
                 }
             }
             if (type == null) {
-                throw new ElasticsearchParseException("failed to parse [{}] query type [{}]. unknown type.", NAME, value);
+                throw new ElasticsearchParseException("failed to parse [{}] query type [{}]. unknown type.", MultiMatchQueryParser.NAME, value);
             }
             return type;
         }
@@ -151,7 +151,7 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
      * Constructs a new text query.
      */
     public MultiMatchQueryBuilder(Object text, String... fields) {
-        this.fields = Lists.newArrayList();
+        this.fields = new ArrayList<>();
         this.fields.addAll(Arrays.asList(fields));
         this.text = text;
     }
@@ -195,7 +195,7 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
     /**
      * Sets the operator to use when using a boolean query. Defaults to <tt>OR</tt>.
      */
-    public MultiMatchQueryBuilder operator(Operator operator) {
+    public MultiMatchQueryBuilder operator(MatchQueryBuilder.Operator operator) {
         this.operator = operator;
         return this;
     }
@@ -210,6 +210,15 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
     }
 
     /**
+     * Set the boost to apply to the query.
+     */
+    @Override
+    public MultiMatchQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
      * Set the phrase slop if evaluated to a phrase query type.
      */
     public MultiMatchQueryBuilder slop(int slop) {
@@ -301,9 +310,17 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
         return this;
     }
 
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public MultiMatchQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(MultiMatchQueryParser.NAME);
 
         builder.field("query", text);
         builder.startArray("fields");
@@ -325,6 +342,9 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
         if (analyzer != null) {
             builder.field("analyzer", analyzer);
         }
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
         if (slop != null) {
             builder.field("slop", slop);
         }
@@ -364,13 +384,11 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
             builder.field("zero_terms_query", zeroTermsQuery.toString());
         }
 
-        printBoostAndQueryName(builder);
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
 
         builder.endObject();
     }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java
index fcd79d8..5922f52 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java
@@ -21,6 +21,7 @@ package org.elasticsearch.index.query;
 
 import com.google.common.collect.Maps;
 
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.regex.Regex;
@@ -36,7 +37,9 @@ import java.util.Map;
 /**
  * Same as {@link MatchQueryParser} but has support for multiple fields.
  */
-public class MultiMatchQueryParser extends BaseQueryParserTemp {
+public class MultiMatchQueryParser implements QueryParser {
+
+    public static final String NAME = "multi_match";
 
     @Inject
     public MultiMatchQueryParser() {
@@ -45,20 +48,19 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
     @Override
     public String[] names() {
         return new String[]{
-                MultiMatchQueryBuilder.NAME, "multiMatch"
+                NAME, "multiMatch"
         };
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         Float tieBreaker = null;
         MultiMatchQueryBuilder.Type type = null;
-        MultiMatchQuery multiMatchQuery = new MultiMatchQuery(context);
+        MultiMatchQuery multiMatchQuery = new MultiMatchQuery(parseContext);
         String minimumShouldMatch = null;
         Map<String, Float> fieldNameWithBoosts = Maps.newHashMap();
         String queryName = null;
@@ -71,12 +73,12 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
             } else if ("fields".equals(currentFieldName)) {
                 if (token == XContentParser.Token.START_ARRAY) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        extractFieldAndBoost(context, parser, fieldNameWithBoosts);
+                        extractFieldAndBoost(parseContext, parser, fieldNameWithBoosts);
                     }
                 } else if (token.isValue()) {
-                    extractFieldAndBoost(context, parser, fieldNameWithBoosts);
+                    extractFieldAndBoost(parseContext, parser, fieldNameWithBoosts);
                 } else {
-                    throw new QueryParsingException(parseContext, "[" + MultiMatchQueryBuilder.NAME + "] query does not support [" + currentFieldName + "]");
+                    throw new QueryParsingException(parseContext, "[" + NAME + "] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("query".equals(currentFieldName)) {
@@ -85,8 +87,8 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
                     type = MultiMatchQueryBuilder.Type.parse(parser.text(), parseContext.parseFieldMatcher());
                 } else if ("analyzer".equals(currentFieldName)) {
                     String analyzer = parser.text();
-                    if (context.analysisService().analyzer(analyzer) == null) {
-                        throw new QueryParsingException(parseContext, "[" + MultiMatchQueryBuilder.NAME + "] analyzer [" + parser.text() + "] not found");
+                    if (parseContext.analysisService().analyzer(analyzer) == null) {
+                        throw new QueryParsingException(parseContext, "[" + NAME + "] analyzer [" + parser.text() + "] not found");
                     }
                     multiMatchQuery.setAnalyzer(analyzer);
                 } else if ("boost".equals(currentFieldName)) {
@@ -100,7 +102,15 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
                 } else if ("max_expansions".equals(currentFieldName) || "maxExpansions".equals(currentFieldName)) {
                     multiMatchQuery.setMaxExpansions(parser.intValue());
                 } else if ("operator".equals(currentFieldName)) {
-                    multiMatchQuery.setOccur(Operator.fromString(parser.text()).toBooleanClauseOccur());
+                    String op = parser.text();
+                    if ("or".equalsIgnoreCase(op)) {
+                        multiMatchQuery.setOccur(BooleanClause.Occur.SHOULD);
+                    } else if ("and".equalsIgnoreCase(op)) {
+                        multiMatchQuery.setOccur(BooleanClause.Occur.MUST);
+                    } else {
+                        throw new QueryParsingException(parseContext, "text query requires operator to be either 'and' or 'or', not [" + op
+                                + "]");
+                    }
                 } else if ("minimum_should_match".equals(currentFieldName) || "minimumShouldMatch".equals(currentFieldName)) {
                     minimumShouldMatch = parser.textOrNull();
                 } else if ("fuzzy_rewrite".equals(currentFieldName) || "fuzzyRewrite".equals(currentFieldName)) {
@@ -157,12 +167,12 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
 
         query.setBoost(boost);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
         return query;
     }
 
-    private void extractFieldAndBoost(QueryShardContext context, XContentParser parser, Map<String, Float> fieldNameWithBoosts) throws IOException {
+    private void extractFieldAndBoost(QueryParseContext parseContext, XContentParser parser, Map<String, Float> fieldNameWithBoosts) throws IOException {
         String fField = null;
         Float fBoost = null;
         char[] fieldText = parser.textCharacters();
@@ -180,16 +190,11 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
         }
 
         if (Regex.isSimpleMatchPattern(fField)) {
-            for (String field : context.mapperService().simpleMatchToIndexNames(fField)) {
+            for (String field : parseContext.mapperService().simpleMatchToIndexNames(fField)) {
                 fieldNameWithBoosts.put(field, fBoost);
             }
         } else {
             fieldNameWithBoosts.put(fField, fBoost);
         }
     }
-
-    @Override
-    public MultiMatchQueryBuilder getBuilderPrototype() {
-        return MultiMatchQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java
index 0e946d6..9c7383d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java
@@ -18,6 +18,6 @@
  */
 package org.elasticsearch.index.query;
 
-public interface MultiTermQueryBuilder<QB extends MultiTermQueryBuilder<QB>> extends QueryBuilder<QB> {
+public abstract class MultiTermQueryBuilder extends QueryBuilder {
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java
index bb2e4b4..63b40dc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java
@@ -25,9 +25,7 @@ import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 import java.io.IOException;
 import java.util.Objects;
 
-public class NestedQueryBuilder extends AbstractQueryBuilder<NestedQueryBuilder> {
-
-    public static final String NAME = "nested";
+public class NestedQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<NestedQueryBuilder> {
 
     private final QueryBuilder queryBuilder;
 
@@ -35,28 +33,39 @@ public class NestedQueryBuilder extends AbstractQueryBuilder<NestedQueryBuilder>
 
     private String scoreMode;
 
-    private QueryInnerHitBuilder innerHit;
+    private float boost = 1.0f;
 
-    static final NestedQueryBuilder PROTOTYPE = new NestedQueryBuilder();
+    private String queryName;
+
+    private QueryInnerHitBuilder innerHit;
 
     public NestedQueryBuilder(String path, QueryBuilder queryBuilder) {
         this.path = path;
         this.queryBuilder = Objects.requireNonNull(queryBuilder);
     }
+    /**
+     * The score mode.
+     */
+    public NestedQueryBuilder scoreMode(String scoreMode) {
+        this.scoreMode = scoreMode;
+        return this;
+    }
 
     /**
-     * private constructor only used internally
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    private NestedQueryBuilder() {
-        this.path = null;
-        this.queryBuilder = null;
+    @Override
+    public NestedQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
-     * The score mode.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public NestedQueryBuilder scoreMode(String scoreMode) {
-        this.scoreMode = scoreMode;
+    public NestedQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
         return this;
     }
 
@@ -70,14 +79,19 @@ public class NestedQueryBuilder extends AbstractQueryBuilder<NestedQueryBuilder>
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(NestedQueryParser.NAME);
         builder.field("query");
         queryBuilder.toXContent(builder, params);
         builder.field("path", path);
         if (scoreMode != null) {
             builder.field("score_mode", scoreMode);
         }
-        printBoostAndQueryName(builder);
+        if (boost != 1.0f) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (innerHit != null) {
             builder.startObject("inner_hits");
             builder.value(innerHit);
@@ -86,8 +100,4 @@ public class NestedQueryBuilder extends AbstractQueryBuilder<NestedQueryBuilder>
         builder.endObject();
     }
 
-    @Override
-    public final String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java
index 7e4b376..e14720b 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java
@@ -26,19 +26,19 @@ import org.apache.lucene.search.join.ToParentBlockJoinQuery;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.query.support.InnerHitsQueryParserHelper;
 import org.elasticsearch.index.query.support.NestedInnerQueryParseSupport;
 import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.internal.SubSearchContext;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
 
 import java.io.IOException;
 
-public class NestedQueryParser extends BaseQueryParserTemp {
+public class NestedQueryParser implements QueryParser {
 
+    public static final String NAME = "nested";
     private static final ParseField FILTER_FIELD = new ParseField("filter").withAllDeprecated("query");
 
     private final InnerHitsQueryParserHelper innerHitsQueryParserHelper;
@@ -50,16 +50,15 @@ public class NestedQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{NestedQueryBuilder.NAME, Strings.toCamelCase(NestedQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        final ToBlockJoinQueryBuilder builder = new ToBlockJoinQueryBuilder(context);
+        final ToBlockJoinQueryBuilder builder = new ToBlockJoinQueryBuilder(parseContext);
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         ScoreMode scoreMode = ScoreMode.Avg;
         String queryName = null;
 
@@ -111,7 +110,7 @@ public class NestedQueryParser extends BaseQueryParserTemp {
         if (joinQuery != null) {
             joinQuery.setBoost(boost);
             if (queryName != null) {
-                context.addNamedQuery(queryName, joinQuery);
+                parseContext.addNamedQuery(queryName, joinQuery);
             }
         }
         return joinQuery;
@@ -120,17 +119,17 @@ public class NestedQueryParser extends BaseQueryParserTemp {
     public static class ToBlockJoinQueryBuilder extends NestedInnerQueryParseSupport {
 
         private ScoreMode scoreMode;
-        private Tuple<String, SubSearchContext> innerHits;
+        private InnerHitsSubSearchContext innerHits;
 
-        public ToBlockJoinQueryBuilder(QueryShardContext context) throws IOException {
-            super(context);
+        public ToBlockJoinQueryBuilder(QueryParseContext parseContext) throws IOException {
+            super(parseContext);
         }
 
         public void setScoreMode(ScoreMode scoreMode) {
             this.scoreMode = scoreMode;
         }
 
-        public void setInnerHits(Tuple<String, SubSearchContext> innerHits) {
+        public void setInnerHits(InnerHitsSubSearchContext innerHits) {
             this.innerHits = innerHits;
         }
 
@@ -147,14 +146,14 @@ public class NestedQueryParser extends BaseQueryParserTemp {
                     innerQuery = null;
                 }
             } else {
-                throw new QueryShardException(shardContext, "[nested] requires either 'query' or 'filter' field");
+                throw new QueryParsingException(parseContext, "[nested] requires either 'query' or 'filter' field");
             }
 
             if (innerHits != null) {
-                ParsedQuery parsedQuery = new ParsedQuery(innerQuery, shardContext.copyNamedQueries());
-                InnerHitsContext.NestedInnerHits nestedInnerHits = new InnerHitsContext.NestedInnerHits(innerHits.v2(), parsedQuery, null, getParentObjectMapper(), nestedObjectMapper);
-                String name = innerHits.v1() != null ? innerHits.v1() : path;
-                shardContext.addInnerHits(name, nestedInnerHits);
+                ParsedQuery parsedQuery = new ParsedQuery(innerQuery, parseContext.copyNamedQueries());
+                InnerHitsContext.NestedInnerHits nestedInnerHits = new InnerHitsContext.NestedInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, getParentObjectMapper(), nestedObjectMapper);
+                String name = innerHits.getName() != null ? innerHits.getName() : path;
+                parseContext.addInnerHits(name, nestedInnerHits);
             }
 
             if (innerQuery != null) {
@@ -165,9 +164,4 @@ public class NestedQueryParser extends BaseQueryParserTemp {
         }
 
     }
-
-    @Override
-    public NestedQueryBuilder getBuilderPrototype() {
-        return NestedQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java
index a26ebb7..c16cf64 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java
@@ -19,10 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
@@ -31,71 +27,29 @@ import java.util.Objects;
 /**
  * A filter that matches documents matching boolean combinations of other filters.
  */
-public class NotQueryBuilder extends AbstractQueryBuilder<NotQueryBuilder> {
-
-    public static final String NAME = "not";
+public class NotQueryBuilder extends QueryBuilder {
 
     private final QueryBuilder filter;
 
-    static final NotQueryBuilder PROTOTYPE = new NotQueryBuilder(null);
+    private String queryName;
 
     public NotQueryBuilder(QueryBuilder filter) {
-        this.filter = filter;
+        this.filter = Objects.requireNonNull(filter);
     }
 
-    /**
-     * @return the query added to "not".
-     */
-    public QueryBuilder innerQuery() {
-        return this.filter;
+    public NotQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(NotQueryParser.NAME);
         builder.field("query");
         filter.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query luceneQuery = filter.toFilter(context);
-        if (luceneQuery == null) {
-            return null;
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return Queries.not(luceneQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQuery(filter, null);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(filter);
-    }
-
-    @Override
-    protected boolean doEquals(NotQueryBuilder other) {
-        return Objects.equals(filter, other.filter);
-    }
-
-    @Override
-    protected NotQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder queryBuilder = in.readQuery();
-        return new NotQueryBuilder(queryBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(filter);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java
index 2388eb1..6bfe4c7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java
@@ -19,17 +19,20 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
 /**
- * Parser for not query
+ *
  */
-public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
+public class NotQueryParser implements QueryParser {
 
+    public static final String NAME = "not";
     private static final ParseField QUERY_FIELD = new ParseField("filter", "query");
 
     @Inject
@@ -38,19 +41,18 @@ public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{NotQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public NotQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder query = null;
+        Query query = null;
         boolean queryFound = false;
 
         String queryName = null;
         String currentFieldName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
@@ -59,18 +61,16 @@ public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
                 // skip
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, QUERY_FIELD)) {
-                    query = parseContext.parseInnerFilterToQueryBuilder();
+                    query = parseContext.parseInnerFilter();
                     queryFound = true;
                 } else {
                     queryFound = true;
                     // its the filter, and the name is the field
-                    query = parseContext.parseInnerFilterToQueryBuilder(currentFieldName);
+                    query = parseContext.parseInnerFilter(currentFieldName);
                 }
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[not] query does not support [" + currentFieldName + "]");
                 }
@@ -81,14 +81,14 @@ public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
             throw new QueryParsingException(parseContext, "filter is required when using `not` query");
         }
 
-        NotQueryBuilder notQueryBuilder = new NotQueryBuilder(query);
-        notQueryBuilder.queryName(queryName);
-        notQueryBuilder.boost(boost);
-        return notQueryBuilder;
-    }
+        if (query == null) {
+            return null;
+        }
 
-    @Override
-    public NotQueryBuilder getBuilderPrototype() {
-        return NotQueryBuilder.PROTOTYPE;
+        Query notQuery = Queries.not(query);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, notQuery);
+        }
+        return notQuery;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/Operator.java b/core/src/main/java/org/elasticsearch/index/query/Operator.java
deleted file mode 100644
index ce143eb..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/Operator.java
+++ /dev/null
@@ -1,85 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.query;
-
-import com.google.common.collect.Lists;
-import org.apache.lucene.search.BooleanClause;
-import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
-
-import java.io.IOException;
-
-public enum Operator implements Writeable<Operator> {
-    OR(0), AND(1);
-
-    private final int ordinal;
-
-    private static final Operator PROTOTYPE = OR;
-
-    private Operator(int ordinal) {
-        this.ordinal = ordinal;
-    }
-
-    public BooleanClause.Occur toBooleanClauseOccur() {
-        switch (this) {
-            case OR:
-                return BooleanClause.Occur.SHOULD;
-            case AND:
-                return BooleanClause.Occur.MUST;
-            default:
-                throw Operator.newOperatorException(this.toString());
-        }
-    }
-
-    @Override
-    public Operator readFrom(StreamInput in) throws IOException {
-        int ord = in.readVInt();
-        for (Operator operator : Operator.values()) {
-            if (operator.ordinal == ord) {
-                return operator;
-            }
-        }
-        throw new ElasticsearchException("unknown serialized operator [" + ord + "]");
-    }
-
-    public static Operator readOperatorFrom(StreamInput in) throws IOException {
-        return PROTOTYPE.readFrom(in);
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeVInt(this.ordinal);
-    }
-
-    public static Operator fromString(String op) {
-        for (Operator operator : Operator.values()) {
-            if (operator.name().equalsIgnoreCase(op)) {
-                return operator;
-            }
-        }
-        throw Operator.newOperatorException(op);
-    }
-
-    private static IllegalArgumentException newOperatorException(String op) {
-        return new IllegalArgumentException("operator needs to be either " + Lists.newArrayList(Operator.values()) +
-                ", but not [" + op + "]");
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/OrQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/OrQueryBuilder.java
index 1a53771..e8ad48b 100644
--- a/core/src/main/java/org/elasticsearch/index/query/OrQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/OrQueryBuilder.java
@@ -19,33 +19,22 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Lists;
-
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collections;
-import java.util.List;
-import java.util.Objects;
 
 /**
  * A filter that matches documents matching boolean combinations of other filters.
  * @deprecated Use {@link BoolQueryBuilder} instead
  */
 @Deprecated
-public class OrQueryBuilder extends AbstractQueryBuilder<OrQueryBuilder> {
-
-    public static final String NAME = "or";
+public class OrQueryBuilder extends QueryBuilder {
 
-    private final ArrayList<QueryBuilder> filters = Lists.newArrayList();
+    private ArrayList<QueryBuilder> filters = new ArrayList<>();
 
-    static final OrQueryBuilder PROTOTYPE = new OrQueryBuilder();
+    private String queryName;
 
     public OrQueryBuilder(QueryBuilder... filters) {
         Collections.addAll(this.filters, filters);
@@ -53,87 +42,28 @@ public class OrQueryBuilder extends AbstractQueryBuilder<OrQueryBuilder> {
 
     /**
      * Adds a filter to the list of filters to "or".
-     * No <tt>null</tt> value allowed.
      */
     public OrQueryBuilder add(QueryBuilder filterBuilder) {
         filters.add(filterBuilder);
         return this;
     }
 
-    /**
-     * @return the list of queries added to "or".
-     */
-    public List<QueryBuilder> innerQueries() {
-        return this.filters;
+    public OrQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(OrQueryParser.NAME);
         builder.startArray("filters");
         for (QueryBuilder filter : filters) {
             filter.toXContent(builder, params);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        if (filters.isEmpty()) {
-            // no filters provided, this should be ignored upstream
-            return null;
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-
-        BooleanQuery query = new BooleanQuery();
-        for (QueryBuilder f : filters) {
-            Query innerQuery = f.toFilter(context);
-            // ignore queries that are null
-            if (innerQuery != null) {
-                query.add(innerQuery, Occur.SHOULD);
-            }
-        }
-        if (query.clauses().isEmpty()) {
-            // no inner lucene query exists, ignore upstream
-            return null;
-        }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQueries(filters, null);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(filters);
-    }
-
-    @Override
-    protected boolean doEquals(OrQueryBuilder other) {
-        return Objects.equals(filters, other.filters);
-    }
-
-    @Override
-    protected OrQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        OrQueryBuilder orQueryBuilder = new OrQueryBuilder();
-        List<QueryBuilder> queryBuilders = readQueries(in);
-        for (QueryBuilder queryBuilder : queryBuilders) {
-            orQueryBuilder.add(queryBuilder);
-        }
-        return orQueryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, filters);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/OrQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/OrQueryParser.java
index 7b37872..ff2c0b2 100644
--- a/core/src/main/java/org/elasticsearch/index/query/OrQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/OrQueryParser.java
@@ -19,20 +19,22 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 import java.util.ArrayList;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
- * Parser for or query
- * @deprecated use bool query instead
+ *
  */
 @Deprecated
-public class OrQueryParser extends BaseQueryParser<OrQueryBuilder> {
+public class OrQueryParser implements QueryParser {
+
+    public static final String NAME = "or";
 
     @Inject
     public OrQueryParser() {
@@ -40,24 +42,23 @@ public class OrQueryParser extends BaseQueryParser<OrQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{OrQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public OrQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        final ArrayList<QueryBuilder> queries = newArrayList();
+        ArrayList<Query> queries = new ArrayList<>();
         boolean queriesFound = false;
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
         String currentFieldName = null;
         XContentParser.Token token = parser.currentToken();
         if (token == XContentParser.Token.START_ARRAY) {
             while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                 queriesFound = true;
-                QueryBuilder filter = parseContext.parseInnerFilterToQueryBuilder();
+                Query filter = parseContext.parseInnerFilter();
                 if (filter != null) {
                     queries.add(filter);
                 }
@@ -70,7 +71,15 @@ public class OrQueryParser extends BaseQueryParser<OrQueryBuilder> {
                     if ("filters".equals(currentFieldName)) {
                         queriesFound = true;
                         while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                            QueryBuilder filter = parseContext.parseInnerFilterToQueryBuilder();
+                            Query filter = parseContext.parseInnerFilter();
+                            if (filter != null) {
+                                queries.add(filter);
+                            }
+                        }
+                    } else {
+                        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
+                            queriesFound = true;
+                            Query filter = parseContext.parseInnerFilter();
                             if (filter != null) {
                                 queries.add(filter);
                             }
@@ -79,8 +88,6 @@ public class OrQueryParser extends BaseQueryParser<OrQueryBuilder> {
                 } else if (token.isValue()) {
                     if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
-                    } else if ("boost".equals(currentFieldName)) {
-                        boost = parser.floatValue();
                     } else {
                         throw new QueryParsingException(parseContext, "[or] query does not support [" + currentFieldName + "]");
                     }
@@ -92,17 +99,17 @@ public class OrQueryParser extends BaseQueryParser<OrQueryBuilder> {
             throw new QueryParsingException(parseContext, "[or] query requires 'filters' to be set on it'");
         }
 
-        OrQueryBuilder orQuery = new OrQueryBuilder();
-        for (QueryBuilder query : queries) {
-            orQuery.add(query);
+        if (queries.isEmpty()) {
+            return null;
         }
-        orQuery.queryName(queryName);
-        orQuery.boost(boost);
-        return orQuery;
-    }
 
-    @Override
-    public OrQueryBuilder getBuilderPrototype() {
-        return OrQueryBuilder.PROTOTYPE;
+        BooleanQuery query = new BooleanQuery();
+        for (Query f : queries) {
+            query.add(f, Occur.SHOULD);
+        }
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java
index a49580c..e0e5b2f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java
@@ -19,53 +19,44 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that matches documents containing terms with a specified prefix.
  */
-public class PrefixQueryBuilder extends AbstractQueryBuilder<PrefixQueryBuilder> implements MultiTermQueryBuilder<PrefixQueryBuilder> {
+public class PrefixQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<PrefixQueryBuilder> {
 
-    public static final String NAME = "prefix";
+    private final String name;
 
-    private final String fieldName;
+    private final String prefix;
 
-    private final String value;
+    private float boost = -1;
 
     private String rewrite;
 
-    static final PrefixQueryBuilder PROTOTYPE = new PrefixQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * A Query that matches documents containing terms with a specified prefix.
      *
-     * @param fieldName The name of the field
-     * @param value The prefix query
+     * @param name   The name of the field
+     * @param prefix The prefix query
      */
-    public PrefixQueryBuilder(String fieldName, String value) {
-        this.fieldName = fieldName;
-        this.value = value;
+    public PrefixQueryBuilder(String name, String prefix) {
+        this.name = name;
+        this.prefix = prefix;
     }
 
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public String value() {
-        return this.value;
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public PrefixQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     public PrefixQueryBuilder rewrite(String rewrite) {
@@ -73,83 +64,33 @@ public class PrefixQueryBuilder extends AbstractQueryBuilder<PrefixQueryBuilder>
         return this;
     }
 
-    public String rewrite() {
-        return this.rewrite;
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public PrefixQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("prefix", this.value);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
-        }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-
-        Query query = null;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            query = fieldType.prefixQuery(value, method, context);
-        }
-        if (query == null) {
-            PrefixQuery prefixQuery = new PrefixQuery(new Term(fieldName, BytesRefs.toBytesRef(value)));
-            if (method != null) {
-                prefixQuery.setRewriteMethod(method);
+        builder.startObject(PrefixQueryParser.NAME);
+        if (boost == -1 && rewrite == null && queryName == null) {
+            builder.field(name, prefix);
+        } else {
+            builder.startObject(name);
+            builder.field("prefix", prefix);
+            if (boost != -1) {
+                builder.field("boost", boost);
             }
-            query = prefixQuery;
-        }
-
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.value == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
+            if (rewrite != null) {
+                builder.field("rewrite", rewrite);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
         }
-        return validationException;
-    }
-
-    @Override
-    protected PrefixQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        PrefixQueryBuilder prefixQueryBuilder = new PrefixQueryBuilder(in.readString(), in.readString());
-        prefixQueryBuilder.rewrite = in.readOptionalString();
-        return prefixQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeString(value);
-        out.writeOptionalString(rewrite);
-    }
-
-    @Override
-    protected final int doHashCode() {
-        return Objects.hash(fieldName, value, rewrite);
-    }
-
-    @Override
-    protected boolean doEquals(PrefixQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java
index 3eae400..d61fec7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java
@@ -19,15 +19,27 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.PrefixQuery;
+import org.apache.lucene.search.Query;
+import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
 /**
- * Parser for prefix query
+ *
  */
-public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
+public class PrefixQueryParser implements QueryParser {
+
+    public static final String NAME = "prefix";
+
+    private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of prefix query");
 
     @Inject
     public PrefixQueryParser() {
@@ -35,19 +47,19 @@ public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{PrefixQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public PrefixQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = parser.currentName();
-        String value = null;
-        String rewrite = null;
-
+        String rewriteMethod = null;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+
+        String value = null;
+        float boost = 1.0f;
         String currentFieldName = null;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -68,14 +80,14 @@ public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
                         } else if ("boost".equals(currentFieldName)) {
                             boost = parser.floatValue();
                         } else if ("rewrite".equals(currentFieldName)) {
-                            rewrite = parser.textOrNull();
+                            rewriteMethod = parser.textOrNull();
                         } else {
                             throw new QueryParsingException(parseContext, "[regexp] query does not support [" + currentFieldName + "]");
                         }
                     }
                 }
             } else {
-                if ("_name".equals(currentFieldName)) {
+                if (parseContext.parseFieldMatcher().match(currentFieldName, NAME_FIELD)) {
                     queryName = parser.text();
                 } else {
                     fieldName = currentFieldName;
@@ -87,14 +99,25 @@ public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
         if (value == null) {
             throw new QueryParsingException(parseContext, "No value specified for prefix query");
         }
-        return new PrefixQueryBuilder(fieldName, value)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    @Override
-    public PrefixQueryBuilder getBuilderPrototype() {
-        return PrefixQueryBuilder.PROTOTYPE;
+        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), rewriteMethod, null);
+
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.prefixQuery(value, method, parseContext);
+        }
+        if (query == null) {
+            PrefixQuery prefixQuery = new PrefixQuery(new Term(fieldName, BytesRefs.toBytesRef(value)));
+            if (method != null) {
+                prefixQuery.setRewriteMethod(method);
+            }
+            query = prefixQuery;
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return  query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java
index 3f69375..fa11d32 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java
@@ -19,79 +19,25 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.client.Requests;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.NamedWriteable;
-import org.elasticsearch.common.xcontent.ToXContent;
+import org.elasticsearch.action.support.ToXContentToBytes;
+import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentType;
 
 import java.io.IOException;
 
-public interface QueryBuilder<QB extends QueryBuilder> extends NamedWriteable<QB>, ToXContent {
+public abstract class QueryBuilder extends ToXContentToBytes {
 
-    /**
-     * Validate the query.
-     * @return a {@link QueryValidationException} containing error messages, {@code null} if query is valid.
-     * e.g. if fields that are needed to create the lucene query are missing.
-     */
-    QueryValidationException validate();
+    protected QueryBuilder() {
+        super(XContentType.JSON);
+    }
 
-    /**
-     * Converts this QueryBuilder to a lucene {@link Query}.
-     * Returns <tt>null</tt> if this query should be ignored in the context of
-     * parent queries.
-     *
-     * @param context additional information needed to construct the queries
-     * @return the {@link Query} or <tt>null</tt> if this query should be ignored upstream
-     * @throws QueryShardException
-     * @throws IOException
-     */
-    Query toQuery(QueryShardContext context) throws IOException;
+    @Override
+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject();
+        doXContent(builder, params);
+        builder.endObject();
+        return builder;
+    }
 
-    /**
-     * Converts this QueryBuilder to an unscored lucene {@link Query} that acts as a filter.
-     * Returns <tt>null</tt> if this query should be ignored in the context of
-     * parent queries.
-     *
-     * @param context additional information needed to construct the queries
-     * @return the {@link Query} or <tt>null</tt> if this query should be ignored upstream
-     * @throws QueryShardException
-     * @throws IOException
-     */
-    Query toFilter(QueryShardContext context) throws IOException;
-
-    /**
-     * Returns a {@link org.elasticsearch.common.bytes.BytesReference}
-     * containing the {@link ToXContent} output in binary format.
-     * Builds the request based on the default {@link XContentType}, either {@link Requests#CONTENT_TYPE} or provided as a constructor argument
-     */
-    //norelease once we move to serializing queries over the wire in Streamable format, this method shouldn't be needed anymore
-    BytesReference buildAsBytes();
-
-    /**
-     * Sets the arbitrary name to be assigned to the query (see named queries).
-     */
-    QB queryName(String queryName);
-
-    /**
-     * Returns the arbitrary name assigned to the query (see named queries).
-     */
-    String queryName();
-
-    /**
-     * Returns the boost for this query.
-     */
-    float boost();
-
-    /**
-     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
-     * weightings) have their score multiplied by the boost provided.
-     */
-    QB boost(float boost);
-
-    /**
-     * Returns the name that identifies uniquely the query
-     */
-    String getName();
+    protected abstract void doXContent(XContentBuilder builder, Params params) throws IOException;
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java b/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
index 9b6ac01..fe2852d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
@@ -40,7 +40,7 @@ import java.util.Map;
 public abstract class QueryBuilders {
 
     /**
-     * A query that matches on all documents.
+     * A query that match on all documents.
      */
     public static MatchAllQueryBuilder matchAllQuery() {
         return new MatchAllQueryBuilder();
@@ -59,11 +59,11 @@ public abstract class QueryBuilders {
     /**
      * Creates a common query for the provided field name and text.
      *
-     * @param fieldName The field name.
+     * @param name The field name.
      * @param text The query text (to be analyzed).
      */
-    public static CommonTermsQueryBuilder commonTermsQuery(String fieldName, Object text) {
-        return new CommonTermsQueryBuilder(fieldName, text);
+    public static CommonTermsQueryBuilder commonTermsQuery(String name, Object text) {
+        return new CommonTermsQueryBuilder(name, text);
     }
 
     /**
@@ -277,8 +277,8 @@ public abstract class QueryBuilders {
      * Unlike the "NOT" clause, this still selects documents that contain undesirable terms,
      * but reduces their overall score:
      */
-    public static BoostingQueryBuilder boostingQuery(QueryBuilder positiveQuery, QueryBuilder negativeQuery) {
-        return new BoostingQueryBuilder(positiveQuery, negativeQuery);
+    public static BoostingQueryBuilder boostingQuery() {
+        return new BoostingQueryBuilder();
     }
 
     /**
@@ -312,33 +312,26 @@ public abstract class QueryBuilders {
         return new SpanFirstQueryBuilder(match, end);
     }
 
-    public static SpanNearQueryBuilder spanNearQuery(int slop) {
-        return new SpanNearQueryBuilder(slop);
+    public static SpanNearQueryBuilder spanNearQuery() {
+        return new SpanNearQueryBuilder();
     }
 
-    public static SpanNotQueryBuilder spanNotQuery(SpanQueryBuilder include, SpanQueryBuilder exclude) {
-        return new SpanNotQueryBuilder(include, exclude);
+    public static SpanNotQueryBuilder spanNotQuery() {
+        return new SpanNotQueryBuilder();
     }
 
     public static SpanOrQueryBuilder spanOrQuery() {
         return new SpanOrQueryBuilder();
     }
 
-    /** Creates a new {@code span_within} builder.
-    * @param big the big clause, it must enclose {@code little} for a match.
-    * @param little the little clause, it must be contained within {@code big} for a match.
-    */
-    public static SpanWithinQueryBuilder spanWithinQuery(SpanQueryBuilder big, SpanQueryBuilder little) {
-        return new SpanWithinQueryBuilder(big, little);
+    /** Creates a new {@code span_within} builder. */
+    public static SpanWithinQueryBuilder spanWithinQuery() {
+        return new SpanWithinQueryBuilder();
     }
 
-    /**
-     * Creates a new {@code span_containing} builder.
-     * @param big the big clause, it must enclose {@code little} for a match.
-     * @param little the little clause, it must be contained within {@code big} for a match.
-     */
-    public static SpanContainingQueryBuilder spanContainingQuery(SpanQueryBuilder big, SpanQueryBuilder little) {
-        return new SpanContainingQueryBuilder(big, little);
+    /** Creates a new {@code span_containing} builder. */
+    public static SpanContainingQueryBuilder spanContainingQuery() {
+        return new SpanContainingQueryBuilder();
     }
 
     /**
@@ -556,8 +549,8 @@ public abstract class QueryBuilders {
     /**
      * A Query builder which allows building a query thanks to a JSON string or binary data.
      */
-    public static WrapperQueryBuilder wrapperQuery(byte[] source) {
-        return new WrapperQueryBuilder(source);
+    public static WrapperQueryBuilder wrapperQuery(byte[] source, int offset, int length) {
+        return new WrapperQueryBuilder(source, offset, length);
     }
 
     /**
@@ -600,10 +593,11 @@ public abstract class QueryBuilders {
     }
 
     /**
-     * A terms query that can extract the terms from another doc in an index.
+     * A terms lookup filter for the provided field name. A lookup terms filter can
+     * extract the terms to filter by from another doc in an index.
      */
-    public static TermsQueryBuilder termsLookupQuery(String name) {
-        return new TermsQueryBuilder(name);
+    public static TermsLookupQueryBuilder termsLookupQuery(String name) {
+        return new TermsLookupQueryBuilder(name);
     }
 
     /**
@@ -690,7 +684,7 @@ public abstract class QueryBuilders {
     public static GeohashCellQuery.Builder geoHashCellQuery(String name, String geohash, boolean neighbors) {
         return new GeohashCellQuery.Builder(name, geohash, neighbors);
     }
-
+    
     /**
      * A filter to filter based on a polygon defined by a set of locations  / points.
      *
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java
index 6dc2d39..936e466 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java
@@ -19,14 +19,9 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A filter that simply wraps a query.
@@ -34,13 +29,11 @@ import java.util.Objects;
  *             query as a filter directly.
  */
 @Deprecated
-public class QueryFilterBuilder extends AbstractQueryBuilder<QueryFilterBuilder> {
-
-    public static final String NAME = "query";
+public class QueryFilterBuilder extends QueryBuilder {
 
     private final QueryBuilder queryBuilder;
 
-    static final QueryFilterBuilder PROTOTYPE = new QueryFilterBuilder(null);
+    private String queryName;
 
     /**
      * A filter that simply wraps a query.
@@ -52,56 +45,26 @@ public class QueryFilterBuilder extends AbstractQueryBuilder<QueryFilterBuilder>
     }
 
     /**
-     * @return the query builder that is wrapped by this {@link QueryFilterBuilder}
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public QueryBuilder innerQuery() {
-        return this.queryBuilder;
+    public QueryFilterBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.field(NAME);
-        queryBuilder.toXContent(builder, params);
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // inner query builder can potentially be `null`, in that case we ignore it
-        Query innerQuery = this.queryBuilder.toQuery(context);
-        if (innerQuery == null) {
-            return null;
+        if (queryName == null) {
+            builder.field(QueryFilterParser.NAME);
+            queryBuilder.toXContent(builder, params);
+        } else {
+            builder.startObject(FQueryFilterParser.NAME);
+            builder.field("query");
+            queryBuilder.toXContent(builder, params);
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
         }
-        return new ConstantScoreQuery(innerQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQuery(queryBuilder, null);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queryBuilder);
-    }
-
-    @Override
-    protected boolean doEquals(QueryFilterBuilder other) {
-        return Objects.equals(queryBuilder, other.queryBuilder);
-    }
-
-    @Override
-    protected QueryFilterBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder innerQueryBuilder = in.readQuery();
-        return new QueryFilterBuilder(innerQueryBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(queryBuilder);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java b/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java
index 03513ab..fdb9cb3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java
@@ -19,16 +19,16 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 
 import java.io.IOException;
 
-/**
- * Parser for query filter
- * @deprecated use any query instead directly, possible since queries and filters are merged.
- */
 @Deprecated
-public class QueryFilterParser extends BaseQueryParser<QueryFilterBuilder> {
+public class QueryFilterParser implements QueryParser {
+
+    public static final String NAME = "query";
 
     @Inject
     public QueryFilterParser() {
@@ -36,16 +36,11 @@ public class QueryFilterParser extends BaseQueryParser<QueryFilterBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{QueryFilterBuilder.NAME};
-    }
-
-    @Override
-    public QueryFilterBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-        return new QueryFilterBuilder(parseContext.parseInnerQueryBuilder());
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryFilterBuilder getBuilderPrototype() {
-        return QueryFilterBuilder.PROTOTYPE;
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
+        return new ConstantScoreQuery(parseContext.parseInnerQuery());
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java b/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java
index 73b9055..4b12200 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java
@@ -19,117 +19,207 @@
 
 package org.elasticsearch.index.query;
 
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.Maps;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.queryparser.classic.MapperQueryParser;
+import org.apache.lucene.queryparser.classic.QueryParserSettings;
+import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.search.join.BitDocIdSetFilter;
+import org.apache.lucene.search.similarities.Similarity;
+import org.elasticsearch.Version;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.ParseFieldMatcher;
+import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.Index;
-import org.elasticsearch.indices.query.IndicesQueriesRegistry;
+import org.elasticsearch.index.analysis.AnalysisService;
+import org.elasticsearch.index.fielddata.IndexFieldData;
+import org.elasticsearch.index.mapper.*;
+import org.elasticsearch.index.mapper.core.StringFieldMapper;
+import org.elasticsearch.index.mapper.object.ObjectMapper;
+import org.elasticsearch.index.query.support.NestedScope;
+import org.elasticsearch.index.similarity.SimilarityService;
+import org.elasticsearch.script.ScriptService;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
+import org.elasticsearch.search.internal.SearchContext;
+import org.elasticsearch.search.lookup.SearchLookup;
 
 import java.io.IOException;
+import java.util.*;
 
 public class QueryParseContext {
 
     private static final ParseField CACHE = new ParseField("_cache").withAllDeprecated("Elasticsearch makes its own caching decisions");
     private static final ParseField CACHE_KEY = new ParseField("_cache_key").withAllDeprecated("Filters are always used as cache keys");
 
-    private XContentParser parser;
+    private static ThreadLocal<String[]> typesContext = new ThreadLocal<>();
+
+    public static void setTypes(String[] types) {
+        typesContext.set(types);
+    }
+
+    public static String[] getTypes() {
+        return typesContext.get();
+    }
+
+    public static String[] setTypesWithPrevious(String[] types) {
+        String[] old = typesContext.get();
+        setTypes(types);
+        return old;
+    }
+
+    public static void removeTypes() {
+        typesContext.remove();
+    }
+
     private final Index index;
-    //norelease this flag is also used in the QueryShardContext, we need to make sure we set it there correctly in doToQuery()
+
+    private final Version indexVersionCreated;
+
+    private final IndexQueryParserService indexQueryParser;
+
+    private final Map<String, Query> namedQueries = Maps.newHashMap();
+
+    private final MapperQueryParser queryParser = new MapperQueryParser(this);
+
+    private XContentParser parser;
+
     private ParseFieldMatcher parseFieldMatcher;
 
-    //norelease this can eventually be deleted when context() method goes away
-    private final QueryShardContext shardContext;
-    private IndicesQueriesRegistry indicesQueriesRegistry;
+    private boolean allowUnmappedFields;
+
+    private boolean mapUnmappedFieldAsString;
 
-    public QueryParseContext(Index index, IndicesQueriesRegistry registry) {
+    private NestedScope nestedScope;
+
+    private boolean isFilter;
+
+    public QueryParseContext(Index index, IndexQueryParserService indexQueryParser) {
         this.index = index;
-        this.indicesQueriesRegistry = registry;
-        this.shardContext = null;
+        this.indexVersionCreated = Version.indexCreated(indexQueryParser.indexSettings());
+        this.indexQueryParser = indexQueryParser;
+    }
+
+    public void parseFieldMatcher(ParseFieldMatcher parseFieldMatcher) {
+        this.parseFieldMatcher = parseFieldMatcher;
     }
 
-    QueryParseContext(QueryShardContext context) {
-        this.shardContext = context;
-        this.index = context.index();
-        this.indicesQueriesRegistry = context.indexQueryParserService().indicesQueriesRegistry();
+    public ParseFieldMatcher parseFieldMatcher() {
+        return parseFieldMatcher;
     }
 
     public void reset(XContentParser jp) {
+        allowUnmappedFields = indexQueryParser.defaultAllowUnmappedFields();
         this.parseFieldMatcher = ParseFieldMatcher.EMPTY;
+        this.lookup = null;
         this.parser = jp;
+        this.namedQueries.clear();
+        this.nestedScope = new NestedScope();
+        this.isFilter = false;
     }
 
-    //norelease this is still used in BaseQueryParserTemp and FunctionScoreQueryParser, remove if not needed there anymore
-    @Deprecated
-    public QueryShardContext shardContext() {
-        return this.shardContext;
+    public Index index() {
+        return this.index;
+    }
+
+    public void parser(XContentParser parser) {
+        this.parser = parser;
     }
 
     public XContentParser parser() {
-        return this.parser;
+        return parser;
+    }
+    
+    public IndexQueryParserService indexQueryParserService() {
+        return indexQueryParser;
     }
 
-    public void parseFieldMatcher(ParseFieldMatcher parseFieldMatcher) {
-        this.parseFieldMatcher = parseFieldMatcher;
+    public AnalysisService analysisService() {
+        return indexQueryParser.analysisService;
     }
 
-    public boolean isDeprecatedSetting(String setting) {
-        return parseFieldMatcher.match(setting, CACHE) || parseFieldMatcher.match(setting, CACHE_KEY);
+    public ScriptService scriptService() {
+        return indexQueryParser.scriptService;
     }
 
-    public Index index() {
-        return this.index;
+    public MapperService mapperService() {
+        return indexQueryParser.mapperService;
     }
 
-    /**
-     * @deprecated replaced by calls to parseInnerFilterToQueryBuilder(String queryName) for the resulting queries
-     */
     @Nullable
-    @Deprecated
-    //norelease should be possible to remove after refactoring all queries
-    public Query parseInnerFilter(String queryName) throws IOException, QueryShardException {
-        assert this.shardContext != null;
-        QueryBuilder builder = parseInnerFilterToQueryBuilder(queryName);
-        return (builder != null) ? builder.toQuery(this.shardContext) : null;
+    public SimilarityService similarityService() {
+        return indexQueryParser.similarityService;
     }
 
-    /**
-     * @deprecated replaced by calls to parseInnerFilterToQueryBuilder() for the resulting queries
-     */
-    @Nullable
-    @Deprecated
-    //norelease should be possible to remove after refactoring all queries
-    public Query parseInnerFilter() throws QueryShardException, IOException {
-        assert this.shardContext != null;
-        QueryBuilder builder = parseInnerFilterToQueryBuilder();
-        Query result = null;
-        if (builder != null) {
-            result = builder.toQuery(this.shardContext);
+    public Similarity searchSimilarity() {
+        return indexQueryParser.similarityService != null ? indexQueryParser.similarityService.similarity() : null;
+    }
+
+    public String defaultField() {
+        return indexQueryParser.defaultField();
+    }
+
+    public boolean queryStringLenient() {
+        return indexQueryParser.queryStringLenient();
+    }
+
+    public MapperQueryParser queryParser(QueryParserSettings settings) {
+        queryParser.reset(settings);
+        return queryParser;
+    }
+
+    public BitDocIdSetFilter bitsetFilter(Filter filter) {
+        return indexQueryParser.bitsetFilterCache.getBitDocIdSetFilter(filter);
+    }
+
+    public <IFD extends IndexFieldData<?>> IFD getForField(MappedFieldType mapper) {
+        return indexQueryParser.fieldDataService.getForField(mapper);
+    }
+
+    public void addNamedQuery(String name, Query query) {
+        if (query != null) {
+            namedQueries.put(name, query);
         }
-        return result;
+    }
+
+    public ImmutableMap<String, Query> copyNamedQueries() {
+        return ImmutableMap.copyOf(namedQueries);
+    }
+
+    public void combineNamedQueries(QueryParseContext context) {
+        namedQueries.putAll(context.namedQueries);
     }
 
     /**
-     * @deprecated replaced by calls to parseInnerQueryBuilder() for the resulting queries
+     * Return whether we are currently parsing a filter or a query.
      */
-    @Nullable
-    @Deprecated
-    //norelease should be possible to remove after refactoring all queries
-    public Query parseInnerQuery() throws IOException, QueryShardException {
-        QueryBuilder builder = parseInnerQueryBuilder();
-        Query result = null;
-        if (builder != null) {
-            result = builder.toQuery(this.shardContext);
+    public boolean isFilter() {
+        return isFilter;
+    }
+
+    public void addInnerHits(String name, InnerHitsContext.BaseInnerHits context) {
+        SearchContext sc = SearchContext.current();
+        if (sc == null) {
+            throw new QueryParsingException(this, "inner_hits unsupported");
         }
-        return result;
+
+        InnerHitsContext innerHitsContext;
+        if (sc.innerHits() == null) {
+            innerHitsContext = new InnerHitsContext(new HashMap<String, InnerHitsContext.BaseInnerHits>());
+            sc.innerHits(innerHitsContext);
+        } else {
+            innerHitsContext = sc.innerHits();
+        }
+        innerHitsContext.addInnerHitDefinition(name, context);
     }
 
-    /**
-     * @return a new QueryBuilder based on the current state of the parser
-     * @throws IOException
-     */
-    public QueryBuilder parseInnerQueryBuilder() throws IOException {
+    @Nullable
+    public Query parseInnerQuery() throws QueryParsingException, IOException {
         // move to START object
         XContentParser.Token token;
         if (parser.currentToken() != XContentParser.Token.START_OBJECT) {
@@ -141,7 +231,7 @@ public class QueryParseContext {
         token = parser.nextToken();
         if (token == XContentParser.Token.END_OBJECT) {
             // empty query
-            return EmptyQueryBuilder.PROTOTYPE;
+            return null;
         }
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new QueryParsingException(this, "[_na] query malformed, no field after start_object");
@@ -153,11 +243,11 @@ public class QueryParseContext {
             throw new QueryParsingException(this, "[_na] query malformed, no field after start_object");
         }
 
-        QueryParser queryParser = queryParser(queryName);
+        QueryParser queryParser = indexQueryParser.queryParser(queryName);
         if (queryParser == null) {
             throw new QueryParsingException(this, "No query registered for [" + queryName + "]");
         }
-        QueryBuilder result = queryParser.fromXContent(this);
+        Query result = queryParser.parse(this);
         if (parser.currentToken() == XContentParser.Token.END_OBJECT || parser.currentToken() == XContentParser.Token.END_ARRAY) {
             // if we are at END_OBJECT, move to the next one...
             parser.nextToken();
@@ -165,47 +255,138 @@ public class QueryParseContext {
         return result;
     }
 
-    /**
-     * @return a new QueryBuilder based on the current state of the parser, but does so that the inner query
-     * is parsed to a filter
-     * @throws IOException
-     */
     @Nullable
-    //norelease setting and checking the isFilter Flag should completely be moved to toQuery/toFilter after query refactoring
-    public QueryBuilder parseInnerFilterToQueryBuilder() throws IOException {
-        final boolean originalIsFilter = this.shardContext.isFilter;
+    public Query parseInnerFilter() throws QueryParsingException, IOException {
+        final boolean originalIsFilter = isFilter;
         try {
-            this.shardContext.isFilter = true;
-            return parseInnerQueryBuilder();
+            isFilter = true;
+            return parseInnerQuery();
         } finally {
-            this.shardContext.isFilter = originalIsFilter;
+            isFilter = originalIsFilter;
         }
     }
 
-    //norelease setting and checking the isFilter Flag should completely be moved to toQuery/toFilter after query refactoring
-    QueryBuilder parseInnerFilterToQueryBuilder(String queryName) throws IOException, QueryParsingException {
-        final boolean originalIsFilter = this.shardContext.isFilter;
+    public Query parseInnerFilter(String queryName) throws IOException, QueryParsingException {
+        final boolean originalIsFilter = isFilter;
         try {
-            this.shardContext.isFilter = true;
-            QueryParser queryParser = queryParser(queryName);
+            isFilter = true;
+            QueryParser queryParser = indexQueryParser.queryParser(queryName);
             if (queryParser == null) {
                 throw new QueryParsingException(this, "No query registered for [" + queryName + "]");
             }
-            return queryParser.fromXContent(this);
+            return queryParser.parse(this);
         } finally {
-            this.shardContext.isFilter = originalIsFilter;
+            isFilter = originalIsFilter;
         }
     }
 
-    public ParseFieldMatcher parseFieldMatcher() {
-        return parseFieldMatcher;
+    public Collection<String> simpleMatchToIndexNames(String pattern) {
+        return indexQueryParser.mapperService.simpleMatchToIndexNames(pattern, getTypes());
+    }
+
+    public MappedFieldType fieldMapper(String name) {
+        return failIfFieldMappingNotFound(name, indexQueryParser.mapperService.smartNameFieldType(name, getTypes()));
+    }
+
+    public ObjectMapper getObjectMapper(String name) {
+        return indexQueryParser.mapperService.getObjectMapper(name, getTypes());
+    }
+
+    /** Gets the search analyzer for the given field, or the default if there is none present for the field
+     * TODO: remove this by moving defaults into mappers themselves
+     */
+    public Analyzer getSearchAnalyzer(MappedFieldType fieldType) {
+        if (fieldType.searchAnalyzer() != null) {
+            return fieldType.searchAnalyzer();
+        }
+        return mapperService().searchAnalyzer();
     }
 
-    public void parser(XContentParser innerParser) {
-        this.parser = innerParser;
+    /** Gets the search quote nalyzer for the given field, or the default if there is none present for the field
+     * TODO: remove this by moving defaults into mappers themselves
+     */
+    public Analyzer getSearchQuoteAnalyzer(MappedFieldType fieldType) {
+        if (fieldType.searchQuoteAnalyzer() != null) {
+            return fieldType.searchQuoteAnalyzer();
+        }
+        return mapperService().searchQuoteAnalyzer();
     }
 
-    QueryParser queryParser(String name) {
-        return indicesQueriesRegistry.queryParsers().get(name);
+    public void setAllowUnmappedFields(boolean allowUnmappedFields) {
+        this.allowUnmappedFields = allowUnmappedFields;
     }
+
+    public void setMapUnmappedFieldAsString(boolean mapUnmappedFieldAsString) {
+        this.mapUnmappedFieldAsString = mapUnmappedFieldAsString;
+    }
+
+    private MappedFieldType failIfFieldMappingNotFound(String name, MappedFieldType fieldMapping) {
+        if (allowUnmappedFields) {
+            return fieldMapping;
+        } else if (mapUnmappedFieldAsString){
+            StringFieldMapper.Builder builder = MapperBuilders.stringField(name);
+            // it would be better to pass the real index settings, but they are not easily accessible from here...
+            Settings settings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, indexQueryParser.getIndexCreatedVersion()).build();
+            return builder.build(new Mapper.BuilderContext(settings, new ContentPath(1))).fieldType();
+        } else {
+            Version indexCreatedVersion = indexQueryParser.getIndexCreatedVersion();
+            if (fieldMapping == null && indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta1)) {
+                throw new QueryParsingException(this, "Strict field resolution and no field mapping can be found for the field with name ["
+                        + name + "]");
+            } else {
+                return fieldMapping;
+            }
+        }
+    }
+
+    /**
+     * Returns the narrowed down explicit types, or, if not set, all types.
+     */
+    public Collection<String> queryTypes() {
+        String[] types = getTypes();
+        if (types == null || types.length == 0) {
+            return mapperService().types();
+        }
+        if (types.length == 1 && types[0].equals("_all")) {
+            return mapperService().types();
+        }
+        return Arrays.asList(types);
+    }
+
+    private SearchLookup lookup = null;
+
+    public SearchLookup lookup() {
+        SearchContext current = SearchContext.current();
+        if (current != null) {
+            return current.lookup();
+        }
+        if (lookup == null) {
+            lookup = new SearchLookup(mapperService(), indexQueryParser.fieldDataService, null);
+        }
+        return lookup;
+    }
+
+    public long nowInMillis() {
+        SearchContext current = SearchContext.current();
+        if (current != null) {
+            return current.nowInMillis();
+        }
+        return System.currentTimeMillis();
+    }
+
+    public NestedScope nestedScope() {
+        return nestedScope;
+    }
+
+    /**
+     * Return whether the setting is deprecated.
+     */
+    public boolean isDeprecatedSetting(String setting) {
+        return parseFieldMatcher.match(setting, CACHE) || parseFieldMatcher.match(setting, CACHE_KEY);
+    }
+
+    public Version indexVersionCreated() {
+        return indexVersionCreated;
+    }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParser.java b/core/src/main/java/org/elasticsearch/index/query/QueryParser.java
index d54971b..eff585a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParser.java
@@ -25,10 +25,9 @@ import org.elasticsearch.common.Nullable;
 import java.io.IOException;
 
 /**
- * Defines a query parser that is able to read and parse a query object in {@link org.elasticsearch.common.xcontent.XContent}
- * format and create an internal object representing the query, implementing {@link QueryBuilder}, which can be streamed to other nodes.
+ *
  */
-public interface QueryParser<QB extends QueryBuilder<QB>> {
+public interface QueryParser {
 
     /**
      * The names this query parser is registered under.
@@ -36,33 +35,11 @@ public interface QueryParser<QB extends QueryBuilder<QB>> {
     String[] names();
 
     /**
-     * Parses the into a query from the current parser location. Will be at
-     * "START_OBJECT" location, and should end when the token is at the matching
-     * "END_OBJECT".
+     * Parses the into a query from the current parser location. Will be at "START_OBJECT" location,
+     * and should end when the token is at the matching "END_OBJECT".
      * <p/>
-     * Returns <tt>null</tt> if this query should be ignored in the context of
-     * the DSL.
+     * Returns <tt>null</tt> if this query should be ignored in the context of the DSL.
      */
-    //norelease can be removed in favour of fromXContent once search requests can be parsed on the coordinating node
     @Nullable
-    Query parse(QueryShardContext context) throws IOException, QueryParsingException;
-
-    /**
-     * Creates a new {@link QueryBuilder} from the query held by the {@link QueryShardContext}
-     * in {@link org.elasticsearch.common.xcontent.XContent} format
-     *
-     * @param parseContext
-     *            the input parse context. The state on the parser contained in
-     *            this context will be changed as a side effect of this method
-     *            call
-     * @return the new QueryBuilder
-     * @throws IOException
-     * @throws QueryParsingException
-     */
-    QB fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException;
-
-    /**
-     * @return an empty {@link QueryBuilder} instance for this parser that can be used for deserialization
-     */
-    QB getBuilderPrototype();
+    Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException;
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java b/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java
index 80acae7..c606953 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java
@@ -31,8 +31,7 @@ import org.elasticsearch.rest.RestStatus;
 import java.io.IOException;
 
 /**
- * Exception that can be used when parsing queries with a given {@link QueryParseContext}.
- * Can contain information about location of the error.
+ *
  */
 public class QueryParsingException extends ElasticsearchException {
 
@@ -72,15 +71,9 @@ public class QueryParsingException extends ElasticsearchException {
         this.columnNumber = col;
     }
 
-    public QueryParsingException(StreamInput in) throws IOException{
-        super(in);
-        lineNumber = in.readInt();
-        columnNumber = in.readInt();
-    }
-
     /**
      * Line number of the location of the error
-     *
+     * 
      * @return the line number or -1 if unknown
      */
     public int getLineNumber() {
@@ -89,7 +82,7 @@ public class QueryParsingException extends ElasticsearchException {
 
     /**
      * Column number of the location of the error
-     *
+     * 
      * @return the column number or -1 if unknown
      */
     public int getColumnNumber() {
@@ -116,4 +109,11 @@ public class QueryParsingException extends ElasticsearchException {
         out.writeInt(lineNumber);
         out.writeInt(columnNumber);
     }
+
+    public QueryParsingException(StreamInput in) throws IOException{
+        super(in);
+        lineNumber = in.readInt();
+        columnNumber = in.readInt();
+    }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java b/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
deleted file mode 100644
index 9e4fb13..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
+++ /dev/null
@@ -1,330 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Maps;
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.queryparser.classic.MapperQueryParser;
-import org.apache.lucene.queryparser.classic.QueryParserSettings;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.join.BitDocIdSetFilter;
-import org.apache.lucene.search.similarities.Similarity;
-import org.elasticsearch.Version;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.index.analysis.AnalysisService;
-import org.elasticsearch.index.fielddata.IndexFieldData;
-import org.elasticsearch.index.mapper.*;
-import org.elasticsearch.index.mapper.core.StringFieldMapper;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
-import org.elasticsearch.index.query.support.NestedScope;
-import org.elasticsearch.index.similarity.SimilarityService;
-import org.elasticsearch.script.ScriptService;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.lookup.SearchLookup;
-
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Map;
-
-/**
- * Context object used to create lucene queries on the shard level.
- */
-public class QueryShardContext {
-
-    private static ThreadLocal<String[]> typesContext = new ThreadLocal<>();
-
-    public static void setTypes(String[] types) {
-        typesContext.set(types);
-    }
-
-    public static String[] getTypes() {
-        return typesContext.get();
-    }
-
-    public static String[] setTypesWithPrevious(String[] types) {
-        String[] old = typesContext.get();
-        setTypes(types);
-        return old;
-    }
-
-    public static void removeTypes() {
-        typesContext.remove();
-    }
-
-    private final Index index;
-
-    private final Version indexVersionCreated;
-
-    private final IndexQueryParserService indexQueryParser;
-
-    private final Map<String, Query> namedQueries = Maps.newHashMap();
-
-    private final MapperQueryParser queryParser = new MapperQueryParser(this);
-
-    private ParseFieldMatcher parseFieldMatcher;
-
-    private boolean allowUnmappedFields;
-
-    private boolean mapUnmappedFieldAsString;
-
-    private NestedScope nestedScope;
-
-    //norelease this should be possible to remove once query context are completely separated
-    private QueryParseContext parseContext;
-
-    boolean isFilter;
-
-    public QueryShardContext(Index index, IndexQueryParserService indexQueryParser) {
-        this.index = index;
-        this.indexVersionCreated = Version.indexCreated(indexQueryParser.indexSettings());
-        this.indexQueryParser = indexQueryParser;
-        this.parseContext = new QueryParseContext(this);
-    }
-
-    public void parseFieldMatcher(ParseFieldMatcher parseFieldMatcher) {
-        this.parseFieldMatcher = parseFieldMatcher;
-    }
-
-    public ParseFieldMatcher parseFieldMatcher() {
-        return parseFieldMatcher;
-    }
-
-    private void reset() {
-        allowUnmappedFields = indexQueryParser.defaultAllowUnmappedFields();
-        this.parseFieldMatcher = ParseFieldMatcher.EMPTY;
-        this.lookup = null;
-        this.namedQueries.clear();
-        this.nestedScope = new NestedScope();
-    }
-
-    //norelease remove parser argument once query contexts are separated
-    public void reset(XContentParser jp) {
-        this.reset();
-        this.parseContext.reset(jp);
-    }
-
-    public Index index() {
-        return this.index;
-    }
-
-    public IndexQueryParserService indexQueryParserService() {
-        return indexQueryParser;
-    }
-
-    public AnalysisService analysisService() {
-        return indexQueryParser.analysisService;
-    }
-
-    public ScriptService scriptService() {
-        return indexQueryParser.scriptService;
-    }
-
-    public MapperService mapperService() {
-        return indexQueryParser.mapperService;
-    }
-
-    @Nullable
-    public SimilarityService similarityService() {
-        return indexQueryParser.similarityService;
-    }
-
-    public Similarity searchSimilarity() {
-        return indexQueryParser.similarityService != null ? indexQueryParser.similarityService.similarity() : null;
-    }
-
-    public String defaultField() {
-        return indexQueryParser.defaultField();
-    }
-
-    public boolean queryStringLenient() {
-        return indexQueryParser.queryStringLenient();
-    }
-
-    public MapperQueryParser queryParser(QueryParserSettings settings) {
-        queryParser.reset(settings);
-        return queryParser;
-    }
-
-    public BitDocIdSetFilter bitsetFilter(Filter filter) {
-        return indexQueryParser.bitsetFilterCache.getBitDocIdSetFilter(filter);
-    }
-
-    public <IFD extends IndexFieldData<?>> IFD getForField(MappedFieldType mapper) {
-        return indexQueryParser.fieldDataService.getForField(mapper);
-    }
-
-    public void addNamedQuery(String name, Query query) {
-        if (query != null) {
-            namedQueries.put(name, query);
-        }
-    }
-
-    public ImmutableMap<String, Query> copyNamedQueries() {
-        return ImmutableMap.copyOf(namedQueries);
-    }
-
-    public void combineNamedQueries(QueryShardContext context) {
-        namedQueries.putAll(context.namedQueries);
-    }
-
-    /**
-     * Return whether we are currently parsing a filter or a query.
-     */
-    public boolean isFilter() {
-        return isFilter;
-    }
-
-    public void addInnerHits(String name, InnerHitsContext.BaseInnerHits context) {
-        SearchContext sc = SearchContext.current();
-        if (sc == null) {
-            throw new QueryShardException(this, "inner_hits unsupported");
-        }
-
-        InnerHitsContext innerHitsContext;
-        if (sc.innerHits() == null) {
-            innerHitsContext = new InnerHitsContext(new HashMap<String, InnerHitsContext.BaseInnerHits>());
-            sc.innerHits(innerHitsContext);
-        } else {
-            innerHitsContext = sc.innerHits();
-        }
-        innerHitsContext.addInnerHitDefinition(name, context);
-    }
-
-    public Collection<String> simpleMatchToIndexNames(String pattern) {
-        return indexQueryParser.mapperService.simpleMatchToIndexNames(pattern, getTypes());
-    }
-
-    public MappedFieldType fieldMapper(String name) {
-        return failIfFieldMappingNotFound(name, indexQueryParser.mapperService.smartNameFieldType(name, getTypes()));
-    }
-
-    public ObjectMapper getObjectMapper(String name) {
-        return indexQueryParser.mapperService.getObjectMapper(name, getTypes());
-    }
-
-    /**
-     * Gets the search analyzer for the given field, or the default if there is none present for the field
-     * TODO: remove this by moving defaults into mappers themselves
-     */
-    public Analyzer getSearchAnalyzer(MappedFieldType fieldType) {
-        if (fieldType.searchAnalyzer() != null) {
-            return fieldType.searchAnalyzer();
-        }
-        return mapperService().searchAnalyzer();
-    }
-
-    /**
-     * Gets the search quote analyzer for the given field, or the default if there is none present for the field
-     * TODO: remove this by moving defaults into mappers themselves
-     */
-    public Analyzer getSearchQuoteAnalyzer(MappedFieldType fieldType) {
-        if (fieldType.searchQuoteAnalyzer() != null) {
-            return fieldType.searchQuoteAnalyzer();
-        }
-        return mapperService().searchQuoteAnalyzer();
-    }
-
-    public void setAllowUnmappedFields(boolean allowUnmappedFields) {
-        this.allowUnmappedFields = allowUnmappedFields;
-    }
-
-    public void setMapUnmappedFieldAsString(boolean mapUnmappedFieldAsString) {
-        this.mapUnmappedFieldAsString = mapUnmappedFieldAsString;
-    }
-
-    private MappedFieldType failIfFieldMappingNotFound(String name, MappedFieldType fieldMapping) {
-        if (allowUnmappedFields) {
-            return fieldMapping;
-        } else if (mapUnmappedFieldAsString) {
-            StringFieldMapper.Builder builder = MapperBuilders.stringField(name);
-            // it would be better to pass the real index settings, but they are not easily accessible from here...
-            Settings settings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, indexQueryParser.getIndexCreatedVersion()).build();
-            return builder.build(new Mapper.BuilderContext(settings, new ContentPath(1))).fieldType();
-        } else {
-            Version indexCreatedVersion = indexQueryParser.getIndexCreatedVersion();
-            if (fieldMapping == null && indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta1)) {
-                throw new QueryShardException(this, "Strict field resolution and no field mapping can be found for the field with name ["
-                        + name + "]");
-            } else {
-                return fieldMapping;
-            }
-        }
-    }
-
-    /**
-     * Returns the narrowed down explicit types, or, if not set, all types.
-     */
-    public Collection<String> queryTypes() {
-        String[] types = getTypes();
-        if (types == null || types.length == 0) {
-            return mapperService().types();
-        }
-        if (types.length == 1 && types[0].equals("_all")) {
-            return mapperService().types();
-        }
-        return Arrays.asList(types);
-    }
-
-    private SearchLookup lookup = null;
-
-    public SearchLookup lookup() {
-        SearchContext current = SearchContext.current();
-        if (current != null) {
-            return current.lookup();
-        }
-        if (lookup == null) {
-            lookup = new SearchLookup(mapperService(), indexQueryParser.fieldDataService, null);
-        }
-        return lookup;
-    }
-
-    public long nowInMillis() {
-        SearchContext current = SearchContext.current();
-        if (current != null) {
-            return current.nowInMillis();
-        }
-        return System.currentTimeMillis();
-    }
-
-    public NestedScope nestedScope() {
-        return nestedScope;
-    }
-
-    public Version indexVersionCreated() {
-        return indexVersionCreated;
-    }
-
-    public QueryParseContext parseContext() {
-        return this.parseContext;
-    }
-
-    public boolean matchesIndices(String... indices) {
-        return this.indexQueryParserService().matchesIndices(indices);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryShardException.java b/core/src/main/java/org/elasticsearch/index/query/QueryShardException.java
deleted file mode 100644
index 1e31c7c..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryShardException.java
+++ /dev/null
@@ -1,72 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.rest.RestStatus;
-
-import java.io.IOException;
-
-/**
- * Exception that is thrown when creating lucene queries on the shard
- */
-public class QueryShardException extends ElasticsearchException {
-
-    public QueryShardException(QueryShardContext context, String msg, Object... args) {
-        this(context, msg, null, args);
-    }
-
-    public QueryShardException(QueryShardContext context, String msg, Throwable cause, Object... args) {
-        super(msg, cause, args);
-        setIndex(context.index());
-    }
-
-    /**
-     * This constructor is provided for use in unit tests where a
-     * {@link QueryShardContext} may not be available
-     */
-    public QueryShardException(Index index, String msg, Throwable cause) {
-        super(msg, cause);
-        setIndex(index);
-    }
-
-    public QueryShardException(StreamInput in) throws IOException{
-        super(in);
-    }
-
-    @Override
-    public RestStatus status() {
-        return RestStatus.BAD_REQUEST;
-    }
-
-    @Override
-    protected void innerToXContent(XContentBuilder builder, Params params) throws IOException {
-        super.innerToXContent(builder, params);
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        super.writeTo(out);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java
index f90b3c7..c7a297e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java
@@ -20,16 +20,14 @@
 package org.elasticsearch.index.query;
 
 import com.carrotsearch.hppc.ObjectFloatHashMap;
-
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * A query that parses a query string and runs it. There are two modes that this operates. The first,
  * when no field is added (using {@link #field(String)}, will run the query once and non prefixed fields
@@ -38,9 +36,12 @@ import static com.google.common.collect.Lists.newArrayList;
  * them either using DisMax or a plain boolean query (see {@link #useDisMax(boolean)}).
  * <p/>
  */
-public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQueryBuilder> {
+public class QueryStringQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<QueryStringQueryBuilder> {
 
-    public static final String NAME = "query_string";
+    public enum Operator {
+        OR,
+        AND
+    }
 
     private final String queryString;
 
@@ -65,6 +66,8 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
 
     private Locale locale;
 
+    private float boost = -1;
+
     private Fuzziness fuzziness;
     private int fuzzyPrefixLength = -1;
     private int fuzzyMaxExpansions = -1;
@@ -86,14 +89,14 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
 
     private Boolean lenient;
 
-    private String timeZone;
+    private String queryName;
 
-    private Boolean escape;
+    private String timeZone;
 
     /** To limit effort spent determinizing regexp queries. */
     private Integer maxDeterminizedStates;
 
-    static final QueryStringQueryBuilder PROTOTYPE = new QueryStringQueryBuilder(null);
+    private Boolean escape;
 
     public QueryStringQueryBuilder(String queryString) {
         this.queryString = queryString;
@@ -113,7 +116,7 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
      */
     public QueryStringQueryBuilder field(String field) {
         if (fields == null) {
-            fields = newArrayList();
+            fields = new ArrayList<>();
         }
         fields.add(field);
         return this;
@@ -124,7 +127,7 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
      */
     public QueryStringQueryBuilder field(String field, float boost) {
         if (fields == null) {
-            fields = newArrayList();
+            fields = new ArrayList<>();
         }
         fields.add(field);
         if (fieldsBoosts == null) {
@@ -291,6 +294,16 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
     }
 
     /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public QueryStringQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
      * An optional field name suffix to automatically try and add to the field searched when using quoted text.
      */
     public QueryStringQueryBuilder quoteFieldSuffix(String quoteFieldSuffix) {
@@ -307,6 +320,14 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public QueryStringQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     public QueryStringQueryBuilder locale(Locale locale) {
         this.locale = locale;
         return this;
@@ -330,7 +351,7 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(QueryStringQueryParser.NAME);
         builder.field("query", queryString);
         if (defaultField != null) {
             builder.field("default_field", defaultField);
@@ -378,6 +399,9 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         if (fuzziness != null) {
             fuzziness.toXContent(builder, params);
         }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
         if (fuzzyPrefixLength != -1) {
             builder.field("fuzzy_prefix_length", fuzzyPrefixLength);
         }
@@ -405,6 +429,9 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         if (lenient != null) {
             builder.field("lenient", lenient);
         }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (locale != null) {
             builder.field("locale", locale.toString());
         }
@@ -414,12 +441,6 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         if (escape != null) {
             builder.field("escape", escape);
         }
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java
index a0e84cc..929f7c1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java
@@ -20,8 +20,6 @@
 package org.elasticsearch.index.query;
 
 import com.carrotsearch.hppc.ObjectFloatHashMap;
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.queryparser.classic.MapperQueryParser;
 import org.apache.lucene.queryparser.classic.QueryParserSettings;
 import org.apache.lucene.search.BooleanQuery;
@@ -40,6 +38,7 @@ import org.elasticsearch.index.query.support.QueryParsers;
 import org.joda.time.DateTimeZone;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Locale;
 
 import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfNeeded;
@@ -47,8 +46,9 @@ import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfN
 /**
  *
  */
-public class QueryStringQueryParser extends BaseQueryParserTemp {
+public class QueryStringQueryParser implements QueryParser {
 
+    public static final String NAME = "query_string";
     private static final ParseField FUZZINESS = Fuzziness.FIELD.withDeprecation("fuzzy_min_sim");
 
     private final boolean defaultAnalyzeWildcard;
@@ -62,18 +62,17 @@ public class QueryStringQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{QueryStringQueryBuilder.NAME, Strings.toCamelCase(QueryStringQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String queryName = null;
         QueryParserSettings qpSettings = new QueryParserSettings();
-        qpSettings.defaultField(context.defaultField());
-        qpSettings.lenient(context.queryStringLenient());
+        qpSettings.defaultField(parseContext.defaultField());
+        qpSettings.lenient(parseContext.queryStringLenient());
         qpSettings.analyzeWildcard(defaultAnalyzeWildcard);
         qpSettings.allowLeadingWildcard(defaultAllowLeadingWildcard);
         qpSettings.locale(Locale.ROOT);
@@ -102,11 +101,11 @@ public class QueryStringQueryParser extends BaseQueryParserTemp {
                             fField = parser.text();
                         }
                         if (qpSettings.fields() == null) {
-                            qpSettings.fields(Lists.<String>newArrayList());
+                            qpSettings.fields(new ArrayList<String>());
                         }
 
                         if (Regex.isSimpleMatchPattern(fField)) {
-                            for (String field : context.mapperService().simpleMatchToIndexNames(fField)) {
+                            for (String field : parseContext.mapperService().simpleMatchToIndexNames(fField)) {
                                 qpSettings.fields().add(field);
                                 if (fBoost != -1) {
                                     if (qpSettings.boosts() == null) {
@@ -144,13 +143,13 @@ public class QueryStringQueryParser extends BaseQueryParserTemp {
                         throw new QueryParsingException(parseContext, "Query default operator [" + op + "] is not allowed");
                     }
                 } else if ("analyzer".equals(currentFieldName)) {
-                    NamedAnalyzer analyzer = context.analysisService().analyzer(parser.text());
+                    NamedAnalyzer analyzer = parseContext.analysisService().analyzer(parser.text());
                     if (analyzer == null) {
                         throw new QueryParsingException(parseContext, "[query_string] analyzer [" + parser.text() + "] not found");
                     }
                     qpSettings.forcedAnalyzer(analyzer);
                 } else if ("quote_analyzer".equals(currentFieldName) || "quoteAnalyzer".equals(currentFieldName)) {
-                    NamedAnalyzer analyzer = context.analysisService().analyzer(parser.text());
+                    NamedAnalyzer analyzer = parseContext.analysisService().analyzer(parser.text());
                     if (analyzer == null) {
                         throw new QueryParsingException(parseContext, "[query_string] quote_analyzer [" + parser.text()
                                 + "] not found");
@@ -215,14 +214,14 @@ public class QueryStringQueryParser extends BaseQueryParserTemp {
         if (qpSettings.queryString() == null) {
             throw new QueryParsingException(parseContext, "query_string must be provided with a [query]");
         }
-        qpSettings.defaultAnalyzer(context.mapperService().searchAnalyzer());
-        qpSettings.defaultQuoteAnalyzer(context.mapperService().searchQuoteAnalyzer());
+        qpSettings.defaultAnalyzer(parseContext.mapperService().searchAnalyzer());
+        qpSettings.defaultQuoteAnalyzer(parseContext.mapperService().searchQuoteAnalyzer());
 
         if (qpSettings.escape()) {
             qpSettings.queryString(org.apache.lucene.queryparser.classic.QueryParser.escape(qpSettings.queryString()));
         }
 
-        MapperQueryParser queryParser = context.queryParser(qpSettings);
+        MapperQueryParser queryParser = parseContext.queryParser(qpSettings);
 
         try {
             Query query = queryParser.parse(qpSettings.queryString());
@@ -237,16 +236,11 @@ public class QueryStringQueryParser extends BaseQueryParserTemp {
                 Queries.applyMinimumShouldMatch((BooleanQuery) query, qpSettings.minimumShouldMatch());
             }
             if (queryName != null) {
-                context.addNamedQuery(queryName, query);
+                parseContext.addNamedQuery(queryName, query);
             }
             return query;
         } catch (org.apache.lucene.queryparser.classic.ParseException e) {
             throw new QueryParsingException(parseContext, "Failed to parse query [" + qpSettings.queryString() + "]", e);
         }
     }
-
-    @Override
-    public QueryStringQueryBuilder getBuilderPrototype() {
-        return QueryStringQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryValidationException.java b/core/src/main/java/org/elasticsearch/index/query/QueryValidationException.java
deleted file mode 100644
index 9e0ee2a..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryValidationException.java
+++ /dev/null
@@ -1,62 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.elasticsearch.common.ValidationException;
-
-import java.util.List;
-
-/**
- * This exception can be used to indicate various reasons why validation of a query has failed.
- */
-public class QueryValidationException extends ValidationException {
-
-    /**
-     * Helper method than can be used to add error messages to an existing {@link QueryValidationException}.
-     * When passing {@code null} as the initial exception, a new exception is created.
-     *
-     * @param queryId the query that caused the error
-     * @param validationError the error message to add to an initial exception
-     * @param validationException an initial exception. Can be {@code null}, in which case a new exception is created.
-     * @return a {@link QueryValidationException} with added validation error message
-     */
-    public static QueryValidationException addValidationError(String queryId, String validationError, QueryValidationException validationException) {
-        if (validationException == null) {
-            validationException = new QueryValidationException();
-        }
-        validationException.addValidationError("[" + queryId + "] " + validationError);
-        return validationException;
-    }
-
-    /**
-     * Helper method than can be used to add error messages to an existing {@link QueryValidationException}.
-     * When passing {@code null} as the initial exception, a new exception is created.
-     * @param validationErrors the error messages to add to an initial exception
-     * @param validationException an initial exception. Can be {@code null}, in which case a new exception is created.
-     * @return a {@link QueryValidationException} with added validation error message
-     */
-    public static QueryValidationException addValidationErrors(List<String> validationErrors, QueryValidationException validationException) {
-        if (validationException == null) {
-            validationException = new QueryValidationException();
-        }
-        validationException.addValidationErrors(validationErrors);
-        return validationException;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryWrappingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryWrappingQueryBuilder.java
deleted file mode 100644
index d3be9da..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryWrappingQueryBuilder.java
+++ /dev/null
@@ -1,59 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-
-import java.io.IOException;
-
-/**
- * QueryBuilder implementation that  holds a lucene query, which can be returned by {@link QueryBuilder#toQuery(QueryShardContext)}.
- * Doesn't support conversion to {@link org.elasticsearch.common.xcontent.XContent} via {@link #doXContent(XContentBuilder, Params)}.
- */
-//norelease to be removed once all queries support separate fromXContent and toQuery methods. Make AbstractQueryBuilder#toQuery final as well then.
-public class QueryWrappingQueryBuilder extends AbstractQueryBuilder<QueryWrappingQueryBuilder> implements SpanQueryBuilder<QueryWrappingQueryBuilder>, MultiTermQueryBuilder<QueryWrappingQueryBuilder>{
-
-    private Query query;
-
-    public QueryWrappingQueryBuilder(Query query) {
-        this.query = query;
-        //hack to make sure that the boost from the wrapped query is used, otherwise it gets overwritten.
-        if (query != null) {
-            this.boost = query.getBoost();
-        }
-    }
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return query;
-    }
-
-    @Override
-    public String getWriteableName() {
-        // this should not be called since we overwrite BaseQueryBuilder#toQuery() in this class
-        throw new UnsupportedOperationException();
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java
index 0db4152..da23698 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java
@@ -19,111 +19,187 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermRangeQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.joda.DateMathParser;
-import org.elasticsearch.common.joda.Joda;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.core.DateFieldMapper;
-import org.joda.time.DateTimeZone;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that matches documents within an range of terms.
  */
-public class RangeQueryBuilder extends AbstractQueryBuilder<RangeQueryBuilder> implements MultiTermQueryBuilder<RangeQueryBuilder> {
+public class RangeQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<RangeQueryBuilder> {
 
-    public static final boolean DEFAULT_INCLUDE_UPPER = true;
+    private final String name;
+    private Object from;
+    private Object to;
+    private String timeZone;
+    private boolean includeLower = true;
+    private boolean includeUpper = true;
+    private float boost = -1;
+    private String queryName;
+    private String format;
 
-    public static final boolean DEFAULT_INCLUDE_LOWER = true;
+    /**
+     * A Query that matches documents within an range of terms.
+     *
+     * @param name The field name
+     */
+    public RangeQueryBuilder(String name) {
+        this.name = name;
+    }
 
-    public static final String NAME = "range";
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(Object from) {
+        this.from = from;
+        return this;
+    }
 
-    private final String fieldName;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(String from) {
+        this.from = from;
+        return this;
+    }
 
-    private Object from;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(int from) {
+        this.from = from;
+        return this;
+    }
 
-    private Object to;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(long from) {
+        this.from = from;
+        return this;
+    }
 
-    private String timeZone;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(float from) {
+        this.from = from;
+        return this;
+    }
 
-    private boolean includeLower = DEFAULT_INCLUDE_LOWER;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(double from) {
+        this.from = from;
+        return this;
+    }
 
-    private boolean includeUpper = DEFAULT_INCLUDE_UPPER;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gt(String from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
+    }
 
-    private String format;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gt(Object from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
+    }
 
-    static final RangeQueryBuilder PROTOTYPE = new RangeQueryBuilder(null);
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gt(int from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
+    }
 
     /**
-     * A Query that matches documents within an range of terms.
-     *
-     * @param fieldName The field name
+     * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder(String fieldName) {
-        this.fieldName = fieldName;
+    public RangeQueryBuilder gt(long from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
     }
 
     /**
-     * Get the field name for this query.
+     * The from part of the range query. Null indicates unbounded.
      */
-    public String fieldName() {
-        return this.fieldName;
+    public RangeQueryBuilder gt(float from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
-     * In case lower bound is assigned to a string, we internally convert it to a {@link BytesRef} because
-     * in {@link RangeQueryParser} field are later parsed as {@link BytesRef} and we need internal representation
-     * of query to be equal regardless of whether it was created from XContent or via Java API.
      */
-    public RangeQueryBuilder from(Object from, boolean includeLower) {
-        this.from = convertToBytesRefIfString(from);
-        this.includeLower = includeLower;
+    public RangeQueryBuilder gt(double from) {
+        this.from = from;
+        this.includeLower = false;
         return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder from(Object from) {
-        return from(from, this.includeLower);
+    public RangeQueryBuilder gte(String from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
-     * Gets the lower range value for this query.
+     * The from part of the range query. Null indicates unbounded.
      */
-    public Object from() {
-        return convertToStringIfBytesRef(this.from);
+    public RangeQueryBuilder gte(Object from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder gt(Object from) {
-        return from(from, false);
+    public RangeQueryBuilder gte(int from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder gte(Object from) {
-        return from(from, true);
+    public RangeQueryBuilder gte(long from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
-     * The to part of the range query. Null indicates unbounded.
+     * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder to(Object to, boolean includeUpper) {
-        this.to = convertToBytesRefIfString(to);
-        this.includeUpper = includeUpper;
+    public RangeQueryBuilder gte(float from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
+    }
+
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gte(double from) {
+        this.from = from;
+        this.includeLower = true;
         return this;
     }
 
@@ -131,214 +207,229 @@ public class RangeQueryBuilder extends AbstractQueryBuilder<RangeQueryBuilder> i
      * The to part of the range query. Null indicates unbounded.
      */
     public RangeQueryBuilder to(Object to) {
-        return to(to, this.includeUpper);
+        this.to = to;
+        return this;
     }
 
     /**
-     * Gets the upper range value for this query.
-     * In case upper bound is assigned to a string, we internally convert it to a {@link BytesRef} because
-     * in {@link RangeQueryParser} field are later parsed as {@link BytesRef} and we need internal representation
-     * of query to be equal regardless of whether it was created from XContent or via Java API.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public Object to() {
-        return convertToStringIfBytesRef(this.to);
+    public RangeQueryBuilder to(String to) {
+        this.to = to;
+        return this;
     }
 
     /**
      * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder lt(Object to) {
-        return to(to, false);
+    public RangeQueryBuilder to(int to) {
+        this.to = to;
+        return this;
     }
 
     /**
      * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder lte(Object to) {
-        return to(to, true);
+    public RangeQueryBuilder to(long to) {
+        this.to = to;
+        return this;
     }
 
     /**
-     * Should the lower bound be included or not. Defaults to <tt>true</tt>.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder includeLower(boolean includeLower) {
-        this.includeLower = includeLower;
+    public RangeQueryBuilder to(float to) {
+        this.to = to;
         return this;
     }
 
     /**
-     * Gets the includeLower flag for this query.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public boolean includeLower() {
-        return this.includeLower;
+    public RangeQueryBuilder to(double to) {
+        this.to = to;
+        return this;
     }
 
     /**
-     * Should the upper bound be included or not. Defaults to <tt>true</tt>.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder includeUpper(boolean includeUpper) {
-        this.includeUpper = includeUpper;
+    public RangeQueryBuilder lt(String to) {
+        this.to = to;
+        this.includeUpper = false;
         return this;
     }
 
     /**
-     * Gets the includeUpper flag for this query.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public boolean includeUpper() {
-        return this.includeUpper;
+    public RangeQueryBuilder lt(Object to) {
+        this.to = to;
+        this.includeUpper = false;
+        return this;
     }
 
     /**
-     * In case of date field, we can adjust the from/to fields using a timezone
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder timeZone(String timezone) {
-        this.timeZone = timezone;
+    public RangeQueryBuilder lt(int to) {
+        this.to = to;
+        this.includeUpper = false;
         return this;
     }
 
     /**
-     * In case of date field, gets the from/to fields timezone adjustment
+     * The to part of the range query. Null indicates unbounded.
      */
-    public String timeZone() {
-        return this.timeZone;
+    public RangeQueryBuilder lt(long to) {
+        this.to = to;
+        this.includeUpper = false;
+        return this;
     }
 
     /**
-     * In case of format field, we can parse the from/to fields using this time format
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder format(String format) {
-        this.format = format;
+    public RangeQueryBuilder lt(float to) {
+        this.to = to;
+        this.includeUpper = false;
         return this;
     }
 
     /**
-     * Gets the format field to parse the from/to fields
+     * The to part of the range query. Null indicates unbounded.
      */
-    public String format() {
-        return this.format;
+    public RangeQueryBuilder lt(double to) {
+        this.to = to;
+        this.includeUpper = false;
+        return this;
     }
 
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("from", convertToStringIfBytesRef(this.from));
-        builder.field("to", convertToStringIfBytesRef(this.to));
-        builder.field("include_lower", includeLower);
-        builder.field("include_upper", includeUpper);
-        if (timeZone != null) {
-            builder.field("time_zone", timeZone);
-        }
-        if (format != null) {
-            builder.field("format", format);
-        }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(String to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(Object to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query query = null;
-        MappedFieldType mapper = context.fieldMapper(this.fieldName);
-        if (mapper != null) {
-            if (mapper instanceof DateFieldMapper.DateFieldType) {
-                DateMathParser forcedDateParser = null;
-                if (this.format  != null) {
-                    forcedDateParser = new DateMathParser(Joda.forPattern(this.format));
-                }
-                DateTimeZone dateTimeZone = null;
-                if (this.timeZone != null) {
-                    dateTimeZone = DateTimeZone.forID(this.timeZone);
-                }
-                query = ((DateFieldMapper.DateFieldType) mapper).rangeQuery(from, to, includeLower, includeUpper, dateTimeZone, forcedDateParser);
-            } else  {
-                if (timeZone != null) {
-                    throw new QueryShardException(context, "[range] time_zone can not be applied to non date field ["
-                            + fieldName + "]");
-                }
-                //LUCENE 4 UPGRADE Mapper#rangeQuery should use bytesref as well?
-                query = mapper.rangeQuery(from, to, includeLower, includeUpper);
-            }
-        } else {
-            if (timeZone != null) {
-                throw new QueryShardException(context, "[range] time_zone can not be applied to non unmapped field ["
-                        + fieldName + "]");
-            }
-        }
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(int to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
+    }
 
-        if (query == null) {
-            query = new TermRangeQuery(this.fieldName, BytesRefs.toBytesRef(from), BytesRefs.toBytesRef(to), includeLower, includeUpper);
-        }
-        return query;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(long to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.fieldName == null || this.fieldName.isEmpty()) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.timeZone != null) {
-            try {
-                DateTimeZone.forID(this.timeZone);
-            } catch (Exception e) {
-                validationException = addValidationError("error parsing timezone." + e.getMessage(),
-                        validationException);
-            }
-        }
-        if (this.format != null) {
-            try {
-                Joda.forPattern(this.format);
-            } catch (Exception e) {
-                validationException = addValidationError("error parsing format." + e.getMessage(),
-                        validationException);
-            }
-        }
-        return validationException;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(float to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    protected RangeQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        RangeQueryBuilder rangeQueryBuilder = new RangeQueryBuilder(in.readString());
-        rangeQueryBuilder.from = in.readGenericValue();
-        rangeQueryBuilder.to = in.readGenericValue();
-        rangeQueryBuilder.includeLower = in.readBoolean();
-        rangeQueryBuilder.includeUpper = in.readBoolean();
-        rangeQueryBuilder.timeZone = in.readOptionalString();
-        rangeQueryBuilder.format = in.readOptionalString();
-        return rangeQueryBuilder;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(double to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(this.fieldName);
-        out.writeGenericValue(this.from);
-        out.writeGenericValue(this.to);
-        out.writeBoolean(this.includeLower);
-        out.writeBoolean(this.includeUpper);
-        out.writeOptionalString(this.timeZone);
-        out.writeOptionalString(this.format);
+    /**
+     * Should the lower bound be included or not. Defaults to <tt>true</tt>.
+     */
+    public RangeQueryBuilder includeLower(boolean includeLower) {
+        this.includeLower = includeLower;
+        return this;
     }
 
+    /**
+     * Should the upper bound be included or not. Defaults to <tt>true</tt>.
+     */
+    public RangeQueryBuilder includeUpper(boolean includeUpper) {
+        this.includeUpper = includeUpper;
+        return this;
+    }
+
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, from, to, timeZone, includeLower, includeUpper, format);
+    public RangeQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public RangeQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
+    /**
+     * In case of date field, we can adjust the from/to fields using a timezone
+     */
+    public RangeQueryBuilder timeZone(String timezone) {
+        this.timeZone = timezone;
+        return this;
+    }
+
+    /**
+     * In case of date field, we can set the format to be used instead of the mapper format
+     */
+    public RangeQueryBuilder format(String format) {
+        this.format = format;
+        return this;
     }
 
     @Override
-    protected boolean doEquals(RangeQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-               Objects.equals(from, other.from) &&
-               Objects.equals(to, other.to) &&
-               Objects.equals(timeZone, other.timeZone) &&
-               Objects.equals(includeLower, other.includeLower) &&
-               Objects.equals(includeUpper, other.includeUpper) &&
-               Objects.equals(format, other.format);
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(RangeQueryParser.NAME);
+        builder.startObject(name);
+        builder.field("from", from);
+        builder.field("to", to);
+        if (timeZone != null) {
+            builder.field("time_zone", timeZone);
+        }
+        if (format != null) {
+            builder.field("format", format);
+        }
+        builder.field("include_lower", includeLower);
+        builder.field("include_upper", includeUpper);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        builder.endObject();
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java
index 5a6d85f..355f9f2 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java
@@ -19,18 +19,28 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermRangeQuery;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.joda.DateMathParser;
+import org.elasticsearch.common.joda.Joda;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.core.DateFieldMapper;
+import org.joda.time.DateTimeZone;
 
 import java.io.IOException;
 
 /**
- * Parser for range query
+ *
  */
-public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
+public class RangeQueryParser implements QueryParser {
 
+    public static final String NAME = "range";
     private static final ParseField FIELDDATA_FIELD = new ParseField("fielddata").withAllDeprecated("[no replacement]");
+    private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of range query");
 
     @Inject
     public RangeQueryParser() {
@@ -38,22 +48,22 @@ public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{RangeQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public RangeQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
         Object from = null;
         Object to = null;
-        boolean includeLower = RangeQueryBuilder.DEFAULT_INCLUDE_LOWER;
-        boolean includeUpper = RangeQueryBuilder.DEFAULT_INCLUDE_UPPER;
-        String timeZone = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        boolean includeLower = true;
+        boolean includeUpper = true;
+        DateTimeZone timeZone = null;
+        DateMathParser forcedDateParser = null;
+        float boost = 1.0f;
         String queryName = null;
-        String format = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -91,18 +101,16 @@ public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
                             to = parser.objectBytes();
                             includeUpper = true;
                         } else if ("time_zone".equals(currentFieldName) || "timeZone".equals(currentFieldName)) {
-                            timeZone = parser.text();
+                            timeZone = DateTimeZone.forID(parser.text());
                         } else if ("format".equals(currentFieldName)) {
-                            format = parser.text();
-                        } else if ("_name".equals(currentFieldName)) {
-                            queryName = parser.text();
+                            forcedDateParser = new DateMathParser(Joda.forPattern(parser.text()));
                         } else {
                             throw new QueryParsingException(parseContext, "[range] query does not support [" + currentFieldName + "]");
                         }
                     }
                 }
             } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
+                if (parseContext.parseFieldMatcher().match(currentFieldName, NAME_FIELD)) {
                     queryName = parser.text();
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, FIELDDATA_FIELD)) {
                     // ignore
@@ -112,20 +120,27 @@ public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
             }
         }
 
-        RangeQueryBuilder rangeQuery = new RangeQueryBuilder(fieldName);
-        rangeQuery.from(from);
-        rangeQuery.to(to);
-        rangeQuery.includeLower(includeLower);
-        rangeQuery.includeUpper(includeUpper);
-        rangeQuery.timeZone(timeZone);
-        rangeQuery.boost(boost);
-        rangeQuery.queryName(queryName);
-        rangeQuery.format(format);
-        return rangeQuery;
-    }
-
-    @Override
-    public RangeQueryBuilder getBuilderPrototype() {
-        return RangeQueryBuilder.PROTOTYPE;
+        Query query = null;
+        MappedFieldType mapper = parseContext.fieldMapper(fieldName);
+        if (mapper != null) {
+            if (mapper instanceof DateFieldMapper.DateFieldType) {
+                query = ((DateFieldMapper.DateFieldType) mapper).rangeQuery(from, to, includeLower, includeUpper, timeZone, forcedDateParser);
+            } else  {
+                if (timeZone != null) {
+                    throw new QueryParsingException(parseContext, "[range] time_zone can not be applied to non date field ["
+                            + fieldName + "]");
+                }
+                //LUCENE 4 UPGRADE Mapper#rangeQuery should use bytesref as well?
+                query = mapper.rangeQuery(from, to, includeLower, includeUpper);
+            }
+        }
+        if (query == null) {
+            query = new TermRangeQuery(fieldName, BytesRefs.toBytesRef(from), BytesRefs.toBytesRef(to), includeLower, includeUpper);
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java
index 6399089..ee143eb 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java
@@ -19,73 +19,48 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.RegexpQuery;
 import org.apache.lucene.util.automaton.Operations;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that does fuzzy matching for a specific value.
  */
-public class RegexpQueryBuilder extends AbstractQueryBuilder<RegexpQueryBuilder> implements MultiTermQueryBuilder<RegexpQueryBuilder> {
+public class RegexpQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<RegexpQueryBuilder> {
 
-    public static final String NAME = "regexp";
+    private final String name;
+    private final String regexp;
 
-    public static final int DEFAULT_FLAGS_VALUE = RegexpFlag.ALL.value();
-
-    public static final int DEFAULT_MAX_DETERMINIZED_STATES = Operations.DEFAULT_MAX_DETERMINIZED_STATES;
-
-    private final String fieldName;
-    
-    private final String value;
-    
-    private int flagsValue = DEFAULT_FLAGS_VALUE;
-    
-    private int maxDeterminizedStates = DEFAULT_MAX_DETERMINIZED_STATES;
-    
+    private int flags = RegexpQueryParser.DEFAULT_FLAGS_VALUE;
+    private float boost = -1;
     private String rewrite;
-    
-    static final RegexpQueryBuilder PROTOTYPE = new RegexpQueryBuilder(null, null);
+    private String queryName;
+    private int maxDeterminizedStates = Operations.DEFAULT_MAX_DETERMINIZED_STATES;
+    private boolean maxDetermizedStatesSet;
 
     /**
-     * Constructs a new regex query.
-     * 
-     * @param fieldName  The name of the field
-     * @param value The regular expression
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param regexp The regular expression
      */
-    public RegexpQueryBuilder(String fieldName, String value) {
-        this.fieldName = fieldName;
-        this.value = value;
-    }
-
-    /** Returns the field name used in this query. */
-    public String fieldName() {
-        return this.fieldName;
+    public RegexpQueryBuilder(String name, String regexp) {
+        this.name = name;
+        this.regexp = regexp;
     }
 
     /**
-     *  Returns the value used in this query.
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public String value() {
-        return this.value;
+    @Override
+    public RegexpQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     public RegexpQueryBuilder flags(RegexpFlag... flags) {
-        if (flags == null) {
-            this.flagsValue = DEFAULT_FLAGS_VALUE;
-            return this;
-        }
         int value = 0;
         if (flags.length == 0) {
             value = RegexpFlag.ALL.value;
@@ -94,120 +69,53 @@ public class RegexpQueryBuilder extends AbstractQueryBuilder<RegexpQueryBuilder>
                 value |= flag.value;
             }
         }
-        this.flagsValue = value;
-        return this;
-    }
-
-    public RegexpQueryBuilder flags(int flags) {
-        this.flagsValue = flags;
+        this.flags = value;
         return this;
     }
 
-    public int flags() {
-        return this.flagsValue;
-    }
-
     /**
      * Sets the regexp maxDeterminizedStates.
      */
     public RegexpQueryBuilder maxDeterminizedStates(int value) {
         this.maxDeterminizedStates = value;
+        this.maxDetermizedStatesSet = true;
         return this;
     }
-    
-    public int maxDeterminizedStates() {
-        return this.maxDeterminizedStates;
-    }
 
     public RegexpQueryBuilder rewrite(String rewrite) {
         this.rewrite = rewrite;
         return this;
     }
-    
-    public String rewrite() {
-        return this.rewrite;
+
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public RegexpQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("value", this.value);
-        builder.field("flags_value", flagsValue);
-        builder.field("max_determinized_states", maxDeterminizedStates);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
+        builder.startObject(RegexpQueryParser.NAME);
+        builder.startObject(name);
+        builder.field("value", regexp);
+        if (flags != -1) {
+            builder.field("flags_value", flags);
         }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public Query doToQuery(QueryShardContext context) throws QueryShardException, IOException {
-        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-
-        Query query = null;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            query = fieldType.regexpQuery(value, flagsValue, maxDeterminizedStates, method, context);
+        if (maxDetermizedStatesSet) {
+            builder.field("max_determinized_states", maxDeterminizedStates);
         }
-        if (query == null) {
-            RegexpQuery regexpQuery = new RegexpQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), flagsValue, maxDeterminizedStates);
-            if (method != null) {
-                regexpQuery.setRewriteMethod(method);
-            }
-            query = regexpQuery;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
+        if (rewrite != null) {
+            builder.field("rewrite", rewrite);
         }
-        if (this.value == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    public RegexpQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        RegexpQueryBuilder regexpQueryBuilder = new RegexpQueryBuilder(in.readString(), in.readString());
-        regexpQueryBuilder.flagsValue = in.readVInt();
-        regexpQueryBuilder.maxDeterminizedStates = in.readVInt();
-        regexpQueryBuilder.rewrite = in.readOptionalString();
-        return regexpQueryBuilder;
-    }
-
-    @Override
-    public void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeString(value);
-        out.writeVInt(flagsValue);
-        out.writeVInt(maxDeterminizedStates);
-        out.writeOptionalString(rewrite);
-    }
-
-    @Override
-    public int doHashCode() {
-        return Objects.hash(fieldName, value, flagsValue, maxDeterminizedStates, rewrite);
-    }
-
-    @Override
-    public boolean doEquals(RegexpQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(flagsValue, other.flagsValue) &&
-                Objects.equals(maxDeterminizedStates, other.maxDeterminizedStates) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java
index 066b302..5844c17 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java
@@ -19,15 +19,30 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.RegexpQuery;
+import org.apache.lucene.util.automaton.Operations;
+import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
 /**
- * Parser for regexp query
+ *
  */
-public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
+public class RegexpQueryParser implements QueryParser {
+
+    public static final String NAME = "regexp";
+
+    public static final int DEFAULT_FLAGS_VALUE = RegexpFlag.ALL.value();
+
+    private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of regexp query");
 
     @Inject
     public RegexpQueryParser() {
@@ -35,20 +50,20 @@ public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{RegexpQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public RegexpQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = parser.currentName();
-        String rewrite = null;
+        String rewriteMethod = null;
 
         String value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        int flagsValue = RegexpQueryBuilder.DEFAULT_FLAGS_VALUE;
-        int maxDeterminizedStates = RegexpQueryBuilder.DEFAULT_MAX_DETERMINIZED_STATES;
+        float boost = 1.0f;
+        int flagsValue = DEFAULT_FLAGS_VALUE;
+        int maxDeterminizedStates = Operations.DEFAULT_MAX_DETERMINIZED_STATES;
         String queryName = null;
         String currentFieldName = null;
         XContentParser.Token token;
@@ -68,7 +83,7 @@ public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
                         } else if ("boost".equals(currentFieldName)) {
                             boost = parser.floatValue();
                         } else if ("rewrite".equals(currentFieldName)) {
-                            rewrite = parser.textOrNull();
+                            rewriteMethod = parser.textOrNull();
                         } else if ("flags".equals(currentFieldName)) {
                             String flags = parser.textOrNull();
                             flagsValue = RegexpFlag.resolveValue(flags);
@@ -84,7 +99,7 @@ public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
                     }
                 }
             } else {
-                if ("_name".equals(currentFieldName)) {
+                if (parseContext.parseFieldMatcher().match(currentFieldName, NAME_FIELD)) {
                     queryName = parser.text();
                 } else {
                     fieldName = currentFieldName;
@@ -96,16 +111,27 @@ public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
         if (value == null) {
             throw new QueryParsingException(parseContext, "No value specified for regexp query");
         }
-        return new RegexpQueryBuilder(fieldName, value)
-                .flags(flagsValue)
-                .maxDeterminizedStates(maxDeterminizedStates)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    @Override
-    public RegexpQueryBuilder getBuilderPrototype() {
-        return RegexpQueryBuilder.PROTOTYPE;
+        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), rewriteMethod, null);
+
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.regexpQuery(value, flagsValue, maxDeterminizedStates, method, parseContext);
+        }
+        if (query == null) {
+            RegexpQuery regexpQuery = new RegexpQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), flagsValue, maxDeterminizedStates);
+            if (method != null) {
+                regexpQuery.setRewriteMethod(method);
+            }
+            query = regexpQuery;
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
+
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java
index 519f065..a9a35ac 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java
@@ -19,155 +19,40 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.RandomAccessWeight;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.util.Bits;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.script.*;
+import org.elasticsearch.script.Script;
 import org.elasticsearch.script.Script.ScriptField;
-import org.elasticsearch.search.lookup.SearchLookup;
 
 import java.io.IOException;
-import java.util.Objects;
+import java.util.HashMap;
+import java.util.Map;
 
-public class ScriptQueryBuilder extends AbstractQueryBuilder<ScriptQueryBuilder> {
+public class ScriptQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "script";
+    private Script script;
 
-    static final ScriptQueryBuilder PROTOTYPE = new ScriptQueryBuilder(null);
-
-    private final Script script;
+    private String queryName;
 
     public ScriptQueryBuilder(Script script) {
         this.script = script;
     }
 
-    public Script script() {
-        return this.script;
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public ScriptQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params builderParams) throws IOException {
-        builder.startObject(NAME);
-        builder.field(ScriptField.SCRIPT.getPreferredName(), script);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return new ScriptQuery(script, context.scriptService(), context.lookup());
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.script == null) {
-            validationException = addValidationError("script cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    static class ScriptQuery extends Query {
-
-        private final Script script;
-
-        private final SearchScript searchScript;
-
-        public ScriptQuery(Script script, ScriptService scriptService, SearchLookup searchLookup) {
-            this.script = script;
-            this.searchScript = scriptService.search(searchLookup, script, ScriptContext.Standard.SEARCH);
-        }
-
-        @Override
-        public String toString(String field) {
-            StringBuilder buffer = new StringBuilder();
-            buffer.append("ScriptFilter(");
-            buffer.append(script);
-            buffer.append(")");
-            return buffer.toString();
-        }
 
-        @Override
-        public boolean equals(Object obj) {
-            if (this == obj)
-                return true;
-            if (!super.equals(obj))
-                return false;
-            ScriptQuery other = (ScriptQuery) obj;
-            return Objects.equals(script, other.script);
-        }
-
-        @Override
-        public int hashCode() {
-            final int prime = 31;
-            int result = super.hashCode();
-            result = prime * result + Objects.hashCode(script);
-            return result;
-        }
-
-        @Override
-        public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-            return new RandomAccessWeight(this) {
-                @Override
-                protected Bits getMatchingDocs(final LeafReaderContext context) throws IOException {
-                    final LeafSearchScript leafScript = searchScript.getLeafSearchScript(context);
-                    return new Bits() {
-
-                        @Override
-                        public boolean get(int doc) {
-                            leafScript.setDocument(doc);
-                            Object val = leafScript.run();
-                            if (val == null) {
-                                return false;
-                            }
-                            if (val instanceof Boolean) {
-                                return (Boolean) val;
-                            }
-                            if (val instanceof Number) {
-                                return ((Number) val).longValue() != 0;
-                            }
-                            throw new IllegalArgumentException("Can't handle type [" + val + "] in script filter");
-                        }
-
-                        @Override
-                        public int length() {
-                            return context.reader().maxDoc();
-                        }
-
-                    };
-                }
-            };
+        builder.startObject(ScriptQueryParser.NAME);
+        builder.field(ScriptField.SCRIPT.getPreferredName(), script);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-    }
-
-    @Override
-    protected ScriptQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new ScriptQueryBuilder(Script.readScript(in));
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        script.writeTo(out);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(script);
-    }
-
-    @Override
-    protected boolean doEquals(ScriptQueryBuilder other) {
-        return Objects.equals(script, other.script);
+        builder.endObject();
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java
index ccbfd66..62561f3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java
@@ -19,12 +19,20 @@
 
 package org.elasticsearch.index.query;
 
+import com.google.common.base.Objects;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.RandomAccessWeight;
+import org.apache.lucene.search.Weight;
+import org.apache.lucene.util.Bits;
+import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.script.Script;
+import org.elasticsearch.script.*;
 import org.elasticsearch.script.Script.ScriptField;
-import org.elasticsearch.script.ScriptParameterParser;
 import org.elasticsearch.script.ScriptParameterParser.ScriptParameterValue;
+import org.elasticsearch.search.lookup.SearchLookup;
 
 import java.io.IOException;
 import java.util.Map;
@@ -32,9 +40,11 @@ import java.util.Map;
 import static com.google.common.collect.Maps.newHashMap;
 
 /**
- * Parser for script query
+ *
  */
-public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
+public class ScriptQueryParser implements QueryParser {
+
+    public static final String NAME = "script";
 
     @Inject
     public ScriptQueryParser() {
@@ -42,23 +52,23 @@ public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{ScriptQueryBuilder.NAME};
+        return new String[] { NAME };
     }
 
     @Override
-    public ScriptQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
         ScriptParameterParser scriptParameterParser = new ScriptParameterParser();
-        
+
+        XContentParser.Token token;
+
         // also, when caching, since its isCacheable is false, will result in loading all bit set...
         Script script = null;
         Map<String, Object> params = null;
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
-
-        XContentParser.Token token;
         String currentFieldName = null;
+
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -75,8 +85,6 @@ public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if (!scriptParameterParser.token(currentFieldName, token, parser, parseContext.parseFieldMatcher())) {
                     throw new QueryParsingException(parseContext, "[script] query does not support [" + currentFieldName + "]");
                 }
@@ -99,13 +107,83 @@ public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
             throw new QueryParsingException(parseContext, "script must be provided with a [script] filter");
         }
 
-        return new ScriptQueryBuilder(script)
-                .boost(boost)
-                .queryName(queryName);
+        Query query = new ScriptQuery(script, parseContext.scriptService(), parseContext.lookup());
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 
-    @Override
-    public ScriptQueryBuilder getBuilderPrototype() {
-        return ScriptQueryBuilder.PROTOTYPE;
+    static class ScriptQuery extends Query {
+
+        private final Script script;
+
+        private final SearchScript searchScript;
+
+        public ScriptQuery(Script script, ScriptService scriptService, SearchLookup searchLookup) {
+            this.script = script;
+            this.searchScript = scriptService.search(searchLookup, script, ScriptContext.Standard.SEARCH);
+        }
+
+        @Override
+        public String toString(String field) {
+            StringBuilder buffer = new StringBuilder();
+            buffer.append("ScriptFilter(");
+            buffer.append(script);
+            buffer.append(")");
+            return buffer.toString();
+        }
+
+        @Override
+        public boolean equals(Object obj) {
+            if (this == obj)
+                return true;
+            if (!super.equals(obj))
+                return false;
+            ScriptQuery other = (ScriptQuery) obj;
+            return Objects.equal(script, other.script);
+        }
+
+        @Override
+        public int hashCode() {
+            final int prime = 31;
+            int result = super.hashCode();
+            result = prime * result + Objects.hashCode(script);
+            return result;
+        }
+
+        @Override
+        public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+            return new RandomAccessWeight(this) {
+                @Override
+                protected Bits getMatchingDocs(final LeafReaderContext context) throws IOException {
+                    final LeafSearchScript leafScript = searchScript.getLeafSearchScript(context);
+                    return new Bits() {
+
+                        @Override
+                        public boolean get(int doc) {
+                            leafScript.setDocument(doc);
+                            Object val = leafScript.run();
+                            if (val == null) {
+                                return false;
+                            }
+                            if (val instanceof Boolean) {
+                                return (Boolean) val;
+                            }
+                            if (val instanceof Number) {
+                                return ((Number) val).longValue() != 0;
+                            }
+                            throw new IllegalArgumentException("Can't handle type [" + val + "] in script filter");
+                        }
+
+                        @Override
+                        public int length() {
+                            return context.reader().maxDoc();
+                        }
+
+                    };
+                }
+            };
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java
index 06a3ccb..fc916f5 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java
@@ -29,7 +29,6 @@ import org.apache.lucene.util.BytesRef;
 import java.io.IOException;
 import java.util.Locale;
 import java.util.Map;
-import java.util.Objects;
 
 /**
  * Wrapper class for Lucene's SimpleQueryParser that allows us to redefine
@@ -203,102 +202,51 @@ public class SimpleQueryParser extends org.apache.lucene.queryparser.simple.Simp
             return new PrefixQuery(new Term(field, termStr));
         }
     }
+
     /**
      * Class encapsulating the settings for the SimpleQueryString query, with
      * their default values
      */
-    static class Settings {
-        /** Locale to use for parsing. */
-        private Locale locale = SimpleQueryStringBuilder.DEFAULT_LOCALE;
-        /** Specifies whether parsed terms should be lowercased. */
-        private boolean lowercaseExpandedTerms = SimpleQueryStringBuilder.DEFAULT_LOWERCASE_EXPANDED_TERMS;
-        /** Specifies whether lenient query parsing should be used. */
-        private boolean lenient = SimpleQueryStringBuilder.DEFAULT_LENIENT;
-        /** Specifies whether wildcards should be analyzed. */
-        private boolean analyzeWildcard = SimpleQueryStringBuilder.DEFAULT_ANALYZE_WILDCARD;
+    public static class Settings {
+        private Locale locale = Locale.ROOT;
+        private boolean lowercaseExpandedTerms = true;
+        private boolean lenient = false;
+        private boolean analyzeWildcard = false;
 
-        /**
-         * Generates default {@link Settings} object (uses ROOT locale, does
-         * lowercase terms, no lenient parsing, no wildcard analysis).
-         * */
         public Settings() {
-        }
 
-        public Settings(Locale locale, Boolean lowercaseExpandedTerms, Boolean lenient, Boolean analyzeWildcard) {
-            this.locale = locale;
-            this.lowercaseExpandedTerms = lowercaseExpandedTerms;
-            this.lenient = lenient;
-            this.analyzeWildcard = analyzeWildcard;
         }
 
-        /** Specifies the locale to use for parsing, Locale.ROOT by default. */
         public void locale(Locale locale) {
-            this.locale = (locale != null) ? locale : SimpleQueryStringBuilder.DEFAULT_LOCALE;
+            this.locale = locale;
         }
 
-        /** Returns the locale to use for parsing. */
         public Locale locale() {
             return this.locale;
         }
 
-        /**
-         * Specifies whether to lowercase parse terms, defaults to true if
-         * unset.
-         */
         public void lowercaseExpandedTerms(boolean lowercaseExpandedTerms) {
             this.lowercaseExpandedTerms = lowercaseExpandedTerms;
         }
 
-        /** Returns whether to lowercase parse terms. */
         public boolean lowercaseExpandedTerms() {
             return this.lowercaseExpandedTerms;
         }
 
-        /** Specifies whether to use lenient parsing, defaults to false. */
         public void lenient(boolean lenient) {
             this.lenient = lenient;
         }
 
-        /** Returns whether to use lenient parsing. */
         public boolean lenient() {
             return this.lenient;
         }
 
-        /** Specifies whether to analyze wildcards. Defaults to false if unset. */
         public void analyzeWildcard(boolean analyzeWildcard) {
             this.analyzeWildcard = analyzeWildcard;
         }
 
-        /** Returns whether to analyze wildcards. */
         public boolean analyzeWildcard() {
             return analyzeWildcard;
         }
-
-        @Override
-        public int hashCode() {
-            // checking the return value of toLanguageTag() for locales only.
-            // For further reasoning see
-            // https://issues.apache.org/jira/browse/LUCENE-4021
-            return Objects.hash(locale.toLanguageTag(), lowercaseExpandedTerms, lenient, analyzeWildcard);
-        }
-
-        @Override
-        public boolean equals(Object obj) {
-            if (this == obj) {
-                return true;
-            }
-            if (obj == null || getClass() != obj.getClass()) {
-                return false;
-            }
-            Settings other = (Settings) obj;
-
-            // checking the return value of toLanguageTag() for locales only.
-            // For further reasoning see
-            // https://issues.apache.org/jira/browse/LUCENE-4021
-            return (Objects.equals(locale.toLanguageTag(), other.locale.toLanguageTag())
-                    && Objects.equals(lowercaseExpandedTerms, other.lowercaseExpandedTerms) 
-                    && Objects.equals(lenient, other.lenient)
-                    && Objects.equals(analyzeWildcard, other.analyzeWildcard));
-        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java
index 1387980..700ad41 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java
@@ -19,304 +19,150 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.regex.Regex;
+import org.elasticsearch.common.xcontent.ToXContent.Params;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.SimpleQueryParser.Settings;
 
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
-import java.util.Objects;
-import java.util.TreeMap;
 
 /**
- * SimpleQuery is a query parser that acts similar to a query_string query, but
- * won't throw exceptions for any weird string syntax.
- *
- * For more detailed explanation of the query string syntax see also the <a
- * href=
- * "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-simple-query-string-query.html"
- * > online documentation</a>.
+ * SimpleQuery is a query parser that acts similar to a query_string
+ * query, but won't throw exceptions for any weird string syntax.
  */
-public class SimpleQueryStringBuilder extends AbstractQueryBuilder<SimpleQueryStringBuilder> {
-    /** Default locale used for parsing.*/
-    public static final Locale DEFAULT_LOCALE = Locale.ROOT;
-    /** Default for lowercasing parsed terms.*/
-    public static final boolean DEFAULT_LOWERCASE_EXPANDED_TERMS = true;
-    /** Default for using lenient query parsing.*/
-    public static final boolean DEFAULT_LENIENT = false;
-    /** Default for wildcard analysis.*/
-    public static final boolean DEFAULT_ANALYZE_WILDCARD = false;
-    /** Default for default operator to use for linking boolean clauses.*/
-    public static final Operator DEFAULT_OPERATOR = Operator.OR;
-    /** Default for search flags to use. */
-    public static final int DEFAULT_FLAGS = SimpleQueryStringFlag.ALL.value;
-    /** Name for (de-)serialization. */
-    public static final String NAME = "simple_query_string";
-
-    /** Query text to parse. */
-    private final String queryText;
-    /**
-     * Fields to query against. If left empty will query default field,
-     * currently _ALL. Uses a TreeMap to hold the fields so boolean clauses are
-     * always sorted in same order for generated Lucene query for easier
-     * testing.
-     *
-     * Can be changed back to HashMap once https://issues.apache.org/jira/browse/LUCENE-6305 is fixed.
-     */
-    private final Map<String, Float> fieldsAndWeights = new TreeMap<>();
-    /** If specified, analyzer to use to parse the query text, defaults to registered default in toQuery. */
+public class SimpleQueryStringBuilder extends QueryBuilder implements BoostableQueryBuilder<SimpleQueryStringBuilder> {
+    private Map<String, Float> fields = new HashMap<>();
     private String analyzer;
-    /** Default operator to use for linking boolean clauses. Defaults to OR according to docs. */
-    private Operator defaultOperator = DEFAULT_OPERATOR;
-    /** If result is a boolean query, minimumShouldMatch parameter to apply. Ignored otherwise. */
+    private Operator operator;
+    private final String queryText;
+    private String queryName;
     private String minimumShouldMatch;
-    /** Any search flags to be used, ALL by default. */
-    private int flags = DEFAULT_FLAGS;
-
-    /** Further search settings needed by the ES specific query string parser only. */
-    private Settings settings = new Settings();
+    private int flags = -1;
+    private float boost = -1.0f;
+    private Boolean lowercaseExpandedTerms;
+    private Boolean lenient;
+    private Boolean analyzeWildcard;
+    private Locale locale;
 
-    static final SimpleQueryStringBuilder PROTOTYPE = new SimpleQueryStringBuilder(null);
+    /**
+     * Operators for the default_operator
+     */
+    public static enum Operator {
+        AND,
+        OR
+    }
 
-    /** Construct a new simple query with this query string. */
-    public SimpleQueryStringBuilder(String queryText) {
-        this.queryText = queryText;
+    /**
+     * Construct a new simple query with the given text
+     */
+    public SimpleQueryStringBuilder(String text) {
+        this.queryText = text;
     }
 
-    /** Returns the text to parse the query from. */
-    public String value() {
-        return this.queryText;
+    /** Set the boost of this query. */
+    @Override
+    public SimpleQueryStringBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+    
+    /** Returns the boost of this query. */
+    public float boost() {
+        return this.boost;
     }
 
-    /** Add a field to run the query against. */
+    /**
+     * Add a field to run the query against
+     */
     public SimpleQueryStringBuilder field(String field) {
-        if (Strings.isEmpty(field)) {
-            throw new IllegalArgumentException("supplied field is null or empty.");
-        }
-        this.fieldsAndWeights.put(field, AbstractQueryBuilder.DEFAULT_BOOST);
+        this.fields.put(field, null);
         return this;
     }
 
-    /** Add a field to run the query against with a specific boost. */
+    /**
+     * Add a field to run the query against with a specific boost
+     */
     public SimpleQueryStringBuilder field(String field, float boost) {
-        if (Strings.isEmpty(field)) {
-            throw new IllegalArgumentException("supplied field is null or empty.");
-        }
-        this.fieldsAndWeights.put(field, boost);
+        this.fields.put(field, boost);
         return this;
     }
 
-    /** Add several fields to run the query against with a specific boost. */
-    public SimpleQueryStringBuilder fields(Map<String, Float> fields) {
-        this.fieldsAndWeights.putAll(fields);
+    /**
+     * Specify a name for the query
+     */
+    public SimpleQueryStringBuilder queryName(String name) {
+        this.queryName = name;
         return this;
     }
 
-    /** Returns the fields including their respective boosts to run the query against. */
-    public Map<String, Float> fields() {
-        return this.fieldsAndWeights;
-    }
-
-    /** Specify an analyzer to use for the query. */
+    /**
+     * Specify an analyzer to use for the query
+     */
     public SimpleQueryStringBuilder analyzer(String analyzer) {
         this.analyzer = analyzer;
         return this;
     }
 
-    /** Returns the analyzer to use for the query. */
-    public String analyzer() {
-        return this.analyzer;
-    }
-
     /**
      * Specify the default operator for the query. Defaults to "OR" if no
-     * operator is specified.
+     * operator is specified
      */
     public SimpleQueryStringBuilder defaultOperator(Operator defaultOperator) {
-        this.defaultOperator = (defaultOperator != null) ? defaultOperator : DEFAULT_OPERATOR;
+        this.operator = defaultOperator;
         return this;
     }
 
-    /** Returns the default operator for the query. */
-    public Operator defaultOperator() {
-        return this.defaultOperator;
-    }
-
     /**
-     * Specify the enabled features of the SimpleQueryString. Defaults to ALL if
-     * none are specified.
+     * Specify the enabled features of the SimpleQueryString.
      */
     public SimpleQueryStringBuilder flags(SimpleQueryStringFlag... flags) {
-        if (flags != null && flags.length > 0) {
-            int value = 0;
+        int value = 0;
+        if (flags.length == 0) {
+            value = SimpleQueryStringFlag.ALL.value;
+        } else {
             for (SimpleQueryStringFlag flag : flags) {
                 value |= flag.value;
             }
-            this.flags = value;
-        } else {
-            this.flags = DEFAULT_FLAGS;
         }
-
+        this.flags = value;
         return this;
     }
 
-    /** For testing and serialisation only. */
-    SimpleQueryStringBuilder flags(int flags) {
-        this.flags = flags;
-        return this;
-    }
-
-    /** For testing only: Return the flags set for this query. */
-    int flags() {
-        return this.flags;
-    }
-
-    /**
-     * Specifies whether parsed terms for this query should be lower-cased.
-     * Defaults to true if not set.
-     */
     public SimpleQueryStringBuilder lowercaseExpandedTerms(boolean lowercaseExpandedTerms) {
-        this.settings.lowercaseExpandedTerms(lowercaseExpandedTerms);
+        this.lowercaseExpandedTerms = lowercaseExpandedTerms;
         return this;
     }
 
-    /** Returns whether parsed terms should be lower cased for this query. */
-    public boolean lowercaseExpandedTerms() {
-        return this.settings.lowercaseExpandedTerms();
-    }
-
-    /** Specifies the locale for parsing terms. Defaults to ROOT if none is set. */
     public SimpleQueryStringBuilder locale(Locale locale) {
-        this.settings.locale(locale);
+        this.locale = locale;
         return this;
     }
 
-    /** Returns the locale for parsing terms for this query. */
-    public Locale locale() {
-        return this.settings.locale();
-    }
-
-    /** Specifies whether query parsing should be lenient. Defaults to false. */
     public SimpleQueryStringBuilder lenient(boolean lenient) {
-        this.settings.lenient(lenient);
+        this.lenient = lenient;
         return this;
     }
 
-    /** Returns whether query parsing should be lenient. */
-    public boolean lenient() {
-        return this.settings.lenient();
-    }
-
-    /** Specifies whether wildcards should be analyzed. Defaults to false. */
     public SimpleQueryStringBuilder analyzeWildcard(boolean analyzeWildcard) {
-        this.settings.analyzeWildcard(analyzeWildcard);
+        this.analyzeWildcard = analyzeWildcard;
         return this;
     }
 
-    /** Returns whether wildcards should by analyzed. */
-    public boolean analyzeWildcard() {
-        return this.settings.analyzeWildcard();
-    }
-
-    /**
-     * Specifies the minimumShouldMatch to apply to the resulting query should
-     * that be a Boolean query.
-     */
     public SimpleQueryStringBuilder minimumShouldMatch(String minimumShouldMatch) {
         this.minimumShouldMatch = minimumShouldMatch;
         return this;
     }
 
-    /**
-     * Returns the minimumShouldMatch to apply to the resulting query should
-     * that be a Boolean query.
-     */
-    public String minimumShouldMatch() {
-        return minimumShouldMatch;
-    }
-
-    /**
-     * {@inheritDoc}
-     *
-     * Checks that mandatory queryText is neither null nor empty.
-     * */
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        // Query text is required
-        if (queryText == null) {
-            validationException = addValidationError("query text missing", validationException);
-        }
-
-        return validationException;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // Use the default field if no fields specified
-        if (fieldsAndWeights.isEmpty()) {
-            fieldsAndWeights.put(context.defaultField(), AbstractQueryBuilder.DEFAULT_BOOST);
-        }
-
-        // field names in builder can have wildcards etc, need to resolve them here
-        Map<String, Float> resolvedFieldsAndWeights = new TreeMap<>();
-        for (String fField : fieldsAndWeights.keySet()) {
-            if (Regex.isSimpleMatchPattern(fField)) {
-                for (String fieldName : context.mapperService().simpleMatchToIndexNames(fField)) {
-                    resolvedFieldsAndWeights.put(fieldName, fieldsAndWeights.get(fField));
-                }
-            } else {
-                MappedFieldType fieldType = context.fieldMapper(fField);
-                if (fieldType != null) {
-                    resolvedFieldsAndWeights.put(fieldType.names().indexName(), fieldsAndWeights.get(fField));
-                } else {
-                    resolvedFieldsAndWeights.put(fField, fieldsAndWeights.get(fField));
-                }
-            }
-        }
-
-        // Use standard analyzer by default if none specified
-        Analyzer luceneAnalyzer;
-        if (analyzer == null) {
-            luceneAnalyzer = context.mapperService().searchAnalyzer();
-        } else {
-            luceneAnalyzer = context.analysisService().analyzer(analyzer);
-            if (luceneAnalyzer == null) {
-                throw new QueryShardException(context, "[" + SimpleQueryStringBuilder.NAME + "] analyzer [" + analyzer
-                        + "] not found");
-            }
-
-        }
-
-        SimpleQueryParser sqp = new SimpleQueryParser(luceneAnalyzer, resolvedFieldsAndWeights, flags, settings);
-        sqp.setDefaultOperator(defaultOperator.toBooleanClauseOccur());
-
-        Query query = sqp.parse(queryText);
-        if (minimumShouldMatch != null && query instanceof BooleanQuery) {
-            Queries.applyMinimumShouldMatch((BooleanQuery) query, minimumShouldMatch);
-        }
-        return query;
-    }
-
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(SimpleQueryStringParser.NAME);
 
         builder.field("query", queryText);
 
-        if (fieldsAndWeights.size() > 0) {
+        if (fields.size() > 0) {
             builder.startArray("fields");
-            for (Map.Entry<String, Float> entry : fieldsAndWeights.entrySet()) {
+            for (Map.Entry<String, Float> entry : fields.entrySet()) {
                 String field = entry.getKey();
                 Float boost = entry.getValue();
                 if (boost != null) {
@@ -328,82 +174,47 @@ public class SimpleQueryStringBuilder extends AbstractQueryBuilder<SimpleQuerySt
             builder.endArray();
         }
 
+        if (flags != -1) {
+            builder.field("flags", flags);
+        }
+
         if (analyzer != null) {
             builder.field("analyzer", analyzer);
         }
 
-        builder.field("flags", flags);
-        builder.field("default_operator", defaultOperator.name().toLowerCase(Locale.ROOT));
-        builder.field("lowercase_expanded_terms", settings.lowercaseExpandedTerms());
-        builder.field("lenient", settings.lenient());
-        builder.field("analyze_wildcard", settings.analyzeWildcard());
-        builder.field("locale", (settings.locale().toLanguageTag()));
+        if (operator != null) {
+            builder.field("default_operator", operator.name().toLowerCase(Locale.ROOT));
+        }
 
-        if (minimumShouldMatch != null) {
-            builder.field("minimum_should_match", minimumShouldMatch);
+        if (lowercaseExpandedTerms != null) {
+            builder.field("lowercase_expanded_terms", lowercaseExpandedTerms);
         }
 
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
+        if (lenient != null) {
+            builder.field("lenient", lenient);
+        }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
+        if (analyzeWildcard != null) {
+            builder.field("analyze_wildcard", analyzeWildcard);
+        }
 
-    @Override
-    protected SimpleQueryStringBuilder doReadFrom(StreamInput in) throws IOException {
-        SimpleQueryStringBuilder result = new SimpleQueryStringBuilder(in.readString());
-        int size = in.readInt();
-        Map<String, Float> fields = new HashMap<>();
-        for (int i = 0; i < size; i++) {
-            String field = in.readString();
-            Float weight = in.readFloat();
-            fields.put(field, weight);
+        if (locale != null) {
+            builder.field("locale", locale.toString());
         }
-        result.fieldsAndWeights.putAll(fields);
-        result.flags = in.readInt();
-        result.analyzer = in.readOptionalString();
-        result.defaultOperator = Operator.readOperatorFrom(in);
-        result.settings.lowercaseExpandedTerms(in.readBoolean());
-        result.settings.lenient(in.readBoolean());
-        result.settings.analyzeWildcard(in.readBoolean());
-        String localeStr = in.readString();
-        result.settings.locale(Locale.forLanguageTag(localeStr));
-        result.minimumShouldMatch = in.readOptionalString();
-        return result;
-    }
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(queryText);
-        out.writeInt(fieldsAndWeights.size());
-        for (Map.Entry<String, Float> entry : fieldsAndWeights.entrySet()) {
-            out.writeString(entry.getKey());
-            out.writeFloat(entry.getValue());
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        out.writeInt(flags);
-        out.writeOptionalString(analyzer);
-        defaultOperator.writeTo(out);
-        out.writeBoolean(settings.lowercaseExpandedTerms());
-        out.writeBoolean(settings.lenient());
-        out.writeBoolean(settings.analyzeWildcard());
-        out.writeString(settings.locale().toLanguageTag());
-        out.writeOptionalString(minimumShouldMatch);
-    }
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldsAndWeights, analyzer, defaultOperator, queryText, minimumShouldMatch, settings, flags);
-    }
+        if (minimumShouldMatch != null) {
+            builder.field("minimum_should_match", minimumShouldMatch);
+        }
+        
+        if (boost != -1.0f) {
+            builder.field("boost", boost);
+        }
 
-    @Override
-    protected boolean doEquals(SimpleQueryStringBuilder other) {
-        return Objects.equals(fieldsAndWeights, other.fieldsAndWeights) && Objects.equals(analyzer, other.analyzer)
-                && Objects.equals(defaultOperator, other.defaultOperator) && Objects.equals(queryText, other.queryText)
-                && Objects.equals(minimumShouldMatch, other.minimumShouldMatch)
-                && Objects.equals(settings, other.settings) && (flags == other.flags);
+        builder.endObject();
     }
-}
 
+}
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java
index 68d19db..ce0ce88 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java
@@ -71,7 +71,7 @@ public enum SimpleQueryStringFlag {
                         magic |= flag.value();
                 }
             } catch (IllegalArgumentException iae) {
-                throw new IllegalArgumentException("Unknown " + SimpleQueryStringBuilder.NAME + " flag [" + s + "]");
+                throw new IllegalArgumentException("Unknown " + SimpleQueryStringParser.NAME + " flag [" + s + "]");
             }
         }
         return magic;
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java
index e45659e..d80423d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java
@@ -19,11 +19,20 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
+import org.elasticsearch.common.regex.Regex;
+import org.elasticsearch.common.util.LocaleUtils;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
@@ -59,7 +68,9 @@ import java.util.Map;
  * {@code fields} - fields to search, defaults to _all if not set, allows
  * boosting a field with ^n
  */
-public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBuilder> {
+public class SimpleQueryStringParser implements QueryParser {
+
+    public static final String NAME = "simple_query_string";
 
     @Inject
     public SimpleQueryStringParser() {
@@ -68,26 +79,23 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
 
     @Override
     public String[] names() {
-        return new String[]{SimpleQueryStringBuilder.NAME, Strings.toCamelCase(SimpleQueryStringBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SimpleQueryStringBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String currentFieldName = null;
         String queryBody = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f; 
         String queryName = null;
         String minimumShouldMatch = null;
-        Map<String, Float> fieldsAndWeights = new HashMap<>();
-        Operator defaultOperator = null;
-        String analyzerName = null;
-        int flags = SimpleQueryStringFlag.ALL.value();
-        boolean lenient = SimpleQueryStringBuilder.DEFAULT_LENIENT;
-        boolean lowercaseExpandedTerms = SimpleQueryStringBuilder.DEFAULT_LOWERCASE_EXPANDED_TERMS;
-        boolean analyzeWildcard = SimpleQueryStringBuilder.DEFAULT_ANALYZE_WILDCARD;
-        Locale locale = null;
+        Map<String, Float> fieldsAndWeights = null;
+        BooleanClause.Occur defaultOperator = null;
+        Analyzer analyzer = null;
+        int flags = -1;
+        SimpleQueryParser.Settings sqsSettings = new SimpleQueryParser.Settings();
 
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -111,10 +119,26 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
                         if (fField == null) {
                             fField = parser.text();
                         }
-                        fieldsAndWeights.put(fField, fBoost);
+
+                        if (fieldsAndWeights == null) {
+                            fieldsAndWeights = new HashMap<>();
+                        }
+
+                        if (Regex.isSimpleMatchPattern(fField)) {
+                            for (String fieldName : parseContext.mapperService().simpleMatchToIndexNames(fField)) {
+                                fieldsAndWeights.put(fieldName, fBoost);
+                            }
+                        } else {
+                            MappedFieldType fieldType = parseContext.fieldMapper(fField);
+                            if (fieldType != null) {
+                                fieldsAndWeights.put(fieldType.names().indexName(), fBoost);
+                            } else {
+                                fieldsAndWeights.put(fField, fBoost);
+                            }
+                        }
                     }
                 } else {
-                    throw new QueryParsingException(parseContext, "[" + SimpleQueryStringBuilder.NAME + "] query does not support [" + currentFieldName + "]");
+                    throw new QueryParsingException(parseContext, "[" + NAME + "] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("query".equals(currentFieldName)) {
@@ -122,9 +146,19 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else if ("analyzer".equals(currentFieldName)) {
-                    analyzerName = parser.text();
+                    analyzer = parseContext.analysisService().analyzer(parser.text());
+                    if (analyzer == null) {
+                        throw new QueryParsingException(parseContext, "[" + NAME + "] analyzer [" + parser.text() + "] not found");
+                    }
                 } else if ("default_operator".equals(currentFieldName) || "defaultOperator".equals(currentFieldName)) {
-                    defaultOperator = Operator.fromString(parser.text());
+                    String op = parser.text();
+                    if ("or".equalsIgnoreCase(op)) {
+                        defaultOperator = BooleanClause.Occur.SHOULD;
+                    } else if ("and".equalsIgnoreCase(op)) {
+                        defaultOperator = BooleanClause.Occur.MUST;
+                    } else {
+                        throw new QueryParsingException(parseContext, "[" + NAME + "] default operator [" + op + "] is not allowed");
+                    }
                 } else if ("flags".equals(currentFieldName)) {
                     if (parser.currentToken() != XContentParser.Token.VALUE_NUMBER) {
                         // Possible options are:
@@ -138,38 +172,56 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
                     }
                 } else if ("locale".equals(currentFieldName)) {
                     String localeStr = parser.text();
-                    locale = Locale.forLanguageTag(localeStr);
+                    Locale locale = LocaleUtils.parse(localeStr);
+                    sqsSettings.locale(locale);
                 } else if ("lowercase_expanded_terms".equals(currentFieldName)) {
-                    lowercaseExpandedTerms = parser.booleanValue();
+                    sqsSettings.lowercaseExpandedTerms(parser.booleanValue());
                 } else if ("lenient".equals(currentFieldName)) {
-                    lenient = parser.booleanValue();
+                    sqsSettings.lenient(parser.booleanValue());
                 } else if ("analyze_wildcard".equals(currentFieldName)) {
-                    analyzeWildcard = parser.booleanValue();
+                    sqsSettings.analyzeWildcard(parser.booleanValue());
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
                 } else if ("minimum_should_match".equals(currentFieldName)) {
                     minimumShouldMatch = parser.textOrNull();
                 } else {
-                    throw new QueryParsingException(parseContext, "[" + SimpleQueryStringBuilder.NAME + "] unsupported field [" + parser.currentName() + "]");
+                    throw new QueryParsingException(parseContext, "[" + NAME + "] unsupported field [" + parser.currentName() + "]");
                 }
             }
         }
 
         // Query text is required
         if (queryBody == null) {
-            throw new QueryParsingException(parseContext, "[" + SimpleQueryStringBuilder.NAME + "] query text missing");
+            throw new QueryParsingException(parseContext, "[" + NAME + "] query text missing");
+        }
+
+        // Use standard analyzer by default
+        if (analyzer == null) {
+            analyzer = parseContext.mapperService().searchAnalyzer();
         }
 
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder(queryBody);
-        qb.boost(boost).fields(fieldsAndWeights).analyzer(analyzerName).queryName(queryName).minimumShouldMatch(minimumShouldMatch);
-        qb.flags(flags).defaultOperator(defaultOperator).locale(locale).lowercaseExpandedTerms(lowercaseExpandedTerms);
-        qb.lenient(lenient).analyzeWildcard(analyzeWildcard).boost(boost);
+        if (fieldsAndWeights == null) {
+            fieldsAndWeights = Collections.singletonMap(parseContext.defaultField(), 1.0F);
+        }
+        SimpleQueryParser sqp = new SimpleQueryParser(analyzer, fieldsAndWeights, flags, sqsSettings);
 
-        return qb;
-    }
+        if (defaultOperator != null) {
+            sqp.setDefaultOperator(defaultOperator);
+        }
 
-    @Override
-    public SimpleQueryStringBuilder getBuilderPrototype() {
-        return SimpleQueryStringBuilder.PROTOTYPE;
+        Query query = sqp.parse(queryBody);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+
+        if (minimumShouldMatch != null && query instanceof BooleanQuery) {
+            Queries.applyMinimumShouldMatch((BooleanQuery) query, minimumShouldMatch);
+        }
+
+        if (query != null) {
+            query.setBoost(boost);
+        }
+
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java
index 81aa01c..0b7a3cd 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java
@@ -19,111 +19,74 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanContainingQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * Builder for {@link org.apache.lucene.search.spans.SpanContainingQuery}.
  */
-public class SpanContainingQueryBuilder extends AbstractQueryBuilder<SpanContainingQueryBuilder> implements SpanQueryBuilder<SpanContainingQueryBuilder> {
+public class SpanContainingQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanContainingQueryBuilder> {
 
-    public static final String NAME = "span_containing";
-    private final SpanQueryBuilder big;
-    private final SpanQueryBuilder little;
-    static final SpanContainingQueryBuilder PROTOTYPE = new SpanContainingQueryBuilder(null, null);
+    private SpanQueryBuilder big;
+    private SpanQueryBuilder little;
+    private float boost = -1;
+    private String queryName;
 
-    /**
-     * @param big the big clause, it must enclose {@code little} for a match.
-     * @param little the little clause, it must be contained within {@code big} for a match.
+    /** 
+     * Sets the little clause, it must be contained within {@code big} for a match.
      */
-    public SpanContainingQueryBuilder(SpanQueryBuilder big, SpanQueryBuilder little) {
-        this.little = little;
-        this.big = big;
+    public SpanContainingQueryBuilder little(SpanQueryBuilder clause) {
+        this.little = clause;
+        return this;
     }
 
-    /**
-     * @return the big clause, it must enclose {@code little} for a match.
+    /** 
+     * Sets the big clause, it must enclose {@code little} for a match.
      */
-    public SpanQueryBuilder bigQuery() {
-        return this.big;
-    }
-
-    /**
-     * @return the little clause, it must be contained within {@code big} for a match.
-     */
-    public SpanQueryBuilder littleQuery() {
-        return this.little;
+    public SpanContainingQueryBuilder big(SpanQueryBuilder clause) {
+        this.big = clause;
+        return this;
     }
 
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("big");
-        big.toXContent(builder, params);
-        builder.field("little");
-        little.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
+    public SpanContainingQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerBig = big.toQuery(context);
-        assert innerBig instanceof SpanQuery;
-        Query innerLittle = little.toQuery(context);
-        assert innerLittle instanceof SpanQuery;
-        return new SpanContainingQuery((SpanQuery) innerBig, (SpanQuery) innerLittle);
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public SpanContainingQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
         if (big == null) {
-            validationException = addValidationError("inner clause [big] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(big, validationException);
+            throw new IllegalArgumentException("Must specify big clause when building a span_containing query");
         }
         if (little == null) {
-            validationException = addValidationError("inner clause [little] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(little, validationException);
+            throw new IllegalArgumentException("Must specify little clause when building a span_containing query");
         }
-        return validationException;
-    }
+        builder.startObject(SpanContainingQueryParser.NAME);
 
-    @Override
-    protected SpanContainingQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder big = (SpanQueryBuilder)in.readQuery();
-        SpanQueryBuilder little = (SpanQueryBuilder)in.readQuery();
-        return new SpanContainingQueryBuilder(big, little);
-    }
+        builder.field("big");
+        big.toXContent(builder, params);
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(big);
-        out.writeQuery(little);
-    }
+        builder.field("little");
+        little.toXContent(builder, params);
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(big, little);
-    }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
 
-    @Override
-    protected boolean doEquals(SpanContainingQueryBuilder other) {
-        return Objects.equals(big, other.big) &&
-               Objects.equals(little, other.little);
-    }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java
index affc853..63e312b 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanContainingQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_containing query
+ * Parser for {@link SpanContainingQuery}
  */
-public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQueryBuilder> {
+public class SpanContainingQueryParser implements QueryParser {
+
+    public static final String NAME = "span_containing";
 
     @Inject
     public SpanContainingQueryParser() {
@@ -36,16 +41,17 @@ public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQue
 
     @Override
     public String[] names() {
-        return new String[]{SpanContainingQueryBuilder.NAME, Strings.toCamelCase(SpanContainingQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanContainingQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+
+        float boost = 1.0f;
         String queryName = null;
-        SpanQueryBuilder<?> big = null;
-        SpanQueryBuilder<?> little = null;
+        SpanQuery big = null;
+        SpanQuery little = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -54,17 +60,17 @@ public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQue
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("big".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder<?>)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "span_containing [big] must be of type span query");
                     }
-                    big = (SpanQueryBuilder<?>) query;
+                    big = (SpanQuery) query;
                 } else if ("little".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder<?>)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "span_containing [little] must be of type span query");
                     }
-                    little = (SpanQueryBuilder<?>) query;
+                    little = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_containing] query does not support [" + currentFieldName + "]");
                 }
@@ -75,15 +81,20 @@ public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQue
             } else {
                 throw new QueryParsingException(parseContext, "[span_containing] query does not support [" + currentFieldName + "]");
             }
+        }        
+        
+        if (big == null) {
+            throw new QueryParsingException(parseContext, "span_containing must include [big]");
+        }
+        if (little == null) {
+            throw new QueryParsingException(parseContext, "span_containing must include [little]");
         }
 
-        SpanContainingQueryBuilder query = new SpanContainingQueryBuilder(big, little);
-        query.boost(boost).queryName(queryName);
+        Query query = new SpanContainingQuery(big, little);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
         return query;
     }
-
-    @Override
-    public SpanContainingQueryBuilder getBuilderPrototype() {
-        return SpanContainingQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java
index a7c4572..f967a1c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java
@@ -19,109 +19,51 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanFirstQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class SpanFirstQueryBuilder extends AbstractQueryBuilder<SpanFirstQueryBuilder> implements SpanQueryBuilder<SpanFirstQueryBuilder>{
-
-    public static final String NAME = "span_first";
+public class SpanFirstQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanFirstQueryBuilder> {
 
     private final SpanQueryBuilder matchBuilder;
 
     private final int end;
 
-    static final SpanFirstQueryBuilder PROTOTYPE = new SpanFirstQueryBuilder(null, -1);
+    private float boost = -1;
+
+    private String queryName;
 
-    /**
-     * Query that matches spans queries defined in <code>matchBuilder</code>
-     * whose end position is less than or equal to <code>end</code>.
-     * @param matchBuilder inner {@link SpanQueryBuilder}
-     * @param end maximum end position of the match, needs to be positive
-     * @throws IllegalArgumentException for negative <code>end</code> positions
-     */
     public SpanFirstQueryBuilder(SpanQueryBuilder matchBuilder, int end) {
         this.matchBuilder = matchBuilder;
         this.end = end;
     }
 
-    /**
-     * @return the inner {@link SpanQueryBuilder} defined in this query
-     */
-    public SpanQueryBuilder innerQuery() {
-        return this.matchBuilder;
+    @Override
+    public SpanFirstQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
-     * @return maximum end position of the matching inner span query
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public int end() {
-        return this.end;
+    public SpanFirstQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(SpanFirstQueryParser.NAME);
         builder.field("match");
         matchBuilder.toXContent(builder, params);
         builder.field("end", end);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerSpanQuery = matchBuilder.toQuery(context);
-        assert innerSpanQuery instanceof SpanQuery;
-        return new SpanFirstQuery((SpanQuery) innerSpanQuery, end);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (matchBuilder == null) {
-            validationException = addValidationError("inner clause [match] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(matchBuilder, validationException);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        if (end < 0) {
-            validationException = addValidationError("parameter [end] needs to be positive.", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    protected SpanFirstQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder matchBuilder = (SpanQueryBuilder)in.readQuery();
-        int end = in.readInt();
-        return new SpanFirstQueryBuilder(matchBuilder, end);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(matchBuilder);
-        out.writeInt(end);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(matchBuilder, end);
-    }
-
-    @Override
-    protected boolean doEquals(SpanFirstQueryBuilder other) {
-        return Objects.equals(matchBuilder, other.matchBuilder) &&
-               Objects.equals(end, other.end);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java
index 995bb4d..5a302eb 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanFirstQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_first query
+ *
  */
-public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder> {
+public class SpanFirstQueryParser implements QueryParser {
+
+    public static final String NAME = "span_first";
 
     @Inject
     public SpanFirstQueryParser() {
@@ -36,17 +41,17 @@ public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder>
 
     @Override
     public String[] names() {
-        return new String[]{SpanFirstQueryBuilder.NAME, Strings.toCamelCase(SpanFirstQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanFirstQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
-        SpanQueryBuilder match = null;
-        Integer end = null;
+        SpanQuery match = null;
+        int end = -1;
         String queryName = null;
 
         String currentFieldName = null;
@@ -56,11 +61,11 @@ public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder>
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("match".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "spanFirst [match] must be of type span query");
                     }
-                    match = (SpanQueryBuilder) query;
+                    match = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_first] query does not support [" + currentFieldName + "]");
                 }
@@ -79,16 +84,15 @@ public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder>
         if (match == null) {
             throw new QueryParsingException(parseContext, "spanFirst must have [match] span query clause");
         }
-        if (end == null) {
+        if (end == -1) {
             throw new QueryParsingException(parseContext, "spanFirst must have [end] set for it");
         }
-        SpanFirstQueryBuilder queryBuilder = new SpanFirstQueryBuilder(match, end);
-        queryBuilder.boost(boost).queryName(queryName);
-        return queryBuilder;
-    }
 
-    @Override
-    public SpanFirstQueryBuilder getBuilderPrototype() {
-        return SpanFirstQueryBuilder.PROTOTYPE;
+        SpanFirstQuery query = new SpanFirstQuery(match, end);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java
index a31b17e..11b9897 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java
@@ -18,88 +18,25 @@
  */
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
-/**
- * Query that allows wraping a {@link MultiTermQueryBuilder} (one of wildcard, fuzzy, prefix, term, range or regexp query)
- * as a {@link SpanQueryBuilder} so it can be nested.
- */
-public class SpanMultiTermQueryBuilder extends AbstractQueryBuilder<SpanMultiTermQueryBuilder> implements SpanQueryBuilder<SpanMultiTermQueryBuilder> {
+public class SpanMultiTermQueryBuilder extends SpanQueryBuilder {
 
-    public static final String NAME = "span_multi";
-    private final MultiTermQueryBuilder multiTermQueryBuilder;
-    static final SpanMultiTermQueryBuilder PROTOTYPE = new SpanMultiTermQueryBuilder(null);
+    private MultiTermQueryBuilder multiTermQueryBuilder;
 
     public SpanMultiTermQueryBuilder(MultiTermQueryBuilder multiTermQueryBuilder) {
         this.multiTermQueryBuilder = multiTermQueryBuilder;
     }
 
-    public MultiTermQueryBuilder innerQuery() {
-        return this.multiTermQueryBuilder;
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params)
             throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(SpanMultiTermQueryParser.NAME);
         builder.field(SpanMultiTermQueryParser.MATCH_NAME);
         multiTermQueryBuilder.toXContent(builder, params);
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query subQuery = multiTermQueryBuilder.toQuery(context);
-        if (subQuery instanceof MultiTermQuery == false) {
-            throw new UnsupportedOperationException("unsupported inner query, should be " + MultiTermQuery.class.getName() +" but was "
-                    + subQuery.getClass().getName());
-        }
-        return new SpanMultiTermQueryWrapper<>((MultiTermQuery) subQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (multiTermQueryBuilder == null) {
-            validationException = addValidationError("inner clause ["+ SpanMultiTermQueryParser.MATCH_NAME +"] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(multiTermQueryBuilder, validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected SpanMultiTermQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        MultiTermQueryBuilder multiTermBuilder = (MultiTermQueryBuilder)in.readQuery();
-        return new SpanMultiTermQueryBuilder(multiTermBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(multiTermQueryBuilder);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(multiTermQueryBuilder);
-    }
-
-    @Override
-    protected boolean doEquals(SpanMultiTermQueryBuilder other) {
-        return Objects.equals(multiTermQueryBuilder, other.multiTermQueryBuilder);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java
index 77e9def..a44580a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java
@@ -18,17 +18,22 @@
  */
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.XContentParser.Token;
 
 import java.io.IOException;
 
 /**
- * Parser for span_multi query
+ *
  */
-public class SpanMultiTermQueryParser extends BaseQueryParser<SpanMultiTermQueryBuilder> {
+public class SpanMultiTermQueryParser implements QueryParser {
 
+    public static final String NAME = "span_multi";
     public static final String MATCH_NAME = "match";
 
     @Inject
@@ -37,50 +42,29 @@ public class SpanMultiTermQueryParser extends BaseQueryParser<SpanMultiTermQuery
 
     @Override
     public String[] names() {
-        return new String[]{SpanMultiTermQueryBuilder.NAME, Strings.toCamelCase(SpanMultiTermQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanMultiTermQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        String currentFieldName = null;
-        MultiTermQueryBuilder subQuery = null;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        XContentParser.Token token;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                currentFieldName = parser.currentName();
-            } else if (token == XContentParser.Token.START_OBJECT) {
-                if (MATCH_NAME.equals(currentFieldName)) {
-                    QueryBuilder innerQuery = parseContext.parseInnerQueryBuilder();
-                    if (innerQuery instanceof MultiTermQueryBuilder == false) {
-                        throw new QueryParsingException(parseContext, "[span_multi] [" + MATCH_NAME + "] must be of type multi term query");
-                    }
-                    subQuery = (MultiTermQueryBuilder) innerQuery;
-                } else {
-                    throw new QueryParsingException(parseContext, "[span_multi] query does not support [" + currentFieldName + "]");
-                }
-            } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
-                } else {
-                    throw new QueryParsingException(parseContext, "[span_multi] query does not support [" + currentFieldName + "]");
-                }
-            }
+
+        Token token = parser.nextToken();
+        if (!MATCH_NAME.equals(parser.currentName()) || token != XContentParser.Token.FIELD_NAME) {
+            throw new QueryParsingException(parseContext, "spanMultiTerm must have [" + MATCH_NAME + "] multi term query clause");
         }
 
-        if (subQuery == null) {
-            throw new QueryParsingException(parseContext, "[span_multi] must have [" + MATCH_NAME + "] multi term query clause");
+        token = parser.nextToken();
+        if (token != XContentParser.Token.START_OBJECT) {
+            throw new QueryParsingException(parseContext, "spanMultiTerm must have [" + MATCH_NAME + "] multi term query clause");
         }
 
-        return new SpanMultiTermQueryBuilder(subQuery).queryName(queryName).boost(boost);
-    }
+        Query subQuery = parseContext.parseInnerQuery();
+        if (!(subQuery instanceof MultiTermQuery)) {
+            throw new QueryParsingException(parseContext, "spanMultiTerm [" + MATCH_NAME + "] must be of type multi term query");
+        }
 
-    @Override
-    public SpanMultiTermQueryBuilder getBuilderPrototype() {
-        return SpanMultiTermQueryBuilder.PROTOTYPE;
+        parser.nextToken();
+        return new SpanMultiTermQueryWrapper<>((MultiTermQuery) subQuery);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java
index e00cc32..cb05e08 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java
@@ -19,179 +19,86 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNearQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.List;
-import java.util.Objects;
 
-/**
- * Matches spans which are near one another. One can specify slop, the maximum number
- * of intervening unmatched positions, as well as whether matches are required to be in-order.
- * The span near query maps to Lucene {@link SpanNearQuery}.
- */
-public class SpanNearQueryBuilder extends AbstractQueryBuilder<SpanNearQueryBuilder> implements SpanQueryBuilder<SpanNearQueryBuilder> {
-
-    public static final String NAME = "span_near";
-
-    /** Default for flag controlling whether matches are required to be in-order */
-    public static boolean DEFAULT_IN_ORDER = true;
-
-    /** Default for flag controlling whether payloads are collected */
-    public static boolean DEFAULT_COLLECT_PAYLOADS = true;
+public class SpanNearQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanNearQueryBuilder> {
 
-    private final List<SpanQueryBuilder> clauses = new ArrayList<>();
+    private ArrayList<SpanQueryBuilder> clauses = new ArrayList<>();
 
-    private final int slop;
+    private Integer slop = null;
 
-    private boolean inOrder = DEFAULT_IN_ORDER;
+    private Boolean inOrder;
 
-    private boolean collectPayloads = DEFAULT_COLLECT_PAYLOADS;
+    private Boolean collectPayloads;
 
-    static final SpanNearQueryBuilder PROTOTYPE = new SpanNearQueryBuilder(0);
+    private float boost = -1;
 
-    /**
-     * @param slop controls the maximum number of intervening unmatched positions permitted
-     */
-    public SpanNearQueryBuilder(int slop) {
-        this.slop = slop;
-    }
-
-    /**
-     * @return the maximum number of intervening unmatched positions permitted
-     */
-    public int slop() {
-        return this.slop;
-    }
+    private String queryName;
 
     public SpanNearQueryBuilder clause(SpanQueryBuilder clause) {
         clauses.add(clause);
         return this;
     }
 
-    /**
-     * @return the {@link SpanQueryBuilder} clauses that were set for this query
-     */
-    public List<SpanQueryBuilder> clauses() {
-        return this.clauses;
+    public SpanNearQueryBuilder slop(int slop) {
+        this.slop = slop;
+        return this;
     }
 
-    /**
-     * When <code>inOrder</code> is true, the spans from each clause
-     * must be in the same order as in <code>clauses</code> and must be non-overlapping.
-     * Defaults to <code>true</code>
-     */
     public SpanNearQueryBuilder inOrder(boolean inOrder) {
         this.inOrder = inOrder;
         return this;
     }
 
-    /**
-     * @see SpanNearQueryBuilder#inOrder(boolean))
-     */
-    public boolean inOrder() {
-        return this.inOrder;
-    }
-
-    /**
-     * @param collectPayloads flag controlling whether payloads are collected
-     */
     public SpanNearQueryBuilder collectPayloads(boolean collectPayloads) {
         this.collectPayloads = collectPayloads;
         return this;
     }
 
+    @Override
+    public SpanNearQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
     /**
-     * @see SpanNearQueryBuilder#collectPayloads(boolean))
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public boolean collectPayloads() {
-        return this.collectPayloads;
+    public SpanNearQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        if (clauses.isEmpty()) {
+            throw new IllegalArgumentException("Must have at least one clause when building a spanNear query");
+        }
+        if (slop == null) {
+            throw new IllegalArgumentException("Must set the slop when building a spanNear query");
+        }
+        builder.startObject(SpanNearQueryParser.NAME);
         builder.startArray("clauses");
         for (SpanQueryBuilder clause : clauses) {
             clause.toXContent(builder, params);
         }
         builder.endArray();
-        builder.field("slop", slop);
-        builder.field("in_order", inOrder);
-        builder.field("collect_payloads", collectPayloads);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        SpanQuery[] spanQueries = new SpanQuery[clauses.size()];
-        for (int i = 0; i < clauses.size(); i++) {
-            Query query = clauses.get(i).toQuery(context);
-            assert query instanceof SpanQuery;
-            spanQueries[i] = (SpanQuery) query;
+        builder.field("slop", slop.intValue());
+        if (inOrder != null) {
+            builder.field("in_order", inOrder);
         }
-        return new SpanNearQuery(spanQueries, slop, inOrder, collectPayloads);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (clauses.isEmpty()) {
-            validationException =  addValidationError("query must include [clauses]", validationException);
+        if (collectPayloads != null) {
+            builder.field("collect_payloads", collectPayloads);
         }
-        for (SpanQueryBuilder innerClause : clauses) {
-            if (innerClause == null) {
-                validationException =  addValidationError("[clauses] contains null element", validationException);
-            } else {
-                validationException = validateInnerQuery(innerClause, validationException);
-            }
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return validationException;
-    }
-
-    @Override
-    protected SpanNearQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(in.readVInt());
-        List<QueryBuilder> clauses = readQueries(in);
-        for (QueryBuilder subClause : clauses) {
-            queryBuilder.clauses.add((SpanQueryBuilder)subClause);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        queryBuilder.collectPayloads = in.readBoolean();
-        queryBuilder.inOrder = in.readBoolean();
-        return queryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeVInt(slop);
-        writeQueries(out, clauses);
-        out.writeBoolean(collectPayloads);
-        out.writeBoolean(inOrder);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(clauses, slop, collectPayloads, inOrder);
-    }
-
-    @Override
-    protected boolean doEquals(SpanNearQueryBuilder other) {
-        return Objects.equals(clauses, other.clauses) &&
-               Objects.equals(slop, other.slop) &&
-               Objects.equals(collectPayloads, other.collectPayloads) &&
-               Objects.equals(inOrder, other.inOrder);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java
index f74b803..506bce2 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java
@@ -19,19 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanNearQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
- * Parser for span_near query
+ *
  */
-public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
+public class SpanNearQueryParser implements QueryParser {
+
+    public static final String NAME = "span_near";
 
     @Inject
     public SpanNearQueryParser() {
@@ -39,20 +43,20 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{SpanNearQueryBuilder.NAME, Strings.toCamelCase(SpanNearQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanNearQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         Integer slop = null;
-        boolean inOrder = SpanNearQueryBuilder.DEFAULT_IN_ORDER;
-        boolean collectPayloads = SpanNearQueryBuilder.DEFAULT_COLLECT_PAYLOADS;
+        boolean inOrder = true;
+        boolean collectPayloads = true;
         String queryName = null;
 
-        List<SpanQueryBuilder> clauses = newArrayList();
+        List<SpanQuery> clauses = new ArrayList<>();
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -62,11 +66,11 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
             } else if (token == XContentParser.Token.START_ARRAY) {
                 if ("clauses".equals(currentFieldName)) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                        if (!(query instanceof SpanQueryBuilder)) {
+                        Query query = parseContext.parseInnerQuery();
+                        if (!(query instanceof SpanQuery)) {
                             throw new QueryParsingException(parseContext, "spanNear [clauses] must be of type span query");
                         }
-                        clauses.add((SpanQueryBuilder) query);
+                        clauses.add((SpanQuery) query);
                     }
                 } else {
                     throw new QueryParsingException(parseContext, "[span_near] query does not support [" + currentFieldName + "]");
@@ -77,7 +81,7 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
                 } else if ("collect_payloads".equals(currentFieldName) || "collectPayloads".equals(currentFieldName)) {
                     collectPayloads = parser.booleanValue();
                 } else if ("slop".equals(currentFieldName)) {
-                    slop = parser.intValue();
+                    slop = Integer.valueOf(parser.intValue());
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else if ("_name".equals(currentFieldName)) {
@@ -89,24 +93,18 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
                 throw new QueryParsingException(parseContext, "[span_near] query does not support [" + currentFieldName + "]");
             }
         }
-
+        if (clauses.isEmpty()) {
+            throw new QueryParsingException(parseContext, "span_near must include [clauses]");
+        }
         if (slop == null) {
             throw new QueryParsingException(parseContext, "span_near must include [slop]");
         }
 
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(slop);
-        for (SpanQueryBuilder subQuery : clauses) {
-            queryBuilder.clause(subQuery);
+        SpanNearQuery query = new SpanNearQuery(clauses.toArray(new SpanQuery[clauses.size()]), slop.intValue(), inOrder, collectPayloads);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
         }
-        queryBuilder.inOrder(inOrder);
-        queryBuilder.collectPayloads(collectPayloads);
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
-
-    @Override
-    public SpanNearQueryBuilder getBuilderPrototype() {
-        return SpanNearQueryBuilder.PROTOTYPE;
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java
index 3af88e3..e37cd80 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java
@@ -19,176 +19,100 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNotQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class SpanNotQueryBuilder extends AbstractQueryBuilder<SpanNotQueryBuilder> implements SpanQueryBuilder<SpanNotQueryBuilder> {
+public class SpanNotQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanNotQueryBuilder> {
 
-    public static final String NAME = "span_not";
+    private SpanQueryBuilder include;
 
-    /** the default pre parameter size */
-    public static final int DEFAULT_PRE = 0;
-    /** the default post parameter size */
-    public static final int DEFAULT_POST = 0;
+    private SpanQueryBuilder exclude;
 
-    private final SpanQueryBuilder include;
+    private Integer dist;
 
-    private final SpanQueryBuilder exclude;
+    private Integer pre;
 
-    private int pre = DEFAULT_PRE;
+    private Integer post;
 
-    private int post = DEFAULT_POST;
+    private Float boost;
 
-    static final SpanNotQueryBuilder PROTOTYPE = new SpanNotQueryBuilder(null, null);
+    private String queryName;
 
-    /**
-     * Construct a span query matching spans from <code>include</code> which
-     * have no overlap with spans from <code>exclude</code>.
-     * @param include the span query whose matches are filtered
-     * @param exclude the span query whose matches must not overlap
-     */
-    public SpanNotQueryBuilder(SpanQueryBuilder include, SpanQueryBuilder exclude) {
+    public SpanNotQueryBuilder include(SpanQueryBuilder include) {
         this.include = include;
-        this.exclude = exclude;
-    }
-
-    /**
-     * @return the span query whose matches are filtered
-     */
-    public SpanQueryBuilder includeQuery() {
-        return this.include;
+        return this;
     }
 
-    /**
-     * @return the span query whose matches must not overlap
-     */
-    public SpanQueryBuilder excludeQuery() {
-        return this.exclude;
+    public SpanNotQueryBuilder exclude(SpanQueryBuilder exclude) {
+        this.exclude = exclude;
+        return this;
     }
 
-    /**
-     * @param dist the amount of tokens from within the include span cant have overlap with the exclude span.
-     * Equivalent to setting both pre and post parameter.
-     */
     public SpanNotQueryBuilder dist(int dist) {
-        pre(dist);
-        post(dist);
+        this.dist = dist;
         return this;
     }
 
-    /**
-     * @param pre the amount of tokens before the include span that cant have overlap with the exclude span. Values
-     * smaller than 0 will be ignored and 0 used instead.
-     */
     public SpanNotQueryBuilder pre(int pre) {
-        this.pre = (pre >= 0) ? pre : 0;
+        this.pre = (pre >=0) ? pre : 0;
         return this;
     }
 
-    /**
-     * @return the amount of tokens before the include span that cant have overlap with the exclude span.
-     * @see SpanNotQueryBuilder#pre(int)
-     */
-    public Integer pre() {
-        return this.pre;
-    }
-
-    /**
-     * @param post the amount of tokens after the include span that cant have overlap with the exclude span.
-     */
     public SpanNotQueryBuilder post(int post) {
         this.post = (post >= 0) ? post : 0;
         return this;
     }
 
-    /**
-     * @return the amount of tokens after the include span that cant have overlap with the exclude span.
-     * @see SpanNotQueryBuilder#post(int)
-     */
-    public Integer post() {
-        return this.post;
-    }
-
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("include");
-        include.toXContent(builder, params);
-        builder.field("exclude");
-        exclude.toXContent(builder, params);
-        builder.field("pre", pre);
-        builder.field("post", post);
-        printBoostAndQueryName(builder);
-        builder.endObject();
+    public SpanNotQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-
-        Query includeQuery = this.include.toQuery(context);
-        assert includeQuery instanceof SpanQuery;
-        Query excludeQuery = this.exclude.toQuery(context);
-        assert excludeQuery instanceof SpanQuery;
-
-        return new SpanNotQuery((SpanQuery) includeQuery, (SpanQuery) excludeQuery, pre, post);
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     * @param queryName The query name
+     * @return this
+     */
+    public SpanNotQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
         if (include == null) {
-            validationException = addValidationError("inner clause [include] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(include, validationException);
+            throw new IllegalArgumentException("Must specify include when using spanNot query");
         }
         if (exclude == null) {
-            validationException = addValidationError("inner clause [exclude] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(exclude, validationException);
+            throw new IllegalArgumentException("Must specify exclude when using spanNot query");
         }
-        return validationException;
-    }
-
-    @Override
-    protected SpanNotQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder include = (SpanQueryBuilder)in.readQuery();
-        SpanQueryBuilder exclude = (SpanQueryBuilder)in.readQuery();
-        SpanNotQueryBuilder queryBuilder = new SpanNotQueryBuilder(include, exclude);
-        queryBuilder.pre(in.readVInt());
-        queryBuilder.post(in.readVInt());
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(include);
-        out.writeQuery(exclude);
-        out.writeVInt(pre);
-        out.writeVInt(post);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(include, exclude, pre, post);
-    }
 
-    @Override
-    protected boolean doEquals(SpanNotQueryBuilder other) {
-        return Objects.equals(include, other.include) &&
-               Objects.equals(exclude, other.exclude) &&
-               (pre == other.pre) &&
-               (post == other.post);
-    }
+        if (dist != null && (pre != null || post != null)) {
+             throw new IllegalArgumentException("spanNot can either use [dist] or [pre] & [post] (or none)");
+        }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.startObject(SpanNotQueryParser.NAME);
+        builder.field("include");
+        include.toXContent(builder, params);
+        builder.field("exclude");
+        exclude.toXContent(builder, params);
+        if (dist != null) {
+            builder.field("dist", dist);
+        }
+        if (pre != null) {
+            builder.field("pre", pre);
+        }
+        if (post != null) {
+            builder.field("post", post);
+        }
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java
index bc9ee51..bcb62e7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanNotQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_not query
+ *
  */
-public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
+public class SpanNotQueryParser implements QueryParser {
+
+    public static final String NAME = "span_not";
 
     @Inject
     public SpanNotQueryParser() {
@@ -36,17 +41,17 @@ public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{SpanNotQueryBuilder.NAME, Strings.toCamelCase(SpanNotQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanNotQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
-        SpanQueryBuilder include = null;
-        SpanQueryBuilder exclude = null;
+        SpanQuery include = null;
+        SpanQuery exclude = null;
 
         Integer dist = null;
         Integer pre  = null;
@@ -61,17 +66,17 @@ public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("include".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "spanNot [include] must be of type span query");
                     }
-                    include = (SpanQueryBuilder) query;
+                    include = (SpanQuery) query;
                 } else if ("exclude".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "spanNot [exclude] must be of type span query");
                     }
-                    exclude = (SpanQueryBuilder) query;
+                    exclude = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_not] query does not support [" + currentFieldName + "]");
                 }
@@ -101,23 +106,26 @@ public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
             throw new QueryParsingException(parseContext, "spanNot can either use [dist] or [pre] & [post] (or none)");
         }
 
-        SpanNotQueryBuilder spanNotQuery = new SpanNotQueryBuilder(include, exclude);
-        if (dist != null) {
-            spanNotQuery.dist(dist);
+        // set appropriate defaults
+        if (pre != null && post == null) {
+            post = 0;
+        } else if (pre == null && post != null){
+            pre = 0;
         }
-        if (pre != null) {
-            spanNotQuery.pre(pre);
-        }
-        if (post != null) {
-            spanNotQuery.post(post);
+
+        SpanNotQuery query;
+        if (pre != null && post != null) {
+            query = new SpanNotQuery(include, exclude, pre, post);
+        } else if (dist != null) {
+            query = new SpanNotQuery(include, exclude, dist);
+        } else {
+            query = new SpanNotQuery(include, exclude);
         }
-        spanNotQuery.boost(boost);
-        spanNotQuery.queryName(queryName);
-        return spanNotQuery;
-    }
 
-    @Override
-    public SpanNotQueryBuilder getBuilderPrototype() {
-        return SpanNotQueryBuilder.PROTOTYPE;
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java
index 8e9b7ae..0042aa7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java
@@ -19,108 +19,55 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanOrQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.List;
-import java.util.Objects;
 
-/**
- * Span query that matches the union of its clauses. Maps to {@link SpanOrQuery}.
- */
-public class SpanOrQueryBuilder extends AbstractQueryBuilder<SpanOrQueryBuilder> implements SpanQueryBuilder<SpanOrQueryBuilder> {
+public class SpanOrQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanOrQueryBuilder> {
 
-    public static final String NAME = "span_or";
+    private ArrayList<SpanQueryBuilder> clauses = new ArrayList<>();
 
-    private final List<SpanQueryBuilder> clauses = new ArrayList<>();
+    private float boost = -1;
 
-    static final SpanOrQueryBuilder PROTOTYPE = new SpanOrQueryBuilder();
+    private String queryName;
 
     public SpanOrQueryBuilder clause(SpanQueryBuilder clause) {
         clauses.add(clause);
         return this;
     }
 
+    @Override
+    public SpanOrQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
     /**
-     * @return the {@link SpanQueryBuilder} clauses that were set for this query
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public List<SpanQueryBuilder> clauses() {
-        return this.clauses;
+    public SpanOrQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        if (clauses.isEmpty()) {
+            throw new IllegalArgumentException("Must have at least one clause when building a spanOr query");
+        }
+        builder.startObject(SpanOrQueryParser.NAME);
         builder.startArray("clauses");
         for (SpanQueryBuilder clause : clauses) {
             clause.toXContent(builder, params);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        SpanQuery[] spanQueries = new SpanQuery[clauses.size()];
-        for (int i = 0; i < clauses.size(); i++) {
-            Query query = clauses.get(i).toQuery(context);
-            assert query instanceof SpanQuery;
-            spanQueries[i] = (SpanQuery) query;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return new SpanOrQuery(spanQueries);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (clauses.isEmpty()) {
-            validationException =  addValidationError("query must include [clauses]", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        for (SpanQueryBuilder innerClause : clauses) {
-            if (innerClause == null) {
-                validationException =  addValidationError("[clauses] contains null element", validationException);
-            } else {
-                validationException = validateInnerQuery(innerClause, validationException);
-            }
-        }
-        return validationException;
-    }
-
-    @Override
-    protected SpanOrQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        List<QueryBuilder> clauses = readQueries(in);
-        for (QueryBuilder subClause : clauses) {
-            queryBuilder.clauses.add((SpanQueryBuilder)subClause);
-        }
-        return queryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, clauses);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(clauses);
-    }
-
-    @Override
-    protected boolean doEquals(SpanOrQueryBuilder other) {
-        return Objects.equals(clauses, other.clauses);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java
index 6489f9b..e28a9cc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java
@@ -19,32 +19,41 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
- * Parser for span_or query
+ *
  */
-public class SpanOrQueryParser extends BaseQueryParser<SpanOrQueryBuilder> {
+public class SpanOrQueryParser implements QueryParser {
+
+    public static final String NAME = "span_or";
+
+    @Inject
+    public SpanOrQueryParser() {
+    }
 
     @Override
     public String[] names() {
-        return new String[]{SpanOrQueryBuilder.NAME, Strings.toCamelCase(SpanOrQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanOrQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String queryName = null;
 
-        List<SpanQueryBuilder> clauses = newArrayList();
+        List<SpanQuery> clauses = new ArrayList<>();
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -54,11 +63,11 @@ public class SpanOrQueryParser extends BaseQueryParser<SpanOrQueryBuilder> {
             } else if (token == XContentParser.Token.START_ARRAY) {
                 if ("clauses".equals(currentFieldName)) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                        if (!(query instanceof SpanQueryBuilder)) {
+                        Query query = parseContext.parseInnerQuery();
+                        if (!(query instanceof SpanQuery)) {
                             throw new QueryParsingException(parseContext, "spanOr [clauses] must be of type span query");
                         }
-                        clauses.add((SpanQueryBuilder) query);
+                        clauses.add((SpanQuery) query);
                     }
                 } else {
                     throw new QueryParsingException(parseContext, "[span_or] query does not support [" + currentFieldName + "]");
@@ -77,17 +86,11 @@ public class SpanOrQueryParser extends BaseQueryParser<SpanOrQueryBuilder> {
             throw new QueryParsingException(parseContext, "spanOr must include [clauses]");
         }
 
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        for (SpanQueryBuilder clause : clauses) {
-            queryBuilder.clause(clause);
+        SpanOrQuery query = new SpanOrQuery(clauses.toArray(new SpanQuery[clauses.size()]));
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
         }
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
-
-    @Override
-    public SpanOrQueryBuilder getBuilderPrototype() {
-        return SpanOrQueryBuilder.PROTOTYPE;
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java
index d35dcbc..4216f22 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java
@@ -19,9 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-/**
- * Marker interface for a specific type of {@link QueryBuilder} that allows to build span queries
- */
-public interface SpanQueryBuilder<QB extends SpanQueryBuilder> extends QueryBuilder<QB> {
+public abstract class SpanQueryBuilder extends QueryBuilder {
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java
index 24cd816..9d0176e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java
@@ -19,76 +19,75 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.apache.lucene.search.spans.SpanTermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 
-/**
- * A Span Query that matches documents containing a term.
- * @see SpanTermQuery
- */
-public class SpanTermQueryBuilder extends BaseTermQueryBuilder<SpanTermQueryBuilder> implements SpanQueryBuilder<SpanTermQueryBuilder> {
+public class SpanTermQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanTermQueryBuilder> {
+
+    private final String name;
+
+    private final Object value;
+
+    private float boost = -1;
 
-    public static final String NAME = "span_term";
-    static final SpanTermQueryBuilder PROTOTYPE = new SpanTermQueryBuilder(null, null);
+    private String queryName;
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, String) */
     public SpanTermQueryBuilder(String name, String value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, int) */
     public SpanTermQueryBuilder(String name, int value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, long) */
     public SpanTermQueryBuilder(String name, long value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, float) */
     public SpanTermQueryBuilder(String name, float value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, double) */
     public SpanTermQueryBuilder(String name, double value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, Object) */
-    public SpanTermQueryBuilder(String name, Object value) {
-        super(name, value);
+    private SpanTermQueryBuilder(String name, Object value) {
+        this.name = name;
+        this.value = value;
     }
 
     @Override
-    public SpanQuery doToQuery(QueryShardContext context) throws IOException {
-        BytesRef valueBytes = null;
-        String fieldName = this.fieldName;
-        MappedFieldType mapper = context.fieldMapper(fieldName);
-        if (mapper != null) {
-            fieldName = mapper.names().indexName();
-            valueBytes = mapper.indexedValueForSearch(value);
-        }
-        if (valueBytes == null) {
-            valueBytes = BytesRefs.toBytesRef(this.value);
-        }
-        return new SpanTermQuery(new Term(fieldName, valueBytes));
+    public SpanTermQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected SpanTermQueryBuilder createBuilder(String fieldName, Object value) {
-        return new SpanTermQueryBuilder(fieldName, value);
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public SpanTermQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public String getWriteableName() {
-        return NAME;
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(SpanTermQueryParser.NAME);
+        if (boost == -1 && queryName != null) {
+            builder.field(name, value);
+        } else {
+            builder.startObject(name);
+            builder.field("value", value);
+            if (boost != -1) {
+                builder.field("boost", boost);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
+        }
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java
index 824b474..c4ff2ee 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java
@@ -19,16 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
 
 /**
- * Parser for span_term query
+ *
  */
-public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
+public class SpanTermQueryParser implements QueryParser {
+
+    public static final String NAME = "span_term";
 
     @Inject
     public SpanTermQueryParser() {
@@ -36,24 +43,23 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{SpanTermQueryBuilder.NAME, Strings.toCamelCase(SpanTermQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanTermQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.currentToken();
         if (token == XContentParser.Token.START_OBJECT) {
             token = parser.nextToken();
         }
-
         assert token == XContentParser.Token.FIELD_NAME;
         String fieldName = parser.currentName();
 
 
-        Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        String value = null;
+        float boost = 1.0f;
         String queryName = null;
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
@@ -63,9 +69,9 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
                     currentFieldName = parser.currentName();
                 } else {
                     if ("term".equals(currentFieldName)) {
-                        value = parser.objectBytes();
+                        value = parser.text();
                     } else if ("value".equals(currentFieldName)) {
-                        value = parser.objectBytes();
+                        value = parser.text();
                     } else if ("boost".equals(currentFieldName)) {
                         boost = parser.floatValue();
                     } else if ("_name".equals(currentFieldName)) {
@@ -77,7 +83,7 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
             }
             parser.nextToken();
         } else {
-            value = parser.objectBytes();
+            value = parser.text();
             // move to the next token
             parser.nextToken();
         }
@@ -86,13 +92,21 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
             throw new QueryParsingException(parseContext, "No value specified for term query");
         }
 
-        SpanTermQueryBuilder result = new SpanTermQueryBuilder(fieldName, value);
-        result.boost(boost).queryName(queryName);
-        return result;
-    }
+        BytesRef valueBytes = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            fieldName = fieldType.names().indexName();
+            valueBytes = fieldType.indexedValueForSearch(value);
+        }
+        if (valueBytes == null) {
+            valueBytes = new BytesRef(value);
+        }
 
-    @Override
-    public SpanTermQueryBuilder getBuilderPrototype() {
-        return SpanTermQueryBuilder.PROTOTYPE;
+        SpanTermQuery query = new SpanTermQuery(new Term(fieldName, valueBytes));
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java
index 83c7716..d2b2fdc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java
@@ -19,53 +19,59 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.apache.lucene.search.spans.SpanWithinQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * Builder for {@link org.apache.lucene.search.spans.SpanWithinQuery}.
  */
-public class SpanWithinQueryBuilder extends AbstractQueryBuilder<SpanWithinQueryBuilder> implements SpanQueryBuilder<SpanWithinQueryBuilder> {
+public class SpanWithinQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanWithinQueryBuilder> {
 
-    public static final String NAME = "span_within";
-    private final SpanQueryBuilder big;
-    private final SpanQueryBuilder little;
-    static final SpanWithinQueryBuilder PROTOTYPE = new SpanWithinQueryBuilder(null, null);
+    private SpanQueryBuilder big;
+    private SpanQueryBuilder little;
+    private float boost = -1;
+    private String queryName;
 
-    /**
-     * Query that returns spans from <code>little</code> that are contained in a spans from <code>big</code>.
-     * @param big clause that must enclose {@code little} for a match.
-     * @param little the little clause, it must be contained within {@code big} for a match.
+    /** 
+     * Sets the little clause, it must be contained within {@code big} for a match.
      */
-    public SpanWithinQueryBuilder(SpanQueryBuilder big, SpanQueryBuilder little) {
-        this.little = little;
-        this.big = big;
+    public SpanWithinQueryBuilder little(SpanQueryBuilder clause) {
+        this.little = clause;
+        return this;
     }
 
-    /**
-     * @return the little clause, contained within {@code big} for a match.
+    /** 
+     * Sets the big clause, it must enclose {@code little} for a match.
      */
-    public SpanQueryBuilder littleQuery() {
-        return this.little;
+    public SpanWithinQueryBuilder big(SpanQueryBuilder clause) {
+        this.big = clause;
+        return this;
+    }
+
+    @Override
+    public SpanWithinQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
-     * @return the big clause that must enclose {@code little} for a match.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public SpanQueryBuilder bigQuery() {
-        return this.big;
+    public SpanWithinQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        if (big == null) {
+            throw new IllegalArgumentException("Must specify big clause when building a span_within query");
+        }
+        if (little == null) {
+            throw new IllegalArgumentException("Must specify little clause when building a span_within query");
+        }
+        builder.startObject(SpanWithinQueryParser.NAME);
 
         builder.field("big");
         big.toXContent(builder, params);
@@ -73,62 +79,14 @@ public class SpanWithinQueryBuilder extends AbstractQueryBuilder<SpanWithinQuery
         builder.field("little");
         little.toXContent(builder, params);
 
-        printBoostAndQueryName(builder);
-
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerBig = big.toQuery(context);
-        assert innerBig instanceof SpanQuery;
-        Query innerLittle = little.toQuery(context);
-        assert innerLittle instanceof SpanQuery;
-        return new SpanWithinQuery((SpanQuery) innerBig, (SpanQuery) innerLittle);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (big == null) {
-            validationException = addValidationError("inner clause [big] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(big, validationException);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        if (little == null) {
-            validationException = addValidationError("inner clause [little] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(little, validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected SpanWithinQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder big = (SpanQueryBuilder)in.readQuery();
-        SpanQueryBuilder little = (SpanQueryBuilder)in.readQuery();
-        return new SpanWithinQueryBuilder(big, little);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(big);
-        out.writeQuery(little);
-    }
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(big, little);
-    }
-
-    @Override
-    protected boolean doEquals(SpanWithinQueryBuilder other) {
-        return Objects.equals(big, other.big) &&
-               Objects.equals(little, other.little);
-    }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java
index 00ddb0e..9194cbd 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanWithinQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_within query
+ * Parser for {@link SpanWithinQuery}
  */
-public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilder> {
+public class SpanWithinQueryParser implements QueryParser {
+
+    public static final String NAME = "span_within";
 
     @Inject
     public SpanWithinQueryParser() {
@@ -36,17 +41,17 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
 
     @Override
     public String[] names() {
-        return new String[]{SpanWithinQueryBuilder.NAME, Strings.toCamelCase(SpanWithinQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanWithinQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String queryName = null;
-        SpanQueryBuilder big = null;
-        SpanQueryBuilder little = null;
+        SpanQuery big = null;
+        SpanQuery little = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -55,17 +60,17 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("big".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (query instanceof SpanQueryBuilder == false) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (query instanceof SpanQuery == false) {
                         throw new QueryParsingException(parseContext, "span_within [big] must be of type span query");
                     }
-                    big = (SpanQueryBuilder) query;
+                    big = (SpanQuery) query;
                 } else if ("little".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (query instanceof SpanQueryBuilder == false) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (query instanceof SpanQuery == false) {
                         throw new QueryParsingException(parseContext, "span_within [little] must be of type span query");
                     }
-                    little = (SpanQueryBuilder) query;
+                    little = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_within] query does not support [" + currentFieldName + "]");
                 }
@@ -76,8 +81,8 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
             } else {
                 throw new QueryParsingException(parseContext, "[span_within] query does not support [" + currentFieldName + "]");
             }
-        }
-
+        }        
+        
         if (big == null) {
             throw new QueryParsingException(parseContext, "span_within must include [big]");
         }
@@ -85,13 +90,11 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
             throw new QueryParsingException(parseContext, "span_within must include [little]");
         }
 
-        SpanWithinQueryBuilder query = new SpanWithinQueryBuilder(big, little);
-        query.boost(boost).queryName(queryName);
+        Query query = new SpanWithinQuery(big, little);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
         return query;
     }
-
-    @Override
-    public SpanWithinQueryBuilder getBuilderPrototype() {
-        return SpanWithinQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java
index 63721c0..852977f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java
@@ -28,10 +28,7 @@ import java.util.Map;
 /**
  * Facilitates creating template query requests.
  * */
-public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuilder> {
-
-    /** Name to reference this type of query. */
-    public static final String NAME = "template";
+public class TemplateQueryBuilder extends QueryBuilder {
 
     /** Template to fill. */
     private Template template;
@@ -42,8 +39,6 @@ public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuil
 
     private ScriptService.ScriptType templateType;
 
-    static final TemplateQueryBuilder PROTOTYPE = new TemplateQueryBuilder(null, null);
-
     /**
      * @param template
      *            the template to use for that query.
@@ -82,16 +77,11 @@ public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuil
 
     @Override
     protected void doXContent(XContentBuilder builder, Params builderParams) throws IOException {
-        builder.field(TemplateQueryBuilder.NAME);
+        builder.field(TemplateQueryParser.NAME);
         if (template == null) {
             new Template(templateString, templateType, null, null, this.vars).toXContent(builder, builderParams);
         } else {
             template.toXContent(builder, builderParams);
         }
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
index 1a75071..9b289f3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
@@ -38,8 +38,10 @@ import java.util.Map;
  * In the simplest case, parse template string and variables from the request,
  * compile the template and execute the template against the given variables.
  * */
-public class TemplateQueryParser extends BaseQueryParserTemp {
+public class TemplateQueryParser implements QueryParser {
 
+    /** Name to reference this type of query. */
+    public static final String NAME = "template";
     /** Name of query parameter containing the template string. */
     public static final String QUERY = "query";
 
@@ -59,21 +61,20 @@ public class TemplateQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[] {TemplateQueryBuilder.NAME};
+        return new String[] { NAME };
     }
 
     /**
      * Parses the template query replacing template parameters with provided
      * values. Handles both submitting the template as part of the request as
      * well as referencing only the template name.
-     *
-     * @param context
+     * 
+     * @param parseContext
      *            parse context containing the templated query.
      */
     @Override
     @Nullable
-    public Query parse(QueryShardContext context) throws IOException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException {
         XContentParser parser = parseContext.parser();
         Template template = parse(parser, parseContext.parseFieldMatcher());
         ExecutableScript executable = this.scriptService.executable(template, ScriptContext.Standard.SEARCH);
@@ -81,9 +82,9 @@ public class TemplateQueryParser extends BaseQueryParserTemp {
         BytesReference querySource = (BytesReference) executable.run();
 
         try (XContentParser qSourceParser = XContentFactory.xContent(querySource).createParser(querySource)) {
-            final QueryShardContext contextCopy = new QueryShardContext(context.index(), context.indexQueryParserService());
-            contextCopy.reset(qSourceParser);
-            return contextCopy.parseContext().parseInnerQuery();
+            final QueryParseContext context = new QueryParseContext(parseContext.index(), parseContext.indexQueryParserService());
+            context.reset(qSourceParser);
+            return context.parseInnerQuery();
         }
     }
 
@@ -112,9 +113,4 @@ public class TemplateQueryParser extends BaseQueryParserTemp {
     public static Template parse(XContentParser parser, Map<String, ScriptService.ScriptType> parameterMap, ParseFieldMatcher parseFieldMatcher) throws IOException {
         return Template.parse(parser, parameterMap, parseFieldMatcher);
     }
-
-    @Override
-    public TemplateQueryBuilder getBuilderPrototype() {
-        return TemplateQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java
index 5c8bf3f..5bd911a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java
@@ -19,77 +19,128 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 
 /**
  * A Query that matches documents containing a term.
  */
-public class TermQueryBuilder extends BaseTermQueryBuilder<TermQueryBuilder> {
+public class TermQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<TermQueryBuilder> {
 
-    public static final String NAME = "term";
-    static final TermQueryBuilder PROTOTYPE = new TermQueryBuilder(null, null);
+    private final String name;
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, String) */
-    public TermQueryBuilder(String fieldName, String value) {
-        super(fieldName, (Object) value);
+    private final Object value;
+
+    private float boost = -1;
+
+    private String queryName;
+
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, String value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, int) */
-    public TermQueryBuilder(String fieldName, int value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, int value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, long) */
-    public TermQueryBuilder(String fieldName, long value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, long value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, float) */
-    public TermQueryBuilder(String fieldName, float value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, float value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, double) */
-    public TermQueryBuilder(String fieldName, double value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, double value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, boolean) */
-    public TermQueryBuilder(String fieldName, boolean value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, boolean value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, Object) */
-    public TermQueryBuilder(String fieldName, Object value) {
-        super(fieldName, value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, Object value) {
+        this.name = name;
+        this.value = value;
     }
 
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    public Query doToQuery(QueryShardContext context) throws IOException {
-        Query query = null;
-        MappedFieldType mapper = context.fieldMapper(this.fieldName);
-        if (mapper != null) {
-            query = mapper.termQuery(this.value, context);
-        }
-        if (query == null) {
-            query = new TermQuery(new Term(this.fieldName, BytesRefs.toBytesRef(this.value)));
-        }
-        return query;
+    public TermQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected TermQueryBuilder createBuilder(String fieldName, Object value) {
-        return new TermQueryBuilder(fieldName, value);
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public TermQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public String getWriteableName() {
-        return NAME;
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(TermQueryParser.NAME);
+        if (boost == -1 && queryName == null) {
+            builder.field(name, value);
+        } else {
+            builder.startObject(name);
+            builder.field("value", value);
+            if (boost != -1) {
+                builder.field("boost", boost);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
+        }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java
index 4de2910..1c3876f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java
@@ -19,15 +19,26 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
+import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
 
 /**
- * Parser for the term query
+ *
  */
-public class TermQueryParser extends BaseQueryParser<TermQueryBuilder> {
+public class TermQueryParser implements QueryParser {
+
+    public static final String NAME = "term";
+
+    private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of term query");
+    private static final ParseField BOOST_FIELD = new ParseField("boost").withAllDeprecated("boost is not supported in short version of term query");
 
     @Inject
     public TermQueryParser() {
@@ -35,17 +46,17 @@ public class TermQueryParser extends BaseQueryParser<TermQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{TermQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public TermQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String queryName = null;
         String fieldName = null;
         Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String currentFieldName = null;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -77,9 +88,9 @@ public class TermQueryParser extends BaseQueryParser<TermQueryBuilder> {
                     }
                 }
             } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
+                if (parseContext.parseFieldMatcher().match(currentFieldName, NAME_FIELD)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, BOOST_FIELD)) {
                     boost = parser.floatValue();
                 } else {
                     if (fieldName != null) {
@@ -93,16 +104,22 @@ public class TermQueryParser extends BaseQueryParser<TermQueryBuilder> {
             }
         }
 
-        TermQueryBuilder termQuery = new TermQueryBuilder(fieldName, value);
-        termQuery.boost(boost);
-        if (queryName != null) {
-            termQuery.queryName(queryName);
+        if (value == null) {
+            throw new QueryParsingException(parseContext, "No value specified for term query");
         }
-        return termQuery;
-    }
 
-    @Override
-    public TermQueryBuilder getBuilderPrototype() {
-        return TermQueryBuilder.PROTOTYPE;
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.termQuery(value, parseContext);
+        }
+        if (query == null) {
+            query = new TermQuery(new Term(fieldName, BytesRefs.toBytesRef(value)));
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java
index a074e2a..4bdd0da 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java
@@ -19,20 +19,93 @@
 
 package org.elasticsearch.index.query;
 
+import org.elasticsearch.common.xcontent.XContentBuilder;
+
+import java.io.IOException;
 
 /**
- * A filter for a field based on several terms matching on any of them.
- * @deprecated use {@link TermsQueryBuilder} instead.
+ * A filer for a field based on several terms matching on any of them.
  */
-@Deprecated
-public class TermsLookupQueryBuilder extends TermsQueryBuilder {
+public class TermsLookupQueryBuilder extends QueryBuilder {
+
+    private final String name;
+    private String lookupIndex;
+    private String lookupType;
+    private String lookupId;
+    private String lookupRouting;
+    private String lookupPath;
+
+    private String queryName;
 
     public TermsLookupQueryBuilder(String name) {
-        super(name, (Object[]) null);
+        this.name = name;
+    }
+
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public TermsLookupQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
+    /**
+     * Sets the index name to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupIndex(String lookupIndex) {
+        this.lookupIndex = lookupIndex;
+        return this;
+    }
+
+    /**
+     * Sets the index type to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupType(String lookupType) {
+        this.lookupType = lookupType;
+        return this;
+    }
+
+    /**
+     * Sets the doc id to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupId(String lookupId) {
+        this.lookupId = lookupId;
+        return this;
+    }
+
+    /**
+     * Sets the path within the document to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupPath(String lookupPath) {
+        this.lookupPath = lookupPath;
+        return this;
+    }
+
+    public TermsLookupQueryBuilder lookupRouting(String lookupRouting) {
+        this.lookupRouting = lookupRouting;
+        return this;
     }
 
     @Override
-    public String getWriteableName() {
-        return TermsQueryBuilder.NAME;
-   }
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(TermsQueryParser.NAME);
+
+        builder.startObject(name);
+        if (lookupIndex != null) {
+            builder.field("index", lookupIndex);
+        }
+        builder.field("type", lookupType);
+        builder.field("id", lookupId);
+        if (lookupRouting != null) {
+            builder.field("routing", lookupRouting);
+        }
+        builder.field("path", lookupPath);
+        builder.endObject();
+
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+
+        builder.endObject();
+    }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java
index 23af2dd..ca54eb3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java
@@ -19,137 +19,101 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.primitives.Doubles;
-import com.google.common.primitives.Floats;
-import com.google.common.primitives.Ints;
-import com.google.common.primitives.Longs;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-import java.util.Objects;
 
 /**
- * A filter for a field based on several terms matching on any of them.
+ * A filer for a field based on several terms matching on any of them.
  */
-public class TermsQueryBuilder extends AbstractQueryBuilder<TermsQueryBuilder> {
+public class TermsQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<TermsQueryBuilder> {
 
-    public static final String NAME = "terms";
+    private final String name;
 
-    static final TermsQueryBuilder PROTOTYPE = new TermsQueryBuilder(null);
+    private final Object values;
 
-    public static final boolean DEFAULT_DISABLE_COORD = false;
-
-    private final String fieldName;
-    private List<Object> values;
     private String minimumShouldMatch;
-    private boolean disableCoord = DEFAULT_DISABLE_COORD;
-    private TermsLookup termsLookup;
+
+    private Boolean disableCoord;
+
+    private String queryName;
+
+    private float boost = -1;
 
     /**
-     * A filter for a field based on several terms matching on any of them.
-     *
-     * @param fieldName The field name
-     * @param values The terms
-     */
-    public TermsQueryBuilder(String fieldName, String... values) {
-        this(fieldName, values != null ? Arrays.asList(values) : (Iterable<?>) null);
-    }
-    
-    /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, int... values) {
-        this(fieldName, values != null ? Ints.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, String... values) {
+        this(name, (Object[]) values);
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, long... values) {
-        this(fieldName, values != null ? Longs.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, int... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, float... values) {
-        this(fieldName, values != null ? Floats.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, long... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, double... values) {
-        this(fieldName, values != null ? Doubles.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, float... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, Object... values) {
-        this(fieldName, values != null ? Arrays.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, double... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * Constructor used for terms query lookup.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
+     * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName) {
-        this.fieldName = fieldName;
+    public TermsQueryBuilder(String name, Object... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, Iterable<?> values) {
-        if (values == null) {
-            throw new IllegalArgumentException("No value specified for terms query");
-        }
-        this.fieldName = fieldName;
-        this.values = convertToBytesRefListIfStringList(values);
-    }
-
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public List<Object> values() {
-        return convertToStringListIfBytesRefList(this.values);
+    public TermsQueryBuilder(String name, Iterable values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
@@ -162,10 +126,6 @@ public class TermsQueryBuilder extends AbstractQueryBuilder<TermsQueryBuilder> {
         return this;
     }
 
-    public String minimumShouldMatch() {
-        return this.minimumShouldMatch;
-    }
-
     /**
      * Disables <tt>Similarity#coord(int,int)</tt> in scoring. Defaults to <tt>false</tt>.
      * @deprecated use [bool] query instead
@@ -176,254 +136,41 @@ public class TermsQueryBuilder extends AbstractQueryBuilder<TermsQueryBuilder> {
         return this;
     }
 
-    public boolean disableCoord() {
-        return this.disableCoord;
-    }
-
-    private boolean isTermsLookupQuery() {
-        return this.termsLookup != null;
-    }
-
-    public TermsQueryBuilder termsLookup(TermsLookup termsLookup) {
-        this.termsLookup = termsLookup;
-        return this;
-    }
-
-    public TermsLookup termsLookup() {
-        return this.termsLookup;
-    }
-
-    /**
-     * Sets the index name to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupIndex(String lookupIndex) {
-        if (lookupIndex == null) {
-            throw new IllegalArgumentException("Lookup index cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.index(lookupIndex);
-        return this;
-    }
-
-    /**
-     * Sets the type name to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupType(String lookupType) {
-        if (lookupType == null) {
-            throw new IllegalArgumentException("Lookup type cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.type(lookupType);
-        return this;
-    }
-
-    /**
-     * Sets the document id to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupId(String lookupId) {
-        if (lookupId == null) {
-            throw new IllegalArgumentException("Lookup id cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.id(lookupId);
-        return this;
-    }
-
     /**
-     * Sets the path name to lookup the terms from.
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
      */
-    public TermsQueryBuilder lookupPath(String lookupPath) {
-        if (lookupPath == null) {
-            throw new IllegalArgumentException("Lookup path cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.path(lookupPath);
+    public TermsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
         return this;
     }
 
-    /**
-     * Sets the routing to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupRouting(String lookupRouting) {
-        if (lookupRouting == null) {
-            throw new IllegalArgumentException("Lookup routing cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.routing(lookupRouting);
+    @Override
+    public TermsQueryBuilder boost(float boost) {
+        this.boost = boost;
         return this;
     }
 
-    /**
-     * Same as {@link #convertToBytesRefIfString} but on Iterable.
-     * @param objs the Iterable of input object
-     * @return the same input or a list of {@link BytesRef} representation if input was a list of type string
-     */
-    private static List<Object> convertToBytesRefListIfStringList(Iterable<?> objs) {
-        if (objs == null) {
-            return null;
-        }
-        List<Object> newObjs = new ArrayList<>();
-        for (Object obj : objs) {
-            newObjs.add(convertToBytesRefIfString(obj));
-        }
-        return newObjs;
-    }
-
-    /**
-     * Same as {@link #convertToStringIfBytesRef} but on Iterable.
-     * @param objs the Iterable of input object
-     * @return the same input or a list of utf8 string if input was a list of type {@link BytesRef}
-     */
-    private static List<Object> convertToStringListIfBytesRefList(Iterable<?> objs) {
-        if (objs == null) {
-            return null;
-        }
-        List<Object> newObjs = new ArrayList<>();
-        for (Object obj : objs) {
-            newObjs.add(convertToStringIfBytesRef(obj));
-        }
-        return newObjs;
-    }
-
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        if (isTermsLookupQuery()) {
-            builder.startObject(fieldName);
-            termsLookup.toXContent(builder, params);
-            builder.endObject();
-        } else {
-            builder.field(fieldName, convertToStringListIfBytesRefList(values));
-        }
+        builder.startObject(TermsQueryParser.NAME);
+        builder.field(name, values);
+
         if (minimumShouldMatch != null) {
             builder.field("minimum_should_match", minimumShouldMatch);
         }
-        builder.field("disable_coord", disableCoord);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        List<Object> terms;
-        if (isTermsLookupQuery()) {
-            if (termsLookup.index() == null) {
-                termsLookup.index(context.index().name());
-            }
-            terms = context.indexQueryParserService().handleTermsLookup(termsLookup);
-        } else {
-            terms = values;
-        }
-        if (terms == null || terms.isEmpty()) {
-            return Queries.newMatchNoDocsQuery();
-        }
-        return handleTermsQuery(terms, fieldName, context, minimumShouldMatch, disableCoord);
-    }
-
-    private static Query handleTermsQuery(List<Object> terms, String fieldName, QueryShardContext context, String minimumShouldMatch, boolean disableCoord) {
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        String indexFieldName;
-        if (fieldType != null) {
-            indexFieldName = fieldType.names().indexName();
-        } else {
-            indexFieldName = fieldName;
-        }
-
-        Query query;
-        if (context.isFilter()) {
-            if (fieldType != null) {
-                query = fieldType.termsQuery(terms, context);
-            } else {
-                BytesRef[] filterValues = new BytesRef[terms.size()];
-                for (int i = 0; i < filterValues.length; i++) {
-                    filterValues[i] = BytesRefs.toBytesRef(terms.get(i));
-                }
-                query = new TermsQuery(indexFieldName, filterValues);
-            }
-        } else {
-            BooleanQuery bq = new BooleanQuery(disableCoord);
-            for (Object term : terms) {
-                if (fieldType != null) {
-                    bq.add(fieldType.termQuery(term, context), BooleanClause.Occur.SHOULD);
-                } else {
-                    bq.add(new TermQuery(new Term(indexFieldName, BytesRefs.toBytesRef(term))), BooleanClause.Occur.SHOULD);
-                }
-            }
-            Queries.applyMinimumShouldMatch(bq, minimumShouldMatch);
-            query = bq;
-        }
-        return query;
-    }
 
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.fieldName == null) {
-            validationException = addValidationError("field name cannot be null.", validationException);
+        if (disableCoord != null) {
+            builder.field("disable_coord", disableCoord);
         }
-        if (isTermsLookupQuery() && this.values != null) {
-            validationException = addValidationError("can't have both a terms query and a lookup query.", validationException);
-        }
-        if (isTermsLookupQuery()) {
-            QueryValidationException exception = termsLookup.validate();
-            if (exception != null) {
-                validationException = QueryValidationException.addValidationErrors(exception.validationErrors(), validationException);
-            }
-        }
-        return validationException;
-    }
 
-    @SuppressWarnings("unchecked")
-    @Override
-    protected TermsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        TermsQueryBuilder termsQueryBuilder = new TermsQueryBuilder(in.readString());
-        if (in.readBoolean()) {
-            termsQueryBuilder.termsLookup = TermsLookup.readTermsLookupFrom(in);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        termsQueryBuilder.values = ((List<Object>) in.readGenericValue());
-        termsQueryBuilder.minimumShouldMatch = in.readOptionalString();
-        termsQueryBuilder.disableCoord = in.readBoolean();
-        return termsQueryBuilder;
-    }
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeBoolean(isTermsLookupQuery());
-        if (isTermsLookupQuery()) {
-            termsLookup.writeTo(out);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        out.writeGenericValue(values);
-        out.writeOptionalString(minimumShouldMatch);
-        out.writeBoolean(disableCoord);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, values, minimumShouldMatch, disableCoord, termsLookup);
-    }
 
-    @Override
-    protected boolean doEquals(TermsQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(values, other.values) &&
-                Objects.equals(minimumShouldMatch, other.minimumShouldMatch) &&
-                Objects.equals(disableCoord, other.disableCoord) &&
-                Objects.equals(termsLookup, other.termsLookup);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java
index 8d05736..0d5ae09 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java
@@ -19,29 +19,40 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Lists;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.queries.TermsQuery;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.util.BytesRef;
+import org.elasticsearch.action.get.GetRequest;
+import org.elasticsearch.action.get.GetResponse;
+import org.elasticsearch.client.Client;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.support.XContentMapValues;
+import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.indices.cache.query.terms.TermsLookup;
+import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
 /**
- * Parser for terms query and terms lookup.
  *
- * Filters documents that have fields that match any of the provided terms (not analyzed)
- *
- * It also supports a terms lookup mechanism which can be used to fetch the term values from
- * a document in an index.
  */
-public class TermsQueryParser extends BaseQueryParser {
+public class TermsQueryParser implements QueryParser {
 
-    private static final ParseField MIN_SHOULD_MATCH_FIELD = new ParseField("min_match", "min_should_match", "minimum_should_match")
-            .withAllDeprecated("Use [bool] query instead");
+    public static final String NAME = "terms";
+    private static final ParseField MIN_SHOULD_MATCH_FIELD = new ParseField("min_match", "min_should_match").withAllDeprecated("Use [bool] query instead");
     private static final ParseField DISABLE_COORD_FIELD = new ParseField("disable_coord").withAllDeprecated("Use [bool] query instead");
     private static final ParseField EXECUTION_FIELD = new ParseField("execution").withAllDeprecated("execution is deprecated and has no effect");
+    private Client client;
 
     @Inject
     public TermsQueryParser() {
@@ -49,24 +60,34 @@ public class TermsQueryParser extends BaseQueryParser {
 
     @Override
     public String[] names() {
-        return new String[]{TermsQueryBuilder.NAME, "in"};
+        return new String[]{NAME, "in"};
+    }
+
+    @Inject(optional = true)
+    public void setClient(Client client) {
+        this.client = client;
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        String fieldName = null;
-        List<Object> values = null;
+        String queryName = null;
+        String currentFieldName = null;
+
+        String lookupIndex = parseContext.index().name();
+        String lookupType = null;
+        String lookupId = null;
+        String lookupPath = null;
+        String lookupRouting = null;
         String minShouldMatch = null;
-        boolean disableCoord = TermsQueryBuilder.DEFAULT_DISABLE_COORD;
-        TermsLookup termsLookup = null;
 
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        boolean disableCoord = false;
 
         XContentParser.Token token;
-        String currentFieldName = null;
+        List<Object> terms = new ArrayList<>();
+        String fieldName = null;
+        float boost = 1f;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -77,16 +98,51 @@ public class TermsQueryParser extends BaseQueryParser {
                     throw new QueryParsingException(parseContext, "[terms] query does not support multiple fields");
                 }
                 fieldName = currentFieldName;
-                values = parseValues(parseContext, parser);
+
+                while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
+                    Object value = parser.objectBytes();
+                    if (value == null) {
+                        throw new QueryParsingException(parseContext, "No value specified for terms query");
+                    }
+                    terms.add(value);
+                }
             } else if (token == XContentParser.Token.START_OBJECT) {
                 fieldName = currentFieldName;
-                termsLookup = parseTermsLookup(parseContext, parser);
+                while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
+                    if (token == XContentParser.Token.FIELD_NAME) {
+                        currentFieldName = parser.currentName();
+                    } else if (token.isValue()) {
+                        if ("index".equals(currentFieldName)) {
+                            lookupIndex = parser.text();
+                        } else if ("type".equals(currentFieldName)) {
+                            lookupType = parser.text();
+                        } else if ("id".equals(currentFieldName)) {
+                            lookupId = parser.text();
+                        } else if ("path".equals(currentFieldName)) {
+                            lookupPath = parser.text();
+                        } else if ("routing".equals(currentFieldName)) {
+                            lookupRouting = parser.textOrNull();
+                        } else {
+                            throw new QueryParsingException(parseContext, "[terms] query does not support [" + currentFieldName
+                                    + "] within lookup element");
+                        }
+                    }
+                }
+                if (lookupType == null) {
+                    throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the type");
+                }
+                if (lookupId == null) {
+                    throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the id");
+                }
+                if (lookupPath == null) {
+                    throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the path");
+                }
             } else if (token.isValue()) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, EXECUTION_FIELD)) {
                     // ignore
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, MIN_SHOULD_MATCH_FIELD)) {
                     if (minShouldMatch != null) {
-                        throw new IllegalArgumentException("[" + currentFieldName + "] is not allowed in a filter context for the [" + TermsQueryBuilder.NAME + "] query");
+                        throw new IllegalArgumentException("[" + currentFieldName + "] is not allowed in a filter context for the [" + NAME + "] query");
                     }
                     minShouldMatch = parser.textOrNull();
                 } else if ("boost".equals(currentFieldName)) {
@@ -102,73 +158,57 @@ public class TermsQueryParser extends BaseQueryParser {
         }
 
         if (fieldName == null) {
-            throw new QueryParsingException(parseContext, "terms query requires a field name, followed by array of terms or a document lookup specification");
+            throw new QueryParsingException(parseContext, "terms query requires a field name, followed by array of terms");
         }
-        TermsQueryBuilder termsQueryBuilder;
-        if (values == null) {
-            termsQueryBuilder = new TermsQueryBuilder(fieldName);
-        } else {
-            termsQueryBuilder = new TermsQueryBuilder(fieldName, values);
+
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            fieldName = fieldType.names().indexName();
         }
-        return termsQueryBuilder
-                .disableCoord(disableCoord)
-                .minimumShouldMatch(minShouldMatch)
-                .termsLookup(termsLookup)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    private static List<Object> parseValues(QueryParseContext parseContext, XContentParser parser) throws IOException {
-        List<Object> values = Lists.newArrayList();
-        XContentParser.Token token;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-            Object value = parser.objectBytes();
-            if (value == null) {
-                throw new QueryParsingException(parseContext, "No value specified for terms query");
+        if (lookupId != null) {
+            final TermsLookup lookup = new TermsLookup(lookupIndex, lookupType, lookupId, lookupRouting, lookupPath, parseContext);
+            GetRequest getRequest = new GetRequest(lookup.getIndex(), lookup.getType(), lookup.getId()).preference("_local").routing(lookup.getRouting());
+            getRequest.copyContextAndHeadersFrom(SearchContext.current());
+            final GetResponse getResponse = client.get(getRequest).actionGet();
+            if (getResponse.isExists()) {
+                List<Object> values = XContentMapValues.extractRawValues(lookup.getPath(), getResponse.getSourceAsMap());
+                terms.addAll(values);
             }
-            values.add(value);
         }
-        return values;
-    }
 
-    private static TermsLookup parseTermsLookup(QueryParseContext parseContext, XContentParser parser) throws IOException {
-        TermsLookup termsLookup = new TermsLookup();
-        XContentParser.Token token;
-        String currentFieldName = null;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                currentFieldName = parser.currentName();
-            } else if (token.isValue()) {
-                if ("index".equals(currentFieldName)) {
-                    termsLookup.index(parser.textOrNull());
-                } else if ("type".equals(currentFieldName)) {
-                    termsLookup.type(parser.text());
-                } else if ("id".equals(currentFieldName)) {
-                    termsLookup.id(parser.text());
-                } else if ("routing".equals(currentFieldName)) {
-                    termsLookup.routing(parser.textOrNull());
-                } else if ("path".equals(currentFieldName)) {
-                    termsLookup.path(parser.text());
+        if (terms.isEmpty()) {
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        Query query;
+        if (parseContext.isFilter()) {
+            if (fieldType != null) {
+                query = fieldType.termsQuery(terms, parseContext);
+            } else {
+                BytesRef[] filterValues = new BytesRef[terms.size()];
+                for (int i = 0; i < filterValues.length; i++) {
+                    filterValues[i] = BytesRefs.toBytesRef(terms.get(i));
+                }
+                query = new TermsQuery(fieldName, filterValues);
+            }
+        } else {
+            BooleanQuery bq = new BooleanQuery(disableCoord);
+            for (Object term : terms) {
+                if (fieldType != null) {
+                    bq.add(fieldType.termQuery(term, parseContext), Occur.SHOULD);
                 } else {
-                    throw new QueryParsingException(parseContext, "[terms] query does not support [" + currentFieldName
-                            + "] within lookup element");
+                    bq.add(new TermQuery(new Term(fieldName, BytesRefs.toBytesRef(term))), Occur.SHOULD);
                 }
             }
+            Queries.applyMinimumShouldMatch(bq, minShouldMatch);
+            query = bq;
         }
-        if (termsLookup.type() == null) {
-            throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the type");
-        }
-        if (termsLookup.id() == null) {
-            throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the id");
-        }
-        if (termsLookup.path() == null) {
-            throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the path");
-        }
-        return termsLookup;
-    }
+        query.setBoost(boost);
 
-    @Override
-    public TermsQueryBuilder getBuilderPrototype() {
-        return TermsQueryBuilder.PROTOTYPE;
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java
index 9f89a94..2a9a6c5 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java
@@ -19,92 +19,22 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class TypeQueryBuilder extends AbstractQueryBuilder<TypeQueryBuilder> {
+public class TypeQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "type";
-
-    private final BytesRef type;
-
-    static final TypeQueryBuilder PROTOTYPE = new TypeQueryBuilder((BytesRef) null);
+    private final String type;
 
     public TypeQueryBuilder(String type) {
-        this.type = BytesRefs.toBytesRef(type);
-    }
-
-    TypeQueryBuilder(BytesRef type) {
         this.type = type;
     }
 
-    public String type() {
-        return BytesRefs.toString(this.type);
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("value", type.utf8ToString());
-        printBoostAndQueryName(builder);
+        builder.startObject(TypeQueryParser.NAME);
+        builder.field("value", type);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query filter;
-        //LUCENE 4 UPGRADE document mapper should use bytesref as well?
-        DocumentMapper documentMapper = context.mapperService().documentMapper(type.utf8ToString());
-        if (documentMapper == null) {
-            filter = new TermQuery(new Term(TypeFieldMapper.NAME, type));
-        } else {
-            filter = documentMapper.typeFilter();
-        }
-        return filter;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (type == null) {
-            validationException = addValidationError("[type] cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected TypeQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new TypeQueryBuilder(in.readBytesRef());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeBytesRef(type);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(type);
-    }
-
-    @Override
-    protected boolean doEquals(TypeQueryBuilder other) {
-        return Objects.equals(type, other.type);
-    }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java
index ee5e772..e4b7889 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java
@@ -19,16 +19,20 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.DocumentMapper;
+import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 
 import java.io.IOException;
 
-/**
- * Parser for type query
- */
-public class TypeQueryParser extends BaseQueryParser<TypeQueryBuilder> {
+public class TypeQueryParser implements QueryParser {
+
+    public static final String NAME = "type";
 
     @Inject
     public TypeQueryParser() {
@@ -36,45 +40,37 @@ public class TypeQueryParser extends BaseQueryParser<TypeQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{TypeQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public TypeQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        BytesRef type = null;
 
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-
-        String currentFieldName = null;
-        XContentParser.Token token;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                currentFieldName = parser.currentName();
-            } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
-                } else if ("value".equals(currentFieldName)) {
-                    type = parser.utf8Bytes();
-                }
-            } else {
-                throw new QueryParsingException(parseContext, "[type] filter doesn't support [" + currentFieldName + "]");
-            }
+        XContentParser.Token token = parser.nextToken();
+        if (token != XContentParser.Token.FIELD_NAME) {
+            throw new QueryParsingException(parseContext, "[type] filter should have a value field, and the type name");
         }
-
-        if (type == null) {
-            throw new QueryParsingException(parseContext, "[type] filter needs to be provided with a value for the type");
+        String fieldName = parser.currentName();
+        if (!fieldName.equals("value")) {
+            throw new QueryParsingException(parseContext, "[type] filter should have a value field, and the type name");
         }
-        return new TypeQueryBuilder(type)
-                .boost(boost)
-                .queryName(queryName);
-    }
+        token = parser.nextToken();
+        if (token != XContentParser.Token.VALUE_STRING) {
+            throw new QueryParsingException(parseContext, "[type] filter should have a value field, and the type name");
+        }
+        BytesRef type = parser.utf8Bytes();
+        // move to the next token
+        parser.nextToken();
 
-    @Override
-    public TypeQueryBuilder getBuilderPrototype() {
-        return TypeQueryBuilder.PROTOTYPE;
+        Query filter;
+        //LUCENE 4 UPGRADE document mapper should use bytesref as well? 
+        DocumentMapper documentMapper = parseContext.mapperService().documentMapper(type.utf8ToString());
+        if (documentMapper == null) {
+            filter = new TermQuery(new Term(TypeFieldMapper.NAME, type));
+        } else {
+            filter = documentMapper.typeFilter();
+        }
+        return filter;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java
index 89b753e..654f14e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java
@@ -19,20 +19,9 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.WildcardQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * Implements the wildcard search query. Supported wildcards are <tt>*</tt>, which
@@ -42,17 +31,17 @@ import java.util.Objects;
  * a Wildcard term should not start with one of the wildcards <tt>*</tt> or
  * <tt>?</tt>.
  */
-public class WildcardQueryBuilder extends AbstractQueryBuilder<WildcardQueryBuilder> implements MultiTermQueryBuilder<WildcardQueryBuilder> {
+public class WildcardQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<WildcardQueryBuilder> {
 
-    public static final String NAME = "wildcard";
+    private final String name;
 
-    private final String fieldName;
+    private final String wildcard;
 
-    private final String value;
+    private float boost = -1;
 
     private String rewrite;
 
-    static final WildcardQueryBuilder PROTOTYPE = new WildcardQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * Implements the wildcard search query. Supported wildcards are <tt>*</tt>, which
@@ -62,20 +51,12 @@ public class WildcardQueryBuilder extends AbstractQueryBuilder<WildcardQueryBuil
      * a Wildcard term should not start with one of the wildcards <tt>*</tt> or
      * <tt>?</tt>.
      *
-     * @param fieldName The field name
-     * @param value The wildcard query string
+     * @param name     The field name
+     * @param wildcard The wildcard query string
      */
-    public WildcardQueryBuilder(String fieldName, String value) {
-        this.fieldName = fieldName;
-        this.value = value;
-    }
-
-    public String fieldName() {
-        return fieldName;
-    }
-
-    public String value() {
-        return value;
+    public WildcardQueryBuilder(String name, String wildcard) {
+        this.name = name;
+        this.wildcard = wildcard;
     }
 
     public WildcardQueryBuilder rewrite(String rewrite) {
@@ -83,83 +64,43 @@ public class WildcardQueryBuilder extends AbstractQueryBuilder<WildcardQueryBuil
         return this;
     }
 
-    public String rewrite() {
-        return this.rewrite;
-    }
-
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    public String getWriteableName() {
-        return NAME;
+    public WildcardQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("wildcard", value);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
-        }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public WildcardQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        String indexFieldName;
-        BytesRef valueBytes;
-
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            indexFieldName = fieldType.names().indexName();
-            valueBytes = fieldType.indexedValueForSearch(value);
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(WildcardQueryParser.NAME);
+        if (boost == -1 && rewrite == null && queryName == null) {
+            builder.field(name, wildcard);
         } else {
-            indexFieldName = fieldName;
-            valueBytes = new BytesRef(value);
+            builder.startObject(name);
+            builder.field("wildcard", wildcard);
+            if (boost != -1) {
+                builder.field("boost", boost);
+            }
+            if (rewrite != null) {
+                builder.field("rewrite", rewrite);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
         }
-
-        WildcardQuery query = new WildcardQuery(new Term(indexFieldName, valueBytes));
-        MultiTermQuery.RewriteMethod rewriteMethod = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-        QueryParsers.setRewriteMethod(query, rewriteMethod);
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.value == null) {
-            validationException = addValidationError("wildcard cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected WildcardQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        WildcardQueryBuilder wildcardQueryBuilder = new WildcardQueryBuilder(in.readString(), in.readString());
-        wildcardQueryBuilder.rewrite = in.readOptionalString();
-        return wildcardQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeString(value);
-        out.writeOptionalString(rewrite);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, value, rewrite);
-    }
-
-    @Override
-    protected boolean doEquals(WildcardQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java
index d3b3e26..da92db4 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java
@@ -19,15 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.WildcardQuery;
+import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
 /**
- * Parser for wildcard query
+ *
  */
-public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
+public class WildcardQueryParser implements QueryParser {
+
+    public static final String NAME = "wildcard";
 
     @Inject
     public WildcardQueryParser() {
@@ -35,11 +43,11 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{WildcardQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public WildcardQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.nextToken();
@@ -47,10 +55,10 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
             throw new QueryParsingException(parseContext, "[wildcard] query malformed, no field");
         }
         String fieldName = parser.currentName();
-        String rewrite = null;
+        String rewriteMethod = null;
 
         String value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String queryName = null;
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
@@ -66,7 +74,7 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
                     } else if ("boost".equals(currentFieldName)) {
                         boost = parser.floatValue();
                     } else if ("rewrite".equals(currentFieldName)) {
-                        rewrite = parser.textOrNull();
+                        rewriteMethod = parser.textOrNull();
                     } else if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
                     } else {
@@ -83,14 +91,22 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
         if (value == null) {
             throw new QueryParsingException(parseContext, "No value specified for prefix query");
         }
-        return new WildcardQueryBuilder(fieldName, value)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    @Override
-    public WildcardQueryBuilder getBuilderPrototype() {
-        return WildcardQueryBuilder.PROTOTYPE;
+        BytesRef valueBytes;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            fieldName = fieldType.names().indexName();
+            valueBytes = fieldType.indexedValueForSearch(value);
+        } else {
+            valueBytes = new BytesRef(value);
+        }
+
+        WildcardQuery wildcardQuery = new WildcardQuery(new Term(fieldName, valueBytes));
+        QueryParsers.setRewriteMethod(wildcardQuery, parseContext.parseFieldMatcher(), rewriteMethod);
+        wildcardQuery.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, wildcardQuery);
+        }
+        return wildcardQuery;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java
index 7be9293..6fde3c7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java
@@ -20,16 +20,10 @@
 package org.elasticsearch.index.query;
 
 import com.google.common.base.Charsets;
-import org.apache.lucene.search.Query;
 import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
-import java.util.Arrays;
 
 /**
  * A Query builder which allows building a query given JSON string or binary data provided as input. This is useful when you want
@@ -45,24 +39,28 @@ import java.util.Arrays;
  * }
  * </pre>
  */
-public class WrapperQueryBuilder extends AbstractQueryBuilder<WrapperQueryBuilder> {
+public class WrapperQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "wrapper";
     private final byte[] source;
-    static final WrapperQueryBuilder PROTOTYPE = new WrapperQueryBuilder((byte[]) null);
+    private final int offset;
+    private final int length;
 
     /**
      * Creates a query builder given a query provided as a string
      */
     public WrapperQueryBuilder(String source) {
         this.source = source.getBytes(Charsets.UTF_8);
+        this.offset = 0;
+        this.length = this.source.length;
     }
 
     /**
      * Creates a query builder given a query provided as a bytes array
      */
-    public WrapperQueryBuilder(byte[] source) {
+    public WrapperQueryBuilder(byte[] source, int offset, int length) {
         this.source = source;
+        this.offset = offset;
+        this.length = length;
     }
 
     /**
@@ -70,66 +68,14 @@ public class WrapperQueryBuilder extends AbstractQueryBuilder<WrapperQueryBuilde
      */
     public WrapperQueryBuilder(BytesReference source) {
         this.source = source.array();
-    }
-
-    public byte[] source() {
-        return this.source;
-    }
-
-    @Override
-    public String getName() {
-        return NAME;
+        this.offset = source.arrayOffset();
+        this.length = source.length();
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("query", source);
+        builder.startObject(WrapperQueryParser.NAME);
+        builder.field("query", source, offset, length);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        try (XContentParser qSourceParser = XContentFactory.xContent(source).createParser(source)) {
-            final QueryShardContext contextCopy = new QueryShardContext(context.index(), context.indexQueryParserService());
-            contextCopy.reset(qSourceParser);
-            QueryBuilder result = contextCopy.parseContext().parseInnerQueryBuilder();
-            context.combineNamedQueries(contextCopy);
-            return result.toQuery(context);
-        }
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.source == null || this.source.length == 0) {
-            validationException = addValidationError("query source text cannot be null or empty", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected WrapperQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new WrapperQueryBuilder(in.readByteArray());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeByteArray(this.source);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Arrays.hashCode(source);
-    }
-
-    @Override
-    protected boolean doEquals(WrapperQueryBuilder other) {
-        return Arrays.equals(source, other.source);   // otherwise we compare pointers
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java
index cd9eb83..331ba78 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java
@@ -19,7 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
@@ -27,7 +29,9 @@ import java.io.IOException;
 /**
  * Query parser for JSON Queries.
  */
-public class WrapperQueryParser extends BaseQueryParser {
+public class WrapperQueryParser implements QueryParser {
+
+    public static final String NAME = "wrapper";
 
     @Inject
     public WrapperQueryParser() {
@@ -35,11 +39,11 @@ public class WrapperQueryParser extends BaseQueryParser {
 
     @Override
     public String[] names() {
-        return new String[]{WrapperQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.nextToken();
@@ -52,18 +56,14 @@ public class WrapperQueryParser extends BaseQueryParser {
         }
         parser.nextToken();
 
-        byte[] source = parser.binaryValue();
-
-        parser.nextToken();
-
-        if (source == null) {
-            throw new QueryParsingException(parseContext, "wrapper query has no [query] specified");
+        byte[] querySource = parser.binaryValue();
+        try (XContentParser qSourceParser = XContentFactory.xContent(querySource).createParser(querySource)) {
+            final QueryParseContext context = new QueryParseContext(parseContext.index(), parseContext.indexQueryParserService());
+            context.reset(qSourceParser);
+            Query result = context.parseInnerQuery();
+            parser.nextToken();
+            parseContext.combineNamedQueries(context);
+            return result;
         }
-        return new WrapperQueryBuilder(source);
-    }
-
-    @Override
-    public WrapperQueryBuilder getBuilderPrototype() {
-        return WrapperQueryBuilder.PROTOTYPE;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
index 7580c84..3dc2427 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.core.DateFieldMapper;
 import org.elasticsearch.index.mapper.core.NumberFieldMapper;
 import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionBuilder;
 import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionParser;
@@ -119,7 +119,7 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
      *
      * */
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
         String currentFieldName;
         XContentParser.Token token;
         AbstractDistanceScoreFunction scoreFunction;
@@ -132,7 +132,7 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
             if (token == XContentParser.Token.START_OBJECT) {
                 variableContent.copyCurrentStructure(parser);
                 fieldName = currentFieldName;
-            } else if (context.parseFieldMatcher().match(currentFieldName, MULTI_VALUE_MODE)) {
+            } else if (parseContext.parseFieldMatcher().match(currentFieldName, MULTI_VALUE_MODE)) {
                 multiValueMode = parser.text();
             } else {
                 throw new ElasticsearchParseException("malformed score function score parameters.");
@@ -142,34 +142,34 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
             throw new ElasticsearchParseException("malformed score function score parameters.");
         }
         XContentParser variableParser = XContentFactory.xContent(variableContent.string()).createParser(variableContent.string());
-        scoreFunction = parseVariable(fieldName, variableParser, context, MultiValueMode.fromString(multiValueMode.toUpperCase(Locale.ROOT)));
+        scoreFunction = parseVariable(fieldName, variableParser, parseContext, MultiValueMode.fromString(multiValueMode.toUpperCase(Locale.ROOT)));
         return scoreFunction;
     }
 
     // parses origin and scale parameter for field "fieldName"
-    private AbstractDistanceScoreFunction parseVariable(String fieldName, XContentParser parser, QueryShardContext context, MultiValueMode mode) throws IOException {
+    private AbstractDistanceScoreFunction parseVariable(String fieldName, XContentParser parser, QueryParseContext parseContext, MultiValueMode mode) throws IOException {
 
         // now, the field must exist, else we cannot read the value for
         // the doc later
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
-            throw new QueryParsingException(context.parseContext(), "unknown field [{}]", fieldName);
+            throw new QueryParsingException(parseContext, "unknown field [{}]", fieldName);
         }
 
         // dates and time need special handling
         parser.nextToken();
         if (fieldType instanceof DateFieldMapper.DateFieldType) {
-            return parseDateVariable(fieldName, parser, context, (DateFieldMapper.DateFieldType) fieldType, mode);
+            return parseDateVariable(fieldName, parser, parseContext, (DateFieldMapper.DateFieldType) fieldType, mode);
         } else if (fieldType instanceof GeoPointFieldMapper.GeoPointFieldType) {
-            return parseGeoVariable(fieldName, parser, context, (GeoPointFieldMapper.GeoPointFieldType) fieldType, mode);
+            return parseGeoVariable(fieldName, parser, parseContext, (GeoPointFieldMapper.GeoPointFieldType) fieldType, mode);
         } else if (fieldType instanceof NumberFieldMapper.NumberFieldType) {
-            return parseNumberVariable(fieldName, parser, context, (NumberFieldMapper.NumberFieldType) fieldType, mode);
+            return parseNumberVariable(fieldName, parser, parseContext, (NumberFieldMapper.NumberFieldType) fieldType, mode);
         } else {
-            throw new QueryParsingException(context.parseContext(), "field [{}] is of type [{}], but only numeric types are supported.", fieldName, fieldType);
+            throw new QueryParsingException(parseContext, "field [{}] is of type [{}], but only numeric types are supported.", fieldName, fieldType);
         }
     }
 
-    private AbstractDistanceScoreFunction parseNumberVariable(String fieldName, XContentParser parser, QueryShardContext context,
+    private AbstractDistanceScoreFunction parseNumberVariable(String fieldName, XContentParser parser, QueryParseContext parseContext,
             NumberFieldMapper.NumberFieldType fieldType, MultiValueMode mode) throws IOException {
         XContentParser.Token token;
         String parameterName = null;
@@ -199,11 +199,11 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
         if (!scaleFound || !refFound) {
             throw new ElasticsearchParseException("both [{}] and [{}] must be set for numeric fields.", DecayFunctionBuilder.SCALE, DecayFunctionBuilder.ORIGIN);
         }
-        IndexNumericFieldData numericFieldData = context.getForField(fieldType);
+        IndexNumericFieldData numericFieldData = parseContext.getForField(fieldType);
         return new NumericFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), numericFieldData, mode);
     }
 
-    private AbstractDistanceScoreFunction parseGeoVariable(String fieldName, XContentParser parser, QueryShardContext context,
+    private AbstractDistanceScoreFunction parseGeoVariable(String fieldName, XContentParser parser, QueryParseContext parseContext,
             GeoPointFieldMapper.GeoPointFieldType fieldType, MultiValueMode mode) throws IOException {
         XContentParser.Token token;
         String parameterName = null;
@@ -231,12 +231,12 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
         }
         double scale = DistanceUnit.DEFAULT.parse(scaleString, DistanceUnit.DEFAULT);
         double offset = DistanceUnit.DEFAULT.parse(offsetString, DistanceUnit.DEFAULT);
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
         return new GeoFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), indexFieldData, mode);
 
     }
 
-    private AbstractDistanceScoreFunction parseDateVariable(String fieldName, XContentParser parser, QueryShardContext context,
+    private AbstractDistanceScoreFunction parseDateVariable(String fieldName, XContentParser parser, QueryParseContext parseContext,
             DateFieldMapper.DateFieldType dateFieldType, MultiValueMode mode) throws IOException {
         XContentParser.Token token;
         String parameterName = null;
@@ -271,7 +271,7 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
         double scale = val.getMillis();
         val = TimeValue.parseTimeValue(offsetString, TimeValue.timeValueHours(24), getClass().getSimpleName() + ".offset");
         double offset = val.getMillis();
-        IndexNumericFieldData numericFieldData = context.getForField(dateFieldType);
+        IndexNumericFieldData numericFieldData = parseContext.getForField(dateFieldType);
         return new NumericFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), numericFieldData, mode);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
index 3880592..dc7571a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
@@ -21,7 +21,7 @@ package org.elasticsearch.index.query.functionscore;
 
 import org.elasticsearch.common.lucene.search.function.CombineFunction;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.AbstractQueryBuilder;
+import org.elasticsearch.index.query.BoostableQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
 
 import java.io.IOException;
@@ -31,12 +31,14 @@ import java.util.ArrayList;
  * A query that uses a filters with a script associated with them to compute the
  * score.
  */
-public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScoreQueryBuilder> {
+public class FunctionScoreQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<FunctionScoreQueryBuilder> {
 
     private final QueryBuilder queryBuilder;
 
     private final QueryBuilder filterBuilder;
 
+    private Float boost;
+
     private Float maxBoost;
 
     private String scoreMode;
@@ -47,8 +49,6 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
     private ArrayList<ScoreFunctionBuilder> scoreFunctions = new ArrayList<>();
     private Float minScore = null;
 
-    static final FunctionScoreQueryBuilder PROTOTYPE = new FunctionScoreQueryBuilder();
-
     /**
      * Creates a function_score query that executes on documents that match query a query.
      * Query and filter will be wrapped into a filtered_query.
@@ -143,6 +143,17 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
         return this;
     }
 
+    /**
+     * Sets the boost for this query. Documents matching this query will (in
+     * addition to the normal weightings) have their score multiplied by the
+     * boost provided.
+     */
+    @Override
+    public FunctionScoreQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject(FunctionScoreQueryParser.NAME);
@@ -175,10 +186,13 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
         if (maxBoost != null) {
             builder.field("max_boost", maxBoost);
         }
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
         if (minScore != null) {
             builder.field("min_score", minScore);
         }
-        printBoostAndQueryName(builder);
+
         builder.endObject();
     }
 
@@ -186,9 +200,4 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
         this.minScore = minScore;
         return this;
     }
-
-    @Override
-    public String getWriteableName() {
-        return FunctionScoreQueryParser.NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
index 3df6b78..02fc425 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
@@ -37,7 +37,9 @@ import org.elasticsearch.common.lucene.search.function.FunctionScoreQuery;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.lucene.search.function.WeightFactorFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParser;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.factor.FactorParser;
 
 import java.io.IOException;
@@ -45,7 +47,7 @@ import java.util.ArrayList;
 import java.util.Arrays;
 
 /**
- * Parser for function_score query
+ *
  */
 public class FunctionScoreQueryParser implements QueryParser {
 
@@ -82,14 +84,12 @@ public class FunctionScoreQueryParser implements QueryParser {
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         Query query = null;
         Query filter = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        String queryName = null;
+        float boost = 1.0f;
 
         FiltersFunctionScoreQuery.ScoreMode scoreMode = FiltersFunctionScoreQuery.ScoreMode.Multiply;
         ArrayList<FiltersFunctionScoreQuery.FilterFunction> filterFunctions = new ArrayList<>();
@@ -119,8 +119,6 @@ public class FunctionScoreQueryParser implements QueryParser {
                 maxBoost = parser.floatValue();
             } else if ("boost".equals(currentFieldName)) {
                 boost = parser.floatValue();
-            } else if ("_name".equals(currentFieldName)) {
-                queryName = parser.text();
             } else if ("min_score".equals(currentFieldName) || "minScore".equals(currentFieldName)) {
                 minScore = parser.floatValue();
             } else if ("functions".equals(currentFieldName)) {
@@ -128,7 +126,7 @@ public class FunctionScoreQueryParser implements QueryParser {
                     String errorString = "already found [" + singleFunctionName + "], now encountering [functions].";
                     handleMisplacedFunctionsDeclaration(errorString, singleFunctionName);
                 }
-                currentFieldName = parseFiltersAndFunctions(context, parser, filterFunctions, currentFieldName);
+                currentFieldName = parseFiltersAndFunctions(parseContext, parser, filterFunctions, currentFieldName);
                 functionArrayFound = true;
             } else {
                 ScoreFunction scoreFunction;
@@ -139,7 +137,7 @@ public class FunctionScoreQueryParser implements QueryParser {
                     // we try to parse a score function. If there is no score
                     // function for the current field name,
                     // functionParserMapper.get() will throw an Exception.
-                    scoreFunction = functionParserMapper.get(parseContext, currentFieldName).parse(context, parser);
+                    scoreFunction = functionParserMapper.get(parseContext, currentFieldName).parse(parseContext, parser);
                 }
                 if (functionArrayFound) {
                     String errorString = "already found [functions] array, now encountering [" + currentFieldName + "].";
@@ -170,7 +168,6 @@ public class FunctionScoreQueryParser implements QueryParser {
         if (maxBoost == null) {
             maxBoost = Float.MAX_VALUE;
         }
-        Query result;
         // handle cases where only one score function and no filter was
         // provided. In this case we create a FunctionScoreQuery.
         if (filterFunctions.size() == 0 || filterFunctions.size() == 1 && (filterFunctions.get(0).filter == null || Queries.isConstantMatchAllQuery(filterFunctions.get(0).filter))) {
@@ -179,8 +176,9 @@ public class FunctionScoreQueryParser implements QueryParser {
             if (combineFunction != null) {
                 theQuery.setCombineFunction(combineFunction);
             }
+            theQuery.setBoost(boost);
             theQuery.setMaxBoost(maxBoost);
-            result = theQuery;
+            return theQuery;
             // in all other cases we create a FiltersFunctionScoreQuery.
         } else {
             FiltersFunctionScoreQuery functionScoreQuery = new FiltersFunctionScoreQuery(query, scoreMode,
@@ -188,13 +186,9 @@ public class FunctionScoreQueryParser implements QueryParser {
             if (combineFunction != null) {
                 functionScoreQuery.setCombineFunction(combineFunction);
             }
-            result = functionScoreQuery;
-        }
-        result.setBoost(boost);
-        if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            functionScoreQuery.setBoost(boost);
+            return functionScoreQuery;
         }
-        return result;
     }
 
     private void handleMisplacedFunctionsDeclaration(String errorString, String functionName) {
@@ -205,9 +199,8 @@ public class FunctionScoreQueryParser implements QueryParser {
         throw new ElasticsearchParseException("failed to parse [{}] query. [{}]", NAME, errorString);
     }
 
-    private String parseFiltersAndFunctions(QueryShardContext context, XContentParser parser,
+    private String parseFiltersAndFunctions(QueryParseContext parseContext, XContentParser parser,
                                             ArrayList<FiltersFunctionScoreQuery.FilterFunction> filterFunctions, String currentFieldName) throws IOException {
-        QueryParseContext parseContext = context.parseContext();
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
             Query filter = null;
@@ -229,7 +222,7 @@ public class FunctionScoreQueryParser implements QueryParser {
                             // functionParserMapper throws exception if parser
                             // non-existent
                             ScoreFunctionParser functionParser = functionParserMapper.get(parseContext, currentFieldName);
-                            scoreFunction = functionParser.parse(context, parser);
+                            scoreFunction = functionParser.parse(parseContext, parser);
                         }
                     }
                 }
@@ -276,16 +269,4 @@ public class FunctionScoreQueryParser implements QueryParser {
         }
         return cf;
     }
-
-    //norelease to be removed once all queries are moved over to extend BaseQueryParser
-    @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-        Query query = parse(parseContext.shardContext());
-        return new QueryWrappingQueryBuilder(query);
-    }
-
-    @Override
-    public FunctionScoreQueryBuilder getBuilderPrototype() {
-        return FunctionScoreQueryBuilder.PROTOTYPE;
-    }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
index 4065f08..74c3d08 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
@@ -21,14 +21,14 @@ package org.elasticsearch.index.query.functionscore;
 
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 
 import java.io.IOException;
 
 public interface ScoreFunctionParser {
 
-    ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException;
+    ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException;
 
     /**
      * Returns the name of the function, for example "linear", "gauss" etc. This
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorParser.java
index 2635c2b..a1c8d20 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorParser.java
@@ -19,13 +19,14 @@
 
 package org.elasticsearch.index.query.functionscore.factor;
 
+import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
+
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.function.BoostScoreFunction;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
 
 import java.io.IOException;
 
@@ -42,7 +43,7 @@ public class FactorParser implements ScoreFunctionParser {
     }
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
         float boostFactor = parser.floatValue();
         return new BoostScoreFunction(boostFactor);
     }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
index a91d954..e6a8f2d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
@@ -24,8 +24,8 @@ import org.elasticsearch.common.lucene.search.function.FieldValueFactorFunction;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.fielddata.IndexNumericFieldData;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
@@ -52,8 +52,7 @@ public class FieldValueFactorFunctionParser implements ScoreFunctionParser {
     public static String[] NAMES = { "field_value_factor", "fieldValueFactor" };
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
 
         String currentFieldName = null;
         String field = null;
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
index 20c2f55..124336c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
@@ -27,8 +27,8 @@ import org.elasticsearch.common.lucene.search.function.RandomScoreFunction;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.fielddata.IndexFieldData;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
@@ -51,8 +51,8 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
     }
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
+
         int seed = -1;
 
         String currentFieldName = null;
@@ -90,7 +90,7 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
         }
 
         if (seed == -1) {
-            seed = Longs.hashCode(context.nowInMillis());
+            seed = Longs.hashCode(parseContext.nowInMillis());
         }
         final ShardId shardId = SearchContext.current().indexShard().shardId();
         final int salt = (shardId.index().name().hashCode() << 10) | shardId.id();
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
index 38a29f3..2cf066f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
@@ -21,11 +21,11 @@
 
 package org.elasticsearch.index.query.functionscore.script;
 
+import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.lucene.search.function.ScriptScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
@@ -58,8 +58,7 @@ public class ScriptScoreFunctionParser implements ScoreFunctionParser {
     }
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
         ScriptParameterParser scriptParameterParser = new ScriptParameterParser();
         Script script = null;
         Map<String, Object> vars = null;
@@ -101,7 +100,7 @@ public class ScriptScoreFunctionParser implements ScoreFunctionParser {
 
         SearchScript searchScript;
         try {
-            searchScript = context.scriptService().search(context.lookup(), script, ScriptContext.Standard.SEARCH);
+            searchScript = parseContext.scriptService().search(parseContext.lookup(), script, ScriptContext.Standard.SEARCH);
             return new ScriptScoreFunction(script, searchScript);
         } catch (Exception e) {
             throw new QueryParsingException(parseContext, NAMES[0] + " the script could not be loaded", e);
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java b/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java
index 6e59d01..b4d3e63 100644
--- a/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java
+++ b/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java
@@ -19,13 +19,12 @@
 
 package org.elasticsearch.index.query.support;
 
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.fetch.fielddata.FieldDataFieldsParseElement;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
 import org.elasticsearch.search.fetch.script.ScriptFieldsParseElement;
 import org.elasticsearch.search.fetch.source.FetchSourceParseElement;
 import org.elasticsearch.search.highlight.HighlighterParseElement;
@@ -52,7 +51,7 @@ public class InnerHitsQueryParserHelper {
         this.fieldDataFieldsParseElement = fieldDataFieldsParseElement;
     }
 
-    public Tuple<String, SubSearchContext> parse(QueryParseContext parserContext) throws IOException, QueryShardException {
+    public InnerHitsSubSearchContext parse(QueryParseContext parserContext) throws IOException, QueryParsingException {
         String fieldName = null;
         XContentParser.Token token;
         String innerHitName = null;
@@ -75,7 +74,7 @@ public class InnerHitsQueryParserHelper {
         } catch (Exception e) {
             throw new QueryParsingException(parserContext, "Failed to parse [_inner_hits]", e);
         }
-        return new Tuple<>(innerHitName, subSearchContext);
+        return new InnerHitsSubSearchContext(innerHitName, subSearchContext);
     }
 
     public static void parseCommonInnerHitOptions(XContentParser parser, XContentParser.Token token, String fieldName, SubSearchContext subSearchContext,
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java b/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java
index 8c90f28..49e1a21 100644
--- a/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java
+++ b/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java
@@ -28,9 +28,8 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
-import org.elasticsearch.index.query.QueryShardContext;
-import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
@@ -42,7 +41,6 @@ import java.io.IOException;
  */
 public class NestedInnerQueryParseSupport {
 
-    protected final QueryShardContext shardContext;
     protected final QueryParseContext parseContext;
 
     private BytesReference source;
@@ -62,15 +60,12 @@ public class NestedInnerQueryParseSupport {
     private ObjectMapper parentObjectMapper;
 
     public NestedInnerQueryParseSupport(XContentParser parser, SearchContext searchContext) {
-        parseContext = searchContext.queryParserService().getShardContext().parseContext();
-        shardContext = searchContext.queryParserService().getShardContext();
-        shardContext.reset(parser);
-
+        parseContext = searchContext.queryParserService().getParseContext();
+        parseContext.reset(parser);
     }
 
-    public NestedInnerQueryParseSupport(QueryShardContext context) {
-        this.parseContext = context.parseContext();
-        this.shardContext = context;
+    public NestedInnerQueryParseSupport(QueryParseContext parseContext) {
+        this.parseContext = parseContext;
     }
 
     public void query() throws IOException {
@@ -108,10 +103,10 @@ public class NestedInnerQueryParseSupport {
             return innerQuery;
         } else {
             if (path == null) {
-                throw new QueryShardException(shardContext, "[nested] requires 'path' field");
+                throw new QueryParsingException(parseContext, "[nested] requires 'path' field");
             }
             if (!queryFound) {
-                throw new QueryShardException(shardContext, "[nested] requires either 'query' or 'filter' field");
+                throw new QueryParsingException(parseContext, "[nested] requires either 'query' or 'filter' field");
             }
 
             XContentParser old = parseContext.parser();
@@ -137,10 +132,10 @@ public class NestedInnerQueryParseSupport {
             return innerFilter;
         } else {
             if (path == null) {
-                throw new QueryShardException(shardContext, "[nested] requires 'path' field");
+                throw new QueryParsingException(parseContext, "[nested] requires 'path' field");
             }
             if (!filterFound) {
-                throw new QueryShardException(shardContext, "[nested] requires either 'query' or 'filter' field");
+                throw new QueryParsingException(parseContext, "[nested] requires either 'query' or 'filter' field");
             }
 
             setPathLevel();
@@ -160,12 +155,12 @@ public class NestedInnerQueryParseSupport {
 
     public void setPath(String path) {
         this.path = path;
-        nestedObjectMapper = shardContext.getObjectMapper(path);
+        nestedObjectMapper = parseContext.getObjectMapper(path);
         if (nestedObjectMapper == null) {
-            throw new QueryShardException(shardContext, "[nested] failed to find nested object under path [" + path + "]");
+            throw new QueryParsingException(parseContext, "[nested] failed to find nested object under path [" + path + "]");
         }
         if (!nestedObjectMapper.nested().isNested()) {
-            throw new QueryShardException(shardContext, "[nested] nested object under path [" + path + "] is not of nested type");
+            throw new QueryParsingException(parseContext, "[nested] nested object under path [" + path + "] is not of nested type");
         }
     }
 
@@ -190,18 +185,18 @@ public class NestedInnerQueryParseSupport {
     }
 
     private void setPathLevel() {
-        ObjectMapper objectMapper = shardContext.nestedScope().getObjectMapper();
+        ObjectMapper objectMapper = parseContext.nestedScope().getObjectMapper();
         if (objectMapper == null) {
-            parentFilter = shardContext.bitsetFilter(Queries.newNonNestedFilter());
+            parentFilter = parseContext.bitsetFilter(Queries.newNonNestedFilter());
         } else {
-            parentFilter = shardContext.bitsetFilter(objectMapper.nestedTypeFilter());
+            parentFilter = parseContext.bitsetFilter(objectMapper.nestedTypeFilter());
         }
         childFilter = nestedObjectMapper.nestedTypeFilter();
-        parentObjectMapper = shardContext.nestedScope().nextLevel(nestedObjectMapper);
+        parentObjectMapper = parseContext.nestedScope().nextLevel(nestedObjectMapper);
     }
 
     private void resetPathLevel() {
-        shardContext.nestedScope().previousLevel();
+        parseContext.nestedScope().previousLevel();
     }
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java b/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java
index a500393..1a12c74 100644
--- a/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java
+++ b/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java
@@ -29,12 +29,12 @@ import org.elasticsearch.common.ParseFieldMatcher;
  */
 public final class QueryParsers {
 
-    public static final ParseField CONSTANT_SCORE = new ParseField("constant_score", "constant_score_auto", "constant_score_filter");
-    public static final ParseField SCORING_BOOLEAN = new ParseField("scoring_boolean");
-    public static final ParseField CONSTANT_SCORE_BOOLEAN = new ParseField("constant_score_boolean");
-    public static final ParseField TOP_TERMS = new ParseField("top_terms_");
-    public static final ParseField TOP_TERMS_BOOST = new ParseField("top_terms_boost_");
-    public static final ParseField TOP_TERMS_BLENDED_FREQS = new ParseField("top_terms_blended_freqs_");
+    private static final ParseField CONSTANT_SCORE = new ParseField("constant_score", "constant_score_auto", "constant_score_filter");
+    private static final ParseField SCORING_BOOLEAN = new ParseField("scoring_boolean");
+    private static final ParseField CONSTANT_SCORE_BOOLEAN = new ParseField("constant_score_boolean");
+    private static final ParseField TOP_TERMS = new ParseField("top_terms_");
+    private static final ParseField TOP_TERMS_BOOST = new ParseField("top_terms_boost_");
+    private static final ParseField TOP_TERMS_BLENDED_FREQS = new ParseField("top_terms_blended_freqs_");
 
     private QueryParsers() {
 
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/XContentStructure.java b/core/src/main/java/org/elasticsearch/index/query/support/XContentStructure.java
index cd8fd27..37716d1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/support/XContentStructure.java
+++ b/core/src/main/java/org/elasticsearch/index/query/support/XContentStructure.java
@@ -25,7 +25,6 @@ import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
@@ -85,14 +84,14 @@ public abstract class XContentStructure {
         BytesReference br = this.bytes();
         assert br != null : "innerBytes must be set with .bytes(bytes) or .freeze() before parsing";
         XContentParser innerParser = XContentHelper.createParser(br);
-        String[] origTypes = QueryShardContext.setTypesWithPrevious(types);
+        String[] origTypes = QueryParseContext.setTypesWithPrevious(types);
         XContentParser old = parseContext.parser();
         parseContext.parser(innerParser);
         try {
             return parseContext.parseInnerQuery();
         } finally {
             parseContext.parser(old);
-            QueryShardContext.setTypes(origTypes);
+            QueryParseContext.setTypes(origTypes);
         }
     }
 
@@ -107,12 +106,12 @@ public abstract class XContentStructure {
         public InnerQuery(QueryParseContext parseContext1, @Nullable String... types) throws IOException {
             super(parseContext1);
             if (types != null) {
-                String[] origTypes = QueryShardContext.setTypesWithPrevious(types);
+                String[] origTypes = QueryParseContext.setTypesWithPrevious(types);
                 try {
                     query = parseContext1.parseInnerQuery();
                     queryParsed = true;
                 } finally {
-                    QueryShardContext.setTypes(origTypes);
+                    QueryParseContext.setTypes(origTypes);
                 }
             } else {
                 BytesReference innerBytes = XContentFactory.smileBuilder().copyCurrentStructure(parseContext1.parser()).bytes();
diff --git a/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java b/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java
index 0b5dae6..fb5fff8 100644
--- a/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java
@@ -30,7 +30,7 @@ import org.elasticsearch.common.lucene.search.MultiPhrasePrefixQuery;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
@@ -49,7 +49,7 @@ public class MatchQuery {
         ALL
     }
 
-    protected final QueryShardContext context;
+    protected final QueryParseContext parseContext;
 
     protected String analyzer;
 
@@ -60,9 +60,9 @@ public class MatchQuery {
     protected int phraseSlop = 0;
 
     protected Fuzziness fuzziness = null;
-
+    
     protected int fuzzyPrefixLength = FuzzyQuery.defaultPrefixLength;
-
+    
     protected int maxExpansions = FuzzyQuery.defaultMaxExpansions;
 
     protected boolean transpositions = FuzzyQuery.defaultTranspositions;
@@ -72,11 +72,11 @@ public class MatchQuery {
     protected boolean lenient;
 
     protected ZeroTermsQuery zeroTermsQuery = ZeroTermsQuery.NONE;
-
+    
     protected Float commonTermsCutoff = null;
-
-    public MatchQuery(QueryShardContext context) {
-        this.context = context;
+    
+    public MatchQuery(QueryParseContext parseContext) {
+        this.parseContext = parseContext;
     }
 
     public void setAnalyzer(String analyzer) {
@@ -86,7 +86,7 @@ public class MatchQuery {
     public void setOccur(BooleanClause.Occur occur) {
         this.occur = occur;
     }
-
+    
     public void setCommonTermsCutoff(float cutoff) {
         this.commonTermsCutoff = Float.valueOf(cutoff);
     }
@@ -134,11 +134,11 @@ public class MatchQuery {
     protected Analyzer getAnalyzer(MappedFieldType fieldType) {
         if (this.analyzer == null) {
             if (fieldType != null) {
-                return context.getSearchAnalyzer(fieldType);
+                return parseContext.getSearchAnalyzer(fieldType);
             }
-            return context.mapperService().searchAnalyzer();
+            return parseContext.mapperService().searchAnalyzer();
         } else {
-            Analyzer analyzer = context.mapperService().analysisService().analyzer(this.analyzer);
+            Analyzer analyzer = parseContext.mapperService().analysisService().analyzer(this.analyzer);
             if (analyzer == null) {
                 throw new IllegalArgumentException("No analyzer found for [" + this.analyzer + "]");
             }
@@ -148,7 +148,7 @@ public class MatchQuery {
 
     public Query parse(Type type, String fieldName, Object value) throws IOException {
         final String field;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType != null) {
             field = fieldType.names().indexName();
         } else {
@@ -157,14 +157,14 @@ public class MatchQuery {
 
         if (fieldType != null && fieldType.useTermQueryWithQueryString() && !forceAnalyzeQueryString()) {
             try {
-                return fieldType.termQuery(value, context);
+                return fieldType.termQuery(value, parseContext);
             } catch (RuntimeException e) {
                 if (lenient) {
                     return null;
                 }
                 throw e;
             }
-
+            
         }
         Analyzer analyzer = getAnalyzer(fieldType);
         assert analyzer != null;
diff --git a/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java b/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java
index b85dcfd..621e7d0 100644
--- a/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java
@@ -29,9 +29,10 @@ import org.apache.lucene.search.Query;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.lucene.search.Queries;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.query.MultiMatchQueryBuilder;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -47,10 +48,10 @@ public class MultiMatchQuery extends MatchQuery {
         this.groupTieBreaker = tieBreaker;
     }
 
-    public MultiMatchQuery(QueryShardContext context) {
-        super(context);
+    public MultiMatchQuery(QueryParseContext parseContext) {
+        super(parseContext);
     }
-
+    
     private Query parseAndApply(Type type, String fieldName, Object value, String minimumShouldMatch, Float boostValue) throws IOException {
         Query query = parse(type, fieldName, value);
         if (query instanceof BooleanQuery) {
@@ -162,7 +163,7 @@ public class MultiMatchQuery extends MatchQuery {
             List<Tuple<String, Float>> missing = new ArrayList<>();
             for (Map.Entry<String, Float> entry : fieldNames.entrySet()) {
                 String name = entry.getKey();
-                MappedFieldType fieldType = context.fieldMapper(name);
+                MappedFieldType fieldType = parseContext.fieldMapper(name);
                 if (fieldType != null) {
                     Analyzer actualAnalyzer = getAnalyzer(fieldType);
                     name = fieldType.names().indexName();
diff --git a/core/src/main/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQuery.java b/core/src/main/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQuery.java
index 82ba626..5548499 100644
--- a/core/src/main/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQuery.java
@@ -103,11 +103,8 @@ public class ChildrenConstantScoreQuery extends IndexCacheableQuery {
             return new BooleanQuery().createWeight(searcher, needsScores);
         }
 
-        IndexSearcher indexSearcher = new IndexSearcher(searcher.getIndexReader());
-        indexSearcher.setSimilarity(searcher.getSimilarity(true));
-        indexSearcher.setQueryCache(null);
         ParentOrdCollector collector = new ParentOrdCollector(globalIfd, valueCount, parentType);
-        indexSearcher.search(childQuery, collector);
+        searcher.search(childQuery, collector);
 
         final long remaining = collector.foundParents();
         if (remaining == 0) {
diff --git a/core/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java b/core/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java
index ffa2e34..c07ccba 100644
--- a/core/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java
@@ -152,9 +152,6 @@ public final class ChildrenQuery extends IndexCacheableQuery {
             // No docs of the specified type exist on this shard
             return new BooleanQuery().createWeight(searcher, needsScores);
         }
-        IndexSearcher indexSearcher = new IndexSearcher(searcher.getIndexReader());
-        indexSearcher.setSimilarity(searcher.getSimilarity(true));
-        indexSearcher.setQueryCache(null);
 
         boolean abort = true;
         long numFoundParents;
@@ -193,7 +190,7 @@ public final class ChildrenQuery extends IndexCacheableQuery {
                 }
             }
 
-            indexSearcher.search(childQuery, collector);
+            searcher.search(childQuery, collector);
             numFoundParents = collector.foundParents();
             if (numFoundParents == 0) {
                 return new BooleanQuery().createWeight(searcher, needsScores);
diff --git a/core/src/main/java/org/elasticsearch/index/search/child/ParentConstantScoreQuery.java b/core/src/main/java/org/elasticsearch/index/search/child/ParentConstantScoreQuery.java
index 31ad5f6..bad3913 100644
--- a/core/src/main/java/org/elasticsearch/index/search/child/ParentConstantScoreQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/search/child/ParentConstantScoreQuery.java
@@ -22,16 +22,7 @@ import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.FilteredDocIdSetIterator;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.*;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.LongBitSet;
 import org.elasticsearch.common.lucene.IndexCacheableQuery;
@@ -92,10 +83,7 @@ public class ParentConstantScoreQuery extends IndexCacheableQuery {
         }
 
         ParentOrdsCollector collector = new ParentOrdsCollector(globalIfd, maxOrd, parentType);
-        IndexSearcher indexSearcher = new IndexSearcher(searcher.getIndexReader());
-        indexSearcher.setSimilarity(searcher.getSimilarity(true));
-        indexSearcher.setQueryCache(null);
-        indexSearcher.search(parentQuery, collector);
+        searcher.search(parentQuery, collector);
 
         if (collector.parentCount() == 0) {
             return new BooleanQuery().createWeight(searcher, needsScores);
diff --git a/core/src/main/java/org/elasticsearch/index/search/child/ParentQuery.java b/core/src/main/java/org/elasticsearch/index/search/child/ParentQuery.java
index 4f74d9a..d574066 100644
--- a/core/src/main/java/org/elasticsearch/index/search/child/ParentQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/search/child/ParentQuery.java
@@ -129,10 +129,7 @@ public class ParentQuery extends IndexCacheableQuery {
 
         try {
             collector = new ParentOrdAndScoreCollector(sc, globalIfd, parentType);
-            IndexSearcher indexSearcher = new IndexSearcher(sc.searcher().getIndexReader());
-            indexSearcher.setSimilarity(searcher.getSimilarity(true));
-            indexSearcher.setQueryCache(null);
-            indexSearcher.search(parentQuery, collector);
+            searcher.search(parentQuery, collector);
             if (collector.parentCount() == 0) {
                 return new BooleanQuery().createWeight(searcher, needsScores);
             }
diff --git a/core/src/main/java/org/elasticsearch/index/search/termslookup/TermsLookupFetchService.java b/core/src/main/java/org/elasticsearch/index/search/termslookup/TermsLookupFetchService.java
deleted file mode 100644
index b787344..0000000
--- a/core/src/main/java/org/elasticsearch/index/search/termslookup/TermsLookupFetchService.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.search.termslookup;
-
-import org.elasticsearch.action.get.GetRequest;
-import org.elasticsearch.action.get.GetResponse;
-import org.elasticsearch.client.Client;
-import org.elasticsearch.common.component.AbstractComponent;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.support.XContentMapValues;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
-import org.elasticsearch.search.internal.SearchContext;
-
-import java.util.ArrayList;
-import java.util.List;
-
-/**
- * Service which retrieves terms from a {@link TermsLookup} specification
- */
-public class TermsLookupFetchService extends AbstractComponent {
-
-    private final Client client;
-
-    @Inject
-    public TermsLookupFetchService(Client client, Settings settings) {
-        super(settings);
-        this.client = client;
-    }
-
-    public List<Object> fetch(TermsLookup termsLookup) {
-        List<Object> terms = new ArrayList<>();
-        GetRequest getRequest = new GetRequest(termsLookup.index(), termsLookup.type(), termsLookup.id())
-                .preference("_local").routing(termsLookup.routing());
-        getRequest.copyContextAndHeadersFrom(SearchContext.current());
-        final GetResponse getResponse = client.get(getRequest).actionGet();
-        if (getResponse.isExists()) {
-            List<Object> extractedValues = XContentMapValues.extractRawValues(termsLookup.path(), getResponse.getSourceAsMap());
-            terms.addAll(extractedValues);
-        }
-        return terms;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/shard/CommitPoints.java b/core/src/main/java/org/elasticsearch/index/shard/CommitPoints.java
index a56a0f6..ff06850 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/CommitPoints.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/CommitPoints.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.index.shard;
 
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
@@ -28,6 +27,7 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentType;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Comparator;
 import java.util.Iterator;
 import java.util.List;
@@ -130,8 +130,8 @@ public class CommitPoints implements Iterable<CommitPoint> {
             long version = -1;
             String name = null;
             CommitPoint.Type type = null;
-            List<CommitPoint.FileInfo> indexFiles = Lists.newArrayList();
-            List<CommitPoint.FileInfo> translogFiles = Lists.newArrayList();
+            List<CommitPoint.FileInfo> indexFiles = new ArrayList<>();
+            List<CommitPoint.FileInfo> translogFiles = new ArrayList<>();
             while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                 if (token == XContentParser.Token.FIELD_NAME) {
                     currentFieldName = parser.currentName();
diff --git a/core/src/main/java/org/elasticsearch/index/shard/ElasticsearchMergePolicy.java b/core/src/main/java/org/elasticsearch/index/shard/ElasticsearchMergePolicy.java
index 7e3435b..c8d0379 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/ElasticsearchMergePolicy.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/ElasticsearchMergePolicy.java
@@ -19,8 +19,12 @@
 
 package org.elasticsearch.index.shard;
 
-import com.google.common.collect.Lists;
-import org.apache.lucene.index.*;
+import org.apache.lucene.index.CodecReader;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.MergePolicy;
+import org.apache.lucene.index.MergeTrigger;
+import org.apache.lucene.index.SegmentCommitInfo;
+import org.apache.lucene.index.SegmentInfos;
 import org.apache.lucene.store.Directory;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.logging.ESLogger;
@@ -28,6 +32,7 @@ import org.elasticsearch.common.logging.Loggers;
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 
@@ -153,7 +158,7 @@ public final class ElasticsearchMergePolicy extends MergePolicy {
                     // TODO: Use IndexUpgradeMergePolicy instead.  We should be comparing codecs,
                     // for now we just assume every minor upgrade has a new format.
                     logger.debug("Adding segment " + info.info.name + " to be upgraded");
-                    spec.add(new OneMerge(Lists.newArrayList(info)));
+                    spec.add(new OneMerge(Collections.singletonList(info)));
                 }
 
                 // TODO: we could check IndexWriter.getMergingSegments and avoid adding merges that IW will just reject?
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
index e60b046..1021798 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
@@ -21,17 +21,10 @@ package org.elasticsearch.index.shard;
 
 import com.google.common.base.Charsets;
 import com.google.common.base.Preconditions;
-
 import org.apache.lucene.codecs.PostingsFormat;
 import org.apache.lucene.index.CheckIndex;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.DisjunctionMaxQuery;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.MatchNoDocsQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryCachingPolicy;
-import org.apache.lucene.search.UsageTrackingQueryCachingPolicy;
+import org.apache.lucene.search.*;
 import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.ThreadInterruptedException;
@@ -48,7 +41,6 @@ import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.ShardRoutingState;
 import org.elasticsearch.common.Booleans;
 import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.logging.ESLogger;
@@ -506,13 +498,13 @@ public class IndexShard extends AbstractIndexShardComponent {
         }
     }
 
-    static Engine.Create prepareCreate(Tuple<DocumentMapper, Mapping> docMapper, SourceToParse source, long version, VersionType versionType, Engine.Operation.Origin origin, boolean canHaveDuplicates, boolean autoGeneratedId) {
+    static Engine.Create prepareCreate(DocumentMapperForType docMapper, SourceToParse source, long version, VersionType versionType, Engine.Operation.Origin origin, boolean canHaveDuplicates, boolean autoGeneratedId) {
         long startTime = System.nanoTime();
-        ParsedDocument doc = docMapper.v1().parse(source);
-        if (docMapper.v2() != null) {
-            doc.addDynamicMappingsUpdate(docMapper.v2());
+        ParsedDocument doc = docMapper.getDocumentMapper().parse(source);
+        if (docMapper.getMapping() != null) {
+            doc.addDynamicMappingsUpdate(docMapper.getMapping());
         }
-        return new Engine.Create(docMapper.v1().uidMapper().term(doc.uid().stringValue()), doc, version, versionType, origin, startTime, canHaveDuplicates, autoGeneratedId);
+        return new Engine.Create(docMapper.getDocumentMapper().uidMapper().term(doc.uid().stringValue()), doc, version, versionType, origin, startTime, canHaveDuplicates, autoGeneratedId);
     }
 
     public void create(Engine.Create create) {
@@ -540,13 +532,13 @@ public class IndexShard extends AbstractIndexShardComponent {
         }
     }
 
-    static Engine.Index prepareIndex(Tuple<DocumentMapper, Mapping> docMapper, SourceToParse source, long version, VersionType versionType, Engine.Operation.Origin origin, boolean canHaveDuplicates) {
+    static Engine.Index prepareIndex(DocumentMapperForType docMapper, SourceToParse source, long version, VersionType versionType, Engine.Operation.Origin origin, boolean canHaveDuplicates) {
         long startTime = System.nanoTime();
-        ParsedDocument doc = docMapper.v1().parse(source);
-        if (docMapper.v2() != null) {
-            doc.addDynamicMappingsUpdate(docMapper.v2());
+        ParsedDocument doc = docMapper.getDocumentMapper().parse(source);
+        if (docMapper.getMapping() != null) {
+            doc.addDynamicMappingsUpdate(docMapper.getMapping());
         }
-        return new Engine.Index(docMapper.v1().uidMapper().term(doc.uid().stringValue()), doc, version, versionType, origin, startTime, canHaveDuplicates);
+        return new Engine.Index(docMapper.getDocumentMapper().uidMapper().term(doc.uid().stringValue()), doc, version, versionType, origin, startTime, canHaveDuplicates);
     }
 
     /**
@@ -573,7 +565,7 @@ public class IndexShard extends AbstractIndexShardComponent {
 
     public Engine.Delete prepareDelete(String type, String id, long version, VersionType versionType, Engine.Operation.Origin origin) {
         long startTime = System.nanoTime();
-        final DocumentMapper documentMapper = docMapper(type).v1();
+        final DocumentMapper documentMapper = docMapper(type).getDocumentMapper();
         return new Engine.Delete(type, id, documentMapper.uidMapper().term(Uid.createUid(type, id)), version, versionType, origin, startTime, false);
     }
 
@@ -1389,7 +1381,7 @@ public class IndexShard extends AbstractIndexShardComponent {
         return indexSettings.get(IndexMetaData.SETTING_INDEX_UUID, IndexMetaData.INDEX_UUID_NA_VALUE);
     }
 
-    private Tuple<DocumentMapper, Mapping> docMapper(String type) {
+    private DocumentMapperForType docMapper(String type) {
         return mapperService.documentMapperWithAutoCreate(type);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java b/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java
index e22659c..8feed27 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/ShardPath.java
@@ -20,6 +20,7 @@ package org.elasticsearch.index.shard;
 
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
+import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.env.NodeEnvironment;
@@ -41,10 +42,18 @@ public final class ShardPath {
     private final String indexUUID;
     private final ShardId shardId;
     private final Path shardStatePath;
-
-
-    public ShardPath(Path path, Path shardStatePath, String indexUUID, ShardId shardId) {
-        this.path = path;
+    private final boolean isCustomDataPath;
+
+    public ShardPath(boolean isCustomDataPath, Path dataPath, Path shardStatePath, String indexUUID, ShardId shardId) {
+        assert dataPath.getFileName().toString().equals(Integer.toString(shardId.id())) : "dataPath must end with the shard ID but didn't: " + dataPath.toString();
+        assert shardStatePath.getFileName().toString().equals(Integer.toString(shardId.id())) : "shardStatePath must end with the shard ID but didn't: " + dataPath.toString();
+        assert dataPath.getParent().getFileName().toString().equals(shardId.getIndex()) : "dataPath must end with index/shardID but didn't: " + dataPath.toString();
+        assert shardStatePath.getParent().getFileName().toString().equals(shardId.getIndex()) : "shardStatePath must end with index/shardID but didn't: " + dataPath.toString();
+        if (isCustomDataPath && dataPath.equals(shardStatePath)) {
+            throw new IllegalArgumentException("shard state path must be different to the data path when using custom data paths");
+        }
+        this.isCustomDataPath = isCustomDataPath;
+        this.path = dataPath;
         this.indexUUID = indexUUID;
         this.shardId = shardId;
         this.shardStatePath = shardStatePath;
@@ -79,6 +88,30 @@ public final class ShardPath {
     }
 
     /**
+     * Returns the data-path root for this shard. The root is a parent of {@link #getDataPath()} without the index name
+     * and the shard ID.
+     */
+    public Path getRootDataPath() {
+        Path noIndexShardId = getDataPath().getParent().getParent();
+        return isCustomDataPath ? noIndexShardId : noIndexShardId.getParent(); // also strip the indices folder
+    }
+
+    /**
+     * Returns the state-path root for this shard. The root is a parent of {@link #getRootStatePath()} ()} without the index name
+     * and the shard ID.
+     */
+    public Path getRootStatePath() {
+        return getShardStatePath().getParent().getParent().getParent(); // also strip the indices folder
+    }
+
+    /**
+     * Returns <code>true</code> iff the data location is a custom data location and therefore outside of the nodes configured data paths.
+     */
+    public boolean isCustomDataPath() {
+        return isCustomDataPath;
+    }
+
+    /**
      * This method walks through the nodes shard paths to find the data and state path for the given shard. If multiple
      * directories with a valid shard state exist the one with the highest version will be used.
      * <b>Note:</b> this method resolves custom data locations for the shard.
@@ -113,7 +146,7 @@ public final class ShardPath {
                 dataPath = statePath;
             }
             logger.debug("{} loaded data path [{}], state path [{}]", shardId, dataPath, statePath);
-            return new ShardPath(dataPath, statePath, indexUUID, shardId);
+            return new ShardPath(NodeEnvironment.hasCustomDataPath(indexSettings), dataPath, statePath, indexUUID, shardId);
         }
     }
 
@@ -202,7 +235,7 @@ public final class ShardPath {
             dataPath = statePath;
         }
 
-        return new ShardPath(dataPath, statePath, indexUUID, shardId);
+        return new ShardPath(NodeEnvironment.hasCustomDataPath(indexSettings), dataPath, statePath, indexUUID, shardId);
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/index/shard/TranslogRecoveryPerformer.java b/core/src/main/java/org/elasticsearch/index/shard/TranslogRecoveryPerformer.java
index d8bea76..890b709 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/TranslogRecoveryPerformer.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/TranslogRecoveryPerformer.java
@@ -25,7 +25,6 @@ import org.elasticsearch.Version;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.lucene.search.Queries;
@@ -35,12 +34,7 @@ import org.elasticsearch.index.aliases.IndexAliasesService;
 import org.elasticsearch.index.cache.IndexCache;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.engine.IgnoreOnRecoveryEngineException;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.MapperException;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.mapper.MapperUtils;
-import org.elasticsearch.index.mapper.Mapping;
-import org.elasticsearch.index.mapper.Uid;
+import org.elasticsearch.index.mapper.*;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.query.ParsedQuery;
 import org.elasticsearch.index.query.QueryParsingException;
@@ -72,7 +66,7 @@ public class TranslogRecoveryPerformer {
         this.indexCache = indexCache;
     }
 
-    protected Tuple<DocumentMapper, Mapping> docMapper(String type) {
+    protected DocumentMapperForType docMapper(String type) {
         return mapperService.documentMapperWithAutoCreate(type); // protected for testing
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
index 042f3c3..3730b67 100644
--- a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
+++ b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
@@ -20,8 +20,6 @@
 package org.elasticsearch.index.snapshots.blobstore;
 
 import com.google.common.collect.Iterables;
-import com.google.common.collect.Lists;
-import com.google.common.io.ByteStreams;
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.IndexFormatTooNewException;
 import org.apache.lucene.index.IndexFormatTooOldException;
@@ -43,7 +41,6 @@ import org.elasticsearch.common.blobstore.BlobContainer;
 import org.elasticsearch.common.blobstore.BlobMetaData;
 import org.elasticsearch.common.blobstore.BlobPath;
 import org.elasticsearch.common.blobstore.BlobStore;
-import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
@@ -51,11 +48,14 @@ import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.lucene.store.InputStreamIndexInput;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.ByteSizeValue;
-import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.snapshots.*;
+import org.elasticsearch.index.snapshots.IndexShardRepository;
+import org.elasticsearch.index.snapshots.IndexShardRestoreFailedException;
+import org.elasticsearch.index.snapshots.IndexShardSnapshotException;
+import org.elasticsearch.index.snapshots.IndexShardSnapshotFailedException;
+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;
 import org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardSnapshot.FileInfo;
 import org.elasticsearch.index.store.Store;
 import org.elasticsearch.index.store.StoreFileMetaData;
@@ -63,15 +63,21 @@ import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.indices.recovery.RecoveryState;
 import org.elasticsearch.repositories.RepositoryName;
 import org.elasticsearch.repositories.RepositoryVerificationException;
-import org.elasticsearch.repositories.blobstore.*;
+import org.elasticsearch.repositories.blobstore.BlobStoreFormat;
+import org.elasticsearch.repositories.blobstore.BlobStoreRepository;
+import org.elasticsearch.repositories.blobstore.ChecksumBlobStoreFormat;
+import org.elasticsearch.repositories.blobstore.LegacyBlobStoreFormat;
 
 import java.io.FilterInputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.OutputStream;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.repositories.blobstore.BlobStoreRepository.testBlobPrefix;
 
 /**
@@ -318,7 +324,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
             }
 
             // Build a list of snapshots that should be preserved
-            List<SnapshotFiles> newSnapshotsList = Lists.newArrayList();
+            List<SnapshotFiles> newSnapshotsList = new ArrayList<>();
             for (SnapshotFiles point : snapshots) {
                 if (!point.snapshot().equals(snapshotId.getSnapshot())) {
                     newSnapshotsList.add(point);
@@ -352,7 +358,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
          */
         protected void finalize(List<SnapshotFiles> snapshots, int fileListGeneration, Map<String, BlobMetaData> blobs) {
             BlobStoreIndexShardSnapshots newSnapshots = new BlobStoreIndexShardSnapshots(snapshots);
-            List<String> blobsToDelete = newArrayList();
+            List<String> blobsToDelete = new ArrayList<>();
             // delete old index files first
             for (String blobName : blobs.keySet()) {
                 // delete old file lists
@@ -369,7 +375,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
                 throw new IndexShardSnapshotFailedException(shardId, "error deleting index files during cleanup, reason: " + e.getMessage(), e);
             }
 
-            blobsToDelete = newArrayList();
+            blobsToDelete = new ArrayList<>();
             // now go over all the blobs, and if they don't exists in a snapshot, delete them
             for (String blobName : blobs.keySet()) {
                 // delete unused files
@@ -459,7 +465,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
             }
 
             // We couldn't load the index file - falling back to loading individual snapshots
-            List<SnapshotFiles> snapshots = Lists.newArrayList();
+            List<SnapshotFiles> snapshots = new ArrayList<>();
             for (String name : blobs.keySet()) {
                 try {
                     BlobStoreIndexShardSnapshot snapshot = null;
@@ -524,11 +530,11 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
                 BlobStoreIndexShardSnapshots snapshots = tuple.v1();
                 int fileListGeneration = tuple.v2();
 
-                final List<BlobStoreIndexShardSnapshot.FileInfo> indexCommitPointFiles = newArrayList();
+                final List<BlobStoreIndexShardSnapshot.FileInfo> indexCommitPointFiles = new ArrayList<>();
 
                 int indexNumberOfFiles = 0;
                 long indexTotalFilesSize = 0;
-                ArrayList<FileInfo> filesToSnapshot = newArrayList();
+                ArrayList<FileInfo> filesToSnapshot = new ArrayList<>();
                 final Store.MetadataSnapshot metadata;
                 // TODO apparently we don't use the MetadataSnapshot#.recoveryDiff(...) here but we should
                 try {
@@ -611,7 +617,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
 
                 // delete all files that are not referenced by any commit point
                 // build a new BlobStoreIndexShardSnapshot, that includes this one and all the saved ones
-                List<SnapshotFiles> newSnapshotsList = Lists.newArrayList();
+                List<SnapshotFiles> newSnapshotsList = new ArrayList<>();
                 newSnapshotsList.add(new SnapshotFiles(snapshot.snapshot(), snapshot.indexFiles()));
                 for (SnapshotFiles point : snapshots) {
                     newSnapshotsList.add(point);
@@ -807,7 +813,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
                     throw new IndexShardRestoreFailedException(shardId, "Can't restore corrupted shard", e);
                 }
 
-                final List<FileInfo> filesToRecover = Lists.newArrayList();
+                final List<FileInfo> filesToRecover = new ArrayList<>();
                 final Map<String, StoreFileMetaData> snapshotMetaData = new HashMap<>();
                 final Map<String, FileInfo> fileInfos = new HashMap<>();
                 for (final FileInfo fileInfo : snapshot.indexFiles()) {
diff --git a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshot.java b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshot.java
index 0e997c1..2c413c4 100644
--- a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshot.java
+++ b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshot.java
@@ -29,14 +29,17 @@ import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.unit.ByteSizeValue;
-import org.elasticsearch.common.xcontent.*;
+import org.elasticsearch.common.xcontent.FromXContentBuilder;
+import org.elasticsearch.common.xcontent.ToXContent;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentBuilderString;
+import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.store.StoreFileMetaData;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * Shard snapshot metadata
  */
@@ -477,7 +480,7 @@ public class BlobStoreIndexShardSnapshot implements ToXContent, FromXContentBuil
         int numberOfFiles = 0;
         long totalSize = 0;
 
-        List<FileInfo> indexFiles = newArrayList();
+        List<FileInfo> indexFiles = new ArrayList<>();
         if (parser.currentToken() == null) { // fresh parser? move to the first token
             parser.nextToken();
         }
diff --git a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshots.java b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshots.java
index 19bf4ee..0a22b1e 100644
--- a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshots.java
+++ b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshots.java
@@ -24,15 +24,19 @@ import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.xcontent.*;
+import org.elasticsearch.common.xcontent.FromXContentBuilder;
+import org.elasticsearch.common.xcontent.ToXContent;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentBuilderString;
+import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardSnapshot.FileInfo;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.newHashMap;
 
 /**
@@ -68,7 +72,7 @@ public class BlobStoreIndexShardSnapshots implements Iterable<SnapshotFiles>, To
             for (FileInfo fileInfo : snapshot.indexFiles()) {
                 List<FileInfo> physicalFileList = physicalFiles.get(fileInfo.physicalName());
                 if (physicalFileList == null) {
-                    physicalFileList = newArrayList();
+                    physicalFileList = new ArrayList<>();
                     physicalFiles.put(fileInfo.physicalName(), physicalFileList);
                 }
                 physicalFileList.add(newFiles.get(fileInfo.name()));
@@ -90,7 +94,7 @@ public class BlobStoreIndexShardSnapshots implements Iterable<SnapshotFiles>, To
             for (FileInfo fileInfo : snapshot.indexFiles()) {
                 List<FileInfo> physicalFileList = physicalFiles.get(fileInfo.physicalName());
                 if (physicalFileList == null) {
-                    physicalFileList = newArrayList();
+                    physicalFileList = new ArrayList<>();
                     physicalFiles.put(fileInfo.physicalName(), physicalFileList);
                 }
                 physicalFileList.add(files.get(fileInfo.name()));
@@ -269,7 +273,7 @@ public class BlobStoreIndexShardSnapshots implements Iterable<SnapshotFiles>, To
                                     if (parseFieldMatcher.match(currentFieldName, ParseFields.FILES) == false) {
                                         throw new ElasticsearchParseException("unknown array [{}]", currentFieldName);
                                     }
-                                    List<String> fileNames = newArrayList();
+                                    List<String> fileNames = new ArrayList<>();
                                     while (parser.nextToken() != XContentParser.Token.END_ARRAY) {
                                         fileNames.add(parser.text());
                                     }
diff --git a/core/src/main/java/org/elasticsearch/index/termvectors/ShardTermVectorsService.java b/core/src/main/java/org/elasticsearch/index/termvectors/ShardTermVectorsService.java
index 0d107e1..cb34c11 100644
--- a/core/src/main/java/org/elasticsearch/index/termvectors/ShardTermVectorsService.java
+++ b/core/src/main/java/org/elasticsearch/index/termvectors/ShardTermVectorsService.java
@@ -20,12 +20,7 @@
 package org.elasticsearch.index.termvectors;
 
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.index.Fields;
-import org.apache.lucene.index.IndexOptions;
-import org.apache.lucene.index.IndexableField;
-import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.*;
 import org.apache.lucene.index.memory.MemoryIndex;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.termvectors.TermVectorsFilter;
@@ -38,20 +33,13 @@ import org.elasticsearch.cluster.action.index.MappingUpdatedAction;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.uid.Versions;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.get.GetField;
 import org.elasticsearch.index.get.GetResult;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.mapper.Mapping;
-import org.elasticsearch.index.mapper.ParseContext;
-import org.elasticsearch.index.mapper.ParsedDocument;
-import org.elasticsearch.index.mapper.Uid;
+import org.elasticsearch.index.mapper.*;
 import org.elasticsearch.index.mapper.core.StringFieldMapper;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.settings.IndexSettings;
@@ -61,14 +49,7 @@ import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.search.dfs.AggregatedDfs;
 
 import java.io.IOException;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.Map;
-import java.util.Set;
-import java.util.TreeMap;
+import java.util.*;
 
 import static org.elasticsearch.index.mapper.SourceToParse.source;
 
@@ -308,10 +289,10 @@ public class ShardTermVectorsService extends AbstractIndexShardComponent {
         MapperService mapperService = indexShard.mapperService();
 
         // TODO: make parsing not dynamically create fields not in the original mapping
-        Tuple<DocumentMapper, Mapping> docMapper = mapperService.documentMapperWithAutoCreate(type);
-        ParsedDocument parsedDocument = docMapper.v1().parse(source(doc).index(index).type(type).flyweight(true));
-        if (docMapper.v2() != null) {
-            parsedDocument.addDynamicMappingsUpdate(docMapper.v2());
+        DocumentMapperForType docMapper = mapperService.documentMapperWithAutoCreate(type);
+        ParsedDocument parsedDocument = docMapper.getDocumentMapper().parse(source(doc).index(index).type(type).flyweight(true));
+        if (docMapper.getMapping() != null) {
+            parsedDocument.addDynamicMappingsUpdate(docMapper.getMapping());
         }
         if (parsedDocument.dynamicMappingsUpdate() != null) {
             mappingUpdatedAction.updateMappingOnMasterSynchronously(index, type, parsedDocument.dynamicMappingsUpdate());
diff --git a/core/src/main/java/org/elasticsearch/index/translog/Translog.java b/core/src/main/java/org/elasticsearch/index/translog/Translog.java
index 3fe4d9d..9b1913e 100644
--- a/core/src/main/java/org/elasticsearch/index/translog/Translog.java
+++ b/core/src/main/java/org/elasticsearch/index/translog/Translog.java
@@ -32,8 +32,10 @@ import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.bytes.ReleasablePagedBytesReference;
-import org.elasticsearch.common.collect.Tuple;
-import org.elasticsearch.common.io.stream.*;
+import org.elasticsearch.common.io.stream.ReleasableBytesStreamOutput;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.io.stream.Streamable;
 import org.elasticsearch.common.lease.Releasable;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.logging.ESLogger;
@@ -231,7 +233,7 @@ public class Translog extends AbstractIndexShardComponent implements IndexShardC
             }
         })) {
             long latestGeneration = -1;
-            List<Tuple<Path, Long>> filesToUpgrade = new ArrayList<>();
+            List<PathWithGeneration> filesToUpgrade = new ArrayList<>();
             for (Path path : stream) {
                 Matcher matcher = parseLegacyIdPattern.matcher(path.getFileName().toString());
                 if (matcher.matches()) {
@@ -239,7 +241,7 @@ public class Translog extends AbstractIndexShardComponent implements IndexShardC
                     if (generation >= translogGeneration.translogFileGeneration) {
                         latestGeneration = Math.max(translogGeneration.translogFileGeneration, generation);
                     }
-                    filesToUpgrade.add(new Tuple<>(path, generation));
+                    filesToUpgrade.add(new PathWithGeneration(path, generation));
                 } else {
                     Matcher strict_matcher = PARSE_STRICT_ID_PATTERN.matcher(path.getFileName().toString());
                     if (strict_matcher.matches()) {
@@ -250,17 +252,17 @@ public class Translog extends AbstractIndexShardComponent implements IndexShardC
             if (latestGeneration < translogGeneration.translogFileGeneration) {
                 throw new IllegalStateException("latest found translog has a lower generation that the excepcted uncommitted " + translogGeneration.translogFileGeneration + " > " + latestGeneration);
             }
-            CollectionUtil.timSort(filesToUpgrade, new Comparator<Tuple<Path, Long>>() {
+            CollectionUtil.timSort(filesToUpgrade, new Comparator<PathWithGeneration>() {
                 @Override
-                public int compare(Tuple<Path, Long> o1, Tuple<Path, Long> o2) {
-                    long gen1 = o1.v2();
-                    long gen2 = o2.v2();
+                public int compare(PathWithGeneration o1, PathWithGeneration o2) {
+                    long gen1 = o1.getGeneration();
+                    long gen2 = o2.getGeneration();
                     return Long.compare(gen1, gen2);
                 }
             });
-            for (Tuple<Path, Long> pathAndGeneration : filesToUpgrade) {
-                final Path path = pathAndGeneration.v1();
-                final long generation = pathAndGeneration.v2();
+            for (PathWithGeneration pathAndGeneration : filesToUpgrade) {
+                final Path path = pathAndGeneration.getPath();
+                final long generation = pathAndGeneration.getGeneration();
                 final Path target = path.resolveSibling(getFilename(generation));
                 logger.debug("upgrading translog copy file from {} to {}", path, target);
                 Files.move(path, target, StandardCopyOption.ATOMIC_MOVE);
@@ -1798,4 +1800,21 @@ public class Translog extends AbstractIndexShardComponent implements IndexShardC
         return outstandingViews.size();
     }
 
+    private static class PathWithGeneration {
+        private final Path path;
+        private final long generation;
+
+        public PathWithGeneration(Path path, long generation) {
+            this.path = path;
+            this.generation = generation;
+        }
+
+        public Path getPath() {
+            return path;
+        }
+
+        public long getGeneration() {
+            return generation;
+        }
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/indices/IndicesModule.java b/core/src/main/java/org/elasticsearch/indices/IndicesModule.java
index e3be629..759c9e5 100644
--- a/core/src/main/java/org/elasticsearch/indices/IndicesModule.java
+++ b/core/src/main/java/org/elasticsearch/indices/IndicesModule.java
@@ -114,7 +114,6 @@ public class IndicesModule extends AbstractModule {
         registerQueryParser(NotQueryParser.class);
         registerQueryParser(ExistsQueryParser.class);
         registerQueryParser(MissingQueryParser.class);
-        registerQueryParser(MatchNoneQueryParser.class);
 
         if (ShapesAvailability.JTS_AVAILABLE) {
             registerQueryParser(GeoShapeQueryParser.class);
diff --git a/core/src/main/java/org/elasticsearch/indices/IndicesService.java b/core/src/main/java/org/elasticsearch/indices/IndicesService.java
index 43fdb3d..4c3b1f5 100644
--- a/core/src/main/java/org/elasticsearch/indices/IndicesService.java
+++ b/core/src/main/java/org/elasticsearch/indices/IndicesService.java
@@ -24,7 +24,6 @@ import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Iterators;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.apache.lucene.store.LockObtainFailedException;
 import org.apache.lucene.util.CollectionUtil;
@@ -38,7 +37,6 @@ import org.elasticsearch.action.admin.indices.stats.ShardStats;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.CreationException;
 import org.elasticsearch.common.inject.Inject;
@@ -106,6 +104,7 @@ import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.common.collect.MapBuilder.newMapBuilder;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
+import static org.elasticsearch.common.util.CollectionUtils.arrayAsArrayList;
 
 /**
  *
@@ -124,7 +123,26 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
     private final NodeEnvironment nodeEnv;
     private final TimeValue shardsClosedTimeout;
 
-    private volatile Map<String, Tuple<IndexService, Injector>> indices = ImmutableMap.of();
+    private volatile Map<String, IndexServiceInjectorPair> indices = ImmutableMap.of();
+    
+    static class IndexServiceInjectorPair {
+        private final IndexService indexService;
+        private final Injector injector;
+
+        public IndexServiceInjectorPair(IndexService indexService, Injector injector) {
+            this.indexService = indexService;
+            this.injector = injector;
+        }
+
+        public IndexService getIndexService() {
+            return indexService;
+        }
+
+        public Injector getInjector() {
+            return injector;
+        }
+    }
+    
     private final Map<Index, List<PendingDelete>> pendingDeletes = new HashMap<>();
 
     private final OldShardsStats oldShardsStats = new OldShardsStats();
@@ -229,16 +247,16 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
         }
 
         Map<Index, List<IndexShardStats>> statsByShard = Maps.newHashMap();
-        for (Tuple<IndexService, Injector> value : indices.values()) {
-            IndexService indexService = value.v1();
+        for (IndexServiceInjectorPair value : indices.values()) {
+            IndexService indexService = value.getIndexService();
             for (IndexShard indexShard : indexService) {
                 try {
                     if (indexShard.routingEntry() == null) {
                         continue;
                     }
-                    IndexShardStats indexShardStats = new IndexShardStats(indexShard.shardId(), new ShardStats[] { new ShardStats(indexShard, indexShard.routingEntry(), flags) });
+                    IndexShardStats indexShardStats = new IndexShardStats(indexShard.shardId(), new ShardStats[] { new ShardStats(indexShard, flags) });
                     if (!statsByShard.containsKey(indexService.index())) {
-                        statsByShard.put(indexService.index(), Lists.<IndexShardStats>newArrayList(indexShardStats));
+                        statsByShard.put(indexService.index(), arrayAsArrayList(indexShardStats));
                     } else {
                         statsByShard.get(indexService.index()).add(indexShardStats);
                     }
@@ -261,10 +279,10 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
 
     @Override
     public Iterator<IndexService> iterator() {
-        return Iterators.transform(indices.values().iterator(), new Function<Tuple<IndexService, Injector>, IndexService>() {
+        return Iterators.transform(indices.values().iterator(), new Function<IndexServiceInjectorPair, IndexService>() {
             @Override
-            public IndexService apply(Tuple<IndexService, Injector> input) {
-                return input.v1();
+            public IndexService apply(IndexServiceInjectorPair input) {
+                return input.getIndexService();
             }
         });
     }
@@ -279,11 +297,11 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
      */
     @Nullable
     public IndexService indexService(String index) {
-        Tuple<IndexService, Injector> indexServiceInjectorTuple = indices.get(index);
-        if (indexServiceInjectorTuple == null) {
+        IndexServiceInjectorPair indexServiceInjectorPair = indices.get(index);
+        if (indexServiceInjectorPair == null) {
             return null;
         } else {
-            return indexServiceInjectorTuple.v1();
+            return indexServiceInjectorPair.getIndexService();
         }
     }
 
@@ -352,7 +370,7 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
 
         indicesLifecycle.afterIndexCreated(indexService);
 
-        indices = newMapBuilder(indices).put(index.name(), new Tuple<>(indexService, indexInjector)).immutableMap();
+        indices = newMapBuilder(indices).put(index.name(), new IndexServiceInjectorPair(indexService, indexInjector)).immutableMap();
 
         return indexService;
     }
@@ -377,10 +395,10 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
                 }
 
                 logger.debug("[{}] closing ... (reason [{}])", index, reason);
-                Map<String, Tuple<IndexService, Injector>> tmpMap = newHashMap(indices);
-                Tuple<IndexService, Injector> remove = tmpMap.remove(index);
-                indexService = remove.v1();
-                indexInjector = remove.v2();
+                Map<String, IndexServiceInjectorPair> tmpMap = newHashMap(indices);
+                IndexServiceInjectorPair remove = tmpMap.remove(index);
+                indexService = remove.getIndexService();
+                indexInjector = remove.getInjector();
                 indices = ImmutableMap.copyOf(tmpMap);
             }
 
@@ -488,7 +506,7 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
             synchronized (this) {
                 String indexName = metaData.index();
                 if (indices.containsKey(indexName)) {
-                    String localUUid = indices.get(indexName).v1().indexUUID();
+                    String localUUid = indices.get(indexName).getIndexService().indexUUID();
                     throw new IllegalStateException("Can't delete index store for [" + indexName + "] - it's still part of the indices service [" + localUUid + "] [" + metaData.getIndexUUID() + "]");
                 }
                 if (clusterState.metaData().hasIndex(indexName) && (clusterState.nodes().localNode().masterNode() == true)) {
@@ -589,9 +607,9 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
      * @return true if the index can be deleted on this node
      */
     public boolean canDeleteIndexContents(Index index, Settings indexSettings) {
-        final Tuple<IndexService, Injector> indexServiceInjectorTuple = this.indices.get(index.name());
+        final IndexServiceInjectorPair indexServiceInjectorPair = this.indices.get(index.name());
         if (IndexMetaData.isOnSharedFilesystem(indexSettings) == false) {
-            if (indexServiceInjectorTuple == null && nodeEnv.hasNodeFile()) {
+            if (indexServiceInjectorPair == null && nodeEnv.hasNodeFile()) {
                 return true;
             }
         } else {
@@ -622,10 +640,10 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
     }
 
     private boolean canDeleteShardContent(ShardId shardId, @IndexSettings Settings indexSettings) {
-        final Tuple<IndexService, Injector> indexServiceInjectorTuple = this.indices.get(shardId.getIndex());
+        final IndexServiceInjectorPair indexServiceInjectorPair = this.indices.get(shardId.getIndex());
         if (IndexMetaData.isOnSharedFilesystem(indexSettings) == false) {
-            if (indexServiceInjectorTuple != null && nodeEnv.hasNodeFile()) {
-                final IndexService indexService = indexServiceInjectorTuple.v1();
+            if (indexServiceInjectorPair != null && nodeEnv.hasNodeFile()) {
+                final IndexService indexService = indexServiceInjectorPair.getIndexService();
                 return indexService.hasShard(shardId.id()) == false;
             } else if (nodeEnv.hasNodeFile()) {
                 if (NodeEnvironment.hasCustomDataPath(indexSettings)) {
diff --git a/core/src/main/java/org/elasticsearch/indices/IndicesWarmer.java b/core/src/main/java/org/elasticsearch/indices/IndicesWarmer.java
index 2b28842..9ee45b2 100644
--- a/core/src/main/java/org/elasticsearch/indices/IndicesWarmer.java
+++ b/core/src/main/java/org/elasticsearch/indices/IndicesWarmer.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.indices;
 
-import com.google.common.collect.Lists;
 import org.apache.lucene.index.IndexReader;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -29,10 +28,11 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.engine.Engine;
-import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.index.shard.IndexShard;
+import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.threadpool.ThreadPool;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.TimeUnit;
@@ -100,7 +100,7 @@ public final class IndicesWarmer extends AbstractComponent {
         }
         indexShard.warmerService().onPreWarm();
         long time = System.nanoTime();
-        final List<TerminationHandle> terminationHandles = Lists.newArrayList();
+        final List<TerminationHandle> terminationHandles = new ArrayList<>();
         // get a handle on pending tasks
         for (final Listener listener : listeners) {
             if (topReader) {
diff --git a/core/src/main/java/org/elasticsearch/indices/NodeIndicesStats.java b/core/src/main/java/org/elasticsearch/indices/NodeIndicesStats.java
index d7d6250..a184f0a 100644
--- a/core/src/main/java/org/elasticsearch/indices/NodeIndicesStats.java
+++ b/core/src/main/java/org/elasticsearch/indices/NodeIndicesStats.java
@@ -19,9 +19,7 @@
 
 package org.elasticsearch.indices;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
-
 import org.elasticsearch.action.admin.indices.stats.CommonStats;
 import org.elasticsearch.action.admin.indices.stats.IndexShardStats;
 import org.elasticsearch.action.admin.indices.stats.ShardStats;
@@ -51,6 +49,7 @@ import org.elasticsearch.index.suggest.stats.SuggestStats;
 import org.elasticsearch.search.suggest.completion.CompletionStats;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -175,7 +174,7 @@ public class NodeIndicesStats implements Streamable, ToXContent {
             for (int i = 0; i < entries; i++) {
                 Index index = Index.readIndexName(in);
                 int indexShardListSize = in.readVInt();
-                List<IndexShardStats> indexShardStats = Lists.newArrayListWithCapacity(indexShardListSize);
+                List<IndexShardStats> indexShardStats = new ArrayList<>(indexShardListSize);
                 for (int j = 0; j < indexShardListSize; j++) {
                     indexShardStats.add(IndexShardStats.readIndexShardStats(in));
                 }
diff --git a/core/src/main/java/org/elasticsearch/indices/breaker/HierarchyCircuitBreakerService.java b/core/src/main/java/org/elasticsearch/indices/breaker/HierarchyCircuitBreakerService.java
index 73877a2..b642286 100644
--- a/core/src/main/java/org/elasticsearch/indices/breaker/HierarchyCircuitBreakerService.java
+++ b/core/src/main/java/org/elasticsearch/indices/breaker/HierarchyCircuitBreakerService.java
@@ -28,13 +28,12 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.node.settings.NodeSettingsService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicLong;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * CircuitBreakerService that attempts to redistribute space between breakers
  * if tripped
@@ -186,7 +185,7 @@ public class HierarchyCircuitBreakerService extends CircuitBreakerService {
     @Override
     public AllCircuitBreakerStats stats() {
         long parentEstimated = 0;
-        List<CircuitBreakerStats> allStats = newArrayList();
+        List<CircuitBreakerStats> allStats = new ArrayList<>();
         // Gather the "estimated" count for the parent breaker by adding the
         // estimations for each individual breaker
         for (CircuitBreaker breaker : this.breakers.values()) {
diff --git a/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java b/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java
index 8da06ea..28ab04b 100644
--- a/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java
+++ b/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java
@@ -19,162 +19,58 @@
 
 package org.elasticsearch.indices.cache.query.terms;
 
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.QueryValidationException;
-
-import java.io.IOException;
-import java.util.Objects;
+import org.elasticsearch.common.Nullable;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
- * Encapsulates the parameters needed to fetch terms.
  */
-public class TermsLookup implements Writeable<TermsLookup>, ToXContent {
-    static final TermsLookup PROTOTYPE = new TermsLookup();
+public class TermsLookup {
 
-    private String index;
-    private String type;
-    private String id;
-    private String path;
-    private String routing;
+    private final String index;
+    private final String type;
+    private final String id;
+    private final String routing;
+    private final String path;
 
-    public TermsLookup() {
-    }
+    @Nullable
+    private final QueryParseContext queryParseContext;
 
-    public TermsLookup(String index, String type, String id, String path) {
+    public TermsLookup(String index, String type, String id, String routing, String path, @Nullable QueryParseContext queryParseContext) {
         this.index = index;
         this.type = type;
         this.id = id;
+        this.routing = routing;
         this.path = path;
+        this.queryParseContext = queryParseContext;
     }
 
-    public String index() {
+    public String getIndex() {
         return index;
     }
 
-    public TermsLookup index(String index) {
-        this.index = index;
-        return this;
-    }
-
-    public String type() {
+    public String getType() {
         return type;
     }
 
-    public TermsLookup type(String type) {
-        this.type = type;
-        return this;
-    }
-
-    public String id() {
+    public String getId() {
         return id;
     }
 
-    public TermsLookup id(String id) {
-        this.id = id;
-        return this;
+    public String getRouting() {
+        return this.routing;
     }
 
-    public String path() {
+    public String getPath() {
         return path;
     }
 
-    public TermsLookup path(String path) {
-        this.path = path;
-        return this;
-    }
-
-    public String routing() {
-        return routing;
-    }
-
-    public TermsLookup routing(String routing) {
-        this.routing = routing;
-        return this;
+    @Nullable
+    public QueryParseContext getQueryParseContext() {
+        return queryParseContext;
     }
 
     @Override
     public String toString() {
         return index + "/" + type + "/" + id + "/" + path;
     }
-
-    @Override
-    public TermsLookup readFrom(StreamInput in) throws IOException {
-        TermsLookup termsLookup = new TermsLookup();
-        termsLookup.index = in.readOptionalString();
-        termsLookup.type = in.readString();
-        termsLookup.id = in.readString();
-        termsLookup.path = in.readString();
-        termsLookup.routing = in.readOptionalString();
-        return termsLookup;
-    }
-
-    public static TermsLookup readTermsLookupFrom(StreamInput in) throws IOException {
-        return PROTOTYPE.readFrom(in);
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeOptionalString(index);
-        out.writeString(type);
-        out.writeString(id);
-        out.writeString(path);
-        out.writeOptionalString(routing);
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        if (index != null) {
-            builder.field("index", index);
-        }
-        builder.field("type", type);
-        builder.field("id", id);
-        builder.field("path", path);
-        if (routing != null) {
-            builder.field("routing", routing);
-        }
-        return builder;
-    }
-
-    @Override
-    public int hashCode() {
-        return Objects.hash(index, type, id, path, routing);
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (obj == null || getClass() != obj.getClass()) {
-            return false;
-        }
-        TermsLookup other = (TermsLookup) obj;
-        return Objects.equals(index, other.index) &&
-                Objects.equals(type, other.type) &&
-                Objects.equals(id, other.id) &&
-                Objects.equals(path, other.path) &&
-                Objects.equals(routing, other.routing);
-    }
-
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (id == null) {
-            validationException = addValidationError("[terms] query lookup element requires specifying the id.", validationException);
-        }
-        if (type == null) {
-            validationException = addValidationError("[terms] query lookup element requires specifying the type.", validationException);
-        }
-        if (path == null) {
-            validationException = addValidationError("[terms] query lookup element requires specifying the path.", validationException);
-        }
-        return validationException;
-    }
-
-    private static QueryValidationException addValidationError(String validationError, QueryValidationException validationException) {
-        return QueryValidationException.addValidationError("terms_lookup", validationError, validationException);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java b/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java
index c669a9d..30cab94 100644
--- a/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java
+++ b/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java
@@ -22,7 +22,6 @@ package org.elasticsearch.indices.cluster;
 import com.carrotsearch.hppc.IntHashSet;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.google.common.base.Predicate;
-import com.google.common.collect.Lists;
 import org.elasticsearch.cluster.ClusterChangedEvent;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.ClusterState;
@@ -34,7 +33,11 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MappingMetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.*;
+import org.elasticsearch.cluster.routing.IndexRoutingTable;
+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
+import org.elasticsearch.cluster.routing.RoutingNodes;
+import org.elasticsearch.cluster.routing.RoutingTable;
+import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
@@ -50,7 +53,12 @@ import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.mapper.DocumentMapper;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.settings.IndexSettingsService;
-import org.elasticsearch.index.shard.*;
+import org.elasticsearch.index.shard.IndexShard;
+import org.elasticsearch.index.shard.IndexShardRecoveryException;
+import org.elasticsearch.index.shard.IndexShardState;
+import org.elasticsearch.index.shard.ShardId;
+import org.elasticsearch.index.shard.ShardNotFoundException;
+import org.elasticsearch.index.shard.StoreRecoveryService;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.indices.recovery.RecoveryFailedException;
 import org.elasticsearch.indices.recovery.RecoveryState;
@@ -58,6 +66,7 @@ import org.elasticsearch.indices.recovery.RecoveryStatus;
 import org.elasticsearch.indices.recovery.RecoveryTarget;
 import org.elasticsearch.threadpool.ThreadPool;
 
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
@@ -335,7 +344,7 @@ public class IndicesClusterStateService extends AbstractLifecycleComponent<Indic
                 // we only create / update here
                 continue;
             }
-            List<String> typesToRefresh = Lists.newArrayList();
+            List<String> typesToRefresh = new ArrayList<>();
             String index = indexMetaData.index();
             IndexService indexService = indicesService.indexService(index);
             if (indexService == null) {
diff --git a/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java b/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java
index 430b763..67d3e8e 100644
--- a/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java
+++ b/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.indices.memory;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
@@ -39,7 +38,12 @@ import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.monitor.jvm.JvmInfo;
 import org.elasticsearch.threadpool.ThreadPool;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.EnumSet;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
 import java.util.concurrent.ScheduledFuture;
 
 /**
@@ -158,7 +162,7 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
 
             changes.addAll(purgeDeletedAndClosedShards());
 
-            final List<IndexShard> activeToInactiveIndexingShards = Lists.newArrayList();
+            final List<IndexShard> activeToInactiveIndexingShards = new ArrayList<>();
             final int activeShards = updateShardStatuses(changes, activeToInactiveIndexingShards);
             for (IndexShard indexShard : activeToInactiveIndexingShards) {
                 // update inactive indexing buffer size
diff --git a/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java b/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
index 2a5d815..7d13fe0 100644
--- a/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
+++ b/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
@@ -21,12 +21,10 @@ package org.elasticsearch.indices.query;
 
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.Maps;
+
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.query.EmptyQueryBuilder;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryParser;
 
 import java.util.Map;
@@ -34,28 +32,24 @@ import java.util.Set;
 
 public class IndicesQueriesRegistry extends AbstractComponent {
 
-    private ImmutableMap<String, QueryParser<?>> queryParsers;
+    private ImmutableMap<String, QueryParser> queryParsers;
 
     @Inject
-    public IndicesQueriesRegistry(Settings settings, Set<QueryParser> injectedQueryParsers, NamedWriteableRegistry namedWriteableRegistry) {
+    public IndicesQueriesRegistry(Settings settings, Set<QueryParser> injectedQueryParsers) {
         super(settings);
-        Map<String, QueryParser<?>> queryParsers = Maps.newHashMap();
-        for (QueryParser<?> queryParser : injectedQueryParsers) {
+        Map<String, QueryParser> queryParsers = Maps.newHashMap();
+        for (QueryParser queryParser : injectedQueryParsers) {
             for (String name : queryParser.names()) {
                 queryParsers.put(name, queryParser);
             }
-            namedWriteableRegistry.registerPrototype(QueryBuilder.class, queryParser.getBuilderPrototype());
         }
-        // EmptyQueryBuilder is not registered as query parser but used internally.
-        // We need to register it with the NamedWriteableRegistry in order to serialize it
-        namedWriteableRegistry.registerPrototype(QueryBuilder.class, EmptyQueryBuilder.PROTOTYPE);
         this.queryParsers = ImmutableMap.copyOf(queryParsers);
     }
 
     /**
      * Returns all the registered query parsers
      */
-    public ImmutableMap<String, QueryParser<?>> queryParsers() {
+    public ImmutableMap<String, QueryParser> queryParsers() {
         return queryParsers;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryResponse.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryResponse.java
index b360130..7ec59a7 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryResponse.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryResponse.java
@@ -19,12 +19,12 @@
 
 package org.elasticsearch.indices.recovery;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.transport.TransportResponse;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -32,10 +32,10 @@ import java.util.List;
  */
 class RecoveryResponse extends TransportResponse {
 
-    List<String> phase1FileNames = Lists.newArrayList();
-    List<Long> phase1FileSizes = Lists.newArrayList();
-    List<String> phase1ExistingFileNames = Lists.newArrayList();
-    List<Long> phase1ExistingFileSizes = Lists.newArrayList();
+    List<String> phase1FileNames = new ArrayList<>();
+    List<Long> phase1FileSizes = new ArrayList<>();
+    List<String> phase1ExistingFileNames = new ArrayList<>();
+    List<Long> phase1ExistingFileSizes = new ArrayList<>();
     long phase1TotalSize;
     long phase1ExistingTotalSize;
     long phase1Time;
@@ -53,23 +53,23 @@ class RecoveryResponse extends TransportResponse {
     public void readFrom(StreamInput in) throws IOException {
         super.readFrom(in);
         int size = in.readVInt();
-        phase1FileNames = Lists.newArrayListWithCapacity(size);
+        phase1FileNames = new ArrayList<>(size);
         for (int i = 0; i < size; i++) {
             phase1FileNames.add(in.readString());
         }
         size = in.readVInt();
-        phase1FileSizes = Lists.newArrayListWithCapacity(size);
+        phase1FileSizes = new ArrayList<>(size);
         for (int i = 0; i < size; i++) {
             phase1FileSizes.add(in.readVLong());
         }
 
         size = in.readVInt();
-        phase1ExistingFileNames = Lists.newArrayListWithCapacity(size);
+        phase1ExistingFileNames = new ArrayList<>(size);
         for (int i = 0; i < size; i++) {
             phase1ExistingFileNames.add(in.readString());
         }
         size = in.readVInt();
-        phase1ExistingFileSizes = Lists.newArrayListWithCapacity(size);
+        phase1ExistingFileSizes = new ArrayList<>(size);
         for (int i = 0; i < size; i++) {
             phase1ExistingFileSizes.add(in.readVLong());
         }
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
index 9d0439d..8d913c6 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.indices.recovery;
 
 import com.google.common.collect.Iterables;
-import com.google.common.collect.Lists;
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.IndexFormatTooNewException;
 import org.apache.lucene.index.IndexFormatTooOldException;
@@ -57,6 +56,7 @@ import org.elasticsearch.transport.TransportRequestOptions;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Comparator;
 import java.util.List;
 import java.util.concurrent.CopyOnWriteArrayList;
@@ -558,7 +558,7 @@ public class RecoverySourceHandler {
         int ops = 0;
         long size = 0;
         int totalOperations = 0;
-        final List<Translog.Operation> operations = Lists.newArrayList();
+        final List<Translog.Operation> operations = new ArrayList<>();
         Translog.Operation operation;
         try {
             operation = snapshot.next(); // this ex should bubble up
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryTranslogOperationsRequest.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryTranslogOperationsRequest.java
index b320c98..345c179 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryTranslogOperationsRequest.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryTranslogOperationsRequest.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.indices.recovery;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.index.shard.ShardId;
diff --git a/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java b/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java
index 1d4eefd..d72e145 100644
--- a/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java
+++ b/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java
@@ -19,12 +19,15 @@
 
 package org.elasticsearch.indices.store;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.FailedNodeException;
 import org.elasticsearch.action.support.ActionFilters;
-import org.elasticsearch.action.support.nodes.*;
+import org.elasticsearch.action.support.nodes.BaseNodeRequest;
+import org.elasticsearch.action.support.nodes.BaseNodeResponse;
+import org.elasticsearch.action.support.nodes.BaseNodesRequest;
+import org.elasticsearch.action.support.nodes.BaseNodesResponse;
+import org.elasticsearch.action.support.nodes.TransportNodesAction;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.ClusterState;
@@ -51,6 +54,7 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
@@ -103,8 +107,8 @@ public class TransportNodesListShardStoreMetaData extends TransportNodesAction<T
 
     @Override
     protected NodesStoreFilesMetaData newResponse(Request request, AtomicReferenceArray responses) {
-        final List<NodeStoreFilesMetaData> nodeStoreFilesMetaDatas = Lists.newArrayList();
-        final List<FailedNodeException> failures = Lists.newArrayList();
+        final List<NodeStoreFilesMetaData> nodeStoreFilesMetaDatas = new ArrayList<>();
+        final List<FailedNodeException> failures = new ArrayList<>();
         for (int i = 0; i < responses.length(); i++) {
             Object resp = responses.get(i);
             if (resp instanceof NodeStoreFilesMetaData) { // will also filter out null response for unallocated ones
diff --git a/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java b/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java
index e925637..6096f29 100644
--- a/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java
+++ b/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java
@@ -19,12 +19,17 @@
 package org.elasticsearch.percolator;
 
 import com.carrotsearch.hppc.IntObjectHashMap;
-import com.google.common.collect.Lists;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.ReaderUtil;
 import org.apache.lucene.index.memory.ExtendedMemoryIndex;
 import org.apache.lucene.index.memory.MemoryIndex;
-import org.apache.lucene.search.*;
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CloseableThreadLocal;
 import org.elasticsearch.ElasticsearchParseException;
@@ -38,7 +43,6 @@ import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
 import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
@@ -59,7 +63,11 @@ import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.fielddata.IndexFieldData;
 import org.elasticsearch.index.fielddata.SortedBinaryDocValues;
-import org.elasticsearch.index.mapper.*;
+import org.elasticsearch.index.mapper.DocumentMapperForType;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.MapperService;
+import org.elasticsearch.index.mapper.ParsedDocument;
+import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.percolator.stats.ShardPercolateService;
 import org.elasticsearch.index.query.ParsedQuery;
@@ -85,6 +93,7 @@ import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
+import static org.elasticsearch.common.util.CollectionUtils.eagerTransform;
 import static org.elasticsearch.index.mapper.SourceToParse.source;
 import static org.elasticsearch.percolator.QueryCollector.*;
 
@@ -275,10 +284,10 @@ public class PercolatorService extends AbstractComponent {
                         }
 
                         MapperService mapperService = documentIndexService.mapperService();
-                        Tuple<DocumentMapper, Mapping> docMapper = mapperService.documentMapperWithAutoCreate(request.documentType());
-                        doc = docMapper.v1().parse(source(parser).index(index).type(request.documentType()).flyweight(true));
-                        if (docMapper.v2() != null) {
-                            doc.addDynamicMappingsUpdate(docMapper.v2());
+                        DocumentMapperForType docMapper = mapperService.documentMapperWithAutoCreate(request.documentType());
+                        doc = docMapper.getDocumentMapper().parse(source(parser).index(index).type(request.documentType()).flyweight(true));
+                        if (docMapper.getMapping() != null) {
+                            doc.addDynamicMappingsUpdate(docMapper.getMapping());
                         }
                         if (doc.dynamicMappingsUpdate() != null) {
                             mappingUpdatedAction.updateMappingOnMasterSynchronously(request.shardId().getIndex(), request.documentType(), doc.dynamicMappingsUpdate());
@@ -384,8 +393,8 @@ public class PercolatorService extends AbstractComponent {
         try {
             parser = XContentFactory.xContent(fetchedDoc).createParser(fetchedDoc);
             MapperService mapperService = documentIndexService.mapperService();
-            Tuple<DocumentMapper, Mapping> docMapper = mapperService.documentMapperWithAutoCreate(type);
-            doc = docMapper.v1().parse(source(parser).index(index).type(type).flyweight(true));
+            DocumentMapperForType docMapper = mapperService.documentMapperWithAutoCreate(type);
+            doc = docMapper.getDocumentMapper().parse(source(parser).index(index).type(type).flyweight(true));
 
             if (context.highlight() != null) {
                 doc.setSource(fetchedDoc);
@@ -847,7 +856,7 @@ public class PercolatorService extends AbstractComponent {
         if (aggregations != null) {
             List<SiblingPipelineAggregator> pipelineAggregators = shardResults.get(0).pipelineAggregators();
             if (pipelineAggregators != null) {
-                List<InternalAggregation> newAggs = new ArrayList<>(Lists.transform(aggregations.asList(), PipelineAggregator.AGGREGATION_TRANFORM_FUNCTION));
+                List<InternalAggregation> newAggs = new ArrayList<>(eagerTransform(aggregations.asList(), PipelineAggregator.AGGREGATION_TRANFORM_FUNCTION));
                 for (SiblingPipelineAggregator pipelineAggregator : pipelineAggregators) {
                     InternalAggregation newAgg = pipelineAggregator.doReduce(new InternalAggregations(newAggs), new ReduceContext(bigArrays,
                             scriptService));
diff --git a/core/src/main/java/org/elasticsearch/percolator/QueryCollector.java b/core/src/main/java/org/elasticsearch/percolator/QueryCollector.java
index 46ece93..dfa9f4b 100644
--- a/core/src/main/java/org/elasticsearch/percolator/QueryCollector.java
+++ b/core/src/main/java/org/elasticsearch/percolator/QueryCollector.java
@@ -19,22 +19,14 @@
 package org.elasticsearch.percolator;
 
 import com.carrotsearch.hppc.FloatArrayList;
-
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.LeafCollector;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.SimpleCollector;
-import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.search.TopScoreDocCollector;
+import org.apache.lucene.search.*;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.index.fielddata.IndexFieldData;
 import org.elasticsearch.index.fielddata.SortedBinaryDocValues;
-import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
diff --git a/core/src/main/java/org/elasticsearch/repositories/Repository.java b/core/src/main/java/org/elasticsearch/repositories/Repository.java
index 2bcdccb..adde0ed 100644
--- a/core/src/main/java/org/elasticsearch/repositories/Repository.java
+++ b/core/src/main/java/org/elasticsearch/repositories/Repository.java
@@ -130,4 +130,10 @@ public interface Repository extends LifecycleComponent<Repository> {
      */
     void endVerification(String verificationToken);
 
+    /**
+     * Returns true if the repository supports only read operations
+     * @return true if the repository is read/only
+     */
+    boolean readOnly();
+
 }
diff --git a/core/src/main/java/org/elasticsearch/repositories/VerifyNodeRepositoryAction.java b/core/src/main/java/org/elasticsearch/repositories/VerifyNodeRepositoryAction.java
index 35a1684..11b898d 100644
--- a/core/src/main/java/org/elasticsearch/repositories/VerifyNodeRepositoryAction.java
+++ b/core/src/main/java/org/elasticsearch/repositories/VerifyNodeRepositoryAction.java
@@ -31,17 +31,22 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.snapshots.IndexShardRepository;
-import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.*;
 import org.elasticsearch.repositories.RepositoriesService.VerifyResponse;
+import org.elasticsearch.threadpool.ThreadPool;
+import org.elasticsearch.transport.EmptyTransportResponseHandler;
+import org.elasticsearch.transport.TransportChannel;
+import org.elasticsearch.transport.TransportException;
+import org.elasticsearch.transport.TransportRequest;
+import org.elasticsearch.transport.TransportRequestHandler;
+import org.elasticsearch.transport.TransportResponse;
+import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.atomic.AtomicInteger;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 public class VerifyNodeRepositoryAction  extends AbstractComponent {
     public static final String ACTION_NAME = "internal:admin/repository/verify";
 
@@ -68,7 +73,7 @@ public class VerifyNodeRepositoryAction  extends AbstractComponent {
         final DiscoveryNode localNode = discoNodes.localNode();
 
         final ObjectContainer<DiscoveryNode> masterAndDataNodes = discoNodes.masterAndDataNodes().values();
-        final List<DiscoveryNode> nodes = newArrayList();
+        final List<DiscoveryNode> nodes = new ArrayList<>();
         for (ObjectCursor<DiscoveryNode> cursor : masterAndDataNodes) {
             DiscoveryNode node = cursor.value;
             nodes.add(node);
diff --git a/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java b/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
index 3e9fbaa..fd712bf 100644
--- a/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
+++ b/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
@@ -56,7 +56,12 @@ import org.elasticsearch.repositories.Repository;
 import org.elasticsearch.repositories.RepositoryException;
 import org.elasticsearch.repositories.RepositorySettings;
 import org.elasticsearch.repositories.RepositoryVerificationException;
-import org.elasticsearch.snapshots.*;
+import org.elasticsearch.snapshots.InvalidSnapshotNameException;
+import org.elasticsearch.snapshots.Snapshot;
+import org.elasticsearch.snapshots.SnapshotCreationException;
+import org.elasticsearch.snapshots.SnapshotException;
+import org.elasticsearch.snapshots.SnapshotMissingException;
+import org.elasticsearch.snapshots.SnapshotShardFailure;
 
 import java.io.FileNotFoundException;
 import java.io.IOException;
@@ -68,8 +73,6 @@ import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * BlobStore - based implementation of Snapshot Repository
  * <p/>
@@ -168,6 +171,8 @@ public abstract class BlobStoreRepository extends AbstractLifecycleComponent<Rep
 
     private LegacyBlobStoreFormat<Snapshot> snapshotLegacyFormat;
 
+    private final boolean readOnly;
+
     /**
      * Constructs new BlobStoreRepository
      *
@@ -181,6 +186,7 @@ public abstract class BlobStoreRepository extends AbstractLifecycleComponent<Rep
         this.indexShardRepository = (BlobStoreIndexShardRepository) indexShardRepository;
         snapshotRateLimiter = getRateLimiter(repositorySettings, "max_snapshot_bytes_per_sec", new ByteSizeValue(40, ByteSizeUnit.MB));
         restoreRateLimiter = getRateLimiter(repositorySettings, "max_restore_bytes_per_sec", new ByteSizeValue(40, ByteSizeUnit.MB));
+        readOnly = repositorySettings.settings().getAsBoolean("readonly", false);
     }
 
     /**
@@ -260,6 +266,9 @@ public abstract class BlobStoreRepository extends AbstractLifecycleComponent<Rep
      */
     @Override
     public void initializeSnapshot(SnapshotId snapshotId, List<String> indices, MetaData metaData) {
+        if (readOnly()) {
+            throw new RepositoryException(this.repositoryName, "cannot create snapshot in a readonly repository");
+        }
         try {
             if (snapshotFormat.exists(snapshotsBlobContainer, snapshotId.getSnapshot()) ||
                     snapshotLegacyFormat.exists(snapshotsBlobContainer, snapshotId.getSnapshot())) {
@@ -283,6 +292,9 @@ public abstract class BlobStoreRepository extends AbstractLifecycleComponent<Rep
      */
     @Override
     public void deleteSnapshot(SnapshotId snapshotId) {
+        if (readOnly()) {
+            throw new RepositoryException(this.repositoryName, "cannot delete snapshot from a readonly repository");
+        }
         List<String> indices = Collections.EMPTY_LIST;
         Snapshot snapshot = null;
         try {
@@ -380,7 +392,7 @@ public abstract class BlobStoreRepository extends AbstractLifecycleComponent<Rep
     @Override
     public List<SnapshotId> snapshots() {
         try {
-            List<SnapshotId> snapshots = newArrayList();
+            List<SnapshotId> snapshots = new ArrayList<>();
             Map<String, BlobMetaData> blobs;
             try {
                 blobs = snapshotsBlobContainer.listBlobsByPrefix(COMMON_SNAPSHOT_PREFIX);
@@ -622,16 +634,21 @@ public abstract class BlobStoreRepository extends AbstractLifecycleComponent<Rep
     @Override
     public String startVerification() {
         try {
-            String seed = Strings.randomBase64UUID();
-            byte[] testBytes = Strings.toUTF8Bytes(seed);
-            BlobContainer testContainer = blobStore().blobContainer(basePath().add(testBlobPrefix(seed)));
-            String blobName = "master.dat";
-            try (OutputStream outputStream = testContainer.createOutput(blobName + "-temp")) {
-                outputStream.write(testBytes);
+            if (readOnly()) {
+                // It's readonly - so there is not much we can do here to verify it
+                return null;
+            } else {
+                String seed = Strings.randomBase64UUID();
+                byte[] testBytes = Strings.toUTF8Bytes(seed);
+                BlobContainer testContainer = blobStore().blobContainer(basePath().add(testBlobPrefix(seed)));
+                String blobName = "master.dat";
+                try (OutputStream outputStream = testContainer.createOutput(blobName + "-temp")) {
+                    outputStream.write(testBytes);
+                }
+                // Make sure that move is supported
+                testContainer.move(blobName + "-temp", blobName);
+                return seed;
             }
-            // Make sure that move is supported
-            testContainer.move(blobName + "-temp", blobName);
-            return seed;
         } catch (IOException exp) {
             throw new RepositoryVerificationException(repositoryName, "path " + basePath() + " is not accessible on master node", exp);
         }
@@ -639,6 +656,9 @@ public abstract class BlobStoreRepository extends AbstractLifecycleComponent<Rep
 
     @Override
     public void endVerification(String seed) {
+        if (readOnly()) {
+            throw new UnsupportedOperationException("shouldn't be called");
+        }
         try {
             blobStore().delete(basePath().add(testBlobPrefix(seed)));
         } catch (IOException exp) {
@@ -649,4 +669,9 @@ public abstract class BlobStoreRepository extends AbstractLifecycleComponent<Rep
     public static String testBlobPrefix(String seed) {
         return TESTS_FILE + seed;
     }
+
+    @Override
+    public boolean readOnly() {
+        return readOnly;
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/repositories/uri/URLRepository.java b/core/src/main/java/org/elasticsearch/repositories/uri/URLRepository.java
index 42a27c1..922c487 100644
--- a/core/src/main/java/org/elasticsearch/repositories/uri/URLRepository.java
+++ b/core/src/main/java/org/elasticsearch/repositories/uri/URLRepository.java
@@ -126,17 +126,6 @@ public class URLRepository extends BlobStoreRepository {
         }
     }
 
-    @Override
-    public String startVerification() {
-        //TODO: #7831 Add check that URL exists and accessible
-        return null;
-    }
-
-    @Override
-    public void endVerification(String seed) {
-        throw new UnsupportedOperationException("shouldn't be called");
-    }
-
     /**
      * Makes sure that the url is white listed or if it points to the local file system it matches one on of the root path in path.repo
      */
@@ -168,4 +157,9 @@ public class URLRepository extends BlobStoreRepository {
         throw new RepositoryException(repositoryName, "unsupported url protocol [" + protocol + "] from URL [" + url + "]");
     }
 
+    @Override
+    public boolean readOnly() {
+        return true;
+    }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/rest/RestModule.java b/core/src/main/java/org/elasticsearch/rest/RestModule.java
index a5d6e1b..e794917 100644
--- a/core/src/main/java/org/elasticsearch/rest/RestModule.java
+++ b/core/src/main/java/org/elasticsearch/rest/RestModule.java
@@ -19,11 +19,11 @@
 
 package org.elasticsearch.rest;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.rest.action.RestActionModule;
 
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -32,7 +32,7 @@ import java.util.List;
 public class RestModule extends AbstractModule {
 
     private final Settings settings;
-    private List<Class<? extends BaseRestHandler>> restPluginsActions = Lists.newArrayList();
+    private List<Class<? extends BaseRestHandler>> restPluginsActions = new ArrayList<>();
 
     public void addRestAction(Class<? extends BaseRestHandler> restAction) {
         restPluginsActions.add(restAction);
diff --git a/core/src/main/java/org/elasticsearch/rest/RestResponse.java b/core/src/main/java/org/elasticsearch/rest/RestResponse.java
index 80ad0e1..7946785 100644
--- a/core/src/main/java/org/elasticsearch/rest/RestResponse.java
+++ b/core/src/main/java/org/elasticsearch/rest/RestResponse.java
@@ -19,12 +19,15 @@
 
 package org.elasticsearch.rest;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.bytes.BytesReference;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
 
 /**
  *
@@ -58,7 +61,7 @@ public abstract class RestResponse {
         for (String key : headerKeySet) {
             List<String> values = customHeaders.get(key);
             if (values == null) {
-                values = Lists.newArrayList();
+                values = new ArrayList<>();
                 customHeaders.put(key, values);
             }
             values.addAll(ex.getHeader(key));
diff --git a/core/src/main/java/org/elasticsearch/rest/action/RestActionModule.java b/core/src/main/java/org/elasticsearch/rest/action/RestActionModule.java
index 0764ca2..02bde5f 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/RestActionModule.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/RestActionModule.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.rest.action;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.inject.multibindings.Multibinder;
 import org.elasticsearch.rest.BaseRestHandler;
@@ -67,10 +65,10 @@ import org.elasticsearch.rest.action.admin.indices.open.RestOpenIndexAction;
 import org.elasticsearch.rest.action.admin.indices.optimize.RestOptimizeAction;
 import org.elasticsearch.rest.action.admin.indices.recovery.RestRecoveryAction;
 import org.elasticsearch.rest.action.admin.indices.refresh.RestRefreshAction;
-import org.elasticsearch.rest.action.admin.indices.shards.RestIndicesShardStoresAction;
 import org.elasticsearch.rest.action.admin.indices.segments.RestIndicesSegmentsAction;
 import org.elasticsearch.rest.action.admin.indices.settings.RestGetSettingsAction;
 import org.elasticsearch.rest.action.admin.indices.settings.RestUpdateSettingsAction;
+import org.elasticsearch.rest.action.admin.indices.shards.RestIndicesShardStoresAction;
 import org.elasticsearch.rest.action.admin.indices.stats.RestIndicesStatsAction;
 import org.elasticsearch.rest.action.admin.indices.template.delete.RestDeleteIndexTemplateAction;
 import org.elasticsearch.rest.action.admin.indices.template.get.RestGetIndexTemplateAction;
@@ -83,7 +81,20 @@ import org.elasticsearch.rest.action.admin.indices.warmer.delete.RestDeleteWarme
 import org.elasticsearch.rest.action.admin.indices.warmer.get.RestGetWarmerAction;
 import org.elasticsearch.rest.action.admin.indices.warmer.put.RestPutWarmerAction;
 import org.elasticsearch.rest.action.bulk.RestBulkAction;
-import org.elasticsearch.rest.action.cat.*;
+import org.elasticsearch.rest.action.cat.AbstractCatAction;
+import org.elasticsearch.rest.action.cat.RestAliasAction;
+import org.elasticsearch.rest.action.cat.RestAllocationAction;
+import org.elasticsearch.rest.action.cat.RestCatAction;
+import org.elasticsearch.rest.action.cat.RestFielddataAction;
+import org.elasticsearch.rest.action.cat.RestHealthAction;
+import org.elasticsearch.rest.action.cat.RestIndicesAction;
+import org.elasticsearch.rest.action.cat.RestMasterAction;
+import org.elasticsearch.rest.action.cat.RestNodeAttrsAction;
+import org.elasticsearch.rest.action.cat.RestNodesAction;
+import org.elasticsearch.rest.action.cat.RestPluginsAction;
+import org.elasticsearch.rest.action.cat.RestSegmentsAction;
+import org.elasticsearch.rest.action.cat.RestShardsAction;
+import org.elasticsearch.rest.action.cat.RestThreadPoolAction;
 import org.elasticsearch.rest.action.delete.RestDeleteAction;
 import org.elasticsearch.rest.action.explain.RestExplainAction;
 import org.elasticsearch.rest.action.fieldstats.RestFieldStatsAction;
@@ -110,13 +121,14 @@ import org.elasticsearch.rest.action.termvectors.RestMultiTermVectorsAction;
 import org.elasticsearch.rest.action.termvectors.RestTermVectorsAction;
 import org.elasticsearch.rest.action.update.RestUpdateAction;
 
+import java.util.ArrayList;
 import java.util.List;
 
 /**
  *
  */
 public class RestActionModule extends AbstractModule {
-    private List<Class<? extends BaseRestHandler>> restPluginsActions = Lists.newArrayList();
+    private List<Class<? extends BaseRestHandler>> restPluginsActions = new ArrayList<>();
 
     public RestActionModule(List<Class<? extends BaseRestHandler>> restPluginsActions) {
         this.restPluginsActions = restPluginsActions;
diff --git a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/analyze/RestAnalyzeAction.java b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/analyze/RestAnalyzeAction.java
index edfab2d..57ceb21 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/analyze/RestAnalyzeAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/analyze/RestAnalyzeAction.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.rest.action.admin.indices.analyze;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.action.admin.indices.analyze.AnalyzeRequest;
 import org.elasticsearch.action.admin.indices.analyze.AnalyzeResponse;
 import org.elasticsearch.client.Client;
@@ -29,11 +28,15 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentType;
-import org.elasticsearch.rest.*;
+import org.elasticsearch.rest.BaseRestHandler;
+import org.elasticsearch.rest.RestChannel;
+import org.elasticsearch.rest.RestController;
+import org.elasticsearch.rest.RestRequest;
 import org.elasticsearch.rest.action.support.RestActions;
 import org.elasticsearch.rest.action.support.RestToXContentListener;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
 import static org.elasticsearch.rest.RestRequest.Method.GET;
@@ -95,7 +98,7 @@ public class RestAnalyzeAction extends BaseRestHandler {
                     } else if ("text".equals(currentFieldName) && token == XContentParser.Token.VALUE_STRING) {
                         analyzeRequest.text(parser.text());
                     } else if ("text".equals(currentFieldName) && token == XContentParser.Token.START_ARRAY) {
-                        List<String> texts = Lists.newArrayList();
+                        List<String> texts = new ArrayList<>();
                         while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                             if (token.isValue() == false) {
                                 throw new IllegalArgumentException(currentFieldName + " array element should only contain text");
@@ -110,7 +113,7 @@ public class RestAnalyzeAction extends BaseRestHandler {
                     } else if ("tokenizer".equals(currentFieldName) && token == XContentParser.Token.VALUE_STRING) {
                         analyzeRequest.tokenizer(parser.text());
                     } else if (("token_filters".equals(currentFieldName) || "filters".equals(currentFieldName)) && token == XContentParser.Token.START_ARRAY) {
-                        List<String> filters = Lists.newArrayList();
+                        List<String> filters = new ArrayList<>();
                         while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                             if (token.isValue() == false) {
                                 throw new IllegalArgumentException(currentFieldName + " array element should only contain token filter's name");
@@ -119,7 +122,7 @@ public class RestAnalyzeAction extends BaseRestHandler {
                         }
                         analyzeRequest.tokenFilters(filters.toArray(Strings.EMPTY_ARRAY));
                     } else if ("char_filters".equals(currentFieldName) && token == XContentParser.Token.START_ARRAY) {
-                        List<String> charFilters = Lists.newArrayList();
+                        List<String> charFilters = new ArrayList<>();
                         while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                             if (token.isValue() == false) {
                                 throw new IllegalArgumentException(currentFieldName + " array element should only contain char filter's name");
diff --git a/core/src/main/java/org/elasticsearch/rest/action/delete/RestDeleteAction.java b/core/src/main/java/org/elasticsearch/rest/action/delete/RestDeleteAction.java
index 69f06ce..209ab68 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/delete/RestDeleteAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/delete/RestDeleteAction.java
@@ -50,9 +50,6 @@ public class RestDeleteAction extends BaseRestHandler {
     @Override
     public void handleRequest(final RestRequest request, final RestChannel channel, final Client client) {
         DeleteRequest deleteRequest = new DeleteRequest(request.param("index"), request.param("type"), request.param("id"));
-
-        deleteRequest.operationThreaded(true);
-
         deleteRequest.routing(request.param("routing"));
         deleteRequest.parent(request.param("parent")); // order is important, set it after routing, so it will set the routing
         deleteRequest.timeout(request.paramAsTime("timeout", DeleteRequest.DEFAULT_TIMEOUT));
diff --git a/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java b/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java
index 7c01fdd..ce306c6 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java
@@ -30,7 +30,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentBuilderString;
 import org.elasticsearch.index.get.GetResult;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.QueryStringQueryBuilder;
 import org.elasticsearch.rest.*;
@@ -75,7 +74,13 @@ public class RestExplainAction extends BaseRestHandler {
             queryStringBuilder.lenient(request.paramAsBoolean("lenient", null));
             String defaultOperator = request.param("default_operator");
             if (defaultOperator != null) {
-                queryStringBuilder.defaultOperator(Operator.fromString(defaultOperator));
+                if ("OR".equals(defaultOperator)) {
+                    queryStringBuilder.defaultOperator(QueryStringQueryBuilder.Operator.OR);
+                } else if ("AND".equals(defaultOperator)) {
+                    queryStringBuilder.defaultOperator(QueryStringQueryBuilder.Operator.AND);
+                } else {
+                    throw new IllegalArgumentException("Unsupported defaultOperator [" + defaultOperator + "], can either be [OR] or [AND]");
+                }
             }
 
             QuerySourceBuilder querySourceBuilder = new QuerySourceBuilder();
diff --git a/core/src/main/java/org/elasticsearch/rest/action/index/RestIndexAction.java b/core/src/main/java/org/elasticsearch/rest/action/index/RestIndexAction.java
index 3d3ecdf..d0d0fe6 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/index/RestIndexAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/index/RestIndexAction.java
@@ -70,7 +70,6 @@ public class RestIndexAction extends BaseRestHandler {
     @Override
     public void handleRequest(final RestRequest request, final RestChannel channel, final Client client) {
         IndexRequest indexRequest = new IndexRequest(request.param("index"), request.param("type"), request.param("id"));
-        indexRequest.operationThreaded(true);
         indexRequest.routing(request.param("routing"));
         indexRequest.parent(request.param("parent")); // order is important, set it after routing, so it will set the routing
         indexRequest.timestamp(request.param("timestamp"));
diff --git a/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java b/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
index 674aa69..bd17c1d 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
@@ -27,7 +27,6 @@ import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.lucene.uid.Versions;
 import org.elasticsearch.common.xcontent.*;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.QueryStringQueryBuilder;
 import org.elasticsearch.rest.RestRequest;
@@ -98,7 +97,13 @@ public class RestActions {
         queryBuilder.lenient(request.paramAsBoolean("lenient", null));
         String defaultOperator = request.param("default_operator");
         if (defaultOperator != null) {
-            queryBuilder.defaultOperator(Operator.fromString(defaultOperator));
+            if ("OR".equals(defaultOperator)) {
+                queryBuilder.defaultOperator(QueryStringQueryBuilder.Operator.OR);
+            } else if ("AND".equals(defaultOperator)) {
+                queryBuilder.defaultOperator(QueryStringQueryBuilder.Operator.AND);
+            } else {
+                throw new IllegalArgumentException("Unsupported defaultOperator [" + defaultOperator + "], can either be [OR] or [AND]");
+            }
         }
         return new QuerySourceBuilder().setQuery(queryBuilder);
     }
diff --git a/core/src/main/java/org/elasticsearch/script/ScriptModule.java b/core/src/main/java/org/elasticsearch/script/ScriptModule.java
index f5de92f..1f06d97 100644
--- a/core/src/main/java/org/elasticsearch/script/ScriptModule.java
+++ b/core/src/main/java/org/elasticsearch/script/ScriptModule.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.script;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.inject.multibindings.MapBinder;
@@ -30,6 +29,7 @@ import org.elasticsearch.script.expression.ExpressionScriptEngineService;
 import org.elasticsearch.script.groovy.GroovyScriptEngineService;
 import org.elasticsearch.script.mustache.MustacheScriptEngineService;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -41,11 +41,11 @@ public class ScriptModule extends AbstractModule {
 
     private final Settings settings;
 
-    private final List<Class<? extends ScriptEngineService>> scriptEngines = Lists.newArrayList();
+    private final List<Class<? extends ScriptEngineService>> scriptEngines = new ArrayList<>();
 
     private final Map<String, Class<? extends NativeScriptFactory>> scripts = Maps.newHashMap();
 
-    private final List<ScriptContext.Plugin> customScriptContexts = Lists.newArrayList();
+    private final List<ScriptContext.Plugin> customScriptContexts = new ArrayList<>();
 
     public ScriptModule(Settings settings) {
         this.settings = settings;
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/AggregationBuilder.java b/core/src/main/java/org/elasticsearch/search/aggregations/AggregationBuilder.java
index b94f657..ed1ba6c 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/AggregationBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/AggregationBuilder.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.search.aggregations;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.ElasticsearchGenerationException;
 import org.elasticsearch.client.Requests;
 import org.elasticsearch.common.bytes.BytesArray;
@@ -29,6 +27,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -54,7 +53,7 @@ public abstract class AggregationBuilder<B extends AggregationBuilder<B>> extend
     @SuppressWarnings("unchecked")
     public B subAggregation(AbstractAggregationBuilder aggregation) {
         if (aggregations == null) {
-            aggregations = Lists.newArrayList();
+            aggregations = new ArrayList<>();
         }
         aggregations.add(aggregation);
         return (B) this;
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/AggregationPhase.java b/core/src/main/java/org/elasticsearch/search/aggregations/AggregationPhase.java
index d4ed3b1..167d2d9 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/AggregationPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/AggregationPhase.java
@@ -19,7 +19,6 @@
 package org.elasticsearch.search.aggregations;
 
 import com.google.common.collect.ImmutableMap;
-
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Query;
@@ -130,6 +129,8 @@ public class AggregationPhase implements SearchPhase {
                 context.searcher().search(query, globalsCollector);
             } catch (Exception e) {
                 throw new QueryPhaseExecutionException(context, "Failed to execute global aggregators", e);
+            } finally {
+                context.clearReleasables(SearchContext.Lifetime.COLLECTION);
             }
         }
 
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregation.java b/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregation.java
index 1f32c0a..90c1dee 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregation.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregation.java
@@ -19,8 +19,6 @@
 package org.elasticsearch.search.aggregations;
 
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.StreamInput;
@@ -36,6 +34,7 @@ import org.elasticsearch.search.aggregations.pipeline.PipelineAggregatorStreams;
 import org.elasticsearch.search.aggregations.support.AggregationPath;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -228,7 +227,7 @@ public abstract class InternalAggregation implements Aggregation, ToXContent, St
         if (size == 0) {
             pipelineAggregators = ImmutableList.of();
         } else {
-            pipelineAggregators = Lists.newArrayListWithCapacity(size);
+            pipelineAggregators = new ArrayList<>(size);
             for (int i = 0; i < size; i++) {
                 BytesReference type = in.readBytesReference();
                 PipelineAggregator pipelineAggregator = PipelineAggregatorStreams.stream(type).readResult(in);
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregations.java b/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregations.java
index ceefcae..e90547e 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregations.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregations.java
@@ -22,9 +22,7 @@ import com.google.common.base.Function;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.Iterators;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
-
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
@@ -43,6 +41,7 @@ import java.util.List;
 import java.util.Map;
 
 import static com.google.common.collect.Maps.newHashMap;
+import static org.elasticsearch.common.util.CollectionUtils.eagerTransform;
 
 /**
  * An internal implementation of {@link Aggregations}.
@@ -84,7 +83,7 @@ public class InternalAggregations implements Aggregations, ToXContent, Streamabl
      */
     @Override
     public List<Aggregation> asList() {
-        return Lists.transform(aggregations, SUPERTYPE_CAST);
+        return eagerTransform(aggregations, SUPERTYPE_CAST);
     }
 
     /**
@@ -215,7 +214,7 @@ public class InternalAggregations implements Aggregations, ToXContent, Streamabl
             aggregations = ImmutableList.of();
             aggregationsAsMap = ImmutableMap.of();
         } else {
-            aggregations = Lists.newArrayListWithCapacity(size);
+            aggregations = new ArrayList<>(size);
             for (int i = 0; i < size; i++) {
                 BytesReference type = in.readBytesReference();
                 InternalAggregation aggregation = AggregationStreams.stream(type).readResult(in);
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/filters/FiltersAggregator.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/filters/FiltersAggregator.java
index 625ef0b..781d47f 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/filters/FiltersAggregator.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/filters/FiltersAggregator.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.search.aggregations.bucket.filters;
 
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Weight;
@@ -38,6 +36,7 @@ import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;
 import org.elasticsearch.search.aggregations.support.AggregationContext;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -113,7 +112,7 @@ public class FiltersAggregator extends BucketsAggregator {
 
     @Override
     public InternalAggregation buildAggregation(long owningBucketOrdinal) throws IOException {
-        List<InternalFilters.Bucket> buckets = Lists.newArrayListWithCapacity(filters.length);
+        List<InternalFilters.Bucket> buckets = new ArrayList<>(filters.length);
         for (int i = 0; i < keys.length; i++) {
             long bucketOrd = bucketOrd(owningBucketOrdinal, i);
             InternalFilters.Bucket bucket = new InternalFilters.Bucket(keys[i], bucketDocCount(bucketOrd), bucketAggregations(bucketOrd), keyed);
@@ -132,7 +131,7 @@ public class FiltersAggregator extends BucketsAggregator {
     @Override
     public InternalAggregation buildEmptyAggregation() {
         InternalAggregations subAggs = buildEmptySubAggregations();
-        List<InternalFilters.Bucket> buckets = Lists.newArrayListWithCapacity(filters.length);
+        List<InternalFilters.Bucket> buckets = new ArrayList<>(filters.length);
         for (int i = 0; i < keys.length; i++) {
             InternalFilters.Bucket bucket = new InternalFilters.Bucket(keys[i], 0, subAggs, keyed);
             buckets.add(bucket);
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/filters/InternalFilters.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/filters/InternalFilters.java
index f520933..e415a02 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/filters/InternalFilters.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/filters/InternalFilters.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.search.aggregations.bucket.filters;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
@@ -118,7 +116,7 @@ public class InternalFilters extends InternalMultiBucketAggregation<InternalFilt
 
         Bucket reduce(List<Bucket> buckets, ReduceContext context) {
             Bucket reduced = null;
-            List<InternalAggregations> aggregationsList = Lists.newArrayListWithCapacity(buckets.size());
+            List<InternalAggregations> aggregationsList = new ArrayList<>(buckets.size());
             for (Bucket bucket : buckets) {
                 if (reduced == null) {
                     reduced = new Bucket(bucket.key, bucket.docCount, bucket.aggregations, bucket.keyed);
@@ -233,7 +231,7 @@ public class InternalFilters extends InternalMultiBucketAggregation<InternalFilt
     protected void doReadFrom(StreamInput in) throws IOException {
         keyed = in.readBoolean();
         int size = in.readVInt();
-        List<Bucket> buckets = Lists.newArrayListWithCapacity(size);
+        List<Bucket> buckets = new ArrayList<>(size);
         for (int i = 0; i < size; i++) {
             Bucket bucket = new Bucket(keyed);
             bucket.readFrom(in);
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java
index d7d3993..da3bc28 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.search.aggregations.bucket.histogram;
 
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.util.CollectionUtil;
 import org.apache.lucene.util.PriorityQueue;
 import org.elasticsearch.common.io.stream.StreamInput;
@@ -42,6 +40,7 @@ import org.elasticsearch.search.aggregations.support.format.ValueFormatterStream
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
 import java.util.ListIterator;
@@ -464,7 +463,9 @@ public class InternalHistogram<B extends InternalHistogram.Bucket> extends Inter
             // maintains order
         } else if (order == InternalOrder.KEY_DESC) {
             // we just need to reverse here...
-            reducedBuckets = Lists.reverse(reducedBuckets);
+            List<B> reverse = new ArrayList<>(reducedBuckets);
+            Collections.reverse(reverse);
+            reducedBuckets = reverse;
         } else {
             // sorted by sub-aggregation, need to fall back to a costly n*log(n) sort
             CollectionUtil.introSort(reducedBuckets, order.comparator());
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/AbstractRangeBuilder.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/AbstractRangeBuilder.java
index e15aa57..c4f0c76 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/AbstractRangeBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/AbstractRangeBuilder.java
@@ -19,13 +19,13 @@
 
 package org.elasticsearch.search.aggregations.bucket.range;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.search.aggregations.ValuesSourceAggregationBuilder;
 import org.elasticsearch.search.builder.SearchSourceBuilderException;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -61,7 +61,7 @@ public abstract class AbstractRangeBuilder<B extends AbstractRangeBuilder<B>> ex
         }
     }
 
-    protected List<Range> ranges = Lists.newArrayList();
+    protected List<Range> ranges = new ArrayList<>();
 
     protected AbstractRangeBuilder(String name, String type) {
         super(name, type);
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/InternalRange.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/InternalRange.java
index 7356718..5303d7f 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/InternalRange.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/InternalRange.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.search.aggregations.bucket.range;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
@@ -167,7 +165,7 @@ public class InternalRange<B extends InternalRange.Bucket, R extends InternalRan
 
         Bucket reduce(List<Bucket> ranges, ReduceContext context) {
             long docCount = 0;
-            List<InternalAggregations> aggregationsList = Lists.newArrayListWithCapacity(ranges.size());
+            List<InternalAggregations> aggregationsList = new ArrayList<>(ranges.size());
             for (Bucket range : ranges) {
                 docCount += range.docCount;
                 aggregationsList.add(range.aggregations);
@@ -315,7 +313,7 @@ public class InternalRange<B extends InternalRange.Bucket, R extends InternalRan
         formatter = ValueFormatterStreams.readOptional(in);
         keyed = in.readBoolean();
         int size = in.readVInt();
-        List<B> ranges = Lists.newArrayListWithCapacity(size);
+        List<B> ranges = new ArrayList<>(size);
         for (int i = 0; i < size; i++) {
             String key = in.readOptionalString();
             ranges.add(getFactory().createBucket(key, in.readDouble(), in.readDouble(), in.readVLong(), InternalAggregations.readAggregations(in), keyed, formatter));
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/RangeAggregator.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/RangeAggregator.java
index f8e5782..125fca4 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/RangeAggregator.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/RangeAggregator.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.search.aggregations.bucket.range;
 
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.util.InPlaceMergeSorter;
 import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;
@@ -198,7 +196,7 @@ public class RangeAggregator extends BucketsAggregator {
 
     @Override
     public InternalAggregation buildAggregation(long owningBucketOrdinal) throws IOException {
-        List<org.elasticsearch.search.aggregations.bucket.range.Range.Bucket> buckets = Lists.newArrayListWithCapacity(ranges.length);
+        List<org.elasticsearch.search.aggregations.bucket.range.Range.Bucket> buckets = new ArrayList<>(ranges.length);
         for (int i = 0; i < ranges.length; i++) {
             Range range = ranges[i];
             final long bucketOrd = subBucketOrdinal(owningBucketOrdinal, i);
@@ -213,7 +211,7 @@ public class RangeAggregator extends BucketsAggregator {
     @Override
     public InternalAggregation buildEmptyAggregation() {
         InternalAggregations subAggs = buildEmptySubAggregations();
-        List<org.elasticsearch.search.aggregations.bucket.range.Range.Bucket> buckets = Lists.newArrayListWithCapacity(ranges.length);
+        List<org.elasticsearch.search.aggregations.bucket.range.Range.Bucket> buckets = new ArrayList<>(ranges.length);
         for (int i = 0; i < ranges.length; i++) {
             Range range = ranges[i];
             org.elasticsearch.search.aggregations.bucket.range.Range.Bucket bucket =
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/geodistance/GeoDistanceBuilder.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/geodistance/GeoDistanceBuilder.java
index 2b03503..e6649fa 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/geodistance/GeoDistanceBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/geodistance/GeoDistanceBuilder.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.search.aggregations.bucket.range.geodistance;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.geo.GeoDistance;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.unit.DistanceUnit;
@@ -29,6 +28,7 @@ import org.elasticsearch.search.aggregations.AggregationBuilder;
 import org.elasticsearch.search.builder.SearchSourceBuilderException;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
 
@@ -80,7 +80,7 @@ public class GeoDistanceBuilder extends AggregationBuilder<GeoDistanceBuilder> {
     private GeoDistance distanceType;
     private GeoPoint point;
 
-    private List<Range> ranges = Lists.newArrayList();
+    private List<Range> ranges = new ArrayList<>();
 
     /**
      * Sole constructor.
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/geodistance/GeoDistanceParser.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/geodistance/GeoDistanceParser.java
index afe3acf..e110cc1 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/geodistance/GeoDistanceParser.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/range/geodistance/GeoDistanceParser.java
@@ -145,8 +145,8 @@ public class GeoDistanceParser implements Aggregator.Parser {
                             + currentFieldName + "].", parser.getTokenLocation());
                 }
             } else {
-                throw new SearchParseException(context, "Unexpected token " + token + " in [" + aggregationName + "].",
-                        parser.getTokenLocation());
+                throw new SearchParseException(context, "Unexpected token " + token + " in [" + aggregationName + "]: ["
+                        + currentFieldName + "].", parser.getTokenLocation());
             }
         }
 
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java
index f85bd80..0ac3b1d 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java
@@ -28,7 +28,7 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 
 import java.io.IOException;
 
@@ -115,7 +115,7 @@ public class GND extends NXYSignificanceHeuristic {
         }
 
         @Override
-        public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryShardException {
+        public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryParsingException {
             String givenName = parser.currentName();
             boolean backgroundIsSuperset = true;
             XContentParser.Token token = parser.nextToken();
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java
index 5c9794a..78f1573 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java
@@ -27,7 +27,7 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 
 import java.io.IOException;
 
@@ -108,7 +108,7 @@ public class JLHScore extends SignificanceHeuristic {
     public static class JLHScoreParser implements SignificanceHeuristicParser {
 
         @Override
-        public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryShardException {
+        public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryParsingException {
             // move to the closing bracket
             if (!parser.nextToken().equals(XContentParser.Token.END_OBJECT)) {
                 throw new ElasticsearchParseException("failed to parse [jhl] significance heuristic. expected an empty object, but found [{}] instead", parser.currentToken());
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java
index d21b319..cc684c8 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java
@@ -27,7 +27,7 @@ import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 
 import java.io.IOException;
 
@@ -138,7 +138,7 @@ public abstract class NXYSignificanceHeuristic extends SignificanceHeuristic {
     public static abstract class NXYParser implements SignificanceHeuristicParser {
 
         @Override
-        public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryShardException {
+        public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryParsingException {
             String givenName = parser.currentName();
             boolean includeNegatives = false;
             boolean backgroundIsSuperset = true;
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java
index 25556c9..1587a8f 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java
@@ -27,7 +27,7 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 
 import java.io.IOException;
 
@@ -77,7 +77,7 @@ public class PercentageScore extends SignificanceHeuristic {
     public static class PercentageScoreParser implements SignificanceHeuristicParser {
 
         @Override
-        public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryShardException {
+        public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryParsingException {
             // move to the closing bracket
             if (!parser.nextToken().equals(XContentParser.Token.END_OBJECT)) {
                 throw new ElasticsearchParseException("failed to parse [percentage] significance heuristic. expected an empty object, but got [{}] instead", parser.currentToken());
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
index d3a4e64..1be9df2 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
@@ -30,7 +30,7 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.logging.ESLoggerFactory;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.script.*;
 import org.elasticsearch.script.Script.ScriptField;
 import org.elasticsearch.script.ScriptParameterParser.ScriptParameterValue;
@@ -129,7 +129,7 @@ public class ScriptHeuristic extends SignificanceHeuristic {
         }
 
         @Override
-        public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryShardException {
+        public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryParsingException {
             String heuristicName = parser.currentName();
             Script script = null;
             XContentParser.Token token;
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/SiblingPipelineAggregator.java b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/SiblingPipelineAggregator.java
index cb14b0d..fcccba0 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/SiblingPipelineAggregator.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/SiblingPipelineAggregator.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.search.aggregations.pipeline;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.search.aggregations.Aggregations;
 import org.elasticsearch.search.aggregations.InternalAggregation;
 import org.elasticsearch.search.aggregations.InternalAggregation.ReduceContext;
@@ -33,6 +31,8 @@ import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
+import static org.elasticsearch.common.util.CollectionUtils.eagerTransform;
+
 public abstract class SiblingPipelineAggregator extends PipelineAggregator {
 
     protected SiblingPipelineAggregator() { // for Serialisation
@@ -54,7 +54,7 @@ public abstract class SiblingPipelineAggregator extends PipelineAggregator {
             for (int i = 0; i < buckets.size(); i++) {
                 InternalMultiBucketAggregation.InternalBucket bucket = (InternalMultiBucketAggregation.InternalBucket) buckets.get(i);
                 InternalAggregation aggToAdd = doReduce(bucket.getAggregations(), reduceContext);
-                List<InternalAggregation> aggs = new ArrayList<>(Lists.transform(bucket.getAggregations().asList(),
+                List<InternalAggregation> aggs = new ArrayList<>(eagerTransform(bucket.getAggregations().asList(),
                         AGGREGATION_TRANFORM_FUNCTION));
                 aggs.add(aggToAdd);
                 InternalMultiBucketAggregation.InternalBucket newBucket = multiBucketsAgg.createBucket(new InternalAggregations(aggs),
@@ -66,7 +66,7 @@ public abstract class SiblingPipelineAggregator extends PipelineAggregator {
         } else if (aggregation instanceof InternalSingleBucketAggregation) {
             InternalSingleBucketAggregation singleBucketAgg = (InternalSingleBucketAggregation) aggregation;
             InternalAggregation aggToAdd = doReduce(singleBucketAgg.getAggregations(), reduceContext);
-            List<InternalAggregation> aggs = new ArrayList<>(Lists.transform(singleBucketAgg.getAggregations().asList(),
+            List<InternalAggregation> aggs = new ArrayList<>(eagerTransform(singleBucketAgg.getAggregations().asList(),
                     AGGREGATION_TRANFORM_FUNCTION));
             aggs.add(aggToAdd);
             return singleBucketAgg.create(new InternalAggregations(aggs));
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketscript/BucketScriptPipelineAggregator.java b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketscript/BucketScriptPipelineAggregator.java
index 3b2a4a5..0655964 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketscript/BucketScriptPipelineAggregator.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketscript/BucketScriptPipelineAggregator.java
@@ -20,8 +20,6 @@
 package org.elasticsearch.search.aggregations.pipeline.bucketscript;
 
 import com.google.common.base.Function;
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.script.CompiledScript;
@@ -50,6 +48,7 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
+import static org.elasticsearch.common.util.CollectionUtils.eagerTransform;
 import static org.elasticsearch.search.aggregations.pipeline.BucketHelpers.resolveBucketValue;
 
 public class BucketScriptPipelineAggregator extends PipelineAggregator {
@@ -135,7 +134,7 @@ public class BucketScriptPipelineAggregator extends PipelineAggregator {
                         throw new AggregationExecutionException("series_arithmetic script for reducer [" + name()
                                 + "] must return a Number");
                     }
-                    List<InternalAggregation> aggs = new ArrayList<>(Lists.transform(bucket.getAggregations().asList(), FUNCTION));
+                    List<InternalAggregation> aggs = new ArrayList<>(eagerTransform(bucket.getAggregations().asList(), FUNCTION));
                     aggs.add(new InternalSimpleValue(name(), ((Number) returned).doubleValue(), formatter,
                             new ArrayList<PipelineAggregator>(), metaData()));
                     InternalMultiBucketAggregation.InternalBucket newBucket = originalAgg.createBucket(new InternalAggregations(aggs),
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/cumulativesum/CumulativeSumPipelineAggregator.java b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/cumulativesum/CumulativeSumPipelineAggregator.java
index 9070cc6..cafefdb 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/cumulativesum/CumulativeSumPipelineAggregator.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/cumulativesum/CumulativeSumPipelineAggregator.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.search.aggregations.pipeline.cumulativesum;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.search.aggregations.AggregatorFactory;
@@ -43,6 +41,7 @@ import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
+import static org.elasticsearch.common.util.CollectionUtils.eagerTransform;
 import static org.elasticsearch.search.aggregations.pipeline.BucketHelpers.resolveBucketValue;
 
 public class CumulativeSumPipelineAggregator extends PipelineAggregator {
@@ -89,7 +88,7 @@ public class CumulativeSumPipelineAggregator extends PipelineAggregator {
         for (InternalHistogram.Bucket bucket : buckets) {
             Double thisBucketValue = resolveBucketValue(histo, bucket, bucketsPaths()[0], GapPolicy.INSERT_ZEROS);
             sum += thisBucketValue;
-            List<InternalAggregation> aggs = new ArrayList<>(Lists.transform(bucket.getAggregations().asList(),
+            List<InternalAggregation> aggs = new ArrayList<>(eagerTransform(bucket.getAggregations().asList(),
                     AGGREGATION_TRANFORM_FUNCTION));
             aggs.add(new InternalSimpleValue(name(), sum, formatter, new ArrayList<PipelineAggregator>(), metaData()));
             InternalHistogram.Bucket newBucket = factory.createBucket(bucket.getKey(), bucket.getDocCount(),
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/derivative/DerivativePipelineAggregator.java b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/derivative/DerivativePipelineAggregator.java
index eeb3192..41b904f 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/derivative/DerivativePipelineAggregator.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/derivative/DerivativePipelineAggregator.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.search.aggregations.pipeline.derivative;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.search.aggregations.AggregationExecutionException;
@@ -44,6 +42,7 @@ import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
+import static org.elasticsearch.common.util.CollectionUtils.eagerTransform;
 import static org.elasticsearch.search.aggregations.pipeline.BucketHelpers.resolveBucketValue;
 
 public class DerivativePipelineAggregator extends PipelineAggregator {
@@ -101,7 +100,7 @@ public class DerivativePipelineAggregator extends PipelineAggregator {
                 if (xAxisUnits != null) {
                     xDiff = (thisBucketKey - lastBucketKey) / xAxisUnits;
                 }
-                List<InternalAggregation> aggs = new ArrayList<>(Lists.transform(bucket.getAggregations().asList(),
+                List<InternalAggregation> aggs = new ArrayList<>(eagerTransform(bucket.getAggregations().asList(),
                         AGGREGATION_TRANFORM_FUNCTION));
                 aggs.add(new InternalDerivative(name(), gradient, xDiff, formatter, new ArrayList<PipelineAggregator>(), metaData()));
                 InternalHistogram.Bucket newBucket = factory.createBucket(bucket.getKey(), bucket.getDocCount(), new InternalAggregations(
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/MovAvgPipelineAggregator.java b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/MovAvgPipelineAggregator.java
index 5b7a867..b1dd92d 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/MovAvgPipelineAggregator.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/MovAvgPipelineAggregator.java
@@ -21,8 +21,6 @@ package org.elasticsearch.search.aggregations.pipeline.movavg;
 
 import com.google.common.base.Function;
 import com.google.common.collect.EvictingQueue;
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.search.aggregations.Aggregation;
@@ -51,6 +49,7 @@ import java.util.List;
 import java.util.ListIterator;
 import java.util.Map;
 
+import static org.elasticsearch.common.util.CollectionUtils.eagerTransform;
 import static org.elasticsearch.search.aggregations.pipeline.BucketHelpers.resolveBucketValue;
 
 public class MovAvgPipelineAggregator extends PipelineAggregator {
@@ -135,7 +134,7 @@ public class MovAvgPipelineAggregator extends PipelineAggregator {
                 if (model.hasValue(values.size())) {
                     double movavg = model.next(values);
 
-                    List<InternalAggregation> aggs = new ArrayList<>(Lists.transform(bucket.getAggregations().asList(), AGGREGATION_TRANFORM_FUNCTION));
+                    List<InternalAggregation> aggs = new ArrayList<>(eagerTransform(bucket.getAggregations().asList(), AGGREGATION_TRANFORM_FUNCTION));
                     aggs.add(new InternalSimpleValue(name(), movavg, formatter, new ArrayList<PipelineAggregator>(), metaData()));
                     newBucket = factory.createBucket(bucket.getKey(), bucket.getDocCount(), new InternalAggregations(
                             aggs), bucket.getKeyed(), bucket.getFormatter());
@@ -176,7 +175,7 @@ public class MovAvgPipelineAggregator extends PipelineAggregator {
                     InternalHistogram.Bucket bucket = (InternalHistogram.Bucket) newBuckets.get(lastValidPosition + i + 1);
 
                     // Get the existing aggs in the bucket so we don't clobber data
-                    aggs = new ArrayList<>(Lists.transform(bucket.getAggregations().asList(), AGGREGATION_TRANFORM_FUNCTION));
+                    aggs = new ArrayList<>(eagerTransform(bucket.getAggregations().asList(), AGGREGATION_TRANFORM_FUNCTION));
                     aggs.add(new InternalSimpleValue(name(), predictions[i], formatter, new ArrayList<PipelineAggregator>(), metaData()));
 
                     InternalHistogram.Bucket newBucket = factory.createBucket(newKey, 0, new InternalAggregations(
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/serialdiff/SerialDiffPipelineAggregator.java b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/serialdiff/SerialDiffPipelineAggregator.java
index 3517a62..e89813c 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/serialdiff/SerialDiffPipelineAggregator.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/serialdiff/SerialDiffPipelineAggregator.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.search.aggregations.pipeline.serialdiff;
 
 import com.google.common.collect.EvictingQueue;
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
@@ -29,7 +28,10 @@ import org.elasticsearch.search.aggregations.InternalAggregation.ReduceContext;
 import org.elasticsearch.search.aggregations.InternalAggregation.Type;
 import org.elasticsearch.search.aggregations.InternalAggregations;
 import org.elasticsearch.search.aggregations.bucket.histogram.InternalHistogram;
-import org.elasticsearch.search.aggregations.pipeline.*;
+import org.elasticsearch.search.aggregations.pipeline.InternalSimpleValue;
+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;
+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregatorFactory;
+import org.elasticsearch.search.aggregations.pipeline.PipelineAggregatorStreams;
 import org.elasticsearch.search.aggregations.support.format.ValueFormatter;
 import org.elasticsearch.search.aggregations.support.format.ValueFormatterStreams;
 
@@ -38,8 +40,9 @@ import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
-import static org.elasticsearch.search.aggregations.pipeline.BucketHelpers.resolveBucketValue;
+import static org.elasticsearch.common.util.CollectionUtils.eagerTransform;
 import static org.elasticsearch.search.aggregations.pipeline.BucketHelpers.GapPolicy;
+import static org.elasticsearch.search.aggregations.pipeline.BucketHelpers.resolveBucketValue;
 
 public class SerialDiffPipelineAggregator extends PipelineAggregator {
 
@@ -111,7 +114,7 @@ public class SerialDiffPipelineAggregator extends PipelineAggregator {
             if (!Double.isNaN(thisBucketValue) && !Double.isNaN(lagValue)) {
                 double diff = thisBucketValue - lagValue;
 
-                List<InternalAggregation> aggs = new ArrayList<>(Lists.transform(bucket.getAggregations().asList(), AGGREGATION_TRANFORM_FUNCTION));
+                List<InternalAggregation> aggs = new ArrayList<>(eagerTransform(bucket.getAggregations().asList(), AGGREGATION_TRANFORM_FUNCTION));
                 aggs.add(new InternalSimpleValue(name(), diff, formatter, new ArrayList<PipelineAggregator>(), metaData()));
                 newBucket = factory.createBucket(bucket.getKey(), bucket.getDocCount(), new InternalAggregations(
                         aggs), bucket.getKeyed(), bucket.getFormatter());
diff --git a/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java b/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java
index 2df22bb..90ce07b 100644
--- a/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java
@@ -22,8 +22,6 @@ package org.elasticsearch.search.builder;
 import com.carrotsearch.hppc.ObjectFloatHashMap;
 import com.google.common.base.Charsets;
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.ElasticsearchGenerationException;
 import org.elasticsearch.action.support.QuerySourceBuilder;
 import org.elasticsearch.action.support.ToXContentToBytes;
@@ -49,7 +47,11 @@ import org.elasticsearch.search.sort.SortOrder;
 import org.elasticsearch.search.suggest.SuggestBuilder;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
 
 /**
  * A search source builder allowing to easily build search source. Simple
@@ -359,7 +361,7 @@ public class SearchSourceBuilder extends ToXContentToBytes {
      */
     public SearchSourceBuilder sort(SortBuilder sort) {
         if (sorts == null) {
-            sorts = Lists.newArrayList();
+            sorts = new ArrayList<>();
         }
         sorts.add(sort);
         return this;
@@ -379,7 +381,7 @@ public class SearchSourceBuilder extends ToXContentToBytes {
      */
     public SearchSourceBuilder aggregation(AbstractAggregationBuilder aggregation) {
         if (aggregations == null) {
-            aggregations = Lists.newArrayList();
+            aggregations = new ArrayList<>();
         }
         aggregations.add(aggregation);
         return this;
@@ -598,7 +600,7 @@ public class SearchSourceBuilder extends ToXContentToBytes {
      */
     public SearchSourceBuilder scriptField(String name, Script script) {
         if (scriptFields == null) {
-            scriptFields = Lists.newArrayList();
+            scriptFields = new ArrayList<>();
         }
         scriptFields.add(new ScriptField(name, script));
         return this;
diff --git a/core/src/main/java/org/elasticsearch/search/controller/SearchPhaseController.java b/core/src/main/java/org/elasticsearch/search/controller/SearchPhaseController.java
index 7faaea7..74e2632 100644
--- a/core/src/main/java/org/elasticsearch/search/controller/SearchPhaseController.java
+++ b/core/src/main/java/org/elasticsearch/search/controller/SearchPhaseController.java
@@ -21,8 +21,6 @@ package org.elasticsearch.search.controller;
 
 import com.carrotsearch.hppc.IntArrayList;
 import com.carrotsearch.hppc.ObjectObjectHashMap;
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.CollectionStatistics;
 import org.apache.lucene.search.FieldDoc;
@@ -65,6 +63,8 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
+import static org.elasticsearch.common.util.CollectionUtils.eagerTransform;
+
 /**
  *
  */
@@ -411,7 +411,7 @@ public class SearchPhaseController extends AbstractComponent {
         if (aggregations != null) {
             List<SiblingPipelineAggregator> pipelineAggregators = firstResult.pipelineAggregators();
             if (pipelineAggregators != null) {
-                List<InternalAggregation> newAggs = new ArrayList<>(Lists.transform(aggregations.asList(), PipelineAggregator.AGGREGATION_TRANFORM_FUNCTION));
+                List<InternalAggregation> newAggs = new ArrayList<>(eagerTransform(aggregations.asList(), PipelineAggregator.AGGREGATION_TRANFORM_FUNCTION));
                 for (SiblingPipelineAggregator pipelineAggregator : pipelineAggregators) {
                     InternalAggregation newAgg = pipelineAggregator.doReduce(new InternalAggregations(newAggs), new ReduceContext(bigArrays,
                             scriptService));
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java
index 81f13c3..f915686 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java
@@ -45,20 +45,12 @@ import org.elasticsearch.index.mapper.DocumentMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.internal.SourceFieldMapper;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHitField;
 import org.elasticsearch.search.SearchParseElement;
 import org.elasticsearch.search.SearchPhase;
-import org.elasticsearch.search.fetch.explain.ExplainFetchSubPhase;
-import org.elasticsearch.search.fetch.fielddata.FieldDataFieldsFetchSubPhase;
 import org.elasticsearch.search.fetch.innerhits.InnerHitsFetchSubPhase;
-import org.elasticsearch.search.fetch.matchedqueries.MatchedQueriesFetchSubPhase;
-import org.elasticsearch.search.fetch.script.ScriptFieldsFetchSubPhase;
 import org.elasticsearch.search.fetch.source.FetchSourceContext;
-import org.elasticsearch.search.fetch.source.FetchSourceSubPhase;
-import org.elasticsearch.search.fetch.version.VersionFetchSubPhase;
-import org.elasticsearch.search.highlight.HighlightPhase;
 import org.elasticsearch.search.internal.InternalSearchHit;
 import org.elasticsearch.search.internal.InternalSearchHitField;
 import org.elasticsearch.search.internal.InternalSearchHits;
@@ -73,7 +65,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.common.xcontent.XContentFactory.contentBuilder;
 
 /**
@@ -146,7 +137,7 @@ public class FetchPhase implements SearchPhase {
                     fieldNames.add(fieldType.names().indexName());
                 } else {
                     if (extractFieldNames == null) {
-                        extractFieldNames = newArrayList();
+                        extractFieldNames = new ArrayList<>();
                     }
                     extractFieldNames.add(fieldName);
                 }
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/explain/ExplainFetchSubPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/explain/ExplainFetchSubPhase.java
index 026e421..1c0eeaa 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/explain/ExplainFetchSubPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/explain/ExplainFetchSubPhase.java
@@ -20,7 +20,6 @@ package org.elasticsearch.search.fetch.explain;
 
 import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.search.Explanation;
-import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.search.SearchParseElement;
 import org.elasticsearch.search.fetch.FetchPhaseExecutionException;
 import org.elasticsearch.search.fetch.FetchSubPhase;
@@ -68,6 +67,8 @@ public class ExplainFetchSubPhase implements FetchSubPhase {
             hitContext.hit().explanation(explanation);
         } catch (IOException e) {
             throw new FetchPhaseExecutionException(context, "Failed to explain doc [" + hitContext.hit().type() + "#" + hitContext.hit().id() + "]", e);
+        } finally {
+            context.clearReleasables(SearchContext.Lifetime.COLLECTION);
         }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/fielddata/FieldDataFieldsContext.java b/core/src/main/java/org/elasticsearch/search/fetch/fielddata/FieldDataFieldsContext.java
index 9f1bfc0..c352e6a 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/fielddata/FieldDataFieldsContext.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/fielddata/FieldDataFieldsContext.java
@@ -18,9 +18,9 @@
  */
 package org.elasticsearch.search.fetch.fielddata;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.search.fetch.FetchSubPhaseContext;
 
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -40,7 +40,7 @@ public class FieldDataFieldsContext extends FetchSubPhaseContext {
         }
     }
 
-    private List<FieldDataField> fields = Lists.newArrayList();
+    private List<FieldDataField> fields = new ArrayList<>();
 
     public FieldDataFieldsContext() {
     }
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsContext.java b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsContext.java
index b639a38..75b4b4f 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsContext.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsContext.java
@@ -135,7 +135,11 @@ public final class InnerHitsContext {
                 } else {
                     topDocsCollector = TopScoreDocCollector.create(topN);
                 }
-                context.searcher().search(q, topDocsCollector);
+                try {
+                    context.searcher().search(q, topDocsCollector);
+                } finally {
+                    clearReleasables(Lifetime.COLLECTION);
+                }
                 return topDocsCollector.topDocs(from(), size());
             }
         }
@@ -306,7 +310,11 @@ public final class InnerHitsContext {
                 } else {
                     topDocsCollector = TopScoreDocCollector.create(topN);
                 }
-                context.searcher().search( q, topDocsCollector);
+                try {
+                    context.searcher().search(q, topDocsCollector);
+                } finally {
+                    clearReleasables(Lifetime.COLLECTION);
+                }
                 return topDocsCollector.topDocs(from(), size());
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java
index ac6dc18..c02e2c6 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java
@@ -24,7 +24,7 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.mapper.DocumentMapper;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
 import org.elasticsearch.index.query.ParsedQuery;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.search.SearchParseElement;
 import org.elasticsearch.search.fetch.fielddata.FieldDataFieldsParseElement;
 import org.elasticsearch.search.fetch.script.ScriptFieldsParseElement;
@@ -59,15 +59,15 @@ public class InnerHitsParseElement implements SearchParseElement {
 
     @Override
     public void parse(XContentParser parser, SearchContext searchContext) throws Exception {
-        QueryShardContext context = searchContext.queryParserService().getShardContext();
-        context.reset(parser);
-        Map<String, InnerHitsContext.BaseInnerHits> innerHitsMap = parseInnerHits(parser, context, searchContext);
+        QueryParseContext parseContext = searchContext.queryParserService().getParseContext();
+        parseContext.reset(parser);
+        Map<String, InnerHitsContext.BaseInnerHits> innerHitsMap = parseInnerHits(parser, parseContext, searchContext);
         if (innerHitsMap != null) {
             searchContext.innerHits(new InnerHitsContext(innerHitsMap));
         }
     }
 
-    private Map<String, InnerHitsContext.BaseInnerHits> parseInnerHits(XContentParser parser, QueryShardContext context, SearchContext searchContext) throws Exception {
+    private Map<String, InnerHitsContext.BaseInnerHits> parseInnerHits(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext) throws Exception {
         XContentParser.Token token;
         Map<String, InnerHitsContext.BaseInnerHits> innerHitsMap = null;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -79,7 +79,7 @@ public class InnerHitsParseElement implements SearchParseElement {
             if (token != XContentParser.Token.START_OBJECT) {
                 throw new IllegalArgumentException("Inner hit definition for [" + innerHitName + " starts with a [" + token + "], expected a [" + XContentParser.Token.START_OBJECT + "].");
             }
-            InnerHitsContext.BaseInnerHits innerHits = parseInnerHit(parser, context, searchContext, innerHitName);
+            InnerHitsContext.BaseInnerHits innerHits = parseInnerHit(parser, parseContext, searchContext, innerHitName);
             if (innerHitsMap == null) {
                 innerHitsMap = new HashMap<>();
             }
@@ -88,7 +88,7 @@ public class InnerHitsParseElement implements SearchParseElement {
         return innerHitsMap;
     }
 
-    private InnerHitsContext.BaseInnerHits parseInnerHit(XContentParser parser, QueryShardContext context, SearchContext searchContext, String innerHitName) throws Exception {
+    private InnerHitsContext.BaseInnerHits parseInnerHit(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext, String innerHitName) throws Exception {
         XContentParser.Token token = parser.nextToken();
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new IllegalArgumentException("Unexpected token " + token + " inside inner hit definition. Either specify [path] or [type] object");
@@ -123,9 +123,9 @@ public class InnerHitsParseElement implements SearchParseElement {
 
         final InnerHitsContext.BaseInnerHits innerHits;
         if (nestedPath != null) {
-            innerHits = parseNested(parser, context, searchContext, fieldName);
+            innerHits = parseNested(parser, parseContext, searchContext, fieldName);
         } else if (type != null) {
-            innerHits = parseParentChild(parser, context, searchContext, fieldName);
+            innerHits = parseParentChild(parser, parseContext, searchContext, fieldName);
         } else {
             throw new IllegalArgumentException("Either [path] or [type] must be defined");
         }
@@ -143,16 +143,16 @@ public class InnerHitsParseElement implements SearchParseElement {
         return innerHits;
     }
 
-    private InnerHitsContext.ParentChildInnerHits parseParentChild(XContentParser parser, QueryShardContext context, SearchContext searchContext, String type) throws Exception {
-        ParseResult parseResult = parseSubSearchContext(searchContext, context, parser);
+    private InnerHitsContext.ParentChildInnerHits parseParentChild(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext, String type) throws Exception {
+        ParseResult parseResult = parseSubSearchContext(searchContext, parseContext, parser);
         DocumentMapper documentMapper = searchContext.mapperService().documentMapper(type);
         if (documentMapper == null) {
             throw new IllegalArgumentException("type [" + type + "] doesn't exist");
         }
-        return new InnerHitsContext.ParentChildInnerHits(parseResult.context(), parseResult.query(), parseResult.childInnerHits(), context.mapperService(), documentMapper);
+        return new InnerHitsContext.ParentChildInnerHits(parseResult.context(), parseResult.query(), parseResult.childInnerHits(), parseContext.mapperService(), documentMapper);
     }
 
-    private InnerHitsContext.NestedInnerHits parseNested(XContentParser parser, QueryShardContext context, SearchContext searchContext, String nestedPath) throws Exception {
+    private InnerHitsContext.NestedInnerHits parseNested(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext, String nestedPath) throws Exception {
         ObjectMapper objectMapper = searchContext.getObjectMapper(nestedPath);
         if (objectMapper == null) {
             throw new IllegalArgumentException("path [" + nestedPath +"] doesn't exist");
@@ -160,14 +160,14 @@ public class InnerHitsParseElement implements SearchParseElement {
         if (objectMapper.nested().isNested() == false) {
             throw new IllegalArgumentException("path [" + nestedPath +"] isn't nested");
         }
-        ObjectMapper parentObjectMapper = context.nestedScope().nextLevel(objectMapper);
-        ParseResult parseResult = parseSubSearchContext(searchContext, context, parser);
-        context.nestedScope().previousLevel();
+        ObjectMapper parentObjectMapper = parseContext.nestedScope().nextLevel(objectMapper);
+        ParseResult parseResult = parseSubSearchContext(searchContext, parseContext, parser);
+        parseContext.nestedScope().previousLevel();
 
         return new InnerHitsContext.NestedInnerHits(parseResult.context(), parseResult.query(), parseResult.childInnerHits(), parentObjectMapper, objectMapper);
     }
 
-    private ParseResult parseSubSearchContext(SearchContext searchContext, QueryShardContext context, XContentParser parser) throws Exception {
+    private ParseResult parseSubSearchContext(SearchContext searchContext, QueryParseContext parseContext, XContentParser parser) throws Exception {
         ParsedQuery query = null;
         Map<String, InnerHitsContext.BaseInnerHits> childInnerHits = null;
         SubSearchContext subSearchContext = new SubSearchContext(searchContext);
@@ -178,10 +178,10 @@ public class InnerHitsParseElement implements SearchParseElement {
                 fieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("query".equals(fieldName)) {
-                    Query q = searchContext.queryParserService().parseInnerQuery(context);
-                    query = new ParsedQuery(q, context.copyNamedQueries());
+                    Query q = searchContext.queryParserService().parseInnerQuery(parseContext);
+                    query = new ParsedQuery(q, parseContext.copyNamedQueries());
                 } else if ("inner_hits".equals(fieldName)) {
-                    childInnerHits = parseInnerHits(parser, context, searchContext);
+                    childInnerHits = parseInnerHits(parser, parseContext, searchContext);
                 } else {
                     parseCommonInnerHitOptions(parser, token, fieldName, subSearchContext, sortParseElement, sourceParseElement, highlighterParseElement, scriptFieldsParseElement, fieldDataFieldsParseElement);
                 }
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsSubSearchContext.java b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsSubSearchContext.java
new file mode 100644
index 0000000..35ab2e1
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsSubSearchContext.java
@@ -0,0 +1,40 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.search.fetch.innerhits;
+
+import org.elasticsearch.search.internal.SubSearchContext;
+
+public class InnerHitsSubSearchContext {
+    private final String name;
+    private final SubSearchContext subSearchContext;
+
+    public InnerHitsSubSearchContext(String name, SubSearchContext subSearchContext) {
+        this.name = name;
+        this.subSearchContext = subSearchContext;
+    }
+
+    public String getName() {
+        return name;
+    }
+
+    public SubSearchContext getSubSearchContext() {
+        return subSearchContext;
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/matchedqueries/MatchedQueriesFetchSubPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/matchedqueries/MatchedQueriesFetchSubPhase.java
index ac4dfa5..75e62d6 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/matchedqueries/MatchedQueriesFetchSubPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/matchedqueries/MatchedQueriesFetchSubPhase.java
@@ -19,8 +19,6 @@
 package org.elasticsearch.search.fetch.matchedqueries;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.TwoPhaseIterator;
@@ -33,6 +31,7 @@ import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.search.internal.SearchContext.Lifetime;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -63,7 +62,7 @@ public class MatchedQueriesFetchSubPhase implements FetchSubPhase {
 
     @Override
     public void hitExecute(SearchContext context, HitContext hitContext) {
-        List<String> matchedQueries = Lists.newArrayListWithCapacity(2);
+        List<String> matchedQueries = new ArrayList<>(2);
 
         try {
             addMatchedQueries(hitContext, context.parsedQuery().namedFilters(), matchedQueries);
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/script/ScriptFieldsContext.java b/core/src/main/java/org/elasticsearch/search/fetch/script/ScriptFieldsContext.java
index 27a7b2a..9cf680d 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/script/ScriptFieldsContext.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/script/ScriptFieldsContext.java
@@ -19,9 +19,9 @@
 
 package org.elasticsearch.search.fetch.script;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.script.SearchScript;
 
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -53,7 +53,7 @@ public class ScriptFieldsContext {
         }
     }
 
-    private List<ScriptField> fields = Lists.newArrayList();
+    private List<ScriptField> fields = new ArrayList<>();
 
     public ScriptFieldsContext() {
     }
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java b/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java
index 79fb54c..c082859 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java
@@ -26,11 +26,10 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * A builder for search highlighting. Settings can control how large fields
  * are summarized to show only selected snippets ("fragments") containing search terms.
@@ -87,7 +86,7 @@ public class HighlightBuilder implements ToXContent {
      */
     public HighlightBuilder field(String name) {
         if (fields == null) {
-            fields = newArrayList();
+            fields = new ArrayList<>();
         }
         fields.add(new Field(name));
         return this;
@@ -103,7 +102,7 @@ public class HighlightBuilder implements ToXContent {
      */
     public HighlightBuilder field(String name, int fragmentSize) {
         if (fields == null) {
-            fields = newArrayList();
+            fields = new ArrayList<>();
         }
         fields.add(new Field(name).fragmentSize(fragmentSize));
         return this;
@@ -120,7 +119,7 @@ public class HighlightBuilder implements ToXContent {
      */
     public HighlightBuilder field(String name, int fragmentSize, int numberOfFragments) {
         if (fields == null) {
-            fields = newArrayList();
+            fields = new ArrayList<>();
         }
         fields.add(new Field(name).fragmentSize(fragmentSize).numOfFragments(numberOfFragments));
         return this;
@@ -138,7 +137,7 @@ public class HighlightBuilder implements ToXContent {
      */
     public HighlightBuilder field(String name, int fragmentSize, int numberOfFragments, int fragmentOffset) {
         if (fields == null) {
-            fields = newArrayList();
+            fields = new ArrayList<>();
         }
         fields.add(new Field(name).fragmentSize(fragmentSize).numOfFragments(numberOfFragments)
                 .fragmentOffset(fragmentOffset));
@@ -147,7 +146,7 @@ public class HighlightBuilder implements ToXContent {
 
     public HighlightBuilder field(Field field) {
         if (fields == null) {
-            fields = newArrayList();
+            fields = new ArrayList<>();
         }
         fields.add(field);
         return this;
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java b/core/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java
index 802122f..74723c7 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java
@@ -19,9 +19,7 @@
 
 package org.elasticsearch.search.highlight;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
-
 import org.apache.lucene.search.vectorhighlight.SimpleBoundaryScanner;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -31,11 +29,10 @@ import org.elasticsearch.search.SearchParseException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
 
-import static com.google.common.collect.Lists.newArrayList;
-
 /**
  * <pre>
  * highlight : {
@@ -78,7 +75,7 @@ public class HighlighterParseElement implements SearchParseElement {
     public SearchContextHighlight parse(XContentParser parser, IndexQueryParserService queryParserService) throws IOException {
         XContentParser.Token token;
         String topLevelFieldName = null;
-        final List<Tuple<String, SearchContextHighlight.FieldOptions.Builder>> fieldsOptions = newArrayList();
+        final List<Tuple<String, SearchContextHighlight.FieldOptions.Builder>> fieldsOptions = new ArrayList<>();
 
         final SearchContextHighlight.FieldOptions.Builder globalOptionsBuilder = new SearchContextHighlight.FieldOptions.Builder()
                 .preTags(DEFAULT_PRE_TAGS).postTags(DEFAULT_POST_TAGS).scoreOrdered(false).highlightFilter(false)
@@ -92,13 +89,13 @@ public class HighlighterParseElement implements SearchParseElement {
                 topLevelFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_ARRAY) {
                 if ("pre_tags".equals(topLevelFieldName) || "preTags".equals(topLevelFieldName)) {
-                    List<String> preTagsList = Lists.newArrayList();
+                    List<String> preTagsList = new ArrayList<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         preTagsList.add(parser.text());
                     }
                     globalOptionsBuilder.preTags(preTagsList.toArray(new String[preTagsList.size()]));
                 } else if ("post_tags".equals(topLevelFieldName) || "postTags".equals(topLevelFieldName)) {
-                    List<String> postTagsList = Lists.newArrayList();
+                    List<String> postTagsList = new ArrayList<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         postTagsList.add(parser.text());
                     }
@@ -184,7 +181,7 @@ public class HighlighterParseElement implements SearchParseElement {
             throw new IllegalArgumentException("Highlighter global preTags are set, but global postTags are not set");
         }
 
-        final List<SearchContextHighlight.Field> fields = Lists.newArrayList();
+        final List<SearchContextHighlight.Field> fields = new ArrayList<>();
         // now, go over and fill all fieldsOptions with default values from the global state
         for (final Tuple<String, SearchContextHighlight.FieldOptions.Builder> tuple : fieldsOptions) {
             fields.add(new SearchContextHighlight.Field(tuple.v1(), tuple.v2().merge(globalOptions).build()));
@@ -202,13 +199,13 @@ public class HighlighterParseElement implements SearchParseElement {
                 fieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_ARRAY) {
                 if ("pre_tags".equals(fieldName) || "preTags".equals(fieldName)) {
-                    List<String> preTagsList = Lists.newArrayList();
+                    List<String> preTagsList = new ArrayList<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         preTagsList.add(parser.text());
                     }
                     fieldOptionsBuilder.preTags(preTagsList.toArray(new String[preTagsList.size()]));
                 } else if ("post_tags".equals(fieldName) || "postTags".equals(fieldName)) {
-                    List<String> postTagsList = Lists.newArrayList();
+                    List<String> postTagsList = new ArrayList<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         postTagsList.add(parser.text());
                     }
diff --git a/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java b/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java
index 2f55bf8..369d761 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/ContextIndexSearcher.java
@@ -19,18 +19,14 @@
 
 package org.elasticsearch.search.internal;
 
-import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
 import org.apache.lucene.search.*;
-import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.common.lease.Releasable;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.search.dfs.AggregatedDfs;
-import org.elasticsearch.search.internal.SearchContext.Lifetime;
 
 import java.io.IOException;
-import java.util.List;
 
 /**
  * Context-aware extension of {@link IndexSearcher}.
@@ -42,14 +38,11 @@ public class ContextIndexSearcher extends IndexSearcher implements Releasable {
      *  AssertingIndexSearcher. */
     private final IndexSearcher in;
 
-    private final SearchContext searchContext;
-
     private AggregatedDfs aggregatedDfs;
 
     public ContextIndexSearcher(SearchContext searchContext, Engine.Searcher searcher) {
         super(searcher.reader());
         in = searcher.searcher();
-        this.searchContext = searchContext;
         setSimilarity(searcher.searcher().getSimilarity(true));
         setQueryCache(searchContext.indexShard().indexService().cache().query());
         setQueryCachingPolicy(searchContext.indexShard().getQueryCachingPolicy());
@@ -65,46 +58,23 @@ public class ContextIndexSearcher extends IndexSearcher implements Releasable {
 
     @Override
     public Query rewrite(Query original) throws IOException {
-        try {
-            return in.rewrite(original);
-        } catch (Throwable t) {
-            searchContext.clearReleasables(Lifetime.COLLECTION);
-            throw ExceptionsHelper.convertToElastic(t);
-        }
+        return in.rewrite(original);
     }
 
     @Override
     public Weight createNormalizedWeight(Query query, boolean needsScores) throws IOException {
         // During tests we prefer to use the wrapped IndexSearcher, because then we use the AssertingIndexSearcher
         // it is hacky, because if we perform a dfs search, we don't use the wrapped IndexSearcher...
-        try {
+        if (aggregatedDfs != null && needsScores) {
             // if scores are needed and we have dfs data then use it
-            if (aggregatedDfs != null && needsScores) {
-                return super.createNormalizedWeight(query, needsScores);
-            }
-            return in.createNormalizedWeight(query, needsScores);
-        } catch (Throwable t) {
-            searchContext.clearReleasables(Lifetime.COLLECTION);
-            throw ExceptionsHelper.convertToElastic(t);
+            return super.createNormalizedWeight(query, needsScores);
         }
+        return in.createNormalizedWeight(query, needsScores);
     }
 
     @Override
     public Explanation explain(Query query, int doc) throws IOException {
-        try {
-            return in.explain(query, doc);
-        } finally {
-            searchContext.clearReleasables(Lifetime.COLLECTION);
-        }
-    }
-
-    @Override
-    protected void search(List<LeafReaderContext> leaves, Weight weight, Collector collector) throws IOException {
-        try {
-            super.search(leaves, weight, collector);
-        } finally {
-            searchContext.clearReleasables(Lifetime.COLLECTION);
-        }
+        return in.explain(query, doc);
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java b/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java
index a3015b9..fdaac5e 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/DefaultSearchContext.java
@@ -21,14 +21,21 @@ package org.elasticsearch.search.internal;
 
 import com.carrotsearch.hppc.ObjectObjectAssociativeContainer;
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.*;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Collector;
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.Sort;
 import org.apache.lucene.util.Counter;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.cache.recycler.PageCacheRecycler;
-import org.elasticsearch.common.*;
+import org.elasticsearch.common.HasContext;
+import org.elasticsearch.common.HasContextAndHeaders;
+import org.elasticsearch.common.HasHeaders;
+import org.elasticsearch.common.Nullable;
+import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.lucene.search.Queries;
@@ -67,7 +74,12 @@ import org.elasticsearch.search.scan.ScanContext;
 import org.elasticsearch.search.suggest.SuggestionSearchContext;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
 
 /**
  *
@@ -567,7 +579,7 @@ public class DefaultSearchContext extends SearchContext {
     @Override
     public List<String> fieldNames() {
         if (fieldNames == null) {
-            fieldNames = Lists.newArrayList();
+            fieldNames = new ArrayList<>();
         }
         return fieldNames;
     }
diff --git a/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java b/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java
index f2ed267..7a349cf 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.search.internal;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.ElasticsearchParseException;
@@ -47,6 +46,7 @@ import org.elasticsearch.search.internal.InternalSearchHits.StreamContext.ShardT
 import org.elasticsearch.search.lookup.SourceLookup;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
@@ -431,8 +431,8 @@ public class InternalSearchHit implements SearchHit {
 
     @Override
     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        List<SearchHitField> metaFields = Lists.newArrayList();
-        List<SearchHitField> otherFields = Lists.newArrayList();
+        List<SearchHitField> metaFields = new ArrayList<>();
+        List<SearchHitField> otherFields = new ArrayList<>();
         if (fields != null && !fields.isEmpty()) {
             for (SearchHitField field : fields.values()) {
                 if (field.values().isEmpty()) {
diff --git a/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java b/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
index 897f10e..a7e45d1 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
@@ -21,7 +21,6 @@ package org.elasticsearch.search.internal;
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Multimap;
 import com.google.common.collect.MultimapBuilder;
-
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Sort;
@@ -42,11 +41,10 @@ import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.query.ParsedQuery;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.similarity.SimilarityService;
 import org.elasticsearch.script.ScriptService;
-import org.elasticsearch.search.Scroll;
 import org.elasticsearch.search.SearchShardTarget;
 import org.elasticsearch.search.aggregations.SearchContextAggregations;
 import org.elasticsearch.search.dfs.DfsSearchResult;
@@ -76,12 +74,12 @@ public abstract class SearchContext implements Releasable, HasContextAndHeaders
 
     public static void setCurrent(SearchContext value) {
         current.set(value);
-        QueryShardContext.setTypes(value.types());
+        QueryParseContext.setTypes(value.types());
     }
 
     public static void removeCurrent() {
         current.remove();
-        QueryShardContext.removeTypes();
+        QueryParseContext.removeTypes();
     }
 
     public static SearchContext current() {
diff --git a/core/src/main/java/org/elasticsearch/search/internal/SubSearchContext.java b/core/src/main/java/org/elasticsearch/search/internal/SubSearchContext.java
index a1a6fd0..4596375 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/SubSearchContext.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/SubSearchContext.java
@@ -19,7 +19,6 @@
 package org.elasticsearch.search.internal;
 
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.util.Counter;
@@ -36,6 +35,7 @@ import org.elasticsearch.search.query.QuerySearchResult;
 import org.elasticsearch.search.rescore.RescoreSearchContext;
 import org.elasticsearch.search.suggest.SuggestionSearchContext;
 
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -233,7 +233,7 @@ public class SubSearchContext extends FilteredSearchContext {
     @Override
     public List<String> fieldNames() {
         if (fieldNames == null) {
-            fieldNames = Lists.newArrayList();
+            fieldNames = new ArrayList<>();
         }
         return fieldNames;
     }
diff --git a/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java b/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java
index 8f21f46..06451af 100644
--- a/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java
@@ -20,24 +20,8 @@
 package org.elasticsearch.search.query;
 
 import com.google.common.collect.ImmutableMap;
-
 import org.apache.lucene.queries.MinDocQuery;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Collector;
-import org.apache.lucene.search.FieldDoc;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.MultiCollector;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.Sort;
-import org.apache.lucene.search.TimeLimitingCollector;
-import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.search.TopDocsCollector;
-import org.apache.lucene.search.TopFieldCollector;
-import org.apache.lucene.search.TopScoreDocCollector;
-import org.apache.lucene.search.TotalHitCountCollector;
-import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.*;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.Lucene;
@@ -173,8 +157,8 @@ public class QueryPhase implements SearchPhase {
                             // skip to the desired doc and stop collecting after ${size} matches
                             if (scrollContext.lastEmittedDoc != null) {
                                 BooleanQuery bq = new BooleanQuery();
-                                bq.add(query, Occur.MUST);
-                                bq.add(new MinDocQuery(lastEmittedDoc.doc + 1), Occur.FILTER);
+                                bq.add(query, BooleanClause.Occur.MUST);
+                                bq.add(new MinDocQuery(lastEmittedDoc.doc + 1), BooleanClause.Occur.FILTER);
                                 query = bq;
                             }
                             searchContext.terminateAfter(numDocs);
@@ -264,13 +248,15 @@ public class QueryPhase implements SearchPhase {
             }
 
             try {
-                searcher.search(query, collector);
+                searchContext.searcher().search(query, collector);
             } catch (TimeLimitingCollector.TimeExceededException e) {
                 assert timeoutSet : "TimeExceededException thrown even though timeout wasn't set";
                 searchContext.queryResult().searchTimedOut(true);
             } catch (Lucene.EarlyTerminationException e) {
                 assert terminateAfterSet : "EarlyTerminationException thrown even though terminateAfter wasn't set";
                 searchContext.queryResult().terminatedEarly(true);
+            } finally {
+                searchContext.clearReleasables(SearchContext.Lifetime.COLLECTION);
             }
             if (terminateAfterSet && searchContext.queryResult().terminatedEarly() == null) {
                 searchContext.queryResult().terminatedEarly(false);
diff --git a/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java b/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java
index f3ef9bd..6f4a0df 100644
--- a/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java
+++ b/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java
@@ -173,7 +173,7 @@ public class GeoDistanceSortParser implements SortParser {
             ObjectMapper objectMapper = context.mapperService().resolveClosestNestedObjectMapper(fieldName);
             if (objectMapper != null && objectMapper.nested().isNested()) {
                 if (nestedHelper == null) {
-                    nestedHelper = new NestedInnerQueryParseSupport(context.queryParserService().getShardContext());
+                    nestedHelper = new NestedInnerQueryParseSupport(context.queryParserService().getParseContext());
                 }
                 nestedHelper.setPath(objectMapper.fullPath());
             }
@@ -181,7 +181,7 @@ public class GeoDistanceSortParser implements SortParser {
 
         final Nested nested;
         if (nestedHelper != null && nestedHelper.getPath() != null) {
-
+            
             BitDocIdSetFilter rootDocumentsFilter = context.bitsetFilterCache().getBitDocIdSetFilter(Queries.newNonNestedFilter());
             Filter innerDocumentsFilter;
             if (nestedHelper.filterFound()) {
diff --git a/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java b/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java
index d248514..2f4dcb3 100644
--- a/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java
+++ b/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java
@@ -20,8 +20,6 @@
 package org.elasticsearch.search.sort;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.Sort;
@@ -44,6 +42,7 @@ import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.search.internal.SubSearchContext;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -80,7 +79,7 @@ public class SortParseElement implements SearchParseElement {
     @Override
     public void parse(XContentParser parser, SearchContext context) throws Exception {
         XContentParser.Token token = parser.currentToken();
-        List<SortField> sortFields = Lists.newArrayListWithCapacity(2);
+        List<SortField> sortFields = new ArrayList<>(2);
         if (token == XContentParser.Token.START_ARRAY) {
             while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                 if (token == XContentParser.Token.START_OBJECT) {
@@ -244,7 +243,7 @@ public class SortParseElement implements SearchParseElement {
                     ObjectMapper objectMapper = context.mapperService().resolveClosestNestedObjectMapper(fieldName);
                     if (objectMapper != null && objectMapper.nested().isNested()) {
                         if (nestedHelper == null) {
-                            nestedHelper = new NestedInnerQueryParseSupport(context.queryParserService().getShardContext());
+                            nestedHelper = new NestedInnerQueryParseSupport(context.queryParserService().getParseContext());
                         }
                         nestedHelper.setPath(objectMapper.fullPath());
                     }
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/context/CategoryContextMapping.java b/core/src/main/java/org/elasticsearch/search/suggest/context/CategoryContextMapping.java
index 975b42a..ad075ac 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/context/CategoryContextMapping.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/context/CategoryContextMapping.java
@@ -21,7 +21,6 @@ package org.elasticsearch.search.suggest.context;
 
 import com.google.common.base.Joiner;
 import com.google.common.collect.Iterables;
-import com.google.common.collect.Lists;
 import org.apache.lucene.analysis.PrefixAnalyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.index.IndexableField;
@@ -36,7 +35,11 @@ import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.ParseContext.Document;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
 
 /**
  * The {@link CategoryContextMapping} is used to define a {@link ContextMapping} that
@@ -165,7 +168,7 @@ public class CategoryContextMapping extends ContextMapping {
         } else if (token == Token.VALUE_BOOLEAN) {
             return new FieldConfig(fieldName, null, Collections.singleton(parser.text()));
         } else if (token == Token.START_ARRAY) {
-            ArrayList<String> values = Lists.newArrayList();
+            ArrayList<String> values = new ArrayList<>();
             while((token = parser.nextToken()) != Token.END_ARRAY) {
                 values.add(parser.text());
             }
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/context/ContextMapping.java b/core/src/main/java/org/elasticsearch/search/suggest/context/ContextMapping.java
index 43956c9..30aaab6 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/context/ContextMapping.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/context/ContextMapping.java
@@ -20,9 +20,7 @@
 package org.elasticsearch.search.suggest.context;
 
 import com.google.common.collect.Iterables;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
-
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.search.suggest.analyzing.XAnalyzingSuggester;
 import org.apache.lucene.util.automaton.Automata;
@@ -39,7 +37,12 @@ import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.ParseContext.Document;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.SortedMap;
 
 /**
  * A {@link ContextMapping} is used t define a context that may used
@@ -300,7 +303,7 @@ public abstract class ContextMapping implements ToXContent {
                 }
             }
 
-            List<ContextQuery> queries = Lists.newArrayListWithExpectedSize(mappings.size());
+            List<ContextQuery> queries = new ArrayList<>(mappings.size());
             for (ContextMapping mapping : mappings.values()) {
                 queries.add(querySet.get(mapping.name));
             }
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/context/GeolocationContextMapping.java b/core/src/main/java/org/elasticsearch/search/suggest/context/GeolocationContextMapping.java
index 22975ff..a02868a 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/context/GeolocationContextMapping.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/context/GeolocationContextMapping.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.search.suggest.context;
 
 import com.carrotsearch.hppc.IntHashSet;
-import com.google.common.collect.Lists;
 import org.apache.lucene.analysis.PrefixAnalyzer.PrefixTokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.index.DocValuesType;
@@ -43,7 +42,13 @@ import org.elasticsearch.index.mapper.ParseContext.Document;
 import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.Map;
 
 /**
  * The {@link GeolocationContextMapping} allows to take GeoInfomation into account
@@ -231,7 +236,7 @@ public class GeolocationContextMapping extends ContextMapping {
                 }
             } else {
                 // otherwise it's a list of locations
-                ArrayList<String> result = Lists.newArrayList();
+                ArrayList<String> result = new ArrayList<>();
                 while (token != Token.END_ARRAY) {
                     result.add(GeoUtils.parseGeoPoint(parser).geohash());
                     token = parser.nextToken(); //infinite loop without this line
diff --git a/core/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java b/core/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java
index f2a996d..336f849 100644
--- a/core/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java
+++ b/core/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java
@@ -21,8 +21,6 @@ package org.elasticsearch.search.warmer;
 
 import com.google.common.base.Objects;
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.Nullable;
@@ -31,7 +29,11 @@ import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.*;
+import org.elasticsearch.common.xcontent.ToXContent;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.XContentType;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -260,7 +262,7 @@ public class IndexWarmersMetaData extends AbstractDiffable<IndexMetaData.Custom>
     @Override
     public IndexMetaData.Custom mergeWith(IndexMetaData.Custom other) {
         IndexWarmersMetaData second = (IndexWarmersMetaData) other;
-        List<Entry> entries = Lists.newArrayList();
+        List<Entry> entries = new ArrayList<>();
         entries.addAll(entries());
         for (Entry secondEntry : second.entries()) {
             boolean found = false;
diff --git a/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java b/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
index d8c6fdc..8738de1 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
@@ -25,15 +25,31 @@ import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
-
 import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.IndicesOptions;
-import org.elasticsearch.cluster.*;
-import org.elasticsearch.cluster.block.ClusterBlocks;
-import org.elasticsearch.cluster.metadata.*;
+import org.elasticsearch.cluster.ClusterChangedEvent;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.ClusterStateListener;
+import org.elasticsearch.cluster.ProcessedClusterStateUpdateTask;
+import org.elasticsearch.cluster.RestoreInProgress;
 import org.elasticsearch.cluster.RestoreInProgress.ShardRestoreStatus;
-import org.elasticsearch.cluster.routing.*;
+import org.elasticsearch.cluster.TimeoutClusterStateUpdateTask;
+import org.elasticsearch.cluster.block.ClusterBlocks;
+import org.elasticsearch.cluster.metadata.AliasMetaData;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
+import org.elasticsearch.cluster.metadata.IndexTemplateMetaData;
+import org.elasticsearch.cluster.metadata.MetaData;
+import org.elasticsearch.cluster.metadata.MetaDataCreateIndexService;
+import org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService;
+import org.elasticsearch.cluster.metadata.RepositoriesMetaData;
+import org.elasticsearch.cluster.metadata.SnapshotId;
+import org.elasticsearch.cluster.routing.IndexRoutingTable;
+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
+import org.elasticsearch.cluster.routing.RestoreSource;
+import org.elasticsearch.cluster.routing.RoutingTable;
+import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.allocation.AllocationService;
 import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
 import org.elasticsearch.cluster.settings.ClusterDynamicSettings;
@@ -50,20 +66,28 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.concurrent.ConcurrentCollections;
 import org.elasticsearch.index.shard.IndexShard;
-import org.elasticsearch.index.shard.StoreRecoveryService;
 import org.elasticsearch.index.shard.ShardId;
+import org.elasticsearch.index.shard.StoreRecoveryService;
 import org.elasticsearch.repositories.RepositoriesService;
 import org.elasticsearch.repositories.Repository;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.*;
+import org.elasticsearch.transport.EmptyTransportResponseHandler;
+import org.elasticsearch.transport.TransportChannel;
+import org.elasticsearch.transport.TransportRequest;
+import org.elasticsearch.transport.TransportRequestHandler;
+import org.elasticsearch.transport.TransportResponse;
+import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Set;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.CopyOnWriteArrayList;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.newHashMap;
 import static com.google.common.collect.Sets.newHashSet;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.*;
@@ -350,7 +374,7 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
                     Settings normalizedChangeSettings = Settings.settingsBuilder().put(changeSettings).normalizePrefix(IndexMetaData.INDEX_SETTING_PREFIX).build();
                     IndexMetaData.Builder builder = IndexMetaData.builder(indexMetaData);
                     Map<String, String> settingsMap = newHashMap(indexMetaData.settings().getAsMap());
-                    List<String> simpleMatchPatterns = newArrayList();
+                    List<String> simpleMatchPatterns = new ArrayList<>();
                     for (String ignoredSetting : ignoreSettings) {
                         if (!Regex.isSimpleMatchPattern(ignoredSetting)) {
                             if (UNREMOVABLE_SETTINGS.contains(ignoredSetting)) {
@@ -515,7 +539,7 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
                 final RestoreInProgress restore = currentState.custom(RestoreInProgress.TYPE);
                 if (restore != null) {
                     int changedCount = 0;
-                    final List<RestoreInProgress.Entry> entries = newArrayList();
+                    final List<RestoreInProgress.Entry> entries = new ArrayList<>();
                     for (RestoreInProgress.Entry entry : restore.entries()) {
                         Map<ShardId, ShardRestoreStatus> shards = null;
 
@@ -577,7 +601,7 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
                         final RestoreInfo restoreInfo = entry.getValue().v1();
                         final Map<ShardId, ShardRestoreStatus> shards = entry.getValue().v2();
                         RoutingTable routingTable = newState.getRoutingTable();
-                        final List<ShardId> waitForStarted = newArrayList();
+                        final List<ShardId> waitForStarted = new ArrayList<>();
                         for (Map.Entry<ShardId, ShardRestoreStatus> shard : shards.entrySet()) {
                             if (shard.getValue().state() == RestoreInProgress.State.SUCCESS ) {
                                 ShardId shardId = shard.getKey();
@@ -711,7 +735,7 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
                     if (!shard.getValue().state().completed()) {
                         if (!event.state().metaData().hasIndex(shard.getKey().getIndex())) {
                             if (shardsToFail == null) {
-                                shardsToFail = newArrayList();
+                                shardsToFail = new ArrayList<>();
                             }
                             shardsToFail.add(shard.getKey());
                         }
diff --git a/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java b/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
index 03b516f..b608363 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
@@ -21,7 +21,12 @@ package org.elasticsearch.snapshots;
 
 import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.ExceptionsHelper;
-import org.elasticsearch.cluster.*;
+import org.elasticsearch.cluster.ClusterChangedEvent;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.ClusterStateListener;
+import org.elasticsearch.cluster.ClusterStateUpdateTask;
+import org.elasticsearch.cluster.SnapshotsInProgress;
 import org.elasticsearch.cluster.metadata.SnapshotId;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
@@ -43,10 +48,17 @@ import org.elasticsearch.index.snapshots.IndexShardSnapshotFailedException;
 import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.*;
+import org.elasticsearch.transport.EmptyTransportResponseHandler;
+import org.elasticsearch.transport.TransportChannel;
+import org.elasticsearch.transport.TransportRequest;
+import org.elasticsearch.transport.TransportRequestHandler;
+import org.elasticsearch.transport.TransportResponse;
+import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.Executor;
 import java.util.concurrent.TimeUnit;
@@ -54,7 +66,6 @@ import java.util.concurrent.locks.Condition;
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReentrantLock;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.newHashMap;
 import static org.elasticsearch.cluster.SnapshotsInProgress.completed;
 
@@ -506,7 +517,7 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
                 final SnapshotsInProgress snapshots = currentState.custom(SnapshotsInProgress.TYPE);
                 if (snapshots != null) {
                     int changedCount = 0;
-                    final List<SnapshotsInProgress.Entry> entries = newArrayList();
+                    final List<SnapshotsInProgress.Entry> entries = new ArrayList<>();
                     for (SnapshotsInProgress.Entry entry : snapshots.entries()) {
                         final Map<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shards = newHashMap();
                         boolean updated = false;
diff --git a/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java b/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
index da796d1..79f6e86 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
@@ -25,10 +25,21 @@ import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.action.search.ShardSearchFailure;
 import org.elasticsearch.action.support.IndicesOptions;
-import org.elasticsearch.cluster.*;
+import org.elasticsearch.cluster.ClusterChangedEvent;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.ClusterStateListener;
+import org.elasticsearch.cluster.ClusterStateUpdateTask;
+import org.elasticsearch.cluster.ProcessedClusterStateUpdateTask;
+import org.elasticsearch.cluster.SnapshotsInProgress;
 import org.elasticsearch.cluster.SnapshotsInProgress.ShardSnapshotStatus;
 import org.elasticsearch.cluster.SnapshotsInProgress.State;
-import org.elasticsearch.cluster.metadata.*;
+import org.elasticsearch.cluster.TimeoutClusterStateUpdateTask;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
+import org.elasticsearch.cluster.metadata.MetaData;
+import org.elasticsearch.cluster.metadata.RepositoriesMetaData;
+import org.elasticsearch.cluster.metadata.SnapshotId;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
 import org.elasticsearch.cluster.routing.IndexRoutingTable;
@@ -51,10 +62,13 @@ import org.elasticsearch.search.SearchShardTarget;
 import org.elasticsearch.threadpool.ThreadPool;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Set;
 import java.util.concurrent.CopyOnWriteArrayList;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Sets.newHashSet;
 import static org.elasticsearch.cluster.SnapshotsInProgress.completed;
 
@@ -134,7 +148,7 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
         for (SnapshotId snapshotId : snapshotIds) {
             snapshotSet.add(repository.readSnapshot(snapshotId));
         }
-        ArrayList<Snapshot> snapshotList = newArrayList(snapshotSet);
+        ArrayList<Snapshot> snapshotList = new ArrayList<>(snapshotSet);
         CollectionUtil.timSort(snapshotList);
         return ImmutableList.copyOf(snapshotList);
     }
@@ -146,7 +160,7 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
      * @return list of snapshots
      */
     public List<Snapshot> currentSnapshots(String repositoryName) {
-        List<Snapshot> snapshotList = newArrayList();
+        List<Snapshot> snapshotList = new ArrayList<>();
         List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, null);
         for (SnapshotsInProgress.Entry entry : entries) {
             snapshotList.add(inProgressSnapshot(entry));
@@ -524,7 +538,7 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                         return currentState;
                     }
                     boolean changed = false;
-                    ArrayList<SnapshotsInProgress.Entry> entries = newArrayList();
+                    ArrayList<SnapshotsInProgress.Entry> entries = new ArrayList<>();
                     for (final SnapshotsInProgress.Entry snapshot : snapshots.entries()) {
                         SnapshotsInProgress.Entry updatedSnapshot = snapshot;
                         boolean snapshotChanged = false;
@@ -596,7 +610,7 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                     SnapshotsInProgress snapshots = currentState.custom(SnapshotsInProgress.TYPE);
                     if (snapshots != null) {
                         boolean changed = false;
-                        ArrayList<SnapshotsInProgress.Entry> entries = newArrayList();
+                        ArrayList<SnapshotsInProgress.Entry> entries = new ArrayList<>();
                         for (final SnapshotsInProgress.Entry snapshot : snapshots.entries()) {
                             SnapshotsInProgress.Entry updatedSnapshot = snapshot;
                             if (snapshot.state() == State.STARTED) {
@@ -763,8 +777,8 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                 try {
                     final Repository repository = repositoriesService.repository(snapshotId.getRepository());
                     logger.trace("[{}] finalizing snapshot in repository, state: [{}], failure[{}]", snapshotId, entry.state(), failure);
-                    ArrayList<ShardSearchFailure> failures = newArrayList();
-                    ArrayList<SnapshotShardFailure> shardFailures = newArrayList();
+                    ArrayList<ShardSearchFailure> failures = new ArrayList<>();
+                    ArrayList<SnapshotShardFailure> shardFailures = new ArrayList<>();
                     for (Map.Entry<ShardId, ShardSnapshotStatus> shardStatus : entry.shards().entrySet()) {
                         ShardId shardId = shardStatus.getKey();
                         ShardSnapshotStatus status = shardStatus.getValue();
@@ -797,7 +811,7 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                 SnapshotsInProgress snapshots = currentState.custom(SnapshotsInProgress.TYPE);
                 if (snapshots != null) {
                     boolean changed = false;
-                    ArrayList<SnapshotsInProgress.Entry> entries = newArrayList();
+                    ArrayList<SnapshotsInProgress.Entry> entries = new ArrayList<>();
                     for (SnapshotsInProgress.Entry entry : snapshots.entries()) {
                         if (entry.snapshotId().equals(snapshotId)) {
                             changed = true;
diff --git a/core/src/main/java/org/elasticsearch/tribe/TribeService.java b/core/src/main/java/org/elasticsearch/tribe/TribeService.java
index f2f21a1..3cc7b77 100644
--- a/core/src/main/java/org/elasticsearch/tribe/TribeService.java
+++ b/core/src/main/java/org/elasticsearch/tribe/TribeService.java
@@ -20,11 +20,14 @@
 package org.elasticsearch.tribe;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.support.master.TransportMasterNodeReadAction;
-import org.elasticsearch.cluster.*;
+import org.elasticsearch.cluster.ClusterChangedEvent;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.ClusterStateListener;
+import org.elasticsearch.cluster.ClusterStateNonMasterUpdateTask;
 import org.elasticsearch.cluster.block.ClusterBlock;
 import org.elasticsearch.cluster.block.ClusterBlockLevel;
 import org.elasticsearch.cluster.block.ClusterBlocks;
@@ -52,6 +55,7 @@ import java.util.EnumSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
+import java.util.concurrent.CopyOnWriteArrayList;
 
 /**
  * The tribe service holds a list of node clients connected to a list of tribe members, and uses their
@@ -115,7 +119,7 @@ public class TribeService extends AbstractLifecycleComponent<TribeService> {
     private final String onConflict;
     private final Set<String> droppedIndices = ConcurrentCollections.newConcurrentSet();
 
-    private final List<Node> nodes = Lists.newCopyOnWriteArrayList();
+    private final List<Node> nodes = new CopyOnWriteArrayList<>();
 
     @Inject
     public TribeService(Settings settings, ClusterService clusterService, DiscoveryService discoveryService) {
diff --git a/core/src/test/java/org/elasticsearch/ESExceptionTests.java b/core/src/test/java/org/elasticsearch/ESExceptionTests.java
index eb3d870..dea127a 100644
--- a/core/src/test/java/org/elasticsearch/ESExceptionTests.java
+++ b/core/src/test/java/org/elasticsearch/ESExceptionTests.java
@@ -35,7 +35,8 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentLocation;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.IndexNotFoundException;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.QueryParsingException;
+import org.elasticsearch.index.query.TestQueryParsingException;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.search.SearchParseException;
 import org.elasticsearch.search.SearchShardTarget;
@@ -51,6 +52,7 @@ import java.io.EOFException;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.nio.file.NoSuchFileException;
+import java.util.Collections;
 
 import static org.hamcrest.Matchers.equalTo;
 
@@ -307,7 +309,7 @@ public class ESExceptionTests extends ESTestCase {
                 new OutOfMemoryError("no memory left"),
                 new AlreadyClosedException("closed!!", new NullPointerException()),
                 new LockObtainFailedException("can't lock directory", new NullPointerException()),
-                new Throwable("this exception is unknown", new QueryShardException(new Index("foo"), "foobar", null) ), // somethin unknown
+                new Throwable("this exception is unknown", new QueryParsingException(new Index("foo"), 1, 2, "foobar", null) ), // somethin unknown
         };
         for (Throwable t : causes) {
             BytesStreamOutput out = new BytesStreamOutput();
diff --git a/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java b/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
index 8117a69..c8a042f 100644
--- a/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
+++ b/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
@@ -34,16 +34,10 @@ import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.*;
 import org.elasticsearch.common.breaker.CircuitBreakingException;
 import org.elasticsearch.common.io.PathUtils;
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.io.stream.*;
 import org.elasticsearch.common.transport.LocalTransportAddress;
 import org.elasticsearch.common.unit.ByteSizeValue;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentLocation;
+import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.discovery.DiscoverySettings;
 import org.elasticsearch.index.AlreadyExpiredException;
 import org.elasticsearch.index.Index;
@@ -52,11 +46,7 @@ import org.elasticsearch.index.engine.IndexFailedEngineException;
 import org.elasticsearch.index.engine.RecoveryEngineException;
 import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.query.QueryParsingException;
-import org.elasticsearch.index.query.QueryShardException;
-import org.elasticsearch.index.shard.IllegalIndexShardStateException;
-import org.elasticsearch.index.shard.IndexShardState;
-import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.shard.TranslogRecoveryPerformer;
+import org.elasticsearch.index.shard.*;
 import org.elasticsearch.indices.IndexTemplateAlreadyExistsException;
 import org.elasticsearch.indices.IndexTemplateMissingException;
 import org.elasticsearch.indices.InvalidIndexTemplateException;
@@ -88,6 +78,7 @@ import java.nio.file.FileVisitor;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.attribute.BasicFileAttributes;
+import java.util.Collections;
 import java.util.HashSet;
 import java.util.Set;
 
@@ -231,16 +222,6 @@ public class ExceptionSerializationTests extends ESTestCase {
         assertEquals(ex.getColumnNumber(), 2);
     }
 
-    public void testQueryShardException() throws IOException {
-        QueryShardException ex = serialize(new QueryShardException(new Index("foo"), "fobar", null));
-        assertEquals(ex.getIndex(), "foo");
-        assertEquals(ex.getMessage(), "fobar");
-
-        ex = serialize(new QueryShardException((Index)null, null, null));
-        assertNull(ex.getIndex());
-        assertNull(ex.getMessage());
-    }
-
     public void testSearchException() throws IOException {
         SearchShardTarget target = new SearchShardTarget("foo", "bar", 1);
         SearchException ex = serialize(new SearchException(target, "hello world"));
diff --git a/core/src/test/java/org/elasticsearch/action/RejectionActionIT.java b/core/src/test/java/org/elasticsearch/action/RejectionActionIT.java
index ff094e0..3c59f67 100644
--- a/core/src/test/java/org/elasticsearch/action/RejectionActionIT.java
+++ b/core/src/test/java/org/elasticsearch/action/RejectionActionIT.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.SearchResponse;
@@ -65,7 +64,7 @@ public class RejectionActionIT extends ESIntegTestCase {
 
         int numberOfAsyncOps = randomIntBetween(200, 700);
         final CountDownLatch latch = new CountDownLatch(numberOfAsyncOps);
-        final CopyOnWriteArrayList<Object> responses = Lists.newCopyOnWriteArrayList();
+        final CopyOnWriteArrayList<Object> responses = new CopyOnWriteArrayList<>();
         for (int i = 0; i < numberOfAsyncOps; i++) {
             client().prepareSearch("test")
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
diff --git a/core/src/test/java/org/elasticsearch/action/admin/indices/template/put/MetaDataIndexTemplateServiceTests.java b/core/src/test/java/org/elasticsearch/action/admin/indices/template/put/MetaDataIndexTemplateServiceTests.java
index 0966212..0914628 100644
--- a/core/src/test/java/org/elasticsearch/action/admin/indices/template/put/MetaDataIndexTemplateServiceTests.java
+++ b/core/src/test/java/org/elasticsearch/action/admin/indices/template/put/MetaDataIndexTemplateServiceTests.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.admin.indices.template.put;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 import org.elasticsearch.Version;
@@ -33,12 +32,12 @@ import org.elasticsearch.indices.InvalidIndexTemplateException;
 import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
 import static org.hamcrest.CoreMatchers.containsString;
 import static org.hamcrest.CoreMatchers.instanceOf;
-import static org.hamcrest.Matchers.contains;
 
 public class MetaDataIndexTemplateServiceTests extends ESTestCase {
     @Test
@@ -89,7 +88,7 @@ public class MetaDataIndexTemplateServiceTests extends ESTestCase {
         );
         MetaDataIndexTemplateService service = new MetaDataIndexTemplateService(Settings.EMPTY, null, createIndexService, null);
 
-        final List<Throwable> throwables = Lists.newArrayList();
+        final List<Throwable> throwables = new ArrayList<>();
         service.putTemplate(request, new MetaDataIndexTemplateService.PutListener() {
             @Override
             public void onResponse(MetaDataIndexTemplateService.PutResponse response) {
diff --git a/core/src/test/java/org/elasticsearch/action/support/TransportActionFilterChainTests.java b/core/src/test/java/org/elasticsearch/action/support/TransportActionFilterChainTests.java
index 41fb1d9..b1fd92a 100644
--- a/core/src/test/java/org/elasticsearch/action/support/TransportActionFilterChainTests.java
+++ b/core/src/test/java/org/elasticsearch/action/support/TransportActionFilterChainTests.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.action.support;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchTimeoutException;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.ActionRequest;
@@ -30,7 +29,12 @@ import org.elasticsearch.test.ESTestCase;
 import org.junit.Before;
 import org.junit.Test;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutionException;
@@ -71,7 +75,7 @@ public class TransportActionFilterChainTests extends ESTestCase {
             }
         };
 
-        ArrayList<ActionFilter> actionFiltersByOrder = Lists.newArrayList(filters);
+        ArrayList<ActionFilter> actionFiltersByOrder = new ArrayList<>(filters);
         Collections.sort(actionFiltersByOrder, new Comparator<ActionFilter>() {
             @Override
             public int compare(ActionFilter o1, ActionFilter o2) {
@@ -79,7 +83,7 @@ public class TransportActionFilterChainTests extends ESTestCase {
             }
         });
 
-        List<ActionFilter> expectedActionFilters = Lists.newArrayList();
+        List<ActionFilter> expectedActionFilters = new ArrayList<>();
         boolean errorExpected = false;
         for (ActionFilter filter : actionFiltersByOrder) {
             RequestTestFilter testFilter = (RequestTestFilter) filter;
@@ -101,7 +105,7 @@ public class TransportActionFilterChainTests extends ESTestCase {
             assertThat("shouldn't get here if an error is not expected " + t.getMessage(), errorExpected, equalTo(true));
         }
 
-        List<RequestTestFilter> testFiltersByLastExecution = Lists.newArrayList();
+        List<RequestTestFilter> testFiltersByLastExecution = new ArrayList<>();
         for (ActionFilter actionFilter : actionFilters.filters()) {
             testFiltersByLastExecution.add((RequestTestFilter) actionFilter);
         }
@@ -112,7 +116,7 @@ public class TransportActionFilterChainTests extends ESTestCase {
             }
         });
 
-        ArrayList<RequestTestFilter> finalTestFilters = Lists.newArrayList();
+        ArrayList<RequestTestFilter> finalTestFilters = new ArrayList<>();
         for (ActionFilter filter : testFiltersByLastExecution) {
             RequestTestFilter testFilter = (RequestTestFilter) filter;
             finalTestFilters.add(testFilter);
@@ -153,7 +157,7 @@ public class TransportActionFilterChainTests extends ESTestCase {
             }
         };
 
-        ArrayList<ActionFilter> actionFiltersByOrder = Lists.newArrayList(filters);
+        ArrayList<ActionFilter> actionFiltersByOrder = new ArrayList<>(filters);
         Collections.sort(actionFiltersByOrder, new Comparator<ActionFilter>() {
             @Override
             public int compare(ActionFilter o1, ActionFilter o2) {
@@ -161,7 +165,7 @@ public class TransportActionFilterChainTests extends ESTestCase {
             }
         });
 
-        List<ActionFilter> expectedActionFilters = Lists.newArrayList();
+        List<ActionFilter> expectedActionFilters = new ArrayList<>();
         boolean errorExpected = false;
         for (ActionFilter filter : actionFiltersByOrder) {
             ResponseTestFilter testFilter = (ResponseTestFilter) filter;
@@ -183,7 +187,7 @@ public class TransportActionFilterChainTests extends ESTestCase {
             assertThat("shouldn't get here if an error is not expected " + t.getMessage(), errorExpected, equalTo(true));
         }
 
-        List<ResponseTestFilter> testFiltersByLastExecution = Lists.newArrayList();
+        List<ResponseTestFilter> testFiltersByLastExecution = new ArrayList<>();
         for (ActionFilter actionFilter : actionFilters.filters()) {
             testFiltersByLastExecution.add((ResponseTestFilter) actionFilter);
         }
@@ -194,7 +198,7 @@ public class TransportActionFilterChainTests extends ESTestCase {
             }
         });
 
-        ArrayList<ResponseTestFilter> finalTestFilters = Lists.newArrayList();
+        ArrayList<ResponseTestFilter> finalTestFilters = new ArrayList<>();
         for (ActionFilter filter : testFiltersByLastExecution) {
             ResponseTestFilter testFilter = (ResponseTestFilter) filter;
             finalTestFilters.add(testFilter);
diff --git a/core/src/test/java/org/elasticsearch/action/support/replication/ShardReplicationTests.java b/core/src/test/java/org/elasticsearch/action/support/replication/ShardReplicationTests.java
index d08840b..d7fb2dd 100644
--- a/core/src/test/java/org/elasticsearch/action/support/replication/ShardReplicationTests.java
+++ b/core/src/test/java/org/elasticsearch/action/support/replication/ShardReplicationTests.java
@@ -661,7 +661,6 @@ public class ShardReplicationTests extends ESTestCase {
         public AtomicInteger processedOnReplicas = new AtomicInteger();
 
         Request() {
-            this.operationThreaded(randomBoolean());
         }
 
         Request(ShardId shardId) {
diff --git a/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java b/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java
index 80f4c45..8f8759e 100644
--- a/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java
+++ b/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java
@@ -151,7 +151,7 @@ public class IndexAliasesIT extends ESIntegTestCase {
         logger.info("--> making sure that filter was stored with alias [alias1] and filter [user:kimchy]");
         ClusterState clusterState = admin().cluster().prepareState().get().getState();
         IndexMetaData indexMd = clusterState.metaData().index("test");
-        assertThat(indexMd.aliases().get("alias1").filter().string(), equalTo("{\"term\":{\"user\":{\"value\":\"kimchy\",\"boost\":1.0}}}"));
+        assertThat(indexMd.aliases().get("alias1").filter().string(), equalTo("{\"term\":{\"user\":\"kimchy\"}}"));
 
     }
 
@@ -413,8 +413,8 @@ public class IndexAliasesIT extends ESIntegTestCase {
         assertThat(client().prepareCount("bars").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(1L));
     }
 
-
-
+    
+    
     @Test
     public void testDeleteAliases() throws Exception {
         logger.info("--> creating index [test1] and [test2]");
@@ -434,17 +434,17 @@ public class IndexAliasesIT extends ESIntegTestCase {
                 .addAlias("test2", "aliasToTests")
                 .addAlias("test2", "foos", termQuery("name", "foo"))
                 .addAlias("test2", "tests", termQuery("name", "test")));
-
-        String[] indices = {"test1", "test2"};
+        
+        String[] indices = {"test1", "test2"}; 
         String[] aliases = {"aliasToTest1", "foos", "bars", "tests", "aliasToTest2", "aliasToTests"};
-
+        
         admin().indices().prepareAliases().removeAlias(indices, aliases).get();
-
+        
         AliasesExistResponse response = admin().indices().prepareAliasesExist(aliases).get();
         assertThat(response.exists(), equalTo(false));
     }
 
-
+    
     @Test
     public void testWaitForAliasCreationMultipleShards() throws Exception {
         logger.info("--> creating index [test]");
@@ -532,16 +532,16 @@ public class IndexAliasesIT extends ESIntegTestCase {
 
         logger.info("--> verify that filter was updated");
         AliasMetaData aliasMetaData = ((AliasOrIndex.Alias) internalCluster().clusterService().state().metaData().getAliasAndIndexLookup().get("alias1")).getFirstAliasMetaData();
-        assertThat(aliasMetaData.getFilter().toString(), equalTo("{\"term\":{\"name\":{\"value\":\"bar\",\"boost\":1.0}}}"));
+        assertThat(aliasMetaData.getFilter().toString(), equalTo("{\"term\":{\"name\":\"bar\"}}"));
 
         logger.info("--> deleting alias1");
         stopWatch.start();
         assertAcked((admin().indices().prepareAliases().removeAlias("test", "alias1").setTimeout(timeout)));
         assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));
 
-
+        
     }
-
+    
     @Test(expected = AliasesNotFoundException.class)
     public void testIndicesRemoveNonExistingAliasResponds404() throws Exception {
         logger.info("--> creating index [test]");
diff --git a/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/SubAggregationSearchCollectModeBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/SubAggregationSearchCollectModeBenchmark.java
index 464c67a..cd06b7b 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/SubAggregationSearchCollectModeBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/SubAggregationSearchCollectModeBenchmark.java
@@ -20,8 +20,6 @@ package org.elasticsearch.benchmark.search.aggregations;
 
 import com.carrotsearch.hppc.ObjectScatterSet;
 import com.carrotsearch.randomizedtesting.generators.RandomStrings;
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;
 import org.elasticsearch.action.admin.cluster.stats.ClusterStatsResponse;
 import org.elasticsearch.action.bulk.BulkRequestBuilder;
@@ -41,6 +39,7 @@ import org.elasticsearch.node.Node;
 import org.elasticsearch.search.aggregations.AggregationBuilders;
 import org.elasticsearch.search.aggregations.Aggregator.SubAggCollectionMode;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
 import java.util.Random;
@@ -208,7 +207,7 @@ public class SubAggregationSearchCollectModeBenchmark {
         COUNT = client.prepareCount().setQuery(matchAllQuery()).execute().actionGet().getCount();
         System.out.println("--> Number of docs in index: " + COUNT);
 
-        List<StatsResult> stats = Lists.newArrayList();
+        List<StatsResult> stats = new ArrayList<>();
         stats.add(runTest("0000", new SubAggCollectionMode[] {SubAggCollectionMode.DEPTH_FIRST,SubAggCollectionMode.DEPTH_FIRST, SubAggCollectionMode.DEPTH_FIRST, SubAggCollectionMode.DEPTH_FIRST}));
         stats.add(runTest("0001", new SubAggCollectionMode[] {SubAggCollectionMode.DEPTH_FIRST,SubAggCollectionMode.DEPTH_FIRST, SubAggCollectionMode.DEPTH_FIRST, SubAggCollectionMode.BREADTH_FIRST}));
         stats.add(runTest("0010", new SubAggCollectionMode[] {SubAggCollectionMode.DEPTH_FIRST,SubAggCollectionMode.DEPTH_FIRST, SubAggCollectionMode.BREADTH_FIRST, SubAggCollectionMode.DEPTH_FIRST}));
diff --git a/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/TermsAggregationSearchBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/TermsAggregationSearchBenchmark.java
index e278feb..7240ee3 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/TermsAggregationSearchBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/TermsAggregationSearchBenchmark.java
@@ -20,8 +20,6 @@ package org.elasticsearch.benchmark.search.aggregations;
 
 import com.carrotsearch.hppc.ObjectScatterSet;
 import com.carrotsearch.randomizedtesting.generators.RandomStrings;
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;
 import org.elasticsearch.action.admin.cluster.stats.ClusterStatsResponse;
 import org.elasticsearch.action.bulk.BulkRequestBuilder;
@@ -42,6 +40,7 @@ import org.elasticsearch.node.Node;
 import org.elasticsearch.search.aggregations.AggregationBuilders;
 import org.elasticsearch.search.aggregations.Aggregator.SubAggCollectionMode;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
 import java.util.Random;
@@ -235,7 +234,7 @@ public class TermsAggregationSearchBenchmark {
         System.out.println("--> Number of docs in index: " + COUNT);
 
 
-        List<StatsResult> stats = Lists.newArrayList();
+        List<StatsResult> stats = new ArrayList<>();
         stats.add(terms("terms_agg_s", Method.AGGREGATION, "s_value", null));
         stats.add(terms("terms_agg_s_dv", Method.AGGREGATION, "s_value_dv", null));
         stats.add(terms("terms_agg_map_s", Method.AGGREGATION, "s_value", "map"));
diff --git a/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/TimeDataHistogramAggregationBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/TimeDataHistogramAggregationBenchmark.java
index 96203cc..5b3984d 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/TimeDataHistogramAggregationBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/TimeDataHistogramAggregationBenchmark.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.benchmark.search.aggregations;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;
 import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;
 import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags;
@@ -44,6 +42,7 @@ import org.elasticsearch.script.ScriptService.ScriptType;
 import org.elasticsearch.search.aggregations.AggregationBuilders;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Locale;
@@ -163,7 +162,7 @@ public class TimeDataHistogramAggregationBenchmark {
         setMapping(ACCEPTABLE_OVERHEAD_RATIO, MEMORY_FORMAT);
         warmUp("hist_l", "l_value", MATCH_PERCENTAGE);
 
-        List<StatsResult> stats = Lists.newArrayList();
+        List<StatsResult> stats = new ArrayList<>();
         stats.add(measureAgg("hist_l", "l_value", MATCH_PERCENTAGE));
 
         NodesStatsResponse nodeStats = client.admin().cluster().prepareNodesStats(nodes[0].settings().get("name")).clear()
diff --git a/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java b/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java
index 7b64f45..1581828 100644
--- a/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java
+++ b/core/src/test/java/org/elasticsearch/bwcompat/OldIndexBackwardsCompatibilityIT.java
@@ -41,7 +41,7 @@ import org.elasticsearch.common.util.MultiDataPathUpgrader;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.env.NodeEnvironment;
 import org.elasticsearch.index.engine.EngineConfig;
-import org.elasticsearch.index.mapper.string.StringFieldMapperPositionOffsetGapTests;
+import org.elasticsearch.index.mapper.string.StringFieldMapperPositionIncrementGapTests;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.shard.MergePolicyConfig;
 import org.elasticsearch.indices.recovery.RecoverySettings;
@@ -332,7 +332,7 @@ public class OldIndexBackwardsCompatibilityIT extends ESIntegTestCase {
         assertNewReplicasWork(indexName);
         assertUpgradeWorks(indexName, isLatestLuceneVersion(version));
         assertDeleteByQueryWorked(indexName, version);
-        assertPositionOffsetGapDefaults(indexName, version);
+        assertPositionIncrementGapDefaults(indexName, version);
         unloadIndex(indexName);
     }
 
@@ -436,7 +436,7 @@ public class OldIndexBackwardsCompatibilityIT extends ESIntegTestCase {
 
     // #10067: create-bwc-index.py deleted any doc with long_sort:[10-20]
     void assertDeleteByQueryWorked(String indexName, Version version) throws Exception {
-        if (version.onOrBefore(Version.V_1_0_0_Beta2)) {
+        if (version.onOrBefore(Version.V_1_0_0_Beta2) || version.onOrAfter(Version.V_2_0_0_beta1)) {
             // TODO: remove this once #10262 is fixed
             return;
         }
@@ -445,11 +445,11 @@ public class OldIndexBackwardsCompatibilityIT extends ESIntegTestCase {
         assertEquals(0, searchReq.get().getHits().getTotalHits());
     }
 
-    void assertPositionOffsetGapDefaults(String indexName, Version version) throws Exception {
+    void assertPositionIncrementGapDefaults(String indexName, Version version) throws Exception {
         if (version.before(Version.V_2_0_0_beta1)) {
-            StringFieldMapperPositionOffsetGapTests.assertGapIsZero(client(), indexName, "doc");
+            StringFieldMapperPositionIncrementGapTests.assertGapIsZero(client(), indexName, "doc");
         } else {
-            StringFieldMapperPositionOffsetGapTests.assertGapIsOneHundred(client(), indexName, "doc");
+            StringFieldMapperPositionIncrementGapTests.assertGapIsOneHundred(client(), indexName, "doc");
         }
     }
 
diff --git a/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java b/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java
index 2130ea5..14bcfc7 100644
--- a/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java
+++ b/core/src/test/java/org/elasticsearch/bwcompat/RestoreBackwardsCompatIT.java
@@ -43,18 +43,15 @@ import java.net.URISyntaxException;
 import java.nio.file.DirectoryStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
 import java.util.SortedSet;
 import java.util.TreeSet;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.notNullValue;
+import static org.hamcrest.Matchers.*;
 
 @ClusterScope(scope = Scope.TEST)
 public class RestoreBackwardsCompatIT extends AbstractSnapshotIntegTestCase {
@@ -144,7 +141,7 @@ public class RestoreBackwardsCompatIT extends AbstractSnapshotIntegTestCase {
     }
 
     private List<String> listRepoVersions(String prefix) throws Exception {
-        List<String> repoVersions = newArrayList();
+        List<String> repoVersions = new ArrayList<>();
         Path repoFiles = reposRoot();
         try (DirectoryStream<Path> stream = Files.newDirectoryStream(repoFiles, prefix + "-*.zip")) {
             for (Path entry : stream) {
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java
index b247441..a35e9f4 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.cluster.routing.allocation;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.google.common.collect.Lists;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -34,6 +33,7 @@ import org.elasticsearch.cluster.routing.allocation.decider.ClusterRebalanceAllo
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.CollectionUtils;
 import org.elasticsearch.test.ESAllocationTestCase;
 import org.hamcrest.Matcher;
 import org.hamcrest.Matchers;
@@ -390,7 +390,7 @@ public class AddIncrementallyTests extends ESAllocationTestCase {
     private ClusterState removeNodes(ClusterState clusterState, AllocationService service, int numNodes) {
         logger.info("Removing [{}] nodes", numNodes);
         DiscoveryNodes.Builder nodes = DiscoveryNodes.builder(clusterState.nodes());
-        ArrayList<DiscoveryNode> discoveryNodes = Lists.newArrayList(clusterState.nodes());
+        ArrayList<DiscoveryNode> discoveryNodes = CollectionUtils.iterableAsArrayList(clusterState.nodes());
         Collections.shuffle(discoveryNodes, getRandom());
         for (DiscoveryNode node : discoveryNodes) {
             nodes.remove(node.id());
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java
index b2bd29d..a6b0e41 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java
@@ -25,20 +25,20 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.RoutingNode;
 import org.elasticsearch.cluster.routing.RoutingNodes;
 import org.elasticsearch.cluster.routing.RoutingTable;
+import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.allocation.decider.ClusterRebalanceAllocationDecider;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.test.ESAllocationTestCase;
 import org.junit.Test;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Sets.newHashSet;
 import static org.elasticsearch.cluster.routing.ShardRoutingState.*;
 import static org.elasticsearch.cluster.routing.allocation.RoutingNodesUtils.numberOfShardsOfType;
@@ -239,7 +239,7 @@ public class SingleShardNoReplicasRoutingTests extends ESAllocationTestCase {
 
         logger.info("Adding " + (numberOfIndices / 2) + " nodes");
         DiscoveryNodes.Builder nodesBuilder = DiscoveryNodes.builder();
-        List<DiscoveryNode> nodes = newArrayList();
+        List<DiscoveryNode> nodes = new ArrayList<>();
         for (int i = 0; i < (numberOfIndices / 2); i++) {
             nodesBuilder.put(newNode("node" + i));
         }
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java
index 35b5ffe..e5a14d2 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/MockDiskUsagesIT.java
@@ -23,7 +23,11 @@ import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
 import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;
 import org.elasticsearch.action.admin.cluster.state.ClusterStateResponse;
-import org.elasticsearch.cluster.*;
+import org.elasticsearch.cluster.ClusterInfo;
+import org.elasticsearch.cluster.ClusterInfoService;
+import org.elasticsearch.cluster.DiskUsage;
+import org.elasticsearch.cluster.InternalClusterInfoService;
+import org.elasticsearch.cluster.MockInternalClusterInfoService;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.RoutingNode;
 import org.elasticsearch.common.settings.Settings;
@@ -32,16 +36,14 @@ import org.elasticsearch.monitor.fs.FsInfo;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
+import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static com.google.common.collect.Maps.newHashMap;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
+import static org.hamcrest.Matchers.*;
 
 @ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)
 public class MockDiskUsagesIT extends ESIntegTestCase {
@@ -100,7 +102,7 @@ public class MockDiskUsagesIT extends ESIntegTestCase {
             }
         });
 
-        final List<String> realNodeNames = newArrayList();
+        final List<String> realNodeNames = new ArrayList<>();
         ClusterStateResponse resp = client().admin().cluster().prepareState().get();
         Iterator<RoutingNode> iter = resp.getState().getRoutingNodes().iterator();
         while (iter.hasNext()) {
diff --git a/core/src/test/java/org/elasticsearch/cluster/settings/SettingsFilteringIT.java b/core/src/test/java/org/elasticsearch/cluster/settings/SettingsFilteringIT.java
index 32551a4..c4bd92e 100644
--- a/core/src/test/java/org/elasticsearch/cluster/settings/SettingsFilteringIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/settings/SettingsFilteringIT.java
@@ -33,7 +33,6 @@ import org.junit.Test;
 import java.util.Collection;
 import java.util.Collections;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.test.ESIntegTestCase.Scope.SUITE;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.hamcrest.Matchers.equalTo;
diff --git a/core/src/test/java/org/elasticsearch/common/StringsTests.java b/core/src/test/java/org/elasticsearch/common/StringsTests.java
index 5844285..07465ac 100644
--- a/core/src/test/java/org/elasticsearch/common/StringsTests.java
+++ b/core/src/test/java/org/elasticsearch/common/StringsTests.java
@@ -29,6 +29,8 @@ public class StringsTests extends ESTestCase {
         assertEquals("fooBar", Strings.toCamelCase("foo_bar"));
         assertEquals("fooBarFooBar", Strings.toCamelCase("foo_bar_foo_bar"));
         assertEquals("fooBar", Strings.toCamelCase("foo_bar_"));
+        assertEquals("_foo", Strings.toCamelCase("_foo"));
+        assertEquals("_fooBar", Strings.toCamelCase("_foo_bar_"));
     }
 
     public void testSubstring() {
diff --git a/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java b/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java
index afc17ce..d313dd7 100644
--- a/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java
+++ b/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java
@@ -26,7 +26,6 @@ import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
 import java.io.IOException;
-
 import java.util.Objects;
 
 import static org.hamcrest.Matchers.closeTo;
diff --git a/core/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java b/core/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java
index 49ca12e..63e0d50 100644
--- a/core/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java
+++ b/core/src/test/java/org/elasticsearch/common/lucene/index/FreqTermsEnumTests.java
@@ -19,10 +19,8 @@
 
 package org.elasticsearch.common.lucene.index;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
-
 import org.apache.lucene.analysis.core.KeywordAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -49,13 +47,13 @@ import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static com.carrotsearch.randomizedtesting.RandomizedTest.randomInt;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.is;
 
@@ -143,7 +141,7 @@ public class FreqTermsEnumTests extends ESTestCase {
 
         // now go over each doc, build the relevant references and filter
         reader = DirectoryReader.open(iw, true);
-        List<Term> filterTerms = Lists.newArrayList();
+        List<Term> filterTerms = new ArrayList<>();
         for (int docId = 0; docId < reader.maxDoc(); docId++) {
             Document doc = reader.document(docId);
             addFreqs(doc, referenceAll);
@@ -207,7 +205,7 @@ public class FreqTermsEnumTests extends ESTestCase {
     private void assertAgainstReference(FreqTermsEnum termsEnum, Map<String, FreqHolder> reference, boolean docFreq, boolean totalTermFreq) throws Exception {
         int cycles = randomIntBetween(1, 5);
         for (int i = 0; i < cycles; i++) {
-            List<String> terms = Lists.newArrayList(Arrays.asList(this.terms));
+            List<String> terms = new ArrayList<>(Arrays.asList(this.terms));
 
            Collections.shuffle(terms, getRandom());
             for (String term : terms) {
diff --git a/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java b/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java
index 807b4a7..234e341 100644
--- a/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java
+++ b/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.common.unit;
 
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.xcontent.XContent;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentType;
@@ -164,29 +162,4 @@ public class FuzzinessTests extends ESTestCase {
         }
     }
 
-    @Test
-    public void testSerialization() throws IOException {
-        Fuzziness fuzziness = Fuzziness.AUTO;
-        Fuzziness deserializedFuzziness = doSerializeRoundtrip(fuzziness);
-        assertEquals(fuzziness, deserializedFuzziness);
-
-        fuzziness = Fuzziness.fromEdits(randomIntBetween(0, 2));
-        deserializedFuzziness = doSerializeRoundtrip(fuzziness);
-        assertEquals(fuzziness, deserializedFuzziness);
-    }
-
-    @Test
-    public void testSerializationAuto() throws IOException {
-        Fuzziness fuzziness = Fuzziness.AUTO;
-        Fuzziness deserializedFuzziness = doSerializeRoundtrip(fuzziness);
-        assertEquals(fuzziness, deserializedFuzziness);
-        assertEquals(fuzziness.asInt(), deserializedFuzziness.asInt());
-    }
-
-    private static Fuzziness doSerializeRoundtrip(Fuzziness in) throws IOException {
-        BytesStreamOutput output = new BytesStreamOutput();
-        in.writeTo(output);
-        StreamInput streamInput = StreamInput.wrap(output.bytes());
-        return Fuzziness.readFuzzinessFrom(streamInput);
-    }
 }
diff --git a/core/src/test/java/org/elasticsearch/common/util/CollectionUtilsTests.java b/core/src/test/java/org/elasticsearch/common/util/CollectionUtilsTests.java
index 09c4b80..d277e3a 100644
--- a/core/src/test/java/org/elasticsearch/common/util/CollectionUtilsTests.java
+++ b/core/src/test/java/org/elasticsearch/common/util/CollectionUtilsTests.java
@@ -28,8 +28,16 @@ import org.apache.lucene.util.Counter;
 import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.SortedSet;
+import java.util.TreeSet;
 
+import static org.elasticsearch.common.util.CollectionUtils.eagerPartition;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.is;
 
@@ -129,4 +137,51 @@ public class CollectionUtilsTests extends ESTestCase {
 
     }
 
+    public void testEmptyPartition() {
+        assertEquals(
+                Collections.emptyList(),
+                eagerPartition(Collections.emptyList(), 1)
+        );
+    }
+
+    public void testSimplePartition() {
+        assertEquals(
+                Arrays.asList(
+                        Arrays.asList(1, 2),
+                        Arrays.asList(3, 4),
+                        Arrays.asList(5)
+                ),
+                eagerPartition(Arrays.asList(1, 2, 3, 4, 5), 2)
+        );
+    }
+
+    public void testSingletonPartition() {
+        assertEquals(
+                Arrays.asList(
+                        Arrays.asList(1),
+                        Arrays.asList(2),
+                        Arrays.asList(3),
+                        Arrays.asList(4),
+                        Arrays.asList(5)
+                ),
+                eagerPartition(Arrays.asList(1, 2, 3, 4, 5), 1)
+        );
+    }
+
+    public void testOversizedPartition() {
+        assertEquals(
+                Arrays.asList(Arrays.asList(1, 2, 3, 4, 5)),
+                eagerPartition(Arrays.asList(1, 2, 3, 4, 5), 15)
+        );
+    }
+
+    public void testPerfectPartition() {
+        assertEquals(
+                Arrays.asList(
+                        Arrays.asList(1, 2, 3, 4, 5, 6),
+                        Arrays.asList(7, 8, 9, 10, 11, 12)
+                ),
+                eagerPartition(Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), 6)
+        );
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/common/util/MultiDataPathUpgraderTests.java b/core/src/test/java/org/elasticsearch/common/util/MultiDataPathUpgraderTests.java
index fc05a79..f916978 100644
--- a/core/src/test/java/org/elasticsearch/common/util/MultiDataPathUpgraderTests.java
+++ b/core/src/test/java/org/elasticsearch/common/util/MultiDataPathUpgraderTests.java
@@ -83,7 +83,7 @@ public class MultiDataPathUpgraderTests extends ESTestCase {
                 ShardStateMetaData.FORMAT.write(new ShardStateMetaData(metaStateVersion, true, uuid), metaStateVersion, shardDataPaths);
             }
             final Path path = randomFrom(shardDataPaths);
-            ShardPath targetPath = new ShardPath(path, path, uuid, new ShardId("foo", 0));
+            ShardPath targetPath = new ShardPath(false, path, path, uuid, new ShardId("foo", 0));
             MultiDataPathUpgrader helper = new MultiDataPathUpgrader(nodeEnvironment);
             helper.upgrade(shardId, targetPath);
             assertFalse(helper.needsUpgrading(shardId));
@@ -177,7 +177,7 @@ public class MultiDataPathUpgraderTests extends ESTestCase {
             }
             logger.info("--> injecting index [{}] into multiple data paths", indexName);
             OldIndexBackwardsCompatibilityIT.copyIndex(logger, src, indexName, multiDataPath);
-            final ShardPath shardPath = new ShardPath(nodeEnvironment.availableShardPaths(new ShardId(indexName, 0))[0], nodeEnvironment.availableShardPaths(new ShardId(indexName, 0))[0], IndexMetaData.INDEX_UUID_NA_VALUE, new ShardId(indexName, 0));
+            final ShardPath shardPath = new ShardPath(false, nodeEnvironment.availableShardPaths(new ShardId(indexName, 0))[0], nodeEnvironment.availableShardPaths(new ShardId(indexName, 0))[0], IndexMetaData.INDEX_UUID_NA_VALUE, new ShardId(indexName, 0));
 
             logger.info("{}", FileSystemUtils.files(shardPath.resolveIndex()));
 
diff --git a/core/src/test/java/org/elasticsearch/common/util/concurrent/PrioritizedExecutorsTests.java b/core/src/test/java/org/elasticsearch/common/util/concurrent/PrioritizedExecutorsTests.java
index ef1c0a9..520b619 100644
--- a/core/src/test/java/org/elasticsearch/common/util/concurrent/PrioritizedExecutorsTests.java
+++ b/core/src/test/java/org/elasticsearch/common/util/concurrent/PrioritizedExecutorsTests.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.common.util.concurrent;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.Priority;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.test.ESTestCase;
@@ -26,9 +25,16 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.junit.Test;
 
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
-import java.util.concurrent.*;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.PriorityBlockingQueue;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.ScheduledThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 
 import static org.hamcrest.Matchers.equalTo;
@@ -42,7 +48,7 @@ public class PrioritizedExecutorsTests extends ESTestCase {
     @Test
     public void testPriorityQueue() throws Exception {
         PriorityBlockingQueue<Priority> queue = new PriorityBlockingQueue<>();
-        List<Priority> priorities = Lists.newArrayList(Priority.values());
+        List<Priority> priorities = Arrays.asList(Priority.values());
         Collections.shuffle(priorities);
 
         for (Priority priority : priorities) {
diff --git a/core/src/test/java/org/elasticsearch/common/xcontent/builder/XContentBuilderTests.java b/core/src/test/java/org/elasticsearch/common/xcontent/builder/XContentBuilderTests.java
index d273f7c..9089ec5 100644
--- a/core/src/test/java/org/elasticsearch/common/xcontent/builder/XContentBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/common/xcontent/builder/XContentBuilderTests.java
@@ -19,19 +19,31 @@
 
 package org.elasticsearch.common.xcontent.builder;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.io.FastCharArrayWriter;
 import org.elasticsearch.common.io.PathUtils;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.xcontent.*;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentBuilderString;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.common.xcontent.XContentGenerator;
+import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.XContentType;
 import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
 import java.io.IOException;
 import java.nio.file.Path;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Calendar;
+import java.util.Date;
+import java.util.GregorianCalendar;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.TimeZone;
 
 import static org.elasticsearch.common.xcontent.XContentBuilder.FieldCaseConversion.CAMELCASE;
 import static org.elasticsearch.common.xcontent.XContentBuilder.FieldCaseConversion.UNDERSCORE;
@@ -142,7 +154,7 @@ public class XContentBuilderTests extends ESTestCase {
     @Test
     public void testOverloadedList() throws Exception {
         XContentBuilder builder = XContentFactory.contentBuilder(XContentType.JSON);
-        builder.startObject().field("test", Lists.newArrayList("1", "2")).endObject();
+        builder.startObject().field("test", Arrays.asList("1", "2")).endObject();
         assertThat(builder.string(), equalTo("{\"test\":[\"1\",\"2\"]}"));
     }
 
diff --git a/core/src/test/java/org/elasticsearch/document/BulkIT.java b/core/src/test/java/org/elasticsearch/document/BulkIT.java
index 3c13b3f..7874684 100644
--- a/core/src/test/java/org/elasticsearch/document/BulkIT.java
+++ b/core/src/test/java/org/elasticsearch/document/BulkIT.java
@@ -195,7 +195,7 @@ public class BulkIT extends ESIntegTestCase {
         bulkResponse = client().prepareBulk()
                 .add(client().prepareUpdate("test", "type", "e1").setDoc("field", "2").setVersion(10)) // INTERNAL
                 .add(client().prepareUpdate("test", "type", "e1").setDoc("field", "3").setVersion(20).setVersionType(VersionType.FORCE))
-                .add(client().prepareUpdate("test", "type", "e1").setDoc("field", "3").setVersion(20).setVersionType(VersionType.INTERNAL)).get();
+                .add(client().prepareUpdate("test", "type", "e1").setDoc("field", "4").setVersion(20).setVersionType(VersionType.INTERNAL)).get();
 
         assertThat(bulkResponse.getItems()[0].getFailureMessage(), containsString("version conflict"));
         assertThat(((UpdateResponse) bulkResponse.getItems()[1].getResponse()).getVersion(), equalTo(20l));
diff --git a/core/src/test/java/org/elasticsearch/http/netty/NettyHttpServerPipeliningTest.java b/core/src/test/java/org/elasticsearch/http/netty/NettyHttpServerPipeliningTest.java
index de923f5..e3a5861 100644
--- a/core/src/test/java/org/elasticsearch/http/netty/NettyHttpServerPipeliningTest.java
+++ b/core/src/test/java/org/elasticsearch/http/netty/NettyHttpServerPipeliningTest.java
@@ -19,27 +19,34 @@
 package org.elasticsearch.http.netty;
 
 import com.google.common.base.Charsets;
-import com.google.common.collect.Lists;
-
+import org.elasticsearch.cache.recycler.MockPageCacheRecycler;
 import org.elasticsearch.common.network.NetworkService;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.InetSocketTransportAddress;
+import org.elasticsearch.common.util.MockBigArrays;
 import org.elasticsearch.http.HttpServerTransport;
 import org.elasticsearch.http.netty.pipelining.OrderedDownstreamChannelEvent;
 import org.elasticsearch.http.netty.pipelining.OrderedUpstreamMessageEvent;
 import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
 import org.elasticsearch.test.ESTestCase;
-import org.elasticsearch.common.util.MockBigArrays;
-import org.elasticsearch.cache.recycler.MockPageCacheRecycler;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.jboss.netty.buffer.ChannelBuffer;
 import org.jboss.netty.buffer.ChannelBuffers;
-import org.jboss.netty.channel.*;
-import org.jboss.netty.handler.codec.http.*;
+import org.jboss.netty.channel.ChannelHandlerContext;
+import org.jboss.netty.channel.ChannelPipeline;
+import org.jboss.netty.channel.ChannelPipelineFactory;
+import org.jboss.netty.channel.ExceptionEvent;
+import org.jboss.netty.channel.MessageEvent;
+import org.jboss.netty.channel.SimpleChannelUpstreamHandler;
+import org.jboss.netty.handler.codec.http.DefaultHttpResponse;
+import org.jboss.netty.handler.codec.http.HttpRequest;
+import org.jboss.netty.handler.codec.http.HttpResponse;
+import org.jboss.netty.handler.codec.http.QueryStringDecoder;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.List;
@@ -108,7 +115,7 @@ public class NettyHttpServerPipeliningTest extends ESTestCase {
         List<String> requests = Arrays.asList("/slow?sleep=1000", "/firstfast", "/secondfast", "/thirdfast", "/slow?sleep=500");
         try (NettyHttpClient nettyHttpClient = new NettyHttpClient()) {
             Collection<HttpResponse> responses = nettyHttpClient.sendRequests(transportAddress.address(), requests.toArray(new String[]{}));
-            List<String> responseBodies = Lists.newArrayList(returnHttpResponseBodies(responses));
+            List<String> responseBodies = new ArrayList<>(returnHttpResponseBodies(responses));
             // we cannot be sure about the order of the fast requests, but the slow ones should have to be last
             assertThat(responseBodies, hasSize(5));
             assertThat(responseBodies.get(3), is("/slow?sleep=500"));
diff --git a/core/src/test/java/org/elasticsearch/http/netty/NettyPipeliningDisabledIT.java b/core/src/test/java/org/elasticsearch/http/netty/NettyPipeliningDisabledIT.java
index 5587967..1d968b7 100644
--- a/core/src/test/java/org/elasticsearch/http/netty/NettyPipeliningDisabledIT.java
+++ b/core/src/test/java/org/elasticsearch/http/netty/NettyPipeliningDisabledIT.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.http.netty;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.InetSocketTransportAddress;
 import org.elasticsearch.http.HttpServerTransport;
@@ -27,6 +26,7 @@ import org.elasticsearch.test.ESIntegTestCase;
 import org.jboss.netty.handler.codec.http.HttpResponse;
 import org.junit.Test;
 
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.List;
@@ -36,7 +36,8 @@ import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.http.netty.NettyHttpClient.returnOpaqueIds;
 import static org.elasticsearch.test.ESIntegTestCase.ClusterScope;
 import static org.elasticsearch.test.ESIntegTestCase.Scope;
-import static org.hamcrest.Matchers.*;
+import static org.hamcrest.Matchers.containsInAnyOrder;
+import static org.hamcrest.Matchers.hasSize;
 
 /**
  *
@@ -61,7 +62,7 @@ public class NettyPipeliningDisabledIT extends ESIntegTestCase {
             Collection<HttpResponse> responses = nettyHttpClient.sendRequests(inetSocketTransportAddress.address(), requests.toArray(new String[]{}));
             assertThat(responses, hasSize(requests.size()));
 
-            List<String> opaqueIds = Lists.newArrayList(returnOpaqueIds(responses));
+            List<String> opaqueIds = new ArrayList<>(returnOpaqueIds(responses));
 
             assertResponsesOutOfOrder(opaqueIds);
         }
diff --git a/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java b/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java
index ee85af9..03100ef 100644
--- a/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java
+++ b/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java
@@ -44,11 +44,15 @@ import org.elasticsearch.snapshots.SnapshotState;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.InternalTestCluster;
 import org.elasticsearch.test.transport.MockTransportService;
-import org.elasticsearch.transport.*;
+import org.elasticsearch.transport.TransportException;
+import org.elasticsearch.transport.TransportRequest;
+import org.elasticsearch.transport.TransportRequestOptions;
+import org.elasticsearch.transport.TransportService;
 import org.junit.Test;
 
 import java.io.IOException;
 import java.nio.file.Path;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.CountDownLatch;
@@ -57,7 +61,6 @@ import java.util.concurrent.Future;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.hamcrest.Matchers.*;
@@ -570,7 +573,7 @@ public class IndexWithShadowReplicasIT extends ESIntegTestCase {
         ensureGreen(IDX);
 
         int docCount = randomIntBetween(10, 100);
-        List<IndexRequestBuilder> builders = newArrayList();
+        List<IndexRequestBuilder> builders = new ArrayList<>();
         for (int i = 0; i < docCount; i++) {
             builders.add(client().prepareIndex(IDX, "doc", i + "").setSource("foo", "bar"));
         }
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/AnalysisModuleTests.java b/core/src/test/java/org/elasticsearch/index/analysis/AnalysisModuleTests.java
index 4a09eee..0398618 100644
--- a/core/src/test/java/org/elasticsearch/index/analysis/AnalysisModuleTests.java
+++ b/core/src/test/java/org/elasticsearch/index/analysis/AnalysisModuleTests.java
@@ -42,8 +42,8 @@ import org.elasticsearch.index.analysis.filter1.MyFilterTokenFilterFactory;
 import org.elasticsearch.index.settings.IndexSettingsModule;
 import org.elasticsearch.indices.analysis.IndicesAnalysisService;
 import org.elasticsearch.test.ESTestCase;
+import org.elasticsearch.test.VersionUtils;
 import org.hamcrest.MatcherAssert;
-import org.junit.Test;
 
 import java.io.BufferedWriter;
 import java.io.IOException;
@@ -54,9 +54,7 @@ import java.nio.file.Path;
 import java.util.Set;
 
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -87,26 +85,22 @@ public class AnalysisModuleTests extends ESTestCase {
 
     }
 
-    @Test
     public void testSimpleConfigurationJson() {
         Settings settings = loadFromClasspath("/org/elasticsearch/index/analysis/test1.json");
         testSimpleConfiguration(settings);
     }
 
-    @Test
     public void testSimpleConfigurationYaml() {
         Settings settings = loadFromClasspath("/org/elasticsearch/index/analysis/test1.yml");
         testSimpleConfiguration(settings);
     }
 
-    @Test
     public void testDefaultFactoryTokenFilters() throws IOException {
         assertTokenFilter("keyword_repeat", KeywordRepeatFilter.class);
         assertTokenFilter("persian_normalization", PersianNormalizationFilter.class);
         assertTokenFilter("arabic_normalization", ArabicNormalizationFilter.class);
     }
 
-    @Test
     public void testVersionedAnalyzers() throws Exception {
         String yaml = "/org/elasticsearch/index/analysis/test1.yml";
         Settings settings2 = settingsBuilder()
@@ -164,7 +158,7 @@ public class AnalysisModuleTests extends ESTestCase {
 //        html = (HtmlStripCharFilterFactory) custom2.charFilters()[1];
 //        assertThat(html.readAheadLimit(), equalTo(1024));
 
-        // verify position offset gap
+        // verify position increment gap
         analyzer = analysisService.analyzer("custom6").analyzer();
         assertThat(analyzer, instanceOf(CustomAnalyzer.class));
         CustomAnalyzer custom6 = (CustomAnalyzer) analyzer;
@@ -215,7 +209,6 @@ public class AnalysisModuleTests extends ESTestCase {
 //        MatcherAssert.assertThat(wordList, hasItems("donau", "dampf", "schiff", "spargel", "creme", "suppe"));
     }
 
-    @Test
     public void testWordListPath() throws Exception {
         Settings settings = Settings.builder()
                                .put("path.home", createTempDir().toString())
@@ -243,7 +236,6 @@ public class AnalysisModuleTests extends ESTestCase {
         return wordListFile;
     }
 
-    @Test
     public void testUnderscoreInAnalyzerName() {
         Settings settings = Settings.builder()
                 .put("index.analysis.analyzer._invalid_name.tokenizer", "keyword")
@@ -255,11 +247,10 @@ public class AnalysisModuleTests extends ESTestCase {
             fail("This should fail with IllegalArgumentException because the analyzers name starts with _");
         } catch (ProvisionException e) {
             assertTrue(e.getCause() instanceof IllegalArgumentException);
-            assertThat(e.getCause().getMessage(), equalTo("analyzer name must not start with '_'. got \"_invalid_name\""));
+            assertThat(e.getCause().getMessage(), either(equalTo("analyzer name must not start with '_'. got \"_invalid_name\"")).or(equalTo("analyzer name must not start with '_'. got \"_invalidName\"")));
         }
     }
 
-    @Test
     public void testUnderscoreInAnalyzerNameAlias() {
         Settings settings = Settings.builder()
                 .put("index.analysis.analyzer.valid_name.tokenizer", "keyword")
@@ -275,4 +266,61 @@ public class AnalysisModuleTests extends ESTestCase {
             assertThat(e.getCause().getMessage(), equalTo("analyzer name must not start with '_'. got \"_invalid_name\""));
         }
     }
+
+    public void testBackwardCompatible() {
+        Settings settings = settingsBuilder()
+                .put("index.analysis.analyzer.custom1.tokenizer", "standard")
+                .put("index.analysis.analyzer.custom1.position_offset_gap", "128")
+                .put("index.analysis.analyzer.custom2.tokenizer", "standard")
+                .put("index.analysis.analyzer.custom2.position_increment_gap", "256")
+                .put("path.home", createTempDir().toString())
+                .put(IndexMetaData.SETTING_VERSION_CREATED, VersionUtils.randomVersionBetween(random(), Version.V_1_0_0,
+                        Version.V_1_7_1))
+                .build();
+        AnalysisService analysisService = getAnalysisService(settings);
+
+        Analyzer custom1 = analysisService.analyzer("custom1").analyzer();
+        assertThat(custom1, instanceOf(CustomAnalyzer.class));
+        assertThat(custom1.getPositionIncrementGap("custom1"), equalTo(128));
+
+        Analyzer custom2 = analysisService.analyzer("custom2").analyzer();
+        assertThat(custom2, instanceOf(CustomAnalyzer.class));
+        assertThat(custom2.getPositionIncrementGap("custom2"), equalTo(256));
+    }
+
+    public void testWithBothSettings() {
+        Settings settings = settingsBuilder()
+                .put("index.analysis.analyzer.custom.tokenizer", "standard")
+                .put("index.analysis.analyzer.custom.position_offset_gap", "128")
+                .put("index.analysis.analyzer.custom.position_increment_gap", "256")
+                .put("path.home", createTempDir().toString())
+                .put(IndexMetaData.SETTING_VERSION_CREATED, VersionUtils.randomVersionBetween(random(), Version.V_1_0_0,
+                        Version.V_1_7_1))
+                .build();
+        try {
+            getAnalysisService(settings);
+            fail("Analyzer has both position_offset_gap and position_increment_gap should fail");
+        } catch (ProvisionException e) {
+            assertTrue(e.getCause() instanceof IllegalArgumentException);
+            assertThat(e.getCause().getMessage(), equalTo("Custom Analyzer [custom] defined both [position_offset_gap] and [position_increment_gap]" +
+                    ", use only [position_increment_gap]"));
+        }
+    }
+
+    public void testDeprecatedPositionOffsetGap() {
+        Settings settings = settingsBuilder()
+                .put("index.analysis.analyzer.custom.tokenizer", "standard")
+                .put("index.analysis.analyzer.custom.position_offset_gap", "128")
+                .put("path.home", createTempDir().toString())
+                .put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT)
+                .build();
+        try {
+            getAnalysisService(settings);
+            fail("Analyzer should fail if it has position_offset_gap");
+        } catch (ProvisionException e) {
+            assertTrue(e.getCause() instanceof IllegalArgumentException);
+            assertThat(e.getCause().getMessage(), equalTo("Option [position_offset_gap] in Custom Analyzer [custom] " +
+                    "has been renamed, please use [position_increment_gap] instead."));
+        }
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/test1.json b/core/src/test/java/org/elasticsearch/index/analysis/test1.json
index 927d070..2434963 100644
--- a/core/src/test/java/org/elasticsearch/index/analysis/test1.json
+++ b/core/src/test/java/org/elasticsearch/index/analysis/test1.json
@@ -68,7 +68,7 @@
                 },
                 "custom6":{
                     "tokenizer":"standard",
-                    "position_offset_gap": 256
+                    "position_increment_gap": 256
                 },
                 "czechAnalyzerWithStemmer":{
                     "tokenizer":"standard",
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/test1.yml b/core/src/test/java/org/elasticsearch/index/analysis/test1.yml
index 518ef2c..196e4ef 100644
--- a/core/src/test/java/org/elasticsearch/index/analysis/test1.yml
+++ b/core/src/test/java/org/elasticsearch/index/analysis/test1.yml
@@ -50,7 +50,7 @@ index :
         char_filter : [my_mapping]
       custom6 :
         tokenizer : standard
-        position_offset_gap: 256
+        position_increment_gap: 256
       custom7 :
         type : standard
         version: 3.6
diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
index 8edc474..f3d45a8 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
@@ -29,15 +29,7 @@ import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.TextField;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexDeletionPolicy;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LiveIndexWriterConfig;
-import org.apache.lucene.index.LogByteSizeMergePolicy;
-import org.apache.lucene.index.MergePolicy;
-import org.apache.lucene.index.NoMergePolicy;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.TieredMergePolicy;
+import org.apache.lucene.index.*;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.TermQuery;
@@ -55,7 +47,6 @@ import org.elasticsearch.common.Base64;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.io.FileSystemUtils;
 import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.lucene.uid.Versions;
@@ -69,16 +60,9 @@ import org.elasticsearch.index.deletionpolicy.KeepOnlyLastDeletionPolicy;
 import org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy;
 import org.elasticsearch.index.engine.Engine.Searcher;
 import org.elasticsearch.index.indexing.ShardIndexingService;
-import org.elasticsearch.index.mapper.ContentPath;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.DocumentMapperParser;
+import org.elasticsearch.index.mapper.*;
 import org.elasticsearch.index.mapper.Mapper.BuilderContext;
-import org.elasticsearch.index.mapper.MapperBuilders;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.mapper.Mapping;
-import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext.Document;
-import org.elasticsearch.index.mapper.ParsedDocument;
 import org.elasticsearch.index.mapper.internal.SourceFieldMapper;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.mapper.object.RootObjectMapper;
@@ -107,13 +91,7 @@ import java.nio.charset.Charset;
 import java.nio.file.DirectoryStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
+import java.util.*;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.regex.Pattern;
@@ -121,12 +99,7 @@ import java.util.regex.Pattern;
 import static org.elasticsearch.common.settings.Settings.Builder.EMPTY_SETTINGS;
 import static org.elasticsearch.index.engine.Engine.Operation.Origin.PRIMARY;
 import static org.elasticsearch.index.engine.Engine.Operation.Origin.REPLICA;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.hasKey;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.*;
 
 public class InternalEngineTests extends ESTestCase {
 
@@ -1984,8 +1957,8 @@ public class InternalEngineTests extends ESTestCase {
         }
 
         @Override
-        protected Tuple<DocumentMapper, Mapping> docMapper(String type) {
-            return new Tuple<>(docMapper, mappingUpdate);
+        protected DocumentMapperForType docMapper(String type) {
+            return new DocumentMapperForType(docMapper, mappingUpdate);
         }
 
         @Override
diff --git a/core/src/test/java/org/elasticsearch/index/fielddata/DuelFieldDataTests.java b/core/src/test/java/org/elasticsearch/index/fielddata/DuelFieldDataTests.java
index 3dee750..9a4250f 100644
--- a/core/src/test/java/org/elasticsearch/index/fielddata/DuelFieldDataTests.java
+++ b/core/src/test/java/org/elasticsearch/index/fielddata/DuelFieldDataTests.java
@@ -20,12 +20,15 @@ package org.elasticsearch.index.fielddata;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
 import com.carrotsearch.randomizedtesting.generators.RandomStrings;
-import com.google.common.collect.Lists;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.SortedSetDocValuesField;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.*;
+import org.apache.lucene.index.CompositeReaderContext;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.RandomAccessOrds;
+import org.apache.lucene.index.SortedNumericDocValues;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.English;
@@ -40,8 +43,16 @@ import org.elasticsearch.index.mapper.DocumentMapper;
 import org.elasticsearch.index.mapper.ParsedDocument;
 import org.junit.Test;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
 import java.util.Map.Entry;
+import java.util.Random;
+import java.util.Set;
 
 import static org.hamcrest.Matchers.*;
 
@@ -578,8 +589,8 @@ public class DuelFieldDataTests extends AbstractFieldDataTests {
             final int numValues = leftValues.count();
             rightValues.setDocument(i);;
             assertEquals(numValues, rightValues.count());
-            List<GeoPoint> leftPoints = Lists.newArrayList();
-            List<GeoPoint> rightPoints = Lists.newArrayList();
+            List<GeoPoint> leftPoints = new ArrayList<>();
+            List<GeoPoint> rightPoints = new ArrayList<>();
             for (int j = 0; j < numValues; ++j) {
                 GeoPoint l = leftValues.valueAt(j);
                 leftPoints.add(new GeoPoint(l.getLat(), l.getLon()));
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/DynamicMappingTests.java b/core/src/test/java/org/elasticsearch/index/mapper/DynamicMappingTests.java
index 02841f7..f989467 100644
--- a/core/src/test/java/org/elasticsearch/index/mapper/DynamicMappingTests.java
+++ b/core/src/test/java/org/elasticsearch/index/mapper/DynamicMappingTests.java
@@ -19,16 +19,11 @@
 package org.elasticsearch.index.mapper;
 
 import com.google.common.collect.ImmutableMap;
-
 import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.indices.mapping.get.GetMappingsResponse;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentHelper;
-import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.mapper.core.IntegerFieldMapper;
 import org.elasticsearch.index.mapper.core.StringFieldMapper;
@@ -368,7 +363,7 @@ public class DynamicMappingTests extends ESSingleNodeTestCase {
 
         // Even if the dynamic type of our new field is long, we already have a mapping for the same field
         // of type string so it should be mapped as a string
-        DocumentMapper newMapper = indexService.mapperService().documentMapperWithAutoCreate("type2").v1();
+        DocumentMapper newMapper = indexService.mapperService().documentMapperWithAutoCreate("type2").getDocumentMapper();
         Mapper update = parse(newMapper, indexService.mapperService().documentMapperParser(),
                 XContentFactory.jsonBuilder().startObject().field("my_field1", 42).endObject());
         Mapper myField1Mapper = null;
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java b/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java
index bfefe43..5ea01ee 100644
--- a/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java
+++ b/core/src/test/java/org/elasticsearch/index/mapper/FieldTypeLookupTests.java
@@ -20,14 +20,13 @@
 package org.elasticsearch.index.mapper;
 
 import com.google.common.collect.Iterators;
-import com.google.common.collect.Lists;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.mapper.core.StringFieldMapper;
 import org.elasticsearch.test.ESTestCase;
 
 import java.io.IOException;
+import java.util.Arrays;
 import java.util.Collection;
 import java.util.Iterator;
 import java.util.List;
@@ -231,7 +230,7 @@ public class FieldTypeLookupTests extends ESTestCase {
     }
 
     static List<FieldMapper> newList(FieldMapper... mapper) {
-        return Lists.newArrayList(mapper);
+        return Arrays.asList(mapper);
     }
 
     // this sucks how much must be overridden just do get a dummy field mapper...
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/date/DateBackwardsCompatibilityTests.java b/core/src/test/java/org/elasticsearch/index/mapper/date/DateBackwardsCompatibilityTests.java
index b6ecb24..4e906ae 100644
--- a/core/src/test/java/org/elasticsearch/index/mapper/date/DateBackwardsCompatibilityTests.java
+++ b/core/src/test/java/org/elasticsearch/index/mapper/date/DateBackwardsCompatibilityTests.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.index.mapper.date;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.index.IndexResponse;
 import org.elasticsearch.action.search.SearchResponse;
@@ -33,6 +32,7 @@ import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.test.ESSingleNodeTestCase;
 import org.junit.Before;
 
+import java.util.Arrays;
 import java.util.List;
 
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
@@ -84,7 +84,7 @@ public class DateBackwardsCompatibilityTests extends ESSingleNodeTestCase {
 
     public void testThatPre2xSupportsUnixTimestampsInAnyDateFormat() throws Exception {
         long dateInMillis = 1435073872l * 1000; // Tue Jun 23 17:37:52 CEST 2015
-        List<String> dateFormats = Lists.newArrayList("dateOptionalTime", "weekDate", "tTime", "ordinalDate", "hourMinuteSecond", "hourMinute");
+        List<String> dateFormats = Arrays.asList("dateOptionalTime", "weekDate", "tTime", "ordinalDate", "hourMinuteSecond", "hourMinute");
 
         for (String format : dateFormats) {
             XContentBuilder mapping = jsonBuilder().startObject().startObject("properties")
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/externalvalues/ExternalMapper.java b/core/src/test/java/org/elasticsearch/index/mapper/externalvalues/ExternalMapper.java
index 0024a63..e0c7a30 100755
--- a/core/src/test/java/org/elasticsearch/index/mapper/externalvalues/ExternalMapper.java
+++ b/core/src/test/java/org/elasticsearch/index/mapper/externalvalues/ExternalMapper.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.index.mapper.externalvalues;
 
 import com.google.common.collect.Iterators;
-import com.google.common.collect.Lists;
 import com.spatial4j.core.shape.Point;
 import org.apache.lucene.document.Field;
 import org.elasticsearch.common.Strings;
@@ -43,6 +42,7 @@ import org.elasticsearch.index.mapper.geo.GeoShapeFieldMapper;
 
 import java.io.IOException;
 import java.nio.charset.Charset;
+import java.util.Arrays;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
@@ -220,7 +220,7 @@ public class ExternalMapper extends FieldMapper {
 
     @Override
     public Iterator<Mapper> iterator() {
-        return Iterators.concat(super.iterator(), Lists.newArrayList(binMapper, boolMapper, pointMapper, shapeMapper, stringMapper).iterator());
+        return Iterators.concat(super.iterator(), Arrays.asList(binMapper, boolMapper, pointMapper, shapeMapper, stringMapper).iterator());
     }
 
     @Override
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/source/DefaultSourceMappingTests.java b/core/src/test/java/org/elasticsearch/index/mapper/source/DefaultSourceMappingTests.java
index f6a4c30..4ec0ff5 100644
--- a/core/src/test/java/org/elasticsearch/index/mapper/source/DefaultSourceMappingTests.java
+++ b/core/src/test/java/org/elasticsearch/index/mapper/source/DefaultSourceMappingTests.java
@@ -38,7 +38,7 @@ import java.util.Arrays;
 import java.util.List;
 import java.util.Map;
 
-import static org.hamcrest.Matchers.*;
+import static org.hamcrest.Matchers.equalTo;
 
 public class DefaultSourceMappingTests extends ESSingleNodeTestCase {
 
@@ -202,7 +202,7 @@ public class DefaultSourceMappingTests extends ESSingleNodeTestCase {
         MapperService mapperService = createIndex("test").mapperService();
         mapperService.merge(MapperService.DEFAULT_MAPPING, new CompressedXContent(defaultMapping), true, false);
 
-        DocumentMapper mapper = mapperService.documentMapperWithAutoCreate("my_type").v1();
+        DocumentMapper mapper = mapperService.documentMapperWithAutoCreate("my_type").getDocumentMapper();
         assertThat(mapper.type(), equalTo("my_type"));
         assertThat(mapper.sourceMapper().enabled(), equalTo(false));
     }
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/string/SimpleStringMappingTests.java b/core/src/test/java/org/elasticsearch/index/mapper/string/SimpleStringMappingTests.java
index a540dd8..f122de9 100644
--- a/core/src/test/java/org/elasticsearch/index/mapper/string/SimpleStringMappingTests.java
+++ b/core/src/test/java/org/elasticsearch/index/mapper/string/SimpleStringMappingTests.java
@@ -20,12 +20,12 @@
 package org.elasticsearch.index.mapper.string;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.index.DocValuesType;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexableField;
 import org.apache.lucene.index.IndexableFieldType;
+import org.elasticsearch.Version;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
@@ -39,11 +39,13 @@ import org.elasticsearch.index.mapper.DocumentMapper;
 import org.elasticsearch.index.mapper.DocumentMapperParser;
 import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.Mapper.BuilderContext;
+import org.elasticsearch.index.mapper.MapperParsingException;
 import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.ParseContext.Document;
 import org.elasticsearch.index.mapper.ParsedDocument;
 import org.elasticsearch.index.mapper.core.StringFieldMapper;
 import org.elasticsearch.test.ESSingleNodeTestCase;
+import org.elasticsearch.test.VersionUtils;
 import org.junit.Before;
 import org.junit.Test;
 
@@ -51,9 +53,7 @@ import java.util.Arrays;
 import java.util.Map;
 
 import static org.elasticsearch.index.mapper.core.StringFieldMapper.Builder;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.*;
 
 /**
  */
@@ -222,22 +222,22 @@ public class SimpleStringMappingTests extends ESSingleNodeTestCase {
                 .startObject("properties")
                 .startObject("field1")
                     .field("type", "string")
-                    .field("position_offset_gap", 1000)
+                    .field("position_increment_gap", 1000)
                 .endObject()
                 .startObject("field2")
                     .field("type", "string")
-                    .field("position_offset_gap", 1000)
+                    .field("position_increment_gap", 1000)
                     .field("analyzer", "standard")
                 .endObject()
                 .startObject("field3")
                     .field("type", "string")
-                    .field("position_offset_gap", 1000)
+                    .field("position_increment_gap", 1000)
                     .field("analyzer", "standard")
                     .field("search_analyzer", "simple")
                 .endObject()
                 .startObject("field4")
                     .field("type", "string")
-                    .field("position_offset_gap", 1000)
+                    .field("position_increment_gap", 1000)
                     .field("analyzer", "standard")
                     .field("search_analyzer", "simple")
                     .field("search_quote_analyzer", "simple")
@@ -246,7 +246,7 @@ public class SimpleStringMappingTests extends ESSingleNodeTestCase {
                 .endObject().endObject().string();
 
         DocumentMapper mapper = parser.parse(mapping);
-        for (String fieldName : Lists.newArrayList("field1", "field2", "field3", "field4")) {
+        for (String fieldName : Arrays.asList("field1", "field2", "field3", "field4")) {
             Map<String, Object> serializedMap = getSerializedMap(fieldName, mapper);
             assertFalse(fieldName, serializedMap.containsKey("search_quote_analyzer"));
         }
@@ -256,12 +256,12 @@ public class SimpleStringMappingTests extends ESSingleNodeTestCase {
                 .startObject("properties")
                 .startObject("field1")
                     .field("type", "string")
-                    .field("position_offset_gap", 1000)
+                    .field("position_increment_gap", 1000)
                     .field("search_quote_analyzer", "simple")
                 .endObject()
                 .startObject("field2")
                     .field("type", "string")
-                    .field("position_offset_gap", 1000)
+                    .field("position_increment_gap", 1000)
                     .field("analyzer", "standard")
                     .field("search_analyzer", "standard")
                     .field("search_quote_analyzer", "simple")
@@ -270,7 +270,7 @@ public class SimpleStringMappingTests extends ESSingleNodeTestCase {
                 .endObject().endObject().string();
         
         mapper = parser.parse(mapping);
-        for (String fieldName : Lists.newArrayList("field1", "field2")) {
+        for (String fieldName : Arrays.asList("field1", "field2")) {
             Map<String, Object> serializedMap = getSerializedMap(fieldName, mapper);
             assertEquals(serializedMap.get("search_quote_analyzer"), "simple");
         }
@@ -518,4 +518,48 @@ public class SimpleStringMappingTests extends ESSingleNodeTestCase {
         assertTrue(mergeResult.buildConflicts()[0].contains("cannot enable norms"));
     }
 
+    /**
+     * Test that expected exceptions are thrown when creating a new index with position_offset_gap
+     */
+    public void testPositionOffsetGapDeprecation() throws Exception {
+        // test deprecation exceptions on newly created indexes
+        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
+                .startObject("properties")
+                .startObject("field1")
+                .field("type", "string")
+                .field("position_increment_gap", 10)
+                .endObject()
+                .startObject("field2")
+                .field("type", "string")
+                .field("position_offset_gap", 50)
+                .field("analyzer", "standard")
+                .endObject().endObject().endObject().endObject().string();
+        try {
+            parser.parse(mapping);
+            fail("Mapping definition should fail with the position_offset_gap setting");
+        }catch (MapperParsingException e) {
+            assertEquals(e.getMessage(), "Mapping definition for [field2] has unsupported parameters:  [position_offset_gap : 50]");
+        }
+    }
+
+    /**
+     * Test backward compatibility
+     */
+    public void testBackwardCompatible() throws Exception {
+
+        Settings settings = Settings.settingsBuilder().put(IndexMetaData.SETTING_VERSION_CREATED, VersionUtils.randomVersionBetween(random(), Version.V_1_0_0,
+                                         Version.V_1_7_1)).build();
+
+        DocumentMapperParser parser = createIndex("backward_compatible_index", settings).mapperService().documentMapperParser();
+
+        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
+                .startObject("properties")
+                .startObject("field1")
+                .field("type", "string")
+                .field("position_offset_gap", 10)
+                .endObject().endObject().endObject().endObject().string();
+        parser.parse(mapping);
+
+        assertThat(parser.parse(mapping).mapping().toString(), containsString("\"position_increment_gap\":10"));
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/string/StringFieldMapperPositionIncrementGapTests.java b/core/src/test/java/org/elasticsearch/index/mapper/string/StringFieldMapperPositionIncrementGapTests.java
new file mode 100644
index 0000000..61a9c3a
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/mapper/string/StringFieldMapperPositionIncrementGapTests.java
@@ -0,0 +1,158 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.mapper.string;
+
+import com.google.common.collect.ImmutableList;
+
+import org.elasticsearch.ExceptionsHelper;
+import org.elasticsearch.client.Client;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.index.mapper.MapperParsingException;
+import org.elasticsearch.test.ESSingleNodeTestCase;
+
+import java.io.IOException;
+
+import static org.elasticsearch.index.query.QueryBuilders.matchPhraseQuery;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.hamcrest.Matchers.containsString;
+
+/**
+ * Tests that position_increment_gap is read from the mapper and applies as
+ * expected in queries.
+ */
+public class StringFieldMapperPositionIncrementGapTests extends ESSingleNodeTestCase {
+    /**
+     * The default position_increment_gap should be large enough that most
+     * "sensible" queries phrase slops won't match across values.
+     */
+    public void testDefault() throws IOException {
+        assertGapIsOneHundred(client(), "test", "test");
+    }
+
+    /**
+     * Asserts that the post-2.0 default is being applied.
+     */
+    public static void assertGapIsOneHundred(Client client, String indexName, String type) throws IOException {
+        testGap(client, indexName, type, 100);
+
+        // No match across gap using default slop with default positionIncrementGap
+        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two")).get(), 0);
+
+        // Nor with small-ish values
+        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(5)).get(), 0);
+        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(50)).get(), 0);
+
+        // But huge-ish values still match
+        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(500)).get(), 1);
+    }
+
+    public void testZero() throws IOException {
+        setupGapInMapping(0);
+        assertGapIsZero(client(), "test", "test");
+    }
+
+    /**
+     * Asserts that the pre-2.0 default has been applied or explicitly
+     * configured.
+     */
+    public static void assertGapIsZero(Client client, String indexName, String type) throws IOException {
+        testGap(client, indexName, type, 0);
+        /*
+         * Phrases match across different values using default slop with pre-2.0 default
+         * position_increment_gap.
+         */
+        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two")).get(), 1);
+    }
+
+    public void testLargerThanDefault() throws IOException {
+        setupGapInMapping(10000);
+        testGap(client(), "test", "test", 10000);
+    }
+
+    public void testSmallerThanDefault() throws IOException {
+        setupGapInMapping(2);
+        testGap(client(), "test", "test", 2);
+    }
+
+    public void testNegativeIsError() throws IOException {
+        try {
+            setupGapInMapping(-1);
+            fail("Expected an error");
+        } catch (MapperParsingException e) {
+            assertThat(ExceptionsHelper.detailedMessage(e), containsString("positions_increment_gap less than 0 aren't allowed"));
+        }
+    }
+
+    /**
+     * Tests that the default actually defaults to the position_increment_gap
+     * configured in the analyzer. This behavior is very old and a little
+     * strange but not worth breaking some thought.
+     */
+    public void testDefaultDefaultsToAnalyzer() throws IOException {
+        XContentBuilder settings = XContentFactory.jsonBuilder().startObject().startObject("analysis").startObject("analyzer")
+                .startObject("gappy");
+        settings.field("type", "custom");
+        settings.field("tokenizer", "standard");
+        settings.field("position_increment_gap", 2);
+        setupAnalyzer(settings, "gappy");
+        testGap(client(), "test", "test", 2);
+    }
+
+    /**
+     * Build an index named "test" with a field named "string" with the provided
+     * positionIncrementGap that uses the standard analyzer.
+     */
+    private void setupGapInMapping(int positionIncrementGap) throws IOException {
+        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("properties").startObject("string");
+        mapping.field("type", "string");
+        mapping.field("position_increment_gap", positionIncrementGap);
+        client().admin().indices().prepareCreate("test").addMapping("test", mapping).get();
+    }
+
+    /**
+     * Build an index named "test" with the provided settings and and a field
+     * named "string" that uses the specified analyzer and default
+     * position_increment_gap.
+     */
+    private void setupAnalyzer(XContentBuilder settings, String analyzer) throws IOException {
+        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("properties").startObject("string");
+        mapping.field("type", "string");
+        mapping.field("analyzer", analyzer);
+        client().admin().indices().prepareCreate("test").addMapping("test", mapping).setSettings(settings).get();
+    }
+
+    private static void testGap(Client client, String indexName, String type, int positionIncrementGap) throws IOException {
+        client.prepareIndex(indexName, type, "position_gap_test").setSource("string", ImmutableList.of("one", "two three")).setRefresh(true).get();
+
+        // Baseline - phrase query finds matches in the same field value
+        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "two three")).get(), 1);
+
+        if (positionIncrementGap > 0) {
+            // No match across gaps when slop < position gap
+            assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(positionIncrementGap - 1)).get(),
+                    0);
+        }
+
+        // Match across gaps when slop >= position gap
+        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(positionIncrementGap)).get(), 1);
+        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(positionIncrementGap + 1)).get(), 1);
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/string/StringFieldMapperPositionOffsetGapTests.java b/core/src/test/java/org/elasticsearch/index/mapper/string/StringFieldMapperPositionOffsetGapTests.java
deleted file mode 100644
index 86701f8..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/string/StringFieldMapperPositionOffsetGapTests.java
+++ /dev/null
@@ -1,158 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.mapper.string;
-
-import com.google.common.collect.ImmutableList;
-
-import org.elasticsearch.ExceptionsHelper;
-import org.elasticsearch.client.Client;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.mapper.MapperParsingException;
-import org.elasticsearch.test.ESSingleNodeTestCase;
-
-import java.io.IOException;
-
-import static org.elasticsearch.index.query.QueryBuilders.matchPhraseQuery;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.hamcrest.Matchers.containsString;
-
-/**
- * Tests that position_offset_gap is read from the mapper and applies as
- * expected in queries.
- */
-public class StringFieldMapperPositionOffsetGapTests extends ESSingleNodeTestCase {
-    /**
-     * The default position_offset_gap should be large enough that most
-     * "sensible" queries phrase slops won't match across values.
-     */
-    public void testDefault() throws IOException {
-        assertGapIsOneHundred(client(), "test", "test");
-    }
-
-    /**
-     * Asserts that the post-2.0 default is being applied.
-     */
-    public static void assertGapIsOneHundred(Client client, String indexName, String type) throws IOException {
-        testGap(client(), indexName, type, 100);
-
-        // No match across gap using default slop with default positionOffsetGap
-        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two")).get(), 0);
-
-        // Nor with small-ish values
-        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(5)).get(), 0);
-        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(50)).get(), 0);
-
-        // But huge-ish values still match
-        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(500)).get(), 1);
-    }
-
-    public void testZero() throws IOException {
-        setupGapInMapping(0);
-        assertGapIsZero(client(), "test", "test");
-    }
-
-    /**
-     * Asserts that the pre-2.0 default has been applied or explicitly
-     * configured.
-     */
-    public static void assertGapIsZero(Client client, String indexName, String type) throws IOException {
-        testGap(client, indexName, type, 0);
-        /*
-         * Phrases match across different values using default slop with pre-2.0 default
-         * position_offset_gap.
-         */
-        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two")).get(), 1);
-    }
-
-    public void testLargerThanDefault() throws IOException {
-        setupGapInMapping(10000);
-        testGap(client(), "test", "test", 10000);
-    }
-
-    public void testSmallerThanDefault() throws IOException {
-        setupGapInMapping(2);
-        testGap(client(), "test", "test", 2);
-    }
-
-    public void testNegativeIsError() throws IOException {
-        try {
-            setupGapInMapping(-1);
-            fail("Expected an error");
-        } catch (MapperParsingException e) {
-            assertThat(ExceptionsHelper.detailedMessage(e), containsString("positions_offset_gap less than 0 aren't allowed"));
-        }
-    }
-
-    /**
-     * Tests that the default actually defaults to the position_offset_gap
-     * configured in the analyzer. This behavior is very old and a little
-     * strange but not worth breaking some thought.
-     */
-    public void testDefaultDefaultsToAnalyzer() throws IOException {
-        XContentBuilder settings = XContentFactory.jsonBuilder().startObject().startObject("analysis").startObject("analyzer")
-                .startObject("gappy");
-        settings.field("type", "custom");
-        settings.field("tokenizer", "standard");
-        settings.field("position_offset_gap", 2);
-        setupAnalyzer(settings, "gappy");
-        testGap(client(), "test", "test", 2);
-    }
-
-    /**
-     * Build an index named "test" with a field named "string" with the provided
-     * positionOffsetGap that uses the standard analyzer.
-     */
-    private void setupGapInMapping(int positionOffsetGap) throws IOException {
-        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("properties").startObject("string");
-        mapping.field("type", "string");
-        mapping.field("position_offset_gap", positionOffsetGap);
-        client().admin().indices().prepareCreate("test").addMapping("test", mapping).get();
-    }
-
-    /**
-     * Build an index named "test" with the provided settings and and a field
-     * named "string" that uses the specified analyzer and default
-     * position_offset_gap.
-     */
-    private void setupAnalyzer(XContentBuilder settings, String analyzer) throws IOException {
-        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("properties").startObject("string");
-        mapping.field("type", "string");
-        mapping.field("analyzer", analyzer);
-        client().admin().indices().prepareCreate("test").addMapping("test", mapping).setSettings(settings).get();
-    }
-
-    private static void testGap(Client client, String indexName, String type, int positionOffsetGap) throws IOException {
-        client.prepareIndex(indexName, type, "position_gap_test").setSource("string", ImmutableList.of("one", "two three")).setRefresh(true).get();
-
-        // Baseline - phrase query finds matches in the same field value
-        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "two three")).get(), 1);
-
-        if (positionOffsetGap > 0) {
-            // No match across gaps when slop < position gap
-            assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(positionOffsetGap - 1)).get(),
-                    0);
-        }
-
-        // Match across gaps when slop >= position gap
-        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(positionOffsetGap)).get(), 1);
-        assertHitCount(client.prepareSearch(indexName).setQuery(matchPhraseQuery("string", "one two").slop(positionOffsetGap + 1)).get(), 1);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/AndQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/AndQueryBuilderTest.java
deleted file mode 100644
index f33e994..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/AndQueryBuilderTest.java
+++ /dev/null
@@ -1,124 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.*;
-
-import static org.hamcrest.CoreMatchers.*;
-
-@SuppressWarnings("deprecation")
-public class AndQueryBuilderTest extends BaseQueryTestCase<AndQueryBuilder> {
-
-    /**
-     * @return a AndQueryBuilder with random limit between 0 and 20
-     */
-    @Override
-    protected AndQueryBuilder doCreateTestQueryBuilder() {
-        AndQueryBuilder query = new AndQueryBuilder();
-        int subQueries = randomIntBetween(1, 5);
-        for (int i = 0; i < subQueries; i++ ) {
-            query.add(RandomQueryBuilder.createQuery(random()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(AndQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.innerQueries().isEmpty()) {
-            assertThat(query, nullValue());
-        } else {
-            List<Query> clauses = new ArrayList<>();
-            for (QueryBuilder innerFilter : queryBuilder.innerQueries()) {
-                Query clause = innerFilter.toQuery(context);
-                if (clause != null) {
-                    clauses.add(clause);
-                }
-            }
-            if (clauses.isEmpty()) {
-                assertThat(query, nullValue());
-            } else {
-                assertThat(query, instanceOf(BooleanQuery.class));
-                BooleanQuery booleanQuery = (BooleanQuery) query;
-                assertThat(booleanQuery.clauses().size(), equalTo(clauses.size()));
-                Iterator<Query> queryIterator = clauses.iterator();
-                for (BooleanClause booleanClause : booleanQuery) {
-                    assertThat(booleanClause.getOccur(), equalTo(BooleanClause.Occur.MUST));
-                    assertThat(booleanClause.getQuery(), equalTo(queryIterator.next()));
-                }
-            }
-        }
-    }
-
-    /**
-     * test corner case where no inner queries exist
-     */
-    @Test
-    public void testNoInnerQueries() throws QueryShardException, IOException {
-        AndQueryBuilder andQuery = new AndQueryBuilder();
-        assertNull(andQuery.toQuery(createShardContext()));
-    }
-
-    @Test(expected=QueryParsingException.class)
-    public void testMissingFiltersSection() throws IOException {
-        parseQuery("{ \"and\" : {}", AndQueryBuilder.NAME);
-    }
-
-    @Test
-    public void testValidate() {
-        AndQueryBuilder andQuery = new AndQueryBuilder();
-        int iters = randomIntBetween(0, 5);
-        int totalExpectedErrors = 0;
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    andQuery.add(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    andQuery.add(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                andQuery.add(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        assertValidate(andQuery, totalExpectedErrors);
-    }
-
-    @Override
-    protected Map<String, AndQueryBuilder> getAlternateVersions() {
-        Map<String, AndQueryBuilder> alternateVersions = new HashMap<>();
-        QueryBuilder innerQuery = createTestQueryBuilder().innerQueries().get(0);
-        AndQueryBuilder expectedQuery = new AndQueryBuilder(innerQuery);
-        String contentString =  "{ \"and\" : [ " + innerQuery + "] }";
-        alternateVersions.put(contentString, expectedQuery);
-        return alternateVersions;
-    }
-
-    @Test(expected=QueryParsingException.class)
-    public void testParsingExceptionNonFiltersElementArray() throws IOException {
-        String queryString = "{ \"and\" : { \"whatever_filters\" : [ { \"match_all\" : {} } ] } }";
-        parseQuery(queryString, AndQueryBuilder.NAME);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java
deleted file mode 100644
index a237595..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java
+++ /dev/null
@@ -1,541 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.Version;
-import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.collect.Tuple;
-import org.elasticsearch.common.compress.CompressedXContent;
-import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.inject.Injector;
-import org.elasticsearch.common.inject.ModulesBuilder;
-import org.elasticsearch.common.inject.multibindings.Multibinder;
-import org.elasticsearch.common.inject.util.Providers;
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.NamedWriteableAwareStreamInput;
-import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.settings.SettingsModule;
-import org.elasticsearch.common.unit.Fuzziness;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.env.Environment;
-import org.elasticsearch.env.EnvironmentModule;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.index.IndexNameModule;
-import org.elasticsearch.index.analysis.AnalysisModule;
-import org.elasticsearch.index.cache.IndexCacheModule;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
-import org.elasticsearch.index.query.support.QueryParsers;
-import org.elasticsearch.index.settings.IndexSettingsModule;
-import org.elasticsearch.index.similarity.SimilarityModule;
-import org.elasticsearch.indices.IndicesModule;
-import org.elasticsearch.indices.analysis.IndicesAnalysisService;
-import org.elasticsearch.indices.breaker.CircuitBreakerService;
-import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
-import org.elasticsearch.script.ScriptModule;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.test.ESTestCase;
-import org.elasticsearch.test.TestSearchContext;
-import org.elasticsearch.test.VersionUtils;
-import org.elasticsearch.test.cluster.TestClusterService;
-import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.threadpool.ThreadPoolModule;
-import org.joda.time.DateTime;
-import org.joda.time.DateTimeZone;
-import org.junit.*;
-
-import java.io.IOException;
-import java.util.Collections;
-import java.util.Map;
-
-import static org.hamcrest.Matchers.*;
-
-public abstract class BaseQueryTestCase<QB extends AbstractQueryBuilder<QB>> extends ESTestCase {
-
-    protected static final String STRING_FIELD_NAME = "mapped_string";
-    protected static final String INT_FIELD_NAME = "mapped_int";
-    protected static final String DOUBLE_FIELD_NAME = "mapped_double";
-    protected static final String BOOLEAN_FIELD_NAME = "mapped_boolean";
-    protected static final String DATE_FIELD_NAME = "mapped_date";
-    protected static final String OBJECT_FIELD_NAME = "mapped_object";
-    protected static final String[] MAPPED_FIELD_NAMES = new String[] { STRING_FIELD_NAME, INT_FIELD_NAME,
-            DOUBLE_FIELD_NAME, BOOLEAN_FIELD_NAME, DATE_FIELD_NAME, OBJECT_FIELD_NAME };
-    protected static final String[] MAPPED_LEAF_FIELD_NAMES = new String[] { STRING_FIELD_NAME, INT_FIELD_NAME,
-            DOUBLE_FIELD_NAME, BOOLEAN_FIELD_NAME, DATE_FIELD_NAME };
-
-    private static Injector injector;
-    private static IndexQueryParserService queryParserService;
-
-    protected static IndexQueryParserService queryParserService() {
-        return queryParserService;
-    }
-
-    private static Index index;
-
-    protected static Index getIndex() {
-        return index;
-    }
-
-    private static String[] currentTypes;
-
-    protected static String[] getCurrentTypes() {
-        return currentTypes;
-    }
-
-    private static NamedWriteableRegistry namedWriteableRegistry;
-
-    /**
-     * Setup for the whole base test class.
-     * @throws IOException
-     */
-    @BeforeClass
-    public static void init() throws IOException {
-        Version version = VersionUtils.randomVersionBetween(random(), Version.V_1_0_0, Version.CURRENT);
-        Settings settings = Settings.settingsBuilder()
-                .put("name", BaseQueryTestCase.class.toString())
-                .put("path.home", createTempDir())
-                .build();
-        Settings indexSettings = Settings.settingsBuilder()
-                .put(IndexMetaData.SETTING_VERSION_CREATED, version).build();
-        index = new Index(randomAsciiOfLengthBetween(1, 10));
-        final TestClusterService clusterService = new TestClusterService();
-        clusterService.setState(new ClusterState.Builder(clusterService.state()).metaData(new MetaData.Builder().put(
-                new IndexMetaData.Builder(index.name()).settings(indexSettings).numberOfShards(1).numberOfReplicas(0))));
-        injector = new ModulesBuilder().add(
-                new EnvironmentModule(new Environment(settings)),
-                new SettingsModule(settings),
-                new ThreadPoolModule(new ThreadPool(settings)),
-                new IndicesModule(settings) {
-                    @Override
-                    public void configure() {
-                        // skip services
-                        bindQueryParsersExtension();
-                    }
-                },
-                new ScriptModule(settings),
-                new IndexSettingsModule(index, indexSettings),
-                new IndexCacheModule(indexSettings),
-                new AnalysisModule(indexSettings, new IndicesAnalysisService(indexSettings)),
-                new SimilarityModule(indexSettings),
-                new IndexNameModule(index),
-                new AbstractModule() {
-                    @Override
-                    protected void configure() {
-                        Multibinder.newSetBinder(binder(), ScoreFunctionParser.class);
-                        bind(ClusterService.class).toProvider(Providers.of(clusterService));
-                        bind(CircuitBreakerService.class).to(NoneCircuitBreakerService.class);
-                        bind(NamedWriteableRegistry.class).asEagerSingleton();
-                    }
-                }
-        ).createInjector();
-        queryParserService = injector.getInstance(IndexQueryParserService.class);
-        MapperService mapperService = queryParserService.mapperService;
-        //create some random type with some default field, those types will stick around for all of the subclasses
-        currentTypes = new String[randomIntBetween(0, 5)];
-        for (int i = 0; i < currentTypes.length; i++) {
-            String type = randomAsciiOfLengthBetween(1, 10);
-            mapperService.merge(type, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(type,
-                    STRING_FIELD_NAME, "type=string",
-                    INT_FIELD_NAME, "type=integer",
-                    DOUBLE_FIELD_NAME, "type=double",
-                    BOOLEAN_FIELD_NAME, "type=boolean",
-                    DATE_FIELD_NAME, "type=date",
-                    OBJECT_FIELD_NAME, "type=object"
-            ).string()), false, false);
-            // also add mappings for two inner field in the object field
-            mapperService.merge(type, new CompressedXContent("{\"properties\":{\""+OBJECT_FIELD_NAME+"\":{\"type\":\"object\","
-                    + "\"properties\":{\""+DATE_FIELD_NAME+"\":{\"type\":\"date\"},\""+INT_FIELD_NAME+"\":{\"type\":\"integer\"}}}}}"), false, false);
-            currentTypes[i] = type;
-        }
-        namedWriteableRegistry = injector.getInstance(NamedWriteableRegistry.class);
-    }
-
-    @AfterClass
-    public static void afterClass() throws Exception {
-        terminate(injector.getInstance(ThreadPool.class));
-        injector = null;
-        index = null;
-        queryParserService = null;
-        currentTypes = null;
-        namedWriteableRegistry = null;
-    }
-
-    @Before
-    public void beforeTest() {
-        //set some random types to be queried as part the search request, before each test
-        String[] types = getRandomTypes();
-        //some query (e.g. range query) have a different behaviour depending on whether the current search context is set or not
-        //which is why we randomly set the search context, which will internally also do QueryParseContext.setTypes(types)
-        if (randomBoolean()) {
-            QueryShardContext.setTypes(types);
-        } else {
-            TestSearchContext testSearchContext = new TestSearchContext();
-            testSearchContext.setTypes(types);
-            SearchContext.setCurrent(testSearchContext);
-        }
-    }
-
-    @After
-    public void afterTest() {
-        QueryShardContext.removeTypes();
-        SearchContext.removeCurrent();
-    }
-
-    protected final QB createTestQueryBuilder() {
-        QB query = doCreateTestQueryBuilder();
-        if (supportsBoostAndQueryName()) {
-            if (randomBoolean()) {
-                query.boost(2.0f / randomIntBetween(1, 20));
-            }
-            if (randomBoolean()) {
-                query.queryName(randomAsciiOfLengthBetween(1, 10));
-            }
-        }
-        return query;
-    }
-
-    /**
-     * Create the query that is being tested
-     */
-    protected abstract QB doCreateTestQueryBuilder();
-
-    /**
-     * Generic test that creates new query from the test query and checks both for equality
-     * and asserts equality on the two queries.
-     */
-    @Test
-    public void testFromXContent() throws IOException {
-        QB testQuery = createTestQueryBuilder();
-        assertParsedQuery(testQuery.toString(), testQuery);
-        for (Map.Entry<String, QB> alternateVersion : getAlternateVersions().entrySet()) {
-            assertParsedQuery(alternateVersion.getKey(), alternateVersion.getValue());
-        }
-    }
-
-    /**
-     * Returns alternate string representation of the query that need to be tested as they are never used as output
-     * of {@link QueryBuilder#toXContent(XContentBuilder, ToXContent.Params)}. By default there are no alternate versions.
-     */
-    protected Map<String, QB> getAlternateVersions() {
-        return Collections.emptyMap();
-    }
-
-    /**
-     * Parses the query provided as string argument and compares it with the expected result provided as argument as a {@link QueryBuilder}
-     */
-    protected void assertParsedQuery(String queryAsString, QueryBuilder<?> expectedQuery) throws IOException {
-        QueryBuilder<?> newQuery = parseQuery(queryAsString, expectedQuery.getName());
-        assertNotSame(newQuery, expectedQuery);
-        assertEquals(expectedQuery, newQuery);
-        assertEquals(expectedQuery.hashCode(), newQuery.hashCode());
-    }
-
-    protected QueryBuilder<?> parseQuery(String queryAsString, String queryId) throws IOException {
-        XContentParser parser = XContentFactory.xContent(queryAsString).createParser(queryAsString);
-        QueryParseContext context = createParseContext();
-        context.reset(parser);
-        assertQueryHeader(parser, queryId);
-        return context.queryParser(queryId).fromXContent(context);
-    }
-
-    /**
-     * Test creates the {@link Query} from the {@link QueryBuilder} under test and delegates the
-     * assertions being made on the result to the implementing subclass.
-     */
-    @Test
-    public void testToQuery() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-
-        QB firstQuery = createTestQueryBuilder();
-        Query firstLuceneQuery = firstQuery.toQuery(context);
-        assertLuceneQuery(firstQuery, firstLuceneQuery, context);
-
-        QB secondQuery = copyQuery(firstQuery);
-        //query _name never should affect the result of toQuery, we randomly set it to make sure
-        if (randomBoolean()) {
-            secondQuery.queryName(secondQuery.queryName() == null ? randomAsciiOfLengthBetween(1, 30) : secondQuery.queryName() + randomAsciiOfLengthBetween(1, 10));
-        }
-        Query secondLuceneQuery = secondQuery.toQuery(context);
-        assertLuceneQuery(secondQuery, secondLuceneQuery, context);
-        assertThat("two equivalent query builders lead to different lucene queries", secondLuceneQuery, equalTo(firstLuceneQuery));
-
-        //if the initial lucene query is null, changing its boost won't have any effect, we shouldn't test that
-        //few queries also don't support boost e.g. wrapper query and filter query
-        //otherwise makes sure that boost is taken into account in toQuery
-        if (firstLuceneQuery != null && supportsBoostAndQueryName()) {
-            secondQuery.boost(firstQuery.boost() + 1f + randomFloat());
-            Query thirdLuceneQuery = secondQuery.toQuery(context);
-            assertThat("modifying the boost doesn't affect the corresponding lucene query", firstLuceneQuery, not(equalTo(thirdLuceneQuery)));
-        }
-    }
-
-    /**
-     * Few queries allow you to set the boost and queryName but don't do anything with it. This method allows
-     * to disable boost and queryName related tests for those queries. Those queries are easy to identify: their parsers
-     * don't parse `boost` and `_name` as they don't apply to the specific query e.g. filter query or wrapper query
-     */
-    protected boolean supportsBoostAndQueryName() {
-        return true;
-    }
-
-    /**
-     * Checks the result of {@link QueryBuilder#toQuery(QueryShardContext)} given the original {@link QueryBuilder} and {@link QueryShardContext}.
-     * Verifies that named queries and boost are properly handled and delegates to {@link #doAssertLuceneQuery(AbstractQueryBuilder, Query, QueryShardContext)}
-     * for query specific checks.
-     */
-    protected final void assertLuceneQuery(QB queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.queryName() != null) {
-            Query namedQuery = context.copyNamedQueries().get(queryBuilder.queryName());
-            assertThat(namedQuery, equalTo(query));
-        }
-        if (query != null) {
-            assertThat(query.getBoost(), equalTo(queryBuilder.boost()));
-        }
-        doAssertLuceneQuery(queryBuilder, query, context);
-    }
-
-    /**
-     * Checks the result of {@link QueryBuilder#toQuery(QueryShardContext)} given the original {@link QueryBuilder} and {@link QueryShardContext}.
-     * Contains the query specific checks to be implemented by subclasses.
-     */
-    protected abstract void doAssertLuceneQuery(QB queryBuilder, Query query, QueryShardContext context) throws IOException;
-
-    /**
-     * Test serialization and deserialization of the test query.
-     */
-    @Test
-    public void testSerialization() throws IOException {
-        QB testQuery = createTestQueryBuilder();
-        try (BytesStreamOutput output = new BytesStreamOutput()) {
-            testQuery.writeTo(output);
-            try (StreamInput in = new NamedWriteableAwareStreamInput(StreamInput.wrap(output.bytes()), namedWriteableRegistry)) {
-                QueryBuilder<?> prototype = queryParser(testQuery.getName()).getBuilderPrototype();
-                QueryBuilder deserializedQuery = prototype.readFrom(in);
-                assertEquals(deserializedQuery, testQuery);
-                assertEquals(deserializedQuery.hashCode(), testQuery.hashCode());
-                assertNotSame(deserializedQuery, testQuery);
-            }
-        }
-    }
-
-    @Test
-    public void testEqualsAndHashcode() throws IOException {
-        QB firstQuery = createTestQueryBuilder();
-        assertFalse("query is equal to null", firstQuery.equals(null));
-        assertFalse("query is equal to incompatible type", firstQuery.equals(""));
-        assertTrue("query is not equal to self", firstQuery.equals(firstQuery));
-        assertThat("same query's hashcode returns different values if called multiple times", firstQuery.hashCode(), equalTo(firstQuery.hashCode()));
-
-        QB secondQuery = copyQuery(firstQuery);
-        assertTrue("query is not equal to self", secondQuery.equals(secondQuery));
-        assertTrue("query is not equal to its copy", firstQuery.equals(secondQuery));
-        assertTrue("equals is not symmetric", secondQuery.equals(firstQuery));
-        assertThat("query copy's hashcode is different from original hashcode", secondQuery.hashCode(), equalTo(firstQuery.hashCode()));
-
-        QB thirdQuery = copyQuery(secondQuery);
-        assertTrue("query is not equal to self", thirdQuery.equals(thirdQuery));
-        assertTrue("query is not equal to its copy", secondQuery.equals(thirdQuery));
-        assertThat("query copy's hashcode is different from original hashcode", secondQuery.hashCode(), equalTo(thirdQuery.hashCode()));
-        assertTrue("equals is not transitive", firstQuery.equals(thirdQuery));
-        assertThat("query copy's hashcode is different from original hashcode", firstQuery.hashCode(), equalTo(thirdQuery.hashCode()));
-        assertTrue("equals is not symmetric", thirdQuery.equals(secondQuery));
-        assertTrue("equals is not symmetric", thirdQuery.equals(firstQuery));
-
-        if (randomBoolean()) {
-            secondQuery.queryName(secondQuery.queryName() == null ? randomAsciiOfLengthBetween(1, 30) : secondQuery.queryName() + randomAsciiOfLengthBetween(1, 10));
-        } else {
-            secondQuery.boost(firstQuery.boost() + 1f + randomFloat());
-        }
-        assertThat("different queries should not be equal", secondQuery, not(equalTo(firstQuery)));
-        assertThat("different queries should have different hashcode", secondQuery.hashCode(), not(equalTo(firstQuery.hashCode())));
-    }
-
-    private QueryParser<?> queryParser(String queryId) {
-        return queryParserService.indicesQueriesRegistry().queryParsers().get(queryId);
-    }
-
-    //we use the streaming infra to create a copy of the query provided as argument
-    private QB copyQuery(QB query) throws IOException {
-        try (BytesStreamOutput output = new BytesStreamOutput()) {
-            query.writeTo(output);
-            try (StreamInput in = new NamedWriteableAwareStreamInput(StreamInput.wrap(output.bytes()), namedWriteableRegistry)) {
-                QueryBuilder<?> prototype = queryParser(query.getName()).getBuilderPrototype();
-                @SuppressWarnings("unchecked")
-                QB secondQuery = (QB)prototype.readFrom(in);
-                return secondQuery;
-            }
-        }
-    }
-
-    /**
-     * @return a new {@link QueryShardContext} based on the base test index and queryParserService
-     */
-    protected static QueryShardContext createShardContext() {
-        QueryShardContext queryCreationContext = new QueryShardContext(index, queryParserService);
-        queryCreationContext.parseFieldMatcher(ParseFieldMatcher.EMPTY);
-        return queryCreationContext;
-    }
-
-    /**
-     * @return a new {@link QueryParseContext} based on the base test index and queryParserService
-     */
-    protected static QueryParseContext createParseContext() {
-        return createShardContext().parseContext();
-    }
-
-    private static void assertQueryHeader(XContentParser parser, String expectedParserName) throws IOException {
-        assertThat(parser.nextToken(), is(XContentParser.Token.START_OBJECT));
-        assertThat(parser.nextToken(), is(XContentParser.Token.FIELD_NAME));
-        assertThat(parser.currentName(), is(expectedParserName));
-        assertThat(parser.nextToken(), either(is(XContentParser.Token.START_OBJECT)).or(is(XContentParser.Token.START_ARRAY)));
-    }
-
-    protected static void assertValidate(QueryBuilder queryBuilder, int totalExpectedErrors) {
-        QueryValidationException queryValidationException = queryBuilder.validate();
-        if (totalExpectedErrors > 0) {
-            assertThat(queryValidationException, notNullValue());
-            assertThat(queryValidationException.validationErrors().size(), equalTo(totalExpectedErrors));
-        } else {
-            assertThat(queryValidationException, nullValue());
-        }
-    }
-
-    /**
-     * create a random value for either {@link BaseQueryTestCase#BOOLEAN_FIELD_NAME}, {@link BaseQueryTestCase#INT_FIELD_NAME},
-     * {@link BaseQueryTestCase#DOUBLE_FIELD_NAME}, {@link BaseQueryTestCase#STRING_FIELD_NAME} or
-     * {@link BaseQueryTestCase#DATE_FIELD_NAME}, or a String value by default
-     */
-    protected static Object getRandomValueForFieldName(String fieldName) {
-        Object value;
-        switch (fieldName) {
-            case STRING_FIELD_NAME:
-                value = rarely() ? randomUnicodeOfLength(10) : randomAsciiOfLengthBetween(1, 10); // unicode in 10% cases
-                break;
-            case INT_FIELD_NAME:
-                value = randomIntBetween(0, 10);
-                break;
-            case DOUBLE_FIELD_NAME:
-                value = randomDouble() * 10;
-                break;
-            case BOOLEAN_FIELD_NAME:
-                value = randomBoolean();
-                break;
-            case DATE_FIELD_NAME:
-                value = new DateTime(System.currentTimeMillis(), DateTimeZone.UTC).toString();
-                break;
-            default:
-                value = randomAsciiOfLengthBetween(1, 10);
-        }
-        return value;
-    }
-
-    /**
-     * Helper method to return a mapped or a random field
-     */
-    protected String getRandomFieldName() {
-        // if no type is set then return a random field name
-        if (currentTypes == null || currentTypes.length == 0 || randomBoolean()) {
-            return randomAsciiOfLengthBetween(1, 10);
-        }
-        return randomFrom(MAPPED_LEAF_FIELD_NAMES);
-    }
-
-    /**
-     * Helper method to return a random field (mapped or unmapped) and a value
-     */
-    protected Tuple<String, Object> getRandomFieldNameAndValue() {
-        String fieldName = getRandomFieldName();
-        return new Tuple<>(fieldName, getRandomValueForFieldName(fieldName));
-    }
-
-    /**
-     * Helper method to return a random rewrite method
-     */
-    protected static String getRandomRewriteMethod() {
-        String rewrite;
-        if (randomBoolean()) {
-            rewrite = randomFrom(QueryParsers.CONSTANT_SCORE,
-                    QueryParsers.SCORING_BOOLEAN,
-                    QueryParsers.CONSTANT_SCORE_BOOLEAN).getPreferredName();
-        } else {
-            rewrite = randomFrom(QueryParsers.TOP_TERMS,
-                    QueryParsers.TOP_TERMS_BOOST,
-                    QueryParsers.TOP_TERMS_BLENDED_FREQS).getPreferredName() + "1";
-        }
-        return rewrite;
-    }
-
-    protected String[] getRandomTypes() {
-        String[] types;
-        if (currentTypes.length > 0 && randomBoolean()) {
-            int numberOfQueryTypes = randomIntBetween(1, currentTypes.length);
-            types = new String[numberOfQueryTypes];
-            for (int i = 0; i < numberOfQueryTypes; i++) {
-                types[i] = randomFrom(currentTypes);
-            }
-        } else {
-            if (randomBoolean()) {
-                types = new String[] { MetaData.ALL };
-            } else {
-                types = new String[0];
-            }
-        }
-        return types;
-    }
-
-    protected String getRandomType() {
-        return (currentTypes.length == 0) ? MetaData.ALL : randomFrom(currentTypes);
-    }
-
-    protected static Fuzziness randomFuzziness(String fieldName) {
-        Fuzziness fuzziness = Fuzziness.AUTO;
-        switch (fieldName) {
-            case INT_FIELD_NAME:
-                fuzziness = Fuzziness.build(randomIntBetween(3, 100));
-                break;
-            case DOUBLE_FIELD_NAME:
-                fuzziness = Fuzziness.build(1 + randomFloat() * 10);
-                break;
-            case DATE_FIELD_NAME:
-                fuzziness = Fuzziness.build(randomTimeValue());
-                break;
-        }
-        if (randomBoolean()) {
-            fuzziness = Fuzziness.fromEdits(randomIntBetween(0, 2));
-        }
-        return fuzziness;
-    }
-
-    protected static boolean isNumericFieldName(String fieldName) {
-        return INT_FIELD_NAME.equals(fieldName) || DOUBLE_FIELD_NAME.equals(fieldName);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/BaseTermQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/BaseTermQueryTestCase.java
deleted file mode 100644
index c83a3f5..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/BaseTermQueryTestCase.java
+++ /dev/null
@@ -1,110 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.junit.Test;
-
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.Matchers.is;
-
-public abstract class BaseTermQueryTestCase<QB extends BaseTermQueryBuilder<QB>> extends BaseQueryTestCase<QB> {
-
-    @Override
-    protected final QB doCreateTestQueryBuilder() {
-        String fieldName = null;
-        Object value;
-        switch (randomIntBetween(0, 3)) {
-            case 0:
-                if (randomBoolean()) {
-                    fieldName = BOOLEAN_FIELD_NAME;
-                }
-                value = randomBoolean();
-                break;
-            case 1:
-                if (randomBoolean()) {
-                    fieldName = STRING_FIELD_NAME;
-                }
-                if (frequently()) {
-                    value = randomAsciiOfLengthBetween(1, 10);
-                } else {
-                    // generate unicode string in 10% of cases
-                    value = randomUnicodeOfLength(10);
-                }
-                break;
-            case 2:
-                if (randomBoolean()) {
-                    fieldName = INT_FIELD_NAME;
-                }
-                value = randomInt(10000);
-                break;
-            case 3:
-                if (randomBoolean()) {
-                    fieldName = DOUBLE_FIELD_NAME;
-                }
-                value = randomDouble();
-                break;
-            default:
-                throw new UnsupportedOperationException();
-        }
-
-        if (fieldName == null) {
-            fieldName = randomAsciiOfLengthBetween(1, 10);
-        }
-        return createQueryBuilder(fieldName, value);
-    }
-
-    protected abstract QB createQueryBuilder(String fieldName, Object value);
-
-    @Test
-    public void testValidate() throws QueryShardException {
-        QB queryBuilder = createQueryBuilder(randomAsciiOfLengthBetween(1, 30), randomAsciiOfLengthBetween(1, 30));
-        assertNull(queryBuilder.validate());
-
-        queryBuilder = createQueryBuilder(null, randomAsciiOfLengthBetween(1, 30));
-        assertNotNull(queryBuilder.validate());
-        assertThat(queryBuilder.validate().validationErrors().size(), is(1));
-
-        queryBuilder = createQueryBuilder("", randomAsciiOfLengthBetween(1, 30));
-        assertNotNull(queryBuilder.validate());
-        assertThat(queryBuilder.validate().validationErrors().size(), is(1));
-
-        queryBuilder = createQueryBuilder("", null);
-        assertNotNull(queryBuilder.validate());
-        assertThat(queryBuilder.validate().validationErrors().size(), is(2));
-    }
-
-    @Override
-    protected Map<String, QB> getAlternateVersions() {
-        HashMap<String, QB> alternateVersions = new HashMap<>();
-        QB tempQuery = createTestQueryBuilder();
-        QB testQuery = createQueryBuilder(tempQuery.fieldName(), tempQuery.value());
-        boolean isString = testQuery.value() instanceof String;
-        String value = (isString ? "\"" : "") + testQuery.value() + (isString ? "\"" : "");
-        String contentString = "{\n" +
-                "    \"" + testQuery.getName() + "\" : {\n" +
-                "        \"" + testQuery.fieldName() + "\" : " + value + "\n" +
-                "    }\n" +
-                "}";
-        alternateVersions.put(contentString, testQuery);
-        return alternateVersions;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/BoolQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/BoolQueryBuilderTest.java
deleted file mode 100644
index a235ba1..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/BoolQueryBuilderTest.java
+++ /dev/null
@@ -1,206 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.*;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class BoolQueryBuilderTest extends BaseQueryTestCase<BoolQueryBuilder> {
-
-    @Override
-    protected BoolQueryBuilder doCreateTestQueryBuilder() {
-        BoolQueryBuilder query = new BoolQueryBuilder();
-        if (randomBoolean()) {
-            query.adjustPureNegative(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.disableCoord(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.minimumNumberShouldMatch(randomIntBetween(1, 10));
-        }
-        int mustClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < mustClauses; i++) {
-            query.must(RandomQueryBuilder.createQuery(random()));
-        }
-        int mustNotClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < mustNotClauses; i++) {
-            query.mustNot(RandomQueryBuilder.createQuery(random()));
-        }
-        int shouldClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < shouldClauses; i++) {
-            query.should(RandomQueryBuilder.createQuery(random()));
-        }
-        int filterClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < filterClauses; i++) {
-            query.filter(RandomQueryBuilder.createQuery(random()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(BoolQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (!queryBuilder.hasClauses()) {
-            assertThat(query, instanceOf(MatchAllDocsQuery.class));
-        } else {
-            List<BooleanClause> clauses = new ArrayList<>();
-            clauses.addAll(getBooleanClauses(queryBuilder.must(), BooleanClause.Occur.MUST, context));
-            clauses.addAll(getBooleanClauses(queryBuilder.mustNot(), BooleanClause.Occur.MUST_NOT, context));
-            clauses.addAll(getBooleanClauses(queryBuilder.should(), BooleanClause.Occur.SHOULD, context));
-            clauses.addAll(getBooleanClauses(queryBuilder.filter(), BooleanClause.Occur.FILTER, context));
-
-            if (clauses.isEmpty()) {
-                assertThat(query, instanceOf(MatchAllDocsQuery.class));
-            } else {
-                assertThat(query, instanceOf(BooleanQuery.class));
-                BooleanQuery booleanQuery = (BooleanQuery) query;
-                if (queryBuilder.adjustPureNegative()) {
-                    boolean isNegative = true;
-                    for (BooleanClause clause : clauses) {
-                        if (clause.isProhibited() == false) {
-                            isNegative = false;
-                            break;
-                        }
-                    }
-                    if (isNegative) {
-                        clauses.add(new BooleanClause(new MatchAllDocsQuery(), BooleanClause.Occur.MUST));
-                    }
-                }
-                assertThat(booleanQuery.clauses().size(), equalTo(clauses.size()));
-                Iterator<BooleanClause> clauseIterator = clauses.iterator();
-                for (BooleanClause booleanClause : booleanQuery.getClauses()) {
-                    assertThat(booleanClause, equalTo(clauseIterator.next()));
-                }
-            }
-        }
-    }
-
-    private static List<BooleanClause> getBooleanClauses(List<QueryBuilder> queryBuilders, BooleanClause.Occur occur, QueryShardContext context) throws IOException {
-        List<BooleanClause> clauses = new ArrayList<>();
-        for (QueryBuilder query : queryBuilders) {
-            Query innerQuery = query.toQuery(context);
-            if (innerQuery != null) {
-                clauses.add(new BooleanClause(innerQuery, occur));
-            }
-        }
-        return clauses;
-    }
-
-    @Override
-    protected Map<String, BoolQueryBuilder> getAlternateVersions() {
-        Map<String, BoolQueryBuilder> alternateVersions = new HashMap<>();
-        BoolQueryBuilder tempQueryBuilder = createTestQueryBuilder();
-        BoolQueryBuilder expectedQuery = new BoolQueryBuilder();
-        String contentString = "{\n" +
-                "    \"bool\" : {\n";
-        if (tempQueryBuilder.must().size() > 0) {
-            QueryBuilder must = tempQueryBuilder.must().get(0);
-            contentString += "must: " + must.toString() + ",";
-            expectedQuery.must(must);
-        }
-        if (tempQueryBuilder.mustNot().size() > 0) {
-            QueryBuilder mustNot = tempQueryBuilder.mustNot().get(0);
-            contentString += (randomBoolean() ? "must_not: " : "mustNot: ") + mustNot.toString() + ",";
-            expectedQuery.mustNot(mustNot);
-        }
-        if (tempQueryBuilder.should().size() > 0) {
-            QueryBuilder should = tempQueryBuilder.should().get(0);
-            contentString += "should: " + should.toString() + ",";
-            expectedQuery.should(should);
-        }
-        if (tempQueryBuilder.filter().size() > 0) {
-            QueryBuilder filter = tempQueryBuilder.filter().get(0);
-            contentString += "filter: " + filter.toString() + ",";
-            expectedQuery.filter(filter);
-        }
-        contentString = contentString.substring(0, contentString.length() - 1);
-        contentString += "    }    \n" + "}";
-        alternateVersions.put(contentString, expectedQuery);
-        return alternateVersions;
-    }
-
-    @Test
-    public void testValidate() {
-        BoolQueryBuilder booleanQuery = new BoolQueryBuilder();
-        int iters = randomIntBetween(0, 3);
-        int totalExpectedErrors = 0;
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.must(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.must(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.must(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        iters = randomIntBetween(0, 3);
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.should(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.should(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.should(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        iters = randomIntBetween(0, 3);
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.mustNot(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.mustNot(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.mustNot(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        iters = randomIntBetween(0, 3);
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.filter(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.filter(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.filter(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        assertValidate(booleanQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/BoostingQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/BoostingQueryBuilderTest.java
deleted file mode 100644
index 2b7ca52..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/BoostingQueryBuilderTest.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.queries.BoostingQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-import static org.hamcrest.CoreMatchers.nullValue;
-
-public class BoostingQueryBuilderTest extends BaseQueryTestCase<BoostingQueryBuilder> {
-
-    @Override
-    protected BoostingQueryBuilder doCreateTestQueryBuilder() {
-        BoostingQueryBuilder query = new BoostingQueryBuilder(RandomQueryBuilder.createQuery(random()), RandomQueryBuilder.createQuery(random()));
-        query.negativeBoost(2.0f / randomIntBetween(1, 20));
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(BoostingQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query positive = queryBuilder.positiveQuery().toQuery(context);
-        Query negative = queryBuilder.negativeQuery().toQuery(context);
-        if (positive == null || negative == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(BoostingQuery.class));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        QueryBuilder positive = null;
-        QueryBuilder negative = null;
-        if (frequently()) {
-            if (randomBoolean()) {
-                negative = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            negative = RandomQueryBuilder.createQuery(random());
-        }
-        if (frequently()) {
-            if (randomBoolean()) {
-                positive = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            positive = RandomQueryBuilder.createQuery(random());
-        }
-        BoostingQueryBuilder boostingQuery = new BoostingQueryBuilder(positive, negative);
-        if (frequently()) {
-            boostingQuery.negativeBoost(0.5f);
-        } else {
-            boostingQuery.negativeBoost(-0.5f);
-            totalExpectedErrors++;
-        }
-        assertValidate(boostingQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/CommonTermsQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/CommonTermsQueryBuilderTest.java
deleted file mode 100644
index ab5cb07..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/CommonTermsQueryBuilderTest.java
+++ /dev/null
@@ -1,105 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.queries.ExtendedCommonTermsQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class CommonTermsQueryBuilderTest extends BaseQueryTestCase<CommonTermsQueryBuilder> {
-
-    @Override
-    protected CommonTermsQueryBuilder doCreateTestQueryBuilder() {
-        CommonTermsQueryBuilder query;
-
-        // mapped or unmapped field
-        String text = randomAsciiOfLengthBetween(1, 10);
-        if (randomBoolean()) {
-            query = new CommonTermsQueryBuilder(STRING_FIELD_NAME, text);
-        } else {
-            query = new CommonTermsQueryBuilder(randomAsciiOfLengthBetween(1, 10), text);
-        }
-
-        if (randomBoolean()) {
-            query.cutoffFrequency((float) randomIntBetween(1, 10));
-        }
-
-        if (randomBoolean()) {
-            query.lowFreqOperator(randomFrom(Operator.values()));
-        }
-
-        // number of low frequency terms that must match
-        if (randomBoolean()) {
-            query.lowFreqMinimumShouldMatch("" + randomIntBetween(1, 5));
-        }
-
-        if (randomBoolean()) {
-            query.highFreqOperator(randomFrom(Operator.values()));
-        }
-
-        // number of high frequency terms that must match
-        if (randomBoolean()) {
-            query.highFreqMinimumShouldMatch("" + randomIntBetween(1, 5));
-        }
-
-        if (randomBoolean()) {
-            query.analyzer(randomFrom("simple", "keyword", "whitespace"));
-        }
-
-        if (randomBoolean()) {
-            query.disableCoord(randomBoolean());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(CommonTermsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(ExtendedCommonTermsQuery.class));
-        ExtendedCommonTermsQuery extendedCommonTermsQuery = (ExtendedCommonTermsQuery) query;
-        assertThat(extendedCommonTermsQuery.getHighFreqMinimumNumberShouldMatchSpec(), equalTo(queryBuilder.highFreqMinimumShouldMatch()));
-        assertThat(extendedCommonTermsQuery.getLowFreqMinimumNumberShouldMatchSpec(), equalTo(queryBuilder.lowFreqMinimumShouldMatch()));
-    }
-
-    @Test
-    public void testValidate() {
-        CommonTermsQueryBuilder commonTermsQueryBuilder = new CommonTermsQueryBuilder("", "text");
-        assertThat(commonTermsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        commonTermsQueryBuilder = new CommonTermsQueryBuilder("field", null);
-        assertThat(commonTermsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        commonTermsQueryBuilder = new CommonTermsQueryBuilder("field", "text");
-        assertNull(commonTermsQueryBuilder.validate());
-    }
-
-    @Test
-    public void testNoTermsFromQueryString() throws IOException {
-        CommonTermsQueryBuilder builder = new CommonTermsQueryBuilder(STRING_FIELD_NAME, "");
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-        assertNull(builder.toQuery(context));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ConstantScoreQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/ConstantScoreQueryBuilderTest.java
deleted file mode 100644
index 1746fee..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/ConstantScoreQueryBuilderTest.java
+++ /dev/null
@@ -1,76 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.*;
-
-public class ConstantScoreQueryBuilderTest extends BaseQueryTestCase<ConstantScoreQueryBuilder> {
-
-    /**
-     * @return a {@link ConstantScoreQueryBuilder} with random boost between 0.1f and 2.0f
-     */
-    @Override
-    protected ConstantScoreQueryBuilder doCreateTestQueryBuilder() {
-        return new ConstantScoreQueryBuilder(RandomQueryBuilder.createQuery(random()));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(ConstantScoreQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query innerQuery = queryBuilder.innerQuery().toQuery(context);
-        if (innerQuery == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(ConstantScoreQuery.class));
-            ConstantScoreQuery constantScoreQuery = (ConstantScoreQuery) query;
-            assertThat(constantScoreQuery.getQuery(), equalTo(innerQuery));
-        }
-    }
-
-    /**
-     * test that missing "filter" element causes {@link QueryParsingException}
-     */
-    @Test(expected=QueryParsingException.class)
-    public void testFilterElement() throws IOException {
-        String queryString = "{ \"" + ConstantScoreQueryBuilder.NAME + "\" : {}";
-        parseQuery(queryString, ConstantScoreQueryBuilder.NAME);
-    }
-
-    @Test
-    public void testValidate() {
-        QueryBuilder innerQuery = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        ConstantScoreQueryBuilder constantScoreQuery = new ConstantScoreQueryBuilder(innerQuery);
-        assertValidate(constantScoreQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/DisMaxQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/DisMaxQueryBuilderTest.java
deleted file mode 100644
index 60e9241..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/DisMaxQueryBuilderTest.java
+++ /dev/null
@@ -1,128 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.DisjunctionMaxQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.Map;
-
-import static org.hamcrest.CoreMatchers.*;
-
-public class DisMaxQueryBuilderTest extends BaseQueryTestCase<DisMaxQueryBuilder> {
-
-    /**
-     * @return a {@link DisMaxQueryBuilder} with random inner queries
-     */
-    @Override
-    protected DisMaxQueryBuilder doCreateTestQueryBuilder() {
-        DisMaxQueryBuilder dismax = new DisMaxQueryBuilder();
-        int clauses = randomIntBetween(1, 5);
-        for (int i = 0; i < clauses; i++) {
-            dismax.add(RandomQueryBuilder.createQuery(random()));
-        }
-        if (randomBoolean()) {
-            dismax.tieBreaker(2.0f / randomIntBetween(1, 20));
-        }
-        return dismax;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(DisMaxQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Collection<Query> queries = AbstractQueryBuilder.toQueries(queryBuilder.innerQueries(), context);
-        if (queries.isEmpty()) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(DisjunctionMaxQuery.class));
-            DisjunctionMaxQuery disjunctionMaxQuery = (DisjunctionMaxQuery) query;
-            assertThat(disjunctionMaxQuery.getTieBreakerMultiplier(), equalTo(queryBuilder.tieBreaker()));
-            assertThat(disjunctionMaxQuery.getDisjuncts().size(), equalTo(queries.size()));
-            Iterator<Query> queryIterator = queries.iterator();
-            for (int i = 0; i < disjunctionMaxQuery.getDisjuncts().size(); i++) {
-                assertThat(disjunctionMaxQuery.getDisjuncts().get(i), equalTo(queryIterator.next()));
-            }
-        }
-    }
-
-    @Override
-    protected Map<String, DisMaxQueryBuilder> getAlternateVersions() {
-        Map<String, DisMaxQueryBuilder> alternateVersions = new HashMap<>();
-        QueryBuilder innerQuery = createTestQueryBuilder().innerQueries().get(0);
-        DisMaxQueryBuilder expectedQuery = new DisMaxQueryBuilder();
-        expectedQuery.add(innerQuery);
-        String contentString = "{\n" +
-                "    \"dis_max\" : {\n" +
-                "        \"queries\" : " + innerQuery.toString() +
-                "    }\n" +
-                "}";
-        alternateVersions.put(contentString, expectedQuery);
-        return alternateVersions;
-    }
-
-    /**
-     * test `null`return value for missing inner queries
-     * @throws IOException
-     * @throws QueryParsingException
-     */
-    @Test
-    public void testNoInnerQueries() throws QueryParsingException, IOException {
-        DisMaxQueryBuilder disMaxBuilder = new DisMaxQueryBuilder();
-        assertNull(disMaxBuilder.toQuery(createShardContext()));
-        assertNull(disMaxBuilder.validate());
-    }
-
-    /**
-     * Test inner query parsing to null. Current DSL allows inner filter element to parse to <tt>null</tt>.
-     * Those should be ignored upstream. To test this, we use inner {@link ConstantScoreQueryBuilder}
-     * with empty inner filter.
-     */
-    @Test
-    public void testInnerQueryReturnsNull() throws IOException {
-        String queryString = "{ \"" + ConstantScoreQueryBuilder.NAME + "\" : { \"filter\" : { } }";
-        QueryBuilder<?> innerQueryBuilder = parseQuery(queryString, ConstantScoreQueryBuilder.NAME);
-        DisMaxQueryBuilder disMaxBuilder = new DisMaxQueryBuilder().add(innerQueryBuilder);
-        assertNull(disMaxBuilder.toQuery(createShardContext()));
-    }
-
-    @Test
-    public void testValidate() {
-        DisMaxQueryBuilder disMaxQuery = new DisMaxQueryBuilder();
-        int iters = randomIntBetween(0, 5);
-        int totalExpectedErrors = 0;
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    disMaxQuery.add(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    disMaxQuery.add(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                disMaxQuery.add(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        assertValidate(disMaxQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ExistsQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/ExistsQueryBuilderTest.java
deleted file mode 100644
index 35400e0..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/ExistsQueryBuilderTest.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
-
-import java.io.IOException;
-import java.util.Collection;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class ExistsQueryBuilderTest extends BaseQueryTestCase<ExistsQueryBuilder> {
-
-    @Override
-    protected ExistsQueryBuilder doCreateTestQueryBuilder() {
-        String fieldPattern;
-        if (randomBoolean()) {
-            fieldPattern = randomFrom(MAPPED_FIELD_NAMES);
-        } else {
-            fieldPattern = randomAsciiOfLengthBetween(1, 10);
-        }
-        // also sometimes test wildcard patterns
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                fieldPattern = fieldPattern + "*";
-            } else {
-                fieldPattern = MetaData.ALL;
-            }
-        }
-        return new ExistsQueryBuilder(fieldPattern);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(ExistsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        String fieldPattern = queryBuilder.fieldName();
-        ObjectMapper objectMapper = context.getObjectMapper(fieldPattern);
-        if (objectMapper != null) {
-            // automatic make the object mapper pattern
-            fieldPattern = fieldPattern + ".*";
-        }
-        Collection<String> fields = context.simpleMatchToIndexNames(fieldPattern);
-        if (getCurrentTypes().length == 0 || fields.size() == 0) {
-            assertThat(query, instanceOf(BooleanQuery.class));
-            BooleanQuery booleanQuery = (BooleanQuery) query;
-            assertThat(booleanQuery.clauses().size(), equalTo(0));
-        } else {
-            assertThat(query, instanceOf(ConstantScoreQuery.class));
-            ConstantScoreQuery constantScoreQuery = (ConstantScoreQuery) query;
-            assertThat(constantScoreQuery.getQuery(), instanceOf(BooleanQuery.class));
-            BooleanQuery booleanQuery = (BooleanQuery) constantScoreQuery.getQuery();
-            assertThat(booleanQuery.clauses().size(), equalTo(fields.size()));
-            for (int i = 0; i < fields.size(); i++) {
-                BooleanClause booleanClause = booleanQuery.clauses().get(i);
-                assertThat(booleanClause.getOccur(), equalTo(BooleanClause.Occur.SHOULD));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/FQueryFilterBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/FQueryFilterBuilderTest.java
deleted file mode 100644
index 0569458..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/FQueryFilterBuilderTest.java
+++ /dev/null
@@ -1,91 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.*;
-
-@SuppressWarnings("deprecation")
-public class FQueryFilterBuilderTest extends BaseQueryTestCase<FQueryFilterBuilder> {
-
-    /**
-     * @return a FQueryFilterBuilder with random inner query
-     */
-    @Override
-    protected FQueryFilterBuilder doCreateTestQueryBuilder() {
-        QueryBuilder innerQuery = RandomQueryBuilder.createQuery(random());
-        return new FQueryFilterBuilder(innerQuery);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(FQueryFilterBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query innerQuery = queryBuilder.innerQuery().toQuery(context);
-        if (innerQuery == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(ConstantScoreQuery.class));
-            ConstantScoreQuery constantScoreQuery = (ConstantScoreQuery) query;
-            assertThat(constantScoreQuery.getQuery(), equalTo(innerQuery));
-        }
-    }
-
-    /**
-     * test corner case where no inner query exist
-     */
-    @Test
-    public void testNoInnerQuery() throws QueryParsingException, IOException {
-        FQueryFilterBuilder queryFilterQuery = new FQueryFilterBuilder(EmptyQueryBuilder.PROTOTYPE);
-        assertNull(queryFilterQuery.toQuery(createShardContext()));
-    }
-
-    /**
-     * test wrapping an inner filter that returns null also returns <tt>null</null> to pass on upwards
-     */
-    @Test
-    public void testInnerQueryReturnsNull() throws IOException {
-        // create inner filter
-        String queryString = "{ \"constant_score\" : { \"filter\" : {} }";
-        QueryBuilder innerQuery = parseQuery(queryString, ConstantScoreQueryBuilder.NAME);
-        // check that when wrapping this filter, toQuery() returns null
-        FQueryFilterBuilder queryFilterQuery = new FQueryFilterBuilder(innerQuery);
-        assertNull(queryFilterQuery.toQuery(createShardContext()));
-    }
-
-    @Test
-    public void testValidate() {
-        QueryBuilder innerQuery = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        FQueryFilterBuilder fQueryFilter = new FQueryFilterBuilder(innerQuery);
-        assertValidate(fQueryFilter, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilderTest.java
deleted file mode 100644
index e2c4f85..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilderTest.java
+++ /dev/null
@@ -1,83 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class FieldMaskingSpanQueryBuilderTest extends BaseQueryTestCase<FieldMaskingSpanQueryBuilder> {
-
-    @Override
-    protected FieldMaskingSpanQueryBuilder doCreateTestQueryBuilder() {
-        String fieldName;
-        if (randomBoolean()) {
-            fieldName = randomFrom(MAPPED_FIELD_NAMES);
-        } else {
-            fieldName = randomAsciiOfLengthBetween(1, 10);
-        }
-        SpanTermQueryBuilder innerQuery = new SpanTermQueryBuilderTest().createTestQueryBuilder();
-        return new FieldMaskingSpanQueryBuilder(innerQuery, fieldName);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(FieldMaskingSpanQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        String fieldInQuery = queryBuilder.fieldName();
-        MappedFieldType fieldType = context.fieldMapper(fieldInQuery);
-        if (fieldType != null) {
-            fieldInQuery = fieldType.names().indexName();
-        }
-        assertThat(query, instanceOf(FieldMaskingSpanQuery.class));
-        FieldMaskingSpanQuery fieldMaskingSpanQuery = (FieldMaskingSpanQuery) query;
-        assertThat(fieldMaskingSpanQuery.getField(), equalTo(fieldInQuery));
-        assertThat(fieldMaskingSpanQuery.getMaskedQuery(), equalTo(queryBuilder.innerQuery().toQuery(context)));
-    }
-
-    @Test
-    public void testValidate() {
-        String fieldName = null;
-        SpanQueryBuilder spanQueryBuilder = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            fieldName = "fieldName";
-        } else {
-            if (randomBoolean()) {
-                fieldName = "";
-            }
-            totalExpectedErrors++;
-        }
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                spanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            }
-            totalExpectedErrors++;
-        } else {
-            spanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        FieldMaskingSpanQueryBuilder queryBuilder = new FieldMaskingSpanQueryBuilder(spanQueryBuilder, fieldName);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/FilteredQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/FilteredQueryBuilderTest.java
deleted file mode 100644
index 9eb7f5e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/FilteredQueryBuilderTest.java
+++ /dev/null
@@ -1,113 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-import static org.hamcrest.CoreMatchers.nullValue;
-
-@SuppressWarnings("deprecation")
-public class FilteredQueryBuilderTest extends BaseQueryTestCase<FilteredQueryBuilder> {
-
-    @Override
-    protected FilteredQueryBuilder doCreateTestQueryBuilder() {
-        QueryBuilder queryBuilder = RandomQueryBuilder.createQuery(random());
-        QueryBuilder filterBuilder = RandomQueryBuilder.createQuery(random());
-        return new FilteredQueryBuilder(queryBuilder, filterBuilder);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(FilteredQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query innerQuery = queryBuilder.innerQuery().toQuery(context);
-        if (innerQuery == null) {
-            assertThat(query, nullValue());
-        } else {
-            Query innerFilter = queryBuilder.innerFilter().toQuery(context);
-            if (innerFilter == null || Queries.isConstantMatchAllQuery(innerFilter)) {
-                innerQuery.setBoost(queryBuilder.boost());
-                assertThat(query, equalTo(innerQuery));
-            } else if (Queries.isConstantMatchAllQuery(innerQuery)) {
-                assertThat(query, instanceOf(ConstantScoreQuery.class));
-                assertThat(((ConstantScoreQuery)query).getQuery(), equalTo(innerFilter));
-            } else {
-                assertThat(query, instanceOf(BooleanQuery.class));
-                BooleanQuery booleanQuery = (BooleanQuery) query;
-                assertThat(booleanQuery.clauses().size(), equalTo(2));
-                assertThat(booleanQuery.clauses().get(0).getOccur(), equalTo(BooleanClause.Occur.MUST));
-                assertThat(booleanQuery.clauses().get(0).getQuery(), equalTo(innerQuery));
-                assertThat(booleanQuery.clauses().get(1).getOccur(), equalTo(BooleanClause.Occur.FILTER));
-                assertThat(booleanQuery.clauses().get(1).getQuery(), equalTo(innerFilter));
-            }
-        }
-    }
-
-    @Test
-    public void testValidation() {
-        QueryBuilder valid = RandomQueryBuilder.createQuery(random());
-        QueryBuilder invalid = RandomQueryBuilder.createInvalidQuery(random());
-
-        // invalid cases
-        FilteredQueryBuilder qb = new FilteredQueryBuilder(invalid);
-        QueryValidationException result = qb.validate();
-        assertNotNull(result);
-        assertEquals(1, result.validationErrors().size());
-
-        qb = new FilteredQueryBuilder(valid, invalid);
-        result = qb.validate();
-        assertNotNull(result);
-        assertEquals(1, result.validationErrors().size());
-
-        qb = new FilteredQueryBuilder(invalid, valid);
-        result = qb.validate();
-        assertNotNull(result);
-        assertEquals(1, result.validationErrors().size());
-
-        qb = new FilteredQueryBuilder(invalid, invalid);
-        result = qb.validate();
-        assertNotNull(result);
-        assertEquals(2, result.validationErrors().size());
-
-        // valid cases
-        qb = new FilteredQueryBuilder(valid);
-        assertNull(qb.validate());
-
-        qb = new FilteredQueryBuilder(null);
-        assertNull(qb.validate());
-
-        qb = new FilteredQueryBuilder(null, valid);
-        assertNull(qb.validate());
-
-        qb = new FilteredQueryBuilder(valid, null);
-        assertNull(qb.validate());
-
-        qb = new FilteredQueryBuilder(valid, valid);
-        assertNull(qb.validate());
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/FuzzyQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/FuzzyQueryBuilderTest.java
deleted file mode 100644
index 5f296be..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/FuzzyQueryBuilderTest.java
+++ /dev/null
@@ -1,98 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.collect.Tuple;
-import org.elasticsearch.common.unit.Fuzziness;
-import org.hamcrest.Matchers;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class FuzzyQueryBuilderTest extends BaseQueryTestCase<FuzzyQueryBuilder> {
-
-    @Override
-    protected FuzzyQueryBuilder doCreateTestQueryBuilder() {
-        Tuple<String, Object> fieldAndValue = getRandomFieldNameAndValue();
-        FuzzyQueryBuilder query = new FuzzyQueryBuilder(fieldAndValue.v1(), fieldAndValue.v2());
-        if (randomBoolean()) {
-            query.fuzziness(randomFuzziness(query.fieldName()));
-        }
-        if (randomBoolean()) {
-            query.prefixLength(randomIntBetween(0, 10));
-        }
-        if (randomBoolean()) {
-            query.maxExpansions(randomIntBetween(1, 10));
-        }
-        if (randomBoolean()) {
-            query.transpositions(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.rewrite(getRandomRewriteMethod());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(FuzzyQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (isNumericFieldName(queryBuilder.fieldName()) || queryBuilder.fieldName().equals(DATE_FIELD_NAME)) {
-            assertThat(query, instanceOf(NumericRangeQuery.class));
-        } else {
-            assertThat(query, instanceOf(FuzzyQuery.class));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        FuzzyQueryBuilder fuzzyQueryBuilder = new FuzzyQueryBuilder("", "text");
-        assertThat(fuzzyQueryBuilder.validate().validationErrors().size(), is(1));
-
-        fuzzyQueryBuilder = new FuzzyQueryBuilder("field", null);
-        assertThat(fuzzyQueryBuilder.validate().validationErrors().size(), is(1));
-
-        fuzzyQueryBuilder = new FuzzyQueryBuilder("field", "text");
-        assertNull(fuzzyQueryBuilder.validate());
-
-        fuzzyQueryBuilder = new FuzzyQueryBuilder(null, null);
-        assertThat(fuzzyQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-    
-    @Test
-    public void testUnsupportedFuzzinessForStringType() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-        
-        FuzzyQueryBuilder fuzzyQueryBuilder = new FuzzyQueryBuilder(STRING_FIELD_NAME, "text");
-        fuzzyQueryBuilder.fuzziness(Fuzziness.build(randomFrom("a string which is not auto", "3h", "200s")));
-
-        try {
-            fuzzyQueryBuilder.toQuery(context);
-            fail("should have failed with NumberFormatException");
-        } catch (NumberFormatException e) {
-            assertThat(e.getMessage(), Matchers.containsString("For input string"));
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTest.java
deleted file mode 100644
index 599d59a..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTest.java
+++ /dev/null
@@ -1,124 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class IdsQueryBuilderTest extends BaseQueryTestCase<IdsQueryBuilder> {
-
-    /**
-     * check that parser throws exception on missing values field
-     * @throws IOException
-     */
-    @Test(expected=QueryParsingException.class)
-    public void testIdsNotProvided() throws IOException {
-        String noIdsFieldQuery = "{\"ids\" : { \"type\" : \"my_type\"  }";
-        parseQuery(noIdsFieldQuery, IdsQueryBuilder.NAME);
-    }
-
-    @Override
-    protected IdsQueryBuilder doCreateTestQueryBuilder() {
-        String[] types;
-        if (getCurrentTypes().length > 0 && randomBoolean()) {
-            int numberOfTypes = randomIntBetween(1, getCurrentTypes().length);
-            types = new String[numberOfTypes];
-            for (int i = 0; i < numberOfTypes; i++) {
-                if (frequently()) {
-                    types[i] = randomFrom(getCurrentTypes());
-                } else {
-                    types[i] = randomAsciiOfLengthBetween(1, 10);
-                }
-            }
-        } else {
-            if (randomBoolean()) {
-                types = new String[]{MetaData.ALL};
-            } else {
-                types = new String[0];
-            }
-        }
-        int numberOfIds = randomIntBetween(0, 10);
-        String[] ids = new String[numberOfIds];
-        for (int i = 0; i < numberOfIds; i++) {
-            ids[i] = randomAsciiOfLengthBetween(1, 10);
-        }
-        IdsQueryBuilder query;
-        if (types.length > 0 || randomBoolean()) {
-            query = new IdsQueryBuilder(types);
-            query.addIds(ids);
-        } else {
-            query = new IdsQueryBuilder();
-            query.addIds(ids);
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(IdsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.ids().size() == 0) {
-            assertThat(query, instanceOf(BooleanQuery.class));
-            assertThat(((BooleanQuery)query).clauses().size(), equalTo(0));
-        } else {
-            assertThat(query, instanceOf(TermsQuery.class));
-        }
-    }
-
-    @Override
-    protected Map<String, IdsQueryBuilder> getAlternateVersions() {
-        Map<String, IdsQueryBuilder> alternateVersions = new HashMap<>();
-
-        IdsQueryBuilder tempQuery = createTestQueryBuilder();
-        if (tempQuery.types() != null && tempQuery.types().length > 0) {
-            String type = tempQuery.types()[0];
-            IdsQueryBuilder testQuery = new IdsQueryBuilder(type);
-
-            //single value type can also be called _type
-            String contentString1 = "{\n" +
-                        "    \"ids\" : {\n" +
-                        "        \"_type\" : \"" + type + "\",\n" +
-                        "        \"values\" : []\n" +
-                        "    }\n" +
-                        "}";
-            alternateVersions.put(contentString1, testQuery);
-
-            //array of types can also be called type rather than types
-            String contentString2 = "{\n" +
-                        "    \"ids\" : {\n" +
-                        "        \"type\" : [\"" + type + "\"],\n" +
-                        "        \"values\" : []\n" +
-                        "    }\n" +
-                        "}";
-            alternateVersions.put(contentString2, testQuery);
-        }
-
-        return alternateVersions;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java b/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java
index 6222f3b..d581aa6 100644
--- a/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java
@@ -83,7 +83,7 @@ public class IndexQueryParserFilterDateRangeTimezoneTests extends ESSingleNodeTe
             SearchContext.setCurrent(new TestSearchContext());
             queryParser.parse(query).query();
             fail("A Range Filter on a numeric field with a TimeZone should raise a QueryParsingException");
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             // We expect it
         } finally {
             SearchContext.removeCurrent();
@@ -120,7 +120,7 @@ public class IndexQueryParserFilterDateRangeTimezoneTests extends ESSingleNodeTe
             SearchContext.setCurrent(new TestSearchContext());
             queryParser.parse(query).query();
             fail("A Range Query on a numeric field with a TimeZone should raise a QueryParsingException");
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             // We expect it
         } finally {
             SearchContext.removeCurrent();
diff --git a/core/src/test/java/org/elasticsearch/index/query/IndicesQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/IndicesQueryBuilderTest.java
deleted file mode 100644
index c045bb0..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/IndicesQueryBuilderTest.java
+++ /dev/null
@@ -1,98 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-public class IndicesQueryBuilderTest extends BaseQueryTestCase<IndicesQueryBuilder> {
-
-    @Override
-    protected IndicesQueryBuilder doCreateTestQueryBuilder() {
-        String[] indices;
-        if (randomBoolean()) {
-            indices = new String[]{getIndex().getName()};
-        } else {
-            indices = generateRandomStringArray(5, 10, false, false);
-        }
-        IndicesQueryBuilder query = new IndicesQueryBuilder(RandomQueryBuilder.createQuery(random()), indices);
-
-        switch (randomInt(2)) {
-            case 0:
-                query.noMatchQuery(RandomQueryBuilder.createQuery(random()));
-                break;
-            case 1:
-                query.noMatchQuery(randomFrom(QueryBuilders.matchAllQuery(), new MatchNoneQueryBuilder()));
-                break;
-            default:
-                // do not set noMatchQuery
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(IndicesQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query expected;
-        if (queryBuilder.indices().length == 1 && getIndex().getName().equals(queryBuilder.indices()[0])) {
-            expected = queryBuilder.innerQuery().toQuery(context);
-        } else {
-            expected = queryBuilder.noMatchQuery().toQuery(context);
-        }
-        if (expected != null) {
-            expected.setBoost(queryBuilder.boost());
-        }
-        assertEquals(query, expected);
-    }
-
-    @Test
-    public void testValidate() {
-        int expectedErrors = 0;
-
-        // inner query
-        QueryBuilder innerQuery;
-        if (randomBoolean()) {
-            // setting innerQuery to null would be caught in the builder already and make validation fail
-            innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            expectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        // indices
-        String[] indices;
-        if (randomBoolean()) {
-            indices = randomBoolean() ? null : new String[0];
-            expectedErrors++;
-        } else {
-            indices = new String[]{"index"};
-        }
-        // no match query
-        QueryBuilder noMatchQuery;
-        if (randomBoolean()) {
-            noMatchQuery = RandomQueryBuilder.createInvalidQuery(random());
-            expectedErrors++;
-        } else {
-            noMatchQuery = RandomQueryBuilder.createQuery(random());
-        }
-
-        assertValidate(new IndicesQueryBuilder(innerQuery, indices).noMatchQuery(noMatchQuery), expectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/LimitQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/LimitQueryBuilderTest.java
deleted file mode 100644
index 59bb644..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/LimitQueryBuilderTest.java
+++ /dev/null
@@ -1,43 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class LimitQueryBuilderTest extends BaseQueryTestCase<LimitQueryBuilder> {
-
-    /**
-     * @return a LimitQueryBuilder with random limit between 0 and 20
-     */
-    @Override
-    protected LimitQueryBuilder doCreateTestQueryBuilder() {
-        return new LimitQueryBuilder(randomIntBetween(0, 20));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(LimitQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(MatchAllDocsQuery.class));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTest.java
deleted file mode 100644
index 277717c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTest.java
+++ /dev/null
@@ -1,40 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class MatchAllQueryBuilderTest extends BaseQueryTestCase<MatchAllQueryBuilder> {
-
-    @Override
-    protected MatchAllQueryBuilder doCreateTestQueryBuilder() {
-        return new MatchAllQueryBuilder();
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(MatchAllQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(MatchAllDocsQuery.class));
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchNoneQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/MatchNoneQueryBuilderTest.java
deleted file mode 100644
index 1a78992..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/MatchNoneQueryBuilderTest.java
+++ /dev/null
@@ -1,43 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.lucene.search.Queries;
-
-import java.io.IOException;
-
-public class MatchNoneQueryBuilderTest extends BaseQueryTestCase {
-
-    @Override
-    protected boolean supportsBoostAndQueryName() {
-        return false;
-    }
-
-    @Override
-    protected AbstractQueryBuilder doCreateTestQueryBuilder() {
-        return new MatchNoneQueryBuilder();
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(AbstractQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertEquals(query, Queries.newMatchNoDocsQuery());
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/MissingQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/MissingQueryBuilderTest.java
deleted file mode 100644
index 54b6a58..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/MissingQueryBuilderTest.java
+++ /dev/null
@@ -1,73 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.is;
-
-public class MissingQueryBuilderTest extends BaseQueryTestCase<MissingQueryBuilder> {
-
-    @Override
-    protected MissingQueryBuilder doCreateTestQueryBuilder() {
-        MissingQueryBuilder query  = new MissingQueryBuilder(randomBoolean() ? randomFrom(MAPPED_FIELD_NAMES) : randomAsciiOfLengthBetween(1, 10));
-        if (randomBoolean()) {
-            query.nullValue(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.existence(randomBoolean());
-        }
-        // cannot set both to false
-        if ((query.nullValue() == false) && (query.existence() == false)) {
-            query.existence(!query.existence());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(MissingQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        //too many mapping dependent cases to test, we don't want to end up duplication the toQuery method
-    }
-
-    @Test
-    public void testValidate() {
-        MissingQueryBuilder missingQueryBuilder = new MissingQueryBuilder("");
-        assertThat(missingQueryBuilder.validate().validationErrors().size(), is(1));
-
-        missingQueryBuilder = new MissingQueryBuilder(null);
-        assertThat(missingQueryBuilder.validate().validationErrors().size(), is(1));
-
-        missingQueryBuilder = new MissingQueryBuilder("field").existence(false).nullValue(false);
-        assertThat(missingQueryBuilder.validate().validationErrors().size(), is(1));
-
-        missingQueryBuilder = new MissingQueryBuilder("field");
-        assertNull(missingQueryBuilder.validate());
-    }
-
-    @Test(expected = QueryShardException.class)
-    public void testBothNullValueAndExistenceFalse() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-        MissingQueryBuilder.newFilter(context, "field", false, false);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/NotQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/NotQueryBuilderTest.java
deleted file mode 100644
index 44645af..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/NotQueryBuilderTest.java
+++ /dev/null
@@ -1,108 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.CoreMatchers.*;
-
-public class NotQueryBuilderTest extends BaseQueryTestCase<NotQueryBuilder> {
-
-    /**
-     * @return a NotQueryBuilder with random limit between 0 and 20
-     */
-    @Override
-    protected NotQueryBuilder doCreateTestQueryBuilder() {
-        return new NotQueryBuilder(RandomQueryBuilder.createQuery(random()));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(NotQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query filter = queryBuilder.innerQuery().toQuery(context);
-        if (filter == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(BooleanQuery.class));
-            BooleanQuery booleanQuery = (BooleanQuery) query;
-            assertThat(booleanQuery.clauses().size(), equalTo(2));
-            assertThat(booleanQuery.clauses().get(0).getOccur(), equalTo(BooleanClause.Occur.MUST));
-            assertThat(booleanQuery.clauses().get(0).getQuery(), instanceOf(MatchAllDocsQuery.class));
-            assertThat(booleanQuery.clauses().get(1).getOccur(), equalTo(BooleanClause.Occur.MUST_NOT));
-            assertThat(booleanQuery.clauses().get(1).getQuery(), equalTo(filter));
-        }
-    }
-
-    /**
-     * @throws IOException
-     */
-    @Test(expected=QueryParsingException.class)
-    public void testMissingFilterSection() throws IOException {
-        String queryString = "{ \"not\" : {}";
-        parseQuery(queryString, NotQueryBuilder.NAME);
-    }
-
-    @Override
-    protected Map<String, NotQueryBuilder> getAlternateVersions() {
-        Map<String, NotQueryBuilder> alternateVersions = new HashMap<>();
-
-        NotQueryBuilder testQuery1 = new NotQueryBuilder(createTestQueryBuilder().innerQuery());
-        String contentString1 = "{\n" +
-                "    \"not\" : {\n" +
-                "        \"filter\" : " + testQuery1.innerQuery().toString() + "\n" +
-                "    }\n" +
-                "}";
-        alternateVersions.put(contentString1, testQuery1);
-
-        QueryBuilder innerQuery = createTestQueryBuilder().innerQuery();
-        //not doesn't support empty query when query/filter element is not specified
-        if (innerQuery != EmptyQueryBuilder.PROTOTYPE) {
-            NotQueryBuilder testQuery2 = new NotQueryBuilder(innerQuery);
-            String contentString2 = "{\n" +
-                    "    \"not\" : " + testQuery2.innerQuery().toString() +  "\n}";
-            alternateVersions.put(contentString2, testQuery2);
-        }
-
-        return alternateVersions;
-    }
-
-    @Test
-    public void testValidate() {
-        QueryBuilder innerQuery = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        NotQueryBuilder notQuery = new NotQueryBuilder(innerQuery);
-        assertValidate(notQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/OrQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/OrQueryBuilderTest.java
deleted file mode 100644
index aae4a02..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/OrQueryBuilderTest.java
+++ /dev/null
@@ -1,120 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.*;
-
-import static org.hamcrest.CoreMatchers.*;
-
-@SuppressWarnings("deprecation")
-public class OrQueryBuilderTest extends BaseQueryTestCase<OrQueryBuilder> {
-
-    /**
-     * @return an OrQueryBuilder with random limit between 0 and 20
-     */
-    @Override
-    protected OrQueryBuilder doCreateTestQueryBuilder() {
-        OrQueryBuilder query = new OrQueryBuilder();
-        int subQueries = randomIntBetween(1, 5);
-        for (int i = 0; i < subQueries; i++ ) {
-            query.add(RandomQueryBuilder.createQuery(random()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(OrQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.innerQueries().isEmpty()) {
-            assertThat(query, nullValue());
-        } else {
-            List<Query> innerQueries = new ArrayList<>();
-            for (QueryBuilder subQuery : queryBuilder.innerQueries()) {
-                Query innerQuery = subQuery.toQuery(context);
-                // ignore queries that are null
-                if (innerQuery != null) {
-                    innerQueries.add(innerQuery);
-                }
-            }
-            if (innerQueries.isEmpty()) {
-                assertThat(query, nullValue());
-            } else {
-                assertThat(query, instanceOf(BooleanQuery.class));
-                BooleanQuery booleanQuery = (BooleanQuery) query;
-                assertThat(booleanQuery.clauses().size(), equalTo(innerQueries.size()));
-                Iterator<Query> queryIterator = innerQueries.iterator();
-                for (BooleanClause booleanClause : booleanQuery) {
-                    assertThat(booleanClause.getOccur(), equalTo(BooleanClause.Occur.SHOULD));
-                    assertThat(booleanClause.getQuery(), equalTo(queryIterator.next()));
-                }
-            }
-        }
-    }
-
-    /**
-     * test corner case where no inner queries exist
-     */
-    @Test
-    public void testNoInnerQueries() throws QueryShardException, IOException {
-        OrQueryBuilder orQuery = new OrQueryBuilder();
-        assertNull(orQuery.toQuery(createShardContext()));
-    }
-
-    @Override
-    protected Map<String, OrQueryBuilder> getAlternateVersions() {
-        Map<String, OrQueryBuilder> alternateVersions = new HashMap<>();
-        QueryBuilder innerQuery = createTestQueryBuilder().innerQueries().get(0);
-        OrQueryBuilder expectedQuery = new OrQueryBuilder(innerQuery);
-        String contentString =  "{ \"or\" : [ " + innerQuery + "] }";
-        alternateVersions.put(contentString, expectedQuery);
-        return alternateVersions;
-    }
-
-    @Test(expected=QueryParsingException.class)
-    public void testMissingFiltersSection() throws IOException {
-        String queryString = "{ \"or\" : {}";
-        parseQuery(queryString, OrQueryBuilder.NAME);
-    }
-
-    @Test
-    public void testValidate() {
-        OrQueryBuilder orQuery = new OrQueryBuilder();
-        int iters = randomIntBetween(0, 5);
-        int totalExpectedErrors = 0;
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    orQuery.add(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    orQuery.add(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                orQuery.add(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        assertValidate(orQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/PrefixQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/PrefixQueryBuilderTest.java
deleted file mode 100644
index 42fe5ab..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/PrefixQueryBuilderTest.java
+++ /dev/null
@@ -1,67 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class PrefixQueryBuilderTest extends BaseQueryTestCase<PrefixQueryBuilder> {
-
-    @Override
-    protected PrefixQueryBuilder doCreateTestQueryBuilder() {
-        String fieldName = randomBoolean() ? STRING_FIELD_NAME : randomAsciiOfLengthBetween(1, 10);
-        String value = randomAsciiOfLengthBetween(1, 10);
-        PrefixQueryBuilder query = new PrefixQueryBuilder(fieldName, value);
-
-        if (randomBoolean()) {
-            query.rewrite(getRandomRewriteMethod());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(PrefixQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(PrefixQuery.class));
-        PrefixQuery prefixQuery = (PrefixQuery) query;
-        assertThat(prefixQuery.getPrefix().field(), equalTo(queryBuilder.fieldName()));
-    }
-
-    @Test
-    public void testValidate() {
-        PrefixQueryBuilder prefixQueryBuilder = new PrefixQueryBuilder("", "prefix");
-        assertThat(prefixQueryBuilder.validate().validationErrors().size(), is(1));
-
-        prefixQueryBuilder = new PrefixQueryBuilder("field", null);
-        assertThat(prefixQueryBuilder.validate().validationErrors().size(), is(1));
-
-        prefixQueryBuilder = new PrefixQueryBuilder("field", "prefix");
-        assertNull(prefixQueryBuilder.validate());
-
-        prefixQueryBuilder = new PrefixQueryBuilder(null, null);
-        assertThat(prefixQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/QueryFilterBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/QueryFilterBuilderTest.java
deleted file mode 100644
index 3e80604..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/QueryFilterBuilderTest.java
+++ /dev/null
@@ -1,84 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.*;
-
-@SuppressWarnings("deprecation")
-public class QueryFilterBuilderTest extends BaseQueryTestCase<QueryFilterBuilder> {
-
-    @Override
-    protected QueryFilterBuilder doCreateTestQueryBuilder() {
-        QueryBuilder innerQuery = RandomQueryBuilder.createQuery(random());
-        return new QueryFilterBuilder(innerQuery);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(QueryFilterBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query innerQuery = queryBuilder.innerQuery().toQuery(context);
-        if (innerQuery == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(ConstantScoreQuery.class));
-            ConstantScoreQuery constantScoreQuery = (ConstantScoreQuery) query;
-            assertThat(constantScoreQuery.getQuery(), equalTo(innerQuery));
-        }
-    }
-
-    @Override
-    protected boolean supportsBoostAndQueryName() {
-        return false;
-    }
-
-    /**
-     * test wrapping an inner filter that returns null also returns <tt>null</null> to pass on upwards
-     */
-    @Test
-    public void testInnerQueryReturnsNull() throws IOException {
-        // create inner filter
-        String queryString = "{ \"constant_score\" : { \"filter\" : {} }";
-        QueryBuilder<?> innerQuery = parseQuery(queryString, ConstantScoreQueryBuilder.NAME);
-        // check that when wrapping this filter, toQuery() returns null
-        QueryFilterBuilder queryFilterQuery = new QueryFilterBuilder(innerQuery);
-        assertNull(queryFilterQuery.toQuery(createShardContext()));
-    }
-
-    @Test
-    public void testValidate() {
-        QueryBuilder innerQuery = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        QueryFilterBuilder fQueryFilter = new QueryFilterBuilder(innerQuery);
-        assertValidate(fQueryFilter, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/RandomQueryBuilder.java b/core/src/test/java/org/elasticsearch/index/query/RandomQueryBuilder.java
deleted file mode 100644
index e86a0ec..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/RandomQueryBuilder.java
+++ /dev/null
@@ -1,91 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.carrotsearch.randomizedtesting.generators.RandomInts;
-import com.carrotsearch.randomizedtesting.generators.RandomStrings;
-
-import java.util.Random;
-
-/**
- * Utility class for creating random QueryBuilders.
- * So far only leaf queries like {@link MatchAllQueryBuilder}, {@link TermQueryBuilder} or
- * {@link IdsQueryBuilder} are returned.
- */
-public class RandomQueryBuilder {
-
-    /**
-     * Create a new query of a random type
-     * @param r random seed
-     * @return a random {@link QueryBuilder}
-     */
-    public static QueryBuilder createQuery(Random r) {
-        switch (RandomInts.randomIntBetween(r, 0, 4)) {
-            case 0:
-                return new MatchAllQueryBuilderTest().createTestQueryBuilder();
-            case 1:
-                return new TermQueryBuilderTest().createTestQueryBuilder();
-            case 2:
-                return new IdsQueryBuilderTest().createTestQueryBuilder();
-            case 3:
-                return createMultiTermQuery(r);
-            case 4:
-                return EmptyQueryBuilder.PROTOTYPE;
-            default:
-                throw new UnsupportedOperationException();
-        }
-    }
-
-    /**
-     * Create a new multi term query of a random type
-     * @param r random seed
-     * @return a random {@link MultiTermQueryBuilder}
-     */
-    public static MultiTermQueryBuilder createMultiTermQuery(Random r) {
-        // for now, only use String Rangequeries for MultiTerm test, numeric and date makes little sense
-        // see issue #12123 for discussion
-        // Prefix / Fuzzy / RegEx / Wildcard can go here later once refactored and they have random query generators
-        RangeQueryBuilder query = new RangeQueryBuilder(BaseQueryTestCase.STRING_FIELD_NAME);
-        query.from("a" + RandomStrings.randomAsciiOfLengthBetween(r, 1, 10));
-        query.to("z" + RandomStrings.randomAsciiOfLengthBetween(r, 1, 10));
-        return query;
-    }
-
-    /**
-     * Create a new invalid query of a random type
-     * @param r random seed
-     * @return a random {@link QueryBuilder} that is invalid, meaning that calling validate against it
-     * will return an error. We can rely on the fact that a single error will be returned per query.
-     */
-    public static QueryBuilder createInvalidQuery(Random r) {
-        switch (RandomInts.randomIntBetween(r, 0, 3)) {
-            case 0:
-                return new TermQueryBuilder("", "test");
-            case 1:
-                return new BoostingQueryBuilder(new MatchAllQueryBuilder(), new MatchAllQueryBuilder()).negativeBoost(-1f);
-            case 2:
-                return new CommonTermsQueryBuilder("", "text");
-            case 3:
-                return new SimpleQueryStringBuilder(null);
-            default:
-                throw new UnsupportedOperationException();
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTest.java
deleted file mode 100644
index 00753d8..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTest.java
+++ /dev/null
@@ -1,144 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermRangeQuery;
-import org.joda.time.DateTime;
-import org.joda.time.DateTimeZone;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class RangeQueryBuilderTest extends BaseQueryTestCase<RangeQueryBuilder> {
-
-    private static final List<String> TIMEZONE_IDS = new ArrayList<>(DateTimeZone.getAvailableIDs());
-
-    @Override
-    protected RangeQueryBuilder doCreateTestQueryBuilder() {
-        RangeQueryBuilder query;
-        // switch between numeric and date ranges
-        switch (randomIntBetween(0, 2)) {
-            case 0:
-                if (randomBoolean()) {
-                    // use mapped integer field for numeric range queries
-                    query = new RangeQueryBuilder(INT_FIELD_NAME);
-                    query.from(randomIntBetween(1, 100));
-                    query.to(randomIntBetween(101, 200));
-                } else {
-                    // use unmapped field for numeric range queries
-                    query = new RangeQueryBuilder(randomAsciiOfLengthBetween(1, 10));
-                    query.from(0.0 - randomDouble());
-                    query.to(randomDouble());
-                }
-                break;
-            case 1:
-                // use mapped date field, using date string representation
-                query = new RangeQueryBuilder(DATE_FIELD_NAME);
-                query.from(new DateTime(System.currentTimeMillis() - randomIntBetween(0, 1000000), DateTimeZone.UTC).toString());
-                query.to(new DateTime(System.currentTimeMillis() + randomIntBetween(0, 1000000), DateTimeZone.UTC).toString());
-                // Create timestamp option only then we have a date mapper,
-                // otherwise we could trigger exception.
-                if (createShardContext().mapperService().smartNameFieldType(DATE_FIELD_NAME) != null) {
-                    if (randomBoolean()) {
-                        query.timeZone(TIMEZONE_IDS.get(randomIntBetween(0, TIMEZONE_IDS.size() - 1)));
-                    }
-                    if (randomBoolean()) {
-                        query.format("yyyy-MM-dd'T'HH:mm:ss.SSSZZ");
-                    }
-                }
-                break;
-            case 2:
-            default:
-                query = new RangeQueryBuilder(STRING_FIELD_NAME);
-                query.from("a" + randomAsciiOfLengthBetween(1, 10));
-                query.to("z" + randomAsciiOfLengthBetween(1, 10));
-                break;
-        }
-        query.includeLower(randomBoolean()).includeUpper(randomBoolean());
-        if (randomBoolean()) {
-            query.from(null);
-        }
-        if (randomBoolean()) {
-            query.to(null);
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(RangeQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (getCurrentTypes().length == 0 || (queryBuilder.fieldName().equals(DATE_FIELD_NAME) == false && queryBuilder.fieldName().equals(INT_FIELD_NAME) == false)) {
-            assertThat(query, instanceOf(TermRangeQuery.class));
-        } else if (queryBuilder.fieldName().equals(DATE_FIELD_NAME)) {
-            //we can't properly test unmapped dates because LateParsingQuery is package private
-        } else if (queryBuilder.fieldName().equals(INT_FIELD_NAME)) {
-            assertThat(query, instanceOf(NumericRangeQuery.class));
-        } else {
-            throw new UnsupportedOperationException();
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        RangeQueryBuilder rangeQueryBuilder = new RangeQueryBuilder("");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(1));
-
-        rangeQueryBuilder = new RangeQueryBuilder("okay").timeZone("UTC");
-        assertNull(rangeQueryBuilder.validate());
-
-        rangeQueryBuilder.timeZone("blab");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(1));
-
-        rangeQueryBuilder.timeZone("UTC").format("basicDate");
-        assertNull(rangeQueryBuilder.validate());
-
-        rangeQueryBuilder.timeZone("UTC").format("broken_xx");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(1));
-
-        rangeQueryBuilder.timeZone("xXx").format("broken_xx");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-
-    /**
-     * Specifying a timezone together with a numeric range query should throw an exception.
-     */
-    @Test(expected=QueryShardException.class)
-    public void testToQueryNonDateWithTimezone() throws QueryShardException, IOException {
-        RangeQueryBuilder query = new RangeQueryBuilder(INT_FIELD_NAME);
-        query.from(1).to(10).timeZone("UTC");
-        query.toQuery(createShardContext());
-    }
-
-    /**
-     * Specifying a timezone together with an unmapped field should throw an exception.
-     */
-    @Test(expected=QueryShardException.class)
-    public void testToQueryUnmappedWithTimezone() throws QueryShardException, IOException {
-        RangeQueryBuilder query = new RangeQueryBuilder("bogus_field");
-        query.from(1).to(10).timeZone("UTC");
-        query.toQuery(createShardContext());
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/RegexpQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/RegexpQueryBuilderTest.java
deleted file mode 100644
index 9328609..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/RegexpQueryBuilderTest.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.RegexpQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class RegexpQueryBuilderTest extends BaseQueryTestCase<RegexpQueryBuilder> {
-
-    @Override
-    protected RegexpQueryBuilder doCreateTestQueryBuilder() {
-        // mapped or unmapped fields
-        String fieldName = randomBoolean() ? STRING_FIELD_NAME : randomAsciiOfLengthBetween(1, 10);
-        String value = randomAsciiOfLengthBetween(1, 10);
-        RegexpQueryBuilder query = new RegexpQueryBuilder(fieldName, value);
-
-        if (randomBoolean()) {
-            List<RegexpFlag> flags = new ArrayList<>();
-            int iter = randomInt(5);
-            for (int i = 0; i < iter; i++) {
-                flags.add(randomFrom(RegexpFlag.values()));
-            }
-            query.flags(flags.toArray(new RegexpFlag[flags.size()]));
-        }
-        if (randomBoolean()) {
-            query.maxDeterminizedStates(randomInt(50000));
-        }
-        if (randomBoolean()) {
-            query.rewrite(randomFrom(getRandomRewriteMethod()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(RegexpQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(RegexpQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        RegexpQueryBuilder regexQueryBuilder = new RegexpQueryBuilder("", "regex");
-        assertThat(regexQueryBuilder.validate().validationErrors().size(), is(1));
-
-        regexQueryBuilder = new RegexpQueryBuilder("field", null);
-        assertThat(regexQueryBuilder.validate().validationErrors().size(), is(1));
-
-        regexQueryBuilder = new RegexpQueryBuilder("field", "regex");
-        assertNull(regexQueryBuilder.validate());
-
-        regexQueryBuilder = new RegexpQueryBuilder(null, null);
-        assertThat(regexQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTest.java
deleted file mode 100644
index dcc74d1..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTest.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.script.ScriptService.ScriptType;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class ScriptQueryBuilderTest extends BaseQueryTestCase<ScriptQueryBuilder> {
-
-    @Override
-    protected ScriptQueryBuilder doCreateTestQueryBuilder() {
-        String script;
-        Map<String, Object> params = null;
-        if (randomBoolean()) {
-            script = "5 * 2 > param";
-            params = new HashMap<>();
-            params.put("param", 1);
-        } else {
-            script = "5 * 2 > 2";
-        }
-        return new ScriptQueryBuilder(new Script(script, ScriptType.INLINE, "expression", params));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(ScriptQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(ScriptQueryBuilder.ScriptQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        ScriptQueryBuilder scriptQueryBuilder = new ScriptQueryBuilder(null);
-        assertThat(scriptQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java b/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
index 8d820f4..559d5d1 100644
--- a/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
@@ -19,25 +19,55 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
 import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
-import org.apache.lucene.index.*;
+import org.apache.lucene.index.Fields;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.index.memory.MemoryIndex;
 import org.apache.lucene.queries.BoostingQuery;
 import org.apache.lucene.queries.ExtendedCommonTermsQuery;
 import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.*;
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.DisjunctionMaxQuery;
+import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.PrefixQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.QueryWrapperFilter;
+import org.apache.lucene.search.RegexpQuery;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.search.TermRangeQuery;
+import org.apache.lucene.search.WildcardQuery;
 import org.apache.lucene.search.join.ToParentBlockJoinQuery;
-import org.apache.lucene.search.spans.*;
+import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
+import org.apache.lucene.search.spans.SpanContainingQuery;
+import org.apache.lucene.search.spans.SpanFirstQuery;
+import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
+import org.apache.lucene.search.spans.SpanNearQuery;
+import org.apache.lucene.search.spans.SpanNotQuery;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.search.spans.SpanWithinQuery;
 import org.apache.lucene.spatial.prefix.IntersectsPrefixTreeFilter;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.automaton.TooComplexToDeterminizeException;
-import org.elasticsearch.action.termvectors.*;
+import org.elasticsearch.action.termvectors.MultiTermVectorsItemResponse;
+import org.elasticsearch.action.termvectors.MultiTermVectorsRequest;
+import org.elasticsearch.action.termvectors.MultiTermVectorsResponse;
+import org.elasticsearch.action.termvectors.TermVectorsRequest;
+import org.elasticsearch.action.termvectors.TermVectorsResponse;
+import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.compress.CompressedXContent;
@@ -72,6 +102,7 @@ import java.io.IOException;
 import java.util.Arrays;
 import java.util.EnumSet;
 import java.util.List;
+import java.util.Locale;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.*;
@@ -969,7 +1000,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testBoostingQueryBuilder() throws IOException {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(boostingQuery(termQuery("field1", "value1"), termQuery("field1", "value2")).negativeBoost(0.2f)).query();
+        Query parsedQuery = queryParser.parse(boostingQuery().positive(termQuery("field1", "value1")).negative(termQuery("field1", "value2")).negativeBoost(0.2f)).query();
         assertThat(parsedQuery, instanceOf(BoostingQuery.class));
     }
 
@@ -1042,7 +1073,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testTermsQueryBuilder() throws IOException {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(termsQuery("name.first", Lists.newArrayList("shay", "test"))).query();
+        Query parsedQuery = queryParser.parse(termsQuery("name.first", Arrays.asList("shay", "test"))).query();
         assertThat(parsedQuery, instanceOf(BooleanQuery.class));
         BooleanQuery booleanQuery = (BooleanQuery) parsedQuery;
         BooleanClause[] clauses = booleanQuery.getClauses();
@@ -1136,7 +1167,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testInQuery() throws IOException {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(termsQuery("name.first", Lists.newArrayList("test1", "test2", "test3"))).query();
+        Query parsedQuery = queryParser.parse(termsQuery("name.first", Arrays.asList("test1", "test2", "test3"))).query();
         assertThat(parsedQuery, instanceOf(BooleanQuery.class));
         BooleanQuery booleanQuery = (BooleanQuery) parsedQuery;
         BooleanClause[] clauses = booleanQuery.getClauses();
@@ -1351,7 +1382,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testSpanNotQueryBuilder() throws IOException {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(spanNotQuery(spanTermQuery("age", 34), spanTermQuery("age", 35))).query();
+        Query parsedQuery = queryParser.parse(spanNotQuery().include(spanTermQuery("age", 34)).exclude(spanTermQuery("age", 35))).query();
         assertThat(parsedQuery, instanceOf(SpanNotQuery.class));
         SpanNotQuery spanNotQuery = (SpanNotQuery) parsedQuery;
         // since age is automatically registered in data, we encode it as numeric
@@ -1376,7 +1407,9 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         IndexQueryParserService queryParser = queryParser();
         Query expectedQuery = new SpanWithinQuery(new SpanTermQuery(new Term("age", longToPrefixCoded(34, 0))),
                                                   new SpanTermQuery(new Term("age", longToPrefixCoded(35, 0))));
-        Query actualQuery = queryParser.parse(spanWithinQuery(spanTermQuery("age", 34), spanTermQuery("age", 35)))
+        Query actualQuery = queryParser.parse(spanWithinQuery()
+                                              .big(spanTermQuery("age", 34))
+                                              .little(spanTermQuery("age", 35)))
                                               .query();
         assertEquals(expectedQuery, actualQuery);
     }
@@ -1396,7 +1429,10 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         IndexQueryParserService queryParser = queryParser();
         Query expectedQuery = new SpanContainingQuery(new SpanTermQuery(new Term("age", longToPrefixCoded(34, 0))),
                                                       new SpanTermQuery(new Term("age", longToPrefixCoded(35, 0))));
-        Query actualQuery = queryParser.parse(spanContainingQuery(spanTermQuery("age", 34), spanTermQuery("age", 35))).query();
+        Query actualQuery = queryParser.parse(spanContainingQuery()
+                                              .big(spanTermQuery("age", 34))
+                                              .little(spanTermQuery("age", 35)))
+                                              .query();
         assertEquals(expectedQuery, actualQuery);
     }
 
@@ -1436,7 +1472,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testSpanNearQueryBuilder() throws IOException {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(spanNearQuery(12).clause(spanTermQuery("age", 34)).clause(spanTermQuery("age", 35)).clause(spanTermQuery("age", 36)).inOrder(false).collectPayloads(false)).query();
+        Query parsedQuery = queryParser.parse(spanNearQuery().clause(spanTermQuery("age", 34)).clause(spanTermQuery("age", 35)).clause(spanTermQuery("age", 36)).slop(12).inOrder(false).collectPayloads(false)).query();
         assertThat(parsedQuery, instanceOf(SpanNearQuery.class));
         SpanNearQuery spanNearQuery = (SpanNearQuery) parsedQuery;
         assertThat(spanNearQuery.getClauses().length, equalTo(3));
@@ -1644,7 +1680,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
 
     @Test
     public void testMoreLikeThisIds() throws Exception {
-        MoreLikeThisQueryParser parser = (MoreLikeThisQueryParser) queryParser.indicesQueriesRegistry().queryParsers().get("more_like_this");
+        MoreLikeThisQueryParser parser = (MoreLikeThisQueryParser) queryParser.queryParser("more_like_this");
         parser.setFetchService(new MockMoreLikeThisFetchService());
 
         IndexQueryParserService queryParser = queryParser();
@@ -1670,7 +1706,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testMLTMinimumShouldMatch() throws Exception {
         // setup for mocking fetching items
-        MoreLikeThisQueryParser parser = (MoreLikeThisQueryParser) queryParser.indicesQueriesRegistry().queryParsers().get("more_like_this");
+        MoreLikeThisQueryParser parser = (MoreLikeThisQueryParser) queryParser.queryParser("more_like_this");
         parser.setFetchService(new MockMoreLikeThisFetchService());
 
         // parsing the ES query
@@ -2311,6 +2347,14 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     }
 
     @Test
+    public void testSimpleQueryString() throws Exception {
+        IndexQueryParserService queryParser = queryParser();
+        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/simple-query-string.json");
+        Query parsedQuery = queryParser.parse(query).query();
+        assertThat(parsedQuery, instanceOf(BooleanQuery.class));
+    }
+
+    @Test
     public void testMatchWithFuzzyTranspositions() throws Exception {
         IndexQueryParserService queryParser = queryParser();
         String query = copyToStringFromClasspath("/org/elasticsearch/index/query/match-with-fuzzy-transpositions.json");
@@ -2440,8 +2484,8 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         assertThat(((ConstantScoreQuery) parsedQuery).getQuery().toString(), equalTo("ToParentBlockJoinQuery (+*:* #QueryWrapperFilter(_type:__nested))"));
         SearchContext.removeCurrent();
     }
-
-    /**
+    
+    /** 
      * helper to extract term from TermQuery. */
     private Term getTerm(Query query) {
         while (query instanceof QueryWrapperFilter) {
@@ -2493,4 +2537,19 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
             assertThat(prefixQuery.getRewriteMethod(), instanceOf(MultiTermQuery.TopTermsBlendedFreqScoringRewrite.class));
         }
     }
+
+    @Test
+    public void testSimpleQueryStringNoFields() throws Exception {
+        IndexQueryParserService queryParser = queryParser();
+        String queryText = randomAsciiOfLengthBetween(1, 10).toLowerCase(Locale.ROOT);
+        String query = "{\n" +
+                "    \"simple_query_string\" : {\n" +
+                "        \"query\" : \"" + queryText + "\"\n" +
+                "    }\n" +
+                "}";
+        Query parsedQuery = queryParser.parse(query).query();
+        assertThat(parsedQuery, instanceOf(TermQuery.class));
+        TermQuery termQuery = (TermQuery) parsedQuery;
+        assertThat(termQuery.getTerm(), equalTo(new Term(MetaData.ALL, queryText)));
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java
deleted file mode 100644
index b5c3b14..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java
+++ /dev/null
@@ -1,330 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.MatchNoDocsQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.Version;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.*;
-
-import static org.hamcrest.Matchers.*;
-
-public class SimpleQueryStringBuilderTest extends BaseQueryTestCase<SimpleQueryStringBuilder> {
-
-    private static final String[] MINIMUM_SHOULD_MATCH = new String[] { "1", "-1", "75%", "-25%", "2<75%", "2<-25%" };
-
-    @Override
-    protected SimpleQueryStringBuilder doCreateTestQueryBuilder() {
-        SimpleQueryStringBuilder result = new SimpleQueryStringBuilder(randomAsciiOfLengthBetween(1, 10));
-        if (randomBoolean()) {
-            result.analyzeWildcard(randomBoolean());
-        }
-        if (randomBoolean()) {
-            result.lenient(randomBoolean());
-        }
-        if (randomBoolean()) {
-            result.lowercaseExpandedTerms(randomBoolean());
-        }
-        if (randomBoolean()) {
-            result.locale(randomLocale(getRandom()));
-        }
-        if (randomBoolean()) {
-            result.minimumShouldMatch(randomFrom(MINIMUM_SHOULD_MATCH));
-        }
-        if (randomBoolean()) {
-            result.analyzer("simple");
-        }
-        if (randomBoolean()) {
-            result.defaultOperator(randomFrom(Operator.AND, Operator.OR));
-        }
-        if (randomBoolean()) {
-            Set<SimpleQueryStringFlag> flagSet = new HashSet<>();
-            int size = randomIntBetween(0, SimpleQueryStringFlag.values().length);
-            for (int i = 0; i < size; i++) {
-                flagSet.add(randomFrom(SimpleQueryStringFlag.values()));
-            }
-            if (flagSet.size() > 0) {
-                result.flags(flagSet.toArray(new SimpleQueryStringFlag[flagSet.size()]));
-            }
-        }
-
-        int fieldCount = randomIntBetween(0, 10);
-        Map<String, Float> fields = new TreeMap<>();
-        for (int i = 0; i < fieldCount; i++) {
-            if (randomBoolean()) {
-                fields.put(randomAsciiOfLengthBetween(1, 10), AbstractQueryBuilder.DEFAULT_BOOST);
-            } else {
-                fields.put(randomAsciiOfLengthBetween(1, 10), 2.0f / randomIntBetween(1, 20));
-            }
-        }
-        result.fields(fields);
-
-        return result;
-    }
-
-    @Test
-    public void testDefaults() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-
-        assertEquals("Wrong default default boost.", AbstractQueryBuilder.DEFAULT_BOOST, qb.boost(), 0.001);
-        assertEquals("Wrong default default boost field.", AbstractQueryBuilder.DEFAULT_BOOST, SimpleQueryStringBuilder.DEFAULT_BOOST,
-                0.001);
-
-        assertEquals("Wrong default flags.", SimpleQueryStringFlag.ALL.value, qb.flags());
-        assertEquals("Wrong default flags field.", SimpleQueryStringFlag.ALL.value(), SimpleQueryStringBuilder.DEFAULT_FLAGS);
-
-        assertEquals("Wrong default default operator.", Operator.OR, qb.defaultOperator());
-        assertEquals("Wrong default default operator field.", Operator.OR, SimpleQueryStringBuilder.DEFAULT_OPERATOR);
-
-        assertEquals("Wrong default default locale.", Locale.ROOT, qb.locale());
-        assertEquals("Wrong default default locale field.", Locale.ROOT, SimpleQueryStringBuilder.DEFAULT_LOCALE);
-
-        assertEquals("Wrong default default analyze_wildcard.", false, qb.analyzeWildcard());
-        assertEquals("Wrong default default analyze_wildcard field.", false, SimpleQueryStringBuilder.DEFAULT_ANALYZE_WILDCARD);
-
-        assertEquals("Wrong default default lowercase_expanded_terms.", true, qb.lowercaseExpandedTerms());
-        assertEquals("Wrong default default lowercase_expanded_terms field.", true,
-                SimpleQueryStringBuilder.DEFAULT_LOWERCASE_EXPANDED_TERMS);
-
-        assertEquals("Wrong default default lenient.", false, qb.lenient());
-        assertEquals("Wrong default default lenient field.", false, SimpleQueryStringBuilder.DEFAULT_LENIENT);
-
-        assertEquals("Wrong default default locale.", Locale.ROOT, qb.locale());
-        assertEquals("Wrong default default locale field.", Locale.ROOT, SimpleQueryStringBuilder.DEFAULT_LOCALE);
-    }
-
-    @Test
-    public void testDefaultNullLocale() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.locale(null);
-        assertEquals("Setting locale to null should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_LOCALE,
-                qb.locale());
-    }
-
-    @Test
-    public void testDefaultNullComplainFlags() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.flags((SimpleQueryStringFlag[]) null);
-        assertEquals("Setting flags to null should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_FLAGS,
-                qb.flags());
-    }
-
-    @Test
-    public void testDefaultEmptyComplainFlags() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.flags(new SimpleQueryStringFlag[] {});
-        assertEquals("Setting flags to empty should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_FLAGS,
-                qb.flags());
-    }
-
-    @Test
-    public void testDefaultNullComplainOp() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.defaultOperator(null);
-        assertEquals("Setting operator to null should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_OPERATOR,
-                qb.defaultOperator());
-    }
-
-    // Check operator handling, and default field handling.
-    @Test
-    public void testDefaultOperatorHandling() throws IOException {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.").field(STRING_FIELD_NAME);
-        QueryShardContext shardContext = createShardContext();
-        shardContext.setAllowUnmappedFields(true); // to avoid occasional cases
-                                                   // in setup where we didn't
-                                                   // add types but strict field
-                                                   // resolution
-        BooleanQuery boolQuery = (BooleanQuery) qb.toQuery(shardContext);
-        assertThat(shouldClauses(boolQuery), is(4));
-
-        qb.defaultOperator(Operator.AND);
-        boolQuery = (BooleanQuery) qb.toQuery(shardContext);
-        assertThat(shouldClauses(boolQuery), is(0));
-
-        qb.defaultOperator(Operator.OR);
-        boolQuery = (BooleanQuery) qb.toQuery(shardContext);
-        assertThat(shouldClauses(boolQuery), is(4));
-    }
-
-    @Test
-    public void testValidation() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        assertNull(qb.validate());
-    }
-
-    @Test
-    public void testNullQueryTextGeneratesException() {
-        SimpleQueryStringBuilder builder = new SimpleQueryStringBuilder(null);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeNull() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field(null);
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeNullAndWeighted() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field(null, AbstractQueryBuilder.DEFAULT_BOOST);
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeEmpty() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field("");
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeEmptyAndWeighted() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field("", AbstractQueryBuilder.DEFAULT_BOOST);
-    }
-
-    /**
-     * The following should fail fast - never silently set the map containing
-     * fields and weights to null but refuse to accept null instead.
-     * */
-    @Test(expected = NullPointerException.class)
-    public void testFieldsCannotBeSetToNull() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.fields(null);
-    }
-
-    @Test
-    public void testDefaultFieldParsing() throws IOException {
-        QueryParseContext context = createParseContext();
-        String query = randomAsciiOfLengthBetween(1, 10).toLowerCase(Locale.ROOT);
-        String contentString = "{\n" +
-                "    \"simple_query_string\" : {\n" +
-                "      \"query\" : \"" + query + "\"" +
-                "    }\n" +
-                "}";
-        XContentParser parser = XContentFactory.xContent(contentString).createParser(contentString);
-        context.reset(parser);
-        SimpleQueryStringBuilder queryBuilder = new SimpleQueryStringParser().fromXContent(context);
-        assertThat(queryBuilder.value(), equalTo(query));
-        assertThat(queryBuilder.fields(), notNullValue());
-        assertThat(queryBuilder.fields().size(), equalTo(0));
-        QueryShardContext shardContext = createShardContext();
-
-        // the remaining tests requires either a mapping that we register with types in base test setup
-        // no strict field resolution (version before V_1_4_0_Beta1)
-        if (getCurrentTypes().length > 0 || shardContext.indexQueryParserService().getIndexCreatedVersion().before(Version.V_1_4_0_Beta1)) {
-            Query luceneQuery = queryBuilder.toQuery(shardContext);
-            assertThat(luceneQuery, instanceOf(TermQuery.class));
-            TermQuery termQuery = (TermQuery) luceneQuery;
-            assertThat(termQuery.getTerm(), equalTo(new Term(MetaData.ALL, query)));
-        }
-    }
-
-    /*
-     * This assumes that Lucene query parsing is being checked already, adding
-     * checks only for our parsing extensions.
-     * 
-     * Also this relies on {@link SimpleQueryStringTests} to test most of the
-     * actual functionality of query parsing.
-     */
-    @Override
-    protected void doAssertLuceneQuery(SimpleQueryStringBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, notNullValue());
-
-        if (queryBuilder.fields().size() > 1 && (!"".equals(queryBuilder.value()))) {
-            assertTrue("Query should have been BooleanQuery but was " + query.getClass().getName(), query instanceof BooleanQuery);
-
-            BooleanQuery boolQuery = (BooleanQuery) query;
-            if (queryBuilder.lowercaseExpandedTerms()) {
-                for (BooleanClause clause : boolQuery.clauses()) {
-                    if (clause.getQuery() instanceof TermQuery) {
-                        TermQuery inner = (TermQuery) clause.getQuery();
-                        assertThat(inner.getTerm().bytes().toString(), is(inner.getTerm().bytes().toString().toLowerCase(Locale.ROOT)));
-                    }
-                }
-            }
-
-            assertThat(boolQuery.clauses().size(), equalTo(queryBuilder.fields().size()));
-            Iterator<String> fields = queryBuilder.fields().keySet().iterator();
-            for (BooleanClause booleanClause : boolQuery) {
-                assertThat(booleanClause.getQuery(), instanceOf(TermQuery.class));
-                TermQuery termQuery = (TermQuery) booleanClause.getQuery();
-                assertThat(termQuery.getTerm(), equalTo(new Term(fields.next(), queryBuilder.value().toLowerCase(Locale.ROOT))));
-            }
-
-            if (queryBuilder.minimumShouldMatch() != null) {
-                Collection<String> minMatchAlways = Arrays.asList(new String[] { "1", "-1", "75%", "-25%" });
-                Collection<String> minMatchLarger = Arrays.asList(new String[] { "2<75%", "2<-25%" });
-
-                if (minMatchAlways.contains(queryBuilder.minimumShouldMatch())) {
-                    assertThat(boolQuery.getMinimumNumberShouldMatch(), greaterThan(0));
-                } else if (minMatchLarger.contains(queryBuilder.minimumShouldMatch())) {
-                    if (shouldClauses(boolQuery) > 2) {
-                        assertThat(boolQuery.getMinimumNumberShouldMatch(), greaterThan(0));
-                    }
-                } else {
-                    assertEquals(0, boolQuery.getMinimumNumberShouldMatch());
-                }
-            }
-        } else if (queryBuilder.fields().size() == 1 && (!"".equals(queryBuilder.value()))) {
-            assertTrue("Query should have been TermQuery but was " + query.getClass().getName(), query instanceof TermQuery);
-
-            TermQuery termQuery = (TermQuery) query;
-            assertThat(termQuery.getTerm().field(), is(queryBuilder.fields().keySet().iterator().next()));
-
-            String field;
-            if (queryBuilder.fields().size() == 0) {
-                field = MetaData.ALL;
-            } else {
-                field = queryBuilder.fields().keySet().iterator().next();
-            }
-            assertThat(termQuery.getTerm(), equalTo(new Term(field, queryBuilder.value().toLowerCase(Locale.ROOT))));
-
-            if (queryBuilder.lowercaseExpandedTerms()) {
-                assertThat(termQuery.getTerm().bytes().toString(), is(termQuery.getTerm().bytes().toString().toLowerCase(Locale.ROOT)));
-            }
-
-        } else if ("".equals(queryBuilder.value())) {
-            assertTrue("Query should have been MatchNoDocsQuery but was " + query.getClass().getName(), query instanceof MatchNoDocsQuery);
-        } else {
-            fail("Encountered lucene query type we do not have a validation implementation for in our SimpleQueryStringBuilderTest");
-        }
-    }
-
-    private int shouldClauses(BooleanQuery query) {
-        int result = 0;
-        for (BooleanClause c : query.clauses()) {
-            if (c.getOccur() == BooleanClause.Occur.SHOULD) {
-                result++;
-            }
-        }
-        return result;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTest.java
deleted file mode 100644
index 7429023..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTest.java
+++ /dev/null
@@ -1,71 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanContainingQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanContainingQueryBuilderTest extends BaseQueryTestCase<SpanContainingQueryBuilder> {
-
-    @Override
-    protected SpanContainingQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTest().createSpanTermQueryBuilders(2);
-        return new SpanContainingQueryBuilder(spanTermQueries[0], spanTermQueries[1]);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanContainingQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanContainingQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder bigSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                bigSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                bigSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            bigSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanQueryBuilder littleSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                littleSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                littleSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            littleSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanContainingQueryBuilder queryBuilder = new SpanContainingQueryBuilder(bigSpanQueryBuilder, littleSpanQueryBuilder);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanFirstQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/SpanFirstQueryBuilderTest.java
deleted file mode 100644
index 833bae5..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanFirstQueryBuilderTest.java
+++ /dev/null
@@ -1,108 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanFirstQuery;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.elasticsearch.index.query.QueryBuilders.spanTermQuery;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanFirstQueryBuilderTest extends BaseQueryTestCase<SpanFirstQueryBuilder> {
-
-    @Override
-    protected SpanFirstQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTest().createSpanTermQueryBuilders(1);
-        return new SpanFirstQueryBuilder(spanTermQueries[0], randomIntBetween(0, 1000));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanFirstQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanFirstQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder innerSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                innerSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            innerSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        int end = randomIntBetween(0, 10);
-        if (randomBoolean()) {
-            end = randomIntBetween(-10, -1);
-            totalExpectedErrors++;
-        }
-        SpanFirstQueryBuilder queryBuilder = new SpanFirstQueryBuilder(innerSpanQueryBuilder, end);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-
-    /**
-     * test exception on missing `end` and `match` parameter in parser
-     */
-    @Test
-    public void testParseEnd() throws IOException {
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanFirstQueryBuilder.NAME);
-            builder.field("match");
-            spanTermQuery("description", "jumped").toXContent(builder, null);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string(), SpanFirstQueryBuilder.NAME);
-                fail("missing [end] parameter should raise exception");
-            } catch (QueryParsingException e) {
-                assertTrue(e.getMessage().contains("spanFirst must have [end] set"));
-            }
-        }
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanFirstQueryBuilder.NAME);
-            builder.field("end", 10);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string(), SpanFirstQueryBuilder.NAME);
-                fail("missing [match] parameter should raise exception");
-            } catch (QueryParsingException e) {
-                assertTrue(e.getMessage().contains("spanFirst must have [match] span query clause"));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTest.java
deleted file mode 100644
index b112a08..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTest.java
+++ /dev/null
@@ -1,87 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanMultiTermQueryBuilderTest extends BaseQueryTestCase<SpanMultiTermQueryBuilder> {
-
-    @Override
-    protected SpanMultiTermQueryBuilder doCreateTestQueryBuilder() {
-        MultiTermQueryBuilder multiTermQueryBuilder = RandomQueryBuilder.createMultiTermQuery(random());
-        return new SpanMultiTermQueryBuilder(multiTermQueryBuilder);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanMultiTermQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanMultiTermQueryWrapper.class));
-        SpanMultiTermQueryWrapper spanMultiTermQueryWrapper = (SpanMultiTermQueryWrapper) query;
-        Query multiTermQuery = queryBuilder.innerQuery().toQuery(context);
-        assertThat(multiTermQuery, instanceOf(MultiTermQuery.class));
-        assertThat(spanMultiTermQueryWrapper.getWrappedQuery(), equalTo(new SpanMultiTermQueryWrapper<>((MultiTermQuery)multiTermQuery).getWrappedQuery()));
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        MultiTermQueryBuilder multiTermQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                multiTermQueryBuilder = new RangeQueryBuilder("");
-            } else {
-                multiTermQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            multiTermQueryBuilder = new RangeQueryBuilder("field");
-        }
-        SpanMultiTermQueryBuilder queryBuilder = new SpanMultiTermQueryBuilder(multiTermQueryBuilder);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-
-    /**
-     * test checks that we throw an {@link UnsupportedOperationException} if the query wrapped
-     * by {@link SpanMultiTermQueryBuilder} does not generate a lucene {@link MultiTermQuery}.
-     * This is currently the case for {@link RangeQueryBuilder} when the target field is mapped
-     * to a date.
-     */
-    @Test
-    public void testUnsupportedInnerQueryType() throws IOException {
-        QueryShardContext context = createShardContext();
-        // test makes only sense if we have at least one type registered with date field mapping
-        if (getCurrentTypes().length > 0 && context.fieldMapper(DATE_FIELD_NAME) != null) {
-            try {
-                RangeQueryBuilder query = new RangeQueryBuilder(DATE_FIELD_NAME);
-                new SpanMultiTermQueryBuilder(query).toQuery(createShardContext());
-                fail("Exception expected, range query on date fields should not generate a lucene " + MultiTermQuery.class.getName());
-            } catch (UnsupportedOperationException e) {
-                assert(e.getMessage().contains("unsupported inner query, should be " + MultiTermQuery.class.getName()));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanNearQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/SpanNearQueryBuilderTest.java
deleted file mode 100644
index d2eb1a0..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanNearQueryBuilderTest.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNearQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Iterator;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanNearQueryBuilderTest extends BaseQueryTestCase<SpanNearQueryBuilder> {
-
-    @Override
-    protected SpanNearQueryBuilder doCreateTestQueryBuilder() {
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(randomIntBetween(-10, 10));
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTest().createSpanTermQueryBuilders(randomIntBetween(1, 6));
-        for (SpanTermQueryBuilder clause : spanTermQueries) {
-            queryBuilder.clause(clause);
-        }
-        queryBuilder.inOrder(randomBoolean());
-        queryBuilder.collectPayloads(randomBoolean());
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanNearQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanNearQuery.class));
-        SpanNearQuery spanNearQuery = (SpanNearQuery) query;
-        assertThat(spanNearQuery.getSlop(), equalTo(queryBuilder.slop()));
-        assertThat(spanNearQuery.isInOrder(), equalTo(queryBuilder.inOrder()));
-        assertThat(spanNearQuery.getClauses().length, equalTo(queryBuilder.clauses().size()));
-        Iterator<SpanQueryBuilder> spanQueryBuilderIterator = queryBuilder.clauses().iterator();
-        for (SpanQuery spanQuery : spanNearQuery.getClauses()) {
-            assertThat(spanQuery, equalTo(spanQueryBuilderIterator.next().toQuery(context)));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(1);
-        assertValidate(queryBuilder, 1); // empty clause list
-
-        int totalExpectedErrors = 0;
-        int clauses = randomIntBetween(1, 10);
-        for (int i = 0; i < clauses; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    queryBuilder.clause(new SpanTermQueryBuilder("", "test"));
-                } else {
-                    queryBuilder.clause(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                queryBuilder.clause(new SpanTermQueryBuilder("name", "value"));
-            }
-        }
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanNotQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/SpanNotQueryBuilderTest.java
deleted file mode 100644
index ab0b81e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanNotQueryBuilderTest.java
+++ /dev/null
@@ -1,205 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNotQuery;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.elasticsearch.index.query.QueryBuilders.spanNearQuery;
-import static org.elasticsearch.index.query.QueryBuilders.spanTermQuery;
-import static org.hamcrest.Matchers.*;
-
-public class SpanNotQueryBuilderTest extends BaseQueryTestCase<SpanNotQueryBuilder> {
-
-    @Override
-    protected SpanNotQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTest().createSpanTermQueryBuilders(2);
-        SpanNotQueryBuilder queryBuilder = new SpanNotQueryBuilder(spanTermQueries[0], spanTermQueries[1]);
-        if (randomBoolean()) {
-            // also test negative values, they should implicitly be changed to 0
-            queryBuilder.dist(randomIntBetween(-2, 10));
-        } else {
-            if (randomBoolean()) {
-                queryBuilder.pre(randomIntBetween(-2, 10));
-            }
-            if (randomBoolean()) {
-                queryBuilder.post(randomIntBetween(-2, 10));
-            }
-        }
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanNotQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanNotQuery.class));
-        SpanNotQuery spanNotQuery = (SpanNotQuery) query;
-        assertThat(spanNotQuery.getExclude(), equalTo(queryBuilder.excludeQuery().toQuery(context)));
-        assertThat(spanNotQuery.getInclude(), equalTo(queryBuilder.includeQuery().toQuery(context)));
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder include;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                include = new SpanTermQueryBuilder("", "test");
-            } else {
-                include = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            include = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanQueryBuilder exclude;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                exclude = new SpanTermQueryBuilder("", "test");
-            } else {
-                exclude = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            exclude = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanNotQueryBuilder queryBuilder = new SpanNotQueryBuilder(include, exclude);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-
-    @Test
-    public void testDist() {
-        SpanNotQueryBuilder builder = new SpanNotQueryBuilder(new SpanTermQueryBuilder("name1", "value1"), new SpanTermQueryBuilder("name2", "value2"));
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.dist(-4);
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.dist(4);
-        assertThat(builder.pre(), equalTo(4));
-        assertThat(builder.post(), equalTo(4));
-    }
-
-    @Test
-    public void testPrePost() {
-        SpanNotQueryBuilder builder = new SpanNotQueryBuilder(new SpanTermQueryBuilder("name1", "value1"), new SpanTermQueryBuilder("name2", "value2"));
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.pre(-4).post(-4);
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.pre(1).post(2);
-        assertThat(builder.pre(), equalTo(1));
-        assertThat(builder.post(), equalTo(2));
-    }
-
-    /**
-     * test correct parsing of `dist` parameter, this should create builder with pre/post set to same value
-     */
-    @Test
-    public void testParseDist() throws IOException {
-        XContentBuilder builder = XContentFactory.jsonBuilder();
-        builder.startObject();
-        builder.startObject(SpanNotQueryBuilder.NAME);
-        builder.field("exclude");
-        spanTermQuery("description", "jumped").toXContent(builder, null);
-        builder.field("include");
-        spanNearQuery(1).clause(QueryBuilders.spanTermQuery("description", "quick"))
-                .clause(QueryBuilders.spanTermQuery("description", "fox")).toXContent(builder, null);
-        builder.field("dist", 3);
-        builder.endObject();
-        builder.endObject();
-        SpanNotQueryBuilder query = (SpanNotQueryBuilder)parseQuery(builder.string(), SpanNotQueryBuilder.NAME);
-        assertThat(query.pre(), equalTo(3));
-        assertThat(query.post(), equalTo(3));
-        assertNotNull(query.includeQuery());
-        assertNotNull(query.excludeQuery());
-    }
-
-    /**
-     * test exceptions for three types of broken json, missing include / exclude and both dist and pre/post specified
-     */
-    @Test
-    public void testParserExceptions() throws IOException {
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanNotQueryBuilder.NAME);
-            builder.field("exclude");
-            spanTermQuery("description", "jumped").toXContent(builder, null);
-            builder.field("dist", 2);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string(), SpanNotQueryBuilder.NAME);
-                fail("QueryParsingException should have been caught");
-            } catch (QueryParsingException e) {
-                assertThat("QueryParsingException should have been caught", e.getDetailedMessage(), containsString("spanNot must have [include]"));
-            }
-        }
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanNotQueryBuilder.NAME);
-            builder.field("include");
-            spanNearQuery(1).clause(QueryBuilders.spanTermQuery("description", "quick"))
-                    .clause(QueryBuilders.spanTermQuery("description", "fox")).toXContent(builder, null);
-            builder.field("dist", 2);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string(), SpanNotQueryBuilder.NAME);
-                fail("QueryParsingException should have been caught");
-            } catch (QueryParsingException e) {
-                assertThat("QueryParsingException should have been caught", e.getDetailedMessage(), containsString("spanNot must have [exclude]"));
-            }
-        }
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanNotQueryBuilder.NAME);
-            builder.field("include");
-            spanNearQuery(1).clause(QueryBuilders.spanTermQuery("description", "quick"))
-                    .clause(QueryBuilders.spanTermQuery("description", "fox")).toXContent(builder, null);
-            builder.field("exclude");
-            spanTermQuery("description", "jumped").toXContent(builder, null);
-            builder.field("dist", 2);
-            builder.field("pre", 2);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string(), SpanNotQueryBuilder.NAME);
-                fail("QueryParsingException should have been caught");
-            } catch (QueryParsingException e) {
-                assertThat("QueryParsingException should have been caught", e.getDetailedMessage(), containsString("spanNot can either use [dist] or [pre] & [post] (or none)"));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanOrQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/SpanOrQueryBuilderTest.java
deleted file mode 100644
index 051e6fd..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanOrQueryBuilderTest.java
+++ /dev/null
@@ -1,77 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanOrQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Iterator;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanOrQueryBuilderTest extends BaseQueryTestCase<SpanOrQueryBuilder> {
-
-    @Override
-    protected SpanOrQueryBuilder doCreateTestQueryBuilder() {
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTest().createSpanTermQueryBuilders(randomIntBetween(1, 6));
-        for (SpanTermQueryBuilder clause : spanTermQueries) {
-            queryBuilder.clause(clause);
-        }
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanOrQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanOrQuery.class));
-        SpanOrQuery spanOrQuery = (SpanOrQuery) query;
-        assertThat(spanOrQuery.getClauses().length, equalTo(queryBuilder.clauses().size()));
-        Iterator<SpanQueryBuilder> spanQueryBuilderIterator = queryBuilder.clauses().iterator();
-        for (SpanQuery spanQuery : spanOrQuery.getClauses()) {
-            assertThat(spanQuery, equalTo(spanQueryBuilderIterator.next().toQuery(context)));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        assertValidate(queryBuilder, 1); // empty clause list
-
-        int totalExpectedErrors = 0;
-        int clauses = randomIntBetween(1, 10);
-        for (int i = 0; i < clauses; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    queryBuilder.clause(new SpanTermQueryBuilder("", "test"));
-                } else {
-                    queryBuilder.clause(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                queryBuilder.clause(new SpanTermQueryBuilder("name", "value"));
-            }
-        }
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanTermQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/SpanTermQueryBuilderTest.java
deleted file mode 100644
index 4fc369e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanTermQueryBuilderTest.java
+++ /dev/null
@@ -1,75 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanTermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanTermQueryBuilderTest extends BaseTermQueryTestCase<SpanTermQueryBuilder> {
-
-    @Override
-    protected SpanTermQueryBuilder createQueryBuilder(String fieldName, Object value) {
-        return new SpanTermQueryBuilder(fieldName, value);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanTermQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanTermQuery.class));
-        SpanTermQuery spanTermQuery = (SpanTermQuery) query;
-        assertThat(spanTermQuery.getTerm().field(), equalTo(queryBuilder.fieldName()));
-        MappedFieldType mapper = context.fieldMapper(queryBuilder.fieldName());
-        if (mapper != null) {
-            BytesRef bytesRef = mapper.indexedValueForSearch(queryBuilder.value());
-            assertThat(spanTermQuery.getTerm().bytes(), equalTo(bytesRef));
-        } else {
-            assertThat(spanTermQuery.getTerm().bytes(), equalTo(BytesRefs.toBytesRef(queryBuilder.value())));
-        }
-    }
-
-    /**
-     * @param amount the number of clauses that will be returned
-     * @return an array of random {@link SpanTermQueryBuilder} with same field name
-     */
-    public SpanTermQueryBuilder[] createSpanTermQueryBuilders(int amount) {
-        SpanTermQueryBuilder[] clauses = new SpanTermQueryBuilder[amount];
-        SpanTermQueryBuilder first = createTestQueryBuilder();
-        clauses[0] = first;
-        for (int i = 1; i < amount; i++) {
-            // we need same field name in all clauses, so we only randomize value
-            SpanTermQueryBuilder spanTermQuery = new SpanTermQueryBuilder(first.fieldName(), getRandomValueForFieldName(first.fieldName()));
-            if (randomBoolean()) {
-                spanTermQuery.boost(2.0f / randomIntBetween(1, 20));
-            }
-            if (randomBoolean()) {
-                spanTermQuery.queryName(randomAsciiOfLengthBetween(1, 10));
-            }
-            clauses[i] = spanTermQuery;
-        }
-        return clauses;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanWithinQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/SpanWithinQueryBuilderTest.java
deleted file mode 100644
index ffc518d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanWithinQueryBuilderTest.java
+++ /dev/null
@@ -1,71 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanWithinQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanWithinQueryBuilderTest extends BaseQueryTestCase<SpanWithinQueryBuilder> {
-
-    @Override
-    protected SpanWithinQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTest().createSpanTermQueryBuilders(2);
-        return new SpanWithinQueryBuilder(spanTermQueries[0], spanTermQueries[1]);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanWithinQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanWithinQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder bigSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                bigSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                bigSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            bigSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanQueryBuilder littleSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                littleSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                littleSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            littleSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanWithinQueryBuilder queryBuilder = new SpanWithinQueryBuilder(bigSpanQueryBuilder, littleSpanQueryBuilder);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTest.java b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTest.java
index 045a21b..34c890a 100644
--- a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTest.java
+++ b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTest.java
@@ -21,6 +21,7 @@ package org.elasticsearch.index.query;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.Version;
+import org.elasticsearch.action.ActionModule;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.inject.AbstractModule;
@@ -62,7 +63,7 @@ import java.io.IOException;
 public class TemplateQueryParserTest extends ESTestCase {
 
     private Injector injector;
-    private QueryShardContext context;
+    private QueryParseContext context;
 
     @Before
     public void setup() throws IOException {
@@ -102,7 +103,7 @@ public class TemplateQueryParserTest extends ESTestCase {
         ).createInjector();
 
         IndexQueryParserService queryParserService = injector.getInstance(IndexQueryParserService.class);
-        context = new QueryShardContext(index, queryParserService);
+        context = new QueryParseContext(index, queryParserService);
     }
 
     @Override
diff --git a/core/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTest.java
deleted file mode 100644
index f84d1c0..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTest.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class TermQueryBuilderTest extends BaseTermQueryTestCase<TermQueryBuilder> {
-
-    /**
-     * @return a TermQuery with random field name and value, optional random boost and queryname
-     */
-    @Override
-    protected TermQueryBuilder createQueryBuilder(String fieldName, Object value) {
-        return new TermQueryBuilder(fieldName, value);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(TermQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(TermQuery.class));
-        TermQuery termQuery = (TermQuery) query;
-        assertThat(termQuery.getTerm().field(), equalTo(queryBuilder.fieldName()));
-        MappedFieldType mapper = context.fieldMapper(queryBuilder.fieldName());
-        if (mapper != null) {
-            BytesRef bytesRef = mapper.indexedValueForSearch(queryBuilder.value());
-            assertThat(termQuery.getTerm().bytes(), equalTo(bytesRef));
-        } else {
-            assertThat(termQuery.getTerm().bytes(), equalTo(BytesRefs.toBytesRef(queryBuilder.value())));
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTest.java
deleted file mode 100644
index 4019366..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTest.java
+++ /dev/null
@@ -1,228 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.search.termslookup.TermsLookupFetchService;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
-import org.hamcrest.Matchers;
-import org.junit.Before;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Iterator;
-import java.util.List;
-
-import static org.hamcrest.Matchers.*;
-
-public class TermsQueryBuilderTest extends BaseQueryTestCase<TermsQueryBuilder> {
-
-    private MockTermsLookupFetchService termsLookupFetchService;
-
-    @Before
-    public void mockTermsLookupFetchService() {
-        termsLookupFetchService = new MockTermsLookupFetchService();
-        queryParserService().setTermsLookupFetchService(termsLookupFetchService);
-    }
-
-    @Override
-    protected TermsQueryBuilder doCreateTestQueryBuilder() {
-        TermsQueryBuilder query;
-        // terms query or lookup query
-        if (randomBoolean()) {
-            // make between 0 and 5 different values of the same type
-            String fieldName = getRandomFieldName();
-            Object[] values = new Object[randomInt(5)];
-            for (int i = 0; i < values.length; i++) {
-                values[i] = getRandomValueForFieldName(fieldName);
-            }
-            query = new TermsQueryBuilder(fieldName, values);
-        } else {
-            // right now the mock service returns us a list of strings
-            query = new TermsQueryBuilder(randomBoolean() ? randomAsciiOfLengthBetween(1,10) : STRING_FIELD_NAME);
-            query.termsLookup(randomTermsLookup());
-        }
-        if (randomBoolean()) {
-            query.minimumShouldMatch(randomInt(100) + "%");
-        }
-        if (randomBoolean()) {
-            query.disableCoord(randomBoolean());
-        }
-        return query;
-    }
-
-    private TermsLookup randomTermsLookup() {
-        return new TermsLookup(
-                randomBoolean() ? randomAsciiOfLength(10) : null,
-                randomAsciiOfLength(10),
-                randomAsciiOfLength(10),
-                randomAsciiOfLength(10)
-        ).routing(randomBoolean() ? randomAsciiOfLength(10) : null);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(TermsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(BooleanQuery.class));
-        BooleanQuery booleanQuery = (BooleanQuery) query;
-
-        // we only do the check below for string fields (otherwise we'd have to decode the values)
-        if (queryBuilder.fieldName().equals(INT_FIELD_NAME) || queryBuilder.fieldName().equals(DOUBLE_FIELD_NAME)
-                || queryBuilder.fieldName().equals(BOOLEAN_FIELD_NAME) || queryBuilder.fieldName().equals(DATE_FIELD_NAME)) {
-            return;
-        }
-
-        // expected returned terms depending on whether we have a terms query or a terms lookup query
-        List<Object> terms;
-        if (queryBuilder.termsLookup() != null) {
-            terms = termsLookupFetchService.getRandomTerms();
-        } else {
-            terms = queryBuilder.values();
-        }
-
-        // compare whether we have the expected list of terms returned
-        Iterator<Object> iter = terms.iterator();
-        for (BooleanClause booleanClause : booleanQuery) {
-            assertThat(booleanClause.getQuery(), instanceOf(TermQuery.class));
-            Term term = ((TermQuery) booleanClause.getQuery()).getTerm();
-            Object next = iter.next();
-            if (next == null) {
-                continue;
-            }
-            assertThat(term, equalTo(new Term(queryBuilder.fieldName(), next.toString())));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        TermsQueryBuilder termsQueryBuilder = new TermsQueryBuilder(null, "term");
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        termsQueryBuilder = new TermsQueryBuilder("field", "term").termsLookup(randomTermsLookup());
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        termsQueryBuilder = new TermsQueryBuilder(null, "term").termsLookup(randomTermsLookup());
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(2));
-
-        termsQueryBuilder = new TermsQueryBuilder("field", "term");
-        assertNull(termsQueryBuilder.validate());
-    }
-
-    @Test
-    public void testValidateLookupQuery() {
-        TermsQueryBuilder termsQuery = new TermsQueryBuilder("field").termsLookup(new TermsLookup());
-        int totalExpectedErrors = 3;
-        if (randomBoolean()) {
-            termsQuery.lookupId("id");
-            totalExpectedErrors--;
-        }
-        if (randomBoolean()) {
-            termsQuery.lookupType("type");
-            totalExpectedErrors--;
-        }
-        if (randomBoolean()) {
-            termsQuery.lookupPath("path");
-            totalExpectedErrors--;
-        }
-        assertValidate(termsQuery, totalExpectedErrors);
-    }
-
-    @Test
-    public void testNullValues() {
-        try {
-            switch (randomInt(6)) {
-                case 0:
-                    new TermsQueryBuilder("field", (String[]) null);
-                    break;
-                case 1:
-                    new TermsQueryBuilder("field", (int[]) null);
-                    break;
-                case 2:
-                    new TermsQueryBuilder("field", (long[]) null);
-                    break;
-                case 3:
-                    new TermsQueryBuilder("field", (float[]) null);
-                    break;
-                case 4:
-                    new TermsQueryBuilder("field", (double[]) null);
-                    break;
-                case 5:
-                    new TermsQueryBuilder("field", (Object[]) null);
-                    break;
-                default:
-                    new TermsQueryBuilder("field", (Iterable<?>) null);
-                    break;
-            }
-            fail("should have failed with IllegalArgumentException");
-        } catch (IllegalArgumentException e) {
-            assertThat(e.getMessage(), Matchers.containsString("No value specified for terms query"));
-        }
-    }
-
-    @Test
-    public void testBothValuesAndLookupSet() throws IOException {
-        String query = "{\n" +
-                "  \"terms\": {\n" +
-                "    \"field\": [\n" +
-                "      \"blue\",\n" +
-                "      \"pill\"\n" +
-                "    ],\n" +
-                "    \"field_lookup\": {\n" +
-                "      \"index\": \"pills\",\n" +
-                "      \"type\": \"red\",\n" +
-                "      \"id\": \"3\",\n" +
-                "      \"path\": \"white rabbit\"\n" +
-                "    }\n" +
-                "  }\n" +
-                "}";
-        QueryBuilder termsQueryBuilder = parseQuery(query, TermsQueryBuilder.NAME);
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-
-    private static class MockTermsLookupFetchService extends TermsLookupFetchService {
-
-        private List<Object> randomTerms = new ArrayList<>();
-
-        MockTermsLookupFetchService() {
-            super(null, Settings.Builder.EMPTY_SETTINGS);
-            String[] strings = generateRandomStringArray(10, 10, false, true);
-            for (String string : strings) {
-                randomTerms.add(string);
-                if (rarely()) {
-                    randomTerms.add(null);
-                }
-            }
-        }
-
-        @Override
-        public List<Object> fetch(TermsLookup termsLookup) {
-            return randomTerms;
-        }
-
-        List<Object> getRandomTerms() {
-            return randomTerms;
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTest.java
deleted file mode 100644
index 18c5534..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTest.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.*;
-
-public class TypeQueryBuilderTest extends BaseQueryTestCase<TypeQueryBuilder> {
-
-    @Override
-    protected TypeQueryBuilder doCreateTestQueryBuilder() {
-        return new TypeQueryBuilder(getRandomType());
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(TypeQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, either(instanceOf(TermQuery.class)).or(instanceOf(ConstantScoreQuery.class)));
-        if (query instanceof ConstantScoreQuery) {
-            query = ((ConstantScoreQuery) query).getQuery();
-            assertThat(query, instanceOf(TermQuery.class));
-        }
-        TermQuery termQuery = (TermQuery) query;
-        assertThat(termQuery.getTerm().field(), equalTo(TypeFieldMapper.NAME));
-        assertThat(termQuery.getTerm().text(), equalTo(queryBuilder.type()));
-    }
-
-    @Test
-    public void testValidate() {
-        TypeQueryBuilder typeQueryBuilder = new TypeQueryBuilder((String) null);
-        assertThat(typeQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/WildcardQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/WildcardQueryBuilderTest.java
deleted file mode 100644
index ba23249..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/WildcardQueryBuilderTest.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.WildcardQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class WildcardQueryBuilderTest extends BaseQueryTestCase<WildcardQueryBuilder> {
-
-    @Override
-    protected WildcardQueryBuilder doCreateTestQueryBuilder() {
-        WildcardQueryBuilder query;
-
-        // mapped or unmapped field
-        String text = randomAsciiOfLengthBetween(1, 10);
-        if (randomBoolean()) {
-            query = new WildcardQueryBuilder(STRING_FIELD_NAME, text);
-        } else {
-            query = new WildcardQueryBuilder(randomAsciiOfLengthBetween(1, 10), text);
-        }
-        if (randomBoolean()) {
-            query.rewrite(randomFrom(getRandomRewriteMethod()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(WildcardQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(WildcardQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        WildcardQueryBuilder wildcardQueryBuilder = new WildcardQueryBuilder("", "text");
-        assertThat(wildcardQueryBuilder.validate().validationErrors().size(), is(1));
-
-        wildcardQueryBuilder = new WildcardQueryBuilder("field", null);
-        assertThat(wildcardQueryBuilder.validate().validationErrors().size(), is(1));
-
-        wildcardQueryBuilder = new WildcardQueryBuilder(null, null);
-        assertThat(wildcardQueryBuilder.validate().validationErrors().size(), is(2));
-
-        wildcardQueryBuilder = new WildcardQueryBuilder("field", "text");
-        assertNull(wildcardQueryBuilder.validate());
-    }
-
-    @Test
-    public void testEmptyValue() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-
-        WildcardQueryBuilder wildcardQueryBuilder = new WildcardQueryBuilder(getRandomType(), "");
-        assertEquals(wildcardQueryBuilder.toQuery(context).getClass(), WildcardQuery.class);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTest.java b/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTest.java
deleted file mode 100644
index d18204f..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTest.java
+++ /dev/null
@@ -1,77 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.is;
-
-public class WrapperQueryBuilderTest extends BaseQueryTestCase<WrapperQueryBuilder> {
-
-    @Override
-    protected boolean supportsBoostAndQueryName() {
-        return false;
-    }
-
-    @Override
-    protected WrapperQueryBuilder doCreateTestQueryBuilder() {
-        QueryBuilder wrappedQuery = RandomQueryBuilder.createQuery(random());
-        switch (randomInt(2)) {
-            case 0:
-                return new WrapperQueryBuilder(wrappedQuery.toString());
-            case 1:
-                return new WrapperQueryBuilder(wrappedQuery.buildAsBytes().toBytes());
-            case 2:
-                return new WrapperQueryBuilder(wrappedQuery.buildAsBytes());
-            default:
-                throw new UnsupportedOperationException();
-        }
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(WrapperQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        try (XContentParser qSourceParser = XContentFactory.xContent(queryBuilder.source()).createParser(queryBuilder.source())) {
-            final QueryShardContext contextCopy = new QueryShardContext(context.index(), context.indexQueryParserService());
-            contextCopy.reset(qSourceParser);
-            QueryBuilder result = contextCopy.parseContext().parseInnerQueryBuilder();
-            context.combineNamedQueries(contextCopy);
-            Query expected = result.toQuery(context);
-            if (expected != null) {
-                expected.setBoost(AbstractQueryBuilder.DEFAULT_BOOST);
-            }
-            assertThat(query, equalTo(expected));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        WrapperQueryBuilder wrapperQueryBuilder = new WrapperQueryBuilder((byte[]) null);
-        assertThat(wrapperQueryBuilder.validate().validationErrors().size(), is(1));
-
-        wrapperQueryBuilder = new WrapperQueryBuilder("");
-        assertThat(wrapperQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java b/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java
index 80cea9c..dbbc358 100644
--- a/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java
+++ b/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java
@@ -25,7 +25,10 @@ import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Weight;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.QueryBuilder;
+import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParser;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.indices.IndicesModule;
 import org.elasticsearch.plugins.Plugin;
 
@@ -47,36 +50,24 @@ public class DummyQueryParserPlugin extends Plugin {
         module.registerQueryParser(DummyQueryParser.class);
     }
 
-    public static class DummyQueryBuilder extends AbstractQueryBuilder<DummyQueryBuilder> {
-        private static final String NAME = "dummy";
-
+    public static class DummyQueryBuilder extends QueryBuilder {
         @Override
         protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-            builder.startObject(NAME).endObject();
-        }
-
-        @Override
-        public String getWriteableName() {
-            return NAME;
+            builder.startObject("dummy").endObject();
         }
     }
 
-    public static class DummyQueryParser extends BaseQueryParserTemp {
+    public static class DummyQueryParser implements QueryParser {
         @Override
         public String[] names() {
-            return new String[]{DummyQueryBuilder.NAME};
+            return new String[]{"dummy"};
         }
 
         @Override
-        public Query parse(QueryShardContext context) throws IOException, QueryShardException {
-            XContentParser.Token token = context.parseContext().parser().nextToken();
+        public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
+            XContentParser.Token token = parseContext.parser().nextToken();
             assert token == XContentParser.Token.END_OBJECT;
-            return new DummyQuery(context.isFilter());
-        }
-
-        @Override
-        public DummyQueryBuilder getBuilderPrototype() {
-            return new DummyQueryBuilder();
+            return new DummyQuery(parseContext.isFilter());
         }
     }
 
diff --git a/core/src/test/java/org/elasticsearch/index/query/simple-query-string.json b/core/src/test/java/org/elasticsearch/index/query/simple-query-string.json
new file mode 100644
index 0000000..9208e88
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/query/simple-query-string.json
@@ -0,0 +1,8 @@
+{
+  "simple_query_string": {
+    "query": "foo bar",
+    "analyzer": "keyword",
+    "fields": ["body^5","_all"],
+    "default_operator": "and"
+  }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/AbstractChildTestCase.java b/core/src/test/java/org/elasticsearch/index/search/child/AbstractChildTestCase.java
index c69220f..c7dd274 100644
--- a/core/src/test/java/org/elasticsearch/index/search/child/AbstractChildTestCase.java
+++ b/core/src/test/java/org/elasticsearch/index/search/child/AbstractChildTestCase.java
@@ -19,19 +19,14 @@
 
 package org.elasticsearch.index.search.child;
 
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.search.*;
 import org.apache.lucene.search.join.BitDocIdSetFilter;
 import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.BitSet;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.compress.CompressedXContent;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -40,7 +35,7 @@ import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.test.ESSingleNodeTestCase;
 import org.hamcrest.Description;
@@ -71,7 +66,7 @@ public abstract class AbstractChildTestCase extends ESSingleNodeTestCase {
         mapperService.merge(childType, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(childType, "_parent", "type=" + parentType, CHILD_SCORE_NAME, "type=double,doc_values=false").string()), true, false);
         return createSearchContext(indexService);
     }
-
+    
     static void assertBitSet(BitSet actual, BitSet expected, IndexSearcher searcher) throws IOException {
         assertBitSet(new BitDocIdSet(actual), new BitDocIdSet(expected), searcher);
     }
@@ -88,7 +83,7 @@ public abstract class AbstractChildTestCase extends ESSingleNodeTestCase {
             throw new java.lang.AssertionError(description.toString());
         }
     }
-
+    
     static boolean equals(BitDocIdSet expected, BitDocIdSet actual) {
         if (actual == null && expected == null) {
             return true;
@@ -140,10 +135,10 @@ public abstract class AbstractChildTestCase extends ESSingleNodeTestCase {
     }
 
     static Query parseQuery(QueryBuilder queryBuilder) throws IOException {
-        QueryShardContext context = new QueryShardContext(new Index("test"), SearchContext.current().queryParserService());
+        QueryParseContext context = new QueryParseContext(new Index("test"), SearchContext.current().queryParserService());
         XContentParser parser = XContentHelper.createParser(queryBuilder.buildAsBytes());
         context.reset(parser);
-        return context.parseContext().parseInnerQuery();
+        return context.parseInnerQuery();
     }
 
 }
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java
index 2a74fb9..2577de5 100644
--- a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java
+++ b/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java
@@ -20,26 +20,12 @@ package org.elasticsearch.index.search.child;
 
 import com.carrotsearch.hppc.IntHashSet;
 import com.carrotsearch.hppc.ObjectObjectHashMap;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowCompositeReaderWrapper;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.*;
 import org.apache.lucene.search.join.BitDocIdSetFilter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.FixedBitSet;
@@ -53,7 +39,6 @@ import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
 import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.search.internal.ContextIndexSearcher;
 import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.test.TestSearchContext;
 import org.junit.AfterClass;
@@ -65,11 +50,7 @@ import java.util.NavigableSet;
 import java.util.Random;
 import java.util.TreeSet;
 
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.filteredQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasChildQuery;
-import static org.elasticsearch.index.query.QueryBuilders.notQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.hamcrest.Matchers.equalTo;
 
 public class ChildrenConstantScoreQueryTests extends AbstractChildTestCase {
@@ -119,9 +100,9 @@ public class ChildrenConstantScoreQueryTests extends AbstractChildTestCase {
 
         IndexReader indexReader = DirectoryReader.open(indexWriter.w, false);
         IndexSearcher searcher = new IndexSearcher(indexReader);
-        ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(
-                SearchContext.current(), new Engine.Searcher(ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher)
-        ));
+        ((TestSearchContext) SearchContext.current()).setSearcher(
+                new Engine.Searcher(ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher)
+        );
 
         TermQuery childQuery = new TermQuery(new Term("field1", "value" + (1 + random().nextInt(3))));
         BitDocIdSetFilter parentFilter = wrapWithBitSetFilter(new QueryWrapperFilter(new TermQuery(new Term(TypeFieldMapper.NAME, "parent"))));
@@ -214,7 +195,7 @@ public class ChildrenConstantScoreQueryTests extends AbstractChildTestCase {
         Engine.Searcher engineSearcher = new Engine.Searcher(
                 ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher
         );
-        ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+        ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
 
         int max = numUniqueChildValues / 4;
         for (int i = 0; i < max; i++) {
@@ -243,7 +224,7 @@ public class ChildrenConstantScoreQueryTests extends AbstractChildTestCase {
                 engineSearcher = new Engine.Searcher(
                         ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher
                 );
-                ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+                ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
             }
 
             String childValue = childValues[random().nextInt(numUniqueChildValues)];
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java
index 9e70f66..60a98ff 100644
--- a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java
+++ b/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java
@@ -22,34 +22,13 @@ import com.carrotsearch.hppc.FloatArrayList;
 import com.carrotsearch.hppc.IntHashSet;
 import com.carrotsearch.hppc.ObjectObjectHashMap;
 import com.carrotsearch.randomizedtesting.generators.RandomInts;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.DoubleField;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowCompositeReaderWrapper;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.LeafCollector;
-import org.apache.lucene.search.MultiCollector;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.search.TopScoreDocCollector;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.*;
 import org.apache.lucene.search.join.BitDocIdSetFilter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.FixedBitSet;
@@ -65,7 +44,6 @@ import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.functionscore.fieldvaluefactor.FieldValueFactorFunctionBuilder;
-import org.elasticsearch.search.internal.ContextIndexSearcher;
 import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.test.TestSearchContext;
 import org.junit.AfterClass;
@@ -73,19 +51,9 @@ import org.junit.BeforeClass;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.Locale;
-import java.util.Map;
-import java.util.NavigableMap;
-import java.util.Random;
-import java.util.TreeMap;
-
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.filteredQuery;
-import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasChildQuery;
-import static org.elasticsearch.index.query.QueryBuilders.notQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.index.query.QueryBuilders.typeQuery;
+import java.util.*;
+
+import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.hamcrest.Matchers.is;
 import static org.hamcrest.Matchers.lessThanOrEqualTo;
 
@@ -195,7 +163,7 @@ public class ChildrenQueryTests extends AbstractChildTestCase {
         Engine.Searcher engineSearcher = new Engine.Searcher(
                 ChildrenQueryTests.class.getSimpleName(), searcher
         );
-        ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+        ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
 
         int max = numUniqueChildValues / 4;
         for (int i = 0; i < max; i++) {
@@ -224,7 +192,7 @@ public class ChildrenQueryTests extends AbstractChildTestCase {
                 engineSearcher = new Engine.Searcher(
                         ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher
                 );
-                ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+                ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
             }
 
             String childValue = childValues[random().nextInt(numUniqueChildValues)];
@@ -385,7 +353,7 @@ public class ChildrenQueryTests extends AbstractChildTestCase {
 
         // setup to read the parent/child map
         Engine.Searcher engineSearcher = new Engine.Searcher(ChildrenQueryTests.class.getSimpleName(), searcher);
-        ((TestSearchContext)context).setSearcher(new ContextIndexSearcher(context, engineSearcher));
+        ((TestSearchContext)context).setSearcher(engineSearcher);
 
         // child query that returns the score as the value of "childScore" for each child document, with the parent's score determined by the score type
         QueryBuilder childQueryBuilder = functionScoreQuery(typeQuery("child")).add(new FieldValueFactorFunctionBuilder(CHILD_SCORE_NAME));
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java
index ac5c3a4..55047d8 100644
--- a/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java
+++ b/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java
@@ -20,26 +20,12 @@ package org.elasticsearch.index.search.child;
 
 import com.carrotsearch.hppc.IntIntHashMap;
 import com.carrotsearch.hppc.ObjectObjectHashMap;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowCompositeReaderWrapper;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.*;
 import org.apache.lucene.search.join.BitDocIdSetFilter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.FixedBitSet;
@@ -52,7 +38,6 @@ import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
 import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.search.internal.ContextIndexSearcher;
 import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.test.TestSearchContext;
 import org.junit.AfterClass;
@@ -64,11 +49,7 @@ import java.util.NavigableSet;
 import java.util.Random;
 import java.util.TreeSet;
 
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.filteredQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasParentQuery;
-import static org.elasticsearch.index.query.QueryBuilders.notQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 
 /**
  */
@@ -173,7 +154,7 @@ public class ParentConstantScoreQueryTests extends AbstractChildTestCase {
         Engine.Searcher engineSearcher = new Engine.Searcher(
                 ParentConstantScoreQuery.class.getSimpleName(), searcher
         );
-        ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+        ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
 
         int max = numUniqueParentValues / 4;
         for (int i = 0; i < max; i++) {
@@ -200,7 +181,7 @@ public class ParentConstantScoreQueryTests extends AbstractChildTestCase {
                 engineSearcher = new Engine.Searcher(
                         ParentConstantScoreQueryTests.class.getSimpleName(), searcher
                 );
-                ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+                ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
             }
 
             String parentValue = parentValues[random().nextInt(numUniqueParentValues)];
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java
index 836ddf3..3fd6384 100644
--- a/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java
+++ b/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java
@@ -21,30 +21,12 @@ package org.elasticsearch.index.search.child;
 import com.carrotsearch.hppc.FloatArrayList;
 import com.carrotsearch.hppc.IntIntHashMap;
 import com.carrotsearch.hppc.ObjectObjectHashMap;
-
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.SlowCompositeReaderWrapper;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.LeafCollector;
-import org.apache.lucene.search.MultiCollector;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.TopScoreDocCollector;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.*;
 import org.apache.lucene.search.join.BitDocIdSetFilter;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.FixedBitSet;
@@ -57,7 +39,6 @@ import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
 import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.search.internal.ContextIndexSearcher;
 import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.test.TestSearchContext;
 import org.junit.AfterClass;
@@ -70,11 +51,7 @@ import java.util.NavigableMap;
 import java.util.Random;
 import java.util.TreeMap;
 
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.filteredQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasParentQuery;
-import static org.elasticsearch.index.query.QueryBuilders.notQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 
 public class ParentQueryTests extends AbstractChildTestCase {
 
@@ -175,7 +152,7 @@ public class ParentQueryTests extends AbstractChildTestCase {
         Engine.Searcher engineSearcher = new Engine.Searcher(
                 ParentQueryTests.class.getSimpleName(), searcher
         );
-        ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+        ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
 
         int max = numUniqueParentValues / 4;
         for (int i = 0; i < max; i++) {
@@ -202,7 +179,7 @@ public class ParentQueryTests extends AbstractChildTestCase {
                 engineSearcher = new Engine.Searcher(
                         ParentConstantScoreQueryTests.class.getSimpleName(), searcher
                 );
-                ((TestSearchContext) SearchContext.current()).setSearcher(new ContextIndexSearcher(SearchContext.current(), engineSearcher));
+                ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
             }
 
             String parentValue = parentValues[random().nextInt(numUniqueParentValues)];
diff --git a/core/src/test/java/org/elasticsearch/index/shard/CommitPointsTests.java b/core/src/test/java/org/elasticsearch/index/shard/CommitPointsTests.java
index 5a84bb0..68bcc4d 100644
--- a/core/src/test/java/org/elasticsearch/index/shard/CommitPointsTests.java
+++ b/core/src/test/java/org/elasticsearch/index/shard/CommitPointsTests.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.index.shard;
 
 import com.google.common.base.Charsets;
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.test.ESTestCase;
@@ -28,7 +27,6 @@ import org.junit.Test;
 
 import java.util.ArrayList;
 
-import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.nullValue;
 
@@ -41,11 +39,11 @@ public class CommitPointsTests extends ESTestCase {
 
     @Test
     public void testCommitPointXContent() throws Exception {
-        ArrayList<CommitPoint.FileInfo> indexFiles = Lists.newArrayList();
+        ArrayList<CommitPoint.FileInfo> indexFiles = new ArrayList<>();
         indexFiles.add(new CommitPoint.FileInfo("file1", "file1_p", 100, "ck1"));
         indexFiles.add(new CommitPoint.FileInfo("file2", "file2_p", 200, "ck2"));
 
-        ArrayList<CommitPoint.FileInfo> translogFiles = Lists.newArrayList();
+        ArrayList<CommitPoint.FileInfo> translogFiles = new ArrayList<>();
         translogFiles.add(new CommitPoint.FileInfo("t_file1", "t_file1_p", 100, null));
         translogFiles.add(new CommitPoint.FileInfo("t_file2", "t_file2_p", 200, null));
 
diff --git a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
index 43edf58..3ec7311 100644
--- a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
+++ b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
@@ -20,9 +20,12 @@ package org.elasticsearch.index.shard;
 
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.store.LockObtainFailedException;
+import org.apache.lucene.util.Constants;
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.Version;
+import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags;
 import org.elasticsearch.action.admin.indices.stats.IndexStats;
+import org.elasticsearch.action.admin.indices.stats.ShardStats;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.action.support.IndicesOptions;
 import org.elasticsearch.cluster.*;
@@ -31,11 +34,16 @@ import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.ShardRoutingState;
 import org.elasticsearch.cluster.routing.TestShardRouting;
 import org.elasticsearch.common.bytes.BytesArray;
+import org.elasticsearch.common.io.stream.BytesStreamOutput;
+import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.env.Environment;
 import org.elasticsearch.env.NodeEnvironment;
 import org.elasticsearch.env.ShardLock;
+import org.elasticsearch.index.Index;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.query.QueryParsingException;
@@ -57,9 +65,7 @@ import java.util.HashSet;
 import java.util.Set;
 import java.util.concurrent.ExecutionException;
 
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_VERSION_CREATED;
+import static org.elasticsearch.cluster.metadata.IndexMetaData.*;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
@@ -541,4 +547,36 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         assertPathHasBeenCleared(startDir.toAbsolutePath().toString());
         assertPathHasBeenCleared(endDir.toAbsolutePath().toString());
     }
+
+    public void testShardStats() throws IOException {
+        createIndex("test");
+        ensureGreen();
+        IndicesService indicesService = getInstanceFromNode(IndicesService.class);
+        IndexService test = indicesService.indexService("test");
+        IndexShard shard = test.shard(0);
+        ShardStats stats = new ShardStats(shard, new CommonStatsFlags());
+        assertEquals(shard.shardPath().getRootDataPath().toString(), stats.getDataPath());
+        assertEquals(shard.shardPath().getRootStatePath().toString(), stats.getStatePath());
+        assertEquals(shard.shardPath().isCustomDataPath(), stats.isCustomDataPath());
+
+        if (randomBoolean() || true) { // try to serialize it to ensure values survive the serialization
+            BytesStreamOutput out = new BytesStreamOutput();
+            stats.writeTo(out);
+            StreamInput in = StreamInput.wrap(out.bytes());
+            stats = ShardStats.readShardStats(in);
+        }
+        XContentBuilder builder = XContentFactory.jsonBuilder();
+        builder.startObject();
+        stats.toXContent(builder, EMPTY_PARAMS);
+        builder.endObject();
+        String xContent = builder.string();
+        StringBuilder expectedSubSequence = new StringBuilder("\"shard_path\":{\"state_path\":\"");
+        expectedSubSequence.append(shard.shardPath().getRootStatePath().toString());
+        expectedSubSequence.append("\",\"data_path\":\"");
+        expectedSubSequence.append(shard.shardPath().getRootDataPath().toString());
+        expectedSubSequence.append("\",\"is_custom_data_path\":").append(shard.shardPath().isCustomDataPath()).append("}");
+        assumeFalse("Some path weirdness on windows", Constants.WINDOWS);
+        assertTrue(xContent.contains(expectedSubSequence));
+    }
+
 }
diff --git a/core/src/test/java/org/elasticsearch/index/shard/ShardPathTests.java b/core/src/test/java/org/elasticsearch/index/shard/ShardPathTests.java
index e03698f..32d2019 100644
--- a/core/src/test/java/org/elasticsearch/index/shard/ShardPathTests.java
+++ b/core/src/test/java/org/elasticsearch/index/shard/ShardPathTests.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.index.shard;
 
+import com.carrotsearch.randomizedtesting.annotations.Repeat;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.env.NodeEnvironment;
@@ -26,6 +27,7 @@ import org.junit.Test;
 
 import java.io.IOException;
 import java.nio.file.Path;
+import java.util.Set;
 
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 
@@ -78,4 +80,71 @@ public class ShardPathTests extends ESTestCase {
         }
     }
 
+    @Test(expected = IllegalArgumentException.class)
+    public void testIllegalCustomDataPath() {
+        final Path path = createTempDir().resolve("foo").resolve("0");
+        new ShardPath(true, path, path, "foo", new ShardId("foo", 0));
+    }
+
+    public void testValidCtor() {
+        final Path path = createTempDir().resolve("foo").resolve("0");
+        ShardPath shardPath = new ShardPath(false, path, path, "foo", new ShardId("foo", 0));
+        assertFalse(shardPath.isCustomDataPath());
+        assertEquals(shardPath.getDataPath(), path);
+        assertEquals(shardPath.getShardStatePath(), path);
+    }
+
+    public void testGetRootPaths() throws IOException {
+        boolean useCustomDataPath = randomBoolean();
+        final Settings indexSetttings;
+        final Settings nodeSettings;
+        Settings.Builder indexSettingsBuilder = settingsBuilder().put(IndexMetaData.SETTING_INDEX_UUID, "0xDEADBEEF");
+        final Path customPath;
+        if (useCustomDataPath) {
+            final Path path = createTempDir();
+            final boolean includeNodeId = randomBoolean();
+            indexSetttings = indexSettingsBuilder.put(IndexMetaData.SETTING_DATA_PATH, "custom").build();
+            nodeSettings = settingsBuilder().put("path.shared_data", path.toAbsolutePath().toAbsolutePath())
+                    .put(NodeEnvironment.ADD_NODE_ID_TO_CUSTOM_PATH, includeNodeId).build();
+            if (includeNodeId) {
+                customPath = path.resolve("custom").resolve("0");
+            } else {
+                customPath = path.resolve("custom");
+            }
+        } else {
+            customPath = null;
+            indexSetttings = indexSettingsBuilder.build();
+            nodeSettings = Settings.EMPTY;
+        }
+        try (final NodeEnvironment env = newNodeEnvironment(nodeSettings)) {
+            ShardId shardId = new ShardId("foo", 0);
+            Path[] paths = env.availableShardPaths(shardId);
+            Path path = randomFrom(paths);
+            ShardStateMetaData.FORMAT.write(new ShardStateMetaData(2, true, "0xDEADBEEF"), 2, path);
+            ShardPath shardPath = ShardPath.loadShardPath(logger, env, shardId, indexSetttings);
+            boolean found = false;
+            for (Path p : env.nodeDataPaths()) {
+                if (p.equals(shardPath.getRootStatePath())) {
+                    found = true;
+                    break;
+                }
+            }
+            assertTrue("root state paths must be a node path but wasn't: " + shardPath.getRootStatePath(), found);
+            found = false;
+            if (useCustomDataPath) {
+                assertNotEquals(shardPath.getRootDataPath(), shardPath.getRootStatePath());
+                assertEquals(customPath, shardPath.getRootDataPath());
+            } else {
+                assertNull(customPath);
+                for (Path p : env.nodeDataPaths()) {
+                    if (p.equals(shardPath.getRootDataPath())) {
+                        found = true;
+                        break;
+                    }
+                }
+                assertTrue("root state paths must be a node path but wasn't: " + shardPath.getRootDataPath(), found);
+            }
+        }
+    }
+
 }
diff --git a/core/src/test/java/org/elasticsearch/index/store/CorruptedFileIT.java b/core/src/test/java/org/elasticsearch/index/store/CorruptedFileIT.java
index b9d0074..6ca68c6 100644
--- a/core/src/test/java/org/elasticsearch/index/store/CorruptedFileIT.java
+++ b/core/src/test/java/org/elasticsearch/index/store/CorruptedFileIT.java
@@ -21,12 +21,14 @@ package org.elasticsearch.index.store;
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
 import com.google.common.base.Charsets;
 import com.google.common.base.Predicate;
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.codecs.CodecUtil;
 import org.apache.lucene.index.CheckIndex;
 import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.store.*;
+import org.apache.lucene.store.ChecksumIndexInput;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.FSDirectory;
+import org.apache.lucene.store.IOContext;
+import org.apache.lucene.store.IndexInput;
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;
 import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
@@ -40,7 +42,11 @@ import org.elasticsearch.client.Requests;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
-import org.elasticsearch.cluster.routing.*;
+import org.elasticsearch.cluster.routing.GroupShardsIterator;
+import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
+import org.elasticsearch.cluster.routing.ShardIterator;
+import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.cluster.routing.ShardRoutingState;
 import org.elasticsearch.cluster.routing.allocation.decider.EnableAllocationDecider;
 import org.elasticsearch.cluster.routing.allocation.decider.ThrottlingAllocationDecider;
 import org.elasticsearch.common.Nullable;
@@ -53,7 +59,10 @@ import org.elasticsearch.common.unit.ByteSizeUnit;
 import org.elasticsearch.discovery.Discovery;
 import org.elasticsearch.gateway.PrimaryShardAllocator;
 import org.elasticsearch.index.settings.IndexSettings;
-import org.elasticsearch.index.shard.*;
+import org.elasticsearch.index.shard.IndexShard;
+import org.elasticsearch.index.shard.IndexShardState;
+import org.elasticsearch.index.shard.MergePolicyConfig;
+import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.index.translog.TranslogService;
 import org.elasticsearch.indices.IndicesLifecycle;
 import org.elasticsearch.indices.IndicesService;
@@ -66,7 +75,10 @@ import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.InternalTestCluster;
 import org.elasticsearch.test.store.MockFSDirectoryService;
 import org.elasticsearch.test.transport.MockTransportService;
-import org.elasticsearch.transport.*;
+import org.elasticsearch.transport.TransportException;
+import org.elasticsearch.transport.TransportRequest;
+import org.elasticsearch.transport.TransportRequestOptions;
+import org.elasticsearch.transport.TransportService;
 import org.junit.Test;
 
 import java.io.IOException;
@@ -78,7 +90,13 @@ import java.nio.file.DirectoryStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.StandardOpenOption;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.TreeSet;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutionException;
@@ -86,6 +104,7 @@ import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
+import static org.elasticsearch.common.util.CollectionUtils.iterableAsArrayList;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.hamcrest.Matchers.*;
 
@@ -595,7 +614,7 @@ public class CorruptedFileIT extends ESIntegTestCase {
     private ShardRouting corruptRandomPrimaryFile(final boolean includePerCommitFiles) throws IOException {
         ClusterState state = client().admin().cluster().prepareState().get().getState();
         GroupShardsIterator shardIterators = state.getRoutingNodes().getRoutingTable().activePrimaryShardsGrouped(new String[]{"test"}, false);
-        List<ShardIterator> iterators = Lists.newArrayList(shardIterators);
+        List<ShardIterator> iterators = iterableAsArrayList(shardIterators);
         ShardIterator shardIterator = RandomPicks.randomFrom(getRandom(), iterators);
         ShardRouting shardRouting = shardIterator.nextOrNull();
         assertNotNull(shardRouting);
diff --git a/core/src/test/java/org/elasticsearch/index/store/CorruptedTranslogIT.java b/core/src/test/java/org/elasticsearch/index/store/CorruptedTranslogIT.java
index 04b0ed3..f0fda71 100644
--- a/core/src/test/java/org/elasticsearch/index/store/CorruptedTranslogIT.java
+++ b/core/src/test/java/org/elasticsearch/index/store/CorruptedTranslogIT.java
@@ -19,9 +19,7 @@
 
 package org.elasticsearch.index.store;
 
-import com.google.common.collect.Lists;
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-
 import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
@@ -38,18 +36,21 @@ import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.engine.MockEngineSupport;
 import org.elasticsearch.test.junit.annotations.TestLogging;
 import org.elasticsearch.test.transport.MockTransportService;
-import org.elasticsearch.transport.TransportModule;
 import org.junit.Test;
 
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.nio.channels.FileChannel;
-import java.nio.file.*;
+import java.nio.file.DirectoryStream;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.StandardOpenOption;
 import java.util.Arrays;
 import java.util.List;
 import java.util.Set;
 import java.util.TreeSet;
 
+import static org.elasticsearch.common.util.CollectionUtils.iterableAsArrayList;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.hamcrest.Matchers.notNullValue;
@@ -115,7 +116,7 @@ public class CorruptedTranslogIT extends ESIntegTestCase {
     private void corruptRandomTranslogFiles() throws IOException {
         ClusterState state = client().admin().cluster().prepareState().get().getState();
         GroupShardsIterator shardIterators = state.getRoutingNodes().getRoutingTable().activePrimaryShardsGrouped(new String[]{"test"}, false);
-        List<ShardIterator> iterators = Lists.newArrayList(shardIterators);
+        List<ShardIterator> iterators = iterableAsArrayList(shardIterators);
         ShardIterator shardIterator = RandomPicks.randomFrom(getRandom(), iterators);
         ShardRouting shardRouting = shardIterator.nextOrNull();
         assertNotNull(shardRouting);
diff --git a/core/src/test/java/org/elasticsearch/index/store/IndexStoreTests.java b/core/src/test/java/org/elasticsearch/index/store/IndexStoreTests.java
index 7523792..e921f95 100644
--- a/core/src/test/java/org/elasticsearch/index/store/IndexStoreTests.java
+++ b/core/src/test/java/org/elasticsearch/index/store/IndexStoreTests.java
@@ -35,11 +35,11 @@ import java.util.Locale;
 public class IndexStoreTests extends ESTestCase {
 
     public void testStoreDirectory() throws IOException {
-        final Path tempDir = createTempDir();
+        final Path tempDir = createTempDir().resolve("foo").resolve("0");
         final IndexStoreModule.Type[] values = IndexStoreModule.Type.values();
         final IndexStoreModule.Type type = RandomPicks.randomFrom(random(), values);
         Settings settings = Settings.settingsBuilder().put(IndexStoreModule.STORE_TYPE, type.name().toLowerCase(Locale.ROOT)).build();
-        FsDirectoryService service = new FsDirectoryService(settings, null, new ShardPath(tempDir, tempDir, "foo", new ShardId("foo", 0)));
+        FsDirectoryService service = new FsDirectoryService(settings, null, new ShardPath(false, tempDir, tempDir, "foo", new ShardId("foo", 0)));
         try (final Directory directory = service.newFSDirectory(tempDir, NoLockFactory.INSTANCE)) {
             switch (type) {
                 case NIOFS:
@@ -70,9 +70,9 @@ public class IndexStoreTests extends ESTestCase {
     }
 
     public void testStoreDirectoryDefault() throws IOException {
-        final Path tempDir = createTempDir();
+        final Path tempDir = createTempDir().resolve("foo").resolve("0");
         Settings settings = Settings.EMPTY;
-        FsDirectoryService service = new FsDirectoryService(settings, null, new ShardPath(tempDir, tempDir, "foo", new ShardId("foo", 0)));
+        FsDirectoryService service = new FsDirectoryService(settings, null, new ShardPath(false, tempDir, tempDir, "foo", new ShardId("foo", 0)));
         try (final Directory directory = service.newFSDirectory(tempDir, NoLockFactory.INSTANCE)) {
             if (Constants.WINDOWS) {
                 assertTrue(directory.toString(), directory instanceof MMapDirectory || directory instanceof SimpleFSDirectory);
diff --git a/core/src/test/java/org/elasticsearch/index/translog/TranslogTests.java b/core/src/test/java/org/elasticsearch/index/translog/TranslogTests.java
index 06fa074..c7ebedf 100644
--- a/core/src/test/java/org/elasticsearch/index/translog/TranslogTests.java
+++ b/core/src/test/java/org/elasticsearch/index/translog/TranslogTests.java
@@ -53,9 +53,25 @@ import java.io.InputStream;
 import java.nio.ByteBuffer;
 import java.nio.channels.FileChannel;
 import java.nio.charset.Charset;
-import java.nio.file.*;
-import java.util.*;
-import java.util.concurrent.*;
+import java.nio.file.DirectoryStream;
+import java.nio.file.Files;
+import java.nio.file.InvalidPathException;
+import java.nio.file.Path;
+import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.ArrayBlockingQueue;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.BrokenBarrierException;
+import java.util.concurrent.CopyOnWriteArrayList;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.CyclicBarrier;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
@@ -63,7 +79,6 @@ import java.util.concurrent.atomic.AtomicReference;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.hamcrest.Matchers.*;
 
 /**
@@ -546,7 +561,7 @@ public class TranslogTests extends ESTestCase {
 
     @Test
     public void testTranslogChecksums() throws Exception {
-        List<Translog.Location> locations = newArrayList();
+        List<Translog.Location> locations = new ArrayList<>();
 
         int translogOperations = randomIntBetween(10, 100);
         for (int op = 0; op < translogOperations; op++) {
@@ -570,7 +585,7 @@ public class TranslogTests extends ESTestCase {
 
     @Test
     public void testTruncatedTranslogs() throws Exception {
-        List<Translog.Location> locations = newArrayList();
+        List<Translog.Location> locations = new ArrayList<>();
 
         int translogOperations = randomIntBetween(10, 100);
         for (int op = 0; op < translogOperations; op++) {
@@ -855,7 +870,7 @@ public class TranslogTests extends ESTestCase {
     }
 
     public void testLocationComparison() throws IOException {
-        List<Translog.Location> locations = newArrayList();
+        List<Translog.Location> locations = new ArrayList<>();
         int translogOperations = randomIntBetween(10, 100);
         int count = 0;
         for (int op = 0; op < translogOperations; op++) {
@@ -884,7 +899,7 @@ public class TranslogTests extends ESTestCase {
 
 
     public void testBasicCheckpoint() throws IOException {
-        List<Translog.Location> locations = newArrayList();
+        List<Translog.Location> locations = new ArrayList<>();
         int translogOperations = randomIntBetween(10, 100);
         int lastSynced = -1;
         for (int op = 0; op < translogOperations; op++) {
@@ -970,7 +985,7 @@ public class TranslogTests extends ESTestCase {
     }
 
     public void testBasicRecovery() throws IOException {
-        List<Translog.Location> locations = newArrayList();
+        List<Translog.Location> locations = new ArrayList<>();
         int translogOperations = randomIntBetween(10, 100);
         Translog.TranslogGeneration translogGeneration = null;
         int minUncommittedOp = -1;
@@ -1012,7 +1027,7 @@ public class TranslogTests extends ESTestCase {
     }
 
     public void testRecoveryUncommitted() throws IOException {
-        List<Translog.Location> locations = newArrayList();
+        List<Translog.Location> locations = new ArrayList<>();
         int translogOperations = randomIntBetween(10, 100);
         final int prepareOp = randomIntBetween(0, translogOperations-1);
         Translog.TranslogGeneration translogGeneration = null;
@@ -1066,7 +1081,7 @@ public class TranslogTests extends ESTestCase {
 
     public void testSnapshotFromStreamInput() throws IOException {
         BytesStreamOutput out = new BytesStreamOutput();
-        List<Translog.Operation> ops = newArrayList();
+        List<Translog.Operation> ops = new ArrayList<>();
         int translogOperations = randomIntBetween(10, 100);
         for (int op = 0; op < translogOperations; op++) {
             Translog.Create test = new Translog.Create("test", "" + op, Integer.toString(op).getBytes(Charset.forName("UTF-8")));
@@ -1079,8 +1094,8 @@ public class TranslogTests extends ESTestCase {
     }
 
     public void testLocationHashCodeEquals() throws IOException {
-        List<Translog.Location> locations = newArrayList();
-        List<Translog.Location> locations2 = newArrayList();
+        List<Translog.Location> locations = new ArrayList<>();
+        List<Translog.Location> locations2 = new ArrayList<>();
         int translogOperations = randomIntBetween(10, 100);
         try(Translog translog2 = create(createTempDir())) {
             for (int op = 0; op < translogOperations; op++) {
@@ -1107,7 +1122,7 @@ public class TranslogTests extends ESTestCase {
     }
 
     public void testOpenForeignTranslog() throws IOException {
-        List<Translog.Location> locations = newArrayList();
+        List<Translog.Location> locations = new ArrayList<>();
         int translogOperations = randomIntBetween(1, 10);
         int firstUncommitted = 0;
         for (int op = 0; op < translogOperations; op++) {
diff --git a/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java b/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java
index fcba11a..7727d8c 100644
--- a/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java
+++ b/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java
@@ -23,7 +23,10 @@ import org.apache.lucene.analysis.hunspell.Dictionary;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.ModuleTestCase;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParser;
+import org.elasticsearch.index.query.QueryParsingException;
+import org.elasticsearch.index.query.TermQueryParser;
 
 import java.io.IOException;
 import java.io.InputStream;
@@ -36,19 +39,8 @@ public class IndicesModuleTests extends ModuleTestCase {
         public String[] names() {
             return new String[] {"fake-query-parser"};
         }
-
-        @Override
-        public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-            return null;
-        }
-
-        @Override
-        public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-            return null;
-        }
-
         @Override
-        public QueryBuilder getBuilderPrototype() {
+        public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
             return null;
         }
     }
diff --git a/core/src/test/java/org/elasticsearch/indices/analysis/PreBuiltAnalyzerIntegrationIT.java b/core/src/test/java/org/elasticsearch/indices/analysis/PreBuiltAnalyzerIntegrationIT.java
index 839fc59..c27a507 100644
--- a/core/src/test/java/org/elasticsearch/indices/analysis/PreBuiltAnalyzerIntegrationIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/analysis/PreBuiltAnalyzerIntegrationIT.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.indices.analysis;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.apache.lucene.analysis.Analyzer;
 import org.elasticsearch.Version;
@@ -30,6 +29,7 @@ import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
 import java.lang.reflect.Field;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
@@ -54,7 +54,7 @@ public class PreBuiltAnalyzerIntegrationIT extends ESIntegTestCase {
     @Test
     public void testThatPreBuiltAnalyzersAreNotClosedOnIndexClose() throws Exception {
         Map<PreBuiltAnalyzers, List<Version>> loadedAnalyzers = Maps.newHashMap();
-        List<String> indexNames = Lists.newArrayList();
+        List<String> indexNames = new ArrayList<>();
         final int numIndices = scaledRandomIntBetween(2, 4);
         for (int i = 0; i < numIndices; i++) {
             String indexName = randomAsciiOfLength(10).toLowerCase(Locale.ROOT);
@@ -66,7 +66,7 @@ public class PreBuiltAnalyzerIntegrationIT extends ESIntegTestCase {
 
             Version randomVersion = randomVersion(random());
             if (!loadedAnalyzers.containsKey(preBuiltAnalyzer)) {
-                 loadedAnalyzers.put(preBuiltAnalyzer, Lists.<Version>newArrayList());
+                 loadedAnalyzers.put(preBuiltAnalyzer, new ArrayList<Version>());
             }
             loadedAnalyzers.get(preBuiltAnalyzer).add(randomVersion);
 
diff --git a/core/src/test/java/org/elasticsearch/indices/analyze/AnalyzeActionIT.java b/core/src/test/java/org/elasticsearch/indices/analyze/AnalyzeActionIT.java
index db46e82..c632fa2 100644
--- a/core/src/test/java/org/elasticsearch/indices/analyze/AnalyzeActionIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/analyze/AnalyzeActionIT.java
@@ -253,7 +253,7 @@ public class AnalyzeActionIT extends ESIntegTestCase {
         ensureGreen();
 
         client().admin().indices().preparePutMapping("test")
-            .setType("document").setSource("simple", "type=string,analyzer=simple,position_offset_gap=100").get();
+            .setType("document").setSource("simple", "type=string,analyzer=simple,position_increment_gap=100").get();
 
         String[] texts = new String[]{"THIS IS A TEST", "THE SECOND TEXT"};
 
diff --git a/core/src/test/java/org/elasticsearch/indices/mapping/UpdateMappingIntegrationIT.java b/core/src/test/java/org/elasticsearch/indices/mapping/UpdateMappingIntegrationIT.java
index 71ccf68..a7ad928 100644
--- a/core/src/test/java/org/elasticsearch/indices/mapping/UpdateMappingIntegrationIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/mapping/UpdateMappingIntegrationIT.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.indices.mapping;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.action.admin.indices.mapping.get.GetMappingsResponse;
 import org.elasticsearch.action.admin.indices.mapping.put.PutMappingResponse;
 import org.elasticsearch.action.admin.indices.refresh.RefreshResponse;
@@ -39,13 +37,15 @@ import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
 import org.hamcrest.Matchers;
 import org.junit.Test;
 
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+import java.util.Map;
 import java.util.concurrent.CyclicBarrier;
 import java.util.concurrent.atomic.AtomicBoolean;
 
 import static org.elasticsearch.cluster.metadata.IndexMetaData.*;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.hamcrest.Matchers.*;
 
@@ -64,7 +64,7 @@ public class UpdateMappingIntegrationIT extends ESIntegTestCase {
 
         int recCount = randomIntBetween(200, 600);
         int numberOfTypes = randomIntBetween(1, 5);
-        List<IndexRequestBuilder> indexRequests = Lists.newArrayList();
+        List<IndexRequestBuilder> indexRequests = new ArrayList<>();
         for (int rec = 0; rec < recCount; rec++) {
             String type = "type" + (rec % numberOfTypes);
             String fieldName = "field_" + type + "_" + rec;
diff --git a/core/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerNoopIT.java b/core/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerNoopIT.java
index 29e057d..4992b9f 100644
--- a/core/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerNoopIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerNoopIT.java
@@ -27,9 +27,9 @@ import org.elasticsearch.search.sort.SortOrder;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
@@ -59,7 +59,7 @@ public class CircuitBreakerNoopIT extends ESIntegTestCase {
 
         // index some different terms so we have some field data for loading
         int docCount = scaledRandomIntBetween(300, 1000);
-        List<IndexRequestBuilder> reqs = newArrayList();
+        List<IndexRequestBuilder> reqs = new ArrayList<>();
         for (long id = 0; id < docCount; id++) {
             reqs.add(client.prepareIndex("cb-test", "type", Long.toString(id)).setSource("test", id));
         }
@@ -77,7 +77,7 @@ public class CircuitBreakerNoopIT extends ESIntegTestCase {
 
         // index some different terms so we have some field data for loading
         int docCount = scaledRandomIntBetween(300, 1000);
-        List<IndexRequestBuilder> reqs = newArrayList();
+        List<IndexRequestBuilder> reqs = new ArrayList<>();
         for (long id = 0; id < docCount; id++) {
             reqs.add(client.prepareIndex("cb-test", "type", Long.toString(id)).setSource("test", id));
         }
diff --git a/core/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceIT.java b/core/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceIT.java
index fb9e9cb..4ffe636 100644
--- a/core/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/memory/breaker/CircuitBreakerServiceIT.java
@@ -40,10 +40,10 @@ import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.TimeUnit;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
@@ -111,7 +111,7 @@ public class CircuitBreakerServiceIT extends ESIntegTestCase {
 
         // index some different terms so we have some field data for loading
         int docCount = scaledRandomIntBetween(300, 1000);
-        List<IndexRequestBuilder> reqs = newArrayList();
+        List<IndexRequestBuilder> reqs = new ArrayList<>();
         for (long id = 0; id < docCount; id++) {
             reqs.add(client.prepareIndex("cb-test", "type", Long.toString(id)).setSource("test", "value" + id));
         }
@@ -158,7 +158,7 @@ public class CircuitBreakerServiceIT extends ESIntegTestCase {
 
         // index some different terms so we have some field data for loading
         int docCount = scaledRandomIntBetween(300, 1000);
-        List<IndexRequestBuilder> reqs = newArrayList();
+        List<IndexRequestBuilder> reqs = new ArrayList<>();
         for (long id = 0; id < docCount; id++) {
             reqs.add(client.prepareIndex("ramtest", "type", Long.toString(id)).setSource("test", "value" + id));
         }
@@ -207,7 +207,7 @@ public class CircuitBreakerServiceIT extends ESIntegTestCase {
 
         // index some different terms so we have some field data for loading
         int docCount = scaledRandomIntBetween(300, 1000);
-        List<IndexRequestBuilder> reqs = newArrayList();
+        List<IndexRequestBuilder> reqs = new ArrayList<>();
         for (long id = 0; id < docCount; id++) {
             reqs.add(client.prepareIndex("cb-test", "type", Long.toString(id)).setSource("test", "value" + id));
         }
@@ -273,7 +273,7 @@ public class CircuitBreakerServiceIT extends ESIntegTestCase {
 
         // index some different terms so we have some field data for loading
         int docCount = scaledRandomIntBetween(300, 1000);
-        List<IndexRequestBuilder> reqs = newArrayList();
+        List<IndexRequestBuilder> reqs = new ArrayList<>();
         for (long id = 0; id < docCount; id++) {
             reqs.add(client.prepareIndex("cb-test", "type", Long.toString(id)).setSource("test", id));
         }
diff --git a/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java b/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java
index b818525..4ffc09b 100644
--- a/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/template/SimpleIndexTemplateIT.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.indices.template;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.action.ActionRequestValidationException;
@@ -41,6 +40,7 @@ import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 import java.util.Set;
@@ -235,7 +235,7 @@ public class SimpleIndexTemplateIT extends ESIntegTestCase {
         GetIndexTemplatesResponse getTemplate1Response = client().admin().indices().prepareGetTemplates("template_*").execute().actionGet();
         assertThat(getTemplate1Response.getIndexTemplates(), hasSize(2));
 
-        List<String> templateNames = Lists.newArrayList();
+        List<String> templateNames = new ArrayList<>();
         templateNames.add(getTemplate1Response.getIndexTemplates().get(0).name());
         templateNames.add(getTemplate1Response.getIndexTemplates().get(1).name());
         assertThat(templateNames, containsInAnyOrder("template_1", "template_2"));
@@ -244,7 +244,7 @@ public class SimpleIndexTemplateIT extends ESIntegTestCase {
         getTemplate1Response = client().admin().indices().prepareGetTemplates("template*").execute().actionGet();
         assertThat(getTemplate1Response.getIndexTemplates(), hasSize(3));
 
-        templateNames = Lists.newArrayList();
+        templateNames = new ArrayList<>();
         templateNames.add(getTemplate1Response.getIndexTemplates().get(0).name());
         templateNames.add(getTemplate1Response.getIndexTemplates().get(1).name());
         templateNames.add(getTemplate1Response.getIndexTemplates().get(2).name());
@@ -254,7 +254,7 @@ public class SimpleIndexTemplateIT extends ESIntegTestCase {
         getTemplate1Response = client().admin().indices().prepareGetTemplates("template_1", "template_2").execute().actionGet();
         assertThat(getTemplate1Response.getIndexTemplates(), hasSize(2));
 
-        templateNames = Lists.newArrayList();
+        templateNames = new ArrayList<>();
         templateNames.add(getTemplate1Response.getIndexTemplates().get(0).name());
         templateNames.add(getTemplate1Response.getIndexTemplates().get(1).name());
         assertThat(templateNames, containsInAnyOrder("template_1", "template_2"));
diff --git a/core/src/test/java/org/elasticsearch/indices/warmer/SimpleIndicesWarmerIT.java b/core/src/test/java/org/elasticsearch/indices/warmer/SimpleIndicesWarmerIT.java
index 6179af7..695845b 100644
--- a/core/src/test/java/org/elasticsearch/indices/warmer/SimpleIndicesWarmerIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/warmer/SimpleIndicesWarmerIT.java
@@ -173,6 +173,18 @@ public class SimpleIndicesWarmerIT extends ESIntegTestCase {
         }
     }
 
+    @Test // issue 8991
+    public void deleteAllIndexWarmerDoesNotThrowWhenNoWarmers() {
+        createIndex("test");
+        DeleteWarmerResponse deleteWarmerResponse = client().admin().indices().prepareDeleteWarmer()
+                .setIndices("test").setNames("_all").execute().actionGet();
+        assertThat(deleteWarmerResponse.isAcknowledged(), equalTo(true));
+
+        deleteWarmerResponse = client().admin().indices().prepareDeleteWarmer()
+                .setIndices("test").setNames("foo", "_all", "bar").execute().actionGet();
+        assertThat(deleteWarmerResponse.isAcknowledged(), equalTo(true));
+    }
+
     @Test
     public void deleteIndexWarmerTest() {
         createIndex("test");
diff --git a/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java b/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java
index cb64437..77a4b63 100644
--- a/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java
@@ -26,7 +26,6 @@ import org.elasticsearch.client.Requests;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.MatchQueryBuilder;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
@@ -361,7 +360,7 @@ public class MultiPercolatorIT extends ESIntegTestCase {
         ensureGreen("nestedindex");
 
         client().prepareIndex("nestedindex", PercolatorService.TYPE_NAME, "Q").setSource(jsonBuilder().startObject()
-                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(Operator.AND)).scoreMode("avg")).endObject()).get();
+                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(MatchQueryBuilder.Operator.AND)).scoreMode("avg")).endObject()).get();
 
         refresh();
 
diff --git a/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java b/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java
index f250e92..ecee193 100644
--- a/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java
@@ -23,8 +23,8 @@ import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.percolate.PercolateResponse;
 import org.elasticsearch.action.percolate.PercolateSourceBuilder;
 import org.elasticsearch.index.percolator.PercolatorException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.test.ESIntegTestCase;
-import org.elasticsearch.index.query.QueryShardException;
 import org.junit.Test;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
@@ -67,7 +67,7 @@ public class PercolatorBackwardsCompatibilityIT extends ESIntegTestCase {
             fail();
         } catch (PercolatorException e) {
             e.printStackTrace();
-            assertThat(e.getRootCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getRootCause(), instanceOf(QueryParsingException.class));
         }
     }
 
diff --git a/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java b/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
index 004771a..fb37a0d 100644
--- a/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
@@ -42,9 +42,8 @@ import org.elasticsearch.index.engine.DocumentMissingException;
 import org.elasticsearch.index.engine.VersionConflictEngineException;
 import org.elasticsearch.index.percolator.PercolatorException;
 import org.elasticsearch.index.query.MatchQueryBuilder;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.factor.FactorBuilder;
 import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 import org.elasticsearch.rest.RestStatus;
@@ -1765,7 +1764,7 @@ public class PercolatorIT extends ESIntegTestCase {
                     .get();
             fail();
         } catch (PercolatorException e) {
-            assertThat(e.getRootCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getRootCause(), instanceOf(QueryParsingException.class));
         }
 
         try {
@@ -1774,7 +1773,7 @@ public class PercolatorIT extends ESIntegTestCase {
                     .get();
             fail();
         } catch (PercolatorException e) {
-            assertThat(e.getRootCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getRootCause(), instanceOf(QueryParsingException.class));
         }
     }
 
@@ -1813,7 +1812,7 @@ public class PercolatorIT extends ESIntegTestCase {
         ensureGreen("nestedindex");
 
         client().prepareIndex("nestedindex", PercolatorService.TYPE_NAME, "Q").setSource(jsonBuilder().startObject()
-                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(Operator.AND)).scoreMode("avg")).endObject()).get();
+                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(MatchQueryBuilder.Operator.AND)).scoreMode("avg")).endObject()).get();
 
         refresh();
 
@@ -2017,7 +2016,7 @@ public class PercolatorIT extends ESIntegTestCase {
                     .execute().actionGet();
             fail("Expected a parse error, because inner_hits isn't supported in the percolate api");
         } catch (Exception e) {
-            assertThat(e.getCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getCause(), instanceOf(QueryParsingException.class));
             assertThat(e.getCause().getMessage(), containsString("inner_hits unsupported"));
         }
     }
diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginInfoTests.java b/core/src/test/java/org/elasticsearch/plugins/PluginInfoTests.java
index 58180b2..2321694 100644
--- a/core/src/test/java/org/elasticsearch/plugins/PluginInfoTests.java
+++ b/core/src/test/java/org/elasticsearch/plugins/PluginInfoTests.java
@@ -20,8 +20,6 @@
 package org.elasticsearch.plugins;
 
 import com.google.common.base.Function;
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.cluster.node.info.PluginsInfo;
 import org.elasticsearch.test.ESTestCase;
@@ -33,6 +31,7 @@ import java.nio.file.Path;
 import java.util.List;
 import java.util.Properties;
 
+import static org.elasticsearch.common.util.CollectionUtils.eagerTransform;
 import static org.hamcrest.Matchers.contains;
 
 public class PluginInfoTests extends ESTestCase {
@@ -282,7 +281,7 @@ public class PluginInfoTests extends ESTestCase {
         pluginsInfo.add(new PluginInfo("d", "foo", true, "dummy", true, "dummyclass", true));
 
         final List<PluginInfo> infos = pluginsInfo.getInfos();
-        List<String> names = Lists.transform(infos, new Function<PluginInfo, String>() {
+        List<String> names = eagerTransform(infos, new Function<PluginInfo, String>() {
             @Override
             public String apply(PluginInfo input) {
                 return input.getName();
diff --git a/core/src/test/java/org/elasticsearch/rest/RestFilterChainTests.java b/core/src/test/java/org/elasticsearch/rest/RestFilterChainTests.java
index a8ad99d..5760c28 100644
--- a/core/src/test/java/org/elasticsearch/rest/RestFilterChainTests.java
+++ b/core/src/test/java/org/elasticsearch/rest/RestFilterChainTests.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.rest;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
@@ -30,7 +29,12 @@ import org.elasticsearch.test.rest.FakeRestRequest;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
@@ -57,7 +61,7 @@ public class RestFilterChainTests extends ESTestCase {
             restController.registerFilter(testFilter);
         }
 
-        ArrayList<RestFilter> restFiltersByOrder = Lists.newArrayList(filters);
+        ArrayList<RestFilter> restFiltersByOrder = new ArrayList<>(filters);
         Collections.sort(restFiltersByOrder, new Comparator<RestFilter>() {
             @Override
             public int compare(RestFilter o1, RestFilter o2) {
@@ -65,7 +69,7 @@ public class RestFilterChainTests extends ESTestCase {
             }
         });
 
-        List<RestFilter> expectedRestFilters = Lists.newArrayList();
+        List<RestFilter> expectedRestFilters = new ArrayList<>();
         for (RestFilter filter : restFiltersByOrder) {
             TestFilter testFilter = (TestFilter) filter;
             expectedRestFilters.add(testFilter);
@@ -87,7 +91,7 @@ public class RestFilterChainTests extends ESTestCase {
         assertThat(fakeRestChannel.await(), equalTo(true));
 
 
-        List<TestFilter> testFiltersByLastExecution = Lists.newArrayList();
+        List<TestFilter> testFiltersByLastExecution = new ArrayList<>();
         for (RestFilter restFilter : filters) {
             testFiltersByLastExecution.add((TestFilter)restFilter);
         }
@@ -98,7 +102,7 @@ public class RestFilterChainTests extends ESTestCase {
             }
         });
 
-        ArrayList<TestFilter> finalTestFilters = Lists.newArrayList();
+        ArrayList<TestFilter> finalTestFilters = new ArrayList<>();
         for (RestFilter filter : testFiltersByLastExecution) {
             TestFilter testFilter = (TestFilter) filter;
             finalTestFilters.add(testFilter);
diff --git a/core/src/test/java/org/elasticsearch/script/GroovyScriptIT.java b/core/src/test/java/org/elasticsearch/script/GroovyScriptIT.java
index 8df2c20..ed4c999 100644
--- a/core/src/test/java/org/elasticsearch/script/GroovyScriptIT.java
+++ b/core/src/test/java/org/elasticsearch/script/GroovyScriptIT.java
@@ -28,18 +28,12 @@ import org.elasticsearch.script.groovy.GroovyScriptEngineService;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
-import static org.elasticsearch.index.query.QueryBuilders.scriptQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertOrderedSearchHits;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHits;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.hamcrest.Matchers.equalTo;
 
 /**
@@ -67,7 +61,7 @@ public class GroovyScriptIT extends ESIntegTestCase {
 
     @Test
     public void testGroovyExceptionSerialization() throws Exception {
-        List<IndexRequestBuilder> reqs = newArrayList();
+        List<IndexRequestBuilder> reqs = new ArrayList<>();
         for (int i = 0; i < randomIntBetween(50, 500); i++) {
             reqs.add(client().prepareIndex("test", "doc", "" + i).setSource("foo", "bar"));
         }
diff --git a/core/src/test/java/org/elasticsearch/script/NativeScriptTests.java b/core/src/test/java/org/elasticsearch/script/NativeScriptTests.java
index 3c35a28..e0a7d4b 100644
--- a/core/src/test/java/org/elasticsearch/script/NativeScriptTests.java
+++ b/core/src/test/java/org/elasticsearch/script/NativeScriptTests.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.script;
 
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.inject.Injector;
 import org.elasticsearch.common.inject.ModulesBuilder;
@@ -36,6 +35,7 @@ import org.elasticsearch.watcher.ResourceWatcherService;
 import org.junit.Test;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Set;
@@ -83,7 +83,7 @@ public class NativeScriptTests extends ESTestCase {
         Map<String, NativeScriptFactory> nativeScriptFactoryMap = new HashMap<>();
         nativeScriptFactoryMap.put("my", new MyNativeScriptFactory());
         Set<ScriptEngineService> scriptEngineServices = ImmutableSet.<ScriptEngineService>of(new NativeScriptEngineService(settings, nativeScriptFactoryMap));
-        ScriptContextRegistry scriptContextRegistry = new ScriptContextRegistry(Lists.<ScriptContext.Plugin>newArrayList());
+        ScriptContextRegistry scriptContextRegistry = new ScriptContextRegistry(new ArrayList<ScriptContext.Plugin>());
         ScriptService scriptService = new ScriptService(settings, environment, scriptEngineServices, resourceWatcherService, scriptContextRegistry);
 
         for (ScriptContext scriptContext : scriptContextRegistry.scriptContexts()) {
diff --git a/core/src/test/java/org/elasticsearch/script/ScriptContextRegistryTests.java b/core/src/test/java/org/elasticsearch/script/ScriptContextRegistryTests.java
index 8bb77b4..c7d3a52 100644
--- a/core/src/test/java/org/elasticsearch/script/ScriptContextRegistryTests.java
+++ b/core/src/test/java/org/elasticsearch/script/ScriptContextRegistryTests.java
@@ -19,12 +19,13 @@
 
 package org.elasticsearch.script;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.test.ESTestCase;
 import org.hamcrest.Matchers;
 import org.junit.Test;
 
 import java.io.IOException;
+import java.util.Arrays;
+import java.util.Collections;
 
 public class ScriptContextRegistryTests extends ESTestCase {
 
@@ -33,7 +34,7 @@ public class ScriptContextRegistryTests extends ESTestCase {
         for (final String rejectedContext : ScriptContextRegistry.RESERVED_SCRIPT_CONTEXTS) {
             try {
                 //try to register a prohibited script context
-                new ScriptContextRegistry(Lists.newArrayList(new ScriptContext.Plugin("test", rejectedContext)));
+                new ScriptContextRegistry(Arrays.asList(new ScriptContext.Plugin("test", rejectedContext)));
                 fail("ScriptContextRegistry initialization should have failed");
             } catch(IllegalArgumentException e) {
                 assertThat(e.getMessage(), Matchers.containsString("[" + rejectedContext + "] is a reserved name, it cannot be registered as a custom script context"));
@@ -46,7 +47,7 @@ public class ScriptContextRegistryTests extends ESTestCase {
         for (final String rejectedContext : ScriptContextRegistry.RESERVED_SCRIPT_CONTEXTS) {
             try {
                 //try to register a prohibited script context
-                new ScriptContextRegistry(Lists.newArrayList(new ScriptContext.Plugin(rejectedContext, "test")));
+                new ScriptContextRegistry(Collections.singleton(new ScriptContext.Plugin(rejectedContext, "test")));
                 fail("ScriptContextRegistry initialization should have failed");
             } catch(IllegalArgumentException e) {
                 assertThat(e.getMessage(), Matchers.containsString("[" + rejectedContext + "] is a reserved name, it cannot be registered as a custom script context"));
@@ -68,7 +69,7 @@ public class ScriptContextRegistryTests extends ESTestCase {
     public void testDuplicatedPluginScriptContexts() throws IOException {
         try {
             //try to register a prohibited script context
-            new ScriptContextRegistry(Lists.newArrayList(new ScriptContext.Plugin("testplugin", "test"), new ScriptContext.Plugin("testplugin", "test")));
+            new ScriptContextRegistry(Arrays.asList(new ScriptContext.Plugin("testplugin", "test"), new ScriptContext.Plugin("testplugin", "test")));
             fail("ScriptContextRegistry initialization should have failed");
         } catch(IllegalArgumentException e) {
             assertThat(e.getMessage(), Matchers.containsString("script context [testplugin_test] cannot be registered twice"));
@@ -77,6 +78,6 @@ public class ScriptContextRegistryTests extends ESTestCase {
 
     @Test
     public void testNonDuplicatedPluginScriptContexts() throws IOException {
-        new ScriptContextRegistry(Lists.newArrayList(new ScriptContext.Plugin("testplugin1", "test"), new ScriptContext.Plugin("testplugin2", "test")));
+        new ScriptContextRegistry(Arrays.asList(new ScriptContext.Plugin("testplugin1", "test"), new ScriptContext.Plugin("testplugin2", "test")));
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/AggregationsIntegrationIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/AggregationsIntegrationIT.java
index 8944294..e395b0a 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/AggregationsIntegrationIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/AggregationsIntegrationIT.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.search.aggregations;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.SearchResponse;
@@ -28,6 +27,7 @@ import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.search.aggregations.bucket.terms.Terms;
 import org.elasticsearch.test.ESIntegTestCase;
 
+import java.util.ArrayList;
 import java.util.List;
 
 import static org.elasticsearch.search.aggregations.AggregationBuilders.terms;
@@ -45,7 +45,7 @@ public class AggregationsIntegrationIT extends ESIntegTestCase {
         assertAcked(prepareCreate("index").addMapping("type", "f", "type=string").get());
         ensureYellow("index");
         numDocs = randomIntBetween(1, 20);
-        List<IndexRequestBuilder> docs = Lists.newArrayList();
+        List<IndexRequestBuilder> docs = new ArrayList<>();
         for (int i = 0; i < numDocs; ++i) {
             docs.add(client().prepareIndex("index", "type").setSource("f", Integer.toString(i / 3)));
         }
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/EquivalenceIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/EquivalenceIT.java
index abe88af..0d881fe 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/EquivalenceIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/EquivalenceIT.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.search.aggregations;
 
 import com.carrotsearch.hppc.IntHashSet;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchRequestBuilder;
@@ -49,19 +48,8 @@ import java.util.List;
 import java.util.Map;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.extendedStats;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.filter;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.max;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.min;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.percentiles;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.range;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.stats;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.sum;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.terms;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAllSuccessful;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
+import static org.elasticsearch.search.aggregations.AggregationBuilders.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.core.IsNull.notNullValue;
 
@@ -202,7 +190,7 @@ public class EquivalenceIT extends ESIntegTestCase {
                         .endObject()
                         .endObject()).execute().actionGet();
 
-        List<IndexRequestBuilder> indexingRequests = Lists.newArrayList();
+        List<IndexRequestBuilder> indexingRequests = new ArrayList<>();
         for (int i = 0; i < numDocs; ++i) {
             final int[] values = new int[randomInt(4)];
             for (int j = 0; j < values.length; ++j) {
@@ -329,7 +317,7 @@ public class EquivalenceIT extends ESIntegTestCase {
 
         final int numDocs = scaledRandomIntBetween(2500, 5000);
         logger.info("Indexing [" + numDocs +"] docs");
-        List<IndexRequestBuilder> indexingRequests = Lists.newArrayList();
+        List<IndexRequestBuilder> indexingRequests = new ArrayList<>();
         for (int i = 0; i < numDocs; ++i) {
             indexingRequests.add(client().prepareIndex("idx", "type", Integer.toString(i)).setSource("double_value", randomDouble()));
         }
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/ChildrenIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/ChildrenIT.java
index 169901a..c729c2f 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/ChildrenIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/ChildrenIT.java
@@ -255,9 +255,15 @@ public class ChildrenIT extends ESIntegTestCase {
             assertThat(count.getValue(), equalTo(4.));
 
             String idToUpdate = Integer.toString(randomInt(3));
+            /*
+             * The whole point of this test is to test these things with deleted
+             * docs in the index so we turn off detect_noop to make sure that
+             * the updates cause that.
+             */
             UpdateResponse updateResponse = client().prepareUpdate(indexName, "child", idToUpdate)
                     .setParent("1")
                     .setDoc("count", 1)
+                    .setDetectNoop(false)
                     .get();
             assertThat(updateResponse.getVersion(), greaterThan(1l));
             refresh();
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java
index bb0340f..c3780e9 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java
@@ -29,7 +29,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.ScriptModule;
@@ -231,7 +231,7 @@ public class SignificantTermsSignificanceScoreIT extends ESIntegTestCase {
         public static class SimpleHeuristicParser implements SignificanceHeuristicParser {
 
             @Override
-            public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryShardException {
+            public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException, QueryParsingException {
                 parser.nextToken();
                 return new SimpleHeuristic();
             }
@@ -287,7 +287,7 @@ public class SignificantTermsSignificanceScoreIT extends ESIntegTestCase {
         assertThat(responseBuilder.string(), equalTo(result));
 
     }
-
+    
     @Test
     public void testDeletesIssue7951() throws Exception {
         String settings = "{\"index.number_of_shards\": 1, \"index.number_of_replicas\": 0}";
@@ -307,10 +307,10 @@ public class SignificantTermsSignificanceScoreIT extends ESIntegTestCase {
         indexRequestBuilderList.add(client().prepareIndex(INDEX_NAME, DOC_TYPE, "4")
                 .setSource(TEXT_FIELD, cat2v2, CLASS_FIELD, "2"));
         indexRandom(true, false, indexRequestBuilderList);
-
+        
         // Now create some holes in the index with selective deletes caused by updates.
         // This is the scenario that caused this issue https://github.com/elasticsearch/elasticsearch/issues/7951
-        // Scoring algorithms throw exceptions if term docFreqs exceed the reported size of the index
+        // Scoring algorithms throw exceptions if term docFreqs exceed the reported size of the index 
         // from which they are taken so need to make sure this doesn't happen.
         String[] text = cat1v1;
         indexRequestBuilderList.clear();
@@ -319,7 +319,7 @@ public class SignificantTermsSignificanceScoreIT extends ESIntegTestCase {
             indexRequestBuilderList.add(client().prepareIndex(INDEX_NAME, DOC_TYPE, "1").setSource(TEXT_FIELD, text, CLASS_FIELD, "1"));
         }
         indexRandom(true, false, indexRequestBuilderList);
-
+        
         SearchResponse response1 = client().prepareSearch(INDEX_NAME).setTypes(DOC_TYPE)
                 .addAggregation(new TermsBuilder("class")
                         .field(CLASS_FIELD)
@@ -329,7 +329,7 @@ public class SignificantTermsSignificanceScoreIT extends ESIntegTestCase {
                                         .minDocCount(1)))
                 .execute()
                 .actionGet();
-    }
+    }    
 
     @Test
     public void testBackgroundVsSeparateSet() throws Exception {
@@ -615,4 +615,4 @@ public class SignificantTermsSignificanceScoreIT extends ESIntegTestCase {
         }
         indexRandom(true, indexRequestBuilderList);
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/AvgIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/AvgIT.java
index 584da8a..13ce893 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/AvgIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/AvgIT.java
@@ -33,6 +33,7 @@ import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.avg;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.global;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.is;
 import static org.hamcrest.Matchers.notNullValue;
@@ -87,7 +88,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").field("value"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -102,7 +103,7 @@ public class AvgIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(global("global").subAggregation(avg("avg").field("value"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Global global = searchResponse.getAggregations().get("global");
         assertThat(global, notNullValue());
@@ -128,7 +129,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").field("value"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -144,7 +145,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").field("value").script(new Script("_value + 1")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -162,7 +163,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").field("value").script(new Script("_value + inc", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -174,7 +175,7 @@ public class AvgIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(avg("avg").format("#").field("value")).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -191,7 +192,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").field("values"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -207,7 +208,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").field("values").script(new Script("_value + 1")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -225,7 +226,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").field("values").script(new Script("_value + inc", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -241,7 +242,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").script(new Script("doc['value'].value")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -259,7 +260,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").script(new Script("doc['value'].value + inc", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -277,7 +278,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").script(new Script("doc['value'].value + inc", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -293,7 +294,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").script(new Script("[ doc['value'].value, doc['value'].value + 1 ]")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -309,7 +310,7 @@ public class AvgIT extends AbstractNumericTestCase {
                 .addAggregation(avg("avg").script(new Script("[ doc['value'].value, doc['value'].value + 1 ]")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
@@ -328,7 +329,7 @@ public class AvgIT extends AbstractNumericTestCase {
                         avg("avg").script(new Script("[ doc['value'].value, doc['value'].value + inc ]", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Avg avg = searchResponse.getAggregations().get("avg");
         assertThat(avg, notNullValue());
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ExtendedStatsIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ExtendedStatsIT.java
index d4ce88e..d54dc7a 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ExtendedStatsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ExtendedStatsIT.java
@@ -34,6 +34,7 @@ import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.extendedStats;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.global;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.is;
 import static org.hamcrest.Matchers.notNullValue;
@@ -121,7 +122,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                 .addAggregation(extendedStats("stats").field("value").sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -147,7 +148,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                 .addAggregation(extendedStats("stats").field("value"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -168,7 +169,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(extendedStats("stats").format("0000.0").field("value").sigma(sigma)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -199,7 +200,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(global("global").subAggregation(extendedStats("stats").field("value"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Global global = searchResponse.getAggregations().get("global");
         assertThat(global, notNullValue());
@@ -249,7 +250,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                 .addAggregation(extendedStats("stats").field("value").sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -274,7 +275,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                 .addAggregation(extendedStats("stats").field("value").script(new Script("_value + 1")).sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -303,7 +304,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                                 .sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -328,7 +329,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                 .addAggregation(extendedStats("stats").field("values").sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -353,7 +354,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                 .addAggregation(extendedStats("stats").field("values").script(new Script("_value - 1")).sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -382,7 +383,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                                 .sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -407,7 +408,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                 .addAggregation(extendedStats("stats").script(new Script("doc['value'].value")).sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -435,7 +436,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                         extendedStats("stats").script(new Script("doc['value'].value + inc", ScriptType.INLINE, null, params)).sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -463,7 +464,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                         extendedStats("stats").script(new Script("doc['value'].value + inc", ScriptType.INLINE, null, params)).sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -488,7 +489,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                 .addAggregation(extendedStats("stats").script(new Script("doc['values'].values")).sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -514,7 +515,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                 .execute().actionGet();
 
         assertShardExecutionState(searchResponse, 0);
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -545,7 +546,7 @@ public class ExtendedStatsIT extends AbstractNumericTestCase {
                                 .sigma(sigma))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ExtendedStats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/HDRPercentileRanksIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/HDRPercentileRanksIT.java
index 6b8c39e..24abca0 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/HDRPercentileRanksIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/HDRPercentileRanksIT.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.search.aggregations.metrics;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.script.Script;
@@ -37,15 +35,11 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
+import static org.elasticsearch.common.util.CollectionUtils.iterableAsArrayList;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.global;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.percentileRanks;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
-import static org.hamcrest.Matchers.lessThanOrEqualTo;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.sameInstance;
+import static org.elasticsearch.search.aggregations.AggregationBuilders.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -79,7 +73,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
     }
 
     private void assertConsistent(double[] pcts, PercentileRanks percentiles, long minValue, long maxValue, int numberSigDigits) {
-        final List<Percentile> percentileList = Lists.newArrayList(percentiles);
+        final List<Percentile> percentileList = iterableAsArrayList(percentiles);
         assertEquals(pcts.length, percentileList.size());
         for (int i = 0; i < pcts.length; ++i) {
             final Percentile percentile = percentileList.get(i);
@@ -166,7 +160,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                         percentileRanks("percentile_ranks").method(PercentilesMethod.HDR).numberOfSignificantValueDigits(sigDigits)
                                 .field("value").percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue, maxValue, sigDigits);
@@ -185,7 +179,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                                 percentileRanks("percentile_ranks").method(PercentilesMethod.HDR).numberOfSignificantValueDigits(sigDigits)
                                         .field("value").percentiles(pcts))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Global global = searchResponse.getAggregations().get("global");
         assertThat(global, notNullValue());
@@ -212,7 +206,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                         percentileRanks("percentile_ranks").method(PercentilesMethod.HDR).numberOfSignificantValueDigits(sigDigits)
                                 .field("value").percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue, maxValue, sigDigits);
@@ -230,7 +224,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                         percentileRanks("percentile_ranks").method(PercentilesMethod.HDR).numberOfSignificantValueDigits(sigDigits)
                                 .field("value").percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue, maxValue, sigDigits);
@@ -248,7 +242,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                         percentileRanks("percentile_ranks").method(PercentilesMethod.HDR).numberOfSignificantValueDigits(sigDigits)
                                 .field("value").script(new Script("_value - 1")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1, sigDigits);
@@ -269,7 +263,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                                 .field("value").script(new Script("_value - dec", ScriptType.INLINE, null, params)).percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1, sigDigits);
@@ -287,7 +281,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                         percentileRanks("percentile_ranks").method(PercentilesMethod.HDR).numberOfSignificantValueDigits(sigDigits)
                                 .field("values").percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues, maxValues, sigDigits);
@@ -305,7 +299,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                         percentileRanks("percentile_ranks").method(PercentilesMethod.HDR).numberOfSignificantValueDigits(sigDigits)
                                 .field("values").script(new Script("_value - 1")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1, sigDigits);
@@ -322,7 +316,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                         percentileRanks("percentile_ranks").method(PercentilesMethod.HDR).numberOfSignificantValueDigits(sigDigits)
                                 .field("values").script(new Script("20 - _value")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, 20 - maxValues, 20 - minValues, sigDigits);
@@ -343,7 +337,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                                 .field("values").script(new Script("_value - dec", ScriptType.INLINE, null, params)).percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1, sigDigits);
@@ -361,7 +355,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                         percentileRanks("percentile_ranks").method(PercentilesMethod.HDR).numberOfSignificantValueDigits(sigDigits)
                                 .script(new Script("doc['value'].value")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue, maxValue, sigDigits);
@@ -382,7 +376,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                                 .script(new Script("doc['value'].value - dec", ScriptType.INLINE, null, params)).percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1, sigDigits);
@@ -403,7 +397,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                                 .script(new Script("doc['value'].value - dec", ScriptType.INLINE, null, params)).percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1, sigDigits);
@@ -421,7 +415,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                         percentileRanks("percentile_ranks").method(PercentilesMethod.HDR).numberOfSignificantValueDigits(sigDigits)
                                 .script(new Script("doc['values'].values")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues, maxValues, sigDigits);
@@ -439,7 +433,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                         percentileRanks("percentile_ranks").method(PercentilesMethod.HDR).numberOfSignificantValueDigits(sigDigits)
                                 .script(new Script("doc['values'].values")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues, maxValues, sigDigits);
@@ -463,7 +457,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                                         "List values = doc['values'].values; double[] res = new double[values.size()]; for (int i = 0; i < res.length; i++) { res[i] = values.get(i) - dec; }; return res;",
                                         ScriptType.INLINE, null, params)).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1, sigDigits);
@@ -483,7 +477,7 @@ public class HDRPercentileRanksIT extends AbstractNumericTestCase {
                                                 .numberOfSignificantValueDigits(sigDigits).percentiles(99))
                                 .order(Order.aggregation("percentile_ranks", "99", asc))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Histogram histo = searchResponse.getAggregations().get("histo");
         double previous = asc ? Double.NEGATIVE_INFINITY : Double.POSITIVE_INFINITY;
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/HDRPercentilesIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/HDRPercentilesIT.java
index ebbbf1e..b5568f9 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/HDRPercentilesIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/HDRPercentilesIT.java
@@ -18,10 +18,9 @@
  */
 package org.elasticsearch.search.aggregations.metrics;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.logging.Loggers;
+import org.elasticsearch.common.util.CollectionUtils;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.ScriptService.ScriptType;
 import org.elasticsearch.search.aggregations.bucket.global.Global;
@@ -38,15 +37,9 @@ import java.util.List;
 import java.util.Map;
 
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.global;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.percentiles;
-import static org.hamcrest.Matchers.closeTo;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
-import static org.hamcrest.Matchers.lessThanOrEqualTo;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.sameInstance;
+import static org.elasticsearch.search.aggregations.AggregationBuilders.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -79,7 +72,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
     }
 
     private void assertConsistent(double[] pcts, Percentiles percentiles, long minValue, long maxValue, int numberSigDigits) {
-        final List<Percentile> percentileList = Lists.newArrayList(percentiles);
+        final List<Percentile> percentileList = CollectionUtils.iterableAsArrayList(percentiles);
         assertEquals(pcts.length, percentileList.size());
         for (int i = 0; i < pcts.length; ++i) {
             final Percentile percentile = percentileList.get(i);
@@ -167,7 +160,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                                 .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue, maxValue, sigDigits);
@@ -187,7 +180,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                                         .field("value")
                                         .percentiles(pcts))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Global global = searchResponse.getAggregations().get("global");
         assertThat(global, notNullValue());
@@ -216,7 +209,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                                 .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue, maxValue, sigDigits);
@@ -234,7 +227,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                         percentiles("percentiles").numberOfSignificantValueDigits(sigDigits).method(PercentilesMethod.HDR).field("value")
                                 .script(new Script("_value - 1")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1, sigDigits);
@@ -255,7 +248,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                                 .script(new Script("_value - dec", ScriptType.INLINE, null, params)).percentiles(pcts)).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1, sigDigits);
@@ -274,7 +267,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                                 .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues, maxValues, sigDigits);
@@ -292,7 +285,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                         percentiles("percentiles").numberOfSignificantValueDigits(sigDigits).method(PercentilesMethod.HDR).field("values")
                                 .script(new Script("_value - 1")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1, sigDigits);
@@ -309,7 +302,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                         percentiles("percentiles").numberOfSignificantValueDigits(sigDigits).method(PercentilesMethod.HDR).field("values")
                                 .script(new Script("20 - _value")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, 20 - maxValues, 20 - minValues, sigDigits);
@@ -330,7 +323,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                                 .script(new Script("_value - dec", ScriptType.INLINE, null, params)).percentiles(pcts)).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1, sigDigits);
@@ -348,7 +341,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                         percentiles("percentiles").numberOfSignificantValueDigits(sigDigits).method(PercentilesMethod.HDR)
                                 .script(new Script("doc['value'].value")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue, maxValue, sigDigits);
@@ -369,7 +362,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                                 .script(new Script("doc['value'].value - dec", ScriptType.INLINE, null, params)).percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1, sigDigits);
@@ -390,7 +383,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                                 .script(new Script("doc['value'].value - dec", ScriptType.INLINE, null, params)).percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1, sigDigits);
@@ -408,7 +401,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                         percentiles("percentiles").numberOfSignificantValueDigits(sigDigits).method(PercentilesMethod.HDR)
                                 .script(new Script("doc['values'].values")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues, maxValues, sigDigits);
@@ -426,7 +419,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                         percentiles("percentiles").numberOfSignificantValueDigits(sigDigits).method(PercentilesMethod.HDR)
                                 .script(new Script("doc['values'].values")).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues, maxValues, sigDigits);
@@ -450,7 +443,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                                         "List values = doc['values'].values; double[] res = new double[values.size()]; for (int i = 0; i < res.length; i++) { res[i] = values.get(i) - dec; }; return res;",
                                         ScriptType.INLINE, null, params)).percentiles(pcts)).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1, sigDigits);
@@ -470,7 +463,7 @@ public class HDRPercentilesIT extends AbstractNumericTestCase {
                                                 .percentiles(99))
                                 .order(Order.aggregation("percentiles", "99", asc))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Histogram histo = searchResponse.getAggregations().get("histo");
         double previous = asc ? Double.NEGATIVE_INFINITY : Double.POSITIVE_INFINITY;
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MaxIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MaxIT.java
index 04a3a90..793565d 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MaxIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MaxIT.java
@@ -33,6 +33,7 @@ import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.global;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.max;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.notNullValue;
 
@@ -86,7 +87,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").field("value"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -99,7 +100,7 @@ public class MaxIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(max("max").format("0000.0").field("value")).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -115,7 +116,7 @@ public class MaxIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(global("global").subAggregation(max("max").field("value"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Global global = searchResponse.getAggregations().get("global");
         assertThat(global, notNullValue());
@@ -142,7 +143,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").field("value"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -158,7 +159,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").field("value").script(new Script("_value + 1")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -176,7 +177,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").field("value").script(new Script("_value + inc", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -192,7 +193,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").field("values"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -208,7 +209,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").field("values").script(new Script("_value + 1")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -226,7 +227,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").field("values").script(new Script("_value + inc", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -242,7 +243,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").script(new Script("doc['value'].value")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -260,7 +261,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").script(new Script("doc['value'].value + inc", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -278,7 +279,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").script(new Script("doc['value'].value + inc", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -294,7 +295,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").script(new Script("doc['values'].values")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -310,7 +311,7 @@ public class MaxIT extends AbstractNumericTestCase {
                 .addAggregation(max("max").script(new Script("doc['values'].values")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
@@ -328,7 +329,7 @@ public class MaxIT extends AbstractNumericTestCase {
                         max("max").script(new Script("[ doc['value'].value, doc['value'].value + inc ]", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Max max = searchResponse.getAggregations().get("max");
         assertThat(max, notNullValue());
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MinIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MinIT.java
index 38e4e1e..00cb2dd 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MinIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MinIT.java
@@ -33,6 +33,7 @@ import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.global;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.min;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.notNullValue;
 
@@ -86,7 +87,7 @@ public class MinIT extends AbstractNumericTestCase {
                 .addAggregation(min("min").field("value"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -99,7 +100,7 @@ public class MinIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(min("min").format("0000.0").field("value")).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -115,7 +116,7 @@ public class MinIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(global("global").subAggregation(min("min").field("value"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Global global = searchResponse.getAggregations().get("global");
         assertThat(global, notNullValue());
@@ -142,7 +143,7 @@ public class MinIT extends AbstractNumericTestCase {
                 .addAggregation(min("min").field("value"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -158,7 +159,7 @@ public class MinIT extends AbstractNumericTestCase {
                 .addAggregation(min("min").field("value").script(new Script("_value - 1")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -176,7 +177,7 @@ public class MinIT extends AbstractNumericTestCase {
                 .addAggregation(min("min").field("value").script(new Script("_value - dec", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -192,7 +193,7 @@ public class MinIT extends AbstractNumericTestCase {
                 .addAggregation(min("min").field("values"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -207,7 +208,7 @@ public class MinIT extends AbstractNumericTestCase {
                 .setQuery(matchAllQuery())
                 .addAggregation(min("min").field("values").script(new Script("_value - 1"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -222,7 +223,7 @@ public class MinIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(min("min").field("values").script(new Script("_value * -1"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -239,7 +240,7 @@ public class MinIT extends AbstractNumericTestCase {
                 .addAggregation(min("min").field("values").script(new Script("_value - dec", ScriptType.INLINE, null, params))).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -253,7 +254,7 @@ public class MinIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(min("min").script(new Script("doc['value'].value"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -270,7 +271,7 @@ public class MinIT extends AbstractNumericTestCase {
                 .addAggregation(min("min").script(new Script("doc['value'].value - dec", ScriptType.INLINE, null, params))).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -287,7 +288,7 @@ public class MinIT extends AbstractNumericTestCase {
                 .addAggregation(min("min").script(new Script("doc['value'].value - dec", ScriptType.INLINE, null, params))).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -301,7 +302,7 @@ public class MinIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(min("min").script(new Script("doc['values'].values"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -315,7 +316,7 @@ public class MinIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(min("min").script(new Script("doc['values'].values"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
@@ -337,7 +338,7 @@ public class MinIT extends AbstractNumericTestCase {
                                         "List values = doc['values'].values; double[] res = new double[values.size()]; for (int i = 0; i < res.length; i++) { res[i] = values.get(i) - dec; }; return res;",
                                         ScriptType.INLINE, null, params))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Min min = searchResponse.getAggregations().get("min");
         assertThat(min, notNullValue());
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/StatsIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/StatsIT.java
index d4e6ea9..f838a89 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/StatsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/StatsIT.java
@@ -34,6 +34,7 @@ import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.global;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.stats;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.is;
 import static org.hamcrest.Matchers.notNullValue;
@@ -103,7 +104,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -120,7 +121,7 @@ public class StatsIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(stats("stats").format("0000.0").field("value")).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -144,7 +145,7 @@ public class StatsIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(global("global").subAggregation(stats("stats").field("value"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Global global = searchResponse.getAggregations().get("global");
         assertThat(global, notNullValue());
@@ -186,7 +187,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -208,7 +209,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -232,7 +233,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -254,7 +255,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -276,7 +277,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -300,7 +301,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -322,7 +323,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -346,7 +347,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -370,7 +371,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -392,7 +393,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -414,7 +415,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
@@ -440,7 +441,7 @@ public class StatsIT extends AbstractNumericTestCase {
 
         assertShardExecutionState(searchResponse, 0);
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Stats stats = searchResponse.getAggregations().get("stats");
         assertThat(stats, notNullValue());
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/SumIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/SumIT.java
index 6351bb6..d87e639 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/SumIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/SumIT.java
@@ -33,6 +33,7 @@ import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.global;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.sum;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.notNullValue;
 
@@ -86,7 +87,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .addAggregation(sum("sum").field("value"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -99,7 +100,7 @@ public class SumIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(sum("sum").format("0000.0").field("value")).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -115,7 +116,7 @@ public class SumIT extends AbstractNumericTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(global("global").subAggregation(sum("sum").field("value"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Global global = searchResponse.getAggregations().get("global");
         assertThat(global, notNullValue());
@@ -141,7 +142,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .addAggregation(sum("sum").field("value"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -157,7 +158,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .addAggregation(sum("sum").field("value").script(new Script("_value + 1")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -175,7 +176,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .addAggregation(sum("sum").field("value").script(new Script("_value + increment", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -191,7 +192,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .addAggregation(sum("sum").script(new Script("doc['value'].value")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -209,7 +210,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .addAggregation(sum("sum").script(new Script("doc['value'].value + inc", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -227,7 +228,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .addAggregation(sum("sum").script(new Script("doc['value'].value + inc", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -244,7 +245,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .addAggregation(sum("sum").script(new Script("[ doc['value'].value, doc['value'].value + 1 ]")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -260,7 +261,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .addAggregation(sum("sum").script(new Script("[ doc['value'].value, doc['value'].value + 1 ]")))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -279,7 +280,7 @@ public class SumIT extends AbstractNumericTestCase {
                         sum("sum").script(new Script("[ doc['value'].value, doc['value'].value + inc ]", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -296,7 +297,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .addAggregation(sum("sum").field("values"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -312,7 +313,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .setQuery(matchAllQuery())
                 .addAggregation(sum("sum").field("values").script(new Script("_value + 1"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
@@ -329,7 +330,7 @@ public class SumIT extends AbstractNumericTestCase {
                 .addAggregation(sum("sum").field("values").script(new Script("_value + increment", ScriptType.INLINE, null, params)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Sum sum = searchResponse.getAggregations().get("sum");
         assertThat(sum, notNullValue());
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TDigestPercentileRanksIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TDigestPercentileRanksIT.java
index b1be56a..8499f75 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TDigestPercentileRanksIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TDigestPercentileRanksIT.java
@@ -18,10 +18,9 @@
  */
 package org.elasticsearch.search.aggregations.metrics;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.logging.Loggers;
+import org.elasticsearch.common.util.CollectionUtils;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.ScriptService.ScriptType;
 import org.elasticsearch.search.aggregations.bucket.global.Global;
@@ -38,14 +37,9 @@ import java.util.List;
 import java.util.Map;
 
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.global;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.percentileRanks;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
-import static org.hamcrest.Matchers.lessThanOrEqualTo;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.sameInstance;
+import static org.elasticsearch.search.aggregations.AggregationBuilders.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -82,7 +76,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
     }
 
     private void assertConsistent(double[] pcts, PercentileRanks percentiles, long minValue, long maxValue) {
-        final List<Percentile> percentileList = Lists.newArrayList(percentiles);
+        final List<Percentile> percentileList = CollectionUtils.iterableAsArrayList(percentiles);
         assertEquals(pcts.length, percentileList.size());
         for (int i = 0; i < pcts.length; ++i) {
             final Percentile percentile = percentileList.get(i);
@@ -159,7 +153,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue, maxValue);
@@ -177,7 +171,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                                 randomCompression(percentileRanks("percentile_ranks")).field("value").percentiles(pcts))).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Global global = searchResponse.getAggregations().get("global");
         assertThat(global, notNullValue());
@@ -203,7 +197,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue, maxValue);
@@ -220,7 +214,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue, maxValue);
@@ -237,7 +231,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1);
@@ -257,7 +251,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1);
@@ -274,7 +268,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues, maxValues);
@@ -291,7 +285,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1);
@@ -307,7 +301,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, -maxValues, -minValues);
@@ -327,7 +321,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1);
@@ -344,7 +338,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue, maxValue);
@@ -364,7 +358,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1);
@@ -384,7 +378,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1);
@@ -401,7 +395,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues, maxValues);
@@ -418,7 +412,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues, maxValues);
@@ -439,7 +433,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final PercentileRanks percentiles = searchResponse.getAggregations().get("percentile_ranks");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1);
@@ -456,7 +450,7 @@ public class TDigestPercentileRanksIT extends AbstractNumericTestCase {
                             .order(Order.aggregation("percentile_ranks", "99", asc)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Histogram histo = searchResponse.getAggregations().get("histo");
         double previous = asc ? Double.NEGATIVE_INFINITY : Double.POSITIVE_INFINITY;
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TDigestPercentilesIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TDigestPercentilesIT.java
index 60e385e..65b0ea5 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TDigestPercentilesIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TDigestPercentilesIT.java
@@ -18,10 +18,9 @@
  */
 package org.elasticsearch.search.aggregations.metrics;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.logging.Loggers;
+import org.elasticsearch.common.util.CollectionUtils;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.ScriptService.ScriptType;
 import org.elasticsearch.search.aggregations.bucket.global.Global;
@@ -38,14 +37,9 @@ import java.util.List;
 import java.util.Map;
 
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.global;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.histogram;
-import static org.elasticsearch.search.aggregations.AggregationBuilders.percentiles;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
-import static org.hamcrest.Matchers.lessThanOrEqualTo;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.sameInstance;
+import static org.elasticsearch.search.aggregations.AggregationBuilders.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -81,7 +75,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
     }
 
     private void assertConsistent(double[] pcts, Percentiles percentiles, long minValue, long maxValue) {
-        final List<Percentile> percentileList = Lists.newArrayList(percentiles);
+        final List<Percentile> percentileList = CollectionUtils.iterableAsArrayList(percentiles);
         assertEquals(pcts.length, percentileList.size());
         for (int i = 0; i < pcts.length; ++i) {
             final Percentile percentile = percentileList.get(i);
@@ -159,7 +153,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue, maxValue);
@@ -176,7 +170,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         global("global").subAggregation(randomCompression(percentiles("percentiles")).field("value").percentiles(pcts)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Global global = searchResponse.getAggregations().get("global");
         assertThat(global, notNullValue());
@@ -203,7 +197,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue, maxValue);
@@ -220,7 +214,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1);
@@ -240,7 +234,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1);
@@ -257,7 +251,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues, maxValues);
@@ -274,7 +268,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1);
@@ -290,7 +284,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, -maxValues, -minValues);
@@ -310,7 +304,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1);
@@ -327,7 +321,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue, maxValue);
@@ -347,7 +341,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1);
@@ -367,7 +361,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValue - 1, maxValue - 1);
@@ -384,7 +378,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues, maxValues);
@@ -401,7 +395,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues, maxValues);
@@ -422,7 +416,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                         .percentiles(pcts))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         final Percentiles percentiles = searchResponse.getAggregations().get("percentiles");
         assertConsistent(pcts, percentiles, minValues - 1, maxValues - 1);
@@ -439,7 +433,7 @@ public class TDigestPercentilesIT extends AbstractNumericTestCase {
                             .order(Order.aggregation("percentiles", "99", asc)))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Histogram histo = searchResponse.getAggregations().get("histo");
         double previous = asc ? Double.NEGATIVE_INFINITY : Double.POSITIVE_INFINITY;
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountIT.java
index 6fd4e83..a2f8106 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountIT.java
@@ -33,6 +33,7 @@ import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.count;
 import static org.elasticsearch.search.aggregations.AggregationBuilders.global;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.notNullValue;
 
@@ -82,7 +83,7 @@ public class ValueCountIT extends ESIntegTestCase {
                 .addAggregation(count("count").field("value"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ValueCount valueCount = searchResponse.getAggregations().get("count");
         assertThat(valueCount, notNullValue());
@@ -96,7 +97,7 @@ public class ValueCountIT extends ESIntegTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(global("global").subAggregation(count("count").field("value"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         Global global = searchResponse.getAggregations().get("global");
         assertThat(global, notNullValue());
@@ -121,7 +122,7 @@ public class ValueCountIT extends ESIntegTestCase {
                 .addAggregation(count("count").field("value"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ValueCount valueCount = searchResponse.getAggregations().get("count");
         assertThat(valueCount, notNullValue());
@@ -137,7 +138,7 @@ public class ValueCountIT extends ESIntegTestCase {
                 .addAggregation(count("count").field("values"))
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ValueCount valueCount = searchResponse.getAggregations().get("count");
         assertThat(valueCount, notNullValue());
@@ -150,7 +151,7 @@ public class ValueCountIT extends ESIntegTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(count("count").script(new Script("doc['value'].value"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ValueCount valueCount = searchResponse.getAggregations().get("count");
         assertThat(valueCount, notNullValue());
@@ -163,7 +164,7 @@ public class ValueCountIT extends ESIntegTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(count("count").script(new Script("doc['values'].values"))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ValueCount valueCount = searchResponse.getAggregations().get("count");
         assertThat(valueCount, notNullValue());
@@ -178,7 +179,7 @@ public class ValueCountIT extends ESIntegTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(count("count").script(new Script("doc[s].value", ScriptType.INLINE, null, params))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ValueCount valueCount = searchResponse.getAggregations().get("count");
         assertThat(valueCount, notNullValue());
@@ -193,7 +194,7 @@ public class ValueCountIT extends ESIntegTestCase {
         SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                 .addAggregation(count("count").script(new Script("doc[s].values", ScriptType.INLINE, null, params))).execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
 
         ValueCount valueCount = searchResponse.getAggregations().get("count");
         assertThat(valueCount, notNullValue());
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java
index f00e95d..cdbe3be 100644
--- a/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java
@@ -26,30 +26,18 @@ import org.elasticsearch.script.ScriptService.ScriptType;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.hamcrest.CoreMatchers;
-import org.junit.Ignore;
 
 import java.util.Arrays;
 import java.util.Comparator;
 import java.util.HashMap;
 import java.util.Map;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
-import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.fieldValueFactorFunction;
-import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.randomFunction;
-import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
+import static org.elasticsearch.index.query.QueryBuilders.*;
+import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.*;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.hamcrest.Matchers.allOf;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
-import static org.hamcrest.Matchers.lessThanOrEqualTo;
-import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.*;
 
 public class RandomScoreFunctionIT extends ESIntegTestCase {
 
@@ -121,7 +109,7 @@ public class RandomScoreFunctionIT extends ESIntegTestCase {
 
         int docCount = randomIntBetween(100, 200);
         for (int i = 0; i < docCount; i++) {
-            client().prepareIndex("test", "type", "" + i).setSource("body", randomFrom(newArrayList("foo", "bar", "baz")), "index", i)
+            client().prepareIndex("test", "type", "" + i).setSource("body", randomFrom(Arrays.asList("foo", "bar", "baz")), "index", i + 1) // we add 1 to the index field to make sure that the scripts below never compute log(0)
                     .get();
         }
         refresh();
diff --git a/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java b/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java
index e193d2a..5a8d7c0 100644
--- a/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java
+++ b/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighter.java
@@ -18,11 +18,11 @@
  */
 package org.elasticsearch.search.highlight;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.text.StringText;
 import org.elasticsearch.common.text.Text;
 import org.elasticsearch.index.mapper.FieldMapper;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
@@ -51,7 +51,7 @@ public class CustomHighlighter implements Highlighter {
             }
         }
 
-        List<Text> responses = Lists.newArrayList();
+        List<Text> responses = new ArrayList<>();
         responses.add(new StringText(String.format(Locale.ENGLISH, "standard response for %s at position %s", field.field(),
                 cacheEntry.position)));
 
diff --git a/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java b/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
index 2509c32..d9f69de 100644
--- a/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
@@ -27,9 +27,10 @@ import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.settings.Settings.Builder;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.BoostableQueryBuilder;
 import org.elasticsearch.index.query.IdsQueryBuilder;
 import org.elasticsearch.index.query.MatchQueryBuilder;
+import org.elasticsearch.index.query.MatchQueryBuilder.Operator;
 import org.elasticsearch.index.query.MatchQueryBuilder.Type;
 import org.elasticsearch.index.query.MultiMatchQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
@@ -70,7 +71,12 @@ import static org.elasticsearch.index.query.QueryBuilders.typeQuery;
 import static org.elasticsearch.index.query.QueryBuilders.wildcardQuery;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.highlight;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.searchSource;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHighlight;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNotHighlighted;
 import static org.elasticsearch.test.hamcrest.RegexMatcher.matches;
 import static org.hamcrest.Matchers.anyOf;
 import static org.hamcrest.Matchers.containsString;
@@ -1391,7 +1397,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
-                .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
+                .query(boostingQuery().positive(termQuery("field2", "brown")).negative(termQuery("field2", "foobar")).negativeBoost(0.5f))
                 .highlight(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source.buildAsBytes()).get();
@@ -1409,7 +1415,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
-                .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
+                .query(boostingQuery().positive(termQuery("field2", "brown")).negative(termQuery("field2", "foobar")).negativeBoost(0.5f))
                 .highlight(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source.buildAsBytes()).get();
@@ -2323,7 +2329,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
-                .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
+                .query(boostingQuery().positive(termQuery("field2", "brown")).negative(termQuery("field2", "foobar")).negativeBoost(0.5f))
                 .highlight(highlight().field("field2").preTags("<x>").postTags("</x>"));
         SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -2611,7 +2617,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
                 queryStringQuery("\"highlight words together\"").field("field1^100").autoGeneratePhraseQueries(true));
     }
 
-    private <P extends AbstractQueryBuilder<P>> void
+    private <P extends QueryBuilder & BoostableQueryBuilder<?>> void
             phraseBoostTestCaseForClauses(String highlighterType, float boost, QueryBuilder terms, P phrase) {
         Matcher<String> highlightedMatcher = Matchers.either(containsString("<em>highlight words together</em>")).or(
                 containsString("<em>highlight</em> <em>words</em> <em>together</em>"));
@@ -2625,10 +2631,10 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         assertHighlight(response, 0, "field1", 0, 1, highlightedMatcher);
         phrase.boost(1);
         // Try with a boosting query
-        response = search.setQuery(boostingQuery(phrase, terms).boost(boost).negativeBoost(1)).get();
+        response = search.setQuery(boostingQuery().positive(phrase).negative(terms).boost(boost).negativeBoost(1)).get();
         assertHighlight(response, 0, "field1", 0, 1, highlightedMatcher);
         // Try with a boosting query using a negative boost
-        response = search.setQuery(boostingQuery(phrase, terms).boost(1).negativeBoost(1/boost)).get();
+        response = search.setQuery(boostingQuery().positive(phrase).negative(terms).boost(1).negativeBoost(1/boost)).get();
         assertHighlight(response, 0, "field1", 0, 1, highlightedMatcher);
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java b/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java
index 793d365..b9099d0 100644
--- a/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java
@@ -28,7 +28,6 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.MatchQueryBuilder;
 import org.elasticsearch.index.query.MultiMatchQueryBuilder;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHits;
@@ -155,7 +154,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         MatchQueryBuilder.Type type = randomBoolean() ? null : MatchQueryBuilder.Type.BOOLEAN;
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         Set<String> topNIds = Sets.newHashSet("theone", "theother");
         for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
             topNIds.remove(searchResponse.getHits().getAt(i).getId());
@@ -167,25 +166,25 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).useDisMax(false).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).useDisMax(false).type(type))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theone"), hasId("theother")));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(type))).get();
         assertFirstHit(searchResponse, hasId("theother"));
 
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
     }
@@ -194,18 +193,18 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
     public void testPhraseType() {
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("Man the Ultimate", "full_name_phrase", "first_name_phrase", "last_name_phrase", "category_phrase")
-                        .operator(Operator.OR).type(MatchQueryBuilder.Type.PHRASE))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(MatchQueryBuilder.Type.PHRASE))).get();
         assertFirstHit(searchResponse, hasId("ultimate2"));
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("Captain", "full_name_phrase", "first_name_phrase", "last_name_phrase", "category_phrase")
-                        .operator(Operator.OR).type(MatchQueryBuilder.Type.PHRASE))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(MatchQueryBuilder.Type.PHRASE))).get();
         assertThat(searchResponse.getHits().getTotalHits(), greaterThan(1l));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("the Ul", "full_name_phrase", "first_name_phrase", "last_name_phrase", "category_phrase")
-                        .operator(Operator.OR).type(MatchQueryBuilder.Type.PHRASE_PREFIX))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(MatchQueryBuilder.Type.PHRASE_PREFIX))).get();
         assertSearchHits(searchResponse, "ultimate2", "ultimate1");
         assertHitCount(searchResponse, 2l);
     }
@@ -264,7 +263,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         Float cutoffFrequency = randomBoolean() ? Math.min(1, numDocs * 1.f / between(10, 20)) : 1.f / between(10, 20);
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).cutoffFrequency(cutoffFrequency))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).cutoffFrequency(cutoffFrequency))).get();
         Set<String> topNIds = Sets.newHashSet("theone", "theother");
         for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
             topNIds.remove(searchResponse.getHits().getAt(i).getId());
@@ -277,39 +276,39 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         cutoffFrequency = randomBoolean() ? Math.min(1, numDocs * 1.f / between(10, 20)) : 1.f / between(10, 20);
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).useDisMax(false).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).useDisMax(false).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theone"), hasId("theother")));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
         long size = searchResponse.getHits().getTotalHits();
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).useDisMax(false).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).useDisMax(false).type(type))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theone"), hasId("theother")));
         assertThat("common terms expected to be a way smaller result set", size, lessThan(searchResponse.getHits().getTotalHits()));
 
         cutoffFrequency = randomBoolean() ? Math.min(1, numDocs * 1.f / between(10, 20)) : 1.f / between(10, 20);
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertFirstHit(searchResponse, hasId("theother"));
 
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "first_name", "last_name", "category")
-                        .operator(Operator.AND).cutoffFrequency(cutoffFrequency)
+                        .operator(MatchQueryBuilder.Operator.AND).cutoffFrequency(cutoffFrequency)
                         .analyzer("category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS))).get();
         assertHitCount(searchResponse, 1l);
@@ -331,7 +330,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 SearchResponse left = client().prepareSearch("test").setSize(numDocs)
                         .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
                         .setQuery(randomizeType(multiMatchQueryBuilder
-                                .operator(Operator.OR).type(type))).get();
+                                .operator(MatchQueryBuilder.Operator.OR).type(type))).get();
 
                 SearchResponse right = client().prepareSearch("test").setSize(numDocs)
                         .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
@@ -347,7 +346,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
             {
                 MatchQueryBuilder.Type type = randomBoolean() ? null : MatchQueryBuilder.Type.BOOLEAN;
                 String minShouldMatch = randomBoolean() ? null : "" + between(0, 1);
-                Operator op = randomBoolean() ? Operator.AND : Operator.OR;
+                MatchQueryBuilder.Operator op = randomBoolean() ? MatchQueryBuilder.Operator.AND : MatchQueryBuilder.Operator.OR;
                 MultiMatchQueryBuilder multiMatchQueryBuilder = randomBoolean() ? multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category") :
                         multiMatchQuery("captain america", "*_name", randomBoolean() ? "category" : "categ*");
                 SearchResponse left = client().prepareSearch("test").setSize(numDocs)
@@ -368,7 +367,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
 
             {
                 String minShouldMatch = randomBoolean() ? null : "" + between(0, 1);
-                Operator op = randomBoolean() ? Operator.AND : Operator.OR;
+                MatchQueryBuilder.Operator op = randomBoolean() ? MatchQueryBuilder.Operator.AND : MatchQueryBuilder.Operator.OR;
                 SearchResponse left = client().prepareSearch("test").setSize(numDocs)
                         .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
                         .setQuery(randomizeType(multiMatchQuery("capta", "full_name", "first_name", "last_name", "category")
@@ -386,7 +385,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
             }
             {
                 String minShouldMatch = randomBoolean() ? null : "" + between(0, 1);
-                Operator op = randomBoolean() ? Operator.AND : Operator.OR;
+                MatchQueryBuilder.Operator op = randomBoolean() ? MatchQueryBuilder.Operator.AND : MatchQueryBuilder.Operator.OR;
                 SearchResponse left;
                 if (randomBoolean()) {
                     left = client().prepareSearch("test").setSize(numDocs)
@@ -417,13 +416,13 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, hasId("theone"));
         assertSecondHit(searchResponse, hasId("theother"));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
@@ -431,13 +430,13 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, hasId("theother"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
@@ -445,7 +444,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 .setQuery(randomizeType(multiMatchQuery("captain america 15", "full_name", "first_name", "last_name", "category", "skill")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .analyzer("category")
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
@@ -466,7 +465,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .cutoffFrequency(0.1f)
                         .analyzer("category")
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theother"), hasId("theone")));
         long numResults = searchResponse.getHits().totalHits();
 
@@ -474,7 +473,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .analyzer("category")
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertThat(numResults, lessThan(searchResponse.getHits().getTotalHits()));
         assertFirstHit(searchResponse, hasId("theone"));
 
@@ -484,28 +483,28 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .analyzer("category")
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
         // counter example
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(randomBoolean() ? MultiMatchQueryBuilder.Type.CROSS_FIELDS : null)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 0l);
 
         // counter example
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(randomBoolean() ? MultiMatchQueryBuilder.Type.CROSS_FIELDS : null)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 0l);
 
         // test if boosts work
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("the ultimate", "full_name", "first_name", "last_name^2", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertFirstHit(searchResponse, hasId("ultimate1"));   // has ultimate in the last_name and that is boosted
         assertSecondHit(searchResponse, hasId("ultimate2"));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
@@ -515,7 +514,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("the ultimate", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertFirstHit(searchResponse, hasId("ultimate2"));
         assertSecondHit(searchResponse, hasId("ultimate1"));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
diff --git a/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java b/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
index 8bc89c7..07363a4 100644
--- a/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.search.query;
 
 import org.apache.lucene.util.English;
+import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
 import org.elasticsearch.action.index.IndexRequestBuilder;
@@ -31,8 +32,15 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.mapper.MapperParsingException;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.BoolQueryBuilder;
+import org.elasticsearch.index.query.CommonTermsQueryBuilder.Operator;
+import org.elasticsearch.index.query.MatchQueryBuilder;
 import org.elasticsearch.index.query.MatchQueryBuilder.Type;
+import org.elasticsearch.index.query.MultiMatchQueryBuilder;
+import org.elasticsearch.index.query.QueryBuilders;
+import org.elasticsearch.index.query.QueryStringQueryBuilder;
+import org.elasticsearch.index.query.TermQueryBuilder;
+import org.elasticsearch.index.query.WrapperQueryBuilder;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.SearchHit;
@@ -56,8 +64,24 @@ import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
 import static org.elasticsearch.test.VersionUtils.randomVersion;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
-import static org.hamcrest.Matchers.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFirstHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHits;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSecondHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertThirdHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasId;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasScore;
+import static org.hamcrest.Matchers.allOf;
+import static org.hamcrest.Matchers.closeTo;
+import static org.hamcrest.Matchers.containsString;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.greaterThan;
+import static org.hamcrest.Matchers.is;
 
 public class SearchQueryIT extends ESIntegTestCase {
 
@@ -327,18 +351,18 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("2"));
 
         // try the same with match query
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.OR)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.OR)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
         assertThirdHit(searchResponse, hasId("3"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND).analyzer("stop")).get();
         assertHitCount(searchResponse, 3l);
         // stop drops "the" since its a stopword
         assertFirstHit(searchResponse, hasId("1"));
@@ -346,7 +370,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("2"));
 
         // try the same with multi match query
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the quick brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the quick brown", "field1", "field2").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
         assertSecondHit(searchResponse, hasId("1"));
@@ -419,18 +443,18 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("2"));
 
         // try the same with match query
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.OR)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.OR)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
         assertThirdHit(searchResponse, hasId("3"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND).analyzer("stop")).get();
         assertHitCount(searchResponse, 3l);
         // stop drops "the" since its a stopword
         assertFirstHit(searchResponse, hasId("1"));
@@ -443,7 +467,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertSecondHit(searchResponse, hasId("2"));
 
         // try the same with multi match query
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the fast brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the fast brown", "field1", "field2").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
         assertSecondHit(searchResponse, hasId("1"));
@@ -914,7 +938,7 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         client().admin().indices().prepareRefresh("test").get();
         builder = multiMatchQuery("value1", "field1", "field2")
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+                .operator(MatchQueryBuilder.Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
         searchResponse = client().prepareSearch()
                 .setQuery(builder)
                 .get();
@@ -923,14 +947,14 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         refresh();
         builder = multiMatchQuery("value1", "field1", "field3^1.5")
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+                .operator(MatchQueryBuilder.Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
         searchResponse = client().prepareSearch().setQuery(builder).get();
         assertHitCount(searchResponse, 2l);
         assertSearchHits(searchResponse, "3", "1");
 
         client().admin().indices().prepareRefresh("test").get();
         builder = multiMatchQuery("value1").field("field1").field("field3", 1.5f)
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+                .operator(MatchQueryBuilder.Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
         searchResponse = client().prepareSearch().setQuery(builder).get();
         assertHitCount(searchResponse, 2l);
         assertSearchHits(searchResponse, "3", "1");
@@ -1573,9 +1597,10 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test").setQuery(
-                spanNearQuery(3)
+                spanNearQuery()
                         .clause(spanTermQuery("description", "foo"))
-                        .clause(spanTermQuery("description", "other"))).get();
+                        .clause(spanTermQuery("description", "other"))
+                        .slop(3)).get();
         assertHitCount(searchResponse, 3l);
     }
 
@@ -1620,22 +1645,33 @@ public class SearchQueryIT extends ESIntegTestCase {
         refresh();
 
         SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(1)
+                .setQuery(spanNotQuery().include(spanNearQuery()
                         .clause(QueryBuilders.spanTermQuery("description", "quick"))
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "brown"))).get();
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "brown"))).get();
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(1)
+                .setQuery(spanNotQuery().include(spanNearQuery()
                         .clause(QueryBuilders.spanTermQuery("description", "quick"))
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "sleeping")).dist(5)).get();
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "sleeping")).dist(5)).get();
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(1)
+                .setQuery(spanNotQuery().include(spanNearQuery()
                         .clause(QueryBuilders.spanTermQuery("description", "quick"))
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "jumped")).pre(1).post(1)).get();
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "jumped")).pre(1).post(1)).get();
         assertHitCount(searchResponse, 1l);
+
+        try {
+            client().prepareSearch("test")
+                    .setQuery(spanNotQuery().include(spanNearQuery()
+                            .clause(QueryBuilders.spanTermQuery("description", "quick"))
+                            .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "jumped")).dist(2).pre(2)
+                    ).get();
+            fail("ElasticsearchIllegalArgumentException should have been caught");
+        } catch (ElasticsearchException e) {
+            assertThat("ElasticsearchIllegalArgumentException should have been caught", e.getDetailedMessage(), containsString("spanNot can either use [dist] or [pre] & [post] (or none)"));
+        }
     }
 
     @Test
@@ -1731,18 +1767,18 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
         refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fast").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fast").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
 
         client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
         refresh();
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
     }
 
@@ -1762,12 +1798,12 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         client().prepareIndex("test", "test", "1").setSource("text", "the fox runs across the street").get();
         refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
 
         client().prepareIndex("test", "test", "2").setSource("text", "run fox run").get();
         refresh();
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
     }
 
@@ -1788,19 +1824,19 @@ public class SearchQueryIT extends ESIntegTestCase {
         client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
         refresh();
 
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("fast").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("fast").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
 
         client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
         refresh();
 
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
     }
 
@@ -1826,7 +1862,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         SearchResponse response = client()
                 .prepareSearch("test")
                 .setQuery(
-                        queryStringQuery("foo.baz").useDisMax(false).defaultOperator(Operator.AND)
+                        queryStringQuery("foo.baz").useDisMax(false).defaultOperator(QueryStringQueryBuilder.Operator.AND)
                                 .field("field1").field("field2")).get();
         assertHitCount(response, 1l);
     }
@@ -1892,7 +1928,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertSearchHits(searchResponse, "1", "2", "3");
         searchResponse = client().prepareSearch("index1", "index2", "index3")
                 .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
-                        .noMatchQuery(QueryBuilders.matchAllQuery())).get();
+                        .noMatchQuery("all")).get();
         assertHitCount(searchResponse, 3l);
         assertSearchHits(searchResponse, "1", "2", "3");
 
@@ -1903,7 +1939,6 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertFirstHit(searchResponse, hasId("1"));
     }
 
-    @AwaitsFix(bugUrl = "https://github.com/elastic/elasticsearch/issues/12822")
     @Test // https://github.com/elasticsearch/elasticsearch/issues/2416
     public void testIndicesQuerySkipParsing() throws Exception {
         createIndex("simple");
diff --git a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
index a8c5ccb..e41c451 100644
--- a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
@@ -23,7 +23,7 @@ import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.BoolQueryBuilder;
-import org.elasticsearch.index.query.Operator;
+import org.elasticsearch.index.query.SimpleQueryStringBuilder;
 import org.elasticsearch.index.query.SimpleQueryStringFlag;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
@@ -33,7 +33,10 @@ import java.util.Locale;
 import java.util.concurrent.ExecutionException;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.*;
+import static org.elasticsearch.index.query.QueryBuilders.boolQuery;
+import static org.elasticsearch.index.query.QueryBuilders.queryStringQuery;
+import static org.elasticsearch.index.query.QueryBuilders.simpleQueryStringQuery;
+import static org.elasticsearch.index.query.QueryBuilders.termQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.hamcrest.Matchers.equalTo;
 
@@ -67,7 +70,7 @@ public class SimpleQueryStringIT extends ESIntegTestCase {
         assertFirstHit(searchResponse, hasId("3"));
 
         searchResponse = client().prepareSearch().setQuery(
-                simpleQueryStringQuery("foo bar").defaultOperator(Operator.AND)).get();
+                simpleQueryStringQuery("foo bar").defaultOperator(SimpleQueryStringBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("3"));
 
@@ -248,21 +251,21 @@ public class SimpleQueryStringIT extends ESIntegTestCase {
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("foo | bar")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.OR)).get();
         assertHitCount(searchResponse, 3l);
         assertSearchHits(searchResponse, "1", "2", "3");
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("foo | bar")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.NONE)).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("3"));
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("baz | egg*")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.NONE)).get();
         assertHitCount(searchResponse, 0l);
 
@@ -279,7 +282,7 @@ public class SimpleQueryStringIT extends ESIntegTestCase {
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("baz | egg*")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.WHITESPACE, SimpleQueryStringFlag.PREFIX)).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("4"));
diff --git a/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java b/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
index 5b559da..6aa31ca 100644
--- a/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
+++ b/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
@@ -33,7 +33,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.MatchQueryBuilder;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
 import org.elasticsearch.script.Script;
@@ -117,7 +116,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         ensureYellow();
         refresh();
         SearchResponse searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                 .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "quick brown").slop(2).boost(4.0f)).setRescoreQueryWeight(2))
                 .setRescoreWindow(5).execute().actionGet();
 
@@ -127,7 +126,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         assertThat(searchResponse.getHits().getHits()[2].getId(), equalTo("2"));
 
         searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                 .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(3)))
                 .setRescoreWindow(5).execute().actionGet();
 
@@ -137,7 +136,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("3"));
 
         searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                 .setRescorer(RescoreBuilder.queryRescorer((QueryBuilders.matchPhraseQuery("field1", "the quick brown"))))
                 .setRescoreWindow(5).execute().actionGet();
 
@@ -180,7 +179,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         client().admin().indices().prepareRefresh("test").execute().actionGet();
         SearchResponse searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
                 .setSize(5)
                 .setRescorer(
@@ -195,7 +194,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
 
         searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
                 .setSize(5)
                 .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
@@ -212,7 +211,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         // Make sure non-zero from works:
         searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(2)
                 .setSize(5)
                 .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
@@ -321,7 +320,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
 
         SearchResponse searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
             .setSize(5).execute().actionGet();
         assertThat(searchResponse.getHits().hits().length, equalTo(4));
@@ -334,7 +333,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         // Now, penalizing rescore (nothing matches the rescore query):
         searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
                 .setSize(5)
                 .setRescorer(
@@ -426,7 +425,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                     .prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR))
                     .setFrom(0)
                     .setSize(resultSize)
                     .setRescorer(
@@ -441,7 +440,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
             SearchResponse plain = client().prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR)).setFrom(0).setSize(resultSize)
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR)).setFrom(0).setSize(resultSize)
                     .execute().actionGet();
             
             // check equivalence
@@ -451,7 +450,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                     .prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR))
                     .setFrom(0)
                     .setSize(resultSize)
                     .setRescorer(
@@ -469,7 +468,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                     .prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR))
                     .setFrom(0)
                     .setSize(resultSize)
                     .setRescorer(
@@ -504,7 +503,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
             SearchResponse searchResponse = client()
                     .prepareSearch()
                     .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                     .setRescorer(
                             RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(2).boost(4.0f))
                                     .setQueryWeight(0.5f).setRescoreQueryWeight(0.4f)).setRescoreWindow(5).setExplain(true).execute()
@@ -542,7 +541,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
             SearchResponse searchResponse = client()
                     .prepareSearch()
                     .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                     .setRescorer(innerRescoreQuery).setRescoreWindow(5).setExplain(true).execute()
                     .actionGet();
             assertHitCount(searchResponse, 3);
@@ -565,7 +564,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                 searchResponse = client()
                         .prepareSearch()
                         .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                        .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                        .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                         .addRescorer(innerRescoreQuery).setRescoreWindow(5)
                         .addRescorer(outerRescoreQuery).setRescoreWindow(10)
                         .setExplain(true).get();
diff --git a/core/src/test/java/org/elasticsearch/search/sort/SimpleSortIT.java b/core/src/test/java/org/elasticsearch/search/sort/SimpleSortIT.java
index b2cdbfa..7aef0d2 100644
--- a/core/src/test/java/org/elasticsearch/search/sort/SimpleSortIT.java
+++ b/core/src/test/java/org/elasticsearch/search/sort/SimpleSortIT.java
@@ -545,7 +545,7 @@ public class SimpleSortIT extends ESIntegTestCase {
                 .setSize(size)
                 .addSort("str_value", SortOrder.ASC)
                 .execute().actionGet();
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(i)));
@@ -558,7 +558,7 @@ public class SimpleSortIT extends ESIntegTestCase {
                 .addSort("str_value", SortOrder.DESC)
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(9 - i)));
@@ -575,7 +575,7 @@ public class SimpleSortIT extends ESIntegTestCase {
                 .setQuery(matchAllQuery())
                 .setSize(size)
                 .addSort(new ScriptSortBuilder(new Script("doc['str_value'].value"), "string")).execute().actionGet();
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(i)));
@@ -586,7 +586,7 @@ public class SimpleSortIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setSize(size).addSort("str_value", SortOrder.DESC).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(9 - i)));
@@ -601,7 +601,7 @@ public class SimpleSortIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setSize(size).addSort("byte_value", SortOrder.ASC).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(i)));
@@ -611,7 +611,7 @@ public class SimpleSortIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setSize(size).addSort("byte_value", SortOrder.DESC).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(9 - i)));
@@ -625,7 +625,7 @@ public class SimpleSortIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setSize(size).addSort("short_value", SortOrder.ASC).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(i)));
@@ -635,7 +635,7 @@ public class SimpleSortIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setSize(size).addSort("short_value", SortOrder.DESC).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(9 - i)));
@@ -649,7 +649,7 @@ public class SimpleSortIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setSize(size).addSort("integer_value", SortOrder.ASC).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(i)));
@@ -661,7 +661,7 @@ public class SimpleSortIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setSize(size).addSort("integer_value", SortOrder.DESC)
                 .execute().actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(9 - i)));
@@ -675,7 +675,7 @@ public class SimpleSortIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setSize(size).addSort("long_value", SortOrder.ASC).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(i)));
@@ -687,7 +687,7 @@ public class SimpleSortIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setSize(size).addSort("long_value", SortOrder.DESC).execute()
                 .actionGet();
         assertHitCount(searchResponse, 10l);
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(9 - i)));
@@ -713,7 +713,7 @@ public class SimpleSortIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setSize(size).addSort("float_value", SortOrder.DESC).execute()
                 .actionGet();
 
-        assertThat(searchResponse.getHits().getTotalHits(), equalTo(10l));
+        assertHitCount(searchResponse, 10);
         assertThat(searchResponse.getHits().hits().length, equalTo(size));
         for (int i = 0; i < size; i++) {
             assertThat(searchResponse.getHits().getAt(i).id(), equalTo(Integer.toString(9 - i)));
diff --git a/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchIT.java b/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchIT.java
index 672dc5e..0b5e0d8 100644
--- a/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchIT.java
@@ -20,8 +20,6 @@ package org.elasticsearch.search.suggest;
 
 import com.carrotsearch.hppc.ObjectLongHashMap;
 import com.carrotsearch.randomizedtesting.generators.RandomStrings;
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.elasticsearch.action.admin.indices.mapping.put.PutMappingResponse;
 import org.elasticsearch.action.admin.indices.optimize.OptimizeResponse;
@@ -51,6 +49,8 @@ import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
 import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
@@ -60,6 +60,7 @@ import java.util.concurrent.ExecutionException;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
+import static org.elasticsearch.common.util.CollectionUtils.iterableAsArrayList;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
@@ -145,7 +146,7 @@ public class CompletionSuggestSearchIT extends ESIntegTestCase {
     public void testThatWeightsAreWorking() throws Exception {
         createIndexAndMapping(completionMappingBuilder);
 
-        List<String> similarNames = Lists.newArrayList("the", "The Prodigy", "The Verve", "The the");
+        List<String> similarNames = Arrays.asList("the", "The Prodigy", "The Verve", "The the");
         // the weight is 1000 divided by string length, so the results are easy to to check
         for (String similarName : similarNames) {
             client().prepareIndex(INDEX, TYPE, similarName).setSource(jsonBuilder()
@@ -853,8 +854,8 @@ public class CompletionSuggestSearchIT extends ESIntegTestCase {
     private void assertSuggestions(SuggestResponse suggestResponse, boolean suggestionOrderStrict, String name, String... suggestions) {
         assertAllSuccessful(suggestResponse);
 
-        List<String> suggestionNames = Lists.newArrayList();
-        for (Suggest.Suggestion<? extends Suggest.Suggestion.Entry<? extends Suggest.Suggestion.Entry.Option>> suggestion : Lists.newArrayList(suggestResponse.getSuggest().iterator())) {
+        List<String> suggestionNames = new ArrayList<>();
+        for (Suggest.Suggestion<? extends Suggest.Suggestion.Entry<? extends Suggest.Suggestion.Entry.Option>> suggestion : iterableAsArrayList(suggestResponse.getSuggest())) {
             suggestionNames.add(suggestion.getName());
         }
         String expectFieldInResponseMsg = String.format(Locale.ROOT, "Expected suggestion named %s in response, got %s", name, suggestionNames);
@@ -881,7 +882,7 @@ public class CompletionSuggestSearchIT extends ESIntegTestCase {
     }
 
     private List<String> getNames(Suggest.Suggestion.Entry<Suggest.Suggestion.Entry.Option> suggestEntry) {
-        List<String> names = Lists.newArrayList();
+        List<String> names = new ArrayList<>();
         for (Suggest.Suggestion.Entry.Option entry : suggestEntry.getOptions()) {
             names.add(entry.getText().string());
         }
diff --git a/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterSearchIT.java b/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterSearchIT.java
index 1d7ad85..90fcee2 100644
--- a/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterSearchIT.java
@@ -18,10 +18,10 @@
  */
 package org.elasticsearch.search.suggest;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.action.search.SearchRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.CollectionUtils;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
@@ -31,7 +31,7 @@ import java.util.List;
 import java.util.Locale;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.test.ESIntegTestCase.*;
+import static org.elasticsearch.test.ESIntegTestCase.Scope;
 import static org.hamcrest.Matchers.hasSize;
 import static org.hamcrest.Matchers.is;
 
@@ -76,7 +76,9 @@ public class CustomSuggesterSearchIT extends ESIntegTestCase {
         SearchResponse searchResponse = searchRequestBuilder.execute().actionGet();
 
         // TODO: infer type once JI-9019884 is fixed
-        List<Suggest.Suggestion.Entry<? extends Suggest.Suggestion.Entry.Option>> suggestions = Lists.<Suggest.Suggestion.Entry<? extends Suggest.Suggestion.Entry.Option>>newArrayList(searchResponse.getSuggest().getSuggestion("someName").iterator());
+        // TODO: see also JDK-8039214
+        List<Suggest.Suggestion.Entry<? extends Suggest.Suggestion.Entry.Option>> suggestions
+                = CollectionUtils.<Suggest.Suggestion.Entry<? extends Suggest.Suggestion.Entry.Option>>iterableAsArrayList(searchResponse.getSuggest().getSuggestion("someName"));
         assertThat(suggestions, hasSize(2));
         assertThat(suggestions.get(0).getText().string(), is(String.format(Locale.ROOT, "%s-%s-%s-12", randomText, randomField, randomSuffix)));
         assertThat(suggestions.get(1).getText().string(), is(String.format(Locale.ROOT, "%s-%s-%s-123", randomText, randomField, randomSuffix)));
diff --git a/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionPostingsFormatTest.java b/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionPostingsFormatTest.java
index 1b29173..0bbd1ce 100644
--- a/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionPostingsFormatTest.java
+++ b/core/src/test/java/org/elasticsearch/search/suggest/completion/CompletionPostingsFormatTest.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.search.suggest.completion;
 
-import com.google.common.collect.Lists;
-
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.FieldsConsumer;
@@ -89,7 +87,7 @@ public class CompletionPostingsFormatTest extends ESTestCase {
     public void testCompletionPostingsFormat() throws IOException {
         AnalyzingCompletionLookupProviderV1 providerV1 = new AnalyzingCompletionLookupProviderV1(true, false, true, true);
         AnalyzingCompletionLookupProvider currentProvider = new AnalyzingCompletionLookupProvider(true, false, true, true);
-        List<Completion090PostingsFormat.CompletionLookupProvider> providers = Lists.newArrayList(providerV1, currentProvider);
+        List<Completion090PostingsFormat.CompletionLookupProvider> providers = Arrays.asList(providerV1, currentProvider);
 
         Completion090PostingsFormat.CompletionLookupProvider randomProvider = providers.get(getRandom().nextInt(providers.size()));
         RAMDirectory dir = new RAMDirectory();
diff --git a/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java b/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java
index 75c7216..d36ecfa 100644
--- a/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java
+++ b/core/src/test/java/org/elasticsearch/snapshots/DedicatedClusterSnapshotRestoreIT.java
@@ -66,7 +66,6 @@ import org.elasticsearch.snapshots.mockstore.MockRepository;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.InternalTestCluster;
 import org.elasticsearch.test.rest.FakeRestRequest;
-import org.elasticsearch.transport.TransportModule;
 import org.junit.Test;
 
 import java.io.IOException;
@@ -79,22 +78,11 @@ import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicReference;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.test.ESIntegTestCase.ClusterScope;
 import static org.elasticsearch.test.ESIntegTestCase.Scope;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertBlocked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertThrows;
-import static org.hamcrest.Matchers.allOf;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
-import static org.hamcrest.Matchers.lessThan;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
 
 /**
  */
@@ -341,7 +329,7 @@ public class DedicatedClusterSnapshotRestoreIT extends AbstractSnapshotIntegTest
     @Test
     public void snapshotWithStuckNodeTest() throws Exception {
         logger.info("--> start 2 nodes");
-        ArrayList<String> nodes = newArrayList();
+        ArrayList<String> nodes = new ArrayList<>();
         nodes.add(internalCluster().startNode());
         nodes.add(internalCluster().startNode());
         Client client = client();
diff --git a/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java b/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java
index 7e28230..c3d3f0f 100644
--- a/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java
+++ b/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java
@@ -64,6 +64,7 @@ import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.index.store.IndexStore;
 import org.elasticsearch.indices.InvalidIndexNameException;
 import org.elasticsearch.repositories.RepositoriesService;
+import org.elasticsearch.repositories.RepositoryException;
 import org.elasticsearch.test.junit.annotations.TestLogging;
 import org.junit.Test;
 
@@ -78,30 +79,13 @@ import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.TimeUnit;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
 import static org.elasticsearch.index.shard.IndexShard.INDEX_REFRESH_INTERVAL;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAliasesExist;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAliasesMissing;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAllSuccessful;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertBlocked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertIndexTemplateExists;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertIndexTemplateMissing;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertThrows;
-import static org.hamcrest.Matchers.allOf;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.lessThan;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
-import static org.hamcrest.Matchers.startsWith;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
 
 public class SharedClusterSnapshotRestoreIT extends AbstractSnapshotIntegTestCase {
 
@@ -132,7 +116,7 @@ public class SharedClusterSnapshotRestoreIT extends AbstractSnapshotIntegTestCas
 
         ListenableActionFuture<FlushResponse> flushResponseFuture = null;
         if (randomBoolean()) {
-            ArrayList<String> indicesToFlush = newArrayList();
+            ArrayList<String> indicesToFlush = new ArrayList<>();
             for (int i = 1; i < 4; i++) {
                 if (randomBoolean()) {
                     indicesToFlush.add("test-idx-" + i);
@@ -1317,6 +1301,63 @@ public class SharedClusterSnapshotRestoreIT extends AbstractSnapshotIntegTestCas
         assertThat(getSnapshotsResponse.getSnapshots().size(), equalTo(0));
     }
 
+
+    @Test
+    public void readonlyRepositoryTest() throws Exception {
+        Client client = client();
+
+        logger.info("-->  creating repository");
+        Path repositoryLocation = randomRepoPath();
+        assertAcked(client.admin().cluster().preparePutRepository("test-repo")
+                .setType("fs").setSettings(Settings.settingsBuilder()
+                        .put("location", repositoryLocation)
+                        .put("compress", randomBoolean())
+                        .put("chunk_size", randomIntBetween(100, 1000), ByteSizeUnit.BYTES)));
+
+        createIndex("test-idx");
+        ensureGreen();
+
+        logger.info("--> indexing some data");
+        for (int i = 0; i < 100; i++) {
+            index("test-idx", "doc", Integer.toString(i), "foo", "bar" + i);
+        }
+        refresh();
+
+        logger.info("--> snapshot");
+        CreateSnapshotResponse createSnapshotResponse = client.admin().cluster().prepareCreateSnapshot("test-repo", "test-snap").setWaitForCompletion(true).setIndices("test-idx").get();
+        assertThat(createSnapshotResponse.getSnapshotInfo().successfulShards(), greaterThan(0));
+        assertThat(createSnapshotResponse.getSnapshotInfo().successfulShards(), equalTo(createSnapshotResponse.getSnapshotInfo().totalShards()));
+
+        assertThat(client.admin().cluster().prepareGetSnapshots("test-repo").setSnapshots("test-snap").get().getSnapshots().get(0).state(), equalTo(SnapshotState.SUCCESS));
+
+        logger.info("--> delete index");
+        cluster().wipeIndices("test-idx");
+
+        logger.info("--> create read-only URL repository");
+        assertAcked(client.admin().cluster().preparePutRepository("readonly-repo")
+                .setType("fs").setSettings(Settings.settingsBuilder()
+                        .put("location", repositoryLocation)
+                        .put("compress", randomBoolean())
+                        .put("readonly", true)
+                        .put("chunk_size", randomIntBetween(100, 1000), ByteSizeUnit.BYTES)));
+        logger.info("--> restore index after deletion");
+        RestoreSnapshotResponse restoreSnapshotResponse = client.admin().cluster().prepareRestoreSnapshot("readonly-repo", "test-snap").setWaitForCompletion(true).setIndices("test-idx").execute().actionGet();
+        assertThat(restoreSnapshotResponse.getRestoreInfo().totalShards(), greaterThan(0));
+
+        assertThat(client.prepareCount("test-idx").get().getCount(), equalTo(100L));
+
+        logger.info("--> list available shapshots");
+        GetSnapshotsResponse getSnapshotsResponse = client.admin().cluster().prepareGetSnapshots("readonly-repo").get();
+        assertThat(getSnapshotsResponse.getSnapshots(), notNullValue());
+        assertThat(getSnapshotsResponse.getSnapshots().size(), equalTo(1));
+
+        logger.info("--> try deleting snapshot");
+        assertThrows(client.admin().cluster().prepareDeleteSnapshot("readonly-repo", "test-snap"), RepositoryException.class, "cannot delete snapshot from a readonly repository");
+
+        logger.info("--> try making another snapshot");
+        assertThrows(client.admin().cluster().prepareCreateSnapshot("readonly-repo", "test-snap-2").setWaitForCompletion(true).setIndices("test-idx"), RepositoryException.class, "cannot create snapshot in a readonly repository");
+    }
+
     @Test
     public void throttlingTest() throws Exception {
         Client client = client();
diff --git a/core/src/test/java/org/elasticsearch/stresstest/manyindices/ManyNodesManyIndicesRecoveryStressTest.java b/core/src/test/java/org/elasticsearch/stresstest/manyindices/ManyNodesManyIndicesRecoveryStressTest.java
index ea4d20f..ccd25a1 100644
--- a/core/src/test/java/org/elasticsearch/stresstest/manyindices/ManyNodesManyIndicesRecoveryStressTest.java
+++ b/core/src/test/java/org/elasticsearch/stresstest/manyindices/ManyNodesManyIndicesRecoveryStressTest.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.stresstest.manyindices;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;
 import org.elasticsearch.action.count.CountResponse;
 import org.elasticsearch.client.Client;
@@ -28,6 +27,7 @@ import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.node.Node;
 import org.elasticsearch.node.NodeBuilder;
 
+import java.util.ArrayList;
 import java.util.List;
 
 public class ManyNodesManyIndicesRecoveryStressTest {
@@ -48,7 +48,7 @@ public class ManyNodesManyIndicesRecoveryStressTest {
                 .put("index.number_of_shards", 1)
                 .build();
 
-        List<Node> nodes = Lists.newArrayList();
+        List<Node> nodes = new ArrayList<>();
         for (int i = 0; i < NUM_NODES; i++) {
             nodes.add(NodeBuilder.nodeBuilder().settings(Settings.settingsBuilder().put(nodeSettings).put("name", "node" + i)).node());
         }
@@ -93,7 +93,7 @@ public class ManyNodesManyIndicesRecoveryStressTest {
         Thread.sleep(5000);
         System.out.println("--> All nodes are closed, starting back...");
 
-        nodes = Lists.newArrayList();
+        nodes = new ArrayList<>();
         for (int i = 0; i < NUM_NODES; i++) {
             nodes.add(NodeBuilder.nodeBuilder().settings(Settings.settingsBuilder().put(nodeSettings).put("name", "node" + i)).node());
         }
diff --git a/core/src/test/java/org/elasticsearch/test/ESAllocationTestCase.java b/core/src/test/java/org/elasticsearch/test/ESAllocationTestCase.java
index 991aea7..d12f4d6 100644
--- a/core/src/test/java/org/elasticsearch/test/ESAllocationTestCase.java
+++ b/core/src/test/java/org/elasticsearch/test/ESAllocationTestCase.java
@@ -46,8 +46,8 @@ import java.util.List;
 import java.util.Map;
 import java.util.Random;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
+import static org.elasticsearch.common.util.CollectionUtils.arrayAsArrayList;
 import static org.hamcrest.CoreMatchers.equalTo;
 import static org.hamcrest.CoreMatchers.is;
 
@@ -132,7 +132,7 @@ public abstract class ESAllocationTestCase extends ESTestCase {
         if (initializingShards.isEmpty()) {
             return clusterState;
         }
-        RoutingTable routingTable = strategy.applyStartedShards(clusterState, newArrayList(initializingShards.get(randomInt(initializingShards.size() - 1)))).routingTable();
+        RoutingTable routingTable = strategy.applyStartedShards(clusterState, arrayAsArrayList(initializingShards.get(randomInt(initializingShards.size() - 1)))).routingTable();
         return ClusterState.builder(clusterState).routingTable(routingTable).build();
     }
 
diff --git a/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java b/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java
index 798c66c..55fae7f 100644
--- a/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java
+++ b/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java
@@ -26,15 +26,7 @@ import com.carrotsearch.randomizedtesting.generators.RandomInts;
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
 import com.google.common.base.Joiner;
 import com.google.common.base.Predicate;
-import com.google.common.collect.Lists;
-
 import org.apache.http.impl.client.HttpClients;
-import org.elasticsearch.action.admin.cluster.state.ClusterStateResponse;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.routing.UnassignedInfo;
-import org.elasticsearch.cluster.routing.allocation.decider.EnableAllocationDecider;
-import org.elasticsearch.common.network.NetworkAddress;
-import org.elasticsearch.index.shard.MergeSchedulerConfig;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.TestUtil;
@@ -47,6 +39,7 @@ import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;
 import org.elasticsearch.action.admin.cluster.node.info.NodeInfo;
 import org.elasticsearch.action.admin.cluster.node.info.NodesInfoResponse;
+import org.elasticsearch.action.admin.cluster.state.ClusterStateResponse;
 import org.elasticsearch.action.admin.cluster.tasks.PendingClusterTasksResponse;
 import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
 import org.elasticsearch.action.admin.indices.exists.indices.IndicesExistsResponse;
@@ -69,17 +62,21 @@ import org.elasticsearch.client.Client;
 import org.elasticsearch.client.Requests;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MappingMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.routing.IndexRoutingTable;
 import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
 import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.cluster.routing.UnassignedInfo;
 import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;
+import org.elasticsearch.cluster.routing.allocation.decider.EnableAllocationDecider;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Priority;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.collect.Tuple;
+import org.elasticsearch.common.network.NetworkAddress;
 import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.InetSocketTransportAddress;
@@ -104,6 +101,7 @@ import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.MappedFieldType.Loading;
 import org.elasticsearch.index.mapper.internal.TimestampFieldMapper;
 import org.elasticsearch.index.shard.MergePolicyConfig;
+import org.elasticsearch.index.shard.MergeSchedulerConfig;
 import org.elasticsearch.index.translog.Translog;
 import org.elasticsearch.index.translog.TranslogConfig;
 import org.elasticsearch.index.translog.TranslogService;
@@ -119,28 +117,49 @@ import org.elasticsearch.search.SearchService;
 import org.elasticsearch.test.client.RandomizingClient;
 import org.elasticsearch.test.disruption.ServiceDisruptionScheme;
 import org.elasticsearch.test.rest.client.http.HttpRequestBuilder;
-import org.elasticsearch.transport.TransportModule;
 import org.hamcrest.Matchers;
 import org.joda.time.DateTimeZone;
-import org.junit.*;
+import org.junit.After;
+import org.junit.AfterClass;
+import org.junit.Before;
+import org.junit.BeforeClass;
 
 import java.io.IOException;
 import java.io.InputStream;
-import java.lang.annotation.*;
+import java.lang.annotation.Annotation;
+import java.lang.annotation.ElementType;
+import java.lang.annotation.Inherited;
+import java.lang.annotation.Retention;
+import java.lang.annotation.RetentionPolicy;
+import java.lang.annotation.Target;
 import java.net.InetAddress;
 import java.net.InetSocketAddress;
 import java.net.UnknownHostException;
 import java.nio.file.DirectoryStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.util.*;
-import java.util.concurrent.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.IdentityHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+import java.util.concurrent.Callable;
+import java.util.concurrent.CopyOnWriteArrayList;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
+import static org.elasticsearch.common.util.CollectionUtils.eagerPartition;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.test.XContentTestUtils.convertToMap;
 import static org.elasticsearch.test.XContentTestUtils.differenceBetweenMapsIgnoringArrayOrder;
@@ -1362,7 +1381,7 @@ public abstract class ESIntegTestCase extends ESTestCase {
                 }
             }
         } else {
-            List<List<IndexRequestBuilder>> partition = Lists.partition(builders, Math.min(MAX_BULK_INDEX_REQUEST_SIZE,
+            List<List<IndexRequestBuilder>> partition = eagerPartition(builders, Math.min(MAX_BULK_INDEX_REQUEST_SIZE,
                     Math.max(1, (int) (builders.size() * randomDouble()))));
             logger.info("Index [{}] docs async: [{}] bulk: [{}] partitions [{}]", builders.size(), false, true, partition.size());
             for (List<IndexRequestBuilder> segmented : partition) {
diff --git a/core/src/test/java/org/elasticsearch/test/ESTestCase.java b/core/src/test/java/org/elasticsearch/test/ESTestCase.java
index 8b7ed6e..e0c24a5 100644
--- a/core/src/test/java/org/elasticsearch/test/ESTestCase.java
+++ b/core/src/test/java/org/elasticsearch/test/ESTestCase.java
@@ -31,7 +31,6 @@ import com.carrotsearch.randomizedtesting.generators.RandomPicks;
 import com.carrotsearch.randomizedtesting.generators.RandomStrings;
 import com.carrotsearch.randomizedtesting.rules.TestRuleAdapter;
 import com.google.common.base.Predicate;
-
 import org.apache.lucene.uninverting.UninvertingReader;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
@@ -39,6 +38,7 @@ import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.TimeUnits;
 import org.elasticsearch.Version;
 import org.elasticsearch.bootstrap.BootstrapForTesting;
+import org.elasticsearch.cache.recycler.MockPageCacheRecycler;
 import org.elasticsearch.client.Requests;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.routing.DjbHashFunction;
@@ -46,19 +46,22 @@ import org.elasticsearch.common.io.PathUtils;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.MockBigArrays;
 import org.elasticsearch.common.util.concurrent.EsExecutors;
 import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;
 import org.elasticsearch.common.xcontent.XContentType;
 import org.elasticsearch.env.Environment;
 import org.elasticsearch.env.NodeEnvironment;
-import org.elasticsearch.common.util.MockBigArrays;
-import org.elasticsearch.cache.recycler.MockPageCacheRecycler;
+import org.elasticsearch.search.MockSearchService;
 import org.elasticsearch.test.junit.listeners.AssertionErrorThreadDumpPrinter;
 import org.elasticsearch.test.junit.listeners.LoggingListener;
 import org.elasticsearch.test.junit.listeners.ReproduceInfoPrinter;
-import org.elasticsearch.search.MockSearchService;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.junit.*;
+import org.junit.After;
+import org.junit.AfterClass;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Rule;
 import org.junit.rules.RuleChain;
 
 import java.io.IOException;
@@ -67,13 +70,18 @@ import java.nio.file.DirectoryStream;
 import java.nio.file.FileSystem;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
 import java.util.concurrent.Callable;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.TimeUnit;
 
-import static com.google.common.collect.Lists.newArrayList;
+import static org.elasticsearch.common.util.CollectionUtils.arrayAsArrayList;
 import static org.hamcrest.Matchers.equalTo;
 
 /**
@@ -375,27 +383,17 @@ public abstract class ESTestCase extends LuceneTestCase {
         return RandomizedTest.randomRealisticUnicodeOfCodepointLength(codePoints);
     }
 
-    public static String[] generateRandomStringArray(int maxArraySize, int maxStringSize, boolean allowNull, boolean allowEmpty) {
+    public static String[] generateRandomStringArray(int maxArraySize, int maxStringSize, boolean allowNull) {
         if (allowNull && random().nextBoolean()) {
             return null;
         }
-        int arraySize = randomIntBetween(allowEmpty ? 0 : 1, maxArraySize);
-        String[] array = new String[arraySize];
-        for (int i = 0; i < arraySize; i++) {
+        String[] array = new String[random().nextInt(maxArraySize)]; // allow empty arrays
+        for (int i = 0; i < array.length; i++) {
             array[i] = RandomStrings.randomAsciiOfLength(random(), maxStringSize);
         }
         return array;
     }
 
-    public static String[] generateRandomStringArray(int maxArraySize, int maxStringSize, boolean allowNull) {
-        return generateRandomStringArray(maxArraySize, maxStringSize, allowNull, true);
-    }
-
-    public static String randomTimeValue() {
-        final String[] values = new String[]{"d", "H", "ms", "s", "S", "w"};
-        return randomIntBetween(0, 1000) + randomFrom(values);
-    }
-
     /**
      * Runs the code block for 10 seconds waiting for no assertion to trip.
      */
@@ -574,7 +572,7 @@ public abstract class ESTestCase extends LuceneTestCase {
         if (size > values.length) {
             throw new IllegalArgumentException("Can\'t pick " + size + " random objects from a list of " + values.length + " objects");
         }
-        List<T> list = newArrayList(values);
+        List<T> list = arrayAsArrayList(values);
         Collections.shuffle(list);
         return list.subList(0, size);
     }
diff --git a/core/src/test/java/org/elasticsearch/test/ExternalTestCluster.java b/core/src/test/java/org/elasticsearch/test/ExternalTestCluster.java
index 42b780c..9a919a3 100644
--- a/core/src/test/java/org/elasticsearch/test/ExternalTestCluster.java
+++ b/core/src/test/java/org/elasticsearch/test/ExternalTestCluster.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.test;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.action.admin.cluster.node.info.NodeInfo;
 import org.elasticsearch.action.admin.cluster.node.info.NodesInfoResponse;
 import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
@@ -38,6 +37,7 @@ import org.elasticsearch.node.internal.InternalSettingsPreparer;
 import java.io.IOException;
 import java.net.InetSocketAddress;
 import java.nio.file.Path;
+import java.util.Collections;
 import java.util.Iterator;
 import java.util.concurrent.atomic.AtomicInteger;
 
@@ -153,7 +153,7 @@ public final class ExternalTestCluster extends TestCluster {
 
     @Override
     public Iterator<Client> iterator() {
-        return Lists.newArrayList(client).iterator();
+        return Collections.singleton(client).iterator();
     }
 
     @Override
diff --git a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
index f24ac1e..217e8da 100644
--- a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
+++ b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
@@ -29,7 +29,6 @@ import com.google.common.base.Predicates;
 import com.google.common.collect.Collections2;
 import com.google.common.collect.Iterables;
 import com.google.common.collect.Iterators;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 import com.google.common.util.concurrent.Futures;
@@ -63,7 +62,6 @@ import org.elasticsearch.common.io.FileSystemUtils;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
-import org.elasticsearch.common.network.NetworkUtils;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.settings.Settings.Builder;
 import org.elasticsearch.common.transport.InetSocketTransportAddress;
@@ -94,9 +92,9 @@ import org.elasticsearch.node.NodeMocksPlugin;
 import org.elasticsearch.node.internal.InternalSettingsPreparer;
 import org.elasticsearch.node.service.NodeService;
 import org.elasticsearch.script.ScriptService;
+import org.elasticsearch.search.MockSearchService;
 import org.elasticsearch.search.SearchService;
 import org.elasticsearch.test.disruption.ServiceDisruptionScheme;
-import org.elasticsearch.search.MockSearchService;
 import org.elasticsearch.test.store.MockFSIndexStore;
 import org.elasticsearch.test.transport.AssertingLocalTransport;
 import org.elasticsearch.test.transport.MockTransportService;
@@ -108,7 +106,6 @@ import org.junit.Assert;
 
 import java.io.Closeable;
 import java.io.IOException;
-import java.net.InetAddress;
 import java.net.InetSocketAddress;
 import java.nio.file.Path;
 import java.util.ArrayList;
@@ -130,16 +127,12 @@ import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 
 import static junit.framework.Assert.fail;
-import static org.apache.lucene.util.LuceneTestCase.TEST_NIGHTLY;
-import static org.apache.lucene.util.LuceneTestCase.rarely;
-import static org.apache.lucene.util.LuceneTestCase.usually;
+import static org.apache.lucene.util.LuceneTestCase.*;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.node.NodeBuilder.nodeBuilder;
 import static org.elasticsearch.test.ESTestCase.assertBusy;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoTimeout;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
+import static org.hamcrest.Matchers.*;
 import static org.junit.Assert.assertThat;
 
 /**
@@ -551,7 +544,7 @@ public final class InternalTestCluster extends TestCluster {
      * stop any of the running nodes.
      */
     public void ensureAtLeastNumDataNodes(int n) {
-        List<ListenableFuture<String>> futures = Lists.newArrayList();
+        List<ListenableFuture<String>> futures = new ArrayList<>();
         synchronized (this) {
             int size = numDataNodes();
             for (int i = size; i < n; i++) {
@@ -1183,7 +1176,7 @@ public final class InternalTestCluster extends TestCluster {
 
     @Override
     public InetSocketAddress[] httpAddresses() {
-        List<InetSocketAddress> addresses = Lists.newArrayList();
+        List<InetSocketAddress> addresses = new ArrayList<>();
         for (HttpServerTransport httpServerTransport : getInstances(HttpServerTransport.class)) {
             addresses.add(((InetSocketTransportAddress) httpServerTransport.boundAddress().publishAddress()).address());
         }
@@ -1587,7 +1580,7 @@ public final class InternalTestCluster extends TestCluster {
      * Starts multiple nodes in an async manner with the given settings and version and returns future with its name.
      */
     public synchronized ListenableFuture<List<String>> startNodesAsync(final int numNodes, final Settings settings, final Version version) {
-        List<ListenableFuture<String>> futures = Lists.newArrayList();
+        List<ListenableFuture<String>> futures = new ArrayList<>();
         for (int i = 0; i < numNodes; i++) {
             futures.add(startNodeAsync(settings, version));
         }
@@ -1599,7 +1592,7 @@ public final class InternalTestCluster extends TestCluster {
      * The order of the node names returned matches the order of the settings provided.
      */
     public synchronized ListenableFuture<List<String>> startNodesAsync(final Settings... settings) {
-        List<ListenableFuture<String>> futures = Lists.newArrayList();
+        List<ListenableFuture<String>> futures = new ArrayList<>();
         for (Settings setting : settings) {
             futures.add(startNodeAsync(setting, Version.CURRENT));
         }
diff --git a/core/src/test/java/org/elasticsearch/test/MockLogAppender.java b/core/src/test/java/org/elasticsearch/test/MockLogAppender.java
index 2e0c293..c0866a81 100644
--- a/core/src/test/java/org/elasticsearch/test/MockLogAppender.java
+++ b/core/src/test/java/org/elasticsearch/test/MockLogAppender.java
@@ -23,9 +23,9 @@ import org.apache.log4j.Level;
 import org.apache.log4j.spi.LoggingEvent;
 import org.elasticsearch.common.regex.Regex;
 
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
 import static org.hamcrest.CoreMatchers.equalTo;
 import static org.hamcrest.MatcherAssert.assertThat;
 
@@ -39,7 +39,7 @@ public class MockLogAppender extends AppenderSkeleton {
     private List<LoggingExpectation> expectations;
 
     public MockLogAppender() {
-        expectations = newArrayList();
+        expectations = new ArrayList<>();
     }
 
     public void addExpectation(LoggingExpectation expectation) {
diff --git a/core/src/test/java/org/elasticsearch/test/TestSearchContext.java b/core/src/test/java/org/elasticsearch/test/TestSearchContext.java
index fa8aeed..e6a37dc 100644
--- a/core/src/test/java/org/elasticsearch/test/TestSearchContext.java
+++ b/core/src/test/java/org/elasticsearch/test/TestSearchContext.java
@@ -36,6 +36,7 @@ import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.analysis.AnalysisService;
 import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
+import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.MapperService;
@@ -284,8 +285,8 @@ public class TestSearchContext extends SearchContext {
         return searcher;
     }
 
-    public void setSearcher(ContextIndexSearcher searcher) {
-        this.searcher = searcher;
+    public void setSearcher(Engine.Searcher searcher) {
+        this.searcher = new ContextIndexSearcher(this, searcher);
     }
 
     @Override
diff --git a/core/src/test/java/org/elasticsearch/test/XContentTestUtils.java b/core/src/test/java/org/elasticsearch/test/XContentTestUtils.java
index 6479303..866a19e 100644
--- a/core/src/test/java/org/elasticsearch/test/XContentTestUtils.java
+++ b/core/src/test/java/org/elasticsearch/test/XContentTestUtils.java
@@ -19,13 +19,13 @@
 
 package org.elasticsearch.test;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -78,7 +78,7 @@ public final class XContentTestUtils {
             }
         } else if (first instanceof List) {
             if (second instanceof List) {
-                List<Object> secondList = Lists.newArrayList((List<Object>) second);
+                List<Object> secondList = new ArrayList<>((List<Object>) second);
                 List<Object> firstList = (List<Object>) first;
                 if (firstList.size() == secondList.size()) {
                     String reason = path + ": no matches found";
diff --git a/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java b/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java
index 9315fff..f3e18d7 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/ESRestTestCase.java
@@ -22,7 +22,6 @@ package org.elasticsearch.test.rest;
 import com.carrotsearch.randomizedtesting.RandomizedTest;
 import com.carrotsearch.randomizedtesting.annotations.TestGroup;
 import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;
-import com.google.common.collect.Lists;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.apache.lucene.util.LuceneTestCase.SuppressFsync;
@@ -68,6 +67,7 @@ import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.PathMatcher;
 import java.nio.file.StandardCopyOption;
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.List;
@@ -169,11 +169,11 @@ public abstract class ESRestTestCase extends ESIntegTestCase {
             enabled = false;
         }
         if (!enabled) {
-            return Lists.newArrayList();
+            return new ArrayList<>();
         }
         //parse tests only if rest test group is enabled, otherwise rest tests might not even be available on file system
         List<RestTestCandidate> restTestCandidates = collectTestCandidates(id, count);
-        List<Object[]> objects = Lists.newArrayList();
+        List<Object[]> objects = new ArrayList<>();
         for (RestTestCandidate restTestCandidate : restTestCandidates) {
             objects.add(new Object[]{restTestCandidate});
         }
@@ -181,7 +181,7 @@ public abstract class ESRestTestCase extends ESIntegTestCase {
     }
 
     private static List<RestTestCandidate> collectTestCandidates(int id, int count) throws RestTestParseException, IOException {
-        List<RestTestCandidate> testCandidates = Lists.newArrayList();
+        List<RestTestCandidate> testCandidates = new ArrayList<>();
         FileSystem fileSystem = getFileSystem();
         // don't make a try-with, getFileSystem returns null
         // ... and you can't close() the default filesystem
@@ -191,7 +191,7 @@ public abstract class ESRestTestCase extends ESIntegTestCase {
             RestTestSuiteParser restTestSuiteParser = new RestTestSuiteParser();
             //yaml suites are grouped by directory (effectively by api)
             for (String api : yamlSuites.keySet()) {
-                List<Path> yamlFiles = Lists.newArrayList(yamlSuites.get(api));
+                List<Path> yamlFiles = new ArrayList<>(yamlSuites.get(api));
                 for (Path yamlFile : yamlFiles) {
                     String key = api + yamlFile.getFileName().toString();
                     if (mustExecute(key, id, count)) {
diff --git a/core/src/test/java/org/elasticsearch/test/rest/client/RestClient.java b/core/src/test/java/org/elasticsearch/test/rest/client/RestClient.java
index f18f920..4eed551 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/client/RestClient.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/client/RestClient.java
@@ -19,10 +19,8 @@
 package org.elasticsearch.test.rest.client;
 
 import com.carrotsearch.randomizedtesting.RandomizedTest;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
-
 import org.apache.http.config.Registry;
 import org.apache.http.config.RegistryBuilder;
 import org.apache.http.conn.socket.ConnectionSocketFactory;
@@ -46,6 +44,7 @@ import org.elasticsearch.test.rest.client.http.HttpResponse;
 import org.elasticsearch.test.rest.spec.RestApi;
 import org.elasticsearch.test.rest.spec.RestSpec;
 
+import javax.net.ssl.SSLContext;
 import java.io.Closeable;
 import java.io.IOException;
 import java.io.InputStream;
@@ -57,13 +56,12 @@ import java.security.KeyStore;
 import java.security.KeyStoreException;
 import java.security.NoSuchAlgorithmException;
 import java.security.cert.CertificateException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
-import javax.net.ssl.SSLContext;
-
 /**
  * REST client used to test the elasticsearch REST layer
  * Holds the {@link RestSpec} used to translate api calls into REST calls
@@ -136,7 +134,7 @@ public class RestClient implements Closeable {
      */
     public RestResponse callApi(String apiName, Map<String, String> params, String body) throws IOException, RestException {
 
-        List<Integer> ignores = Lists.newArrayList();
+        List<Integer> ignores = new ArrayList<>();
         Map<String, String> requestParams = null;
         if (params != null) {
             //makes a copy of the parameters before modifying them for this specific request
diff --git a/core/src/test/java/org/elasticsearch/test/rest/json/JsonPath.java b/core/src/test/java/org/elasticsearch/test/rest/json/JsonPath.java
index 567e849..c3dbd58 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/json/JsonPath.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/json/JsonPath.java
@@ -18,13 +18,12 @@
  */
 package org.elasticsearch.test.rest.json;
 
-import com.google.common.collect.Lists;
-
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.json.JsonXContent;
 import org.elasticsearch.test.rest.Stash;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -93,7 +92,7 @@ public class JsonPath {
     }
 
     private String[] parsePath(String path) {
-        List<String> list = Lists.newArrayList();
+        List<String> list = new ArrayList<>();
         StringBuilder current = new StringBuilder();
         boolean escape = false;
         for (int i = 0; i < path.length(); i++) {
diff --git a/core/src/test/java/org/elasticsearch/test/rest/parser/SkipSectionParser.java b/core/src/test/java/org/elasticsearch/test/rest/parser/SkipSectionParser.java
index 0a81583..3373382 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/parser/SkipSectionParser.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/parser/SkipSectionParser.java
@@ -18,12 +18,12 @@
  */
 package org.elasticsearch.test.rest.parser;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.test.rest.section.SkipSection;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -40,7 +40,7 @@ public class SkipSectionParser implements RestTestFragmentParser<SkipSection> {
         XContentParser.Token token;
         String version = null;
         String reason = null;
-        List<String> features = Lists.newArrayList();
+        List<String> features = new ArrayList<>();
 
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
diff --git a/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java b/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java
index 2a49cd4..a40d226 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java
@@ -21,9 +21,9 @@ package org.elasticsearch.test.rest.section;
 import com.google.common.base.Joiner;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
@@ -34,7 +34,7 @@ public class ApiCallSection {
 
     private final String api;
     private final Map<String, String> params = Maps.newHashMap();
-    private final List<Map<String, Object>> bodies = Lists.newArrayList();
+    private final List<Map<String, Object>> bodies = new ArrayList<>();
 
     public ApiCallSection(String api) {
         this.api = api;
diff --git a/core/src/test/java/org/elasticsearch/test/rest/section/RestTestSuite.java b/core/src/test/java/org/elasticsearch/test/rest/section/RestTestSuite.java
index a9047c1..923ba93 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/section/RestTestSuite.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/section/RestTestSuite.java
@@ -18,9 +18,9 @@
  */
 package org.elasticsearch.test.rest.section;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
 
@@ -71,6 +71,6 @@ public class RestTestSuite {
     }
 
     public List<TestSection> getTestSections() {
-        return Lists.newArrayList(testSections);
+        return new ArrayList<>(testSections);
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/test/rest/section/SetupSection.java b/core/src/test/java/org/elasticsearch/test/rest/section/SetupSection.java
index 72f653e..45c66fb 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/section/SetupSection.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/section/SetupSection.java
@@ -18,8 +18,7 @@
  */
 package org.elasticsearch.test.rest.section;
 
-import com.google.common.collect.Lists;
-
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -36,7 +35,7 @@ public class SetupSection {
 
     private SkipSection skipSection;
 
-    private List<DoSection> doSections = Lists.newArrayList();
+    private List<DoSection> doSections = new ArrayList<>();
 
     public SkipSection getSkipSection() {
         return skipSection;
diff --git a/core/src/test/java/org/elasticsearch/test/rest/section/SkipSection.java b/core/src/test/java/org/elasticsearch/test/rest/section/SkipSection.java
index e7ab455..179d0a1 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/section/SkipSection.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/section/SkipSection.java
@@ -18,12 +18,11 @@
  */
 package org.elasticsearch.test.rest.section;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.Version;
-import org.elasticsearch.common.Strings;
 import org.elasticsearch.test.VersionUtils;
 import org.elasticsearch.test.rest.support.Features;
 
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -44,7 +43,7 @@ public class SkipSection {
     private SkipSection() {
         this.lowerVersion = null;
         this.upperVersion = null;
-        this.features = Lists.newArrayList();
+        this.features = new ArrayList<>();
         this.reason = null;
     }
 
diff --git a/core/src/test/java/org/elasticsearch/test/rest/section/TestSection.java b/core/src/test/java/org/elasticsearch/test/rest/section/TestSection.java
index def613b..3f44e5c 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/section/TestSection.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/section/TestSection.java
@@ -18,8 +18,7 @@
  */
 package org.elasticsearch.test.rest.section;
 
-import com.google.common.collect.Lists;
-
+import java.util.ArrayList;
 import java.util.List;
 
 /**
@@ -32,7 +31,7 @@ public class TestSection implements Comparable<TestSection> {
 
     public TestSection(String name) {
         this.name = name;
-        this.executableSections = Lists.newArrayList();
+        this.executableSections = new ArrayList<>();
     }
 
     public String getName() {
diff --git a/core/src/test/java/org/elasticsearch/test/rest/spec/RestApi.java b/core/src/test/java/org/elasticsearch/test/rest/spec/RestApi.java
index 0996df4..7931be1 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/spec/RestApi.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/spec/RestApi.java
@@ -18,11 +18,11 @@
  */
 package org.elasticsearch.test.rest.spec;
 
-import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 import org.apache.http.client.methods.HttpPost;
 import org.apache.http.client.methods.HttpPut;
 
+import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -35,10 +35,10 @@ import java.util.regex.Pattern;
 public class RestApi {
 
     private final String name;
-    private List<String> methods = Lists.newArrayList();
-    private List<String> paths = Lists.newArrayList();
-    private List<String> pathParts = Lists.newArrayList();
-    private List<String> params = Lists.newArrayList();
+    private List<String> methods = new ArrayList<>();
+    private List<String> paths = new ArrayList<>();
+    private List<String> pathParts = new ArrayList<>();
+    private List<String> params = new ArrayList<>();
     private BODY body = BODY.NOT_SUPPORTED;
 
     public static enum BODY {
@@ -63,7 +63,7 @@ public class RestApi {
     public List<String> getSupportedMethods(Set<String> restParams) {
         //we try to avoid hardcoded mappings but the index api is the exception
         if ("index".equals(name) || "create".equals(name)) {
-            List<String> indexMethods = Lists.newArrayList();
+            List<String> indexMethods = new ArrayList<>();
             for (String method : methods) {
                 if (restParams.contains("id")) {
                     //PUT when the id is provided
@@ -163,7 +163,7 @@ public class RestApi {
      */
     private List<RestPath> findMatchingRestPaths(Set<String> restParams) {
 
-        List<RestPath> matchingRestPaths = Lists.newArrayList();
+        List<RestPath> matchingRestPaths = new ArrayList<>();
         RestPath[] restPaths = buildRestPaths();
 
         for (RestPath restPath : restPaths) {
diff --git a/core/src/test/java/org/elasticsearch/test/rest/support/Features.java b/core/src/test/java/org/elasticsearch/test/rest/support/Features.java
index 3b86726..018d241 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/support/Features.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/support/Features.java
@@ -19,9 +19,9 @@
 
 package org.elasticsearch.test.rest.support;
 
-import com.google.common.collect.Lists;
 import org.elasticsearch.test.ESIntegTestCase;
 
+import java.util.Arrays;
 import java.util.List;
 
 /**
@@ -34,7 +34,7 @@ import java.util.List;
  */
 public final class Features {
 
-    private static final List<String> SUPPORTED = Lists.newArrayList("stash_in_path", "groovy_scripting");
+    private static final List<String> SUPPORTED = Arrays.asList("stash_in_path", "groovy_scripting");
 
     private Features() {
 
diff --git a/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java b/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
index c253a75..d9b9b49 100644
--- a/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
+++ b/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
@@ -80,7 +80,7 @@ public class AssertingLocalTransport extends LocalTransport {
         ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersionBetween(random, minVersion, maxVersion), response);
         super.handleParsedResponse(response, handler);
     }
-
+    
     @Override
     public void sendRequest(final DiscoveryNode node, final long requestId, final String action, final TransportRequest request, TransportRequestOptions options) throws IOException, TransportException {
         ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersionBetween(random, minVersion, maxVersion), request);
diff --git a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
index 44b117a..566d1d8 100644
--- a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
+++ b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
@@ -49,7 +49,7 @@ import org.elasticsearch.index.query.BoolQueryBuilder;
 import org.elasticsearch.index.query.GeoShapeQueryBuilder;
 import org.elasticsearch.index.query.MoreLikeThisQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.TermsQueryBuilder;
+import org.elasticsearch.index.query.TermsLookupQueryBuilder;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.rest.RestController;
 import org.elasticsearch.script.ScriptService;
@@ -141,7 +141,7 @@ public class ContextAndHeaderTransportIT extends ESIntegTestCase {
                 .setSource(jsonBuilder().startObject().field("username", "foo").endObject()).get();
         transportClient().admin().indices().prepareRefresh(queryIndex, lookupIndex).get();
 
-        TermsQueryBuilder termsLookupFilterBuilder = QueryBuilders.termsLookupQuery("username").lookupIndex(lookupIndex).lookupType("type").lookupId("1").lookupPath("followers");
+        TermsLookupQueryBuilder termsLookupFilterBuilder = QueryBuilders.termsLookupQuery("username").lookupIndex(lookupIndex).lookupType("type").lookupId("1").lookupPath("followers");
         BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery().must(QueryBuilders.matchAllQuery()).must(termsLookupFilterBuilder);
 
         SearchResponse searchResponse = transportClient()
diff --git a/core/src/test/java/org/elasticsearch/ttl/SimpleTTLIT.java b/core/src/test/java/org/elasticsearch/ttl/SimpleTTLIT.java
index 6c4bd96..b24a752 100644
--- a/core/src/test/java/org/elasticsearch/ttl/SimpleTTLIT.java
+++ b/core/src/test/java/org/elasticsearch/ttl/SimpleTTLIT.java
@@ -20,17 +20,21 @@
 package org.elasticsearch.ttl;
 
 import com.google.common.base.Predicate;
+
 import org.elasticsearch.action.admin.indices.mapping.get.GetMappingsResponse;
 import org.elasticsearch.action.admin.indices.mapping.put.PutMappingResponse;
 import org.elasticsearch.action.admin.indices.stats.IndicesStatsResponse;
 import org.elasticsearch.action.get.GetResponse;
 import org.elasticsearch.action.index.IndexResponse;
+import org.elasticsearch.action.update.UpdateRequestBuilder;
+import org.elasticsearch.action.update.UpdateResponse;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.index.get.GetField;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
-import org.junit.Test;
+import org.elasticsearch.test.ESIntegTestCase.Scope;
 
 import java.io.IOException;
 import java.util.Locale;
@@ -39,9 +43,16 @@ import java.util.concurrent.TimeUnit;
 
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.test.ESIntegTestCase.Scope;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.hamcrest.Matchers.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
+import static org.hamcrest.Matchers.both;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.greaterThan;
+import static org.hamcrest.Matchers.hasKey;
+import static org.hamcrest.Matchers.is;
+import static org.hamcrest.Matchers.lessThanOrEqualTo;
+import static org.hamcrest.Matchers.notNullValue;
+import static org.hamcrest.Matchers.nullValue;
 
 @ClusterScope(scope= Scope.SUITE, numDataNodes = 1)
 public class SimpleTTLIT extends ESIntegTestCase {
@@ -63,7 +74,6 @@ public class SimpleTTLIT extends ESIntegTestCase {
                 .build();
     }
 
-    @Test
     public void testSimpleTTL() throws Exception {
         assertAcked(prepareCreate("test")
                 .addMapping("type1", XContentFactory.jsonBuilder()
@@ -200,7 +210,7 @@ public class SimpleTTLIT extends ESIntegTestCase {
         assertThat(getResponse.isExists(), equalTo(false));
     }
 
-    @Test // issue 5053
+    // issue 5053
     public void testThatUpdatingMappingShouldNotRemoveTTLConfiguration() throws Exception {
         String index = "foo";
         String type = "mytype";
@@ -220,6 +230,63 @@ public class SimpleTTLIT extends ESIntegTestCase {
         assertTTLMappingEnabled(index, type);
     }
 
+    /**
+     * Test that updates with detect_noop set to true (the default) that don't
+     * change the source don't change the ttl. This is unexpected behavior and
+     * documented in ttl-field.asciidoc. If this behavior changes it is safe to
+     * rewrite this test to reflect the new behavior and to change the
+     * documentation.
+     */
+    public void testNoopUpdate() throws IOException {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1", XContentFactory.jsonBuilder()
+                        .startObject()
+                        .startObject("type1")
+                        .startObject("_timestamp").field("enabled", true).endObject()
+                        .startObject("_ttl").field("enabled", true).endObject()
+                        .endObject()
+                        .endObject()));
+        ensureYellow("test");
+
+        long aLongTime = 10000000;
+        long firstTtl = aLongTime * 3;
+        long secondTtl = aLongTime * 2;
+        long thirdTtl = aLongTime * 1;
+        IndexResponse indexResponse = client().prepareIndex("test", "type1", "1").setSource("field1", "value1")
+                .setTTL(firstTtl).setRefresh(true).get();
+        assertTrue(indexResponse.isCreated());
+        assertThat(getTtl("type1", 1), both(lessThanOrEqualTo(firstTtl)).and(greaterThan(secondTtl)));
+
+        // Updating with the default detect_noop without a change to the document doesn't change the ttl.
+        UpdateRequestBuilder update = client().prepareUpdate("test", "type1", "1").setDoc("field1", "value1").setTtl(secondTtl);
+        assertThat(updateAndGetTtl(update), both(lessThanOrEqualTo(firstTtl)).and(greaterThan(secondTtl)));
+
+        // Updating with the default detect_noop with a change to the document does change the ttl.
+        update = client().prepareUpdate("test", "type1", "1").setDoc("field1", "value2").setTtl(secondTtl);
+        assertThat(updateAndGetTtl(update), both(lessThanOrEqualTo(secondTtl)).and(greaterThan(thirdTtl)));
+
+        // Updating with detect_noop=true without a change to the document doesn't change the ttl.
+        update = client().prepareUpdate("test", "type1", "1").setDoc("field1", "value2").setTtl(secondTtl).setDetectNoop(true);
+        assertThat(updateAndGetTtl(update), both(lessThanOrEqualTo(secondTtl)).and(greaterThan(thirdTtl)));
+
+        // Updating with detect_noop=false without a change to the document does change the ttl.
+        update = client().prepareUpdate("test", "type1", "1").setDoc("field1", "value2").setTtl(thirdTtl).setDetectNoop(false);
+        assertThat(updateAndGetTtl(update), lessThanOrEqualTo(thirdTtl));
+    }
+
+    private long updateAndGetTtl(UpdateRequestBuilder update) {
+        UpdateResponse updateResponse = update.setFields("_ttl").get();
+        assertThat(updateResponse.getShardInfo().getFailed(), equalTo(0));
+        // You can't actually fetch _ttl from an update so we use a get.
+        return getTtl(updateResponse.getType(), updateResponse.getId());
+    }
+
+    private long getTtl(String type, Object id) {
+        GetResponse getResponse = client().prepareGet("test", type, id.toString()).setFields("_ttl").setRealtime(true).execute()
+                .actionGet();
+        return ((Number) getResponse.getField("_ttl").getValue()).longValue();
+    }
+
     private void assertTTLMappingEnabled(String index, String type) throws IOException {
         String errMsg = String.format(Locale.ROOT, "Expected ttl field mapping to be enabled for %s/%s", index, type);
 
diff --git a/core/src/test/java/org/elasticsearch/update/UpdateNoopIT.java b/core/src/test/java/org/elasticsearch/update/UpdateNoopIT.java
index 3f0b1bc..499fb52 100644
--- a/core/src/test/java/org/elasticsearch/update/UpdateNoopIT.java
+++ b/core/src/test/java/org/elasticsearch/update/UpdateNoopIT.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.update;
 
+import org.elasticsearch.action.update.UpdateRequestBuilder;
 import org.elasticsearch.action.update.UpdateResponse;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
@@ -44,8 +45,10 @@ public class UpdateNoopIT extends ESIntegTestCase {
         updateAndCheckSource(4, fields("bar", null));
         updateAndCheckSource(4, fields("bar", null));
         updateAndCheckSource(5, fields("bar", "foo"));
+        // detect_noop defaults to true
+        updateAndCheckSource(5, null, fields("bar", "foo"));
 
-        assertEquals(3, totalNoopUpdates());
+        assertEquals(4, totalNoopUpdates());
     }
 
     @Test
@@ -210,7 +213,8 @@ public class UpdateNoopIT extends ESIntegTestCase {
     }
 
     /**
-     * Totally empty requests are noop if and only if detect noops is true.
+     * Totally empty requests are noop if and only if detect noops is true and
+     * its true by default.
      */
     @Test
     public void totallyEmpty() throws Exception {
@@ -223,6 +227,7 @@ public class UpdateNoopIT extends ESIntegTestCase {
                 .endObject());
         update(true, 1, XContentFactory.jsonBuilder().startObject().endObject());
         update(false, 2, XContentFactory.jsonBuilder().startObject().endObject());
+        update(null, 2, XContentFactory.jsonBuilder().startObject().endObject());
     }
 
     private XContentBuilder fields(Object... fields) throws IOException {
@@ -237,17 +242,23 @@ public class UpdateNoopIT extends ESIntegTestCase {
     }
 
     private void updateAndCheckSource(long expectedVersion, XContentBuilder xContentBuilder) {
-        UpdateResponse updateResponse = update(true, expectedVersion, xContentBuilder);
+        updateAndCheckSource(expectedVersion, true, xContentBuilder);
+    }
+
+    private void updateAndCheckSource(long expectedVersion, Boolean detectNoop, XContentBuilder xContentBuilder) {
+        UpdateResponse updateResponse = update(detectNoop, expectedVersion, xContentBuilder);
         assertEquals(updateResponse.getGetResult().sourceRef().toUtf8(), xContentBuilder.bytes().toUtf8());
     }
 
-    private UpdateResponse update(boolean detectNoop, long expectedVersion, XContentBuilder xContentBuilder) {
-        UpdateResponse updateResponse = client().prepareUpdate("test", "type1", "1")
+    private UpdateResponse update(Boolean detectNoop, long expectedVersion, XContentBuilder xContentBuilder) {
+        UpdateRequestBuilder updateRequest = client().prepareUpdate("test", "type1", "1")
                 .setDoc(xContentBuilder.bytes().toUtf8())
                 .setDocAsUpsert(true)
-                .setDetectNoop(detectNoop)
-                .setFields("_source")
-                .execute().actionGet();
+                .setFields("_source");
+        if (detectNoop != null) {
+            updateRequest.setDetectNoop(detectNoop);
+        }
+        UpdateResponse updateResponse = updateRequest.get();
         assertThat(updateResponse.getGetResult(), notNullValue());
         assertEquals(expectedVersion, updateResponse.getVersion());
         return updateResponse;
diff --git a/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java b/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
index 6f70d36..be493cd 100644
--- a/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
@@ -236,7 +236,7 @@ public class SimpleValidateQueryIT extends ESIntegTestCase {
                 containsString("(field:huge field:brown) +field:pidgin"), true);
         assertExplanation(QueryBuilders.commonTermsQuery("field", "the brown").analyzer("stop"),
                 containsString("field:brown"), true);
-
+        
         // match queries with cutoff frequency
         assertExplanation(QueryBuilders.matchQuery("field", "huge brown pidgin").cutoffFrequency(1),
                 containsString("(field:huge field:brown) +field:pidgin"), true);
@@ -276,7 +276,11 @@ public class SimpleValidateQueryIT extends ESIntegTestCase {
         assertThat(client().admin().indices().prepareValidateQuery("test").setSource(new BytesArray("{\"query\": {\"term\" : { \"user\" : \"kimchy\" }}, \"foo\": \"bar\"}")).get().isValid(), equalTo(false));
     }
 
-    private static void assertExplanation(QueryBuilder queryBuilder, Matcher<String> matcher, boolean withRewrite) {
+    private void assertExplanation(QueryBuilder queryBuilder, Matcher<String> matcher) {
+        assertExplanation(queryBuilder, matcher, false);
+    }
+
+    private void assertExplanation(QueryBuilder queryBuilder, Matcher<String> matcher, boolean withRewrite) {
         ValidateQueryResponse response = client().admin().indices().prepareValidateQuery("test")
                 .setTypes("type1")
                 .setQuery(queryBuilder)
diff --git a/core/src/test/java/org/elasticsearch/watcher/FileWatcherTest.java b/core/src/test/java/org/elasticsearch/watcher/FileWatcherTest.java
index 457f757..537fd87 100644
--- a/core/src/test/java/org/elasticsearch/watcher/FileWatcherTest.java
+++ b/core/src/test/java/org/elasticsearch/watcher/FileWatcherTest.java
@@ -29,12 +29,10 @@ import java.nio.charset.Charset;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.collect.Lists.newArrayList;
-import static org.hamcrest.Matchers.contains;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.hasSize;
+import static org.hamcrest.Matchers.*;
 
 @LuceneTestCase.SuppressFileSystems("ExtrasFS")
 public class FileWatcherTest extends ESTestCase {
@@ -51,7 +49,7 @@ public class FileWatcherTest extends ESTestCase {
             return rootDir.toUri().relativize(file.toUri()).getPath();
         }
 
-        private List<String> notifications = newArrayList();
+        private List<String> notifications = new ArrayList<>();
 
         @Override
         public void onFileInit(Path file) {
diff --git a/dev-tools/create_bwc_index.py b/dev-tools/create_bwc_index.py
index 1a2bfbd..22ba7f7 100644
--- a/dev-tools/create_bwc_index.py
+++ b/dev-tools/create_bwc_index.py
@@ -237,15 +237,19 @@ def generate_index(client, version, index_name):
       }
     }
 
+  settings = {
+    'number_of_shards': 1,
+    'number_of_replicas': 0,
+  }
+  if version.startswith('0.') or version.startswith('1.'):
+    # Same as ES default (60 seconds), but missing the units to make sure they are inserted on upgrade:
+    settings['gc_deletes'] = '60000',
+    # Same as ES default (5 GB), but missing the units to make sure they are inserted on upgrade:
+    settings['merge.policy.max_merged_segment'] = '5368709120'
+    
+
   client.indices.create(index=index_name, body={
-      'settings': {
-          'number_of_shards': 1,
-          'number_of_replicas': 0,
-          # Same as ES default (60 seconds), but missing the units to make sure they are inserted on upgrade:
-          "gc_deletes": '60000',
-          # Same as ES default (5 GB), but missing the units to make sure they are inserted on upgrade:
-          "merge.policy.max_merged_segment": '5368709120'
-      },
+      'settings': settings,
       'mappings': mappings
   })
   health = client.cluster.health(wait_for_status='green', wait_for_relocating_shards=0)
@@ -374,7 +378,8 @@ def create_bwc_index(cfg, version):
     # 10067: get a delete-by-query into the translog on upgrade.  We must do
     # this after the snapshot, because it calls flush.  Otherwise the index
     # will already have the deletions applied on upgrade.
-    delete_by_query(client, version, index_name, 'doc')
+    if version.startswith('0.') or version.startswith('1.'):
+      delete_by_query(client, version, index_name, 'doc')
 
     shutdown_node(node)
     node = None
diff --git a/dev-tools/get-bwc-version.py b/dev-tools/get-bwc-version.py
index a44c06a..54c559d 100644
--- a/dev-tools/get-bwc-version.py
+++ b/dev-tools/get-bwc-version.py
@@ -64,8 +64,10 @@ def main():
   if c.version == '1.2.0':
     # 1.2.0 was pulled from download.elasticsearch.org because of routing bug:
     url = 'http://central.maven.org/maven2/org/elasticsearch/elasticsearch/1.2.0/%s' % filename
-  else:
+  elif c.version.startswith('0.') or c.version.startswith('1.'):
     url = 'https://download.elasticsearch.org/elasticsearch/elasticsearch/%s' % filename
+  else:
+    url = 'http://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/%s/%s' % (c.version, filename)
   print('Downloading %s' % url)
   urllib.request.urlretrieve(url, filename)
 
diff --git a/dev-tools/prepare_release_candidate.py b/dev-tools/prepare_release_candidate.py
index cd35b70..c2f7726 100644
--- a/dev-tools/prepare_release_candidate.py
+++ b/dev-tools/prepare_release_candidate.py
@@ -280,5 +280,14 @@ if __name__ == "__main__":
     """)
     print('NOTE: Running s3cmd might require you to create a config file with your credentials, if the s3cmd does not support suppliying them via the command line!')
   print('*** Once the release is deployed and published send out the following mail to dev@elastic.co:')
-  print(MAIL_TEMPLATE % ({'version' : release_version, 'hash': shortHash, 'major_minor_version' : major_minor_version}))
+  string_format_dict = {'version' : release_version, 'hash': shortHash, 'major_minor_version' : major_minor_version}
+  print(MAIL_TEMPLATE % string_format_dict)
+
+  print('To publish the release and the repo on S3 execute the following commands:')
+  print('   s3cmd cp --recursive s3://download.elasticsearch.org/elasticsearch/staging/%(version)s-%(hash)s/repos/elasticsearch/%(major_minor_version)s/ s3://packages.elasticsearch.org/elasticsearch/%(major_minor_version)s'  % string_format_dict)
+  print('   s3cmd cp --recursive s3://download.elasticsearch.org/elasticsearch/staging/%(version)s-%(hash)s/org/ s3://download.elasticsearch.org/elasticsearch/release/org'  % string_format_dict)
+  print('Now go ahead and tag the release:')
+  print('   git tag -a v%(version)s %(hash)s'  % string_format_dict)
+  print('   git push origin v%(version)s' % string_format_dict )
+
 
diff --git a/dev-tools/smoke_test_rc.py b/dev-tools/smoke_test_rc.py
index 4ed312b..2678024 100644
--- a/dev-tools/smoke_test_rc.py
+++ b/dev-tools/smoke_test_rc.py
@@ -28,14 +28,18 @@
 #
 # USAGE:
 #
-# python3 -B ./dev-tools/smoke_tests_rc.py --version 2.0.0-beta1 --hash bfa3e47
+# python3 -B ./dev-tools/smoke_test_rc.py --version 2.0.0-beta1 --hash bfa3e47
 #
 # to also test other plugins try run
 #
-# python3 -B ./dev-tools/smoke_tests_rc.py --version 2.0.0-beta1 --hash bfa3e47 --plugins license,shield,watcher
+# python3 -B ./dev-tools/smoke_test_rc.py --version 2.0.0-beta1 --hash bfa3e47 --plugins license,shield,watcher
 #
 # Note: Ensure the script is run from the elasticsearch top level directory
 #
+# For testing a release from sonatype try this:
+#
+# python3 -B dev-tools/smoke_test_rc.py --version 2.0.0-beta1 --hash bfa3e47 --fetch_url https://oss.sonatype.org/content/repositories/releases/
+#
 
 import argparse
 import tempfile
@@ -111,8 +115,7 @@ def wait_for_node_startup(host='127.0.0.1', port=9200, timeout=60, header={}):
       conn.close()
   return False
 
-def download_and_verify(version, hash, files, base_url='http://download.elasticsearch.org/elasticsearch/staging', plugins=DEFAULT_PLUGINS, verbose=False):
-  base_url = '%s/%s-%s' % (base_url, version, hash)
+def download_and_verify(version, hash, files, base_url, plugins=DEFAULT_PLUGINS, verbose=False):
   print('Downloading and verifying release %s from %s' % (version, base_url))
   tmp_dir = tempfile.mkdtemp()
   try:
@@ -249,23 +252,31 @@ if __name__ == "__main__":
                       help='A list of additional plugins to smoketest')
   parser.add_argument('--verbose', '-b', dest='verbose',
                     help='Runs the script in verbose mode')
+  parser.add_argument('--fetch_url', '-u', dest='url', default=None,
+                      help='Runs the script in verbose mode')
   parser.set_defaults(hash=None)
   parser.set_defaults(plugins=[])
   parser.set_defaults(version=None)
   parser.set_defaults(verbose=False)
+  parser.set_defaults(url=None)
   args = parser.parse_args()
   plugins = args.plugins
   version = args.version
   hash = args.hash
   verbose = args.verbose
-  files = [
-    'org/elasticsearch/distribution/tar/elasticsearch/2.0.0-beta1/elasticsearch-2.0.0-beta1.tar.gz',
-    'org/elasticsearch/distribution/zip/elasticsearch/2.0.0-beta1/elasticsearch-2.0.0-beta1.zip',
-    'org/elasticsearch/distribution/deb/elasticsearch/2.0.0-beta1/elasticsearch-2.0.0-beta1.deb',
-    'org/elasticsearch/distribution/rpm/elasticsearch/2.0.0-beta1/elasticsearch-2.0.0-beta1.rpm'
-  ]
+  url = args.url
+  files = [ x % {'version': version} for x in [
+    'org/elasticsearch/distribution/tar/elasticsearch/%(version)s/elasticsearch-%(version)s.tar.gz',
+    'org/elasticsearch/distribution/zip/elasticsearch/%(version)s/elasticsearch-%(version)s.zip',
+    'org/elasticsearch/distribution/deb/elasticsearch/%(version)s/elasticsearch-%(version)s.deb',
+    'org/elasticsearch/distribution/rpm/elasticsearch/%(version)s/elasticsearch-%(version)s.rpm'
+  ]]
   verify_java_version('1.7')
-  download_and_verify(version, hash, files, plugins= DEFAULT_PLUGINS + plugins, verbose=verbose)
+  if url:
+    download_url = url
+  else:
+    download_url = '%s/%s-%s' % ('http://download.elasticsearch.org/elasticsearch/staging', version, hash)
+  download_and_verify(version, hash, files, download_url, plugins=DEFAULT_PLUGINS + plugins, verbose=verbose)
 
 
 
diff --git a/dev-tools/src/main/resources/ant/integration-tests.xml b/dev-tools/src/main/resources/ant/integration-tests.xml
index b5439cb..7b97f3e 100644
--- a/dev-tools/src/main/resources/ant/integration-tests.xml
+++ b/dev-tools/src/main/resources/ant/integration-tests.xml
@@ -219,6 +219,30 @@
 
       <extract-pid file="@{es.pidfile}" property="integ.pid"/>
       <echo>Shutting down external node PID ${integ.pid}</echo>
+      <!-- verify with jps that this actually is the correct pid.
+      See if we can find the line "pid org.elasticsearch.bootstrap.Elasticsearch" in the output of jps -l.-->
+      <local name="jps.pidline"/>
+      <local name="jps.executable"/>
+      <local name="environment"/>
+      <property environment="environment"/>
+      <property name="jps.executable" location="${environment.JAVA_HOME}/bin/jps"/>
+      <exec executable="${jps.executable}" failonerror="true">
+        <arg value="-l"/>
+        <redirector outputproperty="jps.pidline">
+          <outputfilterchain>
+            <linecontains>
+              <contains value="${integ.pid} org.elasticsearch.bootstrap.Elasticsearch"/>
+            </linecontains>
+          </outputfilterchain>
+        </redirector>
+      </exec>
+      <fail
+          message="pid file at @{es.pidfile} is ${integ.pid} but jps -l did not report any process with org.elasticsearch.bootstrap.Elasticsearch and this pid.
+          Did you run mvn clean? Maybe an old pid file is still lying around.">
+        <condition>
+          <equals arg1="${jps.pidline}" arg2=""/>
+        </condition>
+      </fail>
 
       <exec executable="taskkill" failonerror="true" osfamily="winnt">
         <arg value="/F"/>
@@ -271,8 +295,6 @@
     <startup-elasticsearch/>
   </target>
 
-  <!-- TODO, for some more safety, add back some of the old jps logic
-       and verify the pid is really an ES process! (fail otherwise) -->
   <target name="stop-external-cluster" if="integ.pidfile.exists">
     <stop-node/>
   </target>
diff --git a/dev-tools/src/main/resources/forbidden/core-signatures.txt b/dev-tools/src/main/resources/forbidden/core-signatures.txt
index 796f3ee..d95b793 100644
--- a/dev-tools/src/main/resources/forbidden/core-signatures.txt
+++ b/dev-tools/src/main/resources/forbidden/core-signatures.txt
@@ -84,3 +84,6 @@ java.util.concurrent.Future#cancel(boolean)
 @defaultMessage Don't try reading from paths that are not configured in Environment, resolve from Environment instead
 org.elasticsearch.common.io.PathUtils#get(java.lang.String, java.lang.String[])
 org.elasticsearch.common.io.PathUtils#get(java.net.URI)
+
+@defaultMessage avoid adding additional dependencies on Guava
+com.google.common.collect.Lists
diff --git a/docs/plugins/cloud-aws.asciidoc b/docs/plugins/cloud-aws.asciidoc
index 7b0fee3..1cab147 100644
--- a/docs/plugins/cloud-aws.asciidoc
+++ b/docs/plugins/cloud-aws.asciidoc
@@ -303,6 +303,9 @@ The following settings are supported:
 
     Number of retries in case of S3 errors. Defaults to `3`.
 
+`read_only`::
+
+    Makes repository read-only. coming[2.1.0]  Defaults to `false`.
 
 The S3 repositories use the same credentials as the rest of the AWS services
 provided by this plugin (`discovery`). See <<cloud-aws-usage>> for details.
diff --git a/docs/plugins/cloud-azure.asciidoc b/docs/plugins/cloud-azure.asciidoc
index 80fd189..3d0e7d0 100644
--- a/docs/plugins/cloud-azure.asciidoc
+++ b/docs/plugins/cloud-azure.asciidoc
@@ -545,6 +545,10 @@ The Azure repository supports following settings:
     setting doesn't affect index files that are already compressed by default.
     Defaults to `false`.
 
+`read_only`::
+
+    Makes repository read-only. coming[2.1.0]  Defaults to `false`.
+
 Some examples, using scripts:
 
 [source,json]
diff --git a/docs/reference/analysis/analyzers/custom-analyzer.asciidoc b/docs/reference/analysis/analyzers/custom-analyzer.asciidoc
index d11cb7f..46111e3 100644
--- a/docs/reference/analysis/analyzers/custom-analyzer.asciidoc
+++ b/docs/reference/analysis/analyzers/custom-analyzer.asciidoc
@@ -20,7 +20,7 @@ filters.
 |`char_filter` |An optional list of logical / registered name of char
 filters.
 
-|`position_offset_gap` |An optional number of positions to increment
+|`position_increment_gap` |An optional number of positions to increment
 between each field value of a field using this analyzer. Defaults to 100.
 100 was chosen because it prevents phrase queries with reasonably large
 slops (less than 100) from matching terms across field values.
@@ -38,7 +38,7 @@ index :
                 tokenizer : myTokenizer1
                 filter : [myTokenFilter1, myTokenFilter2]
                 char_filter : [my_html]
-                position_offset_gap: 256
+                position_increment_gap: 256
         tokenizer :
             myTokenizer1 :
                 type : standard
diff --git a/docs/reference/docs/update.asciidoc b/docs/reference/docs/update.asciidoc
index 06958b4..7d2dbfa 100644
--- a/docs/reference/docs/update.asciidoc
+++ b/docs/reference/docs/update.asciidoc
@@ -114,25 +114,23 @@ If both `doc` and `script` is specified, then `doc` is ignored. Best is
 to put your field pairs of the partial document in the script itself.
 
 [float]
-=== Detecting noop
-
-By default if `doc` is specified then the document is always updated even
-if the merging process doesn't cause any changes.  Specifying `detect_noop`
-as `true` will cause Elasticsearch to check if there are changes and, if
-there aren't, turn the update request into a noop. For example:
-
+=== Detecting noop updates
+If `doc` is specified its value is merged with the existing `_source`. By
+default the document is only reindexed if the new `_source` field differs from
+the old. Setting `detect_noop` to `false` will cause Elasticsearch to always
+update the document even if it hasn't changed. For example:
 [source,js]
 --------------------------------------------------
 curl -XPOST 'localhost:9200/test/type1/1/_update' -d '{
     "doc" : {
         "name" : "new_name"
     },
-    "detect_noop": true
+    "detect_noop": false
 }'
 --------------------------------------------------
 
-If `name` was `new_name` before the request was sent then the entire update
-request is ignored.
+If `name` was `new_name` before the request was sent then document is still
+reindexed.
 
 [[upserts]]
 [float]
diff --git a/docs/reference/mapping/fields/ttl-field.asciidoc b/docs/reference/mapping/fields/ttl-field.asciidoc
index 26bc3e7..07ce8a8 100644
--- a/docs/reference/mapping/fields/ttl-field.asciidoc
+++ b/docs/reference/mapping/fields/ttl-field.asciidoc
@@ -104,3 +104,7 @@ may still be retrieved before they are purged.
 How many deletions are handled by a single <<docs-bulk,`bulk`>> request. The
 default value is `10000`.
 
+==== Note on `detect_noop`
+If an update tries to update just the `_ttl` without changing the `_source` of
+the document it's expiration time won't be updated if `detect_noop` is `true`.
+In 2.1 `detect_noop` defaults to `true`.
diff --git a/docs/reference/mapping/params.asciidoc b/docs/reference/mapping/params.asciidoc
index 119ce82..719fa00 100644
--- a/docs/reference/mapping/params.asciidoc
+++ b/docs/reference/mapping/params.asciidoc
@@ -28,7 +28,7 @@ The following mapping parameters are common to some or all field datatypes:
 * <<multi-fields,`fields`>>
 * <<norms,`norms`>>
 * <<null-value,`null_value`>>
-* <<position-offset-gap,`position_offset_gap`>>
+* <<position-increment-gap,`position_increment_gap`>>
 * <<properties,`properties`>>
 * <<search-analyzer,`search_analyzer`>>
 * <<similarity,`similarity`>>
@@ -78,7 +78,7 @@ include::params/norms.asciidoc[]
 
 include::params/null-value.asciidoc[]
 
-include::params/position-offset-gap.asciidoc[]
+include::params/position-increment-gap.asciidoc[]
 
 include::params/precision-step.asciidoc[]
 
diff --git a/docs/reference/mapping/params/position-increment-gap.asciidoc b/docs/reference/mapping/params/position-increment-gap.asciidoc
new file mode 100644
index 0000000..918e3d4
--- /dev/null
+++ b/docs/reference/mapping/params/position-increment-gap.asciidoc
@@ -0,0 +1,73 @@
+[[position-increment-gap]]
+=== `position_increment_gap`
+
+<<mapping-index,Analyzed>> string fields take term <<index-options,positions>>
+into account, in order to be able to support
+<<query-dsl-match-query-phrase,proximity or phrase queries>>.
+When indexing an array of strings, each string of the array is indexed
+directly after the previous one, almost as though all the strings in the array
+had been concatenated into one big string.
+
+This can result in matches from phrase queries spanning two array elements.
+For instance:
+
+[source,js]
+--------------------------------------------------
+PUT /my_index/groups/1
+{
+    "names": [ "John Abraham", "Lincoln Smith"]
+}
+
+GET /my_index/groups/_search
+{
+    "query": {
+        "match_phrase": {
+            "names": "Abraham Lincoln" <1>
+        }
+    }
+}
+--------------------------------------------------
+// AUTOSENSE
+<1> This phrase query matches our document, even though `Abraham` and `Lincoln` are in separate strings.
+
+The `position_increment_gap` can introduce a fake gap between each array element.  For instance:
+
+[source,js]
+--------------------------------------------------
+PUT my_index
+{
+  "mappings": {
+    "my_type": {
+      "properties": {
+        "names": {
+          "type": "string",
+          "position_increment_gap": 50 <1>
+        }
+      }
+    }
+  }
+}
+
+PUT /my_index/groups/1
+{
+    "names": [ "John Abraham", "Lincoln Smith"]
+}
+
+GET /my_index/groups/_search
+{
+    "query": {
+        "match_phrase": {
+            "names": "Abraham Lincoln" <2>
+        }
+    }
+}
+--------------------------------------------------
+// AUTOSENSE
+<1> The first term in the next array element will be 50 terms apart from the
+    last term in the previous array element.
+<2> The phrase query no longer matches our document.
+
+TIP: The `position_increment_gap` setting is allowed to have different settings
+for fields of the same name in the same index.  Its value can be updated on
+existing fields using the <<indices-put-mapping,PUT mapping API>>.
+
diff --git a/docs/reference/mapping/params/position-offset-gap.asciidoc b/docs/reference/mapping/params/position-offset-gap.asciidoc
deleted file mode 100644
index d22dbd8..0000000
--- a/docs/reference/mapping/params/position-offset-gap.asciidoc
+++ /dev/null
@@ -1,73 +0,0 @@
-[[position-offset-gap]]
-=== `position_offset_gap`
-
-<<mapping-index,Analyzed>> string fields take term <<index-options,positions>>
-into account, in order to be able to support
-<<query-dsl-match-query-phrase,proximity or phrase queries>>.
-When indexing an array of strings, each string of the array is indexed
-directly after the previous one, almost as though all the strings in the array
-had been concatenated into one big string.
-
-This can result in matches from phrase queries spanning two array elements.
-For instance:
-
-[source,js]
---------------------------------------------------
-PUT /my_index/groups/1
-{
-    "names": [ "John Abraham", "Lincoln Smith"]
-}
-
-GET /my_index/groups/_search
-{
-    "query": {
-        "match_phrase": {
-            "names": "Abraham Lincoln" <1>
-        }
-    }
-}
---------------------------------------------------
-// AUTOSENSE
-<1> This phrase query matches our document, even though `Abraham` and `Lincoln` are in separate strings.
-
-The `position_offset_gap` can introduce a fake gap between each array element.  For instance:
-
-[source,js]
---------------------------------------------------
-PUT my_index
-{
-  "mappings": {
-    "my_type": {
-      "properties": {
-        "names": {
-          "type": "string",
-          "position_offset_gap": 50 <1>
-        }
-      }
-    }
-  }
-}
-
-PUT /my_index/groups/1
-{
-    "names": [ "John Abraham", "Lincoln Smith"]
-}
-
-GET /my_index/groups/_search
-{
-    "query": {
-        "match_phrase": {
-            "names": "Abraham Lincoln" <2>
-        }
-    }
-}
---------------------------------------------------
-// AUTOSENSE
-<1> The first term in the next array element will be 50 terms apart from the
-    last term in the previous array element.
-<2> The phrase query no longer matches our document.
-
-TIP: The `position_offset_gap` setting is allowed to have different settings
-for fields of the same name in the same index.  Its value can be updated on
-existing fields using the <<indices-put-mapping,PUT mapping API>>.
-
diff --git a/docs/reference/mapping/types/string.asciidoc b/docs/reference/mapping/types/string.asciidoc
index ef497fe..d5d7b7a 100644
--- a/docs/reference/mapping/types/string.asciidoc
+++ b/docs/reference/mapping/types/string.asciidoc
@@ -141,12 +141,12 @@ Defaults depend on the <<mapping-index,`index`>> setting:
     values.  Defaults to `null`, which means the field is treated as missing.
     If the field is `analyzed`, the `null_value` will also be analyzed.
 
-<<position-offset-gap,`position_offset_gap`>>::
+<<position-increment-gap,`position_increment_gap`>>::
 
     The number of fake term positions which should be inserted between
     each element of an array of strings. Defaults to 0.
     The number of fake term position which should be inserted between each
-    element of an array of strings. Defaults to the position_offset_gap
+    element of an array of strings. Defaults to the position_increment_gap
     configured on the analyzer which defaults to 100. 100 was chosen because it
     prevents phrase queries with reasonably large slops (less than 100) from
     matching terms across field values.
diff --git a/docs/reference/migration/migrate_2_0/mapping.asciidoc b/docs/reference/migration/migrate_2_0/mapping.asciidoc
index 67cd214..edeb243 100644
--- a/docs/reference/migration/migrate_2_0/mapping.asciidoc
+++ b/docs/reference/migration/migrate_2_0/mapping.asciidoc
@@ -385,9 +385,14 @@ default.  If you would like to increase compression levels, use the new
 <<index-codec,`index.codec: best_compression`>> setting instead.
 
 ==== position_offset_gap
-The default `position_offset_gap` is now 100. Indexes created in Elasticsearch
+
+The `position_offset_gap` option is renamed to 'position_increment_gap'. This was
+done to clear away the confusion. Elasticsearch's 'position_increment_gap' now is
+mapped directly to Lucene's 'position_increment_gap'
+
+The default `position_increment_gap` is now 100. Indexes created in Elasticsearch
 2.0.0 will default to using 100 and indexes created before that will continue
 to use the old default of 0. This was done to prevent phrase queries from
 matching across different values of the same term unexpectedly. Specifically,
 100 was chosen to cause phrase queries with slops up to 99 to match only within
-a single value of a field.
+a single value of a field.
\ No newline at end of file
diff --git a/docs/reference/migration/migrate_2_0/query_dsl.asciidoc b/docs/reference/migration/migrate_2_0/query_dsl.asciidoc
index 31283e9..cb9e158 100644
--- a/docs/reference/migration/migrate_2_0/query_dsl.asciidoc
+++ b/docs/reference/migration/migrate_2_0/query_dsl.asciidoc
@@ -178,7 +178,7 @@ The parameter `percent_terms_to_match` has been removed in favor of
 The `limit` filter is deprecated and becomes a no-op. You can achieve similar
 behaviour using the <<search-request-body,terminate_after>> parameter.
 
-==== Jave plugins registering custom queries
+==== Java plugins registering custom queries
 
 Java plugins that register custom queries can do so by using the
 `IndicesQueriesModule#addQuery(Class<? extends QueryParser>)` method. Other
diff --git a/docs/reference/migration/migrate_2_0/removals.asciidoc b/docs/reference/migration/migrate_2_0/removals.asciidoc
index f02bf3a..379565c 100644
--- a/docs/reference/migration/migrate_2_0/removals.asciidoc
+++ b/docs/reference/migration/migrate_2_0/removals.asciidoc
@@ -40,6 +40,24 @@ can install the plugin with:
 ./bin/plugin install delete-by-query
 ------------------
 
+See {plugins}/plugins-delete-by-query.html for more information.
+
+==== Multicast Discovery is now a plugin
+
+Support for multicast is very patchy. Linux doesnt allow multicast listening on localhost,
+while OS/X sends multicast broadcasts across all interfaces regardless of the configured
+bind address. On top of that, some networks have multicast disabled by default.
+
+This feature has been moved to a plugin. The default discovery mechanism now uses
+unicast, with a default setup which looks for the first 5 ports on localhost. If you
+still need to use multicast discovery, you can install the plugin with:
+
+[source,sh]
+------------------
+./bin/plugin install discovery-multicast
+------------------
+
+See {plugins}/discovery-multicast.html for more information.
 
 ==== `_shutdown` API
 
diff --git a/docs/reference/migration/migrate_2_1.asciidoc b/docs/reference/migration/migrate_2_1.asciidoc
index 7542fb3..63092d9 100644
--- a/docs/reference/migration/migrate_2_1.asciidoc
+++ b/docs/reference/migration/migrate_2_1.asciidoc
@@ -25,3 +25,13 @@ GET /my_index/_search?scroll=2m
 Scroll requests sorted by `_doc` have been optimized to more efficiently resume
 from where the previous request stopped, so this will have the same performance
 characteristics as the former `scan` search type.
+
+=== Update changes
+
+==== Updates now `detect_noop` by default
+
+We've switched the default value of the `detect_noop` option from `false` to
+`true`. This means that Elasticsearch will ignore updates that don't change
+source unless you explicitly set `"detect_noop": false`. `detect_noop` was
+always computationally cheap compared to the expense of the update which can be
+thought of as a delete operation followed by an index operation.
diff --git a/docs/reference/migration/migrate_query_refactoring.asciidoc b/docs/reference/migration/migrate_query_refactoring.asciidoc
deleted file mode 100644
index 61b86ad..0000000
--- a/docs/reference/migration/migrate_query_refactoring.asciidoc
+++ /dev/null
@@ -1,74 +0,0 @@
-[[breaking-changes query-refactoring]]
-== Breaking changes on the query-refactoring branch
-
-This section discusses changes that are breaking to the current rest or java-api
-on the query-refactoring feature branch.
-
-=== Plugins
-
-Plugins implementing custom queries need to implement the `fromXContent(QueryParseContext)` method in their
-`QueryParser` subclass rather than `parse`. This method will take care of parsing the query from `XContent` format
-into an intermediate query representation that can be streamed between the nodes in binary format, effectively the
-query object used in the java api. Also, the query parser needs to implement the `getBuilderPrototype` method that
-returns a prototype of the streamable query, which allows to deserialize an incoming query by calling
-`readFrom(StreamInput)` against it, which will create a new object, see usages of `Writeable`. The `QueryParser`
-also needs to declare the generic type of the query that it supports and it's able to parse.
-The query object can then transform itself into a lucene query through the new `toQuery(QueryShardContext)` method,
-which returns a lucene query to be executed on the data node. The query implementation also needs to implement the
-`validate` method that allows to validate the content of the query, no matter whether it came in through the java api
-directly or through the REST layer.
-
-=== Java-API
-
-==== BoostingQueryBuilder
-
-Removed setters for mandatory positive/negative query. Both arguments now have
-to be supplied at construction time already and have to be non-null.
-
-==== SpanContainingQueryBuilder
-
-Removed setters for mandatory big/little inner span queries. Both arguments now have
-to be supplied at construction time already and have to be non-null. Updated
-static factory methods in QueryBuilders accordingly.
-
-==== SpanNearQueryBuilder
-
-Removed setter for mandatory slop parameter, needs to be set in constructor now.
-Updated the static factory methods in QueryBuilders accordingly.
-
-==== SpanNotQueryBuilder
-
-Removed setter for mandatory include/exclude span query clause, needs to be set in constructor now.
-Updated the static factory methods in QueryBuilders and tests accordingly.
-
-==== SpanWithinQueryBuilder
-
-Removed setters for mandatory big/little inner span queries. Both arguments now have
-to be supplied at construction time already and have to be non-null. Updated
-static factory methods in QueryBuilders accordingly.
-
-==== QueryFilterBuilder
-
-Removed the setter `queryName(String queryName)` since this field is not supported
-in this type of query. Use `FQueryFilterBuilder.queryName(String queryName)` instead 
-when in need to wrap a named query as a filter.
-
-==== WrapperQueryBuilder
-
-Removed `wrapperQueryBuilder(byte[] source, int offset, int length)`. Instead simply
-use  `wrapperQueryBuilder(byte[] source)`. Updated the static factory methods in
-QueryBuilders accordingly.
-
-==== Operator
-
-Removed the enums called `Operator` from `MatchQueryBuilder`, `QueryStringQueryBuilder`,
-`SimpleQueryStringBuilder`, and `CommonTermsQueryBuilder` in favour of using the enum
-defined in `org.elasticsearch.index.query.Operator` in an effort to consolidate the
-codebase and avoid duplication.
-
-==== queryName and boost support
-
-Support for `queryName` and `boost` has been streamlined to all of the queries. That is
-a breaking change till queries get sent over the network as serialized json rather
-than in `Streamable` format. In fact whenever additional fields are added to the json
-representation of the query, older nodes might throw error when they find unknown fields.
diff --git a/docs/reference/modules/snapshots.asciidoc b/docs/reference/modules/snapshots.asciidoc
index 32f412e..90f2a02 100644
--- a/docs/reference/modules/snapshots.asciidoc
+++ b/docs/reference/modules/snapshots.asciidoc
@@ -121,6 +121,7 @@ The following settings are supported:
  using size value notation, i.e. 1g, 10m, 5k. Defaults to `null` (unlimited chunk size).
 `max_restore_bytes_per_sec`:: Throttles per node restore rate. Defaults to `40mb` per second.
 `max_snapshot_bytes_per_sec`:: Throttles per node snapshot rate. Defaults to `40mb` per second.
+`readonly`:: Makes repository read-only. coming[2.1.0]  Defaults to `false`.
 
 [float]
 ===== Read-only URL Repository
diff --git a/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/AzureComputeServiceSimpleMock.java b/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/AzureComputeServiceSimpleMock.java
index 6323e91..997a8aa 100644
--- a/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/AzureComputeServiceSimpleMock.java
+++ b/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/AzureComputeServiceSimpleMock.java
@@ -78,10 +78,10 @@ public class AzureComputeServiceSimpleMock extends AzureComputeServiceAbstractMo
         endpoint.setName("elasticsearch");
         endpoint.setVirtualIPAddress(InetAddress.getLoopbackAddress());
         endpoint.setPort(9400);
-        instance.setInstanceEndpoints(CollectionUtils.newArrayList(endpoint));
+        instance.setInstanceEndpoints(CollectionUtils.newSingletonArrayList(endpoint));
 
-        deployment.setRoleInstances(CollectionUtils.newArrayList(instance));
-        response.setDeployments(CollectionUtils.newArrayList(deployment));
+        deployment.setRoleInstances(CollectionUtils.newSingletonArrayList(instance));
+        response.setDeployments(CollectionUtils.newSingletonArrayList(deployment));
 
         return response;
     }
diff --git a/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/AzureComputeServiceTwoNodesMock.java b/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/AzureComputeServiceTwoNodesMock.java
index a87a4ef..ee8bf35 100644
--- a/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/AzureComputeServiceTwoNodesMock.java
+++ b/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/AzureComputeServiceTwoNodesMock.java
@@ -19,15 +19,22 @@
 
 package org.elasticsearch.cloud.azure;
 
-import com.microsoft.windowsazure.management.compute.models.*;
+import com.microsoft.windowsazure.management.compute.models.DeploymentSlot;
+import com.microsoft.windowsazure.management.compute.models.DeploymentStatus;
+import com.microsoft.windowsazure.management.compute.models.HostedServiceGetDetailedResponse;
+import com.microsoft.windowsazure.management.compute.models.InstanceEndpoint;
+import com.microsoft.windowsazure.management.compute.models.RoleInstance;
 import org.elasticsearch.cloud.azure.management.AzureComputeServiceAbstractMock;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.network.NetworkService;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.util.CollectionUtils;
 import org.elasticsearch.plugins.Plugin;
 
 import java.net.InetAddress;
+import java.util.ArrayList;
+import java.util.Arrays;
+
+import static org.elasticsearch.common.util.CollectionUtils.newSingletonArrayList;
 
 
 /**
@@ -78,7 +85,7 @@ public class AzureComputeServiceTwoNodesMock extends AzureComputeServiceAbstract
         endpoint1.setName("elasticsearch");
         endpoint1.setVirtualIPAddress(InetAddress.getLoopbackAddress());
         endpoint1.setPort(9400);
-        instance1.setInstanceEndpoints(CollectionUtils.newArrayList(endpoint1));
+        instance1.setInstanceEndpoints(newSingletonArrayList(endpoint1));
 
         // Fake a first instance
         RoleInstance instance2 = new RoleInstance();
@@ -92,11 +99,11 @@ public class AzureComputeServiceTwoNodesMock extends AzureComputeServiceAbstract
         endpoint2.setName("elasticsearch");
         endpoint2.setVirtualIPAddress(InetAddress.getLoopbackAddress());
         endpoint2.setPort(9401);
-        instance2.setInstanceEndpoints(CollectionUtils.newArrayList(endpoint2));
+        instance2.setInstanceEndpoints(newSingletonArrayList(endpoint2));
 
-        deployment.setRoleInstances(CollectionUtils.newArrayList(instance1, instance2));
+        deployment.setRoleInstances(new ArrayList<>(Arrays.asList(instance1, instance2)));
 
-        response.setDeployments(CollectionUtils.newArrayList(deployment));
+        response.setDeployments(newSingletonArrayList(deployment));
 
         return response;
     }
diff --git a/plugins/cloud-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java b/plugins/cloud-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java
index 7e6d354..7321d03 100644
--- a/plugins/cloud-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java
+++ b/plugins/cloud-gce/src/main/java/org/elasticsearch/cloud/gce/GceComputeServiceImpl.java
@@ -29,12 +29,12 @@ import com.google.api.services.compute.model.Instance;
 import com.google.api.services.compute.model.InstanceList;
 import com.google.common.base.Function;
 import com.google.common.collect.Iterables;
-import com.google.common.collect.Lists;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.util.CollectionUtils;
 
 import java.io.IOException;
 import java.security.GeneralSecurityException;
@@ -43,6 +43,8 @@ import java.util.Collection;
 import java.util.Collections;
 import java.util.List;
 
+import static org.elasticsearch.common.util.CollectionUtils.eagerTransform;
+
 /**
  *
  */
@@ -62,7 +64,7 @@ public class GceComputeServiceImpl extends AbstractLifecycleComponent<GceCompute
 
             logger.debug("get instances for project [{}], zones [{}]", project, zones);
 
-            List<List<Instance>> instanceListByZone = Lists.transform(zones, new Function<String, List<Instance>>() {
+            List<List<Instance>> instanceListByZone = eagerTransform(zones, new Function<String, List<Instance>>() {
                 @Override
                 public List<Instance> apply(String zoneId) {
                     try {
@@ -83,7 +85,7 @@ public class GceComputeServiceImpl extends AbstractLifecycleComponent<GceCompute
             });
 
             // Collapse instances from all zones into one neat list
-            List<Instance> instanceList = Lists.newArrayList(Iterables.concat(instanceListByZone));
+            List<Instance> instanceList = CollectionUtils.iterableAsArrayList(Iterables.concat(instanceListByZone));
 
             if (instanceList.size() == 0) {
                 logger.warn("disabling GCE discovery. Can not get list of nodes");
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.create.json b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.create.json
index a738fa8..bdac6d9 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.create.json
+++ b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.create.json
@@ -20,6 +20,10 @@
         "master_timeout": {
           "type" : "time",
           "description" : "Specify timeout for connection to master"
+        },
+        "update_all_types": {
+          "type": "boolean",
+          "description": "Whether to update the mapping for all fields with the same name across all types or not"
         }
       }
     },
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.put_mapping.json b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.put_mapping.json
index c6b5479..5fce0bc 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.put_mapping.json
+++ b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.put_mapping.json
@@ -38,6 +38,10 @@
           "options" : ["open","closed","none","all"],
           "default" : "open",
           "description" : "Whether to expand wildcard expression to concrete indices that are open, closed or both."
+        },
+        "update_all_types": {
+          "type": "boolean",
+          "description": "Whether to update the mapping for all fields with the same name across all types or not"
         }
       }
     },
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.put_warmer.json b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.put_warmer.json
index d1dce8b..9039367 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.put_warmer.json
+++ b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.put_warmer.json
@@ -41,7 +41,7 @@
         },
         "request_cache": {
           "type" : "boolean",
-          "description" : "Specify whether the request to be wamred shoyd use the request cache, defaults to index level setting"
+          "description" : "Specify whether the request to be warmed should use the request cache, defaults to index level setting"
         }
       }
     },
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/update/75_ttl.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/update/75_ttl.yaml
index cdd5d7e..09179eb 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/update/75_ttl.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/update/75_ttl.yaml
@@ -56,7 +56,7 @@
  - lte:   { _ttl: 100000}
  - gt:    { _ttl: 10000}
 
-# duration
+# seconds
 
  - do:
       update:
@@ -66,6 +66,7 @@
           body:
             doc:        { foo: baz }
             upsert:     { foo: bar }
+            detect_noop:  false
           ttl:       20s
 
  - do:
@@ -89,4 +90,3 @@
           body:      { foo: bar }
           ttl:       20s
           timestamp: 2013-06-23T18:14:40
-

diff --git a/TESTING.asciidoc b/TESTING.asciidoc
index 7a717c6..66eb83f 100644
--- a/TESTING.asciidoc
+++ b/TESTING.asciidoc
@@ -409,6 +409,12 @@ or run all the boxes:
 mvn -Dtests.vagrant=all -pl qa/vagrant verify
 ---------------------------------------
 
+If you want to run a specific test on several boxes you can do:
+
+---------------------------------------
+mvn -Dtests.vagrant=all -pl qa/vagrant verify -DtestScripts=*tar*.bats
+---------------------------------------
+
 Its important to know that if you ctrl-c any of these `mvn` runs that you'll
 probably leave a VM up. You can terminate it by running:
 
diff --git a/core/src/main/java/org/elasticsearch/ElasticsearchException.java b/core/src/main/java/org/elasticsearch/ElasticsearchException.java
index c82cab9..0fa4d68 100644
--- a/core/src/main/java/org/elasticsearch/ElasticsearchException.java
+++ b/core/src/main/java/org/elasticsearch/ElasticsearchException.java
@@ -30,9 +30,8 @@ import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.rest.RestStatus;
 
 import java.io.IOException;
-import java.lang.reflect.Constructor;
-import java.lang.reflect.InvocationTargetException;
 import java.util.*;
+import java.util.stream.Collectors;
 
 /**
  * A base class for all elasticsearch exceptions.
@@ -48,8 +47,8 @@ public class ElasticsearchException extends RuntimeException implements ToXConte
     private static final String RESOURCE_HEADER_TYPE_KEY = "es.resource.type";
     private static final String RESOURCE_HEADER_ID_KEY = "es.resource.id";
 
-    private static final Constructor<? extends ElasticsearchException>[] ID_TO_SUPPLIER;
-    private static final Map<Class<? extends ElasticsearchException>, Integer> CLASS_TO_ID;
+    private static final Map<Integer, FunctionThatThrowsIOException<StreamInput, ? extends ElasticsearchException>> ID_TO_SUPPLIER;
+    private static final Map<Class<? extends ElasticsearchException>, ElasticsearchExceptionHandle> CLASS_TO_ELASTICSEARCH_EXCEPTION_HANDLE;
     private final Map<String, List<String>> headers = new HashMap<>();
 
     /**
@@ -232,33 +231,29 @@ public class ElasticsearchException extends RuntimeException implements ToXConte
     }
 
     public static ElasticsearchException readException(StreamInput input, int id) throws IOException {
-        Constructor<? extends ElasticsearchException> elasticsearchException = ID_TO_SUPPLIER[id];
+        FunctionThatThrowsIOException<StreamInput, ? extends ElasticsearchException> elasticsearchException = ID_TO_SUPPLIER.get(id);
         if (elasticsearchException == null) {
             throw new IllegalStateException("unknown exception for id: " + id);
         }
-        try {
-            return elasticsearchException.newInstance(input);
-        } catch (InstantiationException|IllegalAccessException|InvocationTargetException e) {
-            throw new IOException("failed to read exception for id [" + id + "]", e);
-        }
+        return elasticsearchException.apply(input);
     }
 
     /**
      * Retruns <code>true</code> iff the given class is a registered for an exception to be read.
      */
     public static boolean isRegistered(Class<? extends Throwable> exception) {
-        return CLASS_TO_ID.containsKey(exception);
+        return CLASS_TO_ELASTICSEARCH_EXCEPTION_HANDLE.containsKey(exception);
     }
 
     static Set<Class<? extends ElasticsearchException>> getRegisteredKeys() { // for testing
-        return CLASS_TO_ID.keySet();
+        return CLASS_TO_ELASTICSEARCH_EXCEPTION_HANDLE.keySet();
     }
 
     /**
      * Returns the serialization id the given exception.
      */
     public static int getId(Class<? extends ElasticsearchException> exception) {
-        return CLASS_TO_ID.get(exception).intValue();
+        return CLASS_TO_ELASTICSEARCH_EXCEPTION_HANDLE.get(exception).id;
     }
 
     @Override
@@ -458,179 +453,171 @@ public class ElasticsearchException extends RuntimeException implements ToXConte
         return throwable;
     }
 
-    static {
-        // each exception gets an ordinal assigned that must never change. While the exception name can
+    enum ElasticsearchExceptionHandle {
+        // each exception gets an assigned id that must never change. While the exception name can
         // change due to refactorings etc. like renaming we have to keep the ordinal <--> class mapping
         // to deserialize the exception coming from another node or from an corruption marker on
         // a corrupted index.
-        // NOTE: ONLY APPEND TO THE END and NEVER REMOVE EXCEPTIONS IN MINOR VERSIONS
-        final Map<Class<? extends ElasticsearchException>, Integer> exceptions = new HashMap<>();
-        exceptions.put(org.elasticsearch.index.snapshots.IndexShardSnapshotFailedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.dfs.DfsPhaseExecutionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.common.util.CancellableThreads.ExecutionCancelledException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.discovery.MasterNotDiscoveredException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.ElasticsearchSecurityException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.snapshots.IndexShardRestoreException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.IndexClosedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.http.BindHttpException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.search.ReduceSearchPhaseException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.node.NodeClosedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.SnapshotFailedEngineException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.shard.ShardNotFoundException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.ConnectTransportException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.NotSerializableTransportException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.ResponseHandlerFailureTransportException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.IndexCreationException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.IndexNotFoundException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.cluster.routing.IllegalShardRoutingStateException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.support.broadcast.BroadcastShardOperationFailedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.ResourceNotFoundException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.ActionTransportException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.ElasticsearchGenerationException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.CreateFailedEngineException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.shard.IndexShardStartedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.SearchContextMissingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.script.ScriptException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.shard.TranslogRecoveryPerformer.BatchOperationException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.snapshots.SnapshotCreationException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.DeleteFailedEngineException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.DocumentMissingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.snapshots.SnapshotException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.InvalidAliasNameException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.InvalidIndexNameException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.IndexPrimaryShardNotAllocatedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.TransportException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.ElasticsearchParseException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.SearchException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.mapper.MapperException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.InvalidTypeNameException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.snapshots.SnapshotRestoreException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.common.ParsingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.shard.IndexShardClosedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.recovery.RecoverFilesRecoveryException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.translog.TruncatedTranslogException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.recovery.RecoveryFailedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.shard.IndexShardRelocatedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.NodeShouldNotConnectException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.IndexTemplateAlreadyExistsException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.translog.TranslogCorruptedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.cluster.block.ClusterBlockException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.fetch.FetchPhaseExecutionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.IndexShardAlreadyExistsException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.VersionConflictEngineException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.EngineException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.DocumentAlreadyExistsException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.NoSuchNodeException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.common.settings.SettingsException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.IndexTemplateMissingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.SendRequestTransportException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.common.util.concurrent.EsRejectedExecutionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.common.lucene.Lucene.EarlyTerminationException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.cluster.routing.RoutingValidationException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.AliasFilterParsingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.DeleteByQueryFailedEngineException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.gateway.GatewayException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.shard.IndexShardNotRecoveringException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.http.HttpException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.ElasticsearchException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.snapshots.SnapshotMissingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.PrimaryMissingActionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.FailedNodeException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.SearchParseException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.snapshots.ConcurrentSnapshotExecutionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.common.blobstore.BlobStoreException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.cluster.IncompatibleClusterStateVersionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.RecoveryEngineException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.common.util.concurrent.UncategorizedExecutionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.TimestampParsingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.RoutingMissingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.IndexFailedEngineException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.snapshots.IndexShardRestoreFailedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.repositories.RepositoryException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.ReceiveTimeoutTransportException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.NodeDisconnectedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.AlreadyExpiredException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.aggregations.AggregationExecutionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.mapper.MergeMappingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.InvalidIndexTemplateException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.percolator.PercolateException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.RefreshFailedEngineException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.aggregations.AggregationInitializationException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.recovery.DelayRecoveryException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.warmer.IndexWarmerMissingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.client.transport.NoNodeAvailableException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.script.groovy.GroovyScriptCompilationException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.snapshots.InvalidSnapshotNameException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.shard.IllegalIndexShardStateException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.snapshots.IndexShardSnapshotException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.shard.IndexShardNotStartedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.search.SearchPhaseExecutionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.ActionNotFoundTransportException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.TransportSerializationException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.RemoteTransportException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.EngineCreationFailureException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.cluster.routing.RoutingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.shard.IndexShardRecoveryException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.repositories.RepositoryMissingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.percolator.PercolatorException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.DocumentSourceMissingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.FlushNotAllowedEngineException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.common.settings.NoClassSettingsException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.BindTransportException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.rest.action.admin.indices.alias.delete.AliasesNotFoundException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.shard.IndexShardRecoveringException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.translog.TranslogException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.support.replication.TransportReplicationAction.RetryOnPrimaryException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.ElasticsearchTimeoutException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.query.QueryPhaseExecutionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.repositories.RepositoryVerificationException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.aggregations.InvalidAggregationPathException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.script.groovy.GroovyScriptExecutionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.IndexAlreadyExistsException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.script.Script.ScriptParseException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.netty.SizeHeaderFrameDecoder.HttpOnTransportException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.mapper.MapperParsingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.SearchContextException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.search.builder.SearchSourceBuilderException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.EngineClosedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.NoShardAvailableActionException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.UnavailableShardsException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.engine.FlushFailedEngineException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.common.breaker.CircuitBreakingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.transport.NodeNotConnectedException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.mapper.StrictDynamicMappingException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.action.support.replication.TransportReplicationAction.RetryOnReplicaException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.indices.TypeMissingException.class, exceptions.size());
-        // added in 3.x
-        exceptions.put(org.elasticsearch.discovery.Discovery.FailedToCommitClusterStateException.class, exceptions.size());
-        exceptions.put(org.elasticsearch.index.query.QueryShardException.class, exceptions.size());
-        // NOTE: ONLY APPEND TO THE END and NEVER REMOVE EXCEPTIONS IN MINOR VERSIONS
-        Constructor<? extends ElasticsearchException>[] idToSupplier = new Constructor[exceptions.size()];
-        for (Map.Entry<Class<? extends ElasticsearchException>, Integer> e : exceptions.entrySet()) {
-            try {
-                Constructor<? extends ElasticsearchException> constructor = e.getKey().getDeclaredConstructor(StreamInput.class);
-                if (constructor == null) {
-                    throw new IllegalStateException(e.getKey().getName() + " has not StreamInput ctor");
-                }
-                assert e.getValue().intValue() >= 0;
-                if (idToSupplier[e.getValue().intValue()] != null) {
-                    throw new IllegalStateException("ordinal [" + e.getValue().intValue()  +"] is used more than once");
-                }
-                idToSupplier[e.getValue().intValue()] = constructor;
-            } catch (NoSuchMethodException t) {
-                throw new RuntimeException("failed to register [" + e.getKey().getName() + "] exception must have a public StreamInput ctor", t);
-            }
-        }
-        for (int i = 0; i < idToSupplier.length; i++) {
-            if (idToSupplier[i] == null) {
-                throw new IllegalStateException("missing exception for ordinal [" + i + "]");
-            }
+        // these exceptions can be ordered and removed, but (repeating) the ids must never change
+        // to remove an exception, remove the enum value below, and mark the id as null in ExceptionSerializationTests.testIds.ids
+        INDEX_SHARD_SNAPSHOT_FAILED_EXCEPTION(org.elasticsearch.index.snapshots.IndexShardSnapshotFailedException.class, org.elasticsearch.index.snapshots.IndexShardSnapshotFailedException::new, 0),
+        DFS_PHASE_EXECUTION_EXCEPTION(org.elasticsearch.search.dfs.DfsPhaseExecutionException.class, org.elasticsearch.search.dfs.DfsPhaseExecutionException::new, 1),
+        EXECUTION_CANCELLED_EXCEPTION(org.elasticsearch.common.util.CancellableThreads.ExecutionCancelledException.class, org.elasticsearch.common.util.CancellableThreads.ExecutionCancelledException::new, 2),
+        MASTER_NOT_DISCOVERED_EXCEPTION(org.elasticsearch.discovery.MasterNotDiscoveredException.class, org.elasticsearch.discovery.MasterNotDiscoveredException::new, 3),
+        ELASTICSEARCH_SECURITY_EXCEPTION(org.elasticsearch.ElasticsearchSecurityException.class, org.elasticsearch.ElasticsearchSecurityException::new, 4),
+        INDEX_SHARD_RESTORE_EXCEPTION(org.elasticsearch.index.snapshots.IndexShardRestoreException.class, org.elasticsearch.index.snapshots.IndexShardRestoreException::new, 5),
+        INDEX_CLOSED_EXCEPTION(org.elasticsearch.indices.IndexClosedException.class, org.elasticsearch.indices.IndexClosedException::new, 6),
+        BIND_HTTP_EXCEPTION(org.elasticsearch.http.BindHttpException.class, org.elasticsearch.http.BindHttpException::new, 7),
+        REDUCE_SEARCH_PHASE_EXCEPTION(org.elasticsearch.action.search.ReduceSearchPhaseException.class, org.elasticsearch.action.search.ReduceSearchPhaseException::new, 8),
+        NODE_CLOSED_EXCEPTION(org.elasticsearch.node.NodeClosedException.class, org.elasticsearch.node.NodeClosedException::new, 9),
+        SNAPSHOT_FAILED_ENGINE_EXCEPTION(org.elasticsearch.index.engine.SnapshotFailedEngineException.class, org.elasticsearch.index.engine.SnapshotFailedEngineException::new, 10),
+        SHARD_NOT_FOUND_EXCEPTION(org.elasticsearch.index.shard.ShardNotFoundException.class, org.elasticsearch.index.shard.ShardNotFoundException::new, 11),
+        CONNECT_TRANSPORT_EXCEPTION(org.elasticsearch.transport.ConnectTransportException.class, org.elasticsearch.transport.ConnectTransportException::new, 12),
+        NOT_SERIALIZABLE_TRANSPORT_EXCEPTION(org.elasticsearch.transport.NotSerializableTransportException.class, org.elasticsearch.transport.NotSerializableTransportException::new, 13),
+        RESPONSE_HANDLER_FAILURE_TRANSPORT_EXCEPTION(org.elasticsearch.transport.ResponseHandlerFailureTransportException.class, org.elasticsearch.transport.ResponseHandlerFailureTransportException::new, 14),
+        INDEX_CREATION_EXCEPTION(org.elasticsearch.indices.IndexCreationException.class, org.elasticsearch.indices.IndexCreationException::new, 15),
+        INDEX_NOT_FOUND_EXCEPTION(org.elasticsearch.index.IndexNotFoundException.class, org.elasticsearch.index.IndexNotFoundException::new, 16),
+        ILLEGAL_SHARD_ROUTING_STATE_EXCEPTION(org.elasticsearch.cluster.routing.IllegalShardRoutingStateException.class, org.elasticsearch.cluster.routing.IllegalShardRoutingStateException::new, 17),
+        BROADCAST_SHARD_OPERATION_FAILED_EXCEPTION(org.elasticsearch.action.support.broadcast.BroadcastShardOperationFailedException.class, org.elasticsearch.action.support.broadcast.BroadcastShardOperationFailedException::new, 18),
+        RESOURCE_NOT_FOUND_EXCEPTION(org.elasticsearch.ResourceNotFoundException.class, org.elasticsearch.ResourceNotFoundException::new, 19),
+        ACTION_TRANSPORT_EXCEPTION(org.elasticsearch.transport.ActionTransportException.class, org.elasticsearch.transport.ActionTransportException::new, 20),
+        ELASTICSEARCH_GENERATION_EXCEPTION(org.elasticsearch.ElasticsearchGenerationException.class, org.elasticsearch.ElasticsearchGenerationException::new, 21),
+        CREATE_FAILED_ENGINE_EXCEPTION(org.elasticsearch.index.engine.CreateFailedEngineException.class, org.elasticsearch.index.engine.CreateFailedEngineException::new, 22),
+        INDEX_SHARD_STARTED_EXCEPTION(org.elasticsearch.index.shard.IndexShardStartedException.class, org.elasticsearch.index.shard.IndexShardStartedException::new, 23),
+        SEARCH_CONTEXT_MISSING_EXCEPTION(org.elasticsearch.search.SearchContextMissingException.class, org.elasticsearch.search.SearchContextMissingException::new, 24),
+        SCRIPT_EXCEPTION(org.elasticsearch.script.ScriptException.class, org.elasticsearch.script.ScriptException::new, 25),
+        BATCH_OPERATION_EXCEPTION(org.elasticsearch.index.shard.TranslogRecoveryPerformer.BatchOperationException.class, org.elasticsearch.index.shard.TranslogRecoveryPerformer.BatchOperationException::new, 26),
+        SNAPSHOT_CREATION_EXCEPTION(org.elasticsearch.snapshots.SnapshotCreationException.class, org.elasticsearch.snapshots.SnapshotCreationException::new, 27),
+        DELETE_FAILED_ENGINE_EXCEPTION(org.elasticsearch.index.engine.DeleteFailedEngineException.class, org.elasticsearch.index.engine.DeleteFailedEngineException::new, 28),
+        DOCUMENT_MISSING_EXCEPTION(org.elasticsearch.index.engine.DocumentMissingException.class, org.elasticsearch.index.engine.DocumentMissingException::new, 29),
+        SNAPSHOT_EXCEPTION(org.elasticsearch.snapshots.SnapshotException.class, org.elasticsearch.snapshots.SnapshotException::new, 30),
+        INVALID_ALIAS_NAME_EXCEPTION(org.elasticsearch.indices.InvalidAliasNameException.class, org.elasticsearch.indices.InvalidAliasNameException::new, 31),
+        INVALID_INDEX_NAME_EXCEPTION(org.elasticsearch.indices.InvalidIndexNameException.class, org.elasticsearch.indices.InvalidIndexNameException::new, 32),
+        INDEX_PRIMARY_SHARD_NOT_ALLOCATED_EXCEPTION(org.elasticsearch.indices.IndexPrimaryShardNotAllocatedException.class, org.elasticsearch.indices.IndexPrimaryShardNotAllocatedException::new, 33),
+        TRANSPORT_EXCEPTION(org.elasticsearch.transport.TransportException.class, org.elasticsearch.transport.TransportException::new, 34),
+        ELASTICSEARCH_PARSE_EXCEPTION(org.elasticsearch.ElasticsearchParseException.class, org.elasticsearch.ElasticsearchParseException::new, 35),
+        SEARCH_EXCEPTION(org.elasticsearch.search.SearchException.class, org.elasticsearch.search.SearchException::new, 36),
+        MAPPER_EXCEPTION(org.elasticsearch.index.mapper.MapperException.class, org.elasticsearch.index.mapper.MapperException::new, 37),
+        INVALID_TYPE_NAME_EXCEPTION(org.elasticsearch.indices.InvalidTypeNameException.class, org.elasticsearch.indices.InvalidTypeNameException::new, 38),
+        SNAPSHOT_RESTORE_EXCEPTION(org.elasticsearch.snapshots.SnapshotRestoreException.class, org.elasticsearch.snapshots.SnapshotRestoreException::new, 39),
+        PARSING_EXCEPTION(org.elasticsearch.common.ParsingException.class, org.elasticsearch.common.ParsingException::new, 40),
+        INDEX_SHARD_CLOSED_EXCEPTION(org.elasticsearch.index.shard.IndexShardClosedException.class, org.elasticsearch.index.shard.IndexShardClosedException::new, 41),
+        RECOVER_FILES_RECOVERY_EXCEPTION(org.elasticsearch.indices.recovery.RecoverFilesRecoveryException.class, org.elasticsearch.indices.recovery.RecoverFilesRecoveryException::new, 42),
+        TRUNCATED_TRANSLOG_EXCEPTION(org.elasticsearch.index.translog.TruncatedTranslogException.class, org.elasticsearch.index.translog.TruncatedTranslogException::new, 43),
+        RECOVERY_FAILED_EXCEPTION(org.elasticsearch.indices.recovery.RecoveryFailedException.class, org.elasticsearch.indices.recovery.RecoveryFailedException::new, 44),
+        INDEX_SHARD_RELOCATED_EXCEPTION(org.elasticsearch.index.shard.IndexShardRelocatedException.class, org.elasticsearch.index.shard.IndexShardRelocatedException::new, 45),
+        NODE_SHOULD_NOT_CONNECT_EXCEPTION(org.elasticsearch.transport.NodeShouldNotConnectException.class, org.elasticsearch.transport.NodeShouldNotConnectException::new, 46),
+        INDEX_TEMPLATE_ALREADY_EXISTS_EXCEPTION(org.elasticsearch.indices.IndexTemplateAlreadyExistsException.class, org.elasticsearch.indices.IndexTemplateAlreadyExistsException::new, 47),
+        TRANSLOG_CORRUPTED_EXCEPTION(org.elasticsearch.index.translog.TranslogCorruptedException.class, org.elasticsearch.index.translog.TranslogCorruptedException::new, 48),
+        CLUSTER_BLOCK_EXCEPTION(org.elasticsearch.cluster.block.ClusterBlockException.class, org.elasticsearch.cluster.block.ClusterBlockException::new, 49),
+        FETCH_PHASE_EXECUTION_EXCEPTION(org.elasticsearch.search.fetch.FetchPhaseExecutionException.class, org.elasticsearch.search.fetch.FetchPhaseExecutionException::new, 50),
+        INDEX_SHARD_ALREADY_EXISTS_EXCEPTION(org.elasticsearch.index.IndexShardAlreadyExistsException.class, org.elasticsearch.index.IndexShardAlreadyExistsException::new, 51),
+        VERSION_CONFLICT_ENGINE_EXCEPTION(org.elasticsearch.index.engine.VersionConflictEngineException.class, org.elasticsearch.index.engine.VersionConflictEngineException::new, 52),
+        ENGINE_EXCEPTION(org.elasticsearch.index.engine.EngineException.class, org.elasticsearch.index.engine.EngineException::new, 53),
+        DOCUMENT_ALREADY_EXISTS_EXCEPTION(org.elasticsearch.index.engine.DocumentAlreadyExistsException.class, org.elasticsearch.index.engine.DocumentAlreadyExistsException::new, 54),
+        NO_SUCH_NODE_EXCEPTION(org.elasticsearch.action.NoSuchNodeException.class, org.elasticsearch.action.NoSuchNodeException::new, 55),
+        SETTINGS_EXCEPTION(org.elasticsearch.common.settings.SettingsException.class, org.elasticsearch.common.settings.SettingsException::new, 56),
+        INDEX_TEMPLATE_MISSING_EXCEPTION(org.elasticsearch.indices.IndexTemplateMissingException.class, org.elasticsearch.indices.IndexTemplateMissingException::new, 57),
+        SEND_REQUEST_TRANSPORT_EXCEPTION(org.elasticsearch.transport.SendRequestTransportException.class, org.elasticsearch.transport.SendRequestTransportException::new, 58),
+        ES_REJECTED_EXECUTION_EXCEPTION(org.elasticsearch.common.util.concurrent.EsRejectedExecutionException.class, org.elasticsearch.common.util.concurrent.EsRejectedExecutionException::new, 59),
+        EARLY_TERMINATION_EXCEPTION(org.elasticsearch.common.lucene.Lucene.EarlyTerminationException.class, org.elasticsearch.common.lucene.Lucene.EarlyTerminationException::new, 60),
+        ROUTING_VALIDATION_EXCEPTION(org.elasticsearch.cluster.routing.RoutingValidationException.class, org.elasticsearch.cluster.routing.RoutingValidationException::new, 61),
+        NOT_SERIALIZABLE_EXCEPTION_WRAPPER(org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper.class, org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper::new, 62),
+        ALIAS_FILTER_PARSING_EXCEPTION(org.elasticsearch.indices.AliasFilterParsingException.class, org.elasticsearch.indices.AliasFilterParsingException::new, 63),
+        DELETE_BY_QUERY_FAILED_ENGINE_EXCEPTION(org.elasticsearch.index.engine.DeleteByQueryFailedEngineException.class, org.elasticsearch.index.engine.DeleteByQueryFailedEngineException::new, 64),
+        GATEWAY_EXCEPTION(org.elasticsearch.gateway.GatewayException.class, org.elasticsearch.gateway.GatewayException::new, 65),
+        INDEX_SHARD_NOT_RECOVERING_EXCEPTION(org.elasticsearch.index.shard.IndexShardNotRecoveringException.class, org.elasticsearch.index.shard.IndexShardNotRecoveringException::new, 66),
+        HTTP_EXCEPTION(org.elasticsearch.http.HttpException.class, org.elasticsearch.http.HttpException::new, 67),
+        ELASTICSEARCH_EXCEPTION(org.elasticsearch.ElasticsearchException.class, org.elasticsearch.ElasticsearchException::new, 68),
+        SNAPSHOT_MISSING_EXCEPTION(org.elasticsearch.snapshots.SnapshotMissingException.class, org.elasticsearch.snapshots.SnapshotMissingException::new, 69),
+        PRIMARY_MISSING_ACTION_EXCEPTION(org.elasticsearch.action.PrimaryMissingActionException.class, org.elasticsearch.action.PrimaryMissingActionException::new, 70),
+        FAILED_NODE_EXCEPTION(org.elasticsearch.action.FailedNodeException.class, org.elasticsearch.action.FailedNodeException::new, 71),
+        SEARCH_PARSE_EXCEPTION(org.elasticsearch.search.SearchParseException.class, org.elasticsearch.search.SearchParseException::new, 72),
+        CONCURRENT_SNAPSHOT_EXECUTION_EXCEPTION(org.elasticsearch.snapshots.ConcurrentSnapshotExecutionException.class, org.elasticsearch.snapshots.ConcurrentSnapshotExecutionException::new, 73),
+        BLOB_STORE_EXCEPTION(org.elasticsearch.common.blobstore.BlobStoreException.class, org.elasticsearch.common.blobstore.BlobStoreException::new, 74),
+        INCOMPATIBLE_CLUSTER_STATE_VERSION_EXCEPTION(org.elasticsearch.cluster.IncompatibleClusterStateVersionException.class, org.elasticsearch.cluster.IncompatibleClusterStateVersionException::new, 75),
+        RECOVERY_ENGINE_EXCEPTION(org.elasticsearch.index.engine.RecoveryEngineException.class, org.elasticsearch.index.engine.RecoveryEngineException::new, 76),
+        UNCATEGORIZED_EXECUTION_EXCEPTION(org.elasticsearch.common.util.concurrent.UncategorizedExecutionException.class, org.elasticsearch.common.util.concurrent.UncategorizedExecutionException::new, 77),
+        TIMESTAMP_PARSING_EXCEPTION(org.elasticsearch.action.TimestampParsingException.class, org.elasticsearch.action.TimestampParsingException::new, 78),
+        ROUTING_MISSING_EXCEPTION(org.elasticsearch.action.RoutingMissingException.class, org.elasticsearch.action.RoutingMissingException::new, 79),
+        INDEX_FAILED_ENGINE_EXCEPTION(org.elasticsearch.index.engine.IndexFailedEngineException.class, org.elasticsearch.index.engine.IndexFailedEngineException::new, 80),
+        INDEX_SHARD_RESTORE_FAILED_EXCEPTION(org.elasticsearch.index.snapshots.IndexShardRestoreFailedException.class, org.elasticsearch.index.snapshots.IndexShardRestoreFailedException::new, 81),
+        REPOSITORY_EXCEPTION(org.elasticsearch.repositories.RepositoryException.class, org.elasticsearch.repositories.RepositoryException::new, 82),
+        RECEIVE_TIMEOUT_TRANSPORT_EXCEPTION(org.elasticsearch.transport.ReceiveTimeoutTransportException.class, org.elasticsearch.transport.ReceiveTimeoutTransportException::new, 83),
+        NODE_DISCONNECTED_EXCEPTION(org.elasticsearch.transport.NodeDisconnectedException.class, org.elasticsearch.transport.NodeDisconnectedException::new, 84),
+        ALREADY_EXPIRED_EXCEPTION(org.elasticsearch.index.AlreadyExpiredException.class, org.elasticsearch.index.AlreadyExpiredException::new, 85),
+        AGGREGATION_EXECUTION_EXCEPTION(org.elasticsearch.search.aggregations.AggregationExecutionException.class, org.elasticsearch.search.aggregations.AggregationExecutionException::new, 86),
+        MERGE_MAPPING_EXCEPTION(org.elasticsearch.index.mapper.MergeMappingException.class, org.elasticsearch.index.mapper.MergeMappingException::new, 87),
+        INVALID_INDEX_TEMPLATE_EXCEPTION(org.elasticsearch.indices.InvalidIndexTemplateException.class, org.elasticsearch.indices.InvalidIndexTemplateException::new, 88),
+        PERCOLATE_EXCEPTION(org.elasticsearch.percolator.PercolateException.class, org.elasticsearch.percolator.PercolateException::new, 89),
+        REFRESH_FAILED_ENGINE_EXCEPTION(org.elasticsearch.index.engine.RefreshFailedEngineException.class, org.elasticsearch.index.engine.RefreshFailedEngineException::new, 90),
+        AGGREGATION_INITIALIZATION_EXCEPTION(org.elasticsearch.search.aggregations.AggregationInitializationException.class, org.elasticsearch.search.aggregations.AggregationInitializationException::new, 91),
+        DELAY_RECOVERY_EXCEPTION(org.elasticsearch.indices.recovery.DelayRecoveryException.class, org.elasticsearch.indices.recovery.DelayRecoveryException::new, 92),
+        INDEX_WARMER_MISSING_EXCEPTION(org.elasticsearch.search.warmer.IndexWarmerMissingException.class, org.elasticsearch.search.warmer.IndexWarmerMissingException::new, 93),
+        NO_NODE_AVAILABLE_EXCEPTION(org.elasticsearch.client.transport.NoNodeAvailableException.class, org.elasticsearch.client.transport.NoNodeAvailableException::new, 94),
+        GROOVY_SCRIPT_COMPILATION_EXCEPTION(org.elasticsearch.script.groovy.GroovyScriptCompilationException.class, org.elasticsearch.script.groovy.GroovyScriptCompilationException::new, 95),
+        INVALID_SNAPSHOT_NAME_EXCEPTION(org.elasticsearch.snapshots.InvalidSnapshotNameException.class, org.elasticsearch.snapshots.InvalidSnapshotNameException::new, 96),
+        ILLEGAL_INDEX_SHARD_STATE_EXCEPTION(org.elasticsearch.index.shard.IllegalIndexShardStateException.class, org.elasticsearch.index.shard.IllegalIndexShardStateException::new, 97),
+        INDEX_SHARD_SNAPSHOT_EXCEPTION(org.elasticsearch.index.snapshots.IndexShardSnapshotException.class, org.elasticsearch.index.snapshots.IndexShardSnapshotException::new, 98),
+        INDEX_SHARD_NOT_STARTED_EXCEPTION(org.elasticsearch.index.shard.IndexShardNotStartedException.class, org.elasticsearch.index.shard.IndexShardNotStartedException::new, 99),
+        SEARCH_PHASE_EXECUTION_EXCEPTION(org.elasticsearch.action.search.SearchPhaseExecutionException.class, org.elasticsearch.action.search.SearchPhaseExecutionException::new, 100),
+        ACTION_NOT_FOUND_TRANSPORT_EXCEPTION(org.elasticsearch.transport.ActionNotFoundTransportException.class, org.elasticsearch.transport.ActionNotFoundTransportException::new, 101),
+        TRANSPORT_SERIALIZATION_EXCEPTION(org.elasticsearch.transport.TransportSerializationException.class, org.elasticsearch.transport.TransportSerializationException::new, 102),
+        REMOTE_TRANSPORT_EXCEPTION(org.elasticsearch.transport.RemoteTransportException.class, org.elasticsearch.transport.RemoteTransportException::new, 103),
+        ENGINE_CREATION_FAILURE_EXCEPTION(org.elasticsearch.index.engine.EngineCreationFailureException.class, org.elasticsearch.index.engine.EngineCreationFailureException::new, 104),
+        ROUTING_EXCEPTION(org.elasticsearch.cluster.routing.RoutingException.class, org.elasticsearch.cluster.routing.RoutingException::new, 105),
+        INDEX_SHARD_RECOVERY_EXCEPTION(org.elasticsearch.index.shard.IndexShardRecoveryException.class, org.elasticsearch.index.shard.IndexShardRecoveryException::new, 106),
+        REPOSITORY_MISSING_EXCEPTION(org.elasticsearch.repositories.RepositoryMissingException.class, org.elasticsearch.repositories.RepositoryMissingException::new, 107),
+        PERCOLATOR_EXCEPTION(org.elasticsearch.index.percolator.PercolatorException.class, org.elasticsearch.index.percolator.PercolatorException::new, 108),
+        DOCUMENT_SOURCE_MISSING_EXCEPTION(org.elasticsearch.index.engine.DocumentSourceMissingException.class, org.elasticsearch.index.engine.DocumentSourceMissingException::new, 109),
+        FLUSH_NOT_ALLOWED_ENGINE_EXCEPTION(org.elasticsearch.index.engine.FlushNotAllowedEngineException.class, org.elasticsearch.index.engine.FlushNotAllowedEngineException::new, 110),
+        NO_CLASS_SETTINGS_EXCEPTION(org.elasticsearch.common.settings.NoClassSettingsException.class, org.elasticsearch.common.settings.NoClassSettingsException::new, 111),
+        BIND_TRANSPORT_EXCEPTION(org.elasticsearch.transport.BindTransportException.class, org.elasticsearch.transport.BindTransportException::new, 112),
+        ALIASES_NOT_FOUND_EXCEPTION(org.elasticsearch.rest.action.admin.indices.alias.delete.AliasesNotFoundException.class, org.elasticsearch.rest.action.admin.indices.alias.delete.AliasesNotFoundException::new, 113),
+        INDEX_SHARD_RECOVERING_EXCEPTION(org.elasticsearch.index.shard.IndexShardRecoveringException.class, org.elasticsearch.index.shard.IndexShardRecoveringException::new, 114),
+        TRANSLOG_EXCEPTION(org.elasticsearch.index.translog.TranslogException.class, org.elasticsearch.index.translog.TranslogException::new, 115),
+        PROCESS_CLUSTER_EVENT_TIMEOUT_EXCEPTION(org.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException.class, org.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException::new, 116),
+        RETRY_ON_PRIMARY_EXCEPTION(org.elasticsearch.action.support.replication.TransportReplicationAction.RetryOnPrimaryException.class, org.elasticsearch.action.support.replication.TransportReplicationAction.RetryOnPrimaryException::new, 117),
+        ELASTICSEARCH_TIMEOUT_EXCEPTION(org.elasticsearch.ElasticsearchTimeoutException.class, org.elasticsearch.ElasticsearchTimeoutException::new, 118),
+        QUERY_PHASE_EXECUTION_EXCEPTION(org.elasticsearch.search.query.QueryPhaseExecutionException.class, org.elasticsearch.search.query.QueryPhaseExecutionException::new, 119),
+        REPOSITORY_VERIFICATION_EXCEPTION(org.elasticsearch.repositories.RepositoryVerificationException.class, org.elasticsearch.repositories.RepositoryVerificationException::new, 120),
+        INVALID_AGGREGATION_PATH_EXCEPTION(org.elasticsearch.search.aggregations.InvalidAggregationPathException.class, org.elasticsearch.search.aggregations.InvalidAggregationPathException::new, 121),
+        GROOVY_SCRIPT_EXECUTION_EXCEPTION(org.elasticsearch.script.groovy.GroovyScriptExecutionException.class, org.elasticsearch.script.groovy.GroovyScriptExecutionException::new, 122),
+        INDEX_ALREADY_EXISTS_EXCEPTION(org.elasticsearch.indices.IndexAlreadyExistsException.class, org.elasticsearch.indices.IndexAlreadyExistsException::new, 123),
+        SCRIPT_PARSE_EXCEPTION(org.elasticsearch.script.Script.ScriptParseException.class, org.elasticsearch.script.Script.ScriptParseException::new, 124),
+        HTTP_ON_TRANSPORT_EXCEPTION(org.elasticsearch.transport.netty.SizeHeaderFrameDecoder.HttpOnTransportException.class, org.elasticsearch.transport.netty.SizeHeaderFrameDecoder.HttpOnTransportException::new, 125),
+        MAPPER_PARSING_EXCEPTION(org.elasticsearch.index.mapper.MapperParsingException.class, org.elasticsearch.index.mapper.MapperParsingException::new, 126),
+        SEARCH_CONTEXT_EXCEPTION(org.elasticsearch.search.SearchContextException.class, org.elasticsearch.search.SearchContextException::new, 127),
+        SEARCH_SOURCE_BUILDER_EXCEPTION(org.elasticsearch.search.builder.SearchSourceBuilderException.class, org.elasticsearch.search.builder.SearchSourceBuilderException::new, 128),
+        ENGINE_CLOSED_EXCEPTION(org.elasticsearch.index.engine.EngineClosedException.class, org.elasticsearch.index.engine.EngineClosedException::new, 129),
+        NO_SHARD_AVAILABLE_ACTION_EXCEPTION(org.elasticsearch.action.NoShardAvailableActionException.class, org.elasticsearch.action.NoShardAvailableActionException::new, 130),
+        UNAVAILABLE_SHARDS_EXCEPTION(org.elasticsearch.action.UnavailableShardsException.class, org.elasticsearch.action.UnavailableShardsException::new, 131),
+        FLUSH_FAILED_ENGINE_EXCEPTION(org.elasticsearch.index.engine.FlushFailedEngineException.class, org.elasticsearch.index.engine.FlushFailedEngineException::new, 132),
+        CIRCUIT_BREAKING_EXCEPTION(org.elasticsearch.common.breaker.CircuitBreakingException.class, org.elasticsearch.common.breaker.CircuitBreakingException::new, 133),
+        NODE_NOT_CONNECTED_EXCEPTION(org.elasticsearch.transport.NodeNotConnectedException.class, org.elasticsearch.transport.NodeNotConnectedException::new, 134),
+        STRICT_DYNAMIC_MAPPING_EXCEPTION(org.elasticsearch.index.mapper.StrictDynamicMappingException.class, org.elasticsearch.index.mapper.StrictDynamicMappingException::new, 135),
+        RETRY_ON_REPLICA_EXCEPTION(org.elasticsearch.action.support.replication.TransportReplicationAction.RetryOnReplicaException.class, org.elasticsearch.action.support.replication.TransportReplicationAction.RetryOnReplicaException::new, 136),
+        TYPE_MISSING_EXCEPTION(org.elasticsearch.indices.TypeMissingException.class, org.elasticsearch.indices.TypeMissingException::new, 137),
+        FAILED_TO_COMMIT_CLUSTER_STATE_EXCEPTION(org.elasticsearch.discovery.Discovery.FailedToCommitClusterStateException.class, org.elasticsearch.discovery.Discovery.FailedToCommitClusterStateException::new, 140),
+        QUERY_SHARD_EXCEPTION(org.elasticsearch.index.query.QueryShardException.class, org.elasticsearch.index.query.QueryShardException::new, 141);
+
+        final Class<? extends ElasticsearchException> exceptionClass;
+        final FunctionThatThrowsIOException<StreamInput, ? extends ElasticsearchException> constructor;
+        final int id;
+
+        ElasticsearchExceptionHandle(Class<? extends ElasticsearchException> exceptionClass, FunctionThatThrowsIOException<StreamInput, ? extends ElasticsearchException> constructor, int id) {
+            this.exceptionClass = exceptionClass;
+            this.constructor = constructor;
+            this.id = id;
         }
+    }
+
+    static {
+        final Map<Class<? extends ElasticsearchException>, ElasticsearchExceptionHandle> exceptions = Arrays.stream(ElasticsearchExceptionHandle.values()).collect(Collectors.toMap(e -> e.exceptionClass, e -> e));
+        final Map<Integer, FunctionThatThrowsIOException<StreamInput, ? extends ElasticsearchException>> idToSupplier = Arrays.stream(ElasticsearchExceptionHandle.values()).collect(Collectors.toMap(e -> e.id, e -> e.constructor));
 
-        ID_TO_SUPPLIER = idToSupplier;
-        CLASS_TO_ID = Collections.unmodifiableMap(exceptions);
+        ID_TO_SUPPLIER = Collections.unmodifiableMap(idToSupplier);
+        CLASS_TO_ELASTICSEARCH_EXCEPTION_HANDLE = Collections.unmodifiableMap(exceptions);
     }
 
     public String getIndex() {
@@ -702,4 +689,8 @@ public class ElasticsearchException extends RuntimeException implements ToXConte
         ElasticsearchException.toXContent(builder, params, t);
         builder.endObject();
     }
+
+    interface FunctionThatThrowsIOException<T, R> {
+        R apply(T t) throws IOException;
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
index c9c3eeb..302097a 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
@@ -27,6 +27,7 @@ import org.elasticsearch.common.SuppressForbidden;
 import org.elasticsearch.common.cli.CliTool;
 import org.elasticsearch.common.cli.Terminal;
 import org.elasticsearch.common.collect.Tuple;
+import org.elasticsearch.common.inject.CreationException;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
@@ -40,6 +41,8 @@ import org.elasticsearch.node.Node;
 import org.elasticsearch.node.NodeBuilder;
 import org.elasticsearch.node.internal.InternalSettingsPreparer;
 
+import java.io.ByteArrayOutputStream;
+import java.io.PrintStream;
 import java.util.Locale;
 import java.util.concurrent.CountDownLatch;
 
@@ -287,7 +290,18 @@ final class Bootstrap {
             if (INSTANCE.node != null) {
                 logger = Loggers.getLogger(Bootstrap.class, INSTANCE.node.settings().get("name"));
             }
-            logger.error("Exception", e);
+            // HACK, it sucks to do this, but we will run users out of disk space otherwise
+            if (e instanceof CreationException) {
+                // guice: log the shortened exc to the log file
+                ByteArrayOutputStream os = new ByteArrayOutputStream();
+                PrintStream ps = new PrintStream(os, false, "UTF-8");
+                new StartupError(e).printStackTrace(ps);
+                ps.flush();
+                logger.error("Guice Exception: {}", os.toString("UTF-8"));
+            } else {
+                // full exception
+                logger.error("Exception", e);
+            }
             // re-enable it if appropriate, so they can see any logging during the shutdown process
             if (foreground) {
                 Loggers.enableConsoleLogging();
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/StartupError.java b/core/src/main/java/org/elasticsearch/bootstrap/StartupError.java
index 9a5df8e..781aac3 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/StartupError.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/StartupError.java
@@ -97,7 +97,11 @@ final class StartupError extends RuntimeException {
                 linesWritten++;
             }
         }
-        s.println("Refer to the log for complete error details.");
+        // if its a guice exception, the whole thing really will not be in the log, its megabytes.
+        // refer to the hack in bootstrap, where we don't log it
+        if (originalCause instanceof CreationException == false) {
+            s.println("Refer to the log for complete error details.");
+        }
     }
     
     /** 
diff --git a/core/src/main/java/org/elasticsearch/cluster/ClusterState.java b/core/src/main/java/org/elasticsearch/cluster/ClusterState.java
index d119637..3a71530 100644
--- a/core/src/main/java/org/elasticsearch/cluster/ClusterState.java
+++ b/core/src/main/java/org/elasticsearch/cluster/ClusterState.java
@@ -380,7 +380,7 @@ public class ClusterState implements ToXContent, Diffable<ClusterState> {
 
             if (!blocks().indices().isEmpty()) {
                 builder.startObject("indices");
-                for (Map.Entry<String, Set<ClusterBlock>> entry : blocks().indices().entrySet()) {
+                for (Map.Entry<String, ImmutableSet<ClusterBlock>> entry : blocks().indices().entrySet()) {
                     builder.startObject(entry.getKey());
                     for (ClusterBlock block : entry.getValue()) {
                         block.toXContent(builder, params);
diff --git a/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlockException.java b/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlockException.java
index 94fad64..9d1a41d 100644
--- a/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlockException.java
+++ b/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlockException.java
@@ -19,36 +19,35 @@
 
 package org.elasticsearch.cluster.block;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.rest.RestStatus;
 
 import java.io.IOException;
-import java.util.HashSet;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableSet;
-
 /**
  *
  */
 public class ClusterBlockException extends ElasticsearchException {
-    private final Set<ClusterBlock> blocks;
 
-    public ClusterBlockException(Set<ClusterBlock> blocks) {
+    private final ImmutableSet<ClusterBlock> blocks;
+
+    public ClusterBlockException(ImmutableSet<ClusterBlock> blocks) {
         super(buildMessage(blocks));
         this.blocks = blocks;
     }
 
     public ClusterBlockException(StreamInput in) throws IOException {
         super(in);
-        int totalBlocks = in.readVInt();
-        Set<ClusterBlock> blocks = new HashSet<>(totalBlocks);
-        for (int i = 0; i < totalBlocks;i++) {
-            blocks.add(ClusterBlock.readClusterBlock(in));
+        int num = in.readVInt();
+        ImmutableSet.Builder<ClusterBlock> builder = ImmutableSet.builder();
+        for (int i = 0; i < num; i++) {
+            builder.add(ClusterBlock.readClusterBlock(in));
         }
-        this.blocks = unmodifiableSet(blocks);
+        blocks = builder.build();
     }
 
     @Override
@@ -73,11 +72,11 @@ public class ClusterBlockException extends ElasticsearchException {
         return true;
     }
 
-    public Set<ClusterBlock> blocks() {
+    public ImmutableSet<ClusterBlock> blocks() {
         return blocks;
     }
 
-    private static String buildMessage(Set<ClusterBlock> blocks) {
+    private static String buildMessage(ImmutableSet<ClusterBlock> blocks) {
         StringBuilder sb = new StringBuilder("blocked by: ");
         for (ClusterBlock block : blocks) {
             sb.append("[").append(block.status()).append("/").append(block.id()).append("/").append(block.description()).append("];");
diff --git a/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java b/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
index ab5609c..2352a36 100644
--- a/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
+++ b/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
@@ -20,7 +20,7 @@
 package org.elasticsearch.cluster.block;
 
 import com.google.common.collect.ImmutableMap;
-
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaDataIndexStateService;
@@ -33,72 +33,68 @@ import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
-import java.util.function.Function;
-import java.util.function.Predicate;
-import java.util.stream.Stream;
-
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.emptySet;
-import static java.util.Collections.unmodifiableSet;
-import static java.util.stream.Collectors.toSet;
-import static java.util.stream.Stream.concat;
 
 /**
  * Represents current cluster level blocks to block dirty operations done against the cluster.
  */
 public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
-    public static final ClusterBlocks EMPTY_CLUSTER_BLOCK = new ClusterBlocks(emptySet(), emptyMap());
+
+    public static final ClusterBlocks EMPTY_CLUSTER_BLOCK = new ClusterBlocks(ImmutableSet.<ClusterBlock>of(), ImmutableMap.<String, ImmutableSet<ClusterBlock>>of());
 
     public static final ClusterBlocks PROTO = EMPTY_CLUSTER_BLOCK;
 
-    private final Set<ClusterBlock> global;
+    private final ImmutableSet<ClusterBlock> global;
 
-    private final Map<String, Set<ClusterBlock>> indicesBlocks;
+    private final Map<String, ImmutableSet<ClusterBlock>> indicesBlocks;
 
     private final ImmutableLevelHolder[] levelHolders;
 
-    ClusterBlocks(Set<ClusterBlock> global, Map<String, Set<ClusterBlock>> indicesBlocks) {
+    ClusterBlocks(ImmutableSet<ClusterBlock> global, Map<String, ImmutableSet<ClusterBlock>> indicesBlocks) {
         this.global = global;
         this.indicesBlocks = indicesBlocks;
 
         levelHolders = new ImmutableLevelHolder[ClusterBlockLevel.values().length];
-        for (final ClusterBlockLevel level : ClusterBlockLevel.values()) {
-            Predicate<ClusterBlock> containsLevel = block -> block.contains(level);
-            Set<ClusterBlock> newGlobal = unmodifiableSet(global.stream()
-                    .filter(containsLevel)
-                    .collect(toSet()));
-
-            ImmutableMap.Builder<String, Set<ClusterBlock>> indicesBuilder = ImmutableMap.builder();
-            for (Map.Entry<String, Set<ClusterBlock>> entry : indicesBlocks.entrySet()) {
-                indicesBuilder.put(entry.getKey(), unmodifiableSet(entry.getValue().stream()
-                        .filter(containsLevel)
-                        .collect(toSet())));
+        for (ClusterBlockLevel level : ClusterBlockLevel.values()) {
+            ImmutableSet.Builder<ClusterBlock> globalBuilder = ImmutableSet.builder();
+            for (ClusterBlock block : global) {
+                if (block.contains(level)) {
+                    globalBuilder.add(block);
+                }
+            }
+
+
+            ImmutableMap.Builder<String, ImmutableSet<ClusterBlock>> indicesBuilder = ImmutableMap.builder();
+            for (Map.Entry<String, ImmutableSet<ClusterBlock>> entry : indicesBlocks.entrySet()) {
+                ImmutableSet.Builder<ClusterBlock> indexBuilder = ImmutableSet.builder();
+                for (ClusterBlock block : entry.getValue()) {
+                    if (block.contains(level)) {
+                        indexBuilder.add(block);
+                    }
+                }
+
+                indicesBuilder.put(entry.getKey(), indexBuilder.build());
             }
 
-            levelHolders[level.id()] = new ImmutableLevelHolder(newGlobal, indicesBuilder.build());
+            levelHolders[level.id()] = new ImmutableLevelHolder(globalBuilder.build(), indicesBuilder.build());
         }
     }
 
-    public Set<ClusterBlock> global() {
+    public ImmutableSet<ClusterBlock> global() {
         return global;
     }
 
-    public Map<String, Set<ClusterBlock>> indices() {
+    public Map<String, ImmutableSet<ClusterBlock>> indices() {
         return indicesBlocks;
     }
 
-    public Set<ClusterBlock> global(ClusterBlockLevel level) {
+    public ImmutableSet<ClusterBlock> global(ClusterBlockLevel level) {
         return levelHolders[level.id()].global();
     }
 
-    public Map<String, Set<ClusterBlock>> indices(ClusterBlockLevel level) {
+    public Map<String, ImmutableSet<ClusterBlock>> indices(ClusterBlockLevel level) {
         return levelHolders[level.id()].indices();
     }
 
-    private Set<ClusterBlock> blocksForIndex(ClusterBlockLevel level, String index) {
-        return indices(level).getOrDefault(index, emptySet());
-    }
-
     /**
      * Returns <tt>true</tt> if one of the global blocks as its disable state persistence flag set.
      */
@@ -155,7 +151,7 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
         if (global(level).isEmpty()) {
             return null;
         }
-        return new ClusterBlockException(global(level));
+        return new ClusterBlockException(ImmutableSet.copyOf(global(level)));
     }
 
     public void indexBlockedRaiseException(ClusterBlockLevel level, String index) throws ClusterBlockException {
@@ -169,17 +165,24 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
         if (!indexBlocked(level, index)) {
             return null;
         }
-        Stream<ClusterBlock> blocks = concat(
-                global(level).stream(),
-                blocksForIndex(level, index).stream());
-        return new ClusterBlockException(unmodifiableSet(blocks.collect(toSet())));
+        ImmutableSet.Builder<ClusterBlock> builder = ImmutableSet.builder();
+        builder.addAll(global(level));
+        ImmutableSet<ClusterBlock> indexBlocks = indices(level).get(index);
+        if (indexBlocks != null) {
+            builder.addAll(indexBlocks);
+        }
+        return new ClusterBlockException(builder.build());
     }
 
     public boolean indexBlocked(ClusterBlockLevel level, String index) {
         if (!global(level).isEmpty()) {
             return true;
         }
-        return !blocksForIndex(level, index).isEmpty();
+        ImmutableSet<ClusterBlock> indexBlocks = indices(level).get(index);
+        if (indexBlocks != null && !indexBlocks.isEmpty()) {
+            return true;
+        }
+        return false;
     }
 
     public ClusterBlockException indicesBlockedException(ClusterBlockLevel level, String[] indices) {
@@ -192,24 +195,28 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
         if (!indexIsBlocked) {
             return null;
         }
-        Function<String, Stream<ClusterBlock>> blocksForIndexAtLevel = index -> blocksForIndex(level, index).stream();
-        Stream<ClusterBlock> blocks = concat(
-                global(level).stream(),
-                Stream.of(indices).flatMap(blocksForIndexAtLevel));
-        return new ClusterBlockException(unmodifiableSet(blocks.collect(toSet())));
+        ImmutableSet.Builder<ClusterBlock> builder = ImmutableSet.builder();
+        builder.addAll(global(level));
+        for (String index : indices) {
+            ImmutableSet<ClusterBlock> indexBlocks = indices(level).get(index);
+            if (indexBlocks != null) {
+                builder.addAll(indexBlocks);
+            }
+        }
+        return new ClusterBlockException(builder.build());
     }
 
     @Override
     public void writeTo(StreamOutput out) throws IOException {
         writeBlockSet(global, out);
         out.writeVInt(indicesBlocks.size());
-        for (Map.Entry<String, Set<ClusterBlock>> entry : indicesBlocks.entrySet()) {
+        for (Map.Entry<String, ImmutableSet<ClusterBlock>> entry : indicesBlocks.entrySet()) {
             out.writeString(entry.getKey());
             writeBlockSet(entry.getValue(), out);
         }
     }
 
-    private static void writeBlockSet(Set<ClusterBlock> blocks, StreamOutput out) throws IOException {
+    private static void writeBlockSet(ImmutableSet<ClusterBlock> blocks, StreamOutput out) throws IOException {
         out.writeVInt(blocks.size());
         for (ClusterBlock block : blocks) {
             block.writeTo(out);
@@ -218,8 +225,8 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
 
     @Override
     public ClusterBlocks readFrom(StreamInput in) throws IOException {
-        Set<ClusterBlock> global = readBlockSet(in);
-        ImmutableMap.Builder<String, Set<ClusterBlock>> indicesBuilder = ImmutableMap.builder();
+        ImmutableSet<ClusterBlock> global = readBlockSet(in);
+        ImmutableMap.Builder<String, ImmutableSet<ClusterBlock>> indicesBuilder = ImmutableMap.builder();
         int size = in.readVInt();
         for (int j = 0; j < size; j++) {
             indicesBuilder.put(in.readString().intern(), readBlockSet(in));
@@ -227,32 +234,32 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
         return new ClusterBlocks(global, indicesBuilder.build());
     }
 
-    private static Set<ClusterBlock> readBlockSet(StreamInput in) throws IOException {
-        int totalBlocks = in.readVInt();
-        Set<ClusterBlock> blocks = new HashSet<>(totalBlocks);
-        for (int i = 0; i < totalBlocks;i++) {
-            blocks.add(ClusterBlock.readClusterBlock(in));
+    private static ImmutableSet<ClusterBlock> readBlockSet(StreamInput in) throws IOException {
+        ImmutableSet.Builder<ClusterBlock> builder = ImmutableSet.builder();
+        int size = in.readVInt();
+        for (int i = 0; i < size; i++) {
+            builder.add(ClusterBlock.readClusterBlock(in));
         }
-        return unmodifiableSet(blocks);
+        return builder.build();
     }
 
     static class ImmutableLevelHolder {
 
-        static final ImmutableLevelHolder EMPTY = new ImmutableLevelHolder(emptySet(), ImmutableMap.of());
+        static final ImmutableLevelHolder EMPTY = new ImmutableLevelHolder(ImmutableSet.<ClusterBlock>of(), ImmutableMap.<String, ImmutableSet<ClusterBlock>>of());
 
-        private final Set<ClusterBlock> global;
-        private final ImmutableMap<String, Set<ClusterBlock>> indices;
+        private final ImmutableSet<ClusterBlock> global;
+        private final ImmutableMap<String, ImmutableSet<ClusterBlock>> indices;
 
-        ImmutableLevelHolder(Set<ClusterBlock> global, ImmutableMap<String, Set<ClusterBlock>> indices) {
+        ImmutableLevelHolder(ImmutableSet<ClusterBlock> global, ImmutableMap<String, ImmutableSet<ClusterBlock>> indices) {
             this.global = global;
             this.indices = indices;
         }
 
-        public Set<ClusterBlock> global() {
+        public ImmutableSet<ClusterBlock> global() {
             return global;
         }
 
-        public ImmutableMap<String, Set<ClusterBlock>> indices() {
+        public ImmutableMap<String, ImmutableSet<ClusterBlock>> indices() {
             return indices;
         }
     }
@@ -272,7 +279,7 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
 
         public Builder blocks(ClusterBlocks blocks) {
             global.addAll(blocks.global());
-            for (Map.Entry<String, Set<ClusterBlock>> entry : blocks.indices().entrySet()) {
+            for (Map.Entry<String, ImmutableSet<ClusterBlock>> entry : blocks.indices().entrySet()) {
                 if (!indices.containsKey(entry.getKey())) {
                     indices.put(entry.getKey(), new HashSet<>());
                 }
@@ -338,12 +345,11 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
         }
 
         public ClusterBlocks build() {
-            // We copy the block sets here in case of the builder is modified after build is called
-            ImmutableMap.Builder<String, Set<ClusterBlock>> indicesBuilder = ImmutableMap.builder();
+            ImmutableMap.Builder<String, ImmutableSet<ClusterBlock>> indicesBuilder = ImmutableMap.builder();
             for (Map.Entry<String, Set<ClusterBlock>> entry : indices.entrySet()) {
-                indicesBuilder.put(entry.getKey(), unmodifiableSet(new HashSet<>(entry.getValue())));
+                indicesBuilder.put(entry.getKey(), ImmutableSet.copyOf(entry.getValue()));
             }
-            return new ClusterBlocks(unmodifiableSet(new HashSet<>(global)), indicesBuilder.build());
+            return new ClusterBlocks(ImmutableSet.copyOf(global), indicesBuilder.build());
         }
 
         public static ClusterBlocks readClusterBlocks(StreamInput in) throws IOException {
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasMetaData.java b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasMetaData.java
index c083396..fb640ee 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasMetaData.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasMetaData.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.cluster.metadata;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.ElasticsearchGenerationException;
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.common.Strings;
@@ -35,8 +36,6 @@ import java.util.Collections;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.emptySet;
-
 /**
  *
  */
@@ -62,7 +61,7 @@ public class AliasMetaData extends AbstractDiffable<AliasMetaData> {
         if (searchRouting != null) {
             searchRoutingValues = Collections.unmodifiableSet(Strings.splitStringByCommaToSet(searchRouting));
         } else {
-            searchRoutingValues = emptySet();
+            searchRoutingValues = ImmutableSet.of();
         }
     }
 
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
index d8b98d6..3ca3ec3 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
@@ -22,7 +22,7 @@ package org.elasticsearch.cluster.metadata;
 import com.carrotsearch.hppc.ObjectHashSet;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
+import com.google.common.collect.ImmutableSet;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.cluster.Diff;
 import org.elasticsearch.cluster.Diffable;
@@ -59,26 +59,12 @@ import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.search.warmer.IndexWarmersMetaData;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.EnumSet;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.SortedMap;
-import java.util.TreeMap;
+import java.util.*;
 import java.util.stream.Collectors;
 
-import static java.util.Collections.unmodifiableSet;
 import static org.elasticsearch.common.settings.Settings.readSettingsFromStream;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.settings.Settings.writeSettingsToStream;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
 
 public class MetaData implements Iterable<IndexMetaData>, Diffable<MetaData>, FromXContentBuilder<MetaData>, ToXContent {
 
@@ -743,16 +729,16 @@ public class MetaData implements Iterable<IndexMetaData>, Diffable<MetaData>, Fr
     }
 
     /** All known byte-sized cluster settings. */
-    public static final Set<String> CLUSTER_BYTES_SIZE_SETTINGS = unmodifiableSet(newHashSet(
+    public static final Set<String> CLUSTER_BYTES_SIZE_SETTINGS = ImmutableSet.of(
         IndicesStore.INDICES_STORE_THROTTLE_MAX_BYTES_PER_SEC,
         RecoverySettings.INDICES_RECOVERY_FILE_CHUNK_SIZE,
         RecoverySettings.INDICES_RECOVERY_TRANSLOG_SIZE,
         RecoverySettings.INDICES_RECOVERY_MAX_BYTES_PER_SEC,
-        RecoverySettings.INDICES_RECOVERY_MAX_SIZE_PER_SEC));
+        RecoverySettings.INDICES_RECOVERY_MAX_SIZE_PER_SEC);
 
 
     /** All known time cluster settings. */
-    public static final Set<String> CLUSTER_TIME_SETTINGS = unmodifiableSet(newHashSet(
+    public static final Set<String> CLUSTER_TIME_SETTINGS = ImmutableSet.of(
                                     IndicesTTLService.INDICES_TTL_INTERVAL,
                                     RecoverySettings.INDICES_RECOVERY_RETRY_DELAY_STATE_SYNC,
                                     RecoverySettings.INDICES_RECOVERY_RETRY_DELAY_NETWORK,
@@ -763,7 +749,7 @@ public class MetaData implements Iterable<IndexMetaData>, Diffable<MetaData>, Fr
                                     InternalClusterInfoService.INTERNAL_CLUSTER_INFO_UPDATE_INTERVAL,
                                     InternalClusterInfoService.INTERNAL_CLUSTER_INFO_TIMEOUT,
                                     DiscoverySettings.PUBLISH_TIMEOUT,
-                                    InternalClusterService.SETTING_CLUSTER_SERVICE_SLOW_TASK_LOGGING_THRESHOLD));
+                                    InternalClusterService.SETTING_CLUSTER_SERVICE_SLOW_TASK_LOGGING_THRESHOLD);
 
     /** As of 2.0 we require units for time and byte-sized settings.  This methods adds default units to any cluster settings that don't
      *  specify a unit. */
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java
index a17fe04..365783b 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java
@@ -19,7 +19,6 @@
 package org.elasticsearch.cluster.metadata;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-
 import org.apache.lucene.analysis.Analyzer;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.Version;
@@ -30,6 +29,7 @@ import org.elasticsearch.cluster.routing.UnassignedInfo;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.analysis.AnalysisService;
 import org.elasticsearch.index.analysis.NamedAnalyzer;
@@ -41,9 +41,6 @@ import org.elasticsearch.script.ScriptService;
 import java.util.Locale;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
-
 /**
  * This service is responsible for upgrading legacy index metadata to the current version
  * <p>
@@ -220,7 +217,7 @@ public class MetaDataIndexUpgradeService extends AbstractComponent {
     }
 
     /** All known byte-sized settings for an index. */
-    public static final Set<String> INDEX_BYTES_SIZE_SETTINGS = unmodifiableSet(newHashSet(
+    public static final Set<String> INDEX_BYTES_SIZE_SETTINGS = ImmutableSet.of(
                                     "index.merge.policy.floor_segment",
                                     "index.merge.policy.max_merged_segment",
                                     "index.merge.policy.max_merge_size",
@@ -230,10 +227,10 @@ public class MetaDataIndexUpgradeService extends AbstractComponent {
                                     "index.store.throttle.max_bytes_per_sec",
                                     "index.translog.flush_threshold_size",
                                     "index.translog.fs.buffer_size",
-                                    "index.version_map_size"));
+                                    "index.version_map_size");
 
     /** All known time settings for an index. */
-    public static final Set<String> INDEX_TIME_SETTINGS = unmodifiableSet(newHashSet(
+    public static final Set<String> INDEX_TIME_SETTINGS = ImmutableSet.of(
                                     "index.gateway.wait_for_mapping_update_post_recovery",
                                     "index.shard.wait_for_mapping_update_post_recovery",
                                     "index.gc_deletes",
@@ -255,7 +252,7 @@ public class MetaDataIndexUpgradeService extends AbstractComponent {
                                     "index.translog.flush_threshold_period",
                                     "index.translog.interval",
                                     "index.translog.sync_interval",
-                                    UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING));
+                                    UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING);
 
     /**
      * Elasticsearch 2.0 requires units on byte/memory and time settings; this method adds the default unit to any such settings that are
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingAllocation.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingAllocation.java
index 1874a7b..5e1d150 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingAllocation.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingAllocation.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.cluster.routing.allocation;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.cluster.ClusterInfo;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
@@ -33,9 +34,6 @@ import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.emptySet;
-import static java.util.Collections.unmodifiableSet;
-
 /**
  * The {@link RoutingAllocation} keep the state of the current allocation
  * of shards and holds the {@link AllocationDeciders} which are responsible
@@ -222,13 +220,13 @@ public class RoutingAllocation {
 
     public Set<String> getIgnoreNodes(ShardId shardId) {
         if (ignoredShardToNodes == null) {
-            return emptySet();
+            return ImmutableSet.of();
         }
         Set<String> ignore = ignoredShardToNodes.get(shardId);
         if (ignore == null) {
-            return emptySet();
+            return ImmutableSet.of();
         }
-        return unmodifiableSet(new HashSet<>(ignore));
+        return ImmutableSet.copyOf(ignore);
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/Strings.java b/core/src/main/java/org/elasticsearch/common/Strings.java
index a324736..b81db96 100644
--- a/core/src/main/java/org/elasticsearch/common/Strings.java
+++ b/core/src/main/java/org/elasticsearch/common/Strings.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.common;
 
+import com.google.common.collect.ImmutableSet;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.FastStringReader;
@@ -29,21 +30,7 @@ import org.elasticsearch.common.xcontent.json.JsonXContent;
 
 import java.io.BufferedReader;
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Properties;
-import java.util.Random;
-import java.util.Set;
-import java.util.StringTokenizer;
-import java.util.TreeSet;
-
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
+import java.util.*;
 
 /**
  *
@@ -456,8 +443,7 @@ public class Strings {
         return sb.toString();
     }
 
-    public static final Set<Character> INVALID_FILENAME_CHARS = unmodifiableSet(
-            newHashSet('\\', '/', '*', '?', '"', '<', '>', '|', ' ', ','));
+    public static final ImmutableSet<Character> INVALID_FILENAME_CHARS = ImmutableSet.of('\\', '/', '*', '?', '"', '<', '>', '|', ' ', ',');
 
     public static boolean validFileName(String fileName) {
         for (int i = 0; i < fileName.length(); i++) {
@@ -609,7 +595,7 @@ public class Strings {
                     result[res++] = builder.toString();
                     builder.setLength(0);
                 }
-
+                
             } else {
                 builder.append(s.charAt(i));
             }
@@ -1023,11 +1009,11 @@ public class Strings {
 
     private Strings() {
     }
-
+    
     public static byte[] toUTF8Bytes(CharSequence charSequence) {
         return toUTF8Bytes(charSequence, new BytesRefBuilder());
     }
-
+    
     public static byte[] toUTF8Bytes(CharSequence charSequence, BytesRefBuilder spare) {
         spare.copyChars(charSequence);
         return Arrays.copyOf(spare.bytes(), spare.length());
diff --git a/core/src/main/java/org/elasticsearch/common/inject/BindingProcessor.java b/core/src/main/java/org/elasticsearch/common/inject/BindingProcessor.java
index e560eeb..0ef8c26 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/BindingProcessor.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/BindingProcessor.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.internal.Annotations;
 import org.elasticsearch.common.inject.internal.BindingImpl;
 import org.elasticsearch.common.inject.internal.Errors;
@@ -46,9 +47,6 @@ import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
-
 /**
  * Handles {@link Binder#bind} and {@link Binder#bindConstant} elements.
  *
@@ -284,7 +282,7 @@ class BindingProcessor extends AbstractProcessor {
     // It's unfortunate that we have to maintain a blacklist of specific
     // classes, but we can't easily block the whole package because of
     // all our unit tests.
-    private static final Set<Class<?>> FORBIDDEN_TYPES = unmodifiableSet(newHashSet(
+    private static final Set<Class<?>> FORBIDDEN_TYPES = ImmutableSet.of(
             AbstractModule.class,
             Binder.class,
             Binding.class,
@@ -294,7 +292,7 @@ class BindingProcessor extends AbstractProcessor {
             Module.class,
             Provider.class,
             Scope.class,
-            TypeLiteral.class));
+            TypeLiteral.class);
     // TODO(jessewilson): fix BuiltInModule, then add Stage
 
     interface CreationListener {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/ConfigurationException.java b/core/src/main/java/org/elasticsearch/common/inject/ConfigurationException.java
index 870fece..3aaed0d 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/ConfigurationException.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/ConfigurationException.java
@@ -16,15 +16,12 @@
 
 package org.elasticsearch.common.inject;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.spi.Message;
 
 import java.util.Collection;
 import java.util.Locale;
-import java.util.Set;
-
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
 
 /**
  * Thrown when a programming error such as a misplaced annotation, illegal binding, or unsupported
@@ -34,14 +31,15 @@ import static org.elasticsearch.common.util.set.Sets.newHashSet;
  * @since 2.0
  */
 public final class ConfigurationException extends RuntimeException {
-    private final Set<Message> messages;
+
+    private final ImmutableSet<Message> messages;
     private Object partialValue = null;
 
     /**
      * Creates a ConfigurationException containing {@code messages}.
      */
     public ConfigurationException(Iterable<Message> messages) {
-        this.messages = unmodifiableSet(newHashSet(messages));
+        this.messages = ImmutableSet.copyOf(messages);
         initCause(Errors.getOnlyCause(this.messages));
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/ConstructorInjector.java b/core/src/main/java/org/elasticsearch/common/inject/ConstructorInjector.java
index 734e07d..c8792af 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/ConstructorInjector.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/ConstructorInjector.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.internal.ConstructionContext;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.internal.ErrorsException;
@@ -23,7 +24,6 @@ import org.elasticsearch.common.inject.internal.InternalContext;
 import org.elasticsearch.common.inject.spi.InjectionPoint;
 
 import java.lang.reflect.InvocationTargetException;
-import java.util.Set;
 
 /**
  * Creates instances using an injectable constructor. After construction, all injectable fields and
@@ -33,12 +33,12 @@ import java.util.Set;
  */
 class ConstructorInjector<T> {
 
-    private final Set<InjectionPoint> injectableMembers;
+    private final ImmutableSet<InjectionPoint> injectableMembers;
     private final SingleParameterInjector<?>[] parameterInjectors;
     private final ConstructionProxy<T> constructionProxy;
     private final MembersInjectorImpl<T> membersInjector;
 
-    ConstructorInjector(Set<InjectionPoint> injectableMembers,
+    ConstructorInjector(ImmutableSet<InjectionPoint> injectableMembers,
                         ConstructionProxy<T> constructionProxy,
                         SingleParameterInjector<?>[] parameterInjectors,
                         MembersInjectorImpl<T> membersInjector)
@@ -49,7 +49,7 @@ class ConstructorInjector<T> {
         this.membersInjector = membersInjector;
     }
 
-    public Set<InjectionPoint> getInjectableMembers() {
+    public ImmutableSet<InjectionPoint> getInjectableMembers() {
         return injectableMembers;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/CreationException.java b/core/src/main/java/org/elasticsearch/common/inject/CreationException.java
index 4c8e94b..4900efe 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/CreationException.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/CreationException.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.spi.Message;
 
@@ -28,13 +29,14 @@ import java.util.Collection;
  * @author crazybob@google.com (Bob Lee)
  */
 public class CreationException extends RuntimeException {
-    private final Collection<Message> messages;
+
+    private final ImmutableSet<Message> messages;
 
     /**
      * Creates a CreationException containing {@code messages}.
      */
     public CreationException(Collection<Message> messages) {
-        this.messages = messages;
+        this.messages = ImmutableSet.copyOf(messages);
         if (this.messages.isEmpty()) {
             throw new IllegalArgumentException();
         }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java b/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java
index eb05b1d..12c317b 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InheritingState.java
@@ -16,12 +16,14 @@
 
 package org.elasticsearch.common.inject;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.internal.BindingImpl;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.internal.InstanceBindingImpl;
 import org.elasticsearch.common.inject.internal.InternalFactory;
 import org.elasticsearch.common.inject.internal.MatcherAndConverter;
 import org.elasticsearch.common.inject.internal.SourceProvider;
+import org.elasticsearch.common.inject.spi.InjectionPoint;
 import org.elasticsearch.common.inject.spi.TypeListenerBinding;
 
 import java.lang.annotation.Annotation;
@@ -33,8 +35,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Objects;
 
-import static java.util.Collections.emptySet;
-
 /**
  * @author jessewilson@google.com (Jesse Wilson)
  */
@@ -155,8 +155,7 @@ class InheritingState implements State {
             Key key = entry.getKey();
             BindingImpl<?> binding = (BindingImpl<?>) entry.getValue();
             Object value = binding.getProvider().get();
-            x.put(key, new InstanceBindingImpl<Object>(injector, key, SourceProvider.UNKNOWN_SOURCE, new InternalFactory.Instance(value),
-                    emptySet(), value));
+            x.put(key, new InstanceBindingImpl<Object>(injector, key, SourceProvider.UNKNOWN_SOURCE, new InternalFactory.Instance(value), ImmutableSet.<InjectionPoint>of(), value));
         }
         this.explicitBindingsMutable.clear();
         this.explicitBindingsMutable.putAll(x);
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InjectorBuilder.java b/core/src/main/java/org/elasticsearch/common/inject/InjectorBuilder.java
index 2f9a3f1..4a9ba4a 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InjectorBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InjectorBuilder.java
@@ -16,15 +16,15 @@
 
 package org.elasticsearch.common.inject;
 
-import org.elasticsearch.common.inject.internal.BindingImpl;
-import org.elasticsearch.common.inject.internal.Errors;
-import org.elasticsearch.common.inject.internal.ErrorsException;
-import org.elasticsearch.common.inject.internal.InternalContext;
-import org.elasticsearch.common.inject.internal.Stopwatch;
+import com.google.common.collect.ImmutableSet;
+import org.elasticsearch.common.inject.internal.*;
 import org.elasticsearch.common.inject.spi.Dependency;
+import org.elasticsearch.common.util.iterable.Iterables;
 
+import java.util.Collection;
 import java.util.List;
 import java.util.Map;
+import java.util.Set;
 
 /**
  * Builds a tree of injectors. This is a primary injector, plus child injectors needed for each
@@ -182,38 +182,35 @@ class InjectorBuilder {
      * Loads eager singletons, or all singletons if we're in Stage.PRODUCTION. Bindings discovered
      * while we're binding these singletons are not be eager.
      */
-    public void loadEagerSingletons(InjectorImpl injector, Stage stage, Errors errors) {
-        for (final Binding<?> binding : injector.state.getExplicitBindingsThisLevel().values()) {
-            loadEagerSingletons(injector, stage, errors, (BindingImpl<?>)binding);
-        }
-        for (final Binding<?> binding : injector.jitBindings.values()) {
-            loadEagerSingletons(injector, stage, errors, (BindingImpl<?>)binding);
-        }
-    }
-
-    private void loadEagerSingletons(InjectorImpl injector, Stage stage, final Errors errors, BindingImpl<?> binding) {
-        if (binding.getScoping().isEagerSingleton(stage)) {
-            try {
-                injector.callInContext(new ContextualCallable<Void>() {
-                    Dependency<?> dependency = Dependency.get(binding.getKey());
-
-                    @Override
-                    public Void call(InternalContext context) {
-                        context.setDependency(dependency);
-                        Errors errorsForBinding = errors.withSource(dependency);
-                        try {
-                            binding.getInternalFactory().get(errorsForBinding, context, dependency);
-                        } catch (ErrorsException e) {
-                            errorsForBinding.merge(e.getErrors());
-                        } finally {
-                            context.setDependency(null);
+    public void loadEagerSingletons(InjectorImpl injector, Stage stage, final Errors errors) {
+        @SuppressWarnings("unchecked") // casting Collection<Binding> to Collection<BindingImpl> is safe
+                Set<BindingImpl<?>> candidateBindings = ImmutableSet.copyOf(Iterables.concat(
+                (Collection) injector.state.getExplicitBindingsThisLevel().values(),
+                injector.jitBindings.values()));
+        for (final BindingImpl<?> binding : candidateBindings) {
+            if (binding.getScoping().isEagerSingleton(stage)) {
+                try {
+                    injector.callInContext(new ContextualCallable<Void>() {
+                        Dependency<?> dependency = Dependency.get(binding.getKey());
+
+                        @Override
+                        public Void call(InternalContext context) {
+                            context.setDependency(dependency);
+                            Errors errorsForBinding = errors.withSource(dependency);
+                            try {
+                                binding.getInternalFactory().get(errorsForBinding, context, dependency);
+                            } catch (ErrorsException e) {
+                                errorsForBinding.merge(e.getErrors());
+                            } finally {
+                                context.setDependency(null);
+                            }
+
+                            return null;
                         }
-
-                        return null;
-                    }
-                });
-            } catch (ErrorsException e) {
-                throw new AssertionError();
+                    });
+                } catch (ErrorsException e) {
+                    throw new AssertionError();
+                }
             }
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InjectorImpl.java b/core/src/main/java/org/elasticsearch/common/inject/InjectorImpl.java
index 7ad62af..15fb181 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InjectorImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InjectorImpl.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.Classes;
 import org.elasticsearch.common.inject.internal.Annotations;
 import org.elasticsearch.common.inject.internal.BindingImpl;
@@ -34,6 +35,7 @@ import org.elasticsearch.common.inject.internal.ToStringBuilder;
 import org.elasticsearch.common.inject.spi.BindingTargetVisitor;
 import org.elasticsearch.common.inject.spi.ConvertedConstantBinding;
 import org.elasticsearch.common.inject.spi.Dependency;
+import org.elasticsearch.common.inject.spi.InjectionPoint;
 import org.elasticsearch.common.inject.spi.ProviderBinding;
 import org.elasticsearch.common.inject.spi.ProviderKeyBinding;
 import org.elasticsearch.common.inject.util.Providers;
@@ -52,8 +54,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.emptySet;
-import static java.util.Collections.singleton;
 import static org.elasticsearch.common.inject.internal.Annotations.findScopeAnnotation;
 
 /**
@@ -221,7 +221,7 @@ class InjectorImpl implements Injector, Lookups {
 
 
         return new InstanceBindingImpl<>(this, key, SourceProvider.UNKNOWN_SOURCE,
-                factory, emptySet(), membersInjector);
+                factory, ImmutableSet.<InjectionPoint>of(), membersInjector);
     }
 
     /**
@@ -379,7 +379,7 @@ class InjectorImpl implements Injector, Lookups {
 
         @Override
         public Set<Dependency<?>> getDependencies() {
-            return singleton(Dependency.get(getSourceKey()));
+            return ImmutableSet.<Dependency<?>>of(Dependency.get(getSourceKey()));
         }
 
         @Override
@@ -502,7 +502,7 @@ class InjectorImpl implements Injector, Lookups {
         InternalFactory<TypeLiteral<T>> factory = new ConstantFactory<>(
                 Initializables.of(value));
         return new InstanceBindingImpl<>(this, key, SourceProvider.UNKNOWN_SOURCE,
-                factory, emptySet(), value);
+                factory, ImmutableSet.<InjectionPoint>of(), value);
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java b/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
index 8368ec1..aeb3f2e 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
@@ -25,7 +25,6 @@ import java.util.List;
 import java.util.Objects;
 import java.util.logging.Logger;
 
-import static java.util.Collections.emptySet;
 import static org.elasticsearch.common.inject.Scopes.SINGLETON;
 
 /**
@@ -186,7 +185,7 @@ class InjectorShell {
         injector.state.putBinding(key,
                 new ProviderInstanceBindingImpl<>(injector, key, SourceProvider.UNKNOWN_SOURCE,
                         injectorFactory, Scoping.UNSCOPED, injectorFactory,
-                        emptySet()));
+                        ImmutableSet.<InjectionPoint>of()));
     }
 
     private static class InjectorFactory implements InternalFactory<Injector>, Provider<Injector> {
@@ -223,7 +222,7 @@ class InjectorShell {
         injector.state.putBinding(key,
                 new ProviderInstanceBindingImpl<>(injector, key,
                         SourceProvider.UNKNOWN_SOURCE, loggerFactory, Scoping.UNSCOPED,
-                        loggerFactory, emptySet()));
+                        loggerFactory, ImmutableSet.<InjectionPoint>of()));
     }
 
     private static class LoggerFactory implements InternalFactory<Logger>, Provider<Logger> {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/MembersInjectorImpl.java b/core/src/main/java/org/elasticsearch/common/inject/MembersInjectorImpl.java
index f88ecd6..4208971 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/MembersInjectorImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/MembersInjectorImpl.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.internal.ErrorsException;
 import org.elasticsearch.common.inject.internal.InternalContext;
@@ -23,10 +24,6 @@ import org.elasticsearch.common.inject.spi.InjectionListener;
 import org.elasticsearch.common.inject.spi.InjectionPoint;
 
 import java.util.List;
-import java.util.Set;
-
-import static java.util.Collections.unmodifiableSet;
-import static java.util.stream.Collectors.toSet;
 
 /**
  * Injects members of instances of a given type.
@@ -115,9 +112,11 @@ class MembersInjectorImpl<T> implements MembersInjector<T> {
         return "MembersInjector<" + typeLiteral + ">";
     }
 
-    public Set<InjectionPoint> getInjectionPoints() {
-        return unmodifiableSet(memberInjectors.stream()
-                .map(SingleMemberInjector::getInjectionPoint)
-                .collect(toSet()));
+    public ImmutableSet<InjectionPoint> getInjectionPoints() {
+        ImmutableSet.Builder<InjectionPoint> builder = ImmutableSet.builder();
+        for (SingleMemberInjector memberInjector : memberInjectors) {
+            builder.add(memberInjector.getInjectionPoint());
+        }
+        return builder.build();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/ProvisionException.java b/core/src/main/java/org/elasticsearch/common/inject/ProvisionException.java
index c8887af..6fc7c30 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/ProvisionException.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/ProvisionException.java
@@ -16,16 +16,12 @@
 
 package org.elasticsearch.common.inject;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.spi.Message;
 
 import java.util.Collection;
 import java.util.Collections;
-import java.util.Set;
-
-import static java.util.Collections.singleton;
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
 
 /**
  * Indicates that there was a runtime failure while providing an instance.
@@ -35,13 +31,14 @@ import static org.elasticsearch.common.util.set.Sets.newHashSet;
  * @since 2.0
  */
 public final class ProvisionException extends RuntimeException {
-    private final Set<Message> messages;
+
+    private final ImmutableSet<Message> messages;
 
     /**
      * Creates a ConfigurationException containing {@code messages}.
      */
     public ProvisionException(Iterable<Message> messages) {
-        this.messages = unmodifiableSet(newHashSet(messages));
+        this.messages = ImmutableSet.copyOf(messages);
         if (this.messages.isEmpty()) {
             throw new IllegalArgumentException();
         }
@@ -50,11 +47,11 @@ public final class ProvisionException extends RuntimeException {
 
     public ProvisionException(String message, Throwable cause) {
         super(cause);
-        this.messages = singleton(new Message(Collections.emptyList(), message, cause));
+        this.messages = ImmutableSet.of(new Message(Collections.emptyList(), message, cause));
     }
 
     public ProvisionException(String message) {
-        this.messages = singleton(new Message(message));
+        this.messages = ImmutableSet.of(new Message(message));
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/inject/State.java b/core/src/main/java/org/elasticsearch/common/inject/State.java
index 2337816..0388bb0 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/State.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/State.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.internal.BindingImpl;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.internal.MatcherAndConverter;
@@ -26,8 +27,6 @@ import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.emptySet;
-
 /**
  * The inheritable data within an injector. This class is intended to allow parent and local
  * injector data to be accessed as a unit.
@@ -80,7 +79,7 @@ interface State {
 
         @Override
         public Iterable<MatcherAndConverter> getConvertersThisLevel() {
-            return emptySet();
+            return ImmutableSet.of();
         }
 
         @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java
index ea5a664..78aeb56 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java
@@ -17,7 +17,7 @@
 package org.elasticsearch.common.inject.assistedinject;
 
 import com.google.common.collect.ImmutableMap;
-
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.ConfigurationException;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.Injector;
@@ -37,14 +37,10 @@ import java.lang.reflect.Proxy;
 import java.lang.reflect.Type;
 import java.util.ArrayList;
 import java.util.HashMap;
-import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.singleton;
-import static java.util.Collections.unmodifiableSet;
-
 /**
  * Provides a factory that combines the caller's arguments with injector-supplied values to
  * construct objects.
@@ -283,7 +279,7 @@ public class FactoryProvider<F> implements Provider<F>, HasDependencies {
 
     @Override
     public Set<Dependency<?>> getDependencies() {
-        Set<Dependency<?>> dependencies = new HashSet<>();
+        List<Dependency<?>> dependencies = new ArrayList<>();
         for (AssistedConstructor<?> constructor : factoryMethodToConstructor.values()) {
             for (Parameter parameter : constructor.getAllParameters()) {
                 if (!parameter.isProvidedByFactory()) {
@@ -291,7 +287,7 @@ public class FactoryProvider<F> implements Provider<F>, HasDependencies {
                 }
             }
         }
-        return unmodifiableSet(dependencies);
+        return ImmutableSet.copyOf(dependencies);
     }
 
     @Override
@@ -338,6 +334,6 @@ public class FactoryProvider<F> implements Provider<F>, HasDependencies {
     }
 
     private static ConfigurationException newConfigurationException(String format, Object... args) {
-        return new ConfigurationException(singleton(new Message(Errors.format(format, args))));
+        return new ConfigurationException(ImmutableSet.of(new Message(Errors.format(format, args))));
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
index 0c07e2a..c52b2dd 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
@@ -17,18 +17,7 @@
 package org.elasticsearch.common.inject.assistedinject;
 
 import com.google.common.collect.ImmutableMap;
-
-import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.inject.Binder;
-import org.elasticsearch.common.inject.Binding;
-import org.elasticsearch.common.inject.ConfigurationException;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.inject.Injector;
-import org.elasticsearch.common.inject.Key;
-import org.elasticsearch.common.inject.Module;
-import org.elasticsearch.common.inject.Provider;
-import org.elasticsearch.common.inject.ProvisionException;
-import org.elasticsearch.common.inject.TypeLiteral;
+import org.elasticsearch.common.inject.*;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.internal.ErrorsException;
 import org.elasticsearch.common.inject.spi.Message;
@@ -42,7 +31,6 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
-import java.util.Map;
 
 import static org.elasticsearch.common.inject.internal.Annotations.getKey;
 
@@ -90,7 +78,7 @@ public final class FactoryProvider2<F> implements InvocationHandler, Provider<F>
      * the produced type, or null if all methods return concrete types
      */
     private final Key<?> producedType;
-    private final Map<Method, Key<?>> returnTypesByMethod;
+    private final ImmutableMap<Method, Key<?>> returnTypesByMethod;
     private final ImmutableMap<Method, List<Key<?>>> paramTypes;
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/BindingBuilder.java b/core/src/main/java/org/elasticsearch/common/inject/internal/BindingBuilder.java
index 6e441d7..6b03be5 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/BindingBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/BindingBuilder.java
@@ -16,25 +16,18 @@
 
 package org.elasticsearch.common.inject.internal;
 
-import org.elasticsearch.common.inject.Binder;
-import org.elasticsearch.common.inject.ConfigurationException;
-import org.elasticsearch.common.inject.Key;
-import org.elasticsearch.common.inject.Provider;
-import org.elasticsearch.common.inject.TypeLiteral;
+import com.google.common.collect.ImmutableSet;
+import org.elasticsearch.common.inject.*;
 import org.elasticsearch.common.inject.binder.AnnotatedBindingBuilder;
 import org.elasticsearch.common.inject.spi.Element;
 import org.elasticsearch.common.inject.spi.InjectionPoint;
 import org.elasticsearch.common.inject.spi.Message;
 
 import java.lang.annotation.Annotation;
-import java.util.HashSet;
 import java.util.List;
 import java.util.Objects;
 import java.util.Set;
 
-import static java.util.Collections.emptySet;
-import static java.util.Collections.unmodifiableSet;
-
 /**
  * Bind a non-constant key.
  *
@@ -92,11 +85,11 @@ public class BindingBuilder<T> extends AbstractBindingBuilder<T>
                 for (Message message : e.getErrorMessages()) {
                     binder.addError(message);
                 }
-                injectionPoints = unmodifiableSet(new HashSet<>(e.getPartialValue()));
+                injectionPoints = e.getPartialValue();
             }
         } else {
             binder.addError(BINDING_TO_NULL);
-            injectionPoints = emptySet();
+            injectionPoints = ImmutableSet.of();
         }
 
         BindingImpl<T> base = getBinding();
@@ -117,7 +110,7 @@ public class BindingBuilder<T> extends AbstractBindingBuilder<T>
             for (Message message : e.getErrorMessages()) {
                 binder.addError(message);
             }
-            injectionPoints = unmodifiableSet(new HashSet<>(e.getPartialValue()));
+            injectionPoints = e.getPartialValue();
         }
 
         BindingImpl<T> base = getBinding();
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/ConstantBindingBuilderImpl.java b/core/src/main/java/org/elasticsearch/common/inject/internal/ConstantBindingBuilderImpl.java
index 4e67892..1cf37c1 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/ConstantBindingBuilderImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/ConstantBindingBuilderImpl.java
@@ -16,17 +16,17 @@
 
 package org.elasticsearch.common.inject.internal;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Key;
 import org.elasticsearch.common.inject.binder.AnnotatedConstantBindingBuilder;
 import org.elasticsearch.common.inject.binder.ConstantBindingBuilder;
 import org.elasticsearch.common.inject.spi.Element;
+import org.elasticsearch.common.inject.spi.InjectionPoint;
 
 import java.lang.annotation.Annotation;
 import java.util.List;
 
-import static java.util.Collections.emptySet;
-
 /**
  * Bind a constant.
  *
@@ -130,7 +130,7 @@ public final class ConstantBindingBuilderImpl<T>
         }
 
         setBinding(new InstanceBindingImpl<>(
-                base.getSource(), key, base.getScoping(), emptySet(), instanceAsT));
+                base.getSource(), key, base.getScoping(), ImmutableSet.<InjectionPoint>of(), instanceAsT));
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/Errors.java b/core/src/main/java/org/elasticsearch/common/inject/internal/Errors.java
index d9e193b..6c9d155 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/Errors.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/Errors.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject.internal;
 
+import com.google.common.collect.ImmutableSet;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.common.inject.ConfigurationException;
 import org.elasticsearch.common.inject.CreationException;
@@ -48,9 +49,6 @@ import java.util.Formatter;
 import java.util.List;
 import java.util.Locale;
 
-import static java.util.Collections.emptySet;
-import static java.util.Collections.unmodifiableList;
-
 /**
  * A collection of error messages. If this type is passed as a method parameter, the method is
  * considered to have executed successfully only if new errors were not added to this collection.
@@ -318,7 +316,7 @@ public final class Errors implements Serializable {
         } else if (throwable instanceof CreationException) {
             return ((CreationException) throwable).getErrorMessages();
         } else {
-            return emptySet();
+            return ImmutableSet.of();
         }
     }
 
@@ -465,7 +463,7 @@ public final class Errors implements Serializable {
             }
         });
 
-        return unmodifiableList(result);
+        return result;
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/ExposedBindingImpl.java b/core/src/main/java/org/elasticsearch/common/inject/internal/ExposedBindingImpl.java
index d59a2db..335b415 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/ExposedBindingImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/ExposedBindingImpl.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject.internal;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Injector;
 import org.elasticsearch.common.inject.Key;
@@ -26,8 +27,6 @@ import org.elasticsearch.common.inject.spi.PrivateElements;
 
 import java.util.Set;
 
-import static java.util.Collections.singleton;
-
 public class ExposedBindingImpl<T> extends BindingImpl<T> implements ExposedBinding<T> {
 
     private final PrivateElements privateElements;
@@ -51,7 +50,7 @@ public class ExposedBindingImpl<T> extends BindingImpl<T> implements ExposedBind
 
     @Override
     public Set<Dependency<?>> getDependencies() {
-        return singleton(Dependency.get(Key.get(Injector.class)));
+        return ImmutableSet.<Dependency<?>>of(Dependency.get(Key.get(Injector.class)));
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/InstanceBindingImpl.java b/core/src/main/java/org/elasticsearch/common/inject/internal/InstanceBindingImpl.java
index 7b74e64..73c447e 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/InstanceBindingImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/InstanceBindingImpl.java
@@ -16,33 +16,27 @@
 
 package org.elasticsearch.common.inject.internal;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Injector;
 import org.elasticsearch.common.inject.Key;
 import org.elasticsearch.common.inject.Provider;
-import org.elasticsearch.common.inject.spi.BindingTargetVisitor;
-import org.elasticsearch.common.inject.spi.Dependency;
-import org.elasticsearch.common.inject.spi.HasDependencies;
-import org.elasticsearch.common.inject.spi.InjectionPoint;
-import org.elasticsearch.common.inject.spi.InstanceBinding;
+import org.elasticsearch.common.inject.spi.*;
 import org.elasticsearch.common.inject.util.Providers;
 
-import java.util.HashSet;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableSet;
-
 public class InstanceBindingImpl<T> extends BindingImpl<T> implements InstanceBinding<T> {
 
     final T instance;
     final Provider<T> provider;
-    final Set<InjectionPoint> injectionPoints;
+    final ImmutableSet<InjectionPoint> injectionPoints;
 
     public InstanceBindingImpl(Injector injector, Key<T> key, Object source,
                                InternalFactory<? extends T> internalFactory, Set<InjectionPoint> injectionPoints,
                                T instance) {
         super(injector, key, source, internalFactory, Scoping.UNSCOPED);
-        this.injectionPoints = injectionPoints;
+        this.injectionPoints = ImmutableSet.copyOf(injectionPoints);
         this.instance = instance;
         this.provider = Providers.of(instance);
     }
@@ -50,7 +44,7 @@ public class InstanceBindingImpl<T> extends BindingImpl<T> implements InstanceBi
     public InstanceBindingImpl(Object source, Key<T> key, Scoping scoping,
                                Set<InjectionPoint> injectionPoints, T instance) {
         super(source, key, scoping);
-        this.injectionPoints = injectionPoints;
+        this.injectionPoints = ImmutableSet.copyOf(injectionPoints);
         this.instance = instance;
         this.provider = Providers.of(instance);
     }
@@ -78,7 +72,7 @@ public class InstanceBindingImpl<T> extends BindingImpl<T> implements InstanceBi
     @Override
     public Set<Dependency<?>> getDependencies() {
         return instance instanceof HasDependencies
-                ? unmodifiableSet(new HashSet<>((((HasDependencies) instance).getDependencies())))
+                ? ImmutableSet.copyOf(((HasDependencies) instance).getDependencies())
                 : Dependency.forInjectionPoints(injectionPoints);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java b/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
index 1b68f2c..737b8fa 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
@@ -18,29 +18,18 @@
 package org.elasticsearch.common.inject.internal;
 
 import com.google.common.collect.ImmutableMap;
-
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.ConfigurationException;
 import org.elasticsearch.common.inject.TypeLiteral;
 import org.elasticsearch.common.inject.spi.Message;
 
 import java.io.Serializable;
-import java.lang.reflect.Constructor;
-import java.lang.reflect.Field;
-import java.lang.reflect.GenericArrayType;
-import java.lang.reflect.GenericDeclaration;
-import java.lang.reflect.Member;
-import java.lang.reflect.Method;
-import java.lang.reflect.ParameterizedType;
-import java.lang.reflect.Type;
-import java.lang.reflect.TypeVariable;
-import java.lang.reflect.WildcardType;
+import java.lang.reflect.*;
 import java.util.Arrays;
 import java.util.Map;
 import java.util.NoSuchElementException;
 import java.util.Objects;
 
-import static java.util.Collections.singleton;
-
 /**
  * Static methods for working with types that we aren't publishing in the
  * public {@code Types} API.
@@ -76,7 +65,7 @@ public class MoreTypes {
     public static <T> TypeLiteral<T> makeKeySafe(TypeLiteral<T> type) {
         if (!isFullySpecified(type.getType())) {
             String message = type + " cannot be used as a key; It is not fully specified.";
-            throw new ConfigurationException(singleton(new Message(message)));
+            throw new ConfigurationException(ImmutableSet.of(new Message(message)));
         }
 
         @SuppressWarnings("unchecked")
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderInstanceBindingImpl.java b/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderInstanceBindingImpl.java
index e95d8fe..8337932 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderInstanceBindingImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderInstanceBindingImpl.java
@@ -16,26 +16,20 @@ limitations under the License.
 
 package org.elasticsearch.common.inject.internal;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Injector;
 import org.elasticsearch.common.inject.Key;
 import org.elasticsearch.common.inject.Provider;
-import org.elasticsearch.common.inject.spi.BindingTargetVisitor;
-import org.elasticsearch.common.inject.spi.Dependency;
-import org.elasticsearch.common.inject.spi.HasDependencies;
-import org.elasticsearch.common.inject.spi.InjectionPoint;
-import org.elasticsearch.common.inject.spi.ProviderInstanceBinding;
+import org.elasticsearch.common.inject.spi.*;
 
-import java.util.HashSet;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableSet;
-
 public final class ProviderInstanceBindingImpl<T> extends BindingImpl<T>
         implements ProviderInstanceBinding<T> {
 
     final Provider<? extends T> providerInstance;
-    final Set<InjectionPoint> injectionPoints;
+    final ImmutableSet<InjectionPoint> injectionPoints;
 
     public ProviderInstanceBindingImpl(Injector injector, Key<T> key,
                                        Object source, InternalFactory<? extends T> internalFactory, Scoping scoping,
@@ -43,13 +37,13 @@ public final class ProviderInstanceBindingImpl<T> extends BindingImpl<T>
                                        Set<InjectionPoint> injectionPoints) {
         super(injector, key, source, internalFactory, scoping);
         this.providerInstance = providerInstance;
-        this.injectionPoints = injectionPoints;
+        this.injectionPoints = ImmutableSet.copyOf(injectionPoints);
     }
 
     public ProviderInstanceBindingImpl(Object source, Key<T> key, Scoping scoping,
                                        Set<InjectionPoint> injectionPoints, Provider<? extends T> providerInstance) {
         super(source, key, scoping);
-        this.injectionPoints = injectionPoints;
+        this.injectionPoints = ImmutableSet.copyOf(injectionPoints);
         this.providerInstance = providerInstance;
     }
 
@@ -71,7 +65,7 @@ public final class ProviderInstanceBindingImpl<T> extends BindingImpl<T>
     @Override
     public Set<Dependency<?>> getDependencies() {
         return providerInstance instanceof HasDependencies
-                ? unmodifiableSet(new HashSet<>((((HasDependencies) providerInstance).getDependencies())))
+                ? ImmutableSet.copyOf(((HasDependencies) providerInstance).getDependencies())
                 : Dependency.forInjectionPoints(injectionPoints);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethod.java b/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethod.java
index 0cfafc4..a5d2f09 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethod.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethod.java
@@ -16,11 +16,8 @@
 
 package org.elasticsearch.common.inject.internal;
 
-import org.elasticsearch.common.inject.Binder;
-import org.elasticsearch.common.inject.Exposed;
-import org.elasticsearch.common.inject.Key;
-import org.elasticsearch.common.inject.PrivateBinder;
-import org.elasticsearch.common.inject.Provider;
+import com.google.common.collect.ImmutableSet;
+import org.elasticsearch.common.inject.*;
 import org.elasticsearch.common.inject.spi.Dependency;
 import org.elasticsearch.common.inject.spi.ProviderWithDependencies;
 
@@ -40,7 +37,7 @@ public class ProviderMethod<T> implements ProviderWithDependencies<T> {
     private final Class<? extends Annotation> scopeAnnotation;
     private final Object instance;
     private final Method method;
-    private final Set<Dependency<?>> dependencies;
+    private final ImmutableSet<Dependency<?>> dependencies;
     private final List<Provider<?>> parameterProviders;
     private final boolean exposed;
 
@@ -48,7 +45,7 @@ public class ProviderMethod<T> implements ProviderWithDependencies<T> {
      * @param method the method to invoke. Its return type must be the same type as {@code key}.
      */
     ProviderMethod(Key<T> key, Method method, Object instance,
-                   Set<Dependency<?>> dependencies, List<Provider<?>> parameterProviders,
+                   ImmutableSet<Dependency<?>> dependencies, List<Provider<?>> parameterProviders,
                    Class<? extends Annotation> scopeAnnotation) {
         this.key = key;
         this.scopeAnnotation = scopeAnnotation;
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java b/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java
index 1671b4a..fdd9402 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/ProviderMethodsModule.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject.internal;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Key;
 import org.elasticsearch.common.inject.Module;
@@ -30,12 +31,8 @@ import java.lang.annotation.Annotation;
 import java.lang.reflect.Member;
 import java.lang.reflect.Method;
 import java.util.ArrayList;
-import java.util.HashSet;
 import java.util.List;
 import java.util.Objects;
-import java.util.Set;
-
-import static java.util.Collections.unmodifiableSet;
 
 /**
  * Creates bindings to methods annotated with {@literal @}{@link Provides}. Use the scope and
@@ -97,7 +94,7 @@ public final class ProviderMethodsModule implements Module {
         Errors errors = new Errors(method);
 
         // prepare the parameter providers
-        Set<Dependency<?>> dependencies = new HashSet<>();
+        List<Dependency<?>> dependencies = new ArrayList<>();
         List<Provider<?>> parameterProviders = new ArrayList<>();
         List<TypeLiteral<?>> parameterTypes = typeLiteral.getParameterTypes(method);
         Annotation[][] parameterAnnotations = method.getParameterAnnotations();
@@ -118,7 +115,7 @@ public final class ProviderMethodsModule implements Module {
             binder.addError(message);
         }
 
-        return new ProviderMethod<>(key, method, delegate, unmodifiableSet(dependencies),
+        return new ProviderMethod<>(key, method, delegate, ImmutableSet.copyOf(dependencies),
                 parameterProviders, scopeAnnotation);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java b/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java
index 138b8b0..d498de9 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java
@@ -16,11 +16,11 @@
 
 package org.elasticsearch.common.inject.internal;
 
-import java.util.HashSet;
-import java.util.Set;
+import com.google.common.collect.ImmutableSet;
+import org.elasticsearch.common.util.iterable.Iterables;
 
-import static java.util.Collections.singleton;
-import static java.util.Collections.unmodifiableSet;
+import java.util.ArrayList;
+import java.util.List;
 
 /**
  * Provides access to the calling line of code.
@@ -34,29 +34,35 @@ public class SourceProvider {
      */
     public static final Object UNKNOWN_SOURCE = "[unknown source]";
 
-    private final Set<String> classNamesToSkip;
+    private final ImmutableSet<String> classNamesToSkip;
 
     public SourceProvider() {
-        this.classNamesToSkip = singleton(SourceProvider.class.getName());
+        this.classNamesToSkip = ImmutableSet.of(SourceProvider.class.getName());
     }
 
-    public static final SourceProvider DEFAULT_INSTANCE = new SourceProvider();
+    public static final SourceProvider DEFAULT_INSTANCE
+            = new SourceProvider(ImmutableSet.of(SourceProvider.class.getName()));
 
-    @SuppressWarnings("rawtypes")
-    private SourceProvider(SourceProvider copy, Class[] moreClassesToSkip) {
-        Set<String> classNamesToSkip = new HashSet<>(copy.classNamesToSkip);
-        for (Class toSkip : moreClassesToSkip) {
-            classNamesToSkip.add(toSkip.getName());
-        }
-        this.classNamesToSkip = unmodifiableSet(classNamesToSkip);
+    private SourceProvider(Iterable<String> classesToSkip) {
+        this.classNamesToSkip = ImmutableSet.copyOf(classesToSkip);
     }
 
     /**
      * Returns a new instance that also skips {@code moreClassesToSkip}.
      */
-    @SuppressWarnings("rawtypes")
     public SourceProvider plusSkippedClasses(Class... moreClassesToSkip) {
-        return new SourceProvider(this, moreClassesToSkip);
+        return new SourceProvider(Iterables.concat(classNamesToSkip, asStrings(moreClassesToSkip)));
+    }
+
+    /**
+     * Returns the class names as Strings
+     */
+    private static List<String> asStrings(Class... classes) {
+        List<String> strings = new ArrayList<>();
+        for (Class c : classes) {
+            strings.add(c.getName());
+        }
+        return strings;
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/inject/multibindings/MapBinder.java b/core/src/main/java/org/elasticsearch/common/inject/multibindings/MapBinder.java
index a9a1bb1..81f6656 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/multibindings/MapBinder.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/multibindings/MapBinder.java
@@ -16,12 +16,9 @@
 
 package org.elasticsearch.common.inject.multibindings;
 
-import org.elasticsearch.common.inject.Binder;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.inject.Key;
-import org.elasticsearch.common.inject.Module;
-import org.elasticsearch.common.inject.Provider;
-import org.elasticsearch.common.inject.TypeLiteral;
+import com.google.common.collect.ImmutableSet;
+
+import org.elasticsearch.common.inject.*;
 import org.elasticsearch.common.inject.binder.LinkedBindingBuilder;
 import org.elasticsearch.common.inject.multibindings.Multibinder.RealMultibinder;
 import org.elasticsearch.common.inject.spi.Dependency;
@@ -35,7 +32,6 @@ import java.util.Map;
 import java.util.Map.Entry;
 import java.util.Set;
 
-import static java.util.Collections.singleton;
 import static org.elasticsearch.common.inject.util.Types.newParameterizedType;
 import static org.elasticsearch.common.inject.util.Types.newParameterizedTypeWithOwner;
 
@@ -265,15 +261,15 @@ public abstract class MapBinder<K, V> {
                     binder.getProvider(valueKey)));
             return binder.bind(valueKey);
         }
-
+        
         public static class MapBinderProviderWithDependencies<K,V> implements ProviderWithDependencies<Map<K, Provider<V>>> {
             private Map<K, Provider<V>> providerMap;
-
+            
             @SuppressWarnings("rawtypes") // code is silly stupid with generics
             private final RealMapBinder binder;
             private final Set<Dependency<?>> dependencies;
             private final Provider<Set<Entry<K, Provider<V>>>> provider;
-
+            
             @SuppressWarnings("rawtypes") // code is silly stupid with generics
             MapBinderProviderWithDependencies(RealMapBinder binder, Set<Dependency<?>> dependencies, Provider<Set<Entry<K, Provider<V>>>> provider) {
                 this.binder = binder;
@@ -310,7 +306,8 @@ public abstract class MapBinder<K, V> {
         public void configure(Binder binder) {
             Multibinder.checkConfiguration(!isInitialized(), "MapBinder was already initialized");
 
-            final Set<Dependency<?>> dependencies = singleton(Dependency.get(entrySetBinder.getSetKey()));
+            final ImmutableSet<Dependency<?>> dependencies
+                    = ImmutableSet.<Dependency<?>>of(Dependency.get(entrySetBinder.getSetKey()));
 
             // binds a Map<K, Provider<V>> from a collection of Map<Entry<K, Provider<V>>
             final Provider<Set<Entry<K, Provider<V>>>> entrySetProvider = binder
diff --git a/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java b/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java
index 56f0ec0..9455dc5 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/multibindings/Multibinder.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject.multibindings;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Binding;
 import org.elasticsearch.common.inject.ConfigurationException;
@@ -36,16 +37,11 @@ import java.lang.annotation.Annotation;
 import java.lang.reflect.Type;
 import java.util.ArrayList;
 import java.util.Collections;
-import java.util.HashSet;
 import java.util.LinkedHashSet;
 import java.util.List;
 import java.util.Objects;
 import java.util.Set;
 
-import static java.util.Collections.emptyList;
-import static java.util.Collections.singleton;
-import static java.util.Collections.unmodifiableSet;
-
 /**
  * An API to bind multiple values separately, only to later inject them as a
  * complete collection. Multibinder is intended for use in your application's
@@ -242,8 +238,9 @@ public abstract class Multibinder<T> {
         @Inject
         public void initialize(Injector injector) {
             providers = new ArrayList<>();
-            Set<Dependency<?>> dependencies = new HashSet<>();
+            List<Dependency<?>> dependencies = new ArrayList<>();
             for (Binding<?> entry : injector.findBindingsByType(elementType)) {
+
                 if (keyMatches(entry.getKey())) {
                     @SuppressWarnings("unchecked") // protected by findBindingsByType()
                             Binding<T> binding = (Binding<T>) entry;
@@ -252,7 +249,7 @@ public abstract class Multibinder<T> {
                 }
             }
 
-            this.dependencies = unmodifiableSet(dependencies);
+            this.dependencies = ImmutableSet.copyOf(dependencies);
             this.binder = null;
         }
 
@@ -321,7 +318,7 @@ public abstract class Multibinder<T> {
             return;
         }
 
-        throw new ConfigurationException(singleton(new Message(Errors.format(format, args))));
+        throw new ConfigurationException(ImmutableSet.of(new Message(Errors.format(format, args))));
     }
 
     static <T> T checkNotNull(T reference, String name) {
@@ -330,7 +327,7 @@ public abstract class Multibinder<T> {
         }
 
         NullPointerException npe = new NullPointerException(name);
-        throw new ConfigurationException(singleton(
-                new Message(emptyList(), npe.toString(), npe)));
+        throw new ConfigurationException(ImmutableSet.of(
+                new Message(Collections.emptyList(), npe.toString(), npe)));
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/Dependency.java b/core/src/main/java/org/elasticsearch/common/inject/spi/Dependency.java
index f339f4a..2bac853 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/Dependency.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/Dependency.java
@@ -16,14 +16,14 @@
 
 package org.elasticsearch.common.inject.spi;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.Key;
 
-import java.util.HashSet;
+import java.util.ArrayList;
+import java.util.List;
 import java.util.Objects;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableSet;
-
 /**
  * A variable that can be resolved by an injector.
  * <p>
@@ -60,11 +60,11 @@ public final class Dependency<T> {
      * Returns the dependencies from the given injection points.
      */
     public static Set<Dependency<?>> forInjectionPoints(Set<InjectionPoint> injectionPoints) {
-        Set<Dependency<?>> dependencies = new HashSet<>();
+        List<Dependency<?>> dependencies = new ArrayList<>();
         for (InjectionPoint injectionPoint : injectionPoints) {
             dependencies.addAll(injectionPoint.getDependencies());
         }
-        return unmodifiableSet(dependencies);
+        return ImmutableSet.copyOf(dependencies);
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionPoint.java b/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionPoint.java
index 53e0cb0..2aa07b4 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionPoint.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/InjectionPoint.java
@@ -17,7 +17,6 @@
 package org.elasticsearch.common.inject.spi;
 
 import com.google.common.collect.ImmutableSet;
-
 import org.elasticsearch.common.inject.ConfigurationException;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.Key;
@@ -39,12 +38,10 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
-import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableSet;
 import static org.elasticsearch.common.inject.internal.MoreTypes.getRawType;
 
 /**
@@ -256,13 +253,13 @@ public final class InjectionPoint {
      *                                of the valid injection points.
      */
     public static Set<InjectionPoint> forStaticMethodsAndFields(TypeLiteral type) {
-        Set<InjectionPoint> result = new HashSet<>();
+        List<InjectionPoint> sink = new ArrayList<>();
         Errors errors = new Errors();
 
-        addInjectionPoints(type, Factory.FIELDS, true, result, errors);
-        addInjectionPoints(type, Factory.METHODS, true, result, errors);
+        addInjectionPoints(type, Factory.FIELDS, true, sink, errors);
+        addInjectionPoints(type, Factory.METHODS, true, sink, errors);
 
-        result = unmodifiableSet(result);
+        ImmutableSet<InjectionPoint> result = ImmutableSet.copyOf(sink);
         if (errors.hasErrors()) {
             throw new ConfigurationException(errors.getMessages()).withPartialValue(result);
         }
@@ -296,14 +293,14 @@ public final class InjectionPoint {
      *                                of the valid injection points.
      */
     public static Set<InjectionPoint> forInstanceMethodsAndFields(TypeLiteral<?> type) {
-        Set<InjectionPoint> result = new HashSet<>();
+        List<InjectionPoint> sink = new ArrayList<>();
         Errors errors = new Errors();
 
         // TODO (crazybob): Filter out overridden members.
-        addInjectionPoints(type, Factory.FIELDS, false, result, errors);
-        addInjectionPoints(type, Factory.METHODS, false, result, errors);
+        addInjectionPoints(type, Factory.FIELDS, false, sink, errors);
+        addInjectionPoints(type, Factory.METHODS, false, sink, errors);
 
-        result = unmodifiableSet(result);
+        ImmutableSet<InjectionPoint> result = ImmutableSet.copyOf(sink);
         if (errors.hasErrors()) {
             throw new ConfigurationException(errors.getMessages()).withPartialValue(result);
         }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java b/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java
index 25dc07b..f29e5aa 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/util/Modules.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject.util;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Binding;
@@ -39,9 +40,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
-
 /**
  * Static utility methods for creating and working with instances of {@link Module}.
  *
@@ -96,14 +94,15 @@ public final class Modules {
      * Returns a new module that installs all of {@code modules}.
      */
     public static Module combine(Module... modules) {
-        return combine(Arrays.asList(modules));
+        return combine(ImmutableSet.copyOf(modules));
     }
 
     /**
      * Returns a new module that installs all of {@code modules}.
      */
     public static Module combine(Iterable<? extends Module> modules) {
-        final Set<? extends Module> modulesSet = newHashSet(modules);
+        // TODO: infer type once JI-9019884 is fixed
+        final Set<Module> modulesSet = ImmutableSet.<Module>copyOf(modules);
         return new Module() {
             @Override
             public void configure(Binder binder) {
@@ -132,10 +131,11 @@ public final class Modules {
     }
 
     private static final class RealOverriddenModuleBuilder implements OverriddenModuleBuilder {
-        private final Set<Module> baseModules;
+        private final ImmutableSet<Module> baseModules;
 
         private RealOverriddenModuleBuilder(Iterable<? extends Module> baseModules) {
-            this.baseModules = unmodifiableSet(newHashSet(baseModules));
+            // TODO: infer type once JI-9019884 is fixed
+            this.baseModules = ImmutableSet.<Module>copyOf(baseModules);
         }
 
         @Override
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
index 17d9995..57850da 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
@@ -38,19 +38,9 @@ import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
 import org.joda.time.DateTime;
 import org.joda.time.DateTimeZone;
 
-import java.io.ByteArrayInputStream;
-import java.io.EOFException;
-import java.io.FileNotFoundException;
-import java.io.FilterInputStream;
-import java.io.IOException;
-import java.io.InputStream;
+import java.io.*;
 import java.nio.file.NoSuchFileException;
-import java.util.ArrayList;
-import java.util.Date;
-import java.util.HashMap;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 
 import static org.elasticsearch.ElasticsearchException.readException;
 import static org.elasticsearch.ElasticsearchException.readStackTrace;
diff --git a/core/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java b/core/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java
index d036ad5..a269d23 100644
--- a/core/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java
+++ b/core/src/main/java/org/elasticsearch/common/unit/ByteSizeValue.java
@@ -245,15 +245,16 @@ public class ByteSizeValue implements Streamable {
 
     @Override
     public boolean equals(Object o) {
-        if (this == o) return true;
-        if (o == null || getClass() != o.getClass()) return false;
+        if (this == o) {
+            return true;
+        }
+        if (o == null || getClass() != o.getClass()) {
+            return false;
+        }
 
         ByteSizeValue sizeValue = (ByteSizeValue) o;
 
-        if (size != sizeValue.size) return false;
-        if (sizeUnit != sizeValue.sizeUnit) return false;
-
-        return true;
+        return bytes() == sizeValue.bytes();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/env/NodeEnvironment.java b/core/src/main/java/org/elasticsearch/env/NodeEnvironment.java
index 8c59999..41f209b 100644
--- a/core/src/main/java/org/elasticsearch/env/NodeEnvironment.java
+++ b/core/src/main/java/org/elasticsearch/env/NodeEnvironment.java
@@ -19,14 +19,10 @@
 
 package org.elasticsearch.env;
 
+import com.google.common.collect.ImmutableSet;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.SegmentInfos;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.FSDirectory;
-import org.apache.lucene.store.Lock;
-import org.apache.lucene.store.LockObtainFailedException;
-import org.apache.lucene.store.NativeFSLockFactory;
-import org.apache.lucene.store.SimpleFSDirectory;
+import org.apache.lucene.store.*;
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -46,27 +42,12 @@ import org.elasticsearch.monitor.fs.FsProbe;
 
 import java.io.Closeable;
 import java.io.IOException;
-import java.nio.file.AtomicMoveNotSupportedException;
-import java.nio.file.DirectoryStream;
-import java.nio.file.FileStore;
-import java.nio.file.Files;
-import java.nio.file.Path;
-import java.nio.file.StandardCopyOption;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
-import java.util.Set;
+import java.nio.file.*;
+import java.util.*;
 import java.util.concurrent.Semaphore;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 
-import static java.util.Collections.unmodifiableSet;
-
 /**
  * A component that holds all data paths for a single node.
  */
@@ -526,11 +507,12 @@ public class NodeEnvironment extends AbstractComponent implements Closeable {
     }
 
     /**
-     * Returns all currently lock shards.
+     * Returns all currently lock shards
      */
     public Set<ShardId> lockedShards() {
         synchronized (shardLocks) {
-            return unmodifiableSet(new HashSet<>(shardLocks.keySet()));
+            ImmutableSet.Builder<ShardId> builder = ImmutableSet.builder();
+            return builder.addAll(shardLocks.keySet()).build();
         }
     }
 
diff --git a/core/src/main/java/org/elasticsearch/gateway/AsyncShardFetch.java b/core/src/main/java/org/elasticsearch/gateway/AsyncShardFetch.java
index 4c72894..20a3dd6 100644
--- a/core/src/main/java/org/elasticsearch/gateway/AsyncShardFetch.java
+++ b/core/src/main/java/org/elasticsearch/gateway/AsyncShardFetch.java
@@ -19,7 +19,7 @@
 package org.elasticsearch.gateway;
 
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.ElasticsearchTimeoutException;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.action.ActionListener;
@@ -38,14 +38,7 @@ import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.transport.ReceiveTimeoutTransportException;
 
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.Map;
-import java.util.Set;
-
-import static java.util.Collections.emptySet;
-import static java.util.Collections.unmodifiableSet;
+import java.util.*;
 
 /**
  * Allows to asynchronously fetch shard related data from other nodes for allocation, without blocking
@@ -80,7 +73,6 @@ public abstract class AsyncShardFetch<T extends BaseNodeResponse> implements Rel
         this.action = (List<BaseNodesResponse<T>, T>) action;
     }
 
-    @Override
     public synchronized void close() {
         this.closed = true;
     }
@@ -127,7 +119,7 @@ public abstract class AsyncShardFetch<T extends BaseNodeResponse> implements Rel
 
         // if we are still fetching, return null to indicate it
         if (hasAnyNodeFetching(cache) == true) {
-            return new FetchResult<>(shardId, null, emptySet(), emptySet());
+            return new FetchResult<>(shardId, null, ImmutableSet.<String>of(), ImmutableSet.<String>of());
         } else {
             // nothing to fetch, yay, build the return value
             Map<DiscoveryNode, T> fetchData = new HashMap<>();
@@ -151,7 +143,7 @@ public abstract class AsyncShardFetch<T extends BaseNodeResponse> implements Rel
                     }
                 }
             }
-            Set<String> allIgnoreNodes = unmodifiableSet(new HashSet<>(nodesToIgnore));
+            Set<String> allIgnoreNodes = ImmutableSet.copyOf(nodesToIgnore);
             // clear the nodes to ignore, we had a successful run in fetching everything we can
             // we need to try them if another full run is needed
             nodesToIgnore.clear();
diff --git a/core/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java b/core/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java
index cb462fb..43398c5 100644
--- a/core/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java
+++ b/core/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.gateway;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterChangedEvent;
 import org.elasticsearch.cluster.ClusterState;
@@ -46,9 +47,6 @@ import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
-import static java.util.Collections.emptySet;
-import static java.util.Collections.unmodifiableSet;
-
 /**
  *
  */
@@ -62,7 +60,7 @@ public class GatewayMetaState extends AbstractComponent implements ClusterStateL
     @Nullable
     private volatile MetaData previousMetaData;
 
-    private volatile Set<String> previouslyWrittenIndices = emptySet();
+    private volatile ImmutableSet<String> previouslyWrittenIndices = ImmutableSet.of();
 
     @Inject
     public GatewayMetaState(Settings settings, NodeEnvironment nodeEnv, MetaStateService metaStateService,
@@ -109,7 +107,7 @@ public class GatewayMetaState extends AbstractComponent implements ClusterStateL
         if (state.blocks().disableStatePersistence()) {
             // reset the current metadata, we need to start fresh...
             this.previousMetaData = null;
-            previouslyWrittenIndices = emptySet();
+            previouslyWrittenIndices = ImmutableSet.of();
             return;
         }
 
@@ -128,18 +126,17 @@ public class GatewayMetaState extends AbstractComponent implements ClusterStateL
                     // persistence was disabled or the node was restarted), see getRelevantIndicesOnDataOnlyNode().
                     // we therefore have to check here if we have shards on disk and add their indices to the previouslyWrittenIndices list
                     if (isDataOnlyNode(state)) {
-                        Set<String> newPreviouslyWrittenIndices = new HashSet<>(previouslyWrittenIndices.size());
+                        ImmutableSet.Builder<String> previouslyWrittenIndicesBuilder = ImmutableSet.builder();
                         for (IndexMetaData indexMetaData : newMetaData) {
                             IndexMetaData indexMetaDataOnDisk = null;
                             if (indexMetaData.state().equals(IndexMetaData.State.CLOSE)) {
                                 indexMetaDataOnDisk = metaStateService.loadIndexState(indexMetaData.index());
                             }
                             if (indexMetaDataOnDisk != null) {
-                                newPreviouslyWrittenIndices.add(indexMetaDataOnDisk.index());
+                                previouslyWrittenIndicesBuilder.add(indexMetaDataOnDisk.index());
                             }
                         }
-                        newPreviouslyWrittenIndices.addAll(previouslyWrittenIndices);
-                        previouslyWrittenIndices = unmodifiableSet(newPreviouslyWrittenIndices);
+                        previouslyWrittenIndices = previouslyWrittenIndicesBuilder.addAll(previouslyWrittenIndices).build();
                     }
                 } catch (Throwable e) {
                     success = false;
@@ -171,11 +168,12 @@ public class GatewayMetaState extends AbstractComponent implements ClusterStateL
 
         if (success) {
             previousMetaData = newMetaData;
-            previouslyWrittenIndices = unmodifiableSet(relevantIndices);
+            ImmutableSet.Builder<String> builder = ImmutableSet.builder();
+            previouslyWrittenIndices = builder.addAll(relevantIndices).build();
         }
     }
 
-    public static Set<String> getRelevantIndices(ClusterState state, ClusterState previousState, Set<String> previouslyWrittenIndices) {
+    public static Set<String> getRelevantIndices(ClusterState state, ClusterState previousState,ImmutableSet<String> previouslyWrittenIndices) {
         Set<String> relevantIndices;
         if (isDataOnlyNode(state)) {
             relevantIndices = getRelevantIndicesOnDataOnlyNode(state, previousState, previouslyWrittenIndices);
@@ -266,7 +264,7 @@ public class GatewayMetaState extends AbstractComponent implements ClusterStateL
      * @param newMetaData                 The new metadata
      * @return iterable over all indices states that should be written to disk
      */
-    public static Iterable<GatewayMetaState.IndexMetaWriteInfo> resolveStatesToBeWritten(Set<String> previouslyWrittenIndices, Set<String> potentiallyUnwrittenIndices, MetaData previousMetaData, MetaData newMetaData) {
+    public static Iterable<GatewayMetaState.IndexMetaWriteInfo> resolveStatesToBeWritten(ImmutableSet<String> previouslyWrittenIndices, Set<String> potentiallyUnwrittenIndices, MetaData previousMetaData, MetaData newMetaData) {
         List<GatewayMetaState.IndexMetaWriteInfo> indicesToWrite = new ArrayList<>();
         for (String index : potentiallyUnwrittenIndices) {
             IndexMetaData newIndexMetaData = newMetaData.index(index);
@@ -284,7 +282,7 @@ public class GatewayMetaState extends AbstractComponent implements ClusterStateL
         return indicesToWrite;
     }
 
-    public static Set<String> getRelevantIndicesOnDataOnlyNode(ClusterState state, ClusterState previousState, Set<String> previouslyWrittenIndices) {
+    public static Set<String> getRelevantIndicesOnDataOnlyNode(ClusterState state, ClusterState previousState, ImmutableSet<String> previouslyWrittenIndices) {
         RoutingNode newRoutingNode = state.getRoutingNodes().node(state.nodes().localNodeId());
         if (newRoutingNode == null) {
             throw new IllegalStateException("cluster state does not contain this node - cannot write index meta state");
diff --git a/core/src/main/java/org/elasticsearch/index/IndexService.java b/core/src/main/java/org/elasticsearch/index/IndexService.java
index cf43e6c..85483e2 100644
--- a/core/src/main/java/org/elasticsearch/index/IndexService.java
+++ b/core/src/main/java/org/elasticsearch/index/IndexService.java
@@ -40,7 +40,6 @@ import org.elasticsearch.index.aliases.IndexAliasesService;
 import org.elasticsearch.index.analysis.AnalysisService;
 import org.elasticsearch.index.cache.IndexCache;
 import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
-import org.elasticsearch.index.deletionpolicy.DeletionPolicyModule;
 import org.elasticsearch.index.fielddata.FieldDataType;
 import org.elasticsearch.index.fielddata.IndexFieldDataCache;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
@@ -365,8 +364,6 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
                             injector.getInstance(IndicesQueryCache.class).onClose(shardId);
                         }
                     }), path));
-            modules.add(new DeletionPolicyModule());
-
             pluginsService.processModules(modules);
 
             try {
diff --git a/core/src/main/java/org/elasticsearch/index/analysis/HtmlStripCharFilterFactory.java b/core/src/main/java/org/elasticsearch/index/analysis/HtmlStripCharFilterFactory.java
index 93c8020..18b2dda 100644
--- a/core/src/main/java/org/elasticsearch/index/analysis/HtmlStripCharFilterFactory.java
+++ b/core/src/main/java/org/elasticsearch/index/analysis/HtmlStripCharFilterFactory.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.analysis;
 
+import com.google.common.collect.ImmutableSet;
 import org.apache.lucene.analysis.charfilter.HTMLStripCharFilter;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.assistedinject.Assisted;
@@ -27,26 +28,26 @@ import org.elasticsearch.index.Index;
 import org.elasticsearch.index.settings.IndexSettings;
 
 import java.io.Reader;
-import java.util.Set;
-
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
 
+/**
+ *
+ */
 public class HtmlStripCharFilterFactory extends AbstractCharFilterFactory {
-    private final Set<String> escapedTags;
+
+    private final ImmutableSet<String> escapedTags;
 
     @Inject
     public HtmlStripCharFilterFactory(Index index, @IndexSettings Settings indexSettings, @Assisted String name, @Assisted Settings settings) {
         super(index, indexSettings, name);
         String[] escapedTags = settings.getAsArray("escaped_tags");
         if (escapedTags.length > 0) {
-            this.escapedTags = unmodifiableSet(newHashSet(escapedTags));
+            this.escapedTags = ImmutableSet.copyOf(escapedTags);
         } else {
             this.escapedTags = null;
         }
     }
 
-    public Set<String> escapedTags() {
+    public ImmutableSet<String> escapedTags() {
         return escapedTags;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/codec/CodecService.java b/core/src/main/java/org/elasticsearch/index/codec/CodecService.java
index 62ff583..77d8319 100644
--- a/core/src/main/java/org/elasticsearch/index/codec/CodecService.java
+++ b/core/src/main/java/org/elasticsearch/index/codec/CodecService.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.index.codec;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.codecs.lucene50.Lucene50StoredFieldsFormat.Mode;
 import org.apache.lucene.codecs.lucene53.Lucene53Codec;
@@ -30,8 +32,6 @@ import org.elasticsearch.index.Index;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.settings.IndexSettings;
 
-import java.util.Map;
-
 /**
  * Since Lucene 4.0 low level index segments are read and written through a
  * codec layer that allows to use use-case specific file formats &amp;
@@ -42,7 +42,7 @@ import java.util.Map;
 public class CodecService extends AbstractIndexComponent {
 
     private final MapperService mapperService;
-    private final Map<String, Codec> codecs;
+    private final ImmutableMap<String, Codec> codecs;
 
     public final static String DEFAULT_CODEC = "default";
     public final static String BEST_COMPRESSION_CODEC = "best_compression";
@@ -66,9 +66,9 @@ public class CodecService extends AbstractIndexComponent {
             codecs.put(DEFAULT_CODEC, new Lucene53Codec());
             codecs.put(BEST_COMPRESSION_CODEC, new Lucene53Codec(Mode.BEST_COMPRESSION));
         } else {
-            codecs.put(DEFAULT_CODEC,
+            codecs.put(DEFAULT_CODEC, 
                     new PerFieldMappingPostingFormatCodec(Mode.BEST_SPEED, mapperService, logger));
-            codecs.put(BEST_COMPRESSION_CODEC,
+            codecs.put(BEST_COMPRESSION_CODEC, 
                     new PerFieldMappingPostingFormatCodec(Mode.BEST_COMPRESSION, mapperService, logger));
         }
         codecs.put(LUCENE_DEFAULT_CODEC, Codec.getDefault());
diff --git a/core/src/main/java/org/elasticsearch/index/deletionpolicy/AbstractESDeletionPolicy.java b/core/src/main/java/org/elasticsearch/index/deletionpolicy/AbstractESDeletionPolicy.java
deleted file mode 100644
index 2329685..0000000
--- a/core/src/main/java/org/elasticsearch/index/deletionpolicy/AbstractESDeletionPolicy.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.deletionpolicy;
-
-import org.apache.lucene.index.IndexDeletionPolicy;
-import org.elasticsearch.common.logging.ESLogger;
-import org.elasticsearch.common.logging.Loggers;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.settings.IndexSettings;
-import org.elasticsearch.index.shard.IndexShardComponent;
-import org.elasticsearch.index.shard.ShardId;
-
-abstract class AbstractESDeletionPolicy extends IndexDeletionPolicy implements IndexShardComponent {
-
-    protected final ESLogger logger;
-
-    protected final ShardId shardId;
-
-    protected final Settings indexSettings;
-
-    protected AbstractESDeletionPolicy(ShardId shardId, @IndexSettings Settings indexSettings) {
-        this.shardId = shardId;
-        this.indexSettings = indexSettings;
-        this.logger = Loggers.getLogger(getClass(), indexSettings, shardId);
-    }
-
-    @Override
-    public ShardId shardId() {
-        return this.shardId;
-    }
-
-    @Override
-    public Settings indexSettings() {
-        return this.indexSettings;
-    }
-
-    public String nodeName() {
-        return indexSettings.get("name", "");
-    }
-
-    
-
-}
diff --git a/core/src/main/java/org/elasticsearch/index/deletionpolicy/DeletionPolicyModule.java b/core/src/main/java/org/elasticsearch/index/deletionpolicy/DeletionPolicyModule.java
deleted file mode 100644
index 55ec61f..0000000
--- a/core/src/main/java/org/elasticsearch/index/deletionpolicy/DeletionPolicyModule.java
+++ /dev/null
@@ -1,38 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.deletionpolicy;
-
-import org.apache.lucene.index.IndexDeletionPolicy;
-import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.inject.name.Names;
-
-public class DeletionPolicyModule extends AbstractModule {
-
-    @Override
-    protected void configure() {
-        bind(IndexDeletionPolicy.class)
-                .annotatedWith(Names.named("actual"))
-                .to(KeepOnlyLastDeletionPolicy.class)
-                .asEagerSingleton();
-
-        bind(SnapshotDeletionPolicy.class)
-                .asEagerSingleton();
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/deletionpolicy/KeepLastNDeletionPolicy.java b/core/src/main/java/org/elasticsearch/index/deletionpolicy/KeepLastNDeletionPolicy.java
deleted file mode 100644
index f9b3b89..0000000
--- a/core/src/main/java/org/elasticsearch/index/deletionpolicy/KeepLastNDeletionPolicy.java
+++ /dev/null
@@ -1,63 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.deletionpolicy;
-
-import org.apache.lucene.index.IndexCommit;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.settings.IndexSettings;
-import org.elasticsearch.index.shard.ShardId;
-
-import java.io.IOException;
-import java.util.List;
-
-/**
- *
- */
-public class KeepLastNDeletionPolicy extends AbstractESDeletionPolicy {
-
-    private final int numToKeep;
-
-    @Inject
-    public KeepLastNDeletionPolicy(ShardId shardId, @IndexSettings Settings indexSettings) {
-        super(shardId, indexSettings);
-        this.numToKeep = indexSettings.getAsInt("index.deletionpolicy.num_to_keep", 5);
-        logger.debug("Using [keep_last_n] deletion policy with num_to_keep[{}]", numToKeep);
-    }
-
-    @Override
-    public void onInit(List<? extends IndexCommit> commits) throws IOException {
-        // do no deletions on init
-        doDeletes(commits);
-    }
-
-    @Override
-    public void onCommit(List<? extends IndexCommit> commits) throws IOException {
-        doDeletes(commits);
-    }
-
-    private void doDeletes(List<? extends IndexCommit> commits) {
-        int size = commits.size();
-        for (int i = 0; i < size - numToKeep; i++) {
-            commits.get(i).delete();
-        }
-    }
-
-}
diff --git a/core/src/main/java/org/elasticsearch/index/deletionpolicy/KeepOnlyLastDeletionPolicy.java b/core/src/main/java/org/elasticsearch/index/deletionpolicy/KeepOnlyLastDeletionPolicy.java
deleted file mode 100644
index 9a331c6..0000000
--- a/core/src/main/java/org/elasticsearch/index/deletionpolicy/KeepOnlyLastDeletionPolicy.java
+++ /dev/null
@@ -1,65 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.deletionpolicy;
-
-import org.apache.lucene.index.IndexCommit;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.settings.IndexSettings;
-import org.elasticsearch.index.shard.ShardId;
-
-import java.util.List;
-
-/**
- * This {@link org.apache.lucene.index.IndexDeletionPolicy} implementation that
- * keeps only the most recent commit and immediately removes
- * all prior commits after a new commit is done.  This is
- * the default deletion policy.
- */
-public class KeepOnlyLastDeletionPolicy extends AbstractESDeletionPolicy {
-
-    @Inject
-    public KeepOnlyLastDeletionPolicy(ShardId shardId, @IndexSettings Settings indexSettings) {
-        super(shardId, indexSettings);
-        logger.debug("Using [keep_only_last] deletion policy");
-    }
-
-    /**
-     * Deletes all commits except the most recent one.
-     */
-    @Override
-    public void onInit(List<? extends IndexCommit> commits) {
-        // Note that commits.size() should normally be 1:
-        onCommit(commits);
-    }
-
-    /**
-     * Deletes all commits except the most recent one.
-     */
-    @Override
-    public void onCommit(List<? extends IndexCommit> commits) {
-        // Note that commits.size() should normally be 2 (if not
-        // called by onInit above):
-        int size = commits.size();
-        for (int i = 0; i < size - 1; i++) {
-            commits.get(i).delete();
-        }
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/deletionpolicy/SnapshotDeletionPolicy.java b/core/src/main/java/org/elasticsearch/index/deletionpolicy/SnapshotDeletionPolicy.java
deleted file mode 100644
index be261b1..0000000
--- a/core/src/main/java/org/elasticsearch/index/deletionpolicy/SnapshotDeletionPolicy.java
+++ /dev/null
@@ -1,220 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.deletionpolicy;
-
-import org.apache.lucene.index.IndexCommit;
-import org.apache.lucene.index.IndexDeletionPolicy;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.inject.name.Named;
-import org.elasticsearch.common.util.concurrent.ConcurrentCollections;
-import org.elasticsearch.index.shard.IndexShardComponent;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Iterator;
-import java.util.List;
-import java.util.concurrent.ConcurrentMap;
-
-/**
- * Snapshot deletion policy allows to get snapshots of an index state (last commit or all commits)
- * and if the deletion policy is used with all open index writers (JVM level) then the snapshot
- * state will not be deleted until it will be released.
- *
- *
- */
-public class SnapshotDeletionPolicy extends AbstractESDeletionPolicy {
-
-    private final IndexDeletionPolicy primary;
-
-    private final ConcurrentMap<Long, SnapshotHolder> snapshots = ConcurrentCollections.newConcurrentMap();
-
-    private volatile List<SnapshotIndexCommit> commits;
-
-    private final Object mutex = new Object();
-
-    private SnapshotIndexCommit lastCommit;
-
-    /**
-     * Constructs a new snapshot deletion policy that wraps the provided deletion policy.
-     */
-    @Inject
-    public SnapshotDeletionPolicy(@Named("actual") IndexDeletionPolicy primary) {
-        super(((IndexShardComponent) primary).shardId(), ((IndexShardComponent) primary).indexSettings());
-        this.primary = primary;
-    }
-
-    /**
-     * Called by Lucene. Same as {@link #onCommit(java.util.List)}.
-     */
-    @Override
-    public void onInit(List<? extends IndexCommit> commits) throws IOException {
-        if (!commits.isEmpty()) { // this might be empty if we create a new index. 
-            // the behavior has changed in Lucene 4.4 that calls onInit even with an empty commits list.
-            onCommit(commits);
-        }
-    }
-
-    /**
-     * Called by Lucene.. Wraps the provided commits with {@link SnapshotIndexCommit}
-     * and delegates to the wrapped deletion policy.
-     */
-    @Override
-    public void onCommit(List<? extends IndexCommit> commits) throws IOException {
-        assert !commits.isEmpty() : "Commits must not be empty";
-        synchronized (mutex) {
-            List<SnapshotIndexCommit> snapshotCommits = wrapCommits(commits);
-            primary.onCommit(snapshotCommits);
-
-            // clean snapshots that their respective counts are 0 (should not really happen)
-            for (Iterator<SnapshotHolder> it = snapshots.values().iterator(); it.hasNext(); ) {
-                SnapshotHolder holder = it.next();
-                if (holder.counter <= 0) {
-                    it.remove();
-                }
-            }
-            // build the current commits list (all the ones that are not deleted by the primary)
-            List<SnapshotIndexCommit> newCommits = new ArrayList<>();
-            for (SnapshotIndexCommit commit : snapshotCommits) {
-                if (!commit.isDeleted()) {
-                    newCommits.add(commit);
-                }
-            }
-            this.commits = newCommits;
-            // the last commit that is not deleted
-            this.lastCommit = newCommits.get(newCommits.size() - 1);     
-           
-        }
-    }
-
-    /**
-     * Snapshots all the current commits in the index. Make sure to call
-     * {@link SnapshotIndexCommits#close()} to release it.
-     */
-    public SnapshotIndexCommits snapshots() throws IOException {
-        synchronized (mutex) {
-            if (snapshots == null) {
-                throw new IllegalStateException("Snapshot deletion policy has not been init yet...");
-            }
-            List<SnapshotIndexCommit> result = new ArrayList<>(commits.size());
-            for (SnapshotIndexCommit commit : commits) {
-                result.add(snapshot(commit));
-            }
-            return new SnapshotIndexCommits(result);
-        }
-    }
-
-    /**
-     * Returns a snapshot of the index (for the last commit point). Make
-     * sure to call {@link SnapshotIndexCommit#close()} in order to release it.
-     */
-    public SnapshotIndexCommit snapshot() throws IOException {
-        synchronized (mutex) {
-            if (lastCommit == null) {
-                throw new IllegalStateException("Snapshot deletion policy has not been init yet...");
-            }
-            return snapshot(lastCommit);
-        }
-    }
-
-    @Override
-    public IndexDeletionPolicy clone() {
-       // Lucene IW makes a clone internally but since we hold on to this instance 
-       // the clone will just be the identity. See InternalEngine recovery why we need this.
-       return this;
-    }
-
-    /**
-     * Helper method to snapshot a give commit.
-     */
-    private SnapshotIndexCommit snapshot(SnapshotIndexCommit commit) throws IOException {
-        SnapshotHolder snapshotHolder = snapshots.get(commit.getGeneration());
-        if (snapshotHolder == null) {
-            snapshotHolder = new SnapshotHolder(0);
-            snapshots.put(commit.getGeneration(), snapshotHolder);
-        }
-        snapshotHolder.counter++;
-        return new OneTimeReleaseSnapshotIndexCommit(this, commit);
-    }
-
-    /**
-     * Returns <tt>true</tt> if the version has been snapshotted.
-     */
-    boolean isHeld(long version) {
-        SnapshotDeletionPolicy.SnapshotHolder holder = snapshots.get(version);
-        return holder != null && holder.counter > 0;
-    }
-
-    /**
-     * Releases the version provided. Returns <tt>true</tt> if the release was successful.
-     */
-    boolean close(long version) {
-        synchronized (mutex) {
-            SnapshotDeletionPolicy.SnapshotHolder holder = snapshots.get(version);
-            if (holder == null) {
-                return false;
-            }
-            if (holder.counter <= 0) {
-                snapshots.remove(version);
-                return false;
-            }
-            if (--holder.counter == 0) {
-                snapshots.remove(version);
-            }
-            return true;
-        }
-    }
-
-    /**
-     * A class that wraps an {@link SnapshotIndexCommit} and makes sure that release will only
-     * be called once on it.
-     */
-    private static class OneTimeReleaseSnapshotIndexCommit extends SnapshotIndexCommit {
-        private volatile boolean released = false;
-
-        OneTimeReleaseSnapshotIndexCommit(SnapshotDeletionPolicy deletionPolicy, IndexCommit cp) throws IOException {
-            super(deletionPolicy, cp);
-        }
-
-        @Override
-        public void close() {
-            if (released) {
-                return;
-            }
-            released = true;
-            ((SnapshotIndexCommit) delegate).close();
-        }
-    }
-
-    private static class SnapshotHolder {
-        int counter;
-
-        private SnapshotHolder(int counter) {
-            this.counter = counter;
-        }
-    }
-
-    private List<SnapshotIndexCommit> wrapCommits(List<? extends IndexCommit> commits) throws IOException {
-        final int count = commits.size();
-        List<SnapshotIndexCommit> snapshotCommits = new ArrayList<>(count);
-        for (int i = 0; i < count; i++)
-            snapshotCommits.add(new SnapshotIndexCommit(this, commits.get(i)));
-        return snapshotCommits;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommit.java b/core/src/main/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommit.java
deleted file mode 100644
index d598d53..0000000
--- a/core/src/main/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommit.java
+++ /dev/null
@@ -1,74 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.deletionpolicy;
-
-import org.apache.lucene.index.IndexCommit;
-import org.elasticsearch.common.lease.Releasable;
-import org.elasticsearch.common.lucene.IndexCommitDelegate;
-
-import java.io.IOException;
-import java.util.ArrayList;
-
-/**
- * A snapshot index commit point. While this is held and {@link #close()}
- * was not called, no files will be deleted that relates to this commit point
- * ({@link #getFileNames()}).
- *
- *
- */
-public class SnapshotIndexCommit extends IndexCommitDelegate implements Releasable {
-
-    private final SnapshotDeletionPolicy deletionPolicy;
-
-    private final String[] files;
-
-    SnapshotIndexCommit(SnapshotDeletionPolicy deletionPolicy, IndexCommit cp) throws IOException {
-        super(cp);
-        this.deletionPolicy = deletionPolicy;
-        ArrayList<String> tmpFiles = new ArrayList<>();
-        for (String o : cp.getFileNames()) {
-            tmpFiles.add(o);
-        }
-        files = tmpFiles.toArray(new String[tmpFiles.size()]);
-    }
-
-    public String[] getFiles() {
-        return files;
-    }
-
-    /**
-     * Releases the current snapshot.
-     */
-    @Override
-    public void close() {
-        deletionPolicy.close(getGeneration());
-    }
-
-    /**
-     * Override the delete operation, and only actually delete it if it
-     * is not held by the {@link SnapshotDeletionPolicy}.
-     */
-    @Override
-    public void delete() {
-        if (!deletionPolicy.isHeld(getGeneration())) {
-            delegate.delete();
-        }
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommits.java b/core/src/main/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommits.java
deleted file mode 100644
index 92e7dbe..0000000
--- a/core/src/main/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommits.java
+++ /dev/null
@@ -1,55 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.deletionpolicy;
-
-import org.elasticsearch.common.lease.Releasable;
-import org.elasticsearch.common.lease.Releasables;
-
-import java.util.Iterator;
-import java.util.List;
-
-/**
- * Represents a snapshot view of several commits. Provides a way to iterate over
- * them as well as a simple method to release all of them.
- *
- *
- */
-public class SnapshotIndexCommits implements Iterable<SnapshotIndexCommit>, Releasable {
-
-    private final List<SnapshotIndexCommit> commits;
-
-    public SnapshotIndexCommits(List<SnapshotIndexCommit> commits) {
-        this.commits = commits;
-    }
-
-    public int size() {
-        return commits.size();
-    }
-
-    @Override
-    public Iterator<SnapshotIndexCommit> iterator() {
-        return commits.iterator();
-    }
-
-    @Override
-    public void close() {
-        Releasables.close(commits);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/engine/Engine.java b/core/src/main/java/org/elasticsearch/index/engine/Engine.java
index 0c66b51..2c1e855 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/Engine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/Engine.java
@@ -19,17 +19,7 @@
 
 package org.elasticsearch.index.engine;
 
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.FilterLeafReader;
-import org.apache.lucene.index.IndexCommit;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.SegmentCommitInfo;
-import org.apache.lucene.index.SegmentInfos;
-import org.apache.lucene.index.SegmentReader;
-import org.apache.lucene.index.Term;
+import org.apache.lucene.index.*;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.SearcherManager;
@@ -51,8 +41,6 @@ import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.lucene.uid.Versions;
 import org.elasticsearch.common.util.concurrent.ReleasableLock;
 import org.elasticsearch.index.VersionType;
-import org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy;
-import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.mapper.ParseContext.Document;
 import org.elasticsearch.index.mapper.ParsedDocument;
 import org.elasticsearch.index.mapper.Uid;
@@ -516,7 +504,7 @@ public abstract class Engine implements Closeable {
      *
      * @param flushFirst indicates whether the engine should flush before returning the snapshot
      */
-    public abstract SnapshotIndexCommit snapshotIndex(boolean flushFirst) throws EngineException;
+    public abstract IndexCommit snapshotIndex(boolean flushFirst) throws EngineException;
 
     /**
      * fail engine due to some error. the engine will also be closed.
diff --git a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
index d180979..04eba9f 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
@@ -21,6 +21,7 @@ package org.elasticsearch.index.engine;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.index.MergePolicy;
+import org.apache.lucene.index.SnapshotDeletionPolicy;
 import org.apache.lucene.search.QueryCache;
 import org.apache.lucene.search.QueryCachingPolicy;
 import org.apache.lucene.search.similarities.Similarity;
@@ -30,7 +31,6 @@ import org.elasticsearch.common.unit.ByteSizeUnit;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.index.codec.CodecService;
-import org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy;
 import org.elasticsearch.index.indexing.ShardIndexingService;
 import org.elasticsearch.index.shard.MergeSchedulerConfig;
 import org.elasticsearch.index.shard.ShardId;
@@ -305,7 +305,7 @@ public final class EngineConfig {
     }
 
     /**
-     * Returns a {@link org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy} used in the engines
+     * Returns a {@link SnapshotDeletionPolicy} used in the engines
      * {@link org.apache.lucene.index.IndexWriter}.
      */
     public SnapshotDeletionPolicy getDeletionPolicy() {
diff --git a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
index 773979d..72c8a6d 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
@@ -19,19 +19,8 @@
 
 package org.elasticsearch.index.engine;
 
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.*;
 import org.apache.lucene.index.IndexWriter.IndexReaderWarmer;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.LiveIndexWriterConfig;
-import org.apache.lucene.index.MergePolicy;
-import org.apache.lucene.index.MultiReader;
-import org.apache.lucene.index.SegmentCommitInfo;
-import org.apache.lucene.index.SegmentInfos;
-import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.IndexSearcher;
@@ -59,7 +48,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.util.concurrent.AbstractRunnable;
 import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;
 import org.elasticsearch.common.util.concurrent.ReleasableLock;
-import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.indexing.ShardIndexingService;
 import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.merge.MergeStats;
@@ -885,7 +873,7 @@ public class InternalEngine extends Engine {
     }
 
     @Override
-    public SnapshotIndexCommit snapshotIndex(final boolean flushFirst) throws EngineException {
+    public IndexCommit snapshotIndex(final boolean flushFirst) throws EngineException {
         // we have to flush outside of the readlock otherwise we might have a problem upgrading
         // the to a write lock when we fail the engine in this operation
         if (flushFirst) {
diff --git a/core/src/main/java/org/elasticsearch/index/engine/ShadowEngine.java b/core/src/main/java/org/elasticsearch/index/engine/ShadowEngine.java
index f89b9ce..f589b28 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/ShadowEngine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/ShadowEngine.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.index.engine;
 
 import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.IndexCommit;
 import org.apache.lucene.index.SegmentInfos;
 import org.apache.lucene.search.SearcherFactory;
 import org.apache.lucene.search.SearcherManager;
@@ -29,7 +30,6 @@ import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.lucene.index.ElasticsearchDirectoryReader;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.concurrent.ReleasableLock;
-import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.translog.Translog;
 
 import java.io.IOException;
@@ -209,10 +209,12 @@ public class ShadowEngine extends Engine {
     }
 
     @Override
-    public SnapshotIndexCommit snapshotIndex(boolean flushFirst) throws EngineException {
+    public IndexCommit snapshotIndex(boolean flushFirst) throws EngineException {
         throw new UnsupportedOperationException("Can not take snapshot from a shadow engine");
     }
 
+
+
     @Override
     protected SearcherManager getSearcherManager() {
         return searcherManager;
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/plain/AbstractAtomicParentChildFieldData.java b/core/src/main/java/org/elasticsearch/index/fielddata/plain/AbstractAtomicParentChildFieldData.java
index 1a801d7..f1c64dc 100644
--- a/core/src/main/java/org/elasticsearch/index/fielddata/plain/AbstractAtomicParentChildFieldData.java
+++ b/core/src/main/java/org/elasticsearch/index/fielddata/plain/AbstractAtomicParentChildFieldData.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.index.fielddata.plain;
 
+import com.google.common.collect.ImmutableSet;
+
 import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.util.Accountable;
@@ -32,8 +34,6 @@ import java.util.Collection;
 import java.util.Collections;
 import java.util.Set;
 
-import static java.util.Collections.emptySet;
-
 
 /**
  */
@@ -92,7 +92,7 @@ abstract class AbstractAtomicParentChildFieldData implements AtomicParentChildFi
             public long ramBytesUsed() {
                 return 0;
             }
-
+            
             @Override
             public Collection<Accountable> getChildResources() {
                 return Collections.emptyList();
@@ -109,7 +109,7 @@ abstract class AbstractAtomicParentChildFieldData implements AtomicParentChildFi
 
             @Override
             public Set<String> types() {
-                return emptySet();
+                return ImmutableSet.of();
             }
         };
     }
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/plain/DocValuesIndexFieldData.java b/core/src/main/java/org/elasticsearch/index/fielddata/plain/DocValuesIndexFieldData.java
index d7329be..97fb3e5 100644
--- a/core/src/main/java/org/elasticsearch/index/fielddata/plain/DocValuesIndexFieldData.java
+++ b/core/src/main/java/org/elasticsearch/index/fielddata/plain/DocValuesIndexFieldData.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.fielddata.plain;
 
+import com.google.common.collect.ImmutableSet;
 import org.apache.lucene.index.IndexReader;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.logging.ESLogger;
@@ -29,6 +30,7 @@ import org.elasticsearch.index.fielddata.FieldDataType;
 import org.elasticsearch.index.fielddata.IndexFieldData;
 import org.elasticsearch.index.fielddata.IndexFieldDataCache;
 import org.elasticsearch.index.fielddata.IndexNumericFieldData.NumericType;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.MappedFieldType.Names;
 import org.elasticsearch.index.mapper.MapperService;
@@ -40,9 +42,6 @@ import org.elasticsearch.indices.breaker.CircuitBreakerService;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
-
 /** {@link IndexFieldData} impl based on Lucene's doc values. Caching is done on the Lucene side. */
 public abstract class DocValuesIndexFieldData {
 
@@ -80,7 +79,9 @@ public abstract class DocValuesIndexFieldData {
     }
 
     public static class Builder implements IndexFieldData.Builder {
-        private static final Set<String> BINARY_INDEX_FIELD_NAMES = unmodifiableSet(newHashSet(UidFieldMapper.NAME, IdFieldMapper.NAME));
+
+        private static final Set<String> BINARY_INDEX_FIELD_NAMES = ImmutableSet.of(UidFieldMapper.NAME, IdFieldMapper.NAME);
+        private static final Set<String> NUMERIC_INDEX_FIELD_NAMES = ImmutableSet.of(TimestampFieldMapper.NAME);
 
         private NumericType numericType;
 
diff --git a/core/src/main/java/org/elasticsearch/index/fieldvisitor/FieldsVisitor.java b/core/src/main/java/org/elasticsearch/index/fieldvisitor/FieldsVisitor.java
index fa4b587..31b0a08 100644
--- a/core/src/main/java/org/elasticsearch/index/fieldvisitor/FieldsVisitor.java
+++ b/core/src/main/java/org/elasticsearch/index/fieldvisitor/FieldsVisitor.java
@@ -19,10 +19,9 @@
 package org.elasticsearch.index.fieldvisitor;
 
 import com.google.common.collect.ImmutableMap;
-
+import com.google.common.collect.ImmutableSet;
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.StoredFieldVisitor;
-import org.apache.lucene.index.StoredFieldVisitor;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
@@ -47,19 +46,20 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
+import org.apache.lucene.index.StoredFieldVisitor;
 
 /**
  * Base {@link StoredFieldVisitor} that retrieves all non-redundant metadata.
  */
 public class FieldsVisitor extends StoredFieldVisitor {
-    private static final Set<String> BASE_REQUIRED_FIELDS = unmodifiableSet(newHashSet(
+
+    private static final Set<String> BASE_REQUIRED_FIELDS = ImmutableSet.of(
             UidFieldMapper.NAME,
             TimestampFieldMapper.NAME,
             TTLFieldMapper.NAME,
             RoutingFieldMapper.NAME,
-            ParentFieldMapper.NAME));
+            ParentFieldMapper.NAME
+   );
 
     private final boolean loadSource;
     private final Set<String> requiredFields;
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
index dd31c6e..ecbf60c 100755
--- a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
@@ -21,8 +21,8 @@ package org.elasticsearch.index.mapper;
 
 import com.carrotsearch.hppc.ObjectHashSet;
 import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Iterators;
-
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.DelegatingAnalyzerWrapper;
 import org.apache.lucene.index.IndexOptions;
@@ -64,17 +64,13 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
-import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
-import java.util.Set;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 import java.util.function.Function;
 
-import static java.util.Collections.emptySet;
-import static java.util.Collections.unmodifiableSet;
 import static org.elasticsearch.common.collect.MapBuilder.newMapBuilder;
 
 /**
@@ -120,7 +116,7 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
 
     private volatile ImmutableMap<String, MappedFieldType> unmappedFieldTypes = ImmutableMap.of();
 
-    private volatile Set<String> parentTypes = emptySet();
+    private volatile ImmutableSet<String> parentTypes = ImmutableSet.of();
 
     @Inject
     public MapperService(Index index, @IndexSettings Settings indexSettings, AnalysisService analysisService,
@@ -165,7 +161,6 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
         }
     }
 
-    @Override
     public void close() {
         for (DocumentMapper documentMapper : mappers.values()) {
             documentMapper.close();
@@ -288,10 +283,10 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
                 }
                 mappers = newMapBuilder(mappers).put(mapper.type(), mapper).map();
                 if (mapper.parentFieldMapper().active()) {
-                    Set<String> newParentTypes = new HashSet<>(parentTypes.size() + 1);
-                    newParentTypes.addAll(parentTypes);
-                    newParentTypes.add(mapper.parentFieldMapper().type());
-                    parentTypes = unmodifiableSet(newParentTypes);
+                    ImmutableSet.Builder<String> parentTypesCopy = ImmutableSet.builder();
+                    parentTypesCopy.addAll(parentTypes);
+                    parentTypesCopy.add(mapper.parentFieldMapper().type());
+                    parentTypes = parentTypesCopy.build();
                 }
                 assert assertSerialization(mapper);
                 return mapper;
@@ -599,7 +594,7 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
         return null;
     }
 
-    public Set<String> getParentTypes() {
+    public ImmutableSet<String> getParentTypes() {
         return parentTypes;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
index 683beac..89419d9 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
@@ -22,6 +22,9 @@ package org.elasticsearch.index.shard;
 import java.nio.charset.StandardCharsets;
 import org.apache.lucene.codecs.PostingsFormat;
 import org.apache.lucene.index.CheckIndex;
+import org.apache.lucene.index.IndexCommit;
+import org.apache.lucene.index.KeepOnlyLastCommitDeletionPolicy;
+import org.apache.lucene.index.SnapshotDeletionPolicy;
 import org.apache.lucene.search.QueryCachingPolicy;
 import org.apache.lucene.search.UsageTrackingQueryCachingPolicy;
 import org.apache.lucene.store.AlreadyClosedException;
@@ -65,11 +68,8 @@ import org.elasticsearch.index.cache.bitset.ShardBitsetFilterCache;
 import org.elasticsearch.index.cache.query.QueryCacheStats;
 import org.elasticsearch.index.cache.request.ShardRequestCache;
 import org.elasticsearch.index.codec.CodecService;
-import org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy;
-import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.engine.*;
 import org.elasticsearch.index.fielddata.FieldDataStats;
-import org.elasticsearch.index.fielddata.IndexFieldDataCache;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
 import org.elasticsearch.index.fielddata.ShardFieldData;
 import org.elasticsearch.index.flush.FlushStats;
@@ -206,16 +206,15 @@ public class IndexShard extends AbstractIndexShardComponent {
                       ThreadPool threadPool, MapperService mapperService, IndexQueryParserService queryParserService, IndexCache indexCache, IndexAliasesService indexAliasesService,
                       IndicesQueryCache indicesQueryCache, CodecService codecService,
                       TermVectorsService termVectorsService, IndexFieldDataService indexFieldDataService, IndexService indexService,
-                      @Nullable IndicesWarmer warmer, SnapshotDeletionPolicy deletionPolicy, SimilarityService similarityService, EngineFactory factory,
+                      @Nullable IndicesWarmer warmer, SimilarityService similarityService, EngineFactory factory,
                       ClusterService clusterService, ShardPath path, BigArrays bigArrays, IndexSearcherWrappingService wrappingService) {
         super(shardId, indexSettingsService.getSettings());
         this.codecService = codecService;
         this.warmer = warmer;
-        this.deletionPolicy = deletionPolicy;
+        this.deletionPolicy = new SnapshotDeletionPolicy(new KeepOnlyLastCommitDeletionPolicy());
         this.similarityService = similarityService;
         this.wrappingService = wrappingService;
         Objects.requireNonNull(store, "Store must be provided to the index shard");
-        Objects.requireNonNull(deletionPolicy, "Snapshot deletion policy must be provided to the index shard");
         this.engineFactory = factory;
         this.indicesLifecycle = (InternalIndicesLifecycle) indicesLifecycle;
         this.indexSettingsService = indexSettingsService;
@@ -745,7 +744,13 @@ public class IndexShard extends AbstractIndexShardComponent {
         return luceneVersion == null ? Version.indexCreated(indexSettings).luceneVersion : luceneVersion;
     }
 
-    public SnapshotIndexCommit snapshotIndex(boolean flushFirst) throws EngineException {
+    /**
+     * Creates a new {@link IndexCommit} snapshot form the currently running engine. All resources referenced by this
+     * commit won't be freed until the commit / snapshot is released via {@link #releaseSnapshot(IndexCommit)}.
+     *
+     * @param flushFirst <code>true</code> if the index should first be flushed to disk / a low level lucene commit should be executed
+     */
+    public IndexCommit snapshotIndex(boolean flushFirst) throws EngineException {
         IndexShardState state = this.state; // one time volatile read
         // we allow snapshot on closed index shard, since we want to do one after we close the shard and before we close the engine
         if (state == IndexShardState.STARTED || state == IndexShardState.RELOCATED || state == IndexShardState.CLOSED) {
@@ -755,6 +760,15 @@ public class IndexShard extends AbstractIndexShardComponent {
         }
     }
 
+
+    /**
+     * Releases a snapshot taken from {@link #snapshotIndex(boolean)} this must be called to release the resources
+     * referenced by the given snapshot {@link IndexCommit}.
+     */
+    public void releaseSnapshot(IndexCommit snapshot) throws IOException {
+        deletionPolicy.release(snapshot);
+    }
+
     /**
      * Fails the shard and marks the shard store as corrupted if
      * <code>e</code> is caused by index corruption
diff --git a/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java
index 6c45331..da5cef0 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java
@@ -27,7 +27,6 @@ import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.aliases.IndexAliasesService;
 import org.elasticsearch.index.cache.IndexCache;
 import org.elasticsearch.index.codec.CodecService;
-import org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy;
 import org.elasticsearch.index.engine.IndexSearcherWrappingService;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.engine.EngineConfig;
@@ -35,7 +34,6 @@ import org.elasticsearch.index.engine.EngineFactory;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.merge.MergeStats;
-import org.elasticsearch.index.percolator.stats.ShardPercolateService;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.settings.IndexSettingsService;
 import org.elasticsearch.index.similarity.SimilarityService;
@@ -64,14 +62,14 @@ public final class ShadowIndexShard extends IndexShard {
                             IndexAliasesService indexAliasesService, IndicesQueryCache indicesQueryCache,
                             CodecService codecService, TermVectorsService termVectorsService, IndexFieldDataService indexFieldDataService,
                             IndexService indexService, @Nullable IndicesWarmer warmer,
-                            SnapshotDeletionPolicy deletionPolicy, SimilarityService similarityService,
+                            SimilarityService similarityService,
                             EngineFactory factory, ClusterService clusterService,
                             ShardPath path, BigArrays bigArrays, IndexSearcherWrappingService wrappingService) throws IOException {
         super(shardId, indexSettingsService, indicesLifecycle, store, storeRecoveryService,
                 threadPool, mapperService, queryParserService, indexCache, indexAliasesService,
                 indicesQueryCache, codecService,
                 termVectorsService, indexFieldDataService, indexService,
-                warmer, deletionPolicy, similarityService,
+                warmer, similarityService,
                 factory, clusterService, path, bigArrays, wrappingService);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/snapshots/IndexShardRepository.java b/core/src/main/java/org/elasticsearch/index/snapshots/IndexShardRepository.java
index 8ce487f..ca481e1 100644
--- a/core/src/main/java/org/elasticsearch/index/snapshots/IndexShardRepository.java
+++ b/core/src/main/java/org/elasticsearch/index/snapshots/IndexShardRepository.java
@@ -19,9 +19,9 @@
 
 package org.elasticsearch.index.snapshots;
 
+import org.apache.lucene.index.IndexCommit;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.metadata.SnapshotId;
-import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.indices.recovery.RecoveryState;
 
@@ -47,7 +47,7 @@ public interface IndexShardRepository {
      * @param snapshotIndexCommit commit point
      * @param snapshotStatus      snapshot status
      */
-    void snapshot(SnapshotId snapshotId, ShardId shardId, SnapshotIndexCommit snapshotIndexCommit, IndexShardSnapshotStatus snapshotStatus);
+    void snapshot(SnapshotId snapshotId, ShardId shardId, IndexCommit snapshotIndexCommit, IndexShardSnapshotStatus snapshotStatus);
 
     /**
      * Restores snapshot of the shard.
diff --git a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
index 912be76..c9344d3 100644
--- a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
+++ b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
@@ -19,10 +19,7 @@
 
 package org.elasticsearch.index.snapshots.blobstore;
 
-import org.apache.lucene.index.CorruptIndexException;
-import org.apache.lucene.index.IndexFormatTooNewException;
-import org.apache.lucene.index.IndexFormatTooOldException;
-import org.apache.lucene.index.SegmentInfos;
+import org.apache.lucene.index.*;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
@@ -49,7 +46,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.index.IndexService;
-import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.index.snapshots.*;
 import org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardSnapshot.FileInfo;
@@ -150,12 +146,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
         this.snapshotRateLimiter = snapshotRateLimiter;
         this.restoreRateLimiter = restoreRateLimiter;
         this.rateLimiterListener = rateLimiterListener;
-        this.snapshotThrottleListener = new RateLimitingInputStream.Listener() {
-            @Override
-            public void onPause(long nanos) {
-                rateLimiterListener.onSnapshotPause(nanos);
-            }
-        };
+        this.snapshotThrottleListener = nanos -> rateLimiterListener.onSnapshotPause(nanos);
         this.compress = compress;
         indexShardSnapshotFormat = new ChecksumBlobStoreFormat<>(SNAPSHOT_CODEC, SNAPSHOT_NAME_FORMAT, BlobStoreIndexShardSnapshot.PROTO, parseFieldMatcher, isCompress());
         indexShardSnapshotLegacyFormat = new LegacyBlobStoreFormat<>(LEGACY_SNAPSHOT_NAME_FORMAT, BlobStoreIndexShardSnapshot.PROTO, parseFieldMatcher);
@@ -166,7 +157,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
      * {@inheritDoc}
      */
     @Override
-    public void snapshot(SnapshotId snapshotId, ShardId shardId, SnapshotIndexCommit snapshotIndexCommit, IndexShardSnapshotStatus snapshotStatus) {
+    public void snapshot(SnapshotId snapshotId, ShardId shardId, IndexCommit snapshotIndexCommit, IndexShardSnapshotStatus snapshotStatus) {
         SnapshotContext snapshotContext = new SnapshotContext(snapshotId, shardId, snapshotStatus);
         snapshotStatus.startTime(System.currentTimeMillis());
 
@@ -495,7 +486,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
         public SnapshotContext(SnapshotId snapshotId, ShardId shardId, IndexShardSnapshotStatus snapshotStatus) {
             super(snapshotId, Version.CURRENT, shardId);
             IndexService indexService = indicesService.indexServiceSafe(shardId.getIndex());
-            store = indexService.shardInjectorSafe(shardId.id()).getInstance(Store.class);
+            store = indexService.shard(shardId.id()).store();
             this.snapshotStatus = snapshotStatus;
 
         }
@@ -505,7 +496,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
          *
          * @param snapshotIndexCommit snapshot commit point
          */
-        public void snapshot(SnapshotIndexCommit snapshotIndexCommit) {
+        public void snapshot(IndexCommit snapshotIndexCommit) {
             logger.debug("[{}] [{}] snapshot to [{}] ...", shardId, snapshotId, repositoryName);
             store.incRef();
             try {
@@ -528,12 +519,14 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
                 ArrayList<FileInfo> filesToSnapshot = new ArrayList<>();
                 final Store.MetadataSnapshot metadata;
                 // TODO apparently we don't use the MetadataSnapshot#.recoveryDiff(...) here but we should
+                final Collection<String> fileNames;
                 try {
                     metadata = store.getMetadata(snapshotIndexCommit);
+                    fileNames = snapshotIndexCommit.getFileNames();
                 } catch (IOException e) {
                     throw new IndexShardSnapshotFailedException(shardId, "Failed to get store file metadata", e);
                 }
-                for (String fileName : snapshotIndexCommit.getFiles()) {
+                for (String fileName : fileNames) {
                     if (snapshotStatus.aborted()) {
                         logger.debug("[{}] [{}] Aborted on the file [{}], exiting", shardId, snapshotId, fileName);
                         throw new IndexShardSnapshotFailedException(shardId, "Aborted");
@@ -776,7 +769,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
          */
         public RestoreContext(SnapshotId snapshotId, Version version, ShardId shardId, ShardId snapshotShardId, RecoveryState recoveryState) {
             super(snapshotId, version, shardId, snapshotShardId);
-            store = indicesService.indexServiceSafe(shardId.getIndex()).shardInjectorSafe(shardId.id()).getInstance(Store.class);
+            store = indicesService.indexServiceSafe(shardId.getIndex()).shard(shardId.id()).store();
             this.recoveryState = recoveryState;
         }
 
diff --git a/core/src/main/java/org/elasticsearch/indices/IndicesService.java b/core/src/main/java/org/elasticsearch/indices/IndicesService.java
index 3b24544..9cb8ec8 100644
--- a/core/src/main/java/org/elasticsearch/indices/IndicesService.java
+++ b/core/src/main/java/org/elasticsearch/indices/IndicesService.java
@@ -20,7 +20,7 @@
 package org.elasticsearch.indices;
 
 import com.google.common.collect.ImmutableMap;
-
+import com.google.common.collect.ImmutableSet;
 import org.apache.lucene.store.LockObtainFailedException;
 import org.apache.lucene.util.CollectionUtil;
 import org.apache.lucene.util.IOUtils;
@@ -87,15 +87,14 @@ import java.io.IOException;
 import java.nio.file.Files;
 import java.util.ArrayList;
 import java.util.HashMap;
-import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
-import java.util.Set;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
 import java.util.stream.Stream;
 
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
@@ -163,11 +162,11 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
 
     @Override
     protected void doStop() {
-        ExecutorService indicesStopExecutor = Executors.newFixedThreadPool(5, EsExecutors.daemonThreadFactory("indices_shutdown"));
-
-        // Copy indices because we modify it asynchronously in the body of the loop
-        Set<String> indices = new HashSet<>(this.indices.keySet());
+        ImmutableSet<String> indices = ImmutableSet.copyOf(this.indices.keySet());
         final CountDownLatch latch = new CountDownLatch(indices.size());
+
+        final ExecutorService indicesStopExecutor = Executors.newFixedThreadPool(5, EsExecutors.daemonThreadFactory("indices_shutdown"));
+
         for (final String index : indices) {
             indicesStopExecutor.execute(new Runnable() {
                 @Override
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
index 102fa98..65b5886 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.indices.recovery;
 
 import org.apache.lucene.index.CorruptIndexException;
+import org.apache.lucene.index.IndexCommit;
 import org.apache.lucene.index.IndexFormatTooNewException;
 import org.apache.lucene.index.IndexFormatTooOldException;
 import org.apache.lucene.store.IOContext;
@@ -33,14 +34,12 @@ import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.StopWatch;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.compress.CompressorFactory;
-import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.util.CancellableThreads;
 import org.elasticsearch.common.util.CancellableThreads.Interruptable;
 import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.common.util.concurrent.AbstractRunnable;
-import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.engine.RecoveryEngineException;
 import org.elasticsearch.index.shard.IllegalIndexShardStateException;
@@ -122,7 +121,7 @@ public class RecoverySourceHandler {
         assert engine.getTranslog() != null : "translog must not be null";
         try (Translog.View translogView = engine.getTranslog().newView()) {
             logger.trace("captured translog id [{}] for recovery", translogView.minTranslogGeneration());
-            final SnapshotIndexCommit phase1Snapshot;
+            final IndexCommit phase1Snapshot;
             try {
                 phase1Snapshot = shard.snapshotIndex(false);
             } catch (Throwable e) {
@@ -135,7 +134,11 @@ public class RecoverySourceHandler {
             } catch (Throwable e) {
                 throw new RecoveryEngineException(shard.shardId(), 1, "phase1 failed", e);
             } finally {
-                Releasables.closeWhileHandlingException(phase1Snapshot);
+                try {
+                    shard.releaseSnapshot(phase1Snapshot);
+                } catch (IOException ex) {
+                    logger.warn("releasing snapshot caused exception", ex);
+                }
             }
 
             logger.trace("snapshot translog for recovery. current size is [{}]", translogView.totalOperations());
@@ -151,7 +154,7 @@ public class RecoverySourceHandler {
     }
 
     /**
-     * Perform phase1 of the recovery operations. Once this {@link SnapshotIndexCommit}
+     * Perform phase1 of the recovery operations. Once this {@link IndexCommit}
      * snapshot has been performed no commit operations (files being fsync'd)
      * are effectively allowed on this index until all recovery phases are done
      * <p>
@@ -159,7 +162,7 @@ public class RecoverySourceHandler {
      * segments that are missing. Only segments that have the same size and
      * checksum can be reused
      */
-    public void phase1(final SnapshotIndexCommit snapshot, final Translog.View translogView) {
+    public void phase1(final IndexCommit snapshot, final Translog.View translogView) {
         cancellableThreads.checkForCancel();
         // Total size of segment files that are recovered
         long totalSize = 0;
@@ -176,7 +179,7 @@ public class RecoverySourceHandler {
                 shard.engine().failEngine("recovery", ex);
                 throw ex;
             }
-            for (String name : snapshot.getFiles()) {
+            for (String name : snapshot.getFileNames()) {
                 final StoreFileMetaData md = recoverySourceMetadata.get(name);
                 if (md == null) {
                     logger.info("Snapshot differs from actual index for file: {} meta: {}", name, recoverySourceMetadata.asMap());
diff --git a/core/src/main/java/org/elasticsearch/monitor/jvm/DeadlockAnalyzer.java b/core/src/main/java/org/elasticsearch/monitor/jvm/DeadlockAnalyzer.java
index 97b9730..58e7189 100644
--- a/core/src/main/java/org/elasticsearch/monitor/jvm/DeadlockAnalyzer.java
+++ b/core/src/main/java/org/elasticsearch/monitor/jvm/DeadlockAnalyzer.java
@@ -20,17 +20,12 @@
 package org.elasticsearch.monitor.jvm;
 
 import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.ImmutableSet;
 
 import java.lang.management.ManagementFactory;
 import java.lang.management.ThreadInfo;
 import java.lang.management.ThreadMXBean;
-import java.util.Arrays;
-import java.util.HashSet;
-import java.util.LinkedHashSet;
-import java.util.Map;
-import java.util.Set;
-
-import static java.util.Collections.unmodifiableSet;
+import java.util.*;
 
 /**
  *
@@ -122,15 +117,17 @@ public class DeadlockAnalyzer {
         return threadInfoMap.build();
     }
 
+
     public static class Deadlock {
+
         private final ThreadInfo members[];
         private final String description;
-        private final Set<Long> memberIds;
+        private final ImmutableSet<Long> memberIds;
 
         public Deadlock(ThreadInfo[] members) {
             this.members = members;
 
-            Set<Long> builder = new HashSet<>();
+            ImmutableSet.Builder<Long> builder = ImmutableSet.builder();
             StringBuilder sb = new StringBuilder();
             for (int x = 0; x < members.length; x++) {
                 ThreadInfo ti = members[x];
@@ -142,7 +139,7 @@ public class DeadlockAnalyzer {
                 builder.add(ti.getThreadId());
             }
             this.description = sb.toString();
-            this.memberIds = unmodifiableSet(builder);
+            this.memberIds = builder.build();
         }
 
         public ThreadInfo[] members() {
diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java
index e5b4b0e..9d3aac4 100644
--- a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java
+++ b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java
@@ -19,8 +19,8 @@
 
 package org.elasticsearch.plugins;
 
+import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Iterators;
-
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.Build;
 import org.elasticsearch.ElasticsearchCorruptionException;
@@ -41,29 +41,17 @@ import java.io.IOException;
 import java.io.OutputStream;
 import java.net.MalformedURLException;
 import java.net.URL;
-import java.nio.file.DirectoryStream;
-import java.nio.file.FileVisitResult;
-import java.nio.file.Files;
-import java.nio.file.Path;
-import java.nio.file.SimpleFileVisitor;
+import java.nio.file.*;
 import java.nio.file.attribute.BasicFileAttributes;
 import java.nio.file.attribute.PosixFileAttributeView;
 import java.nio.file.attribute.PosixFilePermission;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Locale;
-import java.util.Random;
-import java.util.Set;
+import java.util.*;
 import java.util.zip.ZipEntry;
 import java.util.zip.ZipInputStream;
 
-import static java.util.Collections.unmodifiableSet;
 import static org.elasticsearch.common.Strings.hasLength;
 import static org.elasticsearch.common.cli.Terminal.Verbosity.VERBOSE;
 import static org.elasticsearch.common.io.FileSystemUtils.moveFilesWithoutOverwriting;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
 
 /**
  *
@@ -76,33 +64,35 @@ public class PluginManager {
         DEFAULT, SILENT, VERBOSE
     }
 
-    private static final Set<String> BLACKLIST = unmodifiableSet(newHashSet(
-            "elasticsearch",
-            "elasticsearch.bat",
-            "elasticsearch.in.sh",
-            "plugin",
-            "plugin.bat",
-            "service.bat"));
-
-    static final Set<String> OFFICIAL_PLUGINS = unmodifiableSet(newHashSet(
-            "analysis-icu",
-            "analysis-kuromoji",
-            "analysis-phonetic",
-            "analysis-smartcn",
-            "analysis-stempel",
-            "cloud-gce",
-            "delete-by-query",
-            "discovery-azure",
-            "discovery-ec2",
-            "discovery-multicast",
-            "lang-expression",
-            "lang-javascript",
-            "lang-python",
-            "mapper-murmur3",
-            "mapper-size",
-            "repository-azure",
-            "repository-s3",
-            "store-smb"));
+    private static final ImmutableSet<String> BLACKLIST = ImmutableSet.<String>builder()
+            .add("elasticsearch",
+                    "elasticsearch.bat",
+                    "elasticsearch.in.sh",
+                    "plugin",
+                    "plugin.bat",
+                    "service.bat").build();
+
+    static final ImmutableSet<String> OFFICIAL_PLUGINS = ImmutableSet.<String>builder()
+            .add(
+                    "analysis-icu",
+                    "analysis-kuromoji",
+                    "analysis-phonetic",
+                    "analysis-smartcn",
+                    "analysis-stempel",
+                    "cloud-gce",
+                    "delete-by-query",
+                    "discovery-azure",
+                    "discovery-ec2",
+                    "discovery-multicast",
+                    "lang-expression",
+                    "lang-javascript",
+                    "lang-python",
+                    "mapper-murmur3",
+                    "mapper-size",
+                    "repository-azure",
+                    "repository-s3",
+                    "store-smb"
+            ).build();
 
     private final Environment environment;
     private URL url;
diff --git a/core/src/main/java/org/elasticsearch/repositories/Repository.java b/core/src/main/java/org/elasticsearch/repositories/Repository.java
index a766c3a..294b36d 100644
--- a/core/src/main/java/org/elasticsearch/repositories/Repository.java
+++ b/core/src/main/java/org/elasticsearch/repositories/Repository.java
@@ -18,9 +18,12 @@
  */
 package org.elasticsearch.repositories;
 
+import org.apache.lucene.index.IndexCommit;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.metadata.SnapshotId;
 import org.elasticsearch.common.component.LifecycleComponent;
+import org.elasticsearch.index.shard.ShardId;
+import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;
 import org.elasticsearch.snapshots.Snapshot;
 import org.elasticsearch.snapshots.SnapshotShardFailure;
 
@@ -38,7 +41,7 @@ import java.util.List;
  * <ul>
  * <li>Master calls {@link #initializeSnapshot(org.elasticsearch.cluster.metadata.SnapshotId, List, org.elasticsearch.cluster.metadata.MetaData)}
  * with list of indices that will be included into the snapshot</li>
- * <li>Data nodes call {@link org.elasticsearch.index.snapshots.IndexShardRepository#snapshot(org.elasticsearch.cluster.metadata.SnapshotId, org.elasticsearch.index.shard.ShardId, org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit, org.elasticsearch.index.snapshots.IndexShardSnapshotStatus)} for each shard</li>
+ * <li>Data nodes call {@link org.elasticsearch.index.snapshots.IndexShardRepository#snapshot(SnapshotId, ShardId, IndexCommit, IndexShardSnapshotStatus)} for each shard</li>
  * <li>When all shard calls return master calls {@link #finalizeSnapshot}
  * with possible list of failures</li>
  * </ul>
diff --git a/core/src/main/java/org/elasticsearch/rest/RestController.java b/core/src/main/java/org/elasticsearch/rest/RestController.java
index d0a46d2..cc6c09a 100644
--- a/core/src/main/java/org/elasticsearch/rest/RestController.java
+++ b/core/src/main/java/org/elasticsearch/rest/RestController.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.rest;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.Inject;
@@ -29,21 +30,18 @@ import org.elasticsearch.rest.support.RestUtils;
 
 import java.io.IOException;
 import java.util.Arrays;
-import java.util.Collections;
 import java.util.Comparator;
-import java.util.HashSet;
-import java.util.Set;
 import java.util.concurrent.atomic.AtomicInteger;
 
-import static java.util.Collections.emptySet;
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.rest.RestStatus.BAD_REQUEST;
-import static org.elasticsearch.rest.RestStatus.OK;
+import static org.elasticsearch.rest.RestStatus.*;
 
 /**
  *
  */
 public class RestController extends AbstractLifecycleComponent<RestController> {
+
+    private ImmutableSet<String> relevantHeaders = ImmutableSet.of();
+
     private final PathTrie<RestHandler> getHandlers = new PathTrie<>(RestUtils.REST_DECODER);
     private final PathTrie<RestHandler> postHandlers = new PathTrie<>(RestUtils.REST_DECODER);
     private final PathTrie<RestHandler> putHandlers = new PathTrie<>(RestUtils.REST_DECODER);
@@ -53,8 +51,6 @@ public class RestController extends AbstractLifecycleComponent<RestController> {
 
     private final RestHandlerFilter handlerFilter = new RestHandlerFilter();
 
-    private Set<String> relevantHeaders = emptySet();
-
     // non volatile since the assumption is that pre processors are registered on startup
     private RestFilter[] filters = new RestFilter[0];
 
@@ -85,10 +81,7 @@ public class RestController extends AbstractLifecycleComponent<RestController> {
      * By default no headers get copied but it is possible to extend this behaviour via plugins by calling this method.
      */
     public synchronized void registerRelevantHeaders(String... headers) {
-        Set<String> newRelevantHeaders = new HashSet<>(relevantHeaders.size() + headers.length);
-        newRelevantHeaders.addAll(relevantHeaders);
-        Collections.addAll(newRelevantHeaders, headers);
-        relevantHeaders = unmodifiableSet(newRelevantHeaders);
+        relevantHeaders = new ImmutableSet.Builder<String>().addAll(relevantHeaders).add(headers).build();
     }
 
     /**
@@ -96,7 +89,7 @@ public class RestController extends AbstractLifecycleComponent<RestController> {
      * its corresponding {@link org.elasticsearch.transport.TransportRequest}(s).
      * By default no headers get copied but it is possible to extend this behaviour via plugins by calling {@link #registerRelevantHeaders(String...)}.
      */
-    public Set<String> relevantHeaders() {
+    public ImmutableSet<String> relevantHeaders() {
         return relevantHeaders;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java
index 005b30e..4006143 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/settings/RestUpdateSettingsAction.java
@@ -26,31 +26,23 @@ import org.elasticsearch.client.Client;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.rest.BaseRestHandler;
-import org.elasticsearch.rest.RestChannel;
-import org.elasticsearch.rest.RestController;
-import org.elasticsearch.rest.RestRequest;
+import org.elasticsearch.rest.*;
 import org.elasticsearch.rest.action.support.AcknowledgedRestListener;
 
 import java.util.Map;
-import java.util.Set;
 
-import static java.util.Collections.unmodifiableSet;
 import static org.elasticsearch.client.Requests.updateSettingsRequest;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
+import com.google.common.collect.ImmutableSet;
 
 /**
  *
  */
 public class RestUpdateSettingsAction extends BaseRestHandler {
-    private static final Set<String> VALUES_TO_EXCLUDE = unmodifiableSet(newHashSet(
-            "pretty",
-            "timeout",
-            "master_timeout",
-            "index",
-            "expand_wildcards",
-            "ignore_unavailable",
-            "allow_no_indices"));
+
+    private static final ImmutableSet<String> VALUES_TO_EXCLUDE = ImmutableSet.<String>builder()
+            .add("pretty").add("timeout").add("master_timeout").add("index")
+            .add("expand_wildcards").add("ignore_unavailable").add("allow_no_indices")
+            .build();
 
     @Inject
     public RestUpdateSettingsAction(Settings settings, RestController controller, Client client) {
diff --git a/core/src/main/java/org/elasticsearch/script/ScriptContextRegistry.java b/core/src/main/java/org/elasticsearch/script/ScriptContextRegistry.java
index bf2b667..acd050d 100644
--- a/core/src/main/java/org/elasticsearch/script/ScriptContextRegistry.java
+++ b/core/src/main/java/org/elasticsearch/script/ScriptContextRegistry.java
@@ -21,14 +21,11 @@ package org.elasticsearch.script;
 
 import com.google.common.collect.ImmutableCollection;
 import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.ImmutableSet;
 
 import java.util.Collection;
 import java.util.HashMap;
-import java.util.HashSet;
 import java.util.Map;
-import java.util.Set;
-
-import static java.util.Collections.unmodifiableSet;
 
 /**
  * Registry for operations that use scripts as part of their execution. Can be standard operations of custom defined ones (via plugin).
@@ -36,7 +33,7 @@ import static java.util.Collections.unmodifiableSet;
  * Scripts can be enabled/disabled via fine-grained settings for each single registered operation.
  */
 public final class ScriptContextRegistry {
-    static final Set<String> RESERVED_SCRIPT_CONTEXTS = reservedScriptContexts();
+    static final ImmutableSet<String> RESERVED_SCRIPT_CONTEXTS = reservedScriptContexts();
 
     private final ImmutableMap<String, ScriptContext> scriptContexts;
 
@@ -79,16 +76,15 @@ public final class ScriptContextRegistry {
         }
     }
 
-    private static Set<String> reservedScriptContexts() {
-        Set<String> reserved = new HashSet<>(ScriptService.ScriptType.values().length + ScriptContext.Standard.values().length);
+    private static ImmutableSet<String> reservedScriptContexts() {
+        ImmutableSet.Builder<String> builder = ImmutableSet.builder();
         for (ScriptService.ScriptType scriptType : ScriptService.ScriptType.values()) {
-            reserved.add(scriptType.toString());
+            builder.add(scriptType.toString());
         }
         for (ScriptContext.Standard scriptContext : ScriptContext.Standard.values()) {
-            reserved.add(scriptContext.getKey());
+            builder.add(scriptContext.getKey());
         }
-        reserved.add("script");
-        reserved.add("engine");
-        return unmodifiableSet(reserved);
+        builder.add("script").add("engine");
+        return builder.build();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/HighlightUtils.java b/core/src/main/java/org/elasticsearch/search/highlight/HighlightUtils.java
index db64af8..b26be72 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/HighlightUtils.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/HighlightUtils.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.search.highlight;
 
+import com.google.common.collect.ImmutableSet;
 import org.apache.lucene.search.highlight.DefaultEncoder;
 import org.apache.lucene.search.highlight.Encoder;
 import org.apache.lucene.search.highlight.SimpleHTMLEncoder;
@@ -31,8 +32,6 @@ import java.io.IOException;
 import java.util.Collections;
 import java.util.List;
 
-import static java.util.Collections.singleton;
-
 public final class HighlightUtils {
 
     //U+2029 PARAGRAPH SEPARATOR (PS): each value holds a discrete passage for highlighting (postings highlighter)
@@ -48,7 +47,7 @@ public final class HighlightUtils {
         boolean forceSource = searchContext.highlight().forceSource(field);
         List<Object> textsToHighlight;
         if (!forceSource && mapper.fieldType().stored()) {
-            CustomFieldsVisitor fieldVisitor = new CustomFieldsVisitor(singleton(mapper.fieldType().names().indexName()), false);
+            CustomFieldsVisitor fieldVisitor = new CustomFieldsVisitor(ImmutableSet.of(mapper.fieldType().names().indexName()), false);
             hitContext.reader().document(hitContext.docId(), fieldVisitor);
             textsToHighlight = fieldVisitor.fields().get(mapper.fieldType().names().indexName());
             if (textsToHighlight == null) {
diff --git a/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java b/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
index 0d20760..1b49da5 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
@@ -23,31 +23,15 @@ import com.carrotsearch.hppc.IntSet;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
 import com.google.common.collect.ImmutableMap;
-
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.IndicesOptions;
-import org.elasticsearch.cluster.ClusterChangedEvent;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.ClusterStateListener;
-import org.elasticsearch.cluster.ClusterStateUpdateTask;
-import org.elasticsearch.cluster.RestoreInProgress;
+import org.elasticsearch.cluster.*;
 import org.elasticsearch.cluster.RestoreInProgress.ShardRestoreStatus;
 import org.elasticsearch.cluster.block.ClusterBlocks;
-import org.elasticsearch.cluster.metadata.AliasMetaData;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.metadata.IndexTemplateMetaData;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.cluster.metadata.MetaDataCreateIndexService;
-import org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService;
-import org.elasticsearch.cluster.metadata.RepositoriesMetaData;
-import org.elasticsearch.cluster.metadata.SnapshotId;
-import org.elasticsearch.cluster.routing.IndexRoutingTable;
-import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
-import org.elasticsearch.cluster.routing.RestoreSource;
-import org.elasticsearch.cluster.routing.RoutingTable;
-import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.cluster.metadata.*;
+import org.elasticsearch.cluster.routing.*;
 import org.elasticsearch.cluster.routing.allocation.AllocationService;
 import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
 import org.elasticsearch.cluster.settings.ClusterDynamicSettings;
@@ -69,39 +53,16 @@ import org.elasticsearch.index.shard.StoreRecoveryService;
 import org.elasticsearch.repositories.RepositoriesService;
 import org.elasticsearch.repositories.Repository;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.EmptyTransportResponseHandler;
-import org.elasticsearch.transport.TransportChannel;
-import org.elasticsearch.transport.TransportRequest;
-import org.elasticsearch.transport.TransportRequestHandler;
-import org.elasticsearch.transport.TransportResponse;
-import org.elasticsearch.transport.TransportService;
+import org.elasticsearch.transport.*;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 import java.util.Map.Entry;
-import java.util.Set;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.CopyOnWriteArrayList;
 
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_AUTO_EXPAND_REPLICAS;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_CREATION_DATE;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_INDEX_UUID;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_LEGACY_ROUTING_HASH_FUNCTION;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_LEGACY_ROUTING_USE_TYPE;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_VERSION_CREATED;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_VERSION_MINIMUM_COMPATIBLE;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_VERSION_UPGRADED;
+import static org.elasticsearch.cluster.metadata.IndexMetaData.*;
 import static org.elasticsearch.cluster.metadata.MetaDataIndexStateService.INDEX_CLOSED_BLOCK;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
 
 /**
  * Service responsible for restoring snapshots
@@ -129,26 +90,22 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
 
     public static final String UPDATE_RESTORE_ACTION_NAME = "internal:cluster/snapshot/update_restore";
 
-    private static final Set<String> UNMODIFIABLE_SETTINGS = unmodifiableSet(newHashSet(
+    private static final ImmutableSet<String> UNMODIFIABLE_SETTINGS = ImmutableSet.of(
             SETTING_NUMBER_OF_SHARDS,
             SETTING_VERSION_CREATED,
             SETTING_LEGACY_ROUTING_HASH_FUNCTION,
             SETTING_LEGACY_ROUTING_USE_TYPE,
             SETTING_INDEX_UUID,
-            SETTING_CREATION_DATE));
+            SETTING_CREATION_DATE);
 
     // It's OK to change some settings, but we shouldn't allow simply removing them
-    private static final Set<String> UNREMOVABLE_SETTINGS;
-
-    static {
-        Set<String> unremovable = new HashSet<>(UNMODIFIABLE_SETTINGS.size() + 4);
-        unremovable.addAll(UNMODIFIABLE_SETTINGS);
-        unremovable.add(SETTING_NUMBER_OF_REPLICAS);
-        unremovable.add(SETTING_AUTO_EXPAND_REPLICAS);
-        unremovable.add(SETTING_VERSION_UPGRADED);
-        unremovable.add(SETTING_VERSION_MINIMUM_COMPATIBLE);
-        UNREMOVABLE_SETTINGS = unmodifiableSet(unremovable);
-    }
+    private static final ImmutableSet<String> UNREMOVABLE_SETTINGS = ImmutableSet.<String>builder()
+            .addAll(UNMODIFIABLE_SETTINGS)
+            .add(SETTING_NUMBER_OF_REPLICAS)
+            .add(SETTING_AUTO_EXPAND_REPLICAS)
+            .add(SETTING_VERSION_UPGRADED)
+            .add(SETTING_VERSION_MINIMUM_COMPATIBLE)
+            .build();
 
     private final ClusterService clusterService;
 
diff --git a/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java b/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
index 3502916..3850888 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.snapshots;
 
 import com.google.common.collect.ImmutableMap;
+import org.apache.lucene.index.IndexCommit;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.cluster.ClusterChangedEvent;
 import org.elasticsearch.cluster.ClusterService;
@@ -38,7 +39,6 @@ import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.concurrent.AbstractRunnable;
 import org.elasticsearch.common.util.concurrent.ConcurrentCollections;
-import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.engine.SnapshotFailedEngineException;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.shard.IndexShardState;
@@ -335,7 +335,7 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
 
         try {
             // we flush first to make sure we get the latest writes snapshotted
-            SnapshotIndexCommit snapshotIndexCommit = indexShard.snapshotIndex(true);
+            IndexCommit snapshotIndexCommit = indexShard.snapshotIndex(true);
             try {
                 indexShardRepository.snapshot(snapshotId, shardId, snapshotIndexCommit, snapshotStatus);
                 if (logger.isDebugEnabled()) {
@@ -345,7 +345,7 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
                     logger.debug(sb.toString());
                 }
             } finally {
-                snapshotIndexCommit.close();
+                indexShard.releaseSnapshot(snapshotIndexCommit);
             }
         } catch (SnapshotFailedEngineException e) {
             throw e;
diff --git a/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java b/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
index 7da0da8..aec95db 100644
--- a/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
+++ b/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
@@ -20,7 +20,7 @@ package org.elasticsearch;
 
 import com.fasterxml.jackson.core.JsonLocation;
 import com.fasterxml.jackson.core.JsonParseException;
-
+import com.google.common.collect.ImmutableSet;
 import org.apache.lucene.util.Constants;
 import org.codehaus.groovy.runtime.typehandling.GroovyCastException;
 import org.elasticsearch.action.FailedNodeException;
@@ -32,13 +32,7 @@ import org.elasticsearch.client.AbstractClientHeadersTestCase;
 import org.elasticsearch.cluster.block.ClusterBlockException;
 import org.elasticsearch.cluster.metadata.SnapshotId;
 import org.elasticsearch.cluster.node.DiscoveryNode;
-import org.elasticsearch.cluster.routing.IllegalShardRoutingStateException;
-import org.elasticsearch.cluster.routing.RoutingTableValidation;
-import org.elasticsearch.cluster.routing.RoutingValidationException;
-import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.cluster.routing.ShardRoutingState;
-import org.elasticsearch.cluster.routing.TestShardRouting;
-import org.elasticsearch.common.ParsingException;
+import org.elasticsearch.cluster.routing.*;
 import org.elasticsearch.common.breaker.CircuitBreakingException;
 import org.elasticsearch.common.io.PathUtils;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
@@ -60,6 +54,7 @@ import org.elasticsearch.index.engine.CreateFailedEngineException;
 import org.elasticsearch.index.engine.IndexFailedEngineException;
 import org.elasticsearch.index.engine.RecoveryEngineException;
 import org.elasticsearch.index.mapper.MergeMappingException;
+import org.elasticsearch.common.ParsingException;
 import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.shard.IllegalIndexShardStateException;
 import org.elasticsearch.index.shard.IndexShardState;
@@ -96,10 +91,12 @@ import java.nio.file.FileVisitor;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.attribute.BasicFileAttributes;
+import java.util.HashMap;
 import java.util.HashSet;
+import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.singleton;
+import static org.hamcrest.Matchers.greaterThanOrEqualTo;
 
 public class ExceptionSerializationTests extends ESTestCase {
 
@@ -230,13 +227,13 @@ public class ExceptionSerializationTests extends ESTestCase {
         ParsingException ex = serialize(new ParsingException(1, 2, "fobar", null));
         assertNull(ex.getIndex());
         assertEquals(ex.getMessage(), "fobar");
-        assertEquals(ex.getLineNumber(),1);
+        assertEquals(ex.getLineNumber(), 1);
         assertEquals(ex.getColumnNumber(), 2);
 
         ex = serialize(new ParsingException(1, 2, null, null));
         assertNull(ex.getIndex());
         assertNull(ex.getMessage());
-        assertEquals(ex.getLineNumber(),1);
+        assertEquals(ex.getLineNumber(), 1);
         assertEquals(ex.getColumnNumber(), 2);
     }
 
@@ -544,7 +541,7 @@ public class ExceptionSerializationTests extends ESTestCase {
     }
 
     public void testClusterBlockException() throws IOException {
-        ClusterBlockException ex = serialize(new ClusterBlockException(singleton(DiscoverySettings.NO_MASTER_BLOCK_WRITES)));
+        ClusterBlockException ex = serialize(new ClusterBlockException(ImmutableSet.of(DiscoverySettings.NO_MASTER_BLOCK_WRITES)));
         assertEquals("blocked by: [SERVICE_UNAVAILABLE/2/no master];", ex.getMessage());
         assertTrue(ex.blocks().contains(DiscoverySettings.NO_MASTER_BLOCK_WRITES));
         assertEquals(1, ex.blocks().size());
@@ -644,4 +641,180 @@ public class ExceptionSerializationTests extends ESTestCase {
         InterruptedException ex = serialize(orig);
         assertEquals(orig.getMessage(), ex.getMessage());
     }
+
+    public void testThatIdsArePositive() {
+        for (ElasticsearchException.ElasticsearchExceptionHandle handle : ElasticsearchException.ElasticsearchExceptionHandle.values()) {
+            assertThat("negative id", handle.id, greaterThanOrEqualTo(0));
+        }
+    }
+
+    public void testThatIdsAreUnique() {
+        Set<Integer> ids = new HashSet<>();
+        for (ElasticsearchException.ElasticsearchExceptionHandle handle : ElasticsearchException.ElasticsearchExceptionHandle.values()) {
+            assertTrue("duplicate id", ids.add(handle.id));
+        }
+    }
+
+    public void testIds() {
+        Map<Integer, Class<? extends ElasticsearchException>> ids = new HashMap<>();
+        ids.put(0, org.elasticsearch.index.snapshots.IndexShardSnapshotFailedException.class);
+        ids.put(1, org.elasticsearch.search.dfs.DfsPhaseExecutionException.class);
+        ids.put(2, org.elasticsearch.common.util.CancellableThreads.ExecutionCancelledException.class);
+        ids.put(3, org.elasticsearch.discovery.MasterNotDiscoveredException.class);
+        ids.put(4, org.elasticsearch.ElasticsearchSecurityException.class);
+        ids.put(5, org.elasticsearch.index.snapshots.IndexShardRestoreException.class);
+        ids.put(6, org.elasticsearch.indices.IndexClosedException.class);
+        ids.put(7, org.elasticsearch.http.BindHttpException.class);
+        ids.put(8, org.elasticsearch.action.search.ReduceSearchPhaseException.class);
+        ids.put(9, org.elasticsearch.node.NodeClosedException.class);
+        ids.put(10, org.elasticsearch.index.engine.SnapshotFailedEngineException.class);
+        ids.put(11, org.elasticsearch.index.shard.ShardNotFoundException.class);
+        ids.put(12, org.elasticsearch.transport.ConnectTransportException.class);
+        ids.put(13, org.elasticsearch.transport.NotSerializableTransportException.class);
+        ids.put(14, org.elasticsearch.transport.ResponseHandlerFailureTransportException.class);
+        ids.put(15, org.elasticsearch.indices.IndexCreationException.class);
+        ids.put(16, org.elasticsearch.index.IndexNotFoundException.class);
+        ids.put(17, org.elasticsearch.cluster.routing.IllegalShardRoutingStateException.class);
+        ids.put(18, org.elasticsearch.action.support.broadcast.BroadcastShardOperationFailedException.class);
+        ids.put(19, org.elasticsearch.ResourceNotFoundException.class);
+        ids.put(20, org.elasticsearch.transport.ActionTransportException.class);
+        ids.put(21, org.elasticsearch.ElasticsearchGenerationException.class);
+        ids.put(22, org.elasticsearch.index.engine.CreateFailedEngineException.class);
+        ids.put(23, org.elasticsearch.index.shard.IndexShardStartedException.class);
+        ids.put(24, org.elasticsearch.search.SearchContextMissingException.class);
+        ids.put(25, org.elasticsearch.script.ScriptException.class);
+        ids.put(26, org.elasticsearch.index.shard.TranslogRecoveryPerformer.BatchOperationException.class);
+        ids.put(27, org.elasticsearch.snapshots.SnapshotCreationException.class);
+        ids.put(28, org.elasticsearch.index.engine.DeleteFailedEngineException.class);
+        ids.put(29, org.elasticsearch.index.engine.DocumentMissingException.class);
+        ids.put(30, org.elasticsearch.snapshots.SnapshotException.class);
+        ids.put(31, org.elasticsearch.indices.InvalidAliasNameException.class);
+        ids.put(32, org.elasticsearch.indices.InvalidIndexNameException.class);
+        ids.put(33, org.elasticsearch.indices.IndexPrimaryShardNotAllocatedException.class);
+        ids.put(34, org.elasticsearch.transport.TransportException.class);
+        ids.put(35, org.elasticsearch.ElasticsearchParseException.class);
+        ids.put(36, org.elasticsearch.search.SearchException.class);
+        ids.put(37, org.elasticsearch.index.mapper.MapperException.class);
+        ids.put(38, org.elasticsearch.indices.InvalidTypeNameException.class);
+        ids.put(39, org.elasticsearch.snapshots.SnapshotRestoreException.class);
+        ids.put(40, org.elasticsearch.common.ParsingException.class);
+        ids.put(41, org.elasticsearch.index.shard.IndexShardClosedException.class);
+        ids.put(42, org.elasticsearch.indices.recovery.RecoverFilesRecoveryException.class);
+        ids.put(43, org.elasticsearch.index.translog.TruncatedTranslogException.class);
+        ids.put(44, org.elasticsearch.indices.recovery.RecoveryFailedException.class);
+        ids.put(45, org.elasticsearch.index.shard.IndexShardRelocatedException.class);
+        ids.put(46, org.elasticsearch.transport.NodeShouldNotConnectException.class);
+        ids.put(47, org.elasticsearch.indices.IndexTemplateAlreadyExistsException.class);
+        ids.put(48, org.elasticsearch.index.translog.TranslogCorruptedException.class);
+        ids.put(49, org.elasticsearch.cluster.block.ClusterBlockException.class);
+        ids.put(50, org.elasticsearch.search.fetch.FetchPhaseExecutionException.class);
+        ids.put(51, org.elasticsearch.index.IndexShardAlreadyExistsException.class);
+        ids.put(52, org.elasticsearch.index.engine.VersionConflictEngineException.class);
+        ids.put(53, org.elasticsearch.index.engine.EngineException.class);
+        ids.put(54, org.elasticsearch.index.engine.DocumentAlreadyExistsException.class);
+        ids.put(55, org.elasticsearch.action.NoSuchNodeException.class);
+        ids.put(56, org.elasticsearch.common.settings.SettingsException.class);
+        ids.put(57, org.elasticsearch.indices.IndexTemplateMissingException.class);
+        ids.put(58, org.elasticsearch.transport.SendRequestTransportException.class);
+        ids.put(59, org.elasticsearch.common.util.concurrent.EsRejectedExecutionException.class);
+        ids.put(60, org.elasticsearch.common.lucene.Lucene.EarlyTerminationException.class);
+        ids.put(61, org.elasticsearch.cluster.routing.RoutingValidationException.class);
+        ids.put(62, org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper.class);
+        ids.put(63, org.elasticsearch.indices.AliasFilterParsingException.class);
+        ids.put(64, org.elasticsearch.index.engine.DeleteByQueryFailedEngineException.class);
+        ids.put(65, org.elasticsearch.gateway.GatewayException.class);
+        ids.put(66, org.elasticsearch.index.shard.IndexShardNotRecoveringException.class);
+        ids.put(67, org.elasticsearch.http.HttpException.class);
+        ids.put(68, org.elasticsearch.ElasticsearchException.class);
+        ids.put(69, org.elasticsearch.snapshots.SnapshotMissingException.class);
+        ids.put(70, org.elasticsearch.action.PrimaryMissingActionException.class);
+        ids.put(71, org.elasticsearch.action.FailedNodeException.class);
+        ids.put(72, org.elasticsearch.search.SearchParseException.class);
+        ids.put(73, org.elasticsearch.snapshots.ConcurrentSnapshotExecutionException.class);
+        ids.put(74, org.elasticsearch.common.blobstore.BlobStoreException.class);
+        ids.put(75, org.elasticsearch.cluster.IncompatibleClusterStateVersionException.class);
+        ids.put(76, org.elasticsearch.index.engine.RecoveryEngineException.class);
+        ids.put(77, org.elasticsearch.common.util.concurrent.UncategorizedExecutionException.class);
+        ids.put(78, org.elasticsearch.action.TimestampParsingException.class);
+        ids.put(79, org.elasticsearch.action.RoutingMissingException.class);
+        ids.put(80, org.elasticsearch.index.engine.IndexFailedEngineException.class);
+        ids.put(81, org.elasticsearch.index.snapshots.IndexShardRestoreFailedException.class);
+        ids.put(82, org.elasticsearch.repositories.RepositoryException.class);
+        ids.put(83, org.elasticsearch.transport.ReceiveTimeoutTransportException.class);
+        ids.put(84, org.elasticsearch.transport.NodeDisconnectedException.class);
+        ids.put(85, org.elasticsearch.index.AlreadyExpiredException.class);
+        ids.put(86, org.elasticsearch.search.aggregations.AggregationExecutionException.class);
+        ids.put(87, org.elasticsearch.index.mapper.MergeMappingException.class);
+        ids.put(88, org.elasticsearch.indices.InvalidIndexTemplateException.class);
+        ids.put(89, org.elasticsearch.percolator.PercolateException.class);
+        ids.put(90, org.elasticsearch.index.engine.RefreshFailedEngineException.class);
+        ids.put(91, org.elasticsearch.search.aggregations.AggregationInitializationException.class);
+        ids.put(92, org.elasticsearch.indices.recovery.DelayRecoveryException.class);
+        ids.put(93, org.elasticsearch.search.warmer.IndexWarmerMissingException.class);
+        ids.put(94, org.elasticsearch.client.transport.NoNodeAvailableException.class);
+        ids.put(95, org.elasticsearch.script.groovy.GroovyScriptCompilationException.class);
+        ids.put(96, org.elasticsearch.snapshots.InvalidSnapshotNameException.class);
+        ids.put(97, org.elasticsearch.index.shard.IllegalIndexShardStateException.class);
+        ids.put(98, org.elasticsearch.index.snapshots.IndexShardSnapshotException.class);
+        ids.put(99, org.elasticsearch.index.shard.IndexShardNotStartedException.class);
+        ids.put(100, org.elasticsearch.action.search.SearchPhaseExecutionException.class);
+        ids.put(101, org.elasticsearch.transport.ActionNotFoundTransportException.class);
+        ids.put(102, org.elasticsearch.transport.TransportSerializationException.class);
+        ids.put(103, org.elasticsearch.transport.RemoteTransportException.class);
+        ids.put(104, org.elasticsearch.index.engine.EngineCreationFailureException.class);
+        ids.put(105, org.elasticsearch.cluster.routing.RoutingException.class);
+        ids.put(106, org.elasticsearch.index.shard.IndexShardRecoveryException.class);
+        ids.put(107, org.elasticsearch.repositories.RepositoryMissingException.class);
+        ids.put(108, org.elasticsearch.index.percolator.PercolatorException.class);
+        ids.put(109, org.elasticsearch.index.engine.DocumentSourceMissingException.class);
+        ids.put(110, org.elasticsearch.index.engine.FlushNotAllowedEngineException.class);
+        ids.put(111, org.elasticsearch.common.settings.NoClassSettingsException.class);
+        ids.put(112, org.elasticsearch.transport.BindTransportException.class);
+        ids.put(113, org.elasticsearch.rest.action.admin.indices.alias.delete.AliasesNotFoundException.class);
+        ids.put(114, org.elasticsearch.index.shard.IndexShardRecoveringException.class);
+        ids.put(115, org.elasticsearch.index.translog.TranslogException.class);
+        ids.put(116, org.elasticsearch.cluster.metadata.ProcessClusterEventTimeoutException.class);
+        ids.put(117, org.elasticsearch.action.support.replication.TransportReplicationAction.RetryOnPrimaryException.class);
+        ids.put(118, org.elasticsearch.ElasticsearchTimeoutException.class);
+        ids.put(119, org.elasticsearch.search.query.QueryPhaseExecutionException.class);
+        ids.put(120, org.elasticsearch.repositories.RepositoryVerificationException.class);
+        ids.put(121, org.elasticsearch.search.aggregations.InvalidAggregationPathException.class);
+        ids.put(122, org.elasticsearch.script.groovy.GroovyScriptExecutionException.class);
+        ids.put(123, org.elasticsearch.indices.IndexAlreadyExistsException.class);
+        ids.put(124, org.elasticsearch.script.Script.ScriptParseException.class);
+        ids.put(125, org.elasticsearch.transport.netty.SizeHeaderFrameDecoder.HttpOnTransportException.class);
+        ids.put(126, org.elasticsearch.index.mapper.MapperParsingException.class);
+        ids.put(127, org.elasticsearch.search.SearchContextException.class);
+        ids.put(128, org.elasticsearch.search.builder.SearchSourceBuilderException.class);
+        ids.put(129, org.elasticsearch.index.engine.EngineClosedException.class);
+        ids.put(130, org.elasticsearch.action.NoShardAvailableActionException.class);
+        ids.put(131, org.elasticsearch.action.UnavailableShardsException.class);
+        ids.put(132, org.elasticsearch.index.engine.FlushFailedEngineException.class);
+        ids.put(133, org.elasticsearch.common.breaker.CircuitBreakingException.class);
+        ids.put(134, org.elasticsearch.transport.NodeNotConnectedException.class);
+        ids.put(135, org.elasticsearch.index.mapper.StrictDynamicMappingException.class);
+        ids.put(136, org.elasticsearch.action.support.replication.TransportReplicationAction.RetryOnReplicaException.class);
+        ids.put(137, org.elasticsearch.indices.TypeMissingException.class);
+        ids.put(138, null);
+        ids.put(139, null);
+        ids.put(140, org.elasticsearch.discovery.Discovery.FailedToCommitClusterStateException.class);
+        ids.put(141, org.elasticsearch.index.query.QueryShardException.class);
+
+        Map<Class<? extends ElasticsearchException>, Integer> reverse = new HashMap<>();
+        for (Map.Entry<Integer, Class<? extends ElasticsearchException>> entry : ids.entrySet()) {
+            if (entry.getValue() != null) {
+                reverse.put(entry.getValue(), entry.getKey());
+            }
+        }
+
+        for (ElasticsearchException.ElasticsearchExceptionHandle handle : ElasticsearchException.ElasticsearchExceptionHandle.values()) {
+            assertEquals((int)reverse.get(handle.exceptionClass), handle.id);
+        }
+
+        for (Map.Entry<Integer, Class<? extends ElasticsearchException>> entry : ids.entrySet()) {
+            if (entry.getValue() != null) {
+                assertEquals((int) entry.getKey(), ElasticsearchException.getId(entry.getValue()));
+            }
+        }
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
index 606911f..0372128 100644
--- a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.cluster;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.ActionModule;
@@ -58,10 +59,7 @@ import java.util.Set;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.atomic.AtomicBoolean;
 
-import static java.util.Collections.emptySet;
-import static java.util.Collections.unmodifiableSet;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.hamcrest.CoreMatchers.equalTo;
 import static org.hamcrest.Matchers.greaterThan;
@@ -91,7 +89,8 @@ public class ClusterInfoServiceIT extends ESIntegTestCase {
     }
 
     public static class BlockingActionFilter extends org.elasticsearch.action.support.ActionFilter.Simple {
-        private Set<String> blockedActions = emptySet();
+
+        ImmutableSet<String> blockedActions = ImmutableSet.of();
 
         @Inject
         public BlockingActionFilter(Settings settings) {
@@ -117,7 +116,7 @@ public class ClusterInfoServiceIT extends ESIntegTestCase {
         }
 
         public void blockActions(String... actions) {
-            blockedActions = unmodifiableSet(newHashSet(actions));
+            blockedActions = ImmutableSet.copyOf(actions);
         }
     }
 
@@ -205,7 +204,7 @@ public class ClusterInfoServiceIT extends ESIntegTestCase {
         MockTransportService mockTransportService = (MockTransportService) internalCluster().getInstance(TransportService.class, internalTestCluster.getMasterName());
 
         final AtomicBoolean timeout = new AtomicBoolean(false);
-        final Set<String> blockedActions = newHashSet(NodesStatsAction.NAME, NodesStatsAction.NAME + "[n]", IndicesStatsAction.NAME, IndicesStatsAction.NAME + "[n]");
+        final Set<String> blockedActions = ImmutableSet.of(NodesStatsAction.NAME, NodesStatsAction.NAME + "[n]", IndicesStatsAction.NAME, IndicesStatsAction.NAME + "[n]");
         // drop all outgoing stats requests to force a timeout.
         for (DiscoveryNode node : internalTestCluster.clusterService().state().getNodes()) {
             mockTransportService.addDelegate(node, new MockTransportService.DelegateTransport(mockTransportService.original()) {
diff --git a/core/src/test/java/org/elasticsearch/common/unit/ByteSizeValueTests.java b/core/src/test/java/org/elasticsearch/common/unit/ByteSizeValueTests.java
index 362fd0d..200d04a 100644
--- a/core/src/test/java/org/elasticsearch/common/unit/ByteSizeValueTests.java
+++ b/core/src/test/java/org/elasticsearch/common/unit/ByteSizeValueTests.java
@@ -57,6 +57,13 @@ public class ByteSizeValueTests extends ESTestCase {
         assertThat(ByteSizeUnit.PB.toPB(10), is(new ByteSizeValue(10, ByteSizeUnit.PB).pb()));
     }
 
+    public void testEquality() {
+        String[] equalValues = new String[]{"1GB", "1024MB", "1048576KB", "1073741824B"};
+        ByteSizeValue value1 = ByteSizeValue.parseBytesSizeValue(randomFrom(equalValues), "equalTest");
+        ByteSizeValue value2 = ByteSizeValue.parseBytesSizeValue(randomFrom(equalValues), "equalTest");
+        assertThat(value1, equalTo(value2));
+    }
+
     @Test
     public void testToString() {
         assertThat("10b", is(new ByteSizeValue(10, ByteSizeUnit.BYTES).toString()));
diff --git a/core/src/test/java/org/elasticsearch/explain/ExplainActionIT.java b/core/src/test/java/org/elasticsearch/explain/ExplainActionIT.java
index d2b1e6d..be998b1 100644
--- a/core/src/test/java/org/elasticsearch/explain/ExplainActionIT.java
+++ b/core/src/test/java/org/elasticsearch/explain/ExplainActionIT.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.explain;
 
+import com.google.common.collect.ImmutableSet;
+
 import org.apache.lucene.search.Explanation;
 import org.elasticsearch.action.admin.indices.alias.Alias;
 import org.elasticsearch.action.explain.ExplainResponse;
@@ -40,7 +42,6 @@ import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.singleton;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.queryStringQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
@@ -59,7 +60,7 @@ public class ExplainActionIT extends ESIntegTestCase {
         ensureGreen("test");
 
         client().prepareIndex("test", "test", "1").setSource("field", "value1").get();
-
+        
         ExplainResponse response = client().prepareExplain(indexOrAlias(), "test", "1")
                 .setQuery(QueryBuilders.matchAllQuery()).get();
         assertNotNull(response);
@@ -144,7 +145,7 @@ public class ExplainActionIT extends ESIntegTestCase {
         assertThat(response.getGetResult().getId(), equalTo("1"));
         Set<String> fields = new HashSet<>(response.getGetResult().getFields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly added via templates
-        assertThat(fields, equalTo(singleton("obj1.field1")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("obj1.field1")));
         assertThat(response.getGetResult().getFields().get("obj1.field1").getValue().toString(), equalTo("value1"));
         assertThat(response.getGetResult().isSourceEmpty(), equalTo(true));
 
@@ -161,7 +162,7 @@ public class ExplainActionIT extends ESIntegTestCase {
         assertThat(response.getGetResult().getId(), equalTo("1"));
         fields = new HashSet<>(response.getGetResult().getFields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly added via templates
-        assertThat(fields, equalTo(singleton("obj1.field1")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("obj1.field1")));
         assertThat(response.getGetResult().getFields().get("obj1.field1").getValue().toString(), equalTo("value1"));
         assertThat(response.getGetResult().isSourceEmpty(), equalTo(false));
 
diff --git a/core/src/test/java/org/elasticsearch/gateway/AsyncShardFetchTests.java b/core/src/test/java/org/elasticsearch/gateway/AsyncShardFetchTests.java
index 88f47e7..c9139d2 100644
--- a/core/src/test/java/org/elasticsearch/gateway/AsyncShardFetchTests.java
+++ b/core/src/test/java/org/elasticsearch/gateway/AsyncShardFetchTests.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.gateway;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.FailedNodeException;
 import org.elasticsearch.action.support.nodes.BaseNodeResponse;
@@ -38,7 +39,6 @@ import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.atomic.AtomicInteger;
 
-import static java.util.Collections.emptySet;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.sameInstance;
 
@@ -56,7 +56,6 @@ public class AsyncShardFetchTests extends ESTestCase {
     private ThreadPool threadPool;
     private TestFetch test;
 
-    @Override
     @Before
     public void setUp() throws Exception {
         super.setUp();
@@ -75,7 +74,7 @@ public class AsyncShardFetchTests extends ESTestCase {
         test.addSimulation(node1.getId(), response1);
 
         // first fetch, no data, still on going
-        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(false));
         assertThat(test.reroute.get(), equalTo(0));
 
@@ -85,7 +84,7 @@ public class AsyncShardFetchTests extends ESTestCase {
         assertThat(test.reroute.get(), equalTo(1));
         test.close();
         try {
-            test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+            test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
             fail("fetch data should fail when closed");
         } catch (IllegalStateException e) {
             // all is well
@@ -99,7 +98,7 @@ public class AsyncShardFetchTests extends ESTestCase {
         test.addSimulation(node1.getId(), response1);
 
         // first fetch, no data, still on going
-        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(false));
         assertThat(test.reroute.get(), equalTo(0));
 
@@ -107,7 +106,7 @@ public class AsyncShardFetchTests extends ESTestCase {
         test.fireSimulationAndWait(node1.getId());
         // verify we get back the data node
         assertThat(test.reroute.get(), equalTo(1));
-        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(true));
         assertThat(fetchData.getData().size(), equalTo(1));
         assertThat(fetchData.getData().get(node1), sameInstance(response1));
@@ -120,7 +119,7 @@ public class AsyncShardFetchTests extends ESTestCase {
         test.addSimulation(node1.getId(), failure1);
 
         // first fetch, no data, still on going
-        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(false));
         assertThat(test.reroute.get(), equalTo(0));
 
@@ -128,19 +127,19 @@ public class AsyncShardFetchTests extends ESTestCase {
         test.fireSimulationAndWait(node1.getId());
         // failure, fetched data exists, but has no data
         assertThat(test.reroute.get(), equalTo(1));
-        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(true));
         assertThat(fetchData.getData().size(), equalTo(0));
 
         // on failure, we reset the failure on a successive call to fetchData, and try again afterwards
         test.addSimulation(node1.getId(), response1);
-        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(false));
 
         test.fireSimulationAndWait(node1.getId());
         // 2 reroutes, cause we have a failure that we clear
         assertThat(test.reroute.get(), equalTo(3));
-        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(true));
         assertThat(fetchData.getData().size(), equalTo(1));
         assertThat(fetchData.getData().get(node1), sameInstance(response1));
@@ -153,7 +152,7 @@ public class AsyncShardFetchTests extends ESTestCase {
         test.addSimulation(node2.getId(), response2);
 
         // no fetched data, 2 requests still on going
-        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(false));
         assertThat(test.reroute.get(), equalTo(0));
 
@@ -161,14 +160,14 @@ public class AsyncShardFetchTests extends ESTestCase {
         test.fireSimulationAndWait(node1.getId());
         // there is still another on going request, so no data
         assertThat(test.getNumberOfInFlightFetches(), equalTo(1));
-        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(false));
 
         // fire the second simulation, this should allow us to get the data
         test.fireSimulationAndWait(node2.getId());
         // no more ongoing requests, we should fetch the data
         assertThat(test.reroute.get(), equalTo(2));
-        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(true));
         assertThat(fetchData.getData().size(), equalTo(2));
         assertThat(fetchData.getData().get(node1), sameInstance(response1));
@@ -182,21 +181,21 @@ public class AsyncShardFetchTests extends ESTestCase {
         test.addSimulation(node2.getId(), failure2);
 
         // no fetched data, 2 requests still on going
-        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(false));
         assertThat(test.reroute.get(), equalTo(0));
 
         // fire the first response, it should trigger a reroute
         test.fireSimulationAndWait(node1.getId());
         assertThat(test.reroute.get(), equalTo(1));
-        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(false));
 
         // fire the second simulation, this should allow us to get the data
         test.fireSimulationAndWait(node2.getId());
         assertThat(test.reroute.get(), equalTo(2));
         // since one of those failed, we should only have one entry
-        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(true));
         assertThat(fetchData.getData().size(), equalTo(1));
         assertThat(fetchData.getData().get(node1), sameInstance(response1));
@@ -208,7 +207,7 @@ public class AsyncShardFetchTests extends ESTestCase {
         test.addSimulation(node1.getId(), response1);
 
         // no fetched data, 2 requests still on going
-        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        AsyncShardFetch.FetchResult<Response> fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(false));
         assertThat(test.reroute.get(), equalTo(0));
 
@@ -219,14 +218,14 @@ public class AsyncShardFetchTests extends ESTestCase {
         nodes = DiscoveryNodes.builder(nodes).put(node2).build();
         test.addSimulation(node2.getId(), response2);
         // no fetch data, has a new node introduced
-        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(false));
 
         // fire the second simulation, this should allow us to get the data
         test.fireSimulationAndWait(node2.getId());
 
         // since one of those failed, we should only have one entry
-        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, emptySet());
+        fetchData = test.fetchData(nodes, MetaData.EMPTY_META_DATA, ImmutableSet.<String>of());
         assertThat(fetchData.hasData(), equalTo(true));
         assertThat(fetchData.getData().size(), equalTo(2));
         assertThat(fetchData.getData().get(node1), sameInstance(response1));
diff --git a/core/src/test/java/org/elasticsearch/gateway/GatewayMetaStateTests.java b/core/src/test/java/org/elasticsearch/gateway/GatewayMetaStateTests.java
index 6e71b94..22850e1 100644
--- a/core/src/test/java/org/elasticsearch/gateway/GatewayMetaStateTests.java
+++ b/core/src/test/java/org/elasticsearch/gateway/GatewayMetaStateTests.java
@@ -34,7 +34,6 @@ import org.junit.Test;
 
 import java.util.*;
 
-import static java.util.Collections.emptySet;
 import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.hamcrest.Matchers.equalTo;
@@ -171,10 +170,11 @@ public class GatewayMetaStateTests extends ESAllocationTestCase {
                             boolean stateInMemory,
                             boolean expectMetaData) throws Exception {
         MetaData inMemoryMetaData = null;
-        Set<String> oldIndicesList = emptySet();
+        ImmutableSet<String> oldIndicesList = ImmutableSet.of();
         if (stateInMemory) {
             inMemoryMetaData = event.previousState().metaData();
-            oldIndicesList = GatewayMetaState.getRelevantIndices(event.previousState(), event.previousState(), oldIndicesList);
+            ImmutableSet.Builder<String> relevantIndices = ImmutableSet.builder();
+            oldIndicesList = relevantIndices.addAll(GatewayMetaState.getRelevantIndices(event.previousState(), event.previousState(), oldIndicesList)).build();
         }
         Set<String> newIndicesList = GatewayMetaState.getRelevantIndices(event.state(),event.previousState(), oldIndicesList);
         // third, get the actual write info
diff --git a/core/src/test/java/org/elasticsearch/gateway/RecoverAfterNodesIT.java b/core/src/test/java/org/elasticsearch/gateway/RecoverAfterNodesIT.java
index 5766ef3..458bb69 100644
--- a/core/src/test/java/org/elasticsearch/gateway/RecoverAfterNodesIT.java
+++ b/core/src/test/java/org/elasticsearch/gateway/RecoverAfterNodesIT.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.gateway;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.cluster.block.ClusterBlock;
 import org.elasticsearch.cluster.block.ClusterBlockLevel;
@@ -26,12 +27,10 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
-import org.elasticsearch.test.ESIntegTestCase.Scope;
 import org.junit.Test;
 
-import java.util.Set;
-
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
+import static org.elasticsearch.test.ESIntegTestCase.Scope;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.hasItem;
 
@@ -40,9 +39,9 @@ public class RecoverAfterNodesIT extends ESIntegTestCase {
 
     private final static TimeValue BLOCK_WAIT_TIMEOUT = TimeValue.timeValueSeconds(10);
 
-    public Set<ClusterBlock> waitForNoBlocksOnNode(TimeValue timeout, Client nodeClient) throws InterruptedException {
+    public ImmutableSet<ClusterBlock> waitForNoBlocksOnNode(TimeValue timeout, Client nodeClient) throws InterruptedException {
         long start = System.currentTimeMillis();
-        Set<ClusterBlock> blocks;
+        ImmutableSet<ClusterBlock> blocks;
         do {
             blocks = nodeClient.admin().cluster().prepareState().setLocal(true).execute().actionGet()
                     .getState().blocks().global(ClusterBlockLevel.METADATA_WRITE);
diff --git a/core/src/test/java/org/elasticsearch/get/GetActionIT.java b/core/src/test/java/org/elasticsearch/get/GetActionIT.java
index 55b104d..743304d 100644
--- a/core/src/test/java/org/elasticsearch/get/GetActionIT.java
+++ b/core/src/test/java/org/elasticsearch/get/GetActionIT.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.get;
 
+import com.google.common.collect.ImmutableSet;
+
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.ShardOperationFailedException;
@@ -50,17 +52,9 @@ import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.singleton;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.hasKey;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
-import static org.hamcrest.Matchers.startsWith;
+import static org.hamcrest.Matchers.*;
 
 public class GetActionIT extends ESIntegTestCase {
 
@@ -301,7 +295,7 @@ public class GetActionIT extends ESIntegTestCase {
         assertThat(response.getType(), equalTo("type1"));
         Set<String> fields = new HashSet<>(response.getFields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(singleton("field")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("field")));
         assertThat(response.getFields().get("field").getValues().size(), equalTo(2));
         assertThat(response.getFields().get("field").getValues().get(0).toString(), equalTo("1"));
         assertThat(response.getFields().get("field").getValues().get(1).toString(), equalTo("2"));
@@ -313,7 +307,7 @@ public class GetActionIT extends ESIntegTestCase {
         assertThat(response.getId(), equalTo("1"));
         fields = new HashSet<>(response.getFields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(singleton("field")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("field")));
         assertThat(response.getFields().get("field").getValues().size(), equalTo(2));
         assertThat(response.getFields().get("field").getValues().get(0).toString(), equalTo("1"));
         assertThat(response.getFields().get("field").getValues().get(1).toString(), equalTo("2"));
@@ -325,7 +319,7 @@ public class GetActionIT extends ESIntegTestCase {
         assertThat(response.getId(), equalTo("1"));
         fields = new HashSet<>(response.getFields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(singleton("field")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("field")));
         assertThat(response.getFields().get("field").getValues().size(), equalTo(2));
         assertThat(response.getFields().get("field").getValues().get(0).toString(), equalTo("1"));
         assertThat(response.getFields().get("field").getValues().get(1).toString(), equalTo("2"));
@@ -335,7 +329,7 @@ public class GetActionIT extends ESIntegTestCase {
         assertThat(response.getId(), equalTo("1"));
         fields = new HashSet<>(response.getFields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(singleton("field")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("field")));
         assertThat(response.getFields().get("field").getValues().size(), equalTo(2));
         assertThat(response.getFields().get("field").getValues().get(0).toString(), equalTo("1"));
         assertThat(response.getFields().get("field").getValues().get(1).toString(), equalTo("2"));
diff --git a/core/src/test/java/org/elasticsearch/index/TransportIndexFailuresIT.java b/core/src/test/java/org/elasticsearch/index/TransportIndexFailuresIT.java
index aed603c..ba73d9e 100644
--- a/core/src/test/java/org/elasticsearch/index/TransportIndexFailuresIT.java
+++ b/core/src/test/java/org/elasticsearch/index/TransportIndexFailuresIT.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;
 import org.elasticsearch.action.index.IndexAction;
 import org.elasticsearch.action.index.IndexResponse;
@@ -39,7 +40,6 @@ import org.junit.Test;
 import java.util.Collection;
 import java.util.List;
 
-import static java.util.Collections.singleton;
 import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
 import static org.elasticsearch.cluster.routing.ShardRoutingState.RELOCATING;
 import static org.elasticsearch.cluster.routing.ShardRoutingState.STARTED;
@@ -118,12 +118,12 @@ public class TransportIndexFailuresIT extends ESIntegTestCase {
         TransportService mockTransportService = internalCluster().getInstance(TransportService.class, primaryNode);
         ((MockTransportService) mockTransportService).addFailToSendNoConnectRule(
                 internalCluster().getInstance(Discovery.class, replicaNode).localNode(),
-                singleton(IndexAction.NAME + "[r]")
+                ImmutableSet.of(IndexAction.NAME + "[r]")
         );
         mockTransportService = internalCluster().getInstance(TransportService.class, replicaNode);
         ((MockTransportService) mockTransportService).addFailToSendNoConnectRule(
                 internalCluster().getInstance(Discovery.class, primaryNode).localNode(),
-                singleton(IndexAction.NAME + "[r]")
+                ImmutableSet.of(IndexAction.NAME + "[r]")
         );
 
         logger.info("--> indexing into primary");
diff --git a/core/src/test/java/org/elasticsearch/index/deletionpolicy/SnapshotDeletionPolicyTests.java b/core/src/test/java/org/elasticsearch/index/deletionpolicy/SnapshotDeletionPolicyTests.java
deleted file mode 100644
index a7d80e7..0000000
--- a/core/src/test/java/org/elasticsearch/index/deletionpolicy/SnapshotDeletionPolicyTests.java
+++ /dev/null
@@ -1,180 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.deletionpolicy;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.TextField;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.store.RAMDirectory;
-import org.elasticsearch.common.lucene.Lucene;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.test.ESTestCase;
-import org.junit.After;
-import org.junit.Before;
-import org.junit.Test;
-
-import static org.apache.lucene.index.DirectoryReader.listCommits;
-import static org.elasticsearch.common.settings.Settings.Builder.EMPTY_SETTINGS;
-import static org.hamcrest.Matchers.equalTo;
-
-/**
- * A set of tests for {@link org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy}.
- */
-public class SnapshotDeletionPolicyTests extends ESTestCase {
-
-    protected final ShardId shardId = new ShardId(new Index("index"), 1);
-
-    private RAMDirectory dir;
-    private SnapshotDeletionPolicy deletionPolicy;
-    private IndexWriter indexWriter;
-
-    @Override
-    @Before
-    public void setUp() throws Exception {
-        super.setUp();
-        dir = new RAMDirectory();
-        deletionPolicy = new SnapshotDeletionPolicy(new KeepOnlyLastDeletionPolicy(shardId, EMPTY_SETTINGS));
-        indexWriter = new IndexWriter(dir, new IndexWriterConfig(Lucene.STANDARD_ANALYZER)
-                .setIndexDeletionPolicy(deletionPolicy)
-                .setOpenMode(IndexWriterConfig.OpenMode.CREATE));
-    }
-
-    @Override
-    @After
-    public void tearDown() throws Exception {
-        super.tearDown();
-        indexWriter.close();
-        dir.close();
-    }
-
-    private Document testDocument() {
-        Document document = new Document();
-        document.add(new TextField("test", "1", Field.Store.YES));
-        return document;
-    }
-
-    @Test
-    public void testSimpleSnapshot() throws Exception {
-        // add a document and commit, resulting in one commit point
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-
-        assertThat(listCommits(dir).size(), equalTo(1));
-
-        // add another document and commit, resulting again in one commit point
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(1));
-
-        // snapshot the last commit, and then add a document and commit, now we should have two commit points
-        SnapshotIndexCommit snapshot = deletionPolicy.snapshot();
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(2));
-
-        // release the commit, add a document and commit, now we should be back to one commit point
-        snapshot.close();
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(1));
-    }
-
-    @Test
-    public void testMultiSnapshot() throws Exception {
-        // add a document and commit, resulting in one commit point
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(1));
-
-        // take two snapshots
-        SnapshotIndexCommit snapshot1 = deletionPolicy.snapshot();
-        SnapshotIndexCommit snapshot2 = deletionPolicy.snapshot();
-
-        // we should have two commits points
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(2));
-
-        // release one snapshot, we should still have two commit points
-        snapshot1.close();
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(2));
-
-        // release the second snapshot, we should be back to one commit
-        snapshot2.close();
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(1));
-    }
-
-    @Test
-    public void testMultiReleaseException() throws Exception {
-        // add a document and commit, resulting in one commit point
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(1));
-
-        // snapshot the last commit, and release it twice, the seconds should throw an exception
-        SnapshotIndexCommit snapshot = deletionPolicy.snapshot();
-        snapshot.close();
-        snapshot.close();
-    }
-
-    @Test
-    public void testSimpleSnapshots() throws Exception {
-        // add a document and commit, resulting in one commit point
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(1));
-
-        // add another document and commit, resulting again in one commint point
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(1));
-
-        // snapshot the last commit, and then add a document and commit, now we should have two commit points
-        SnapshotIndexCommit snapshot = deletionPolicy.snapshot();
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(2));
-
-        // now, take a snapshot of all the commits
-        SnapshotIndexCommits snapshots = deletionPolicy.snapshots();
-        assertThat(snapshots.size(), equalTo(2));
-
-        // release the snapshot, add a document and commit
-        // we should have 3 commits points since we are holding onto the first two with snapshots
-        // and we are using the keep only last
-        snapshot.close();
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(3));
-
-        // now release the snapshots, we should be back to a single commit point
-        snapshots.close();
-        indexWriter.addDocument(testDocument());
-        indexWriter.commit();
-        assertThat(listCommits(dir).size(), equalTo(1));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommitExistsMatcher.java b/core/src/test/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommitExistsMatcher.java
deleted file mode 100644
index 26f723b..0000000
--- a/core/src/test/java/org/elasticsearch/index/deletionpolicy/SnapshotIndexCommitExistsMatcher.java
+++ /dev/null
@@ -1,58 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.deletionpolicy;
-
-import org.elasticsearch.common.util.set.Sets;
-import org.hamcrest.Description;
-import org.hamcrest.Matcher;
-import org.hamcrest.TypeSafeMatcher;
-
-import java.io.IOException;
-import java.util.HashSet;
-
-/**
- *
- */
-public class SnapshotIndexCommitExistsMatcher extends TypeSafeMatcher<SnapshotIndexCommit> {
-
-    @Override
-    public boolean matchesSafely(SnapshotIndexCommit snapshotIndexCommit) {
-        try {
-            HashSet<String> files = Sets.newHashSet(snapshotIndexCommit.getDirectory().listAll());
-            for (String fileName : snapshotIndexCommit.getFiles()) {
-                if (files.contains(fileName) == false) {
-                    return false;
-                }
-            }
-        } catch (IOException ex) {
-            throw new RuntimeException(ex);
-        }
-        return true;
-    }
-
-    @Override
-    public void describeTo(Description description) {
-        description.appendText("an index commit existence");
-    }
-
-    public static Matcher<SnapshotIndexCommit> snapshotIndexCommitExists() {
-        return new SnapshotIndexCommitExistsMatcher();
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
index 3381102..c775639 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
@@ -60,8 +60,6 @@ import org.elasticsearch.index.Index;
 import org.elasticsearch.index.VersionType;
 import org.elasticsearch.index.analysis.AnalysisService;
 import org.elasticsearch.index.codec.CodecService;
-import org.elasticsearch.index.deletionpolicy.KeepOnlyLastDeletionPolicy;
-import org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy;
 import org.elasticsearch.index.engine.Engine.Searcher;
 import org.elasticsearch.index.indexing.ShardIndexingService;
 import org.elasticsearch.index.mapper.*;
@@ -231,15 +229,10 @@ public class InternalEngineTests extends ESTestCase {
         return new Translog(translogConfig);
     }
 
-    protected IndexDeletionPolicy createIndexDeletionPolicy() {
-        return new KeepOnlyLastDeletionPolicy(shardId, EMPTY_SETTINGS);
-    }
-
     protected SnapshotDeletionPolicy createSnapshotDeletionPolicy() {
-        return new SnapshotDeletionPolicy(createIndexDeletionPolicy());
+        return new SnapshotDeletionPolicy(new KeepOnlyLastCommitDeletionPolicy());
     }
 
-
     protected InternalEngine createEngine(Store store, Path translogPath, IndexSearcherWrapper... wrappers) {
         return createEngine(defaultSettings, store, translogPath, new MergeSchedulerConfig(defaultSettings), newMergePolicy(), wrappers);
     }
diff --git a/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
index 79f5e07..a6ca90a 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
@@ -40,8 +40,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.codec.CodecService;
-import org.elasticsearch.index.deletionpolicy.KeepOnlyLastDeletionPolicy;
-import org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy;
 import org.elasticsearch.index.indexing.ShardIndexingService;
 import org.elasticsearch.index.mapper.Mapping;
 import org.elasticsearch.index.mapper.ParseContext;
@@ -185,15 +183,10 @@ public class ShadowEngineTests extends ESTestCase {
         return new Store(shardId, EMPTY_SETTINGS, directoryService, new DummyShardLock(shardId));
     }
 
-    protected IndexDeletionPolicy createIndexDeletionPolicy() {
-        return new KeepOnlyLastDeletionPolicy(shardId, EMPTY_SETTINGS);
-    }
-
     protected SnapshotDeletionPolicy createSnapshotDeletionPolicy() {
-        return new SnapshotDeletionPolicy(createIndexDeletionPolicy());
+        return new SnapshotDeletionPolicy(new KeepOnlyLastCommitDeletionPolicy());
     }
 
-
     protected ShadowEngine createShadowEngine(Store store) {
         return createShadowEngine(defaultSettings, store);
     }
diff --git a/core/src/test/java/org/elasticsearch/index/store/StoreTests.java b/core/src/test/java/org/elasticsearch/index/store/StoreTests.java
index 5711d6a..18ba33f 100644
--- a/core/src/test/java/org/elasticsearch/index/store/StoreTests.java
+++ b/core/src/test/java/org/elasticsearch/index/store/StoreTests.java
@@ -40,8 +40,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.env.ShardLock;
 import org.elasticsearch.index.Index;
-import org.elasticsearch.index.deletionpolicy.KeepOnlyLastDeletionPolicy;
-import org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.index.translog.Translog;
@@ -1144,7 +1142,7 @@ public class StoreTests extends ESTestCase {
         DirectoryService directoryService = new LuceneManagedDirectoryService(random());
         Store store = new Store(shardId, Settings.EMPTY, directoryService, new DummyShardLock(shardId));
         IndexWriterConfig config = newIndexWriterConfig(random(), new MockAnalyzer(random())).setCodec(TestUtil.getDefaultCodec());
-        SnapshotDeletionPolicy deletionPolicy = new SnapshotDeletionPolicy(new KeepOnlyLastDeletionPolicy(shardId, EMPTY_SETTINGS));
+        SnapshotDeletionPolicy deletionPolicy = new SnapshotDeletionPolicy(new KeepOnlyLastCommitDeletionPolicy());
         config.setIndexDeletionPolicy(deletionPolicy);
         IndexWriter writer = new IndexWriter(store.directory(), config);
         Document doc = new Document();
diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java b/core/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java
index 81c834a..c1ae4c2 100644
--- a/core/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java
+++ b/core/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java
@@ -32,7 +32,6 @@ import java.io.IOException;
 import java.net.URL;
 import java.nio.charset.Charset;
 import java.nio.file.Path;
-import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.Locale;
 
@@ -95,7 +94,7 @@ public class PluginManagerUnitTests extends ESTestCase {
 
     @Test
     public void testOfficialPluginName() throws IOException {
-        String randomPluginName = randomFrom(new ArrayList<>(PluginManager.OFFICIAL_PLUGINS));
+        String randomPluginName = randomFrom(PluginManager.OFFICIAL_PLUGINS.asList());
         PluginManager.PluginHandle handle = PluginManager.PluginHandle.parse(randomPluginName);
         assertThat(handle.name, is(randomPluginName));
 
diff --git a/core/src/test/java/org/elasticsearch/script/NativeScriptTests.java b/core/src/test/java/org/elasticsearch/script/NativeScriptTests.java
index 9998234..cf7f7b1 100644
--- a/core/src/test/java/org/elasticsearch/script/NativeScriptTests.java
+++ b/core/src/test/java/org/elasticsearch/script/NativeScriptTests.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.script;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.ContextAndHeaderHolder;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.inject.Injector;
@@ -40,7 +41,6 @@ import java.util.HashMap;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.singleton;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.notNullValue;
 
@@ -85,7 +85,7 @@ public class NativeScriptTests extends ESTestCase {
         ResourceWatcherService resourceWatcherService = new ResourceWatcherService(settings, null);
         Map<String, NativeScriptFactory> nativeScriptFactoryMap = new HashMap<>();
         nativeScriptFactoryMap.put("my", new MyNativeScriptFactory());
-        Set<ScriptEngineService> scriptEngineServices = singleton(new NativeScriptEngineService(settings, nativeScriptFactoryMap));
+        Set<ScriptEngineService> scriptEngineServices = ImmutableSet.<ScriptEngineService>of(new NativeScriptEngineService(settings, nativeScriptFactoryMap));
         ScriptContextRegistry scriptContextRegistry = new ScriptContextRegistry(new ArrayList<ScriptContext.Plugin>());
         ScriptService scriptService = new ScriptService(settings, environment, scriptEngineServices, resourceWatcherService, scriptContextRegistry);
 
diff --git a/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java b/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java
index 37030a2..cfa4eda 100644
--- a/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java
+++ b/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java
@@ -20,7 +20,7 @@
 package org.elasticsearch.script;
 
 import com.google.common.collect.ImmutableMap;
-
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.script.ScriptService.ScriptType;
@@ -38,16 +38,13 @@ import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.singleton;
-import static java.util.Collections.unmodifiableSet;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
 import static org.hamcrest.CoreMatchers.equalTo;
 import static org.hamcrest.CoreMatchers.notNullValue;
 
 // TODO: this needs to be a base test class, and all scripting engines extend it
 public class ScriptModesTests extends ESTestCase {
-    private static final Set<String> ALL_LANGS = unmodifiableSet(
-            newHashSet(GroovyScriptEngineService.NAME, MustacheScriptEngineService.NAME, "custom", "test"));
+
+    private static final Set<String> ALL_LANGS = ImmutableSet.of(GroovyScriptEngineService.NAME, MustacheScriptEngineService.NAME, "custom", "test");
 
     static final String[] ENABLE_VALUES = new String[]{"on", "true", "yes", "1"};
     static final String[] DISABLE_VALUES = new String[]{"off", "false", "no", "0"};
@@ -74,7 +71,7 @@ public class ScriptModesTests extends ESTestCase {
         }
         scriptContextRegistry = new ScriptContextRegistry(contexts.values());
         scriptContexts = scriptContextRegistry.scriptContexts().toArray(new ScriptContext[scriptContextRegistry.scriptContexts().size()]);
-        scriptEngines = buildScriptEnginesByLangMap(newHashSet(
+        scriptEngines = buildScriptEnginesByLangMap(ImmutableSet.of(
                 new GroovyScriptEngineService(Settings.EMPTY),
                 new MustacheScriptEngineService(Settings.EMPTY),
                 //add the native engine just to make sure it gets filtered out
@@ -198,7 +195,7 @@ public class ScriptModesTests extends ESTestCase {
         Settings.Builder builder = Settings.builder()
                 .put(specificEngineOpSettings(GroovyScriptEngineService.NAME, ScriptType.INLINE, ScriptContext.Standard.MAPPING), randomFrom(DISABLE_VALUES))
                 .put(specificEngineOpSettings(GroovyScriptEngineService.NAME, ScriptType.INLINE, ScriptContext.Standard.UPDATE), randomFrom(DISABLE_VALUES));
-        Set<String> groovyLangSet = singleton(GroovyScriptEngineService.NAME);
+        ImmutableSet<String> groovyLangSet = ImmutableSet.of(GroovyScriptEngineService.NAME);
         Set<String> allButGroovyLangSet = new HashSet<>(ALL_LANGS);
         allButGroovyLangSet.remove(GroovyScriptEngineService.NAME);
         this.scriptModes = new ScriptModes(scriptEngines, scriptContextRegistry, builder.build());
@@ -214,7 +211,7 @@ public class ScriptModesTests extends ESTestCase {
         Settings.Builder builder = Settings.builder().put("script.inline", randomFrom(DISABLE_VALUES))
                 .put(specificEngineOpSettings(MustacheScriptEngineService.NAME, ScriptType.INLINE, ScriptContext.Standard.AGGS), randomFrom(ENABLE_VALUES))
                 .put(specificEngineOpSettings(MustacheScriptEngineService.NAME, ScriptType.INLINE, ScriptContext.Standard.SEARCH), randomFrom(ENABLE_VALUES));
-        Set<String> mustacheLangSet = singleton(MustacheScriptEngineService.NAME);
+        ImmutableSet<String> mustacheLangSet = ImmutableSet.of(MustacheScriptEngineService.NAME);
         Set<String> allButMustacheLangSet = new HashSet<>(ALL_LANGS);
         allButMustacheLangSet.remove(MustacheScriptEngineService.NAME);
         this.scriptModes = new ScriptModes(scriptEngines, scriptContextRegistry, builder.build());
diff --git a/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java b/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java
index 4f19cd9..6b33de8 100644
--- a/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java
+++ b/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.script;
 
+import com.google.common.collect.ImmutableSet;
 import org.elasticsearch.common.ContextAndHeaderHolder;
 import org.elasticsearch.common.HasContextAndHeaders;
 import org.elasticsearch.common.Nullable;
@@ -41,7 +42,6 @@ import java.util.Map;
 import java.util.Set;
 
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
 import static org.hamcrest.CoreMatchers.containsString;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.notNullValue;
@@ -75,7 +75,7 @@ public class ScriptServiceTests extends ESTestCase {
                 .put("path.conf", genericConfigFolder)
                 .build();
         resourceWatcherService = new ResourceWatcherService(baseSettings, null);
-        scriptEngineServices = newHashSet(new TestEngineService(), new GroovyScriptEngineService(baseSettings),
+        scriptEngineServices = ImmutableSet.of(new TestEngineService(), new GroovyScriptEngineService(baseSettings),
                                                new MustacheScriptEngineService(baseSettings));
         scriptEnginesByLangMap = ScriptModesTests.buildScriptEnginesByLangMap(scriptEngineServices);
         //randomly register custom script contexts
diff --git a/core/src/test/java/org/elasticsearch/search/fields/SearchFieldsIT.java b/core/src/test/java/org/elasticsearch/search/fields/SearchFieldsIT.java
index 21afbd5..1075347 100644
--- a/core/src/test/java/org/elasticsearch/search/fields/SearchFieldsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/fields/SearchFieldsIT.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.search.fields;
 
+import com.google.common.collect.ImmutableSet;
+
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
@@ -53,9 +55,7 @@ import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ExecutionException;
 
-import static java.util.Collections.singleton;
 import static org.elasticsearch.client.Requests.refreshRequest;
-import static org.elasticsearch.common.util.set.Sets.newHashSet;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
@@ -63,10 +63,7 @@ import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFail
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -173,21 +170,21 @@ public class SearchFieldsIT extends ESIntegTestCase {
         assertThat(response.getHits().getAt(0).id(), equalTo("1"));
         Set<String> fields = new HashSet<>(response.getHits().getAt(0).fields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(newHashSet("sNum1", "sNum1_field", "date1")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("sNum1", "sNum1_field", "date1")));
         assertThat((Double) response.getHits().getAt(0).fields().get("sNum1").values().get(0), equalTo(1.0));
         assertThat((Double) response.getHits().getAt(0).fields().get("sNum1_field").values().get(0), equalTo(1.0));
         assertThat((Long) response.getHits().getAt(0).fields().get("date1").values().get(0), equalTo(0l));
         assertThat(response.getHits().getAt(1).id(), equalTo("2"));
         fields = new HashSet<>(response.getHits().getAt(0).fields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(newHashSet("sNum1", "sNum1_field", "date1")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("sNum1", "sNum1_field", "date1")));
         assertThat((Double) response.getHits().getAt(1).fields().get("sNum1").values().get(0), equalTo(2.0));
         assertThat((Double) response.getHits().getAt(1).fields().get("sNum1_field").values().get(0), equalTo(2.0));
         assertThat((Long) response.getHits().getAt(1).fields().get("date1").values().get(0), equalTo(25000l));
         assertThat(response.getHits().getAt(2).id(), equalTo("3"));
         fields = new HashSet<>(response.getHits().getAt(0).fields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(newHashSet("sNum1", "sNum1_field", "date1")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("sNum1", "sNum1_field", "date1")));
         assertThat((Double) response.getHits().getAt(2).fields().get("sNum1").values().get(0), equalTo(3.0));
         assertThat((Double) response.getHits().getAt(2).fields().get("sNum1_field").values().get(0), equalTo(3.0));
         assertThat((Long) response.getHits().getAt(2).fields().get("date1").values().get(0), equalTo(120000l));
@@ -204,17 +201,17 @@ public class SearchFieldsIT extends ESIntegTestCase {
         assertThat(response.getHits().getAt(0).id(), equalTo("1"));
         fields = new HashSet<>(response.getHits().getAt(0).fields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(singleton("sNum1")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("sNum1")));
         assertThat((Double) response.getHits().getAt(0).fields().get("sNum1").values().get(0), equalTo(2.0));
         assertThat(response.getHits().getAt(1).id(), equalTo("2"));
         fields = new HashSet<>(response.getHits().getAt(0).fields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(singleton("sNum1")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("sNum1")));
         assertThat((Double) response.getHits().getAt(1).fields().get("sNum1").values().get(0), equalTo(4.0));
         assertThat(response.getHits().getAt(2).id(), equalTo("3"));
         fields = new HashSet<>(response.getHits().getAt(0).fields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(singleton("sNum1")));
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("sNum1")));
         assertThat((Double) response.getHits().getAt(2).fields().get("sNum1").values().get(0), equalTo(6.0));
     }
 
@@ -242,7 +239,7 @@ public class SearchFieldsIT extends ESIntegTestCase {
             assertThat(response.getHits().getAt(i).id(), equalTo(Integer.toString(i)));
             Set<String> fields = new HashSet<>(response.getHits().getAt(i).fields().keySet());
             fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-            assertThat(fields, equalTo(singleton("uid")));
+            assertThat(fields, equalTo((Set<String>) ImmutableSet.of("uid")));
             assertThat((String)response.getHits().getAt(i).fields().get("uid").value(), equalTo("type1#" + Integer.toString(i)));
         }
 
@@ -257,7 +254,7 @@ public class SearchFieldsIT extends ESIntegTestCase {
             assertThat(response.getHits().getAt(i).id(), equalTo(Integer.toString(i)));
             Set<String> fields = new HashSet<>(response.getHits().getAt(i).fields().keySet());
             fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-            assertThat(fields, equalTo(singleton("id")));
+            assertThat(fields, equalTo((Set<String>) ImmutableSet.of("id")));
             assertThat((String)response.getHits().getAt(i).fields().get("id").value(), equalTo(Integer.toString(i)));
         }
 
@@ -272,7 +269,7 @@ public class SearchFieldsIT extends ESIntegTestCase {
             assertThat(response.getHits().getAt(i).id(), equalTo(Integer.toString(i)));
             Set<String> fields = new HashSet<>(response.getHits().getAt(i).fields().keySet());
             fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-            assertThat(fields, equalTo(singleton("type")));
+            assertThat(fields, equalTo((Set<String>) ImmutableSet.of("type")));
             assertThat((String)response.getHits().getAt(i).fields().get("type").value(), equalTo("type1"));
         }
 
@@ -288,7 +285,7 @@ public class SearchFieldsIT extends ESIntegTestCase {
             assertThat(response.getHits().getAt(i).id(), equalTo(Integer.toString(i)));
             Set<String> fields = new HashSet<>(response.getHits().getAt(i).fields().keySet());
             fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-            assertThat(fields, equalTo(newHashSet("uid", "type", "id")));
+            assertThat(fields, equalTo((Set<String>) ImmutableSet.of("uid", "type", "id")));
             assertThat((String)response.getHits().getAt(i).fields().get("uid").value(), equalTo("type1#" + Integer.toString(i)));
             assertThat((String)response.getHits().getAt(i).fields().get("type").value(), equalTo("type1"));
             assertThat((String)response.getHits().getAt(i).fields().get("id").value(), equalTo(Integer.toString(i)));
@@ -409,7 +406,7 @@ public class SearchFieldsIT extends ESIntegTestCase {
         assertThat(searchResponse.getHits().hits().length, equalTo(1));
         Set<String> fields = new HashSet<>(searchResponse.getHits().getAt(0).fields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(newHashSet("byte_field", "short_field", "integer_field", "long_field",
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("byte_field", "short_field", "integer_field", "long_field",
                 "float_field", "double_field", "date_field", "boolean_field", "binary_field")));
 
 
@@ -588,7 +585,7 @@ public class SearchFieldsIT extends ESIntegTestCase {
         assertThat(searchResponse.getHits().hits().length, equalTo(1));
         Set<String> fields = new HashSet<>(searchResponse.getHits().getAt(0).fields().keySet());
         fields.remove(TimestampFieldMapper.NAME); // randomly enabled via templates
-        assertThat(fields, equalTo(newHashSet("byte_field", "short_field", "integer_field", "long_field",
+        assertThat(fields, equalTo((Set<String>) ImmutableSet.of("byte_field", "short_field", "integer_field", "long_field",
                 "float_field", "double_field", "date_field", "boolean_field", "string_field")));
 
         assertThat(searchResponse.getHits().getAt(0).fields().get("byte_field").value().toString(), equalTo("1"));
diff --git a/dev-tools/src/main/resources/forbidden/all-signatures.txt b/dev-tools/src/main/resources/forbidden/all-signatures.txt
index 49bf0c8..60a07c0 100644
--- a/dev-tools/src/main/resources/forbidden/all-signatures.txt
+++ b/dev-tools/src/main/resources/forbidden/all-signatures.txt
@@ -127,7 +127,7 @@ com.google.common.collect.HashMultimap
 com.google.common.collect.FluentIterable
 com.google.common.io.Files
 com.google.common.primitives.Ints
-com.google.common.collect.ImmutableSet
+com.google.common.collect.ImmutableMap#entrySet()
 
 @defaultMessage Do not violate java's access system
 java.lang.reflect.AccessibleObject#setAccessible(boolean)
diff --git a/docs/reference/aggregations/bucket/filters-aggregation.asciidoc b/docs/reference/aggregations/bucket/filters-aggregation.asciidoc
index d60c301..3e81e99 100644
--- a/docs/reference/aggregations/bucket/filters-aggregation.asciidoc
+++ b/docs/reference/aggregations/bucket/filters-aggregation.asciidoc
@@ -136,7 +136,7 @@ not match any of the given filters. The value of this parameter can be as follow
 `true`::          Returns the `other` bucket bucket either in a bucket (named `_other_` by default) if named filters are being used, 
                   or as the last bucket if anonymous filters are being used
 
-The `other_bucket_key` parameter can be used to set the key for the `other` bucket to a value other than the default `_other_`. Seting 
+The `other_bucket_key` parameter can be used to set the key for the `other` bucket to a value other than the default `_other_`. Setting 
 this parameter will implicitly set the `other_bucket` parameter to `true`.
 
 The following snippet shows a response where the `other` bucket is requested to be named `other_messages`.
diff --git a/pom.xml b/pom.xml
index dd9e539..273234c 100644
--- a/pom.xml
+++ b/pom.xml
@@ -697,6 +697,7 @@
                                     showStatusFailure="true"
                                     showStatusIgnored="true"
                                     showSuiteSummary="true"
+                                    showNumFailures="30"
                                     timestamps="false">
                                 <filtertrace>
                                     <!-- custom filters: we carefully only omit test infra noise here -->

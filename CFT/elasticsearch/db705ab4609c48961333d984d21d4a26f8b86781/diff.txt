diff --git a/core/pom.xml b/core/pom.xml
index 7abde96..fa8e352 100644
--- a/core/pom.xml
+++ b/core/pom.xml
@@ -197,39 +197,22 @@
 
         <resources>
             <resource>
-                <directory>${project.basedir}/src/main/java</directory>
+                <directory>${project.basedir}/src/main/resources</directory>
                 <includes>
-                    <include>**/*.json</include>
-                    <include>**/*.yml</include>
+                    <include>es-build.properties</include>
                 </includes>
+                <filtering>true</filtering>
             </resource>
             <resource>
                 <directory>${project.basedir}/src/main/resources</directory>
                 <includes>
                     <include>**/*.*</include>
                 </includes>
-                <filtering>true</filtering>
             </resource>
         </resources>
 
         <testResources>
             <testResource>
-                <directory>${project.basedir}/src/test/java</directory>
-                <includes>
-                    <include>**/*.json</include>
-                    <include>**/*.yml</include>
-                    <include>**/*.txt</include>
-                    <include>**/*.properties</include>
-                </includes>
-                <filtering>true</filtering>
-            </testResource>
-            <testResource>
-                <directory>${project.basedir}/src/test/java</directory>
-                <includes>
-                    <include>**/*.gz</include>
-                </includes>
-            </testResource>
-            <testResource>
                 <directory>${project.basedir}/src/test/resources</directory>
                 <includes>
                     <include>**/*.*</include>
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java b/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java
index cb4bee3..6cac629 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/ExistsFieldQueryExtension.java
@@ -21,8 +21,8 @@ package org.apache.lucene.queryparser.classic;
 
 import org.apache.lucene.search.ConstantScoreQuery;
 import org.apache.lucene.search.Query;
-import org.elasticsearch.index.query.ExistsQueryBuilder;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.ExistsQueryParser;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
  *
@@ -32,7 +32,7 @@ public class ExistsFieldQueryExtension implements FieldQueryExtension {
     public static final String NAME = "_exists_";
 
     @Override
-    public Query query(QueryShardContext context, String queryText) {
-        return new ConstantScoreQuery(ExistsQueryBuilder.newFilter(context, queryText));
+    public Query query(QueryParseContext parseContext, String queryText) {
+        return new ConstantScoreQuery(ExistsQueryParser.newFilter(parseContext, queryText, null));
     }
 }
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java b/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java
index 299a37a..003ff18 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/FieldQueryExtension.java
@@ -20,12 +20,12 @@
 package org.apache.lucene.queryparser.classic;
 
 import org.apache.lucene.search.Query;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
  *
  */
 public interface FieldQueryExtension {
 
-    Query query(QueryShardContext context, String queryText);
+    Query query(QueryParseContext parseContext, String queryText);
 }
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java b/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
index 6ed7f52..1585acd 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
@@ -39,7 +39,7 @@ import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.core.DateFieldMapper;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.support.QueryParsers;
 
 import com.google.common.collect.ImmutableMap;
@@ -70,7 +70,7 @@ public class MapperQueryParser extends QueryParser {
                 .build();
     }
 
-    private final QueryShardContext context;
+    private final QueryParseContext parseContext;
 
     private QueryParserSettings settings;
 
@@ -85,9 +85,9 @@ public class MapperQueryParser extends QueryParser {
 
     private String quoteFieldSuffix;
 
-    public MapperQueryParser(QueryShardContext context) {
+    public MapperQueryParser(QueryParseContext parseContext) {
         super(null, null);
-        this.context = context;
+        this.parseContext = parseContext;
     }
 
     public void reset(QueryParserSettings settings) {
@@ -162,7 +162,7 @@ public class MapperQueryParser extends QueryParser {
     public Query getFieldQuery(String field, String queryText, boolean quoted) throws ParseException {
         FieldQueryExtension fieldQueryExtension = fieldQueryExtensions.get(field);
         if (fieldQueryExtension != null) {
-            return fieldQueryExtension.query(context, queryText);
+            return fieldQueryExtension.query(parseContext, queryText);
         }
         Collection<String> fields = extractMultiFields(field);
         if (fields != null) {
@@ -226,27 +226,27 @@ public class MapperQueryParser extends QueryParser {
             if (quoted) {
                 setAnalyzer(quoteAnalyzer);
                 if (quoteFieldSuffix != null) {
-                    currentFieldType = context.fieldMapper(field + quoteFieldSuffix);
+                    currentFieldType = parseContext.fieldMapper(field + quoteFieldSuffix);
                 }
             }
             if (currentFieldType == null) {
-                currentFieldType = context.fieldMapper(field);
+                currentFieldType = parseContext.fieldMapper(field);
             }
             if (currentFieldType != null) {
                 if (quoted) {
                     if (!forcedQuoteAnalyzer) {
-                        setAnalyzer(context.getSearchQuoteAnalyzer(currentFieldType));
+                        setAnalyzer(parseContext.getSearchQuoteAnalyzer(currentFieldType));
                     }
                 } else {
                     if (!forcedAnalyzer) {
-                        setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                        setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                     }
                 }
                 if (currentFieldType != null) {
                     Query query = null;
                     if (currentFieldType.useTermQueryWithQueryString()) {
                         try {
-                            query = currentFieldType.termQuery(queryText, context);
+                            query = currentFieldType.termQuery(queryText, parseContext);
                         } catch (RuntimeException e) {
                             if (settings.lenient()) {
                                 return null;
@@ -357,7 +357,7 @@ public class MapperQueryParser extends QueryParser {
     }
 
     private Query getRangeQuerySingle(String field, String part1, String part2, boolean startInclusive, boolean endInclusive) {
-        currentFieldType = context.fieldMapper(field);
+        currentFieldType = parseContext.fieldMapper(field);
         if (currentFieldType != null) {
             if (lowercaseExpandedTerms && !currentFieldType.isNumeric()) {
                 part1 = part1 == null ? null : part1.toLowerCase(locale);
@@ -422,7 +422,7 @@ public class MapperQueryParser extends QueryParser {
     }
 
     private Query getFuzzyQuerySingle(String field, String termStr, String minSimilarity) throws ParseException {
-        currentFieldType = context.fieldMapper(field);
+        currentFieldType = parseContext.fieldMapper(field);
         if (currentFieldType != null) {
             try {
                 return currentFieldType.fuzzyQuery(termStr, Fuzziness.build(minSimilarity), fuzzyPrefixLength, settings.fuzzyMaxExpansions(), FuzzyQuery.defaultTranspositions);
@@ -492,14 +492,14 @@ public class MapperQueryParser extends QueryParser {
         currentFieldType = null;
         Analyzer oldAnalyzer = getAnalyzer();
         try {
-            currentFieldType = context.fieldMapper(field);
+            currentFieldType = parseContext.fieldMapper(field);
             if (currentFieldType != null) {
                 if (!forcedAnalyzer) {
-                    setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                    setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                 }
                 Query query = null;
                 if (currentFieldType.useTermQueryWithQueryString()) {
-                    query = currentFieldType.prefixQuery(termStr, multiTermRewriteMethod, context);
+                    query = currentFieldType.prefixQuery(termStr, multiTermRewriteMethod, parseContext);
                 }
                 if (query == null) {
                     query = getPossiblyAnalyzedPrefixQuery(currentFieldType.names().indexName(), termStr);
@@ -584,7 +584,7 @@ public class MapperQueryParser extends QueryParser {
                     return newMatchAllDocsQuery();
                 }
                 // effectively, we check if a field exists or not
-                return fieldQueryExtensions.get(ExistsFieldQueryExtension.NAME).query(context, actualField);
+                return fieldQueryExtensions.get(ExistsFieldQueryExtension.NAME).query(parseContext, actualField);
             }
         }
         if (lowercaseExpandedTerms) {
@@ -633,10 +633,10 @@ public class MapperQueryParser extends QueryParser {
         currentFieldType = null;
         Analyzer oldAnalyzer = getAnalyzer();
         try {
-            currentFieldType = context.fieldMapper(field);
+            currentFieldType = parseContext.fieldMapper(field);
             if (currentFieldType != null) {
                 if (!forcedAnalyzer) {
-                    setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                    setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                 }
                 indexedNameField = currentFieldType.names().indexName();
                 return getPossiblyAnalyzedWildcardQuery(indexedNameField, termStr);
@@ -765,14 +765,14 @@ public class MapperQueryParser extends QueryParser {
         currentFieldType = null;
         Analyzer oldAnalyzer = getAnalyzer();
         try {
-            currentFieldType = context.fieldMapper(field);
+            currentFieldType = parseContext.fieldMapper(field);
             if (currentFieldType != null) {
                 if (!forcedAnalyzer) {
-                    setAnalyzer(context.getSearchAnalyzer(currentFieldType));
+                    setAnalyzer(parseContext.getSearchAnalyzer(currentFieldType));
                 }
                 Query query = null;
                 if (currentFieldType.useTermQueryWithQueryString()) {
-                    query = currentFieldType.regexpQuery(termStr, RegExp.ALL, maxDeterminizedStates, multiTermRewriteMethod, context);
+                    query = currentFieldType.regexpQuery(termStr, RegExp.ALL, maxDeterminizedStates, multiTermRewriteMethod, parseContext);
                 }
                 if (query == null) {
                     query = super.getRegexpQuery(field, termStr);
@@ -830,7 +830,7 @@ public class MapperQueryParser extends QueryParser {
     private Collection<String> extractMultiFields(String field) {
         Collection<String> fields = null;
         if (field != null) {
-            fields = context.simpleMatchToIndexNames(field);
+            fields = parseContext.simpleMatchToIndexNames(field);
         } else {
             fields = settings.fields();
         }
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java b/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java
index f9fc8c9..ed1b704 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/MissingFieldQueryExtension.java
@@ -21,8 +21,8 @@ package org.apache.lucene.queryparser.classic;
 
 import org.apache.lucene.search.ConstantScoreQuery;
 import org.apache.lucene.search.Query;
-import org.elasticsearch.index.query.MissingQueryBuilder;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.MissingQueryParser;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
  *
@@ -32,11 +32,8 @@ public class MissingFieldQueryExtension implements FieldQueryExtension {
     public static final String NAME = "_missing_";
 
     @Override
-    public Query query(QueryShardContext context, String queryText) {
-        Query query = MissingQueryBuilder.newFilter(context, queryText, MissingQueryBuilder.DEFAULT_EXISTENCE_VALUE, MissingQueryBuilder.DEFAULT_NULL_VALUE);
-        if (query != null) {
-            return new ConstantScoreQuery(query);
-        }
-        return null;
+    public Query query(QueryParseContext parseContext, String queryText) {
+        return new ConstantScoreQuery(MissingQueryParser.newFilter(parseContext, queryText,
+                MissingQueryParser.DEFAULT_EXISTENCE_VALUE, MissingQueryParser.DEFAULT_NULL_VALUE, null));
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/ElasticsearchException.java b/core/src/main/java/org/elasticsearch/ElasticsearchException.java
index d1693e5..a9b0ba5 100644
--- a/core/src/main/java/org/elasticsearch/ElasticsearchException.java
+++ b/core/src/main/java/org/elasticsearch/ElasticsearchException.java
@@ -580,11 +580,9 @@ public class ElasticsearchException extends RuntimeException implements ToXConte
                 org.elasticsearch.index.engine.RecoveryEngineException.class,
                 org.elasticsearch.common.blobstore.BlobStoreException.class,
                 org.elasticsearch.index.snapshots.IndexShardRestoreException.class,
-                org.elasticsearch.index.query.QueryShardException.class,
                 org.elasticsearch.index.query.QueryParsingException.class,
                 org.elasticsearch.action.support.replication.TransportReplicationAction.RetryOnPrimaryException.class,
                 org.elasticsearch.index.engine.DeleteByQueryFailedEngineException.class,
-                org.elasticsearch.index.engine.ForceMergeFailedEngineException.class,
                 org.elasticsearch.discovery.MasterNotDiscoveredException.class,
                 org.elasticsearch.action.support.broadcast.BroadcastShardOperationFailedException.class,
                 org.elasticsearch.node.NodeClosedException.class,
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java
index 549ce8f..846612d 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java
@@ -74,7 +74,7 @@ public class TransportOptimizeAction extends TransportBroadcastByNodeAction<Opti
     }
 
     @Override
-    protected EmptyResult shardOperation(OptimizeRequest request, ShardRouting shardRouting) {
+    protected EmptyResult shardOperation(OptimizeRequest request, ShardRouting shardRouting) throws IOException {
         IndexShard indexShard = indicesService.indexServiceSafe(shardRouting.shardId().getIndex()).shardSafe(shardRouting.shardId().id());
         indexShard.optimize(request);
         return EmptyResult.INSTANCE;
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
index 11bc190..80e146b 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
@@ -119,7 +119,7 @@ public class TransportUpgradeAction extends TransportBroadcastByNodeAction<Upgra
     }
 
     @Override
-    protected ShardUpgradeResult shardOperation(UpgradeRequest request, ShardRouting shardRouting) {
+    protected ShardUpgradeResult shardOperation(UpgradeRequest request, ShardRouting shardRouting) throws IOException {
         IndexShard indexShard = indicesService.indexServiceSafe(shardRouting.shardId().getIndex()).shardSafe(shardRouting.shardId().id());
         org.apache.lucene.util.Version oldestLuceneSegment = indexShard.upgrade(request);
         // We are using the current version of Elasticsearch as upgrade version since we update mapping to match the current version
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
index d73e0d2..6fefa0d 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
@@ -42,7 +42,6 @@ import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.query.IndexQueryParserService;
-import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.indices.IndicesService;
@@ -189,8 +188,8 @@ public class TransportValidateQueryAction extends TransportBroadcastAction<Valid
             }
             if (request.rewrite()) {
                 explanation = getRewrittenQuery(searcher.searcher(), searchContext.query());
-            }
-        } catch (QueryShardException|QueryParsingException e) {
+            }   
+        } catch (QueryParsingException e) {
             valid = false;
             error = e.getDetailedMessage();
         } catch (AssertionError|IOException e) {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java
index 515ecd1..4acdfdc 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequestBuilder.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.action.admin.indices.validate.query;
 
+import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.QuerySourceBuilder;
 import org.elasticsearch.action.support.broadcast.BroadcastOperationRequestBuilder;
 import org.elasticsearch.client.ElasticsearchClient;
diff --git a/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java b/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
index 6995859..d9c89e7 100644
--- a/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
@@ -41,7 +41,7 @@ import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.IndexService;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.script.ScriptService;
@@ -166,10 +166,10 @@ public class TransportExistsAction extends TransportBroadcastAction<ExistsReques
             BytesReference source = request.querySource();
             if (source != null && source.length() > 0) {
                 try {
-                    QueryShardContext.setTypes(request.types());
+                    QueryParseContext.setTypes(request.types());
                     context.parsedQuery(indexService.queryParserService().parseQuery(source));
                 } finally {
-                    QueryShardContext.removeTypes();
+                    QueryParseContext.removeTypes();
                 }
             }
             context.preProcess();
diff --git a/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java
index ccdfb23..f636534 100644
--- a/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java
@@ -715,13 +715,8 @@ public class SearchRequestBuilder extends ActionRequestBuilder<SearchRequest, Se
         return this;
     }
 
-    public SearchRequestBuilder addParentChildInnerHits(String name, String type,  InnerHitsBuilder.InnerHit innerHit) {
-        innerHitsBuilder().addParentChildInnerHits(name, type, innerHit);
-        return this;
-    }
-
-    public SearchRequestBuilder addNestedInnerHits(String name, String path,  InnerHitsBuilder.InnerHit innerHit) {
-        innerHitsBuilder().addNestedInnerHits(name, path, innerHit);
+    public SearchRequestBuilder addInnerHit(String name, InnerHitsBuilder.InnerHit innerHit) {
+        innerHitsBuilder().addInnerHit(name, innerHit);
         return this;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/action/support/TransportActions.java b/core/src/main/java/org/elasticsearch/action/support/TransportActions.java
index c05486d..950596c 100644
--- a/core/src/main/java/org/elasticsearch/action/support/TransportActions.java
+++ b/core/src/main/java/org/elasticsearch/action/support/TransportActions.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.action.support;
 
+import org.apache.lucene.store.AlreadyClosedException;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.action.NoShardAvailableActionException;
 import org.elasticsearch.action.UnavailableShardsException;
@@ -36,7 +37,8 @@ public class TransportActions {
                 actual instanceof IndexNotFoundException ||
                 actual instanceof IllegalIndexShardStateException ||
                 actual instanceof NoShardAvailableActionException ||
-                actual instanceof UnavailableShardsException) {
+                actual instanceof UnavailableShardsException ||
+                actual instanceof AlreadyClosedException) {
             return true;
         }
         return false;
diff --git a/core/src/main/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java b/core/src/main/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java
index 06c10b4..846121e 100644
--- a/core/src/main/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java
+++ b/core/src/main/java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java
@@ -181,7 +181,7 @@ public abstract class TransportBroadcastByNodeAction<Request extends BroadcastRe
      * @param shardRouting the shard on which to execute the operation
      * @return the result of the shard-level operation for the shard
      */
-    protected abstract ShardOperationResult shardOperation(Request request, ShardRouting shardRouting);
+    protected abstract ShardOperationResult shardOperation(Request request, ShardRouting shardRouting) throws IOException;
 
     /**
      * Determines the shards on which this operation will be executed on. The operation is executed once per shard.
diff --git a/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsRequest.java b/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsRequest.java
index 46fe199..cbc1b47 100644
--- a/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsRequest.java
@@ -640,7 +640,7 @@ public class TermVectorsRequest extends SingleShardRequest<TermVectorsRequest> i
         }
     }
 
-    private static Map<String, String> readPerFieldAnalyzer(Map<String, Object> map) {
+    public static Map<String, String> readPerFieldAnalyzer(Map<String, Object> map) {
         Map<String, String> mapStrStr = new HashMap<>();
         for (Map.Entry<String, Object> e : map.entrySet()) {
             if (e.getValue() instanceof String) {
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
index bf37fc2..b73045a 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
@@ -164,7 +164,7 @@ final class Bootstrap {
                 .put(InternalSettingsPreparer.IGNORE_SYSTEM_PROPERTIES_SETTING, true)
                 .build();
 
-        NodeBuilder nodeBuilder = NodeBuilder.nodeBuilder().settings(nodeSettings).loadConfigSettings(false);
+        NodeBuilder nodeBuilder = NodeBuilder.nodeBuilder().settings(nodeSettings);
         node = nodeBuilder.build();
     }
     
@@ -195,9 +195,9 @@ final class Bootstrap {
         }
     }
 
-    private static Tuple<Settings, Environment> initialSettings(boolean foreground) {
+    private static Environment initialSettings(boolean foreground) {
         Terminal terminal = foreground ? Terminal.DEFAULT : null;
-        return InternalSettingsPreparer.prepareSettings(EMPTY_SETTINGS, true, terminal);
+        return InternalSettingsPreparer.prepareEnvironment(EMPTY_SETTINGS, terminal);
     }
 
     private void start() {
@@ -234,9 +234,8 @@ final class Bootstrap {
             foreground = false;
         }
 
-        Tuple<Settings, Environment> tuple = initialSettings(foreground);
-        Settings settings = tuple.v1();
-        Environment environment = tuple.v2();
+        Environment environment = initialSettings(foreground);
+        Settings settings = environment.settings();
 
         if (environment.pidFile() != null) {
             PidFile.create(environment.pidFile(), true);
diff --git a/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java b/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java
index 9d35fab..c56124f 100644
--- a/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java
+++ b/core/src/main/java/org/elasticsearch/client/transport/TransportClient.java
@@ -85,7 +85,6 @@ public class TransportClient extends AbstractClient {
 
         private Settings settings = Settings.EMPTY;
         private List<Class<? extends Plugin>> pluginClasses = new ArrayList<>();
-        private boolean loadConfigSettings = true;
 
         /**
          * The settings to configure the transport client with.
@@ -103,15 +102,6 @@ public class TransportClient extends AbstractClient {
         }
 
         /**
-         * Should the transport client load file based configuration automatically or not (and rely
-         * only on the provided settings), defaults to true.
-         */
-        public Builder loadConfigSettings(boolean loadConfigSettings) {
-            this.loadConfigSettings = loadConfigSettings;
-            return this;
-        }
-
-        /**
          * Add the given plugin to the client when it is created.
          */
         public Builder addPlugin(Class<? extends Plugin> pluginClass) {
@@ -123,17 +113,16 @@ public class TransportClient extends AbstractClient {
          * Builds a new instance of the transport client.
          */
         public TransportClient build() {
-            Tuple<Settings, Environment> tuple = InternalSettingsPreparer.prepareSettings(settings, loadConfigSettings);
-            Settings settings = settingsBuilder()
+            Settings settings = InternalSettingsPreparer.prepareSettings(this.settings);
+            settings = settingsBuilder()
                     .put(NettyTransport.PING_SCHEDULE, "5s") // enable by default the transport schedule ping interval
-                    .put(tuple.v1())
+                    .put(settings)
                     .put("network.server", false)
                     .put("node.client", true)
                     .put(CLIENT_TYPE_SETTING, CLIENT_TYPE)
                     .build();
-            Environment environment = tuple.v2();
 
-            PluginsService pluginsService = new PluginsService(settings, tuple.v2(), pluginClasses);
+            PluginsService pluginsService = new PluginsService(settings, null, pluginClasses);
             this.settings = pluginsService.updatedSettings();
 
             Version version = Version.CURRENT;
@@ -149,7 +138,6 @@ public class TransportClient extends AbstractClient {
                     modules.add(pluginModule);
                 }
                 modules.add(new PluginsModule(pluginsService));
-                modules.add(new EnvironmentModule(environment));
                 modules.add(new SettingsModule(this.settings));
                 modules.add(new NetworkModule());
                 modules.add(new ClusterNameModule(this.settings));
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java
index d5b398c..f12824d 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasValidator.java
@@ -28,7 +28,7 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.query.IndexQueryParserService;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.indices.InvalidAliasNameException;
 
 import java.io.IOException;
@@ -142,10 +142,10 @@ public class AliasValidator extends AbstractComponent {
     }
 
     private void validateAliasFilter(XContentParser parser, IndexQueryParserService indexQueryParserService) throws IOException {
-        QueryShardContext context = indexQueryParserService.getShardContext();
+        QueryParseContext context = indexQueryParserService.getParseContext();
         try {
             context.reset(parser);
-            context.parseContext().parseInnerFilter();
+            context.parseInnerFilter();
         } finally {
             context.reset(null);
             parser.close();
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
index 5839502..9177697 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataMappingService.java
@@ -399,7 +399,7 @@ public class MetaDataMappingService extends AbstractComponent {
                                 // For example in MapperService we can't distinguish between a create index api call
                                 // and a put mapping api call, so we don't which type did exist before.
                                 // Also the order of the mappings may be backwards.
-                                if (Version.indexCreated(indexService.getIndexSettings()).onOrAfter(Version.V_2_0_0_beta1) && newMapper.parentFieldMapper().active()) {
+                                if (newMapper.parentFieldMapper().active()) {
                                     IndexMetaData indexMetaData = currentState.metaData().index(index);
                                     for (ObjectCursor<MappingMetaData> mapping : indexMetaData.mappings().values()) {
                                         if (newMapper.parentFieldMapper().type().equals(mapping.value.type())) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodeFilters.java b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodeFilters.java
index 2ac98dc..ab7da4b 100644
--- a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodeFilters.java
+++ b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodeFilters.java
@@ -19,9 +19,12 @@
 
 package org.elasticsearch.cluster.node;
 
+import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.network.NetworkAddress;
 import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.transport.InetSocketTransportAddress;
 
 import java.util.HashMap;
 import java.util.Map;
@@ -64,21 +67,72 @@ public class DiscoveryNodeFilters {
         this.filters = filters;
     }
 
+    private boolean matchByIP(String[] values, @Nullable String hostIp, @Nullable String publishIp) {
+        for (String value : values) {
+            boolean matchIp = Regex.simpleMatch(value, hostIp) || Regex.simpleMatch(value, publishIp);
+            if (matchIp) {
+                return matchIp;
+            }
+        }
+        return false;
+    }
+
     public boolean match(DiscoveryNode node) {
         for (Map.Entry<String, String[]> entry : filters.entrySet()) {
             String attr = entry.getKey();
             String[] values = entry.getValue();
             if ("_ip".equals(attr)) {
-                for (String value : values) {
-                    if (Regex.simpleMatch(value, node.getHostAddress())) {
-                        if (opType == OpType.OR) {
-                            return true;
-                        }
-                    } else {
-                        if (opType == OpType.AND) {
-                            return false;
-                        }
+                // We check both the host_ip or the publish_ip
+                String publishAddress = null;
+                if (node.address() instanceof InetSocketTransportAddress) {
+                    publishAddress = NetworkAddress.format(((InetSocketTransportAddress) node.address()).address().getAddress());
+                }
+
+                boolean match = matchByIP(values, node.getHostAddress(), publishAddress);
+
+                if (opType == OpType.AND) {
+                    if (match) {
+                        // If we match, we can check to the next filter
+                        continue;
+                    }
+                    return false;
+                }
+
+                if (match && opType == OpType.OR) {
+                    return true;
+                }
+            } else if ("_host_ip".equals(attr)) {
+                // We check explicitly only the host_ip
+                boolean match = matchByIP(values, node.getHostAddress(), null);
+                if (opType == OpType.AND) {
+                    if (match) {
+                        // If we match, we can check to the next filter
+                        continue;
                     }
+                    return false;
+                }
+
+                if (match && opType == OpType.OR) {
+                    return true;
+                }
+            } else if ("_publish_ip".equals(attr)) {
+                // We check explicitly only the publish_ip
+                String address = null;
+                if (node.address() instanceof InetSocketTransportAddress) {
+                    address = NetworkAddress.format(((InetSocketTransportAddress) node.address()).address().getAddress());
+                }
+
+                boolean match = matchByIP(values, address, null);
+                if (opType == OpType.AND) {
+                    if (match) {
+                        // If we match, we can check to the next filter
+                        continue;
+                    }
+                    return false;
+                }
+
+                if (match && opType == OpType.OR) {
+                    return true;
                 }
             } else if ("_host".equals(attr)) {
                 for (String value : values) {
@@ -171,7 +225,7 @@ public class DiscoveryNodeFilters {
             for (String value : values) {
                 sb.append(value);
                 if (valueCount > 1) {
-                    sb.append(" " + opType.toString() + " ");
+                    sb.append(" ").append(opType.toString()).append(" ");
                 }
                 valueCount--;
             }
diff --git a/core/src/main/java/org/elasticsearch/common/cli/CliTool.java b/core/src/main/java/org/elasticsearch/common/cli/CliTool.java
index b3533b5..d264232 100644
--- a/core/src/main/java/org/elasticsearch/common/cli/CliTool.java
+++ b/core/src/main/java/org/elasticsearch/common/cli/CliTool.java
@@ -104,9 +104,8 @@ public abstract class CliTool {
         Preconditions.checkArgument(config.cmds().size() != 0, "At least one command must be configured");
         this.config = config;
         this.terminal = terminal;
-        Tuple<Settings, Environment> tuple = InternalSettingsPreparer.prepareSettings(EMPTY_SETTINGS, true, terminal);
-        settings = tuple.v1();
-        env = tuple.v2();
+        env = InternalSettingsPreparer.prepareEnvironment(EMPTY_SETTINGS, terminal);
+        settings = env.settings();
     }
 
     public final ExitStatus execute(String... args) {
diff --git a/core/src/main/java/org/elasticsearch/common/geo/XShapeCollection.java b/core/src/main/java/org/elasticsearch/common/geo/XShapeCollection.java
index 28d7227..2cc4a09 100644
--- a/core/src/main/java/org/elasticsearch/common/geo/XShapeCollection.java
+++ b/core/src/main/java/org/elasticsearch/common/geo/XShapeCollection.java
@@ -36,10 +36,20 @@ import java.util.List;
  */
 public class XShapeCollection<S extends Shape> extends ShapeCollection<S> {
 
+  private boolean pointsOnly = false;
+
   public XShapeCollection(List<S> shapes, SpatialContext ctx) {
     super(shapes, ctx);
   }
 
+  public boolean pointsOnly() {
+    return this.pointsOnly;
+  }
+
+  public void setPointsOnly(boolean pointsOnly) {
+    this.pointsOnly = pointsOnly;
+  }
+
   @Override
   protected Rectangle computeBoundingBox(Collection<? extends Shape> shapes, SpatialContext ctx) {
     Rectangle retBox = shapes.iterator().next().getBoundingBox();
diff --git a/core/src/main/java/org/elasticsearch/common/geo/builders/MultiPointBuilder.java b/core/src/main/java/org/elasticsearch/common/geo/builders/MultiPointBuilder.java
index 23a7b9a..5a9aaa9 100644
--- a/core/src/main/java/org/elasticsearch/common/geo/builders/MultiPointBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/geo/builders/MultiPointBuilder.java
@@ -51,7 +51,9 @@ public class MultiPointBuilder extends PointCollection<MultiPointBuilder> {
         for (Coordinate coord : points) {
             shapes.add(SPATIAL_CONTEXT.makePoint(coord.x, coord.y));
         }
-        return new XShapeCollection<>(shapes, SPATIAL_CONTEXT);
+        XShapeCollection multiPoints = new XShapeCollection<>(shapes, SPATIAL_CONTEXT);
+        multiPoints.setPointsOnly(true);
+        return multiPoints;
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/geo/builders/ShapeBuilder.java b/core/src/main/java/org/elasticsearch/common/geo/builders/ShapeBuilder.java
index bfb4109..e33d63a 100644
--- a/core/src/main/java/org/elasticsearch/common/geo/builders/ShapeBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/geo/builders/ShapeBuilder.java
@@ -27,7 +27,6 @@ import com.vividsolutions.jts.geom.Coordinate;
 import com.vividsolutions.jts.geom.Geometry;
 import com.vividsolutions.jts.geom.GeometryFactory;
 import org.elasticsearch.ElasticsearchParseException;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.ESLoggerFactory;
 import org.elasticsearch.common.unit.DistanceUnit.Distance;
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java b/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java
index 5f3bd01..0dac786 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/FilterStreamInput.java
@@ -68,4 +68,4 @@ public abstract class FilterStreamInput extends StreamInput {
     public void setVersion(Version version) {
         delegate.setVersion(version);
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
index c2bbaa3..1b22a69 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
@@ -33,7 +33,6 @@ import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.text.StringAndBytesText;
 import org.elasticsearch.common.text.Text;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.joda.time.DateTime;
 import org.joda.time.DateTimeZone;
 
@@ -46,18 +45,8 @@ import static org.elasticsearch.ElasticsearchException.readStackTrace;
 
 public abstract class StreamInput extends InputStream {
 
-    private final NamedWriteableRegistry namedWriteableRegistry;
-
     private Version version = Version.CURRENT;
 
-    protected StreamInput() {
-        this.namedWriteableRegistry = new NamedWriteableRegistry();
-    }
-
-    protected StreamInput(NamedWriteableRegistry namedWriteableRegistry) {
-        this.namedWriteableRegistry = namedWriteableRegistry;
-    }
-
     public Version getVersion() {
         return this.version;
     }
@@ -572,13 +561,6 @@ public abstract class StreamInput extends InputStream {
         throw new UnsupportedOperationException();
     }
 
-    /**
-     * Reads a {@link QueryBuilder} from the current stream
-     */
-    public QueryBuilder readQuery() throws IOException {
-        return readNamedWriteable(QueryBuilder.class);
-    }
-
     public static StreamInput wrap(BytesReference reference) {
         if (reference.hasArray() == false) {
             reference = reference.toBytesArray();
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java b/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
index a808919..536af8b 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
@@ -31,7 +31,6 @@ import org.elasticsearch.Version;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.text.Text;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.joda.time.ReadableInstant;
 
 import java.io.EOFException;
@@ -570,11 +569,4 @@ public abstract class StreamOutput extends OutputStream {
         writeString(namedWriteable.getWriteableName());
         namedWriteable.writeTo(this);
     }
-
-    /**
-     * Writes a {@link QueryBuilder} to the current stream
-     */
-    public void writeQuery(QueryBuilder queryBuilder) throws IOException {
-        writeNamedWriteable(queryBuilder);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java b/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java
index 2e86bef..21c4cdd 100644
--- a/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java
+++ b/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java
@@ -40,6 +40,7 @@ import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 
+import static org.elasticsearch.common.Strings.cleanPath;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 
 /**
@@ -87,6 +88,7 @@ public class LogConfigurator {
             return;
         }
         loaded = true;
+        // TODO: this is partly a copy of InternalSettingsPreparer...we should pass in Environment and not do all this...
         Environment environment = new Environment(settings);
         Settings.Builder settingsBuilder = settingsBuilder().put(settings);
         resolveConfig(environment, settingsBuilder);
@@ -109,6 +111,8 @@ public class LogConfigurator {
                 props.setProperty(key, value);
             }
         }
+        // ensure explicit path to logs dir exists
+        props.setProperty("log4j.path.logs", cleanPath(environment.logsFile().toAbsolutePath().toString()));
         PropertyConfigurator.configure(props);
     }
 
@@ -116,11 +120,11 @@ public class LogConfigurator {
      * sets the loaded flag to false so that logging configuration can be
      * overridden. Should only be used in tests.
      */
-    public static void reset() {
+    static void reset() {
         loaded = false;
     }
 
-    public static void resolveConfig(Environment env, final Settings.Builder settingsBuilder) {
+    static void resolveConfig(Environment env, final Settings.Builder settingsBuilder) {
 
         try {
             Files.walkFileTree(env.configFile(), EnumSet.of(FileVisitOption.FOLLOW_LINKS), Integer.MAX_VALUE, new SimpleFileVisitor<Path>() {
@@ -143,7 +147,7 @@ public class LogConfigurator {
         }
     }
 
-    public static void loadConfig(Path file, Settings.Builder settingsBuilder) {
+    static void loadConfig(Path file, Settings.Builder settingsBuilder) {
         try {
             settingsBuilder.loadFromPath(file);
         } catch (SettingsException | NoClassDefFoundError e) {
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/MoreLikeThisQuery.java b/core/src/main/java/org/elasticsearch/common/lucene/search/MoreLikeThisQuery.java
index 2084b67..cdfa9ad 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/MoreLikeThisQuery.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/MoreLikeThisQuery.java
@@ -253,12 +253,12 @@ public class MoreLikeThisQuery extends Query {
         setLikeText(likeText.toArray(Strings.EMPTY_ARRAY));
     }
 
-    public void setUnlikeText(Fields... ignoreFields) {
-        this.unlikeFields = ignoreFields;
+    public void setUnlikeText(Fields... unlikeFields) {
+        this.unlikeFields = unlikeFields;
     }
 
-    public void setIgnoreText(List<String> ignoreText) {
-        this.unlikeText = ignoreText.toArray(Strings.EMPTY_ARRAY);
+    public void setUnlikeText(List<String> unlikeText) {
+        this.unlikeText = unlikeText.toArray(Strings.EMPTY_ARRAY);
     }
 
     public String[] getMoreLikeFields() {
diff --git a/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java b/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
index bc48042..cfcd209 100644
--- a/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
+++ b/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
@@ -19,26 +19,22 @@
 package org.elasticsearch.common.unit;
 
 import com.google.common.base.Preconditions;
-
+import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.util.automaton.LevenshteinAutomata;
 import org.elasticsearch.common.ParseField;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentBuilderString;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
-import java.util.Locale;
-import java.util.Objects;
 
 /**
  * A unit class that encapsulates all in-exact search
  * parsing and conversion from similarities to edit distances
  * etc.
  */
-public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
+public final class Fuzziness implements ToXContent {
 
     public static final XContentBuilderString X_FIELD_NAME = new XContentBuilderString("fuzziness");
     public static final Fuzziness ZERO = new Fuzziness(0);
@@ -49,20 +45,13 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
 
     private final String fuzziness;
 
-    /** the prototype constant is intended for deserialization when used with
-     * {@link org.elasticsearch.common.io.stream.StreamableReader#readFrom(StreamInput)} */
-    static final Fuzziness PROTOTYPE = AUTO;
-
     private Fuzziness(int fuzziness) {
         Preconditions.checkArgument(fuzziness >= 0 && fuzziness <= 2, "Valid edit distances are [0, 1, 2] but was [" + fuzziness + "]");
         this.fuzziness = Integer.toString(fuzziness);
     }
 
     private Fuzziness(String fuzziness) {
-        if (fuzziness == null) {
-            throw new IllegalArgumentException("fuzziness can't be null!");
-        }
-        this.fuzziness = fuzziness.toUpperCase(Locale.ROOT);
+        this.fuzziness = fuzziness;
     }
 
     /**
@@ -132,7 +121,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public int asDistance(String text) {
-        if (this.equals(AUTO)) { //AUTO
+        if (this == AUTO) { //AUTO
             final int len = termLen(text);
             if (len <= 2) {
                 return 0;
@@ -146,7 +135,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public TimeValue asTimeValue() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return TimeValue.timeValueMillis(1);
         } else {
             return TimeValue.parseTimeValue(fuzziness.toString(), null, "fuzziness");
@@ -154,7 +143,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public long asLong() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -165,7 +154,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public int asInt() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -176,7 +165,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public short asShort() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -187,7 +176,7 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public byte asByte() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1;
         }
         try {
@@ -198,14 +187,14 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     }
 
     public double asDouble() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1d;
         }
         return Double.parseDouble(fuzziness.toString());
     }
 
     public float asFloat() {
-        if (this.equals(AUTO)) {
+        if (this == AUTO) {
             return 1f;
         }
         return Float.parseFloat(fuzziness.toString());
@@ -218,35 +207,4 @@ public final class Fuzziness implements ToXContent, Writeable<Fuzziness> {
     public String asString() {
         return fuzziness.toString();
     }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (obj == null || getClass() != obj.getClass()) {
-            return false;
-        }
-        Fuzziness other = (Fuzziness) obj;
-        return Objects.equals(fuzziness, other.fuzziness);
-    }
-
-    @Override
-    public int hashCode() {
-        return fuzziness.hashCode();
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeString(fuzziness);
-    }
-
-    @Override
-    public Fuzziness readFrom(StreamInput in) throws IOException {
-        return new Fuzziness(in.readString());
-    }
-
-    public static Fuzziness readFuzzinessFrom(StreamInput in) throws IOException {
-        return PROTOTYPE.readFrom(in);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/util/ExtensionPoint.java b/core/src/main/java/org/elasticsearch/common/util/ExtensionPoint.java
index 1ec8eb7..a5878e1 100644
--- a/core/src/main/java/org/elasticsearch/common/util/ExtensionPoint.java
+++ b/core/src/main/java/org/elasticsearch/common/util/ExtensionPoint.java
@@ -145,7 +145,11 @@ public abstract class ExtensionPoint {
             if (instance == null) {
                 throw new IllegalArgumentException("Unknown [" + this.name + "] type [" + type + "]");
             }
-            binder.bind(extensionClass).to(instance).asEagerSingleton();
+            if (extensionClass == instance) {
+                binder.bind(extensionClass).asEagerSingleton();
+            } else {
+                binder.bind(extensionClass).to(instance).asEagerSingleton();
+            }
             return type;
         }
 
diff --git a/core/src/main/java/org/elasticsearch/gateway/Gateway.java b/core/src/main/java/org/elasticsearch/gateway/Gateway.java
index 2910027..249243c 100644
--- a/core/src/main/java/org/elasticsearch/gateway/Gateway.java
+++ b/core/src/main/java/org/elasticsearch/gateway/Gateway.java
@@ -32,7 +32,6 @@ import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.env.NodeEnvironment;
 
-
 import java.nio.file.Path;
 
 /**
@@ -73,30 +72,8 @@ public class Gateway extends AbstractComponent implements ClusterStateListener {
         TransportNodesListGatewayMetaState.NodesGatewayMetaState nodesState = listGatewayMetaState.list(nodesIds.toArray(String.class), null).actionGet();
 
 
-        int requiredAllocation = 1;
-        try {
-            if ("quorum".equals(initialMeta)) {
-                if (nodesIds.size() > 2) {
-                    requiredAllocation = (nodesIds.size() / 2) + 1;
-                }
-            } else if ("quorum-1".equals(initialMeta) || "half".equals(initialMeta)) {
-                if (nodesIds.size() > 2) {
-                    requiredAllocation = ((1 + nodesIds.size()) / 2);
-                }
-            } else if ("one".equals(initialMeta)) {
-                requiredAllocation = 1;
-            } else if ("full".equals(initialMeta) || "all".equals(initialMeta)) {
-                requiredAllocation = nodesIds.size();
-            } else if ("full-1".equals(initialMeta) || "all-1".equals(initialMeta)) {
-                if (nodesIds.size() > 1) {
-                    requiredAllocation = nodesIds.size() - 1;
-                }
-            } else {
-                requiredAllocation = Integer.parseInt(initialMeta);
-            }
-        } catch (Exception e) {
-            logger.warn("failed to derived initial_meta from value {}", initialMeta);
-        }
+        int requiredAllocation = calcRequiredAllocations(this.initialMeta, nodesIds.size());
+
 
         if (nodesState.failures().length > 0) {
             for (FailedNodeException failedNodeException : nodesState.failures()) {
@@ -163,6 +140,34 @@ public class Gateway extends AbstractComponent implements ClusterStateListener {
         listener.onSuccess(builder.build());
     }
 
+    protected int calcRequiredAllocations(final String setting, final int nodeCount) {
+        int requiredAllocation = 1;
+        try {
+            if ("quorum".equals(setting)) {
+                if (nodeCount > 2) {
+                    requiredAllocation = (nodeCount / 2) + 1;
+                }
+            } else if ("quorum-1".equals(setting) || "half".equals(setting)) {
+                if (nodeCount > 2) {
+                    requiredAllocation = ((1 + nodeCount) / 2);
+                }
+            } else if ("one".equals(setting)) {
+                requiredAllocation = 1;
+            } else if ("full".equals(setting) || "all".equals(setting)) {
+                requiredAllocation = nodeCount;
+            } else if ("full-1".equals(setting) || "all-1".equals(setting)) {
+                if (nodeCount > 1) {
+                    requiredAllocation = nodeCount - 1;
+                }
+            } else {
+                requiredAllocation = Integer.parseInt(setting);
+            }
+        } catch (Exception e) {
+            logger.warn("failed to derived initial_meta from value {}", setting);
+        }
+        return requiredAllocation;
+    }
+
     public void reset() throws Exception {
         try {
             Path[] dataPaths = nodeEnv.nodeDataPaths();
diff --git a/core/src/main/java/org/elasticsearch/gateway/GatewayModule.java b/core/src/main/java/org/elasticsearch/gateway/GatewayModule.java
index 9378302..3402488 100644
--- a/core/src/main/java/org/elasticsearch/gateway/GatewayModule.java
+++ b/core/src/main/java/org/elasticsearch/gateway/GatewayModule.java
@@ -19,19 +19,38 @@
 
 package org.elasticsearch.gateway;
 
-import org.elasticsearch.common.inject.*;
+import org.elasticsearch.common.inject.AbstractModule;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.ExtensionPoint;
 
 /**
  *
  */
 public class GatewayModule extends AbstractModule {
 
+    public static final String GATEWAY_TYPE_KEY = "gateway.type";
+
+    private final ExtensionPoint.SelectedType<Gateway> gatewayTypes = new ExtensionPoint.SelectedType<>("gateway", Gateway.class);
+    private final Settings settings;
+
+    public GatewayModule(Settings settings) {
+        this.settings = settings;
+        registerGatewayType("default", Gateway.class);
+    }
+
+    /**
+     * Adds a custom Discovery type.
+     */
+    public void registerGatewayType(String type, Class<? extends Gateway> clazz) {
+        gatewayTypes.registerExtension(type, clazz);
+    }
+
     @Override
     protected void configure() {
         bind(MetaStateService.class).asEagerSingleton();
         bind(DanglingIndicesState.class).asEagerSingleton();
         bind(GatewayService.class).asEagerSingleton();
-        bind(Gateway.class).asEagerSingleton();
+        gatewayTypes.bindType(binder(), settings, GATEWAY_TYPE_KEY, "default");
         bind(TransportNodesListGatewayMetaState.class).asEagerSingleton();
         bind(GatewayMetaState.class).asEagerSingleton();
         bind(TransportNodesListGatewayStartedShards.class).asEagerSingleton();
diff --git a/core/src/main/java/org/elasticsearch/index/engine/Engine.java b/core/src/main/java/org/elasticsearch/index/engine/Engine.java
index 071a00b..54cbcca 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/Engine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/Engine.java
@@ -502,14 +502,14 @@ public abstract class Engine implements Closeable {
     /**
      * Optimizes to 1 segment
      */
-    public void forceMerge(boolean flush) {
+    public void forceMerge(boolean flush) throws IOException {
         forceMerge(flush, 1, false, false, false);
     }
 
     /**
      * Triggers a forced merge on this engine
      */
-    public abstract void forceMerge(boolean flush, int maxNumSegments, boolean onlyExpungeDeletes, boolean upgrade, boolean upgradeOnlyAncientSegments) throws EngineException;
+    public abstract void forceMerge(boolean flush, int maxNumSegments, boolean onlyExpungeDeletes, boolean upgrade, boolean upgradeOnlyAncientSegments) throws EngineException, IOException;
 
     /**
      * Snapshots the index and returns a handle to it. If needed will try and "commit" the
diff --git a/core/src/main/java/org/elasticsearch/index/engine/ForceMergeFailedEngineException.java b/core/src/main/java/org/elasticsearch/index/engine/ForceMergeFailedEngineException.java
deleted file mode 100644
index 7aac909..0000000
--- a/core/src/main/java/org/elasticsearch/index/engine/ForceMergeFailedEngineException.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.engine;
-
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.index.shard.ShardId;
-
-import java.io.IOException;
-
-/**
- *
- */
-public class ForceMergeFailedEngineException extends EngineException {
-
-    public ForceMergeFailedEngineException(ShardId shardId, Throwable t) {
-        super(shardId, "force merge failed", t);
-    }
-
-    public ForceMergeFailedEngineException(StreamInput in) throws IOException{
-        super(in);
-    }
-}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
index 054b0b1..45f7801 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
@@ -45,6 +45,7 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.InfoStream;
 import org.elasticsearch.ElasticsearchException;
+import org.elasticsearch.action.support.TransportActions;
 import org.elasticsearch.cluster.routing.DjbHashFunction;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.lease.Releasable;
@@ -755,9 +756,10 @@ public class InternalEngine extends Engine {
                         logger.trace("starting commit for flush; commitTranslog=true");
                         commitIndexWriter(indexWriter, translog);
                         logger.trace("finished commit for flush");
-                        translog.commit();
                         // we need to refresh in order to clear older version values
                         refresh("version_table_flush");
+                        // after refresh documents can be retrieved from the index so we can now commit the translog
+                        translog.commit();
                     } catch (Throwable e) {
                         throw new FlushFailedEngineException(shardId, e);
                     }
@@ -823,7 +825,7 @@ public class InternalEngine extends Engine {
 
     @Override
     public void forceMerge(final boolean flush, int maxNumSegments, boolean onlyExpungeDeletes,
-                           final boolean upgrade, final boolean upgradeOnlyAncientSegments) throws EngineException {
+                           final boolean upgrade, final boolean upgradeOnlyAncientSegments) throws EngineException, EngineClosedException, IOException {
         /*
          * We do NOT acquire the readlock here since we are waiting on the merges to finish
          * that's fine since the IW.rollback should stop all the threads and trigger an IOException
@@ -865,9 +867,8 @@ public class InternalEngine extends Engine {
                 store.decRef();
             }
         } catch (Throwable t) {
-            ForceMergeFailedEngineException ex = new ForceMergeFailedEngineException(shardId, t);
-            maybeFailEngine("force merge", ex);
-            throw ex;
+            maybeFailEngine("force merge", t);
+            throw t;
         } finally {
             try {
                 mp.setUpgradeInProgress(false, false); // reset it just to make sure we reset it in a case of an error
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java b/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java
index 8f69e87..ef2f964 100644
--- a/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java
+++ b/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java
@@ -245,16 +245,6 @@ public class IndexFieldDataService extends AbstractIndexComponent {
                 }
                 fieldDataCaches.put(fieldNames.indexName(), cache);
             }
-
-            // Remove this in 3.0
-            final boolean isOldParentField = ParentFieldMapper.NAME.equals(fieldNames.indexName())
-                    && Version.indexCreated(indexSettings).before(Version.V_2_0_0_beta1);
-            if (isOldParentField) {
-                if (parentIndexFieldData == null) {
-                    parentIndexFieldData = builder.build(index, indexSettings, fieldType, cache, circuitBreakerService, mapperService);
-                }
-                return (IFD) parentIndexFieldData;
-            }
         }
 
         return (IFD) builder.build(index, indexSettings, fieldType, cache, circuitBreakerService, mapperService);
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildAtomicFieldData.java b/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildAtomicFieldData.java
deleted file mode 100644
index 468c3fe..0000000
--- a/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildAtomicFieldData.java
+++ /dev/null
@@ -1,93 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.fielddata.plain;
-
-import com.carrotsearch.hppc.cursors.ObjectCursor;
-
-import org.apache.lucene.index.DocValues;
-import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.util.Accountable;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
-import org.elasticsearch.index.fielddata.AtomicOrdinalsFieldData;
-import org.elasticsearch.search.MultiValueMode;
-
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.Set;
-
-/**
- */
-public class ParentChildAtomicFieldData extends AbstractAtomicParentChildFieldData {
-
-    private final ImmutableOpenMap<String, AtomicOrdinalsFieldData> typeToIds;
-    private final long memorySizeInBytes;
-
-    public ParentChildAtomicFieldData(ImmutableOpenMap<String, AtomicOrdinalsFieldData> typeToIds) {
-        this.typeToIds = typeToIds;
-        long size = 0;
-        for (ObjectCursor<AtomicOrdinalsFieldData> cursor : typeToIds.values()) {
-            size += cursor.value.ramBytesUsed();
-        }
-        this.memorySizeInBytes = size;
-    }
-
-    @Override
-    public long ramBytesUsed() {
-        return memorySizeInBytes;
-    }
-
-    @Override
-    public Collection<Accountable> getChildResources() {
-        // TODO: should we break down by type?
-        // the current 'map' does not impl java.util.Map so we cant use Accountables.namedAccountables...
-        return Collections.emptyList();
-    }
-
-    @Override
-    public Set<String> types() {
-        final Set<String> types = new HashSet<>();
-        for (ObjectCursor<String> cursor : typeToIds.keys()) {
-            types.add(cursor.value);
-        }
-        return types;
-    }
-
-    @Override
-    public SortedDocValues getOrdinalsValues(String type) {
-        AtomicOrdinalsFieldData atomicFieldData = typeToIds.get(type);
-        if (atomicFieldData != null) {
-            return MultiValueMode.MIN.select(atomicFieldData.getOrdinalsValues());
-        } else {
-            return DocValues.emptySorted();
-        }
-    }
-
-    public AtomicOrdinalsFieldData getAtomicFieldData(String type) {
-        return typeToIds.get(type);
-    }
-
-    @Override
-    public void close() {
-        for (ObjectCursor<AtomicOrdinalsFieldData> cursor : typeToIds.values()) {
-            cursor.value.close();
-        }
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildFilteredTermsEnum.java b/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildFilteredTermsEnum.java
deleted file mode 100644
index cda6481..0000000
--- a/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildFilteredTermsEnum.java
+++ /dev/null
@@ -1,84 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.fielddata.plain;
-
-import org.apache.lucene.index.FilteredTermsEnum;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.index.mapper.Uid;
-
-import java.io.IOException;
-import java.util.NavigableSet;
-
-/**
- * Only emits terms that exist in the parentTypes set.
- *
- * @elasticsearch.internal
- */
-final class ParentChildFilteredTermsEnum extends FilteredTermsEnum {
-
-    private final NavigableSet<BytesRef> parentTypes;
-
-    private BytesRef seekTerm;
-    private String type;
-    private BytesRef id;
-
-    ParentChildFilteredTermsEnum(TermsEnum tenum, NavigableSet<BytesRef> parentTypes) {
-        super(tenum, true);
-        this.parentTypes = parentTypes;
-        this.seekTerm = parentTypes.isEmpty() ? null : parentTypes.first();
-    }
-
-    @Override
-    protected BytesRef nextSeekTerm(BytesRef currentTerm) throws IOException {
-        BytesRef temp = seekTerm;
-        seekTerm = null;
-        return temp;
-    }
-
-    @Override
-    protected AcceptStatus accept(BytesRef term) throws IOException {
-        if (parentTypes.isEmpty()) {
-            return AcceptStatus.END;
-        }
-
-        BytesRef[] typeAndId = Uid.splitUidIntoTypeAndId(term);
-        if (parentTypes.contains(typeAndId[0])) {
-            type = typeAndId[0].utf8ToString();
-            id = typeAndId[1];
-            return AcceptStatus.YES;
-        } else {
-            BytesRef nextType = parentTypes.ceiling(typeAndId[0]);
-            if (nextType == null) {
-                return AcceptStatus.END;
-            }
-            seekTerm = nextType;
-            return AcceptStatus.NO_AND_SEEK;
-        }
-    }
-
-    public String type() {
-        return type;
-    }
-
-    public BytesRef id() {
-        return id;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIndexFieldData.java b/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIndexFieldData.java
index ae7d498..eebcf4a 100644
--- a/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIndexFieldData.java
+++ b/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIndexFieldData.java
@@ -67,36 +67,24 @@ import java.util.concurrent.TimeUnit;
  * ParentChildIndexFieldData is responsible for loading the id cache mapping
  * needed for has_child and has_parent queries into memory.
  */
-public class ParentChildIndexFieldData extends AbstractIndexFieldData<AtomicParentChildFieldData> implements IndexParentChildFieldData, DocumentTypeListener {
+public class ParentChildIndexFieldData extends AbstractIndexFieldData<AtomicParentChildFieldData> implements IndexParentChildFieldData {
 
-    private final NavigableSet<String> parentTypes;
+    private final Set<String> parentTypes;
     private final CircuitBreakerService breakerService;
 
-    // If child type (a type with _parent field) is added or removed, we want to make sure modifications don't happen
-    // while loading.
-    private final Object lock = new Object();
-
     public ParentChildIndexFieldData(Index index, @IndexSettings Settings indexSettings, MappedFieldType.Names fieldNames,
                                      FieldDataType fieldDataType, IndexFieldDataCache cache, MapperService mapperService,
                                      CircuitBreakerService breakerService) {
         super(index, indexSettings, fieldNames, fieldDataType, cache);
         this.breakerService = breakerService;
-        if (Version.indexCreated(indexSettings).before(Version.V_2_0_0_beta1)) {
-            parentTypes = new TreeSet<>();
-            for (DocumentMapper documentMapper : mapperService.docMappers(false)) {
-                beforeCreate(documentMapper);
-            }
-            mapperService.addTypeListener(this);
-        } else {
-            ImmutableSortedSet.Builder<String> builder = ImmutableSortedSet.naturalOrder();
-            for (DocumentMapper mapper : mapperService.docMappers(false)) {
-                ParentFieldMapper parentFieldMapper = mapper.parentFieldMapper();
-                if (parentFieldMapper.active()) {
-                    builder.add(parentFieldMapper.type());
-                }
+        Set<String> parentTypes = new HashSet<>();
+        for (DocumentMapper mapper : mapperService.docMappers(false)) {
+            ParentFieldMapper parentFieldMapper = mapper.parentFieldMapper();
+            if (parentFieldMapper.active()) {
+                parentTypes.add(parentFieldMapper.type());
             }
-            parentTypes = builder.build();
         }
+        this.parentTypes = parentTypes;
     }
 
     @Override
@@ -106,158 +94,47 @@ public class ParentChildIndexFieldData extends AbstractIndexFieldData<AtomicPare
 
     @Override
     public AtomicParentChildFieldData load(LeafReaderContext context) {
-        if (Version.indexCreated(indexSettings).onOrAfter(Version.V_2_0_0_beta1)) {
-            final LeafReader reader = context.reader();
-            return new AbstractAtomicParentChildFieldData() {
-
-                public Set<String> types() {
-                    return parentTypes;
-                }
-
-                @Override
-                public SortedDocValues getOrdinalsValues(String type) {
-                    try {
-                        return DocValues.getSorted(reader, ParentFieldMapper.joinField(type));
-                    } catch (IOException e) {
-                        throw new IllegalStateException("cannot load join doc values field for type [" + type + "]", e);
-                    }
-                }
+        final LeafReader reader = context.reader();
+        return new AbstractAtomicParentChildFieldData() {
 
-                @Override
-                public long ramBytesUsed() {
-                    // unknown
-                    return 0;
-                }
-
-                @Override
-                public Collection<Accountable> getChildResources() {
-                    return Collections.emptyList();
-                }
+            public Set<String> types() {
+                return parentTypes;
+            }
 
-                @Override
-                public void close() throws ElasticsearchException {
-                }
-            };
-        } else {
-            try {
-                return cache.load(context, this);
-            } catch (Throwable e) {
-                if (e instanceof ElasticsearchException) {
-                    throw (ElasticsearchException) e;
-                } else {
-                    throw new ElasticsearchException(e.getMessage(), e);
+            @Override
+            public SortedDocValues getOrdinalsValues(String type) {
+                try {
+                    return DocValues.getSorted(reader, ParentFieldMapper.joinField(type));
+                } catch (IOException e) {
+                    throw new IllegalStateException("cannot load join doc values field for type [" + type + "]", e);
                 }
             }
-        }
-    }
 
-    @Override
-    public AbstractAtomicParentChildFieldData loadDirect(LeafReaderContext context) throws Exception {
-        // Make this method throw an UnsupportedOperationException in 3.0, only
-        // needed for indices created BEFORE 2.0
-        LeafReader reader = context.reader();
-        final float acceptableTransientOverheadRatio = fieldDataType.getSettings().getAsFloat(
-                "acceptable_transient_overhead_ratio", OrdinalsBuilder.DEFAULT_ACCEPTABLE_OVERHEAD_RATIO
-        );
-
-        final NavigableSet<BytesRef> parentTypes = new TreeSet<>();
-        synchronized (lock) {
-            for (String parentType : this.parentTypes) {
-                parentTypes.add(new BytesRef(parentType));
+            @Override
+            public long ramBytesUsed() {
+                // unknown
+                return 0;
             }
-        }
-        boolean success = false;
-        ParentChildAtomicFieldData data = null;
-        ParentChildFilteredTermsEnum termsEnum = new ParentChildFilteredTermsEnum(
-                new ParentChildIntersectTermsEnum(reader, UidFieldMapper.NAME, ParentFieldMapper.NAME),
-                parentTypes
-        );
-        ParentChildEstimator estimator = new ParentChildEstimator(breakerService.getBreaker(CircuitBreaker.FIELDDATA), termsEnum);
-        TermsEnum estimatedTermsEnum = estimator.beforeLoad(null);
-        ObjectObjectHashMap<String, TypeBuilder> typeBuilders = new ObjectObjectHashMap<>();
-        try {
-            try {
-                PostingsEnum docsEnum = null;
-                for (BytesRef term = estimatedTermsEnum.next(); term != null; term = estimatedTermsEnum.next()) {
-                    // Usually this would be estimatedTermsEnum, but the
-                    // abstract TermsEnum class does not support the .type()
-                    // and .id() methods, so we skip using the wrapped
-                    // TermsEnum and delegate directly to the
-                    // ParentChildFilteredTermsEnum that was originally wrapped
-                    String type = termsEnum.type();
-                    TypeBuilder typeBuilder = typeBuilders.get(type);
-                    if (typeBuilder == null) {
-                        typeBuilders.put(type, typeBuilder = new TypeBuilder(acceptableTransientOverheadRatio, reader));
-                    }
 
-                    BytesRef id = termsEnum.id();
-                    final long termOrd = typeBuilder.builder.nextOrdinal();
-                    assert termOrd == typeBuilder.termOrdToBytesOffset.size();
-                    typeBuilder.termOrdToBytesOffset.add(typeBuilder.bytes.copyUsingLengthPrefix(id));
-                    docsEnum = estimatedTermsEnum.postings(docsEnum, PostingsEnum.NONE);
-                    for (int docId = docsEnum.nextDoc(); docId != DocIdSetIterator.NO_MORE_DOCS; docId = docsEnum.nextDoc()) {
-                        typeBuilder.builder.addDoc(docId);
-                    }
-                }
-
-                ImmutableOpenMap.Builder<String, AtomicOrdinalsFieldData> typeToAtomicFieldData = ImmutableOpenMap.builder(typeBuilders.size());
-                for (ObjectObjectCursor<String, TypeBuilder> cursor : typeBuilders) {
-                    PagedBytes.Reader bytesReader = cursor.value.bytes.freeze(true);
-                    final Ordinals ordinals = cursor.value.builder.build(fieldDataType.getSettings());
-
-                    typeToAtomicFieldData.put(
-                            cursor.key,
-                            new PagedBytesAtomicFieldData(bytesReader, cursor.value.termOrdToBytesOffset.build(), ordinals)
-                    );
-                }
-                data = new ParentChildAtomicFieldData(typeToAtomicFieldData.build());
-            } finally {
-                for (ObjectObjectCursor<String, TypeBuilder> cursor : typeBuilders) {
-                    cursor.value.builder.close();
-                }
+            @Override
+            public Collection<Accountable> getChildResources() {
+                return Collections.emptyList();
             }
-            success = true;
-            return data;
-        } finally {
-            if (success) {
-                estimator.afterLoad(estimatedTermsEnum, data.ramBytesUsed());
-            } else {
-                estimator.afterLoad(estimatedTermsEnum, 0);
+
+            @Override
+            public void close() throws ElasticsearchException {
             }
-        }
+        };
     }
 
     @Override
-    public void beforeCreate(DocumentMapper mapper) {
-        // Remove in 3.0
-        synchronized (lock) {
-            ParentFieldMapper parentFieldMapper = mapper.parentFieldMapper();
-            if (parentFieldMapper.active()) {
-                // A _parent field can never be added to an existing mapping, so a _parent field either exists on
-                // a new created or doesn't exists. This is why we can update the known parent types via DocumentTypeListener
-                if (parentTypes.add(parentFieldMapper.type())) {
-                    clear();
-                }
-            }
-        }
+    public AbstractAtomicParentChildFieldData loadDirect(LeafReaderContext context) throws Exception {
+        throw new UnsupportedOperationException();
     }
 
     @Override
     protected AtomicParentChildFieldData empty(int maxDoc) {
-        return new ParentChildAtomicFieldData(ImmutableOpenMap.<String, AtomicOrdinalsFieldData>of());
-    }
-
-    class TypeBuilder {
-
-        final PagedBytes bytes;
-        final PackedLongValues.Builder termOrdToBytesOffset;
-        final OrdinalsBuilder builder;
-
-        TypeBuilder(float acceptableTransientOverheadRatio, LeafReader reader) throws IOException {
-            bytes = new PagedBytes(15);
-            termOrdToBytesOffset = PackedLongValues.monotonicBuilder(PackedInts.COMPACT);
-            builder = new OrdinalsBuilder(-1, reader.maxDoc(), acceptableTransientOverheadRatio);
-        }
+        return AbstractAtomicParentChildFieldData.empty();
     }
 
     public static class Builder implements IndexFieldData.Builder {
@@ -267,56 +144,7 @@ public class ParentChildIndexFieldData extends AbstractIndexFieldData<AtomicPare
                                        IndexFieldDataCache cache, CircuitBreakerService breakerService,
                                        MapperService mapperService) {
             return new ParentChildIndexFieldData(index, indexSettings, fieldType.names(), fieldType.fieldDataType(), cache,
-                mapperService, breakerService);
-        }
-    }
-
-    /**
-     * Estimator that wraps parent/child id field data by wrapping the data
-     * in a RamAccountingTermsEnum.
-     */
-    public class ParentChildEstimator implements PerValueEstimator {
-
-        private final CircuitBreaker breaker;
-        private final TermsEnum filteredEnum;
-
-        // The TermsEnum is passed in here instead of being generated in the
-        // beforeLoad() function since it's filtered inside the previous
-        // TermsEnum wrappers
-        public ParentChildEstimator(CircuitBreaker breaker, TermsEnum filteredEnum) {
-            this.breaker = breaker;
-            this.filteredEnum = filteredEnum;
-        }
-
-        /**
-         * General overhead for ids is 2 times the length of the ID
-         */
-        @Override
-        public long bytesPerValue(BytesRef term) {
-            if (term == null) {
-                return 0;
-            }
-            return 2 * term.length;
-        }
-
-        /**
-         * Wraps the already filtered {@link TermsEnum} in a
-         * {@link RamAccountingTermsEnum} and returns it
-         */
-        @Override
-        public TermsEnum beforeLoad(Terms terms) throws IOException {
-            return new RamAccountingTermsEnum(filteredEnum, breaker, this, "parent/child id cache");
-        }
-
-        /**
-         * Adjusts the breaker based on the difference between the actual usage
-         * and the aggregated estimations.
-         */
-        @Override
-        public void afterLoad(TermsEnum termsEnum, long actualUsed) {
-            assert termsEnum instanceof RamAccountingTermsEnum;
-            long estimatedBytes = ((RamAccountingTermsEnum) termsEnum).getTotalBytes();
-            breaker.addWithoutBreaking(-(estimatedBytes - actualUsed));
+                    mapperService, breakerService);
         }
     }
 
@@ -358,14 +186,6 @@ public class ParentChildIndexFieldData extends AbstractIndexFieldData<AtomicPare
     @Override
     public IndexParentChildFieldData localGlobalDirect(IndexReader indexReader) throws Exception {
         final long startTime = System.nanoTime();
-        final Set<String> parentTypes;
-        if (Version.indexCreated(indexSettings).before(Version.V_2_0_0_beta1)) {
-            synchronized (lock) {
-                parentTypes = ImmutableSet.copyOf(this.parentTypes);
-            }
-        } else {
-            parentTypes = this.parentTypes;
-        }
 
         long ramBytesUsed = 0;
         final Map<String, OrdinalMapAndAtomicFieldData> perType = new HashMap<>();
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIntersectTermsEnum.java b/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIntersectTermsEnum.java
deleted file mode 100644
index d02b161..0000000
--- a/core/src/main/java/org/elasticsearch/index/fielddata/plain/ParentChildIntersectTermsEnum.java
+++ /dev/null
@@ -1,335 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.fielddata.plain;
-
-import com.carrotsearch.hppc.IntArrayList;
-
-import org.apache.lucene.index.*;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.util.BytesRef;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Iterator;
-import java.util.List;
-
-/**
- * Intersects the terms and unions the doc ids for terms enum of multiple fields.
- *
- * @elasticsearch.internal
- */
-final class ParentChildIntersectTermsEnum extends TermsEnum {
-
-    private final List<TermsEnumState> states;
-    private final IntArrayList stateSlots;
-
-    private BytesRef current;
-
-    ParentChildIntersectTermsEnum(LeafReader atomicReader, String... fields) throws IOException {
-        List<TermsEnum> fieldEnums = new ArrayList<>();
-        for (String field : fields) {
-            Terms terms = atomicReader.terms(field);
-            if (terms != null) {
-                fieldEnums.add(terms.iterator());
-            }
-        }
-        states = new ArrayList<>(fieldEnums.size());
-        for (TermsEnum tEnum : fieldEnums) {
-            states.add(new TermsEnumState(tEnum));
-        }
-        stateSlots = new IntArrayList(states.size());
-    }
-
-    @Override
-    public BytesRef term() throws IOException {
-        return current;
-    }
-
-    @Override
-    public PostingsEnum postings(PostingsEnum reuse, int flags) throws IOException {
-        int size = stateSlots.size();
-        assert size > 0;
-        if (size == 1) {
-            // Can't use 'reuse' since we don't know to which previous TermsEnum it belonged to.
-            return states.get(stateSlots.get(0)).termsEnum.postings(null, flags);
-        } else {
-            List<PostingsEnum> docsEnums = new ArrayList<>(stateSlots.size());
-            for (int i = 0; i < stateSlots.size(); i++) {
-                docsEnums.add(states.get(stateSlots.get(i)).termsEnum.postings(null, flags));
-            }
-            return new CompoundDocsEnum(docsEnums);
-        }
-    }
-
-    @Override
-    public BytesRef next() throws IOException {
-        if (states.isEmpty()) {
-            return null;
-        }
-
-        if (current == null) {
-            // unpositioned
-            for (TermsEnumState state : states) {
-                state.initialize();
-            }
-        } else {
-            int removed = 0;
-            for (int i = 0; i < stateSlots.size(); i++) {
-                int stateSlot = stateSlots.get(i);
-                if (states.get(stateSlot - removed).next() == null) {
-                    states.remove(stateSlot - removed);
-                    removed++;
-                }
-            }
-
-            if (states.isEmpty()) {
-                return null;
-            }
-            stateSlots.clear();
-        }
-
-        BytesRef lowestTerm = states.get(0).term;
-        stateSlots.add(0);
-        for (int i = 1; i < states.size(); i++) {
-            TermsEnumState state = states.get(i);
-            int cmp = lowestTerm.compareTo(state.term);
-            if (cmp > 0) {
-                lowestTerm = state.term;
-                stateSlots.clear();
-                stateSlots.add(i);
-            } else if (cmp == 0) {
-                stateSlots.add(i);
-            }
-        }
-
-        return current = lowestTerm;
-    }
-
-    @Override
-    public SeekStatus seekCeil(BytesRef text) throws IOException {
-        if (states.isEmpty()) {
-            return SeekStatus.END;
-        }
-
-        boolean found  = false;
-        if (current == null) {
-            // unpositioned
-            Iterator<TermsEnumState> iterator = states.iterator();
-            while (iterator.hasNext()) {
-                SeekStatus seekStatus = iterator.next().seekCeil(text);
-                if (seekStatus == SeekStatus.END) {
-                    iterator.remove();
-                } else if (seekStatus == SeekStatus.FOUND) {
-                    found = true;
-                }
-            }
-        } else {
-            int removed = 0;
-            for (int i = 0; i < stateSlots.size(); i++) {
-                int stateSlot = stateSlots.get(i);
-                SeekStatus seekStatus = states.get(stateSlot - removed).seekCeil(text);
-                if (seekStatus == SeekStatus.END) {
-                    states.remove(stateSlot - removed);
-                    removed++;
-                } else if (seekStatus == SeekStatus.FOUND) {
-                    found = true;
-                }
-            }
-        }
-
-        if (states.isEmpty()) {
-            return SeekStatus.END;
-        }
-        stateSlots.clear();
-
-        if (found) {
-            for (int i = 0; i < states.size(); i++) {
-                if (states.get(i).term.equals(text)) {
-                    stateSlots.add(i);
-                }
-            }
-            current = text;
-            return SeekStatus.FOUND;
-        } else {
-            BytesRef lowestTerm = states.get(0).term;
-            stateSlots.add(0);
-            for (int i = 1; i < states.size(); i++) {
-                TermsEnumState state = states.get(i);
-                int cmp = lowestTerm.compareTo(state.term);
-                if (cmp > 0) {
-                    lowestTerm = state.term;
-                    stateSlots.clear();
-                    stateSlots.add(i);
-                } else if (cmp == 0) {
-                    stateSlots.add(i);
-                }
-            }
-            current = lowestTerm;
-            return SeekStatus.NOT_FOUND;
-        }
-    }
-
-    class TermsEnumState {
-
-        final TermsEnum termsEnum;
-        BytesRef term;
-        SeekStatus lastSeekStatus;
-
-        TermsEnumState(TermsEnum termsEnum) {
-            this.termsEnum = termsEnum;
-        }
-
-        void initialize() throws IOException {
-            term = termsEnum.next();
-        }
-
-        BytesRef next() throws IOException {
-            return term = termsEnum.next();
-        }
-
-        SeekStatus seekCeil(BytesRef text) throws IOException {
-            lastSeekStatus = termsEnum.seekCeil(text);
-            if (lastSeekStatus != SeekStatus.END) {
-                term = termsEnum.term();
-            }
-            return lastSeekStatus;
-        }
-    }
-
-    class CompoundDocsEnum extends PostingsEnum {
-
-        final List<State> states;
-        int current = -1;
-
-        CompoundDocsEnum(List<PostingsEnum> docsEnums) {
-            this.states = new ArrayList<>(docsEnums.size());
-            for (PostingsEnum docsEnum : docsEnums) {
-                states.add(new State(docsEnum));
-            }
-        }
-
-        @Override
-        public int freq() throws IOException {
-            throw new UnsupportedOperationException();
-        }
-
-        @Override
-        public int docID() {
-            return current;
-        }
-
-        @Override
-        public int nextDoc() throws IOException {
-            if (states.isEmpty()) {
-                return current = NO_MORE_DOCS;
-            }
-
-            if (current == -1) {
-                for (State state : states) {
-                    state.initialize();
-                }
-            }
-
-            int lowestIndex = 0;
-            int lowestDocId = states.get(0).current;
-            for (int i = 1; i < states.size(); i++) {
-                State state = states.get(i);
-                if (lowestDocId > state.current) {
-                    lowestDocId = state.current;
-                    lowestIndex = i;
-                }
-            }
-
-            if (states.get(lowestIndex).next() == DocIdSetIterator.NO_MORE_DOCS) {
-                states.remove(lowestIndex);
-            }
-
-            return current = lowestDocId;
-        }
-
-        @Override
-        public int advance(int target) throws IOException {
-            throw new UnsupportedOperationException();
-        }
-
-        @Override
-        public long cost() {
-            throw new UnsupportedOperationException();
-        }
-
-        @Override
-        public int endOffset() throws IOException {
-            throw new UnsupportedOperationException();
-        }
-
-        @Override
-        public BytesRef getPayload() throws IOException {
-            throw new UnsupportedOperationException();
-        }
-
-        @Override
-        public int nextPosition() throws IOException {
-            throw new UnsupportedOperationException();
-        }
-
-        @Override
-        public int startOffset() throws IOException {
-            throw new UnsupportedOperationException();
-        }
-
-        class State {
-
-            final PostingsEnum docsEnum;
-            int current = -1;
-
-            State(PostingsEnum docsEnum) {
-                this.docsEnum = docsEnum;
-            }
-
-            void initialize() throws IOException {
-                current = docsEnum.nextDoc();
-            }
-
-            int next() throws IOException {
-                return current = docsEnum.nextDoc();
-            }
-        }
-    }
-
-    @Override
-    public long ord() throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public void seekExact(long ord) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public int docFreq() throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public long totalTermFreq() throws IOException {
-        throw new UnsupportedOperationException();
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java
index ff90dd7..6534bca 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java
@@ -113,7 +113,7 @@ public class DocumentMapper implements ToXContent {
             this.rootMappers.put(TimestampFieldMapper.class, new TimestampFieldMapper(indexSettings, mapperService.fullName(TimestampFieldMapper.NAME)));
             this.rootMappers.put(TTLFieldMapper.class, new TTLFieldMapper(indexSettings));
             this.rootMappers.put(VersionFieldMapper.class, new VersionFieldMapper(indexSettings));
-            this.rootMappers.put(ParentFieldMapper.class, new ParentFieldMapper(indexSettings, mapperService.fullName(ParentFieldMapper.NAME)));
+            this.rootMappers.put(ParentFieldMapper.class, new ParentFieldMapper(indexSettings, mapperService.fullName(ParentFieldMapper.NAME), /* parent type */builder.name()));
             // _field_names last so that it can see all other fields
             this.rootMappers.put(FieldNamesFieldMapper.class, new FieldNamesFieldMapper(indexSettings, mapperService.fullName(FieldNamesFieldMapper.NAME)));
         }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java
index 33281dc..e0e4051 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java
@@ -147,8 +147,8 @@ public class DocumentMapperParser {
         }
     }
 
-    public Mapper.TypeParser.ParserContext parserContext() {
-        return new Mapper.TypeParser.ParserContext(analysisService, similarityLookupService, mapperService, typeParsers, indexVersionCreated, parseFieldMatcher);
+    public Mapper.TypeParser.ParserContext parserContext(String type) {
+        return new Mapper.TypeParser.ParserContext(type, analysisService, similarityLookupService, mapperService, typeParsers, indexVersionCreated, parseFieldMatcher);
     }
 
     public DocumentMapper parse(String source) throws MapperParsingException {
@@ -206,7 +206,7 @@ public class DocumentMapperParser {
         }
 
 
-        Mapper.TypeParser.ParserContext parserContext = parserContext();
+        Mapper.TypeParser.ParserContext parserContext = parserContext(type);
         // parse RootObjectMapper
         DocumentMapper.Builder docBuilder = doc(indexSettings, (RootObjectMapper.Builder) rootObjectTypeParser.parse(type, mapping, parserContext), mapperService);
         // Add default mapping for the plugged-in meta mappers
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java b/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
index 2e1f9df..1d34e4e 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/MappedFieldType.java
@@ -33,7 +33,7 @@ import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.index.analysis.NamedAnalyzer;
 import org.elasticsearch.index.fielddata.FieldDataType;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.similarity.SimilarityProvider;
 
 import java.io.IOException;
@@ -437,7 +437,7 @@ public abstract class MappedFieldType extends FieldType {
     }
 
     /**
-     * Should the field query {@link #termQuery(Object, org.elasticsearch.index.query.QueryShardContext)}  be used when detecting this
+     * Should the field query {@link #termQuery(Object, org.elasticsearch.index.query.QueryParseContext)}  be used when detecting this
      * field in query string.
      */
     public boolean useTermQueryWithQueryString() {
@@ -449,11 +449,11 @@ public abstract class MappedFieldType extends FieldType {
         return new Term(names().indexName(), indexedValueForSearch(value));
     }
 
-    public Query termQuery(Object value, @Nullable QueryShardContext context) {
+    public Query termQuery(Object value, @Nullable QueryParseContext context) {
         return new TermQuery(createTerm(value));
     }
 
-    public Query termsQuery(List values, @Nullable QueryShardContext context) {
+    public Query termsQuery(List values, @Nullable QueryParseContext context) {
         BytesRef[] bytesRefs = new BytesRef[values.size()];
         for (int i = 0; i < bytesRefs.length; i++) {
             bytesRefs[i] = indexedValueForSearch(values.get(i));
@@ -472,7 +472,7 @@ public abstract class MappedFieldType extends FieldType {
         return new FuzzyQuery(createTerm(value), fuzziness.asDistance(BytesRefs.toString(value)), prefixLength, maxExpansions, transpositions);
     }
 
-    public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+    public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
         PrefixQuery query = new PrefixQuery(createTerm(value));
         if (method != null) {
             query.setRewriteMethod(method);
@@ -480,7 +480,7 @@ public abstract class MappedFieldType extends FieldType {
         return query;
     }
 
-    public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+    public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
         RegexpQuery query = new RegexpQuery(createTerm(value), flags, maxDeterminizedStates);
         if (method != null) {
             query.setRewriteMethod(method);
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/Mapper.java b/core/src/main/java/org/elasticsearch/index/mapper/Mapper.java
index eaeea7a..ab56146 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/Mapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/Mapper.java
@@ -81,6 +81,8 @@ public abstract class Mapper implements ToXContent, Iterable<Mapper> {
 
         class ParserContext {
 
+            private final String type;
+
             private final AnalysisService analysisService;
 
             private final SimilarityLookupService similarityLookupService;
@@ -93,9 +95,10 @@ public abstract class Mapper implements ToXContent, Iterable<Mapper> {
 
             private final ParseFieldMatcher parseFieldMatcher;
 
-            public ParserContext(AnalysisService analysisService, SimilarityLookupService similarityLookupService,
+            public ParserContext(String type, AnalysisService analysisService, SimilarityLookupService similarityLookupService,
                                  MapperService mapperService, ImmutableMap<String, TypeParser> typeParsers,
-                                Version indexVersionCreated, ParseFieldMatcher parseFieldMatcher) {
+                                 Version indexVersionCreated, ParseFieldMatcher parseFieldMatcher) {
+                this.type = type;
                 this.analysisService = analysisService;
                 this.similarityLookupService = similarityLookupService;
                 this.mapperService = mapperService;
@@ -104,6 +107,10 @@ public abstract class Mapper implements ToXContent, Iterable<Mapper> {
                 this.parseFieldMatcher = parseFieldMatcher;
             }
 
+            public String type() {
+                return type;
+            }
+
             public AnalysisService analysisService() {
                 return analysisService;
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
index a5496a5..1753e94 100755
--- a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
@@ -70,7 +70,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
-import java.util.function.Predicate;
 
 import static org.elasticsearch.common.collect.MapBuilder.newMapBuilder;
 
@@ -264,7 +263,7 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
             if (mapper.type().contains(",")) {
                 throw new InvalidTypeNameException("mapping type name [" + mapper.type() + "] should not include ',' in it");
             }
-            if (Version.indexCreated(indexSettings).onOrAfter(Version.V_2_0_0_beta1) && mapper.type().equals(mapper.parentFieldMapper().type())) {
+            if (mapper.type().equals(mapper.parentFieldMapper().type())) {
                 throw new IllegalArgumentException("The [_parent.type] option can't point to the same type");
             }
             if (typeNameStartsWithIllegalDot(mapper)) {
@@ -556,7 +555,7 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
         final ImmutableMap<String, MappedFieldType> unmappedFieldMappers = this.unmappedFieldTypes;
         MappedFieldType fieldType = unmappedFieldMappers.get(type);
         if (fieldType == null) {
-            final Mapper.TypeParser.ParserContext parserContext = documentMapperParser().parserContext();
+            final Mapper.TypeParser.ParserContext parserContext = documentMapperParser().parserContext(type);
             Mapper.TypeParser typeParser = parserContext.typeParser(type);
             if (typeParser == null) {
                 throw new IllegalArgumentException("No mapper found for type [" + type + "]");
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/default-mapping.json b/core/src/main/java/org/elasticsearch/index/mapper/default-mapping.json
deleted file mode 100644
index 7b035a3..0000000
--- a/core/src/main/java/org/elasticsearch/index/mapper/default-mapping.json
+++ /dev/null
@@ -1,4 +0,0 @@
-{
-    "_default_":{
-    }
-}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapper.java
index c28285f..4179508 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapper.java
@@ -18,7 +18,9 @@
  */
 package org.elasticsearch.index.mapper.geo;
 
+import com.spatial4j.core.shape.Point;
 import com.spatial4j.core.shape.Shape;
+import com.spatial4j.core.shape.jts.JtsGeometry;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.spatial.prefix.PrefixTreeStrategy;
@@ -38,6 +40,7 @@ import org.elasticsearch.common.geo.builders.ShapeBuilder.Orientation;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.DistanceUnit;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.support.XContentMapValues;
 import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.Mapper;
@@ -85,12 +88,14 @@ public class GeoShapeFieldMapper extends FieldMapper {
         public static final String DISTANCE_ERROR_PCT = "distance_error_pct";
         public static final String ORIENTATION = "orientation";
         public static final String STRATEGY = "strategy";
+        public static final String STRATEGY_POINTS_ONLY = "points_only";
         public static final String COERCE = "coerce";
     }
 
     public static class Defaults {
         public static final String TREE = Names.TREE_GEOHASH;
         public static final String STRATEGY = SpatialStrategy.RECURSIVE.getStrategyName();
+        public static final boolean POINTS_ONLY = false;
         public static final int GEOHASH_LEVELS = GeoUtils.geoHashLevelsForPrecision("50m");
         public static final int QUADTREE_LEVELS = GeoUtils.quadTreeLevelsForPrecision("50m");
         public static final double LEGACY_DISTANCE_ERROR_PCT = 0.025d;
@@ -143,7 +148,7 @@ public class GeoShapeFieldMapper extends FieldMapper {
         public GeoShapeFieldMapper build(BuilderContext context) {
             GeoShapeFieldType geoShapeFieldType = (GeoShapeFieldType)fieldType;
 
-            if (geoShapeFieldType.tree.equals("quadtree") && context.indexCreatedVersion().before(Version.V_2_0_0_beta1)) {
+            if (geoShapeFieldType.tree.equals(Names.TREE_QUADTREE) && context.indexCreatedVersion().before(Version.V_2_0_0_beta1)) {
                 geoShapeFieldType.setTree("legacyquadtree");
             }
 
@@ -188,6 +193,9 @@ public class GeoShapeFieldMapper extends FieldMapper {
                 } else if (Names.COERCE.equals(fieldName)) {
                     builder.coerce(nodeBooleanValue(fieldNode));
                     iterator.remove();
+                } else if (Names.STRATEGY_POINTS_ONLY.equals(fieldName)) {
+                    builder.fieldType().setPointsOnly(XContentMapValues.nodeBooleanValue(fieldNode));
+                    iterator.remove();
                 }
             }
             return builder;
@@ -198,6 +206,7 @@ public class GeoShapeFieldMapper extends FieldMapper {
 
         private String tree = Defaults.TREE;
         private String strategyName = Defaults.STRATEGY;
+        private boolean pointsOnly = Defaults.POINTS_ONLY;
         private int treeLevels = 0;
         private double precisionInMeters = -1;
         private Double distanceErrorPct;
@@ -215,6 +224,7 @@ public class GeoShapeFieldMapper extends FieldMapper {
             super(ref);
             this.tree = ref.tree;
             this.strategyName = ref.strategyName;
+            this.pointsOnly = ref.pointsOnly;
             this.treeLevels = ref.treeLevels;
             this.precisionInMeters = ref.precisionInMeters;
             this.distanceErrorPct = ref.distanceErrorPct;
@@ -236,13 +246,15 @@ public class GeoShapeFieldMapper extends FieldMapper {
                 defaultDistanceErrorPct == that.defaultDistanceErrorPct &&
                 Objects.equals(tree, that.tree) &&
                 Objects.equals(strategyName, that.strategyName) &&
+                pointsOnly == that.pointsOnly &&
                 Objects.equals(distanceErrorPct, that.distanceErrorPct) &&
                 orientation == that.orientation;
         }
 
         @Override
         public int hashCode() {
-            return Objects.hash(super.hashCode(), tree, strategyName, treeLevels, precisionInMeters, distanceErrorPct, defaultDistanceErrorPct, orientation);
+            return Objects.hash(super.hashCode(), tree, strategyName, pointsOnly, treeLevels, precisionInMeters, distanceErrorPct,
+                    defaultDistanceErrorPct, orientation);
         }
 
         @Override
@@ -288,6 +300,10 @@ public class GeoShapeFieldMapper extends FieldMapper {
                 conflicts.add("mapper [" + names().fullName() + "] has different [tree]");
             }
 
+            if ((pointsOnly() != other.pointsOnly())) {
+                conflicts.add("mapper [" + names().fullName() + "] has different points_only");
+            }
+
             // TODO we should allow this, but at the moment levels is used to build bookkeeping variables
             // in lucene's SpatialPrefixTree implementations, need a patch to correct that first
             if (treeLevels() != other.treeLevels()) {
@@ -333,6 +349,14 @@ public class GeoShapeFieldMapper extends FieldMapper {
             this.strategyName = strategyName;
         }
 
+        public boolean pointsOnly() {
+            return pointsOnly;
+        }
+
+        public void setPointsOnly(boolean pointsOnly) {
+            checkIfFrozen();
+            this.pointsOnly = pointsOnly;
+        }
         public int treeLevels() {
             return treeLevels;
         }
@@ -378,6 +402,7 @@ public class GeoShapeFieldMapper extends FieldMapper {
 
         public PrefixTreeStrategy resolveStrategy(String strategyName) {
             if (SpatialStrategy.RECURSIVE.getStrategyName().equals(strategyName)) {
+                recursiveStrategy.setPointsOnly(pointsOnly());
                 return recursiveStrategy;
             }
             if (SpatialStrategy.TERM.getStrategyName().equals(strategyName)) {
@@ -417,6 +442,10 @@ public class GeoShapeFieldMapper extends FieldMapper {
                 }
                 shape = shapeBuilder.build();
             }
+            if (fieldType().defaultStrategy() instanceof RecursivePrefixTreeStrategy && fieldType().pointsOnly() && !(shape instanceof Point)) {
+                throw new MapperParsingException("[{" + fieldType().names().fullName() + "}] is configured for points only but a " +
+                        ((shape instanceof JtsGeometry) ? ((JtsGeometry)shape).getGeom().getGeometryType() : shape.getClass()) + " was found");
+            }
             Field[] fields = fieldType().defaultStrategy().createIndexableFields(shape);
             if (fields == null || fields.length == 0) {
                 return null;
@@ -474,6 +503,9 @@ public class GeoShapeFieldMapper extends FieldMapper {
         if (includeDefaults || fieldType().orientation() != Defaults.ORIENTATION) {
             builder.field(Names.ORIENTATION, fieldType().orientation());
         }
+        if (includeDefaults || fieldType().pointsOnly() != GeoShapeFieldMapper.Defaults.POINTS_ONLY) {
+            builder.field(Names.STRATEGY_POINTS_ONLY, fieldType().pointsOnly());
+        }
         if (includeDefaults || coerce.explicit()) {
             builder.field("coerce", coerce.value());
         }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java
index e538a00..f872207 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/AllFieldMapper.java
@@ -40,7 +40,7 @@ import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.similarity.SimilarityLookupService;
 
 import java.io.IOException;
@@ -186,7 +186,7 @@ public class AllFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, QueryShardContext context) {
+        public Query termQuery(Object value, QueryParseContext context) {
             return queryStringTermQuery(createTerm(value));
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
index b012a45..96810ec 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
@@ -49,7 +49,7 @@ import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.Collection;
@@ -167,7 +167,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.termQuery(value, context);
             }
@@ -176,7 +176,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termsQuery(List values, @Nullable QueryShardContext context) {
+        public Query termsQuery(List values, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.termsQuery(values, context);
             }
@@ -184,7 +184,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+        public Query prefixQuery(String value, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.prefixQuery(value, method, context);
             }
@@ -201,7 +201,7 @@ public class IdFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryShardContext context) {
+        public Query regexpQuery(String value, int flags, int maxDeterminizedStates, @Nullable MultiTermQuery.RewriteMethod method, @Nullable QueryParseContext context) {
             if (indexOptions() != IndexOptions.NONE || context == null) {
                 return super.regexpQuery(value, flags, maxDeterminizedStates, method, context);
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java
index 1b7168a..3f395a8 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/IndexFieldMapper.java
@@ -38,7 +38,7 @@ import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.Iterator;
@@ -157,7 +157,7 @@ public class IndexFieldMapper extends MetadataFieldMapper {
          * indices
          */
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             if (context == null) {
                 return super.termQuery(value, context);
             }
@@ -171,7 +171,7 @@ public class IndexFieldMapper extends MetadataFieldMapper {
         
 
         @Override
-        public Query termsQuery(List values, QueryShardContext context) {
+        public Query termsQuery(List values, QueryParseContext context) {
             if (context == null) {
                 return super.termsQuery(values, context);
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java
index 2c9c4b7..9d3d9d3 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/ParentFieldMapper.java
@@ -20,6 +20,7 @@ package org.elasticsearch.index.mapper.internal;
 
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.SortedDocValuesField;
+import org.apache.lucene.index.DocValuesType;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.queries.TermsQuery;
 import org.apache.lucene.search.Query;
@@ -33,16 +34,8 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.settings.loader.SettingsLoader;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.fielddata.FieldDataType;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.Mapper;
-import org.elasticsearch.index.mapper.MapperParsingException;
-import org.elasticsearch.index.mapper.MergeMappingException;
-import org.elasticsearch.index.mapper.MergeResult;
-import org.elasticsearch.index.mapper.MetadataFieldMapper;
-import org.elasticsearch.index.mapper.ParseContext;
-import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.mapper.*;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -67,6 +60,7 @@ public class ParentFieldMapper extends MetadataFieldMapper {
         public static final String NAME = ParentFieldMapper.NAME;
 
         public static final MappedFieldType FIELD_TYPE = new ParentFieldType();
+        public static final MappedFieldType JOIN_FIELD_TYPE = new ParentFieldType();
 
         static {
             FIELD_TYPE.setIndexOptions(IndexOptions.DOCS);
@@ -77,41 +71,66 @@ public class ParentFieldMapper extends MetadataFieldMapper {
             FIELD_TYPE.setSearchAnalyzer(Lucene.KEYWORD_ANALYZER);
             FIELD_TYPE.setNames(new MappedFieldType.Names(NAME));
             FIELD_TYPE.freeze();
+
+            JOIN_FIELD_TYPE.setHasDocValues(true);
+            JOIN_FIELD_TYPE.setDocValuesType(DocValuesType.SORTED);
+            JOIN_FIELD_TYPE.freeze();
         }
     }
 
     public static class Builder extends MetadataFieldMapper.Builder<Builder, ParentFieldMapper> {
 
+        private String parentType;
+
         protected String indexName;
 
-        private String type;
+        private final String documentType;
+
+        private final MappedFieldType parentJoinFieldType = Defaults.JOIN_FIELD_TYPE.clone();
 
-        public Builder() {
+        private final MappedFieldType childJoinFieldType = Defaults.JOIN_FIELD_TYPE.clone();
+
+        public Builder(String documentType) {
             super(Defaults.NAME, Defaults.FIELD_TYPE);
             this.indexName = name;
+            this.documentType = documentType;
             builder = this;
         }
 
         public Builder type(String type) {
-            this.type = type;
+            this.parentType = type;
             return builder;
         }
 
         @Override
+        public Builder fieldDataSettings(Settings fieldDataSettings) {
+            Settings settings = Settings.builder().put(childJoinFieldType.fieldDataType().getSettings()).put(fieldDataSettings).build();
+            childJoinFieldType.setFieldDataType(new FieldDataType(childJoinFieldType.fieldDataType().getType(), settings));
+            return this;
+        }
+
+        @Override
         public ParentFieldMapper build(BuilderContext context) {
-            if (type == null) {
+            if (parentType == null) {
                 throw new MapperParsingException("[_parent] field mapping must contain the [type] option");
             }
-            setupFieldType(context);
-            fieldType.setHasDocValues(context.indexCreatedVersion().onOrAfter(Version.V_2_0_0_beta1));
-            return new ParentFieldMapper(fieldType, type, context.indexSettings());
+            parentJoinFieldType.setNames(new MappedFieldType.Names(joinField(documentType)));
+            parentJoinFieldType.setFieldDataType(null);
+            childJoinFieldType.setNames(new MappedFieldType.Names(joinField(parentType)));
+            if (context.indexCreatedVersion().before(Version.V_2_0_0_beta1)) {
+                childJoinFieldType.setHasDocValues(false);
+                childJoinFieldType.setDocValuesType(DocValuesType.NONE);
+                parentJoinFieldType.setHasDocValues(false);
+                parentJoinFieldType.setDocValuesType(DocValuesType.NONE);
+            }
+            return new ParentFieldMapper(fieldType, parentJoinFieldType, childJoinFieldType, parentType, context.indexSettings());
         }
     }
 
     public static class TypeParser implements Mapper.TypeParser {
         @Override
         public Mapper.Builder parse(String name, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {
-            Builder builder = new Builder();
+            Builder builder = new Builder(parserContext.type());
             for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(); iterator.hasNext();) {
                 Map.Entry<String, Object> entry = iterator.next();
                 String fieldName = Strings.toUnderscoreCase(entry.getKey());
@@ -189,12 +208,12 @@ public class ParentFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             return termsQuery(Collections.singletonList(value), context);
         }
 
         @Override
-        public Query termsQuery(List values, @Nullable QueryShardContext context) {
+        public Query termsQuery(List values, @Nullable QueryParseContext context) {
             if (context == null) {
                 return super.termsQuery(values, context);
             }
@@ -222,25 +241,50 @@ public class ParentFieldMapper extends MetadataFieldMapper {
         }
     }
 
-    private final String type;
+    private final String parentType;
+    // determines the field data settings
+    private MappedFieldType childJoinFieldType;
+    // has no impact of field data settings, is just here for creating a join field, the parent field mapper in the child type pointing to this type determines the field data settings for this join field
+    private final MappedFieldType parentJoinFieldType;
+
+    protected ParentFieldMapper(MappedFieldType fieldType, MappedFieldType parentJoinFieldType, MappedFieldType childJoinFieldType, String parentType, Settings indexSettings) {
+        super(NAME, fieldType, Defaults.FIELD_TYPE, indexSettings);
+        this.parentType = parentType;
+        this.parentJoinFieldType = parentJoinFieldType;
+        this.parentJoinFieldType.freeze();
+        this.childJoinFieldType = childJoinFieldType;
+        if (childJoinFieldType != null) {
+            this.childJoinFieldType.freeze();
+        }
+    }
+
+    public ParentFieldMapper(Settings indexSettings, MappedFieldType existing, String parentType) {
+        this(existing == null ? Defaults.FIELD_TYPE.clone() : existing.clone(), joinFieldTypeForParentType(parentType, indexSettings), null, null, indexSettings);
+    }
+
+    private static MappedFieldType joinFieldTypeForParentType(String parentType, Settings indexSettings) {
+        MappedFieldType parentJoinFieldType = Defaults.JOIN_FIELD_TYPE.clone();
+        parentJoinFieldType.setNames(new MappedFieldType.Names(joinField(parentType)));
 
-    protected ParentFieldMapper(MappedFieldType fieldType, String type, Settings indexSettings) {
-        super(NAME, setupDocValues(indexSettings, fieldType), setupDocValues(indexSettings, Defaults.FIELD_TYPE), indexSettings);
-        this.type = type;
+        Version indexCreated = Version.indexCreated(indexSettings);
+        if (indexCreated.before(Version.V_2_0_0_beta1)) {
+            parentJoinFieldType.setHasDocValues(false);
+            parentJoinFieldType.setDocValuesType(DocValuesType.NONE);
+        }
+        parentJoinFieldType.freeze();
+        return parentJoinFieldType;
     }
 
-    public ParentFieldMapper(Settings indexSettings, MappedFieldType existing) {
-        this(existing == null ? Defaults.FIELD_TYPE.clone() : existing.clone(), null, indexSettings);
+    public MappedFieldType getParentJoinFieldType() {
+        return parentJoinFieldType;
     }
 
-    static MappedFieldType setupDocValues(Settings indexSettings, MappedFieldType fieldType) {
-        fieldType = fieldType.clone();
-        fieldType.setHasDocValues(Version.indexCreated(indexSettings).onOrAfter(Version.V_2_0_0_beta1));
-        return fieldType;
+    public MappedFieldType getChildJoinFieldType() {
+        return childJoinFieldType;
     }
 
     public String type() {
-        return type;
+        return parentType;
     }
 
     @Override
@@ -257,8 +301,8 @@ public class ParentFieldMapper extends MetadataFieldMapper {
     @Override
     protected void parseCreateField(ParseContext context, List<Field> fields) throws IOException {
         boolean parent = context.docMapper().isParent(context.type());
-        if (parent && fieldType().hasDocValues()) {
-            fields.add(createJoinField(context.type(), context.id()));
+        if (parent) {
+            addJoinFieldIfNeeded(fields, parentJoinFieldType, context.id());
         }
 
         if (!active()) {
@@ -269,10 +313,8 @@ public class ParentFieldMapper extends MetadataFieldMapper {
             // we are in the parsing of _parent phase
             String parentId = context.parser().text();
             context.sourceToParse().parent(parentId);
-            fields.add(new Field(fieldType().names().indexName(), Uid.createUid(context.stringBuilder(), type, parentId), fieldType()));
-            if (fieldType().hasDocValues()) {
-                fields.add(createJoinField(type, parentId));
-            }
+            fields.add(new Field(fieldType().names().indexName(), Uid.createUid(context.stringBuilder(), parentType, parentId), fieldType()));
+            addJoinFieldIfNeeded(fields, childJoinFieldType, parentId);
         } else {
             // otherwise, we are running it post processing of the xcontent
             String parsedParentId = context.doc().get(Defaults.NAME);
@@ -283,11 +325,9 @@ public class ParentFieldMapper extends MetadataFieldMapper {
                         throw new MapperParsingException("No parent id provided, not within the document, and not externally");
                     }
                     // we did not add it in the parsing phase, add it now
-                    fields.add(new Field(fieldType().names().indexName(), Uid.createUid(context.stringBuilder(), type, parentId), fieldType()));
-                    if (fieldType().hasDocValues()) {
-                        fields.add(createJoinField(type, parentId));
-                    }
-                } else if (parentId != null && !parsedParentId.equals(Uid.createUid(context.stringBuilder(), type, parentId))) {
+                    fields.add(new Field(fieldType().names().indexName(), Uid.createUid(context.stringBuilder(), parentType, parentId), fieldType()));
+                    addJoinFieldIfNeeded(fields, childJoinFieldType, parentId);
+                } else if (parentId != null && !parsedParentId.equals(Uid.createUid(context.stringBuilder(), parentType, parentId))) {
                     throw new MapperParsingException("Parent id mismatch, document value is [" + Uid.createUid(parsedParentId).id() + "], while external value is [" + parentId + "]");
                 }
             }
@@ -295,9 +335,10 @@ public class ParentFieldMapper extends MetadataFieldMapper {
         // we have parent mapping, yet no value was set, ignore it...
     }
 
-    private SortedDocValuesField createJoinField(String parentType, String id) {
-        String joinField = joinField(parentType);
-        return new SortedDocValuesField(joinField, new BytesRef(id));
+    private void addJoinFieldIfNeeded(List<Field> fields, MappedFieldType fieldType, String id) {
+        if (fieldType.hasDocValues()) {
+            fields.add(new SortedDocValuesField(fieldType.names().indexName(), new BytesRef(id)));
+        }
     }
 
     public static String joinField(String parentType) {
@@ -309,6 +350,10 @@ public class ParentFieldMapper extends MetadataFieldMapper {
         return CONTENT_TYPE;
     }
 
+    private boolean joinFieldHasCustomFieldDataSettings() {
+        return childJoinFieldType != null && childJoinFieldType.fieldDataType() != null && childJoinFieldType.fieldDataType().equals(Defaults.JOIN_FIELD_TYPE.fieldDataType()) == false;
+    }
+
     @Override
     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
         if (!active()) {
@@ -317,9 +362,9 @@ public class ParentFieldMapper extends MetadataFieldMapper {
         boolean includeDefaults = params.paramAsBoolean("include_defaults", false);
 
         builder.startObject(CONTENT_TYPE);
-        builder.field("type", type);
-        if (includeDefaults || hasCustomFieldDataSettings()) {
-            builder.field("fielddata", (Map) fieldType().fieldDataType().getSettings().getAsMap());
+        builder.field("type", parentType);
+        if (includeDefaults || joinFieldHasCustomFieldDataSettings()) {
+            builder.field("fielddata", (Map) childJoinFieldType.fieldDataType().getSettings().getAsMap());
         }
         builder.endObject();
         return builder;
@@ -329,8 +374,23 @@ public class ParentFieldMapper extends MetadataFieldMapper {
     public void merge(Mapper mergeWith, MergeResult mergeResult) throws MergeMappingException {
         super.merge(mergeWith, mergeResult);
         ParentFieldMapper fieldMergeWith = (ParentFieldMapper) mergeWith;
-        if (Objects.equals(type, fieldMergeWith.type) == false) {
-            mergeResult.addConflict("The _parent field's type option can't be changed: [" + type + "]->[" + fieldMergeWith.type + "]");
+        if (Objects.equals(parentType, fieldMergeWith.parentType) == false) {
+            mergeResult.addConflict("The _parent field's type option can't be changed: [" + parentType + "]->[" + fieldMergeWith.parentType + "]");
+        }
+
+        List<String> conflicts = new ArrayList<>();
+        fieldType().checkCompatibility(fieldMergeWith.fieldType(), conflicts, true); // always strict, this cannot change
+        parentJoinFieldType.checkCompatibility(fieldMergeWith.parentJoinFieldType, conflicts, true); // same here
+        if (childJoinFieldType != null) {
+            // TODO: this can be set to false when the old parent/child impl is removed, we can do eager global ordinals loading per type.
+            childJoinFieldType.checkCompatibility(fieldMergeWith.childJoinFieldType, conflicts, mergeResult.updateAllTypes() == false);
+        }
+        for (String conflict : conflicts) {
+            mergeResult.addConflict(conflict);
+        }
+
+        if (active() && mergeResult.simulate() == false && mergeResult.hasConflicts() == false) {
+            childJoinFieldType = fieldMergeWith.childJoinFieldType.clone();
         }
     }
 
@@ -338,7 +398,7 @@ public class ParentFieldMapper extends MetadataFieldMapper {
      * @return Whether the _parent field is actually configured.
      */
     public boolean active() {
-        return type != null;
+        return parentType != null;
     }
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java
index 12e40de..480d2a4 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/TypeFieldMapper.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.List;
@@ -137,7 +137,7 @@ public class TypeFieldMapper extends MetadataFieldMapper {
         }
 
         @Override
-        public Query termQuery(Object value, @Nullable QueryShardContext context) {
+        public Query termQuery(Object value, @Nullable QueryParseContext context) {
             if (indexOptions() == IndexOptions.NONE) {
                 return new ConstantScoreQuery(new PrefixQuery(new Term(UidFieldMapper.NAME, Uid.typePrefixAsBytes(BytesRefs.toBytesRef(value)))));
             }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java
index cb0815a..160c8ed 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/object/RootObjectMapper.java
@@ -245,7 +245,7 @@ public class RootObjectMapper extends ObjectMapper {
         if (dynamicTemplate == null) {
             return null;
         }
-        Mapper.TypeParser.ParserContext parserContext = context.docMapperParser().parserContext();
+        Mapper.TypeParser.ParserContext parserContext = context.docMapperParser().parserContext(name);
         String mappingType = dynamicTemplate.mappingType(dynamicType);
         Mapper.TypeParser typeParser = parserContext.typeParser(mappingType);
         if (typeParser == null) {
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/script-mapping.json b/core/src/main/java/org/elasticsearch/index/mapper/script-mapping.json
deleted file mode 100644
index 799039c..0000000
--- a/core/src/main/java/org/elasticsearch/index/mapper/script-mapping.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-     "_default_": {
-
-       "properties": {
-         "script": { "enabled": false },
-         "template": { "enabled": false }
-       }
-     }
-}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java b/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
index 19c466a..7add3d3 100644
--- a/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
+++ b/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 import org.elasticsearch.index.percolator.stats.ShardPercolateService;
 import org.elasticsearch.index.query.IndexQueryParserService;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.shard.AbstractIndexShardComponent;
@@ -185,13 +185,12 @@ public class PercolatorQueriesRegistry extends AbstractIndexShardComponent imple
         }
     }
 
-    //norelease this method parses from xcontent to lucene query, need to re-investigate how to split context here
     private Query parseQuery(String type, XContentParser parser) {
         String[] previousTypes = null;
         if (type != null) {
-            QueryShardContext.setTypesWithPrevious(new String[]{type});
+            QueryParseContext.setTypesWithPrevious(new String[]{type});
         }
-        QueryShardContext context = queryParserService.getShardContext();
+        QueryParseContext context = queryParserService.getParseContext();
         try {
             context.reset(parser);
             // This means that fields in the query need to exist in the mapping prior to registering this query
@@ -210,10 +209,10 @@ public class PercolatorQueriesRegistry extends AbstractIndexShardComponent imple
             context.setMapUnmappedFieldAsString(mapUnmappedFieldsAsString ? true : false);
             return queryParserService.parseInnerQuery(context);
         } catch (IOException e) {
-            throw new QueryParsingException(context.parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(context, "Failed to parse", e);
         } finally {
             if (type != null) {
-                QueryShardContext.setTypes(previousTypes);
+                QueryParseContext.setTypes(previousTypes);
             }
             context.reset(null);
         }
diff --git a/core/src/main/java/org/elasticsearch/index/query/AbstractQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/AbstractQueryBuilder.java
deleted file mode 100644
index a38c067..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/AbstractQueryBuilder.java
+++ /dev/null
@@ -1,328 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.action.support.ToXContentToBytes;
-import org.elasticsearch.common.ParseField;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentType;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-import java.util.Objects;
-
-/**
- * Base class for all classes producing lucene queries.
- * Supports conversion to BytesReference and creation of lucene Query objects.
- */
-public abstract class AbstractQueryBuilder<QB extends AbstractQueryBuilder> extends ToXContentToBytes implements QueryBuilder<QB> {
-
-    /** Default for boost to apply to resulting Lucene query. Defaults to 1.0*/
-    public static final float DEFAULT_BOOST = 1.0f;
-    public static final ParseField NAME_FIELD = new ParseField("_name");
-    public static final ParseField BOOST_FIELD = new ParseField("boost");
-
-    protected String queryName;
-    protected float boost = DEFAULT_BOOST;
-
-    protected AbstractQueryBuilder() {
-        super(XContentType.JSON);
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject();
-        doXContent(builder, params);
-        builder.endObject();
-        return builder;
-    }
-
-    protected abstract void doXContent(XContentBuilder builder, Params params) throws IOException;
-
-    protected void printBoostAndQueryName(XContentBuilder builder) throws IOException {
-        builder.field("boost", boost);
-        if (queryName != null) {
-            builder.field("_name", queryName);
-        }
-    }
-
-    @Override
-    public final Query toQuery(QueryShardContext context) throws IOException {
-        Query query = doToQuery(context);
-        if (query != null) {
-            setFinalBoost(query);
-            if (queryName != null) {
-                context.addNamedQuery(queryName, query);
-            }
-        }
-        return query;
-    }
-
-    /**
-     * Sets the main boost to the query obtained by converting the current query into a lucene query.
-     * The default behaviour is to set the main boost, after verifying that we are not overriding any non default boost
-     * value that was previously set to the lucene query. That case would require some manual decision on how to combine
-     * the main boost with the boost coming from lucene by overriding this method.
-     * @throws IllegalStateException if the lucene query boost has already been set
-     */
-    protected void setFinalBoost(Query query) {
-        if (query.getBoost() != AbstractQueryBuilder.DEFAULT_BOOST) {
-            throw new IllegalStateException("lucene query boost is already set, override setFinalBoost to define how to combine lucene boost with main boost");
-        }
-        query.setBoost(boost);
-    }
-
-    @Override
-    public final Query toFilter(QueryShardContext context) throws IOException {
-        Query result = null;
-            final boolean originalIsFilter = context.isFilter;
-            try {
-                context.isFilter = true;
-                result = toQuery(context);
-            } finally {
-                context.isFilter = originalIsFilter;
-            }
-        return result;
-    }
-
-    //norelease to be made abstract once all query builders override doToQuery providing their own specific implementation.
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return context.indexQueryParserService().indicesQueriesRegistry().queryParsers().get(getName()).parse(context);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // default impl does not validate, subclasses should override.
-        //norelease to be possibly made abstract once all queries support validation
-        return null;
-    }
-
-    /**
-     * Returns the query name for the query.
-     */
-    @SuppressWarnings("unchecked")
-    @Override
-    public final QB queryName(String queryName) {
-        this.queryName = queryName;
-        return (QB) this;
-    }
-
-    /**
-     * Sets the query name for the query.
-     */
-    @Override
-    public final String queryName() {
-        return queryName;
-    }
-
-    /**
-     * Returns the boost for this query.
-     */
-    @Override
-    public final float boost() {
-        return this.boost;
-    }
-
-    /**
-     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
-     * weightings) have their score multiplied by the boost provided.
-     */
-    @SuppressWarnings("unchecked")
-    @Override
-    public final QB boost(float boost) {
-        this.boost = boost;
-        return (QB) this;
-    }
-
-    @Override
-    public final QB readFrom(StreamInput in) throws IOException {
-        QB queryBuilder = doReadFrom(in);
-        queryBuilder.boost = in.readFloat();
-        queryBuilder.queryName = in.readOptionalString();
-        return queryBuilder;
-    }
-
-    //norelease make this abstract once all builders implement doReadFrom themselves
-    protected QB doReadFrom(StreamInput in) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    public final void writeTo(StreamOutput out) throws IOException {
-        doWriteTo(out);
-        out.writeFloat(boost);
-        out.writeOptionalString(queryName);
-    }
-
-    //norelease make this abstract once all builders implement doWriteTo themselves
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    protected final QueryValidationException addValidationError(String validationError, QueryValidationException validationException) {
-        return QueryValidationException.addValidationError(getName(), validationError, validationException);
-    }
-
-    @Override
-    public final boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (obj == null || getClass() != obj.getClass()) {
-            return false;
-        }
-        @SuppressWarnings("unchecked")
-        QB other = (QB) obj;
-        return Objects.equals(queryName, other.queryName) &&
-                Objects.equals(boost, other.boost) &&
-                doEquals(other);
-    }
-
-    /**
-     * Indicates whether some other {@link QueryBuilder} object of the same type is "equal to" this one.
-     */
-    //norelease to be made abstract once all queries are refactored
-    protected boolean doEquals(QB other) {
-        return super.equals(other);
-    }
-
-    @Override
-    public final int hashCode() {
-        return Objects.hash(getClass(), queryName, boost, doHashCode());
-    }
-
-    //norelease to be made abstract once all queries are refactored
-    protected int doHashCode() {
-        return super.hashCode();
-    }
-
-    /**
-     * This helper method checks if the object passed in is a string, if so it
-     * converts it to a {@link BytesRef}.
-     * @param obj the input object
-     * @return the same input object or a {@link BytesRef} representation if input was of type string
-     */
-    protected static Object convertToBytesRefIfString(Object obj) {
-        if (obj instanceof String) {
-            return BytesRefs.toBytesRef(obj);
-        }
-        return obj;
-    }
-
-    /**
-     * This helper method checks if the object passed in is a {@link BytesRef}, if so it
-     * converts it to a utf8 string.
-     * @param obj the input object
-     * @return the same input object or a utf8 string if input was of type {@link BytesRef}
-     */
-    protected static Object convertToStringIfBytesRef(Object obj) {
-        if (obj instanceof BytesRef) {
-            return ((BytesRef) obj).utf8ToString();
-        }
-        return obj;
-    }
-
-    /**
-     * Helper method to convert collection of {@link QueryBuilder} instances to lucene
-     * {@link Query} instances. {@link QueryBuilder} that return <tt>null</tt> calling
-     * their {@link QueryBuilder#toQuery(QueryShardContext)} method are not added to the
-     * resulting collection.
-     *
-     * @throws IOException
-     * @throws QueryShardException
-     */
-    protected static Collection<Query> toQueries(Collection<QueryBuilder> queryBuilders, QueryShardContext context) throws QueryShardException,
-            IOException {
-        List<Query> queries = new ArrayList<>(queryBuilders.size());
-        for (QueryBuilder queryBuilder : queryBuilders) {
-            Query query = queryBuilder.toQuery(context);
-            if (query != null) {
-                queries.add(query);
-            }
-        }
-        return queries;
-    }
-
-    protected QueryValidationException validateInnerQueries(List<QueryBuilder> queryBuilders, QueryValidationException initialValidationException) {
-        QueryValidationException validationException = initialValidationException;
-        for (QueryBuilder queryBuilder : queryBuilders) {
-            validationException = validateInnerQuery(queryBuilder, validationException);
-        }
-        return validationException;
-    }
-
-    protected QueryValidationException validateInnerQuery(QueryBuilder queryBuilder, QueryValidationException initialValidationException) {
-        QueryValidationException validationException = initialValidationException;
-        if (queryBuilder != null) {
-            QueryValidationException queryValidationException = queryBuilder.validate();
-            if (queryValidationException != null) {
-                validationException = QueryValidationException.addValidationErrors(queryValidationException.validationErrors(), validationException);
-            }
-        } else {
-            validationException = addValidationError("inner query cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    public String getName() {
-        //default impl returns the same as writeable name, but we keep the distinction between the two just to make sure
-        return getWriteableName();
-    }
-
-    protected final void writeQueries(StreamOutput out, List<? extends QueryBuilder> queries) throws IOException {
-        out.writeVInt(queries.size());
-        for (QueryBuilder query : queries) {
-            out.writeQuery(query);
-        }
-    }
-
-    protected final List<QueryBuilder> readQueries(StreamInput in) throws IOException {
-        List<QueryBuilder> queries = new ArrayList<>();
-        int size = in.readVInt();
-        for (int i = 0; i < size; i++) {
-            queries.add(in.readQuery());
-        }
-        return queries;
-    }
-
-    protected final void writeOptionalQuery(StreamOutput out, QueryBuilder query) throws IOException {
-        if (query == null) {
-            out.writeBoolean(false);
-        } else {
-            out.writeBoolean(true);
-            out.writeQuery(query);
-        }
-    }
-
-    protected final QueryBuilder readOptionalQuery(StreamInput in) throws IOException {
-        if (in.readBoolean()) {
-            return in.readQuery();
-        }
-        return null;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/AndQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/AndQueryBuilder.java
index f214dd5..1d55663 100644
--- a/core/src/main/java/org/elasticsearch/index/query/AndQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/AndQueryBuilder.java
@@ -19,42 +19,30 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collections;
-import java.util.List;
-import java.util.Objects;
 
 /**
  * A filter that matches documents matching boolean combinations of other filters.
  * @deprecated Use {@link BoolQueryBuilder} instead
  */
 @Deprecated
-public class AndQueryBuilder extends AbstractQueryBuilder<AndQueryBuilder> {
+public class AndQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "and";
+    private ArrayList<QueryBuilder> filters = new ArrayList<>();
 
-    private final ArrayList<QueryBuilder> filters = new ArrayList<>();
+    private String queryName;
 
-    static final AndQueryBuilder PROTOTYPE = new AndQueryBuilder();
-
-    /**
-     * @param filters nested filters, no <tt>null</tt> values are allowed
-     */
     public AndQueryBuilder(QueryBuilder... filters) {
-        Collections.addAll(this.filters, filters);
+        for (QueryBuilder filter : filters) {
+            this.filters.add(filter);
+        }
     }
 
     /**
      * Adds a filter to the list of filters to "and".
-     * @param filterBuilder nested filter, no <tt>null</tt> value allowed
      */
     public AndQueryBuilder add(QueryBuilder filterBuilder) {
         filters.add(filterBuilder);
@@ -62,80 +50,24 @@ public class AndQueryBuilder extends AbstractQueryBuilder<AndQueryBuilder> {
     }
 
     /**
-     * @return the list of queries added to "and".
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
      */
-    public List<QueryBuilder> innerQueries() {
-        return this.filters;
+    public AndQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(AndQueryParser.NAME);
         builder.startArray("filters");
         for (QueryBuilder filter : filters) {
             filter.toXContent(builder, params);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        if (filters.isEmpty()) {
-            // no filters provided, this should be ignored upstream
-            return null;
-        }
-
-        BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();
-        for (QueryBuilder f : filters) {
-            Query innerQuery = f.toFilter(context);
-            // ignore queries that are null
-            if (innerQuery != null) {
-                queryBuilder.add(innerQuery, Occur.MUST);
-            }
-        }
-        BooleanQuery query = queryBuilder.build();
-        if (query.clauses().isEmpty()) {
-            // no inner lucene query exists, ignore upstream
-            return null;
-        }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQueries(filters, null);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(filters);
-    }
-
-    @Override
-    protected boolean doEquals(AndQueryBuilder other) {
-        return Objects.equals(filters, other.filters);
-    }
-
-    @Override
-    protected AndQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        AndQueryBuilder andQueryBuilder = new AndQueryBuilder();
-        List<QueryBuilder> queryBuilders = readQueries(in);
-        for (QueryBuilder queryBuilder : queryBuilders) {
-            andQueryBuilder.add(queryBuilder);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return andQueryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, filters);
+        builder.endObject();
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/AndQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/AndQueryParser.java
index a233ead..9141b16 100644
--- a/core/src/main/java/org/elasticsearch/index/query/AndQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/AndQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
@@ -26,11 +29,12 @@ import java.io.IOException;
 import java.util.ArrayList;
 
 /**
- * Parser for and query
- * @deprecated use bool query instead
+ *
  */
 @Deprecated
-public class AndQueryParser extends BaseQueryParser<AndQueryBuilder> {
+public class AndQueryParser implements QueryParser {
+
+    public static final String NAME = "and";
 
     @Inject
     public AndQueryParser() {
@@ -38,25 +42,26 @@ public class AndQueryParser extends BaseQueryParser<AndQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{AndQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public AndQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        final ArrayList<QueryBuilder> queries = new ArrayList<>();
+        ArrayList<Query> queries = new ArrayList<>();
         boolean queriesFound = false;
 
         String queryName = null;
         String currentFieldName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         XContentParser.Token token = parser.currentToken();
         if (token == XContentParser.Token.START_ARRAY) {
             while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                 queriesFound = true;
-                QueryBuilder filter = parseContext.parseInnerFilterToQueryBuilder();
-                queries.add(filter);
+                Query filter = parseContext.parseInnerFilter();
+                if (filter != null) {
+                    queries.add(filter);
+                }
             }
         } else {
             while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -68,15 +73,23 @@ public class AndQueryParser extends BaseQueryParser<AndQueryBuilder> {
                     if ("filters".equals(currentFieldName)) {
                         queriesFound = true;
                         while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                            QueryBuilder filter = parseContext.parseInnerFilterToQueryBuilder();
-                            queries.add(filter);
+                            Query filter = parseContext.parseInnerFilter();
+                            if (filter != null) {
+                                queries.add(filter);
+                            }
+                        }
+                    } else {
+                        queriesFound = true;
+                        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
+                            Query filter = parseContext.parseInnerFilter();
+                            if (filter != null) {
+                                queries.add(filter);
+                            }
                         }
                     }
                 } else if (token.isValue()) {
                     if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
-                    } else if ("boost".equals(currentFieldName)) {
-                        boost = parser.floatValue();
                     } else {
                         throw new QueryParsingException(parseContext, "[and] query does not support [" + currentFieldName + "]");
                     }
@@ -88,17 +101,19 @@ public class AndQueryParser extends BaseQueryParser<AndQueryBuilder> {
             throw new QueryParsingException(parseContext, "[and] query requires 'filters' to be set on it'");
         }
 
-        AndQueryBuilder andQuery = new AndQueryBuilder();
-        for (QueryBuilder query : queries) {
-            andQuery.add(query);
+        if (queries.isEmpty()) {
+            // no filters provided, this should be ignored upstream
+            return null;
         }
-        andQuery.queryName(queryName);
-        andQuery.boost(boost);
-        return andQuery;
-    }
 
-    @Override
-    public AndQueryBuilder getBuilderPrototype() {
-        return AndQueryBuilder.PROTOTYPE;
+        BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();
+        for (Query f : queries) {
+            queryBuilder.add(f, Occur.MUST);
+        }
+        BooleanQuery query = queryBuilder.build();
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/BaseQueryParser.java
deleted file mode 100644
index 4ff02df..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParser.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-/**
- * Class used during the query parsers refactoring. Will be removed once we can parse search requests on the coordinating node.
- * All query parsers that have a refactored "fromXContent" method can be changed to extend this instead of {@link BaseQueryParserTemp}.
- * Keeps old {@link QueryParser#parse(QueryShardContext)} method as a stub delegating to
- * {@link QueryParser#fromXContent(QueryParseContext)} and {@link QueryBuilder#toQuery(QueryShardContext)}}
- */
-//norelease needs to be removed once we parse search requests on the coordinating node, as the parse method is not needed anymore at that point.
-public abstract class BaseQueryParser<QB extends QueryBuilder<QB>> implements QueryParser<QB> {
-
-    @Override
-    public final Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        return fromXContent(context.parseContext()).toQuery(context);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParserTemp.java b/core/src/main/java/org/elasticsearch/index/query/BaseQueryParserTemp.java
deleted file mode 100644
index 4dc3eae..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/BaseQueryParserTemp.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-/**
- * This class with method impl is an intermediate step in the query parsers refactoring.
- * Provides a fromXContent default implementation for query parsers that don't have yet a
- * specific fromXContent implementation that returns a QueryBuilder.
- */
-//norelease to be removed once all queries are moved over to extend BaseQueryParser
-public abstract class BaseQueryParserTemp implements QueryParser {
-
-    @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-        Query query = parse(parseContext.shardContext());
-        return new QueryWrappingQueryBuilder(query);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BaseTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BaseTermQueryBuilder.java
deleted file mode 100644
index 6444184..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/BaseTermQueryBuilder.java
+++ /dev/null
@@ -1,171 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-
-import java.io.IOException;
-import java.util.Objects;
-
-public abstract class BaseTermQueryBuilder<QB extends BaseTermQueryBuilder<QB>> extends AbstractQueryBuilder<QB> {
-
-    /** Name of field to match against. */
-    protected final String fieldName;
-
-    /** Value to find matches for. */
-    protected final Object value;
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, String value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, int value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, long value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, float value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, double value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, boolean value) {
-        this(fieldName, (Object) value);
-    }
-
-    /**
-     * Constructs a new base term query.
-     * In case value is assigned to a string, we internally convert it to a {@link BytesRef}
-     * because in {@link TermQueryParser} and {@link SpanTermQueryParser} string values are parsed to {@link BytesRef}
-     * and we want internal representation of query to be equal regardless of whether it was created from XContent or via Java API.
-     *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
-     */
-    public BaseTermQueryBuilder(String fieldName, Object value) {
-        this.fieldName = fieldName;
-        this.value = convertToBytesRefIfString(value);
-    }
-
-    /** Returns the field name used in this query. */
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    /**
-     *  Returns the value used in this query.
-     *  If necessary, converts internal {@link BytesRef} representation back to string.
-     */
-    public Object value() {
-        return convertToStringIfBytesRef(this.value);
-    }
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(getName());
-        builder.startObject(fieldName);
-        builder.field("value", convertToStringIfBytesRef(this.value));
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    /** Returns a {@link QueryValidationException} if fieldName is null or empty, or if value is null. */
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (fieldName == null || fieldName.isEmpty()) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (value == null) {
-            validationException = addValidationError("value cannot be null.", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected final int doHashCode() {
-        return Objects.hash(fieldName, value);
-    }
-
-    @Override
-    protected final boolean doEquals(BaseTermQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-               Objects.equals(value, other.value);
-    }
-
-    @Override
-    protected final QB doReadFrom(StreamInput in) throws IOException {
-        return createBuilder(in.readString(), in.readGenericValue());
-    }
-
-    protected abstract QB createBuilder(String fieldName, Object value);
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeGenericValue(value);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java
index 9b4e06d..c377667 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoolQueryBuilder.java
@@ -19,35 +19,17 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Objects;
-
-import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfNeeded;
 
 /**
  * A Query that matches documents matching boolean combinations of other queries.
  */
-public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
-
-    public static final String NAME = "bool";
-
-    public static final boolean ADJUST_PURE_NEGATIVE_DEFAULT = true;
-
-    public static final boolean DISABLE_COORD_DEFAULT = false;
-
-    static final BoolQueryBuilder PROTOTYPE = new BoolQueryBuilder();
+public class BoolQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<BoolQueryBuilder> {
 
     private final List<QueryBuilder> mustClauses = new ArrayList<>();
 
@@ -57,15 +39,19 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
 
     private final List<QueryBuilder> shouldClauses = new ArrayList<>();
 
-    private boolean disableCoord = DISABLE_COORD_DEFAULT;
+    private float boost = -1;
 
-    private boolean adjustPureNegative = ADJUST_PURE_NEGATIVE_DEFAULT;
+    private Boolean disableCoord;
 
     private String minimumShouldMatch;
+    
+    private Boolean adjustPureNegative;
+
+    private String queryName;
 
     /**
      * Adds a query that <b>must</b> appear in the matching documents and will
-     * contribute to scoring. No <tt>null</tt> value allowed.
+     * contribute to scoring.
      */
     public BoolQueryBuilder must(QueryBuilder queryBuilder) {
         mustClauses.add(queryBuilder);
@@ -73,15 +59,8 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the queries that <b>must</b> appear in the matching documents.
-     */
-    public List<QueryBuilder> must() {
-        return this.mustClauses;
-    }
-
-    /**
      * Adds a query that <b>must</b> appear in the matching documents but will
-     * not contribute to scoring. No <tt>null</tt> value allowed.
+     * not contribute to scoring.
      */
     public BoolQueryBuilder filter(QueryBuilder queryBuilder) {
         filterClauses.add(queryBuilder);
@@ -89,15 +68,8 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the queries that <b>must</b> appear in the matching documents but don't conntribute to scoring
-     */
-    public List<QueryBuilder> filter() {
-        return this.filterClauses;
-    }
-
-    /**
-     * Adds a query that <b>must not</b> appear in the matching documents.
-     * No <tt>null</tt> value allowed.
+     * Adds a query that <b>must not</b> appear in the matching documents and
+     * will not contribute to scoring.
      */
     public BoolQueryBuilder mustNot(QueryBuilder queryBuilder) {
         mustNotClauses.add(queryBuilder);
@@ -105,16 +77,9 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the queries that <b>must not</b> appear in the matching documents.
-     */
-    public List<QueryBuilder> mustNot() {
-        return this.mustNotClauses;
-    }
-
-    /**
-     * Adds a clause that <i>should</i> be matched by the returned documents. For a boolean query with no
+     * Adds a query that <i>should</i> appear in the matching documents. For a boolean query with no
      * <tt>MUST</tt> clauses one or more <code>SHOULD</code> clauses must match a document
-     * for the BooleanQuery to match. No <tt>null</tt> value allowed.
+     * for the BooleanQuery to match.
      *
      * @see #minimumNumberShouldMatch(int)
      */
@@ -124,13 +89,13 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * Gets the list of clauses that <b>should</b> be matched by the returned documents.
-     *
-     * @see #should(QueryBuilder)
-     *  @see #minimumNumberShouldMatch(int)
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public List<QueryBuilder> should() {
-        return this.shouldClauses;
+    @Override
+    public BoolQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
@@ -142,13 +107,6 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * @return whether the <tt>Similarity#coord(int,int)</tt> in scoring are disabled. Defaults to <tt>false</tt>.
-     */
-    public boolean disableCoord() {
-        return this.disableCoord;
-    }
-
-    /**
      * Specifies a minimum number of the optional (should) boolean clauses which must be satisfied.
      * <p/>
      * <p>By default no optional clauses are necessary for a match
@@ -166,23 +124,6 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
         return this;
     }
 
-
-    /**
-     * Specifies a minimum number of the optional (should) boolean clauses which must be satisfied.
-     * @see BoolQueryBuilder#minimumNumberShouldMatch(int)
-     */
-    public BoolQueryBuilder minimumNumberShouldMatch(String minimumNumberShouldMatch) {
-        this.minimumShouldMatch = minimumNumberShouldMatch;
-        return this;
-    }
-
-    /**
-     * @return the string representation of the minimumShouldMatch settings for this query
-     */
-    public String minimumNumberShouldMatch() {
-        return this.minimumShouldMatch;
-    }
-
     /**
      * Sets the minimum should match using the special syntax (for example, supporting percentage).
      */
@@ -198,7 +139,7 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     public boolean hasClauses() {
         return !(mustClauses.isEmpty() && shouldClauses.isEmpty() && mustNotClauses.isEmpty() && filterClauses.isEmpty());
     }
-
+    
     /**
      * If a boolean query contains only negative ("must not") clauses should the
      * BooleanQuery be enhanced with a {@link MatchAllDocsQuery} in order to act
@@ -210,136 +151,52 @@ public class BoolQueryBuilder extends AbstractQueryBuilder<BoolQueryBuilder> {
     }
 
     /**
-     * @return the setting for the adjust_pure_negative setting in this query
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public boolean adjustPureNegative() {
-        return this.adjustPureNegative;
+    public BoolQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject("bool");
         doXArrayContent("must", mustClauses, builder, params);
         doXArrayContent("filter", filterClauses, builder, params);
         doXArrayContent("must_not", mustNotClauses, builder, params);
         doXArrayContent("should", shouldClauses, builder, params);
-        builder.field("disable_coord", disableCoord);
-        builder.field("adjust_pure_negative", adjustPureNegative);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        if (disableCoord != null) {
+            builder.field("disable_coord", disableCoord);
+        }
         if (minimumShouldMatch != null) {
             builder.field("minimum_should_match", minimumShouldMatch);
         }
-        printBoostAndQueryName(builder);
+        if (adjustPureNegative != null) {
+            builder.field("adjust_pure_negative", adjustPureNegative);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         builder.endObject();
     }
 
-    private static void doXArrayContent(String field, List<QueryBuilder> clauses, XContentBuilder builder, Params params) throws IOException {
+    private void doXArrayContent(String field, List<QueryBuilder> clauses, XContentBuilder builder, Params params) throws IOException {
         if (clauses.isEmpty()) {
             return;
         }
-        builder.startArray(field);
-        for (QueryBuilder clause : clauses) {
-            clause.toXContent(builder, params);
-        }
-        builder.endArray();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        BooleanQuery.Builder booleanQueryBuilder = new BooleanQuery.Builder();
-        booleanQueryBuilder.setDisableCoord(disableCoord);
-        addBooleanClauses(context, booleanQueryBuilder, mustClauses, BooleanClause.Occur.MUST);
-        addBooleanClauses(context, booleanQueryBuilder, mustNotClauses, BooleanClause.Occur.MUST_NOT);
-        addBooleanClauses(context, booleanQueryBuilder, shouldClauses, BooleanClause.Occur.SHOULD);
-        addBooleanClauses(context, booleanQueryBuilder, filterClauses, BooleanClause.Occur.FILTER);
-        BooleanQuery booleanQuery = booleanQueryBuilder.build();
-        if (booleanQuery.clauses().isEmpty()) {
-            return new MatchAllDocsQuery();
-        }
-        booleanQuery = Queries.applyMinimumShouldMatch(booleanQuery, minimumShouldMatch);
-        return adjustPureNegative ? fixNegativeQueryIfNeeded(booleanQuery) : booleanQuery;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        validationException = validateInnerQueries(mustClauses, validationException);
-        validationException = validateInnerQueries(shouldClauses, validationException);
-        validationException = validateInnerQueries(mustNotClauses, validationException);
-        validationException = validateInnerQueries(filterClauses, validationException);
-        return validationException;
-    }
-
-    private void addBooleanClauses(QueryShardContext context, BooleanQuery.Builder booleanQueryBuilder, List<QueryBuilder> clauses, Occur occurs) throws IOException {
-        for (QueryBuilder query : clauses) {
-            Query luceneQuery = null;
-            switch (occurs) {
-            case SHOULD:
-                if (context.isFilter() && minimumShouldMatch == null) {
-                    minimumShouldMatch = "1";
-                }
-                luceneQuery = query.toQuery(context);
-                break;
-            case FILTER:
-            case MUST_NOT:
-                luceneQuery = query.toFilter(context);
-                break;
-            case MUST:
-                luceneQuery = query.toQuery(context);
-            }
-            if (luceneQuery != null) {
-                booleanQueryBuilder.add(new BooleanClause(luceneQuery, occurs));
+        if (clauses.size() == 1) {
+            builder.field(field);
+            clauses.get(0).toXContent(builder, params);
+        } else {
+            builder.startArray(field);
+            for (QueryBuilder clause : clauses) {
+                clause.toXContent(builder, params);
             }
+            builder.endArray();
         }
     }
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(adjustPureNegative, disableCoord,
-                minimumShouldMatch, mustClauses, shouldClauses, mustNotClauses, filterClauses);
-    }
-
-    @Override
-    protected boolean doEquals(BoolQueryBuilder other) {
-        return Objects.equals(adjustPureNegative, other.adjustPureNegative) &&
-                Objects.equals(disableCoord, other.disableCoord) &&
-                Objects.equals(minimumShouldMatch, other.minimumShouldMatch) &&
-                Objects.equals(mustClauses, other.mustClauses) &&
-                Objects.equals(shouldClauses, other.shouldClauses) &&
-                Objects.equals(mustNotClauses, other.mustNotClauses) &&
-                Objects.equals(filterClauses, other.filterClauses);
-    }
-
-    @Override
-    protected BoolQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder();
-        List<QueryBuilder> queryBuilders = readQueries(in);
-        boolQueryBuilder.mustClauses.addAll(queryBuilders);
-        queryBuilders = readQueries(in);
-        boolQueryBuilder.mustNotClauses.addAll(queryBuilders);
-        queryBuilders = readQueries(in);
-        boolQueryBuilder.shouldClauses.addAll(queryBuilders);
-        queryBuilders = readQueries(in);
-        boolQueryBuilder.filterClauses.addAll(queryBuilders);
-        boolQueryBuilder.adjustPureNegative = in.readBoolean();
-        boolQueryBuilder.disableCoord = in.readBoolean();
-        boolQueryBuilder.minimumShouldMatch = in.readOptionalString();
-        return boolQueryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, mustClauses);
-        writeQueries(out, mustNotClauses);
-        writeQueries(out, shouldClauses);
-        writeQueries(out, filterClauses);
-        out.writeBoolean(adjustPureNegative);
-        out.writeBoolean(disableCoord);
-        out.writeOptionalString(minimumShouldMatch);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java
index a1ff2fa..542a085 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java
@@ -19,7 +19,10 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.settings.Settings;
@@ -32,9 +35,11 @@ import java.util.List;
 import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfNeeded;
 
 /**
- * Parser for bool query
+ *
  */
-public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
+public class BoolQueryParser implements QueryParser {
+
+    public static final String NAME = "bool";
 
     @Inject
     public BoolQueryParser(Settings settings) {
@@ -43,27 +48,23 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{BoolQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public BoolQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        boolean disableCoord = BoolQueryBuilder.DISABLE_COORD_DEFAULT;
-        boolean adjustPureNegative = BoolQueryBuilder.ADJUST_PURE_NEGATIVE_DEFAULT;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        boolean disableCoord = false;
+        float boost = 1.0f;
         String minimumShouldMatch = null;
 
-        final List<QueryBuilder> mustClauses = new ArrayList<>();
-        final List<QueryBuilder> mustNotClauses = new ArrayList<>();
-        final List<QueryBuilder> shouldClauses = new ArrayList<>();
-        final List<QueryBuilder> filterClauses = new ArrayList<>();
+        List<BooleanClause> clauses = new ArrayList<>();
+        boolean adjustPureNegative = true;
         String queryName = null;
-
+        
         String currentFieldName = null;
         XContentParser.Token token;
-        QueryBuilder query;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -72,21 +73,32 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
             } else if (token == XContentParser.Token.START_OBJECT) {
                 switch (currentFieldName) {
                 case "must":
-                    query = parseContext.parseInnerQueryBuilder();
-                    mustClauses.add(query);
+                    Query query = parseContext.parseInnerQuery();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST));
+                    }
                     break;
                 case "should":
-                    query = parseContext.parseInnerQueryBuilder();
-                    shouldClauses.add(query);
+                    query = parseContext.parseInnerQuery();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.SHOULD));
+                        if (parseContext.isFilter() && minimumShouldMatch == null) {
+                            minimumShouldMatch = "1";
+                        }
+                    }
                     break;
                 case "filter":
-                    query = parseContext.parseInnerFilterToQueryBuilder();
-                    filterClauses.add(query);
+                    query = parseContext.parseInnerFilter();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.FILTER));
+                    }
                     break;
                 case "must_not":
                 case "mustNot":
-                    query = parseContext.parseInnerFilterToQueryBuilder();
-                    mustNotClauses.add(query);
+                    query = parseContext.parseInnerFilter();
+                    if (query != null) {
+                        clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST_NOT));
+                    }
                     break;
                 default:
                     throw new QueryParsingException(parseContext, "[bool] query does not support [" + currentFieldName + "]");
@@ -95,21 +107,32 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
                 while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                     switch (currentFieldName) {
                     case "must":
-                        query = parseContext.parseInnerQueryBuilder();
-                        mustClauses.add(query);
+                        Query query = parseContext.parseInnerQuery();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST));
+                        }
                         break;
                     case "should":
-                        query = parseContext.parseInnerQueryBuilder();
-                        shouldClauses.add(query);
+                        query = parseContext.parseInnerQuery();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.SHOULD));
+                            if (parseContext.isFilter() && minimumShouldMatch == null) {
+                                minimumShouldMatch = "1";
+                            }
+                        }
                         break;
                     case "filter":
-                        query = parseContext.parseInnerFilterToQueryBuilder();
-                        filterClauses.add(query);
+                        query = parseContext.parseInnerFilter();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.FILTER));
+                        }
                         break;
                     case "must_not":
                     case "mustNot":
-                        query = parseContext.parseInnerFilterToQueryBuilder();
-                        mustNotClauses.add(query);
+                        query = parseContext.parseInnerFilter();
+                        if (query != null) {
+                            clauses.add(new BooleanClause(query, BooleanClause.Occur.MUST_NOT));
+                        }
                         break;
                     default:
                         throw new QueryParsingException(parseContext, "bool query does not support [" + currentFieldName + "]");
@@ -133,29 +156,23 @@ public class BoolQueryParser extends BaseQueryParser<BoolQueryBuilder> {
                 }
             }
         }
-        BoolQueryBuilder boolQuery = new BoolQueryBuilder();
-        for (QueryBuilder queryBuilder : mustClauses) {
-            boolQuery.must(queryBuilder);
-        }
-        for (QueryBuilder queryBuilder : mustNotClauses) {
-            boolQuery.mustNot(queryBuilder);
+
+        if (clauses.isEmpty()) {
+            return new MatchAllDocsQuery();
         }
-        for (QueryBuilder queryBuilder : shouldClauses) {
-            boolQuery.should(queryBuilder);
+
+        BooleanQuery.Builder booleanQueryBuilder = new BooleanQuery.Builder();
+        booleanQueryBuilder.setDisableCoord(disableCoord);
+        for (BooleanClause clause : clauses) {
+            booleanQueryBuilder.add(clause);
         }
-        for (QueryBuilder queryBuilder : filterClauses) {
-            boolQuery.filter(queryBuilder);
+        BooleanQuery booleanQuery = booleanQueryBuilder.build();
+        booleanQuery.setBoost(boost);
+        booleanQuery = Queries.applyMinimumShouldMatch(booleanQuery, minimumShouldMatch);
+        Query query = adjustPureNegative ? fixNegativeQueryIfNeeded(booleanQuery) : booleanQuery;
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
         }
-        boolQuery.boost(boost);
-        boolQuery.disableCoord(disableCoord);
-        boolQuery.adjustPureNegative(adjustPureNegative);
-        boolQuery.minimumNumberShouldMatch(minimumShouldMatch);
-        boolQuery.queryName(queryName);
-        return boolQuery;
-    }
-
-    @Override
-    public BoolQueryBuilder getBuilderPrototype() {
-        return BoolQueryBuilder.PROTOTYPE;
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoostableQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BoostableQueryBuilder.java
new file mode 100644
index 0000000..31572ce
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/query/BoostableQueryBuilder.java
@@ -0,0 +1,33 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query;
+
+/**
+ * Query builder which allow setting some boost
+ */
+public interface BoostableQueryBuilder<B extends BoostableQueryBuilder<B>> {
+
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    B boost(float boost);
+
+}
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java
index 69ab70a..9d67469 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryBuilder.java
@@ -19,14 +19,9 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.queries.BoostingQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * The BoostingQuery class can be used to effectively demote results that match a given query.
@@ -40,132 +35,63 @@ import java.util.Objects;
  * multiplied by the supplied "boost" parameter, so this should be less than 1 to achieve a
  * demoting effect
  */
-public class BoostingQueryBuilder extends AbstractQueryBuilder<BoostingQueryBuilder> {
+public class BoostingQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<BoostingQueryBuilder> {
 
-    public static final String NAME = "boosting";
+    private QueryBuilder positiveQuery;
 
-    private final QueryBuilder positiveQuery;
-
-    private final QueryBuilder negativeQuery;
+    private QueryBuilder negativeQuery;
 
     private float negativeBoost = -1;
 
-    static final BoostingQueryBuilder PROTOTYPE = new BoostingQueryBuilder(null, null);
+    private float boost = -1;
+
+    public BoostingQueryBuilder() {
 
-    /**
-     * Create a new {@link BoostingQueryBuilder}
-     *
-     * @param positiveQuery the positive query for this boosting query.
-     * @param negativeQuery the negative query for this boosting query.
-     */
-    public BoostingQueryBuilder(QueryBuilder positiveQuery, QueryBuilder negativeQuery) {
-        this.positiveQuery = positiveQuery;
-        this.negativeQuery = negativeQuery;
     }
 
-    /**
-     * Get the positive query for this boosting query.
-     */
-    public QueryBuilder positiveQuery() {
-        return this.positiveQuery;
+    public BoostingQueryBuilder positive(QueryBuilder positiveQuery) {
+        this.positiveQuery = positiveQuery;
+        return this;
     }
 
-    /**
-     * Get the negative query for this boosting query.
-     */
-    public QueryBuilder negativeQuery() {
-        return this.negativeQuery;
+    public BoostingQueryBuilder negative(QueryBuilder negativeQuery) {
+        this.negativeQuery = negativeQuery;
+        return this;
     }
 
-    /**
-     * Set the negative boost factor.
-     */
     public BoostingQueryBuilder negativeBoost(float negativeBoost) {
         this.negativeBoost = negativeBoost;
         return this;
     }
 
-    /**
-     * Get the negative boost factor.
-     */
-    public float negativeBoost() {
-        return this.negativeBoost;
-    }
-
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("positive");
-        positiveQuery.toXContent(builder, params);
-        builder.field("negative");
-        negativeQuery.toXContent(builder, params);
-        builder.field("negative_boost", negativeBoost);
-        printBoostAndQueryName(builder);
-        builder.endObject();
+    public BoostingQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (negativeBoost < 0) {
-            validationException = addValidationError("query requires negativeBoost to be set to positive value", validationException);
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
+        if (positiveQuery == null) {
+            throw new IllegalArgumentException("boosting query requires positive query to be set");
         }
         if (negativeQuery == null) {
-            validationException = addValidationError("inner clause [negative] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(negativeQuery, validationException);
+            throw new IllegalArgumentException("boosting query requires negative query to be set");
         }
-        if (positiveQuery == null) {
-            validationException = addValidationError("inner clause [positive] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(positiveQuery, validationException);
+        if (negativeBoost == -1) {
+            throw new IllegalArgumentException("boosting query requires negativeBoost to be set");
         }
-        return validationException;
-    }
+        builder.startObject(BoostingQueryParser.NAME);
+        builder.field("positive");
+        positiveQuery.toXContent(builder, params);
+        builder.field("negative");
+        negativeQuery.toXContent(builder, params);
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
+        builder.field("negative_boost", negativeBoost);
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query positive = positiveQuery.toQuery(context);
-        Query negative = negativeQuery.toQuery(context);
-        // make upstream queries ignore this query by returning `null`
-        // if either inner query builder returns null
-        if (positive == null || negative == null) {
-            return null;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-
-        return new BoostingQuery(positive, negative, negativeBoost);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(negativeBoost, positiveQuery, negativeQuery);
-    }
-
-    @Override
-    protected boolean doEquals(BoostingQueryBuilder other) {
-        return Objects.equals(negativeBoost, other.negativeBoost) &&
-                Objects.equals(positiveQuery, other.positiveQuery) &&
-                Objects.equals(negativeQuery, other.negativeQuery);
-    }
-
-    @Override
-    protected BoostingQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder positiveQuery = in.readQuery();
-        QueryBuilder negativeQuery = in.readQuery();
-        BoostingQueryBuilder boostingQuery = new BoostingQueryBuilder(positiveQuery, negativeQuery);
-        boostingQuery.negativeBoost = in.readFloat();
-        return boostingQuery;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(positiveQuery);
-        out.writeQuery(negativeQuery);
-        out.writeFloat(negativeBoost);
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java
index 699d23d..c160b2f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/BoostingQueryParser.java
@@ -19,15 +19,19 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.queries.BoostingQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
 /**
- * Parser for boosting query
+ *
  */
-public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
+public class BoostingQueryParser implements QueryParser {
+
+    public static final String NAME = "boosting";
 
     @Inject
     public BoostingQueryParser() {
@@ -35,20 +39,19 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{BoostingQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public BoostingQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder positiveQuery = null;
+        Query positiveQuery = null;
         boolean positiveQueryFound = false;
-        QueryBuilder negativeQuery = null;
+        Query negativeQuery = null;
         boolean negativeQueryFound = false;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = -1;
         float negativeBoost = -1;
-        String queryName = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -57,10 +60,10 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("positive".equals(currentFieldName)) {
-                    positiveQuery = parseContext.parseInnerQueryBuilder();
+                    positiveQuery = parseContext.parseInnerQuery();
                     positiveQueryFound = true;
                 } else if ("negative".equals(currentFieldName)) {
-                    negativeQuery = parseContext.parseInnerQueryBuilder();
+                    negativeQuery = parseContext.parseInnerQuery();
                     negativeQueryFound = true;
                 } else {
                     throw new QueryParsingException(parseContext, "[boosting] query does not support [" + currentFieldName + "]");
@@ -68,8 +71,6 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
             } else if (token.isValue()) {
                 if ("negative_boost".equals(currentFieldName) || "negativeBoost".equals(currentFieldName)) {
                     negativeBoost = parser.floatValue();
-                } else if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else {
@@ -78,25 +79,25 @@ public class BoostingQueryParser extends BaseQueryParser<BoostingQueryBuilder> {
             }
         }
 
-        if (!positiveQueryFound) {
+        if (positiveQuery == null && !positiveQueryFound) {
             throw new QueryParsingException(parseContext, "[boosting] query requires 'positive' query to be set'");
         }
-        if (!negativeQueryFound) {
+        if (negativeQuery == null && !negativeQueryFound) {
             throw new QueryParsingException(parseContext, "[boosting] query requires 'negative' query to be set'");
         }
-        if (negativeBoost < 0) {
-            throw new QueryParsingException(parseContext, "[boosting] query requires 'negative_boost' to be set to be a positive value'");
+        if (negativeBoost == -1) {
+            throw new QueryParsingException(parseContext, "[boosting] query requires 'negative_boost' to be set'");
         }
 
-        BoostingQueryBuilder boostingQuery = new BoostingQueryBuilder(positiveQuery, negativeQuery);
-        boostingQuery.negativeBoost(negativeBoost);
-        boostingQuery.boost(boost);
-        boostingQuery.queryName(queryName);
-        return boostingQuery;
-    }
+        // parsers returned null
+        if (positiveQuery == null || negativeQuery == null) {
+            return null;
+        }
 
-    @Override
-    public BoostingQueryBuilder getBuilderPrototype() {
-        return BoostingQueryBuilder.PROTOTYPE;
+        BoostingQuery boostingQuery = new BoostingQuery(positiveQuery, negativeQuery, negativeBoost);
+        if (boost != -1) {
+            boostingQuery.setBoost(boost);
+        }
+        return boostingQuery;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java
index 853c583..ae9c10d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryBuilder.java
@@ -19,31 +19,18 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.queries.ExtendedCommonTermsQuery;
-import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
 import org.apache.lucene.search.similarities.Similarity;
-import org.apache.lucene.util.BytesRefBuilder;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * CommonTermsQuery query is a query that executes high-frequency terms in a
  * optional sub-query to prevent slow queries due to "common" terms like
- * stopwords. This query basically builds 2 queries off the
- * {@link org.apache.lucene.queries.CommonTermsQuery#add(Term) added} terms
- * where low-frequency terms are added to a required boolean clause
+ * stopwords. This query basically builds 2 queries off the {@link #add(Term)
+ * added} terms where low-frequency terms are added to a required boolean clause
  * and high-frequency terms are added to an optional boolean clause. The
  * optional clause is only executed if the required "low-frequency' clause
  * matches. Scores produced by this query will be slightly different to plain
@@ -55,52 +42,46 @@ import java.util.Objects;
  * execution times significantly if applicable.
  * <p>
  */
-public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQueryBuilder> {
+public class CommonTermsQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<CommonTermsQueryBuilder> {
 
-    public static final String NAME = "common";
-
-    public static final float DEFAULT_CUTOFF_FREQ = 0.01f;
-
-    public static final Operator DEFAULT_HIGH_FREQ_OCCUR = Operator.OR;
-
-    public static final Operator DEFAULT_LOW_FREQ_OCCUR = Operator.OR;
-
-    public static final boolean DEFAULT_DISABLE_COORD = true;
+    public static enum Operator {
+        OR, AND
+    }
 
-    private final String fieldName;
+    private final String name;
 
     private final Object text;
 
-    private Operator highFreqOperator = DEFAULT_HIGH_FREQ_OCCUR;
+    private Operator highFreqOperator = null;
 
-    private Operator lowFreqOperator = DEFAULT_LOW_FREQ_OCCUR;
+    private Operator lowFreqOperator = null;
 
     private String analyzer = null;
 
+    private Float boost = null;
+
     private String lowFreqMinimumShouldMatch = null;
 
     private String highFreqMinimumShouldMatch = null;
 
-    private boolean disableCoord = DEFAULT_DISABLE_COORD;
+    private Boolean disableCoord = null;
 
-    private float cutoffFrequency = DEFAULT_CUTOFF_FREQ;
+    private Float cutoffFrequency = null;
 
-    static final CommonTermsQueryBuilder PROTOTYPE = new CommonTermsQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * Constructs a new common terms query.
      */
-    public CommonTermsQueryBuilder(String fieldName, Object text) {
-        this.fieldName = fieldName;
+    public CommonTermsQueryBuilder(String name, Object text) {
+        if (name == null) {
+            throw new IllegalArgumentException("Field name must not be null");
+        }
+        if (text == null) {
+            throw new IllegalArgumentException("Query must not be null");
+        }
         this.text = text;
-    }
-
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public Object value() {
-        return this.text;
+        this.name = name;
     }
 
     /**
@@ -109,27 +90,19 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
      * <tt>AND</tt>.
      */
     public CommonTermsQueryBuilder highFreqOperator(Operator operator) {
-        this.highFreqOperator = (operator == null) ? DEFAULT_HIGH_FREQ_OCCUR : operator;
+        this.highFreqOperator = operator;
         return this;
     }
 
-    public Operator highFreqOperator() {
-        return highFreqOperator;
-    }
-
     /**
      * Sets the operator to use for terms with a low document frequency (less
      * than {@link #cutoffFrequency(float)}. Defaults to <tt>AND</tt>.
      */
     public CommonTermsQueryBuilder lowFreqOperator(Operator operator) {
-        this.lowFreqOperator = (operator == null) ? DEFAULT_LOW_FREQ_OCCUR : operator;
+        this.lowFreqOperator = operator;
         return this;
     }
 
-    public Operator lowFreqOperator() {
-        return lowFreqOperator;
-    }
-
     /**
      * Explicitly set the analyzer to use. Defaults to use explicit mapping
      * config for the field, or, if not set, the default search analyzer.
@@ -139,8 +112,13 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
         return this;
     }
 
-    public String analyzer() {
-        return this.analyzer;
+    /**
+     * Set the boost to apply to the query.
+     */
+    @Override
+    public CommonTermsQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
@@ -148,17 +126,13 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
      * in [0..1] (or absolute number >=1) representing the maximum threshold of
      * a terms document frequency to be considered a low frequency term.
      * Defaults to
-     * <tt>{@value #DEFAULT_CUTOFF_FREQ}</tt>
+     * <tt>{@value CommonTermsQueryParser#DEFAULT_MAX_TERM_DOC_FREQ}</tt>
      */
     public CommonTermsQueryBuilder cutoffFrequency(float cutoffFrequency) {
         this.cutoffFrequency = cutoffFrequency;
         return this;
     }
 
-    public float cutoffFrequency() {
-        return this.cutoffFrequency;
-    }
-
     /**
      * Sets the minimum number of high frequent query terms that need to match in order to
      * produce a hit when there are no low frequen terms.
@@ -168,10 +142,6 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
         return this;
     }
 
-    public String highFreqMinimumShouldMatch() {
-        return this.highFreqMinimumShouldMatch;
-    }
-
     /**
      * Sets the minimum number of low frequent query terms that need to match in order to
      * produce a hit.
@@ -180,32 +150,44 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
         this.lowFreqMinimumShouldMatch = lowFreqMinimumShouldMatch;
         return this;
     }
-
-    public String lowFreqMinimumShouldMatch() {
-        return this.lowFreqMinimumShouldMatch;
-    }
-
+    
     public CommonTermsQueryBuilder disableCoord(boolean disableCoord) {
         this.disableCoord = disableCoord;
         return this;
     }
 
-    public boolean disableCoord() {
-        return this.disableCoord;
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public CommonTermsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(CommonTermsQueryParser.NAME);
+        builder.startObject(name);
+
         builder.field("query", text);
-        builder.field("disable_coord", disableCoord);
-        builder.field("high_freq_operator", highFreqOperator.toString());
-        builder.field("low_freq_operator", lowFreqOperator.toString());
+        if (disableCoord != null) {
+            builder.field("disable_coord", disableCoord);
+        }
+        if (highFreqOperator != null) {
+            builder.field("high_freq_operator", highFreqOperator.toString());
+        }
+        if (lowFreqOperator != null) {
+            builder.field("low_freq_operator", lowFreqOperator.toString());
+        }
         if (analyzer != null) {
             builder.field("analyzer", analyzer);
         }
-        builder.field("cutoff_frequency", cutoffFrequency);
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
+        if (cutoffFrequency != null) {
+            builder.field("cutoff_frequency", cutoffFrequency);
+        }
         if (lowFreqMinimumShouldMatch != null || highFreqMinimumShouldMatch != null) {
             builder.startObject("minimum_should_match");
             if (lowFreqMinimumShouldMatch != null) {
@@ -216,125 +198,11 @@ public class CommonTermsQueryBuilder extends AbstractQueryBuilder<CommonTermsQue
             }
             builder.endObject();
         }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        String field;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            field = fieldType.names().indexName();
-        } else {
-            field = fieldName;
-        }
-
-        Analyzer analyzerObj;
-        if (analyzer == null) {
-            if (fieldType != null) {
-                analyzerObj = context.getSearchAnalyzer(fieldType);
-            } else {
-                analyzerObj = context.mapperService().searchAnalyzer();
-            }
-        } else {
-            analyzerObj = context.mapperService().analysisService().analyzer(analyzer);
-            if (analyzerObj == null) {
-                throw new QueryShardException(context, "[common] analyzer [" + analyzer + "] not found");
-            }
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
 
-        Occur highFreqOccur = highFreqOperator.toBooleanClauseOccur();
-        Occur lowFreqOccur = lowFreqOperator.toBooleanClauseOccur();
-
-        ExtendedCommonTermsQuery commonsQuery = new ExtendedCommonTermsQuery(highFreqOccur, lowFreqOccur, cutoffFrequency, disableCoord, fieldType);
-        return parseQueryString(commonsQuery, text, field, analyzerObj, lowFreqMinimumShouldMatch, highFreqMinimumShouldMatch);
-    }
-
-    static Query parseQueryString(ExtendedCommonTermsQuery query, Object queryString, String field, Analyzer analyzer,
-                                         String lowFreqMinimumShouldMatch, String highFreqMinimumShouldMatch) throws IOException {
-        // Logic similar to QueryParser#getFieldQuery
-        int count = 0;
-        try (TokenStream source = analyzer.tokenStream(field, queryString.toString())) {
-            source.reset();
-            CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);
-            BytesRefBuilder builder = new BytesRefBuilder();
-            while (source.incrementToken()) {
-                // UTF-8
-                builder.copyChars(termAtt);
-                query.add(new Term(field, builder.toBytesRef()));
-                count++;
-            }
-        }
-
-        if (count == 0) {
-            return null;
-        }
-        query.setLowFreqMinimumNumberShouldMatch(lowFreqMinimumShouldMatch);
-        query.setHighFreqMinimumNumberShouldMatch(highFreqMinimumShouldMatch);
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.text == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected CommonTermsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        CommonTermsQueryBuilder commonTermsQueryBuilder = new CommonTermsQueryBuilder(in.readString(), in.readGenericValue());
-        commonTermsQueryBuilder.highFreqOperator = Operator.readOperatorFrom(in);
-        commonTermsQueryBuilder.lowFreqOperator = Operator.readOperatorFrom(in);
-        commonTermsQueryBuilder.analyzer = in.readOptionalString();
-        commonTermsQueryBuilder.lowFreqMinimumShouldMatch = in.readOptionalString();
-        commonTermsQueryBuilder.highFreqMinimumShouldMatch = in.readOptionalString();
-        commonTermsQueryBuilder.disableCoord = in.readBoolean();
-        commonTermsQueryBuilder.cutoffFrequency = in.readFloat();
-        return commonTermsQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(this.fieldName);
-        out.writeGenericValue(this.text);
-        highFreqOperator.writeTo(out);
-        lowFreqOperator.writeTo(out);
-        out.writeOptionalString(analyzer);
-        out.writeOptionalString(lowFreqMinimumShouldMatch);
-        out.writeOptionalString(highFreqMinimumShouldMatch);
-        out.writeBoolean(disableCoord);
-        out.writeFloat(cutoffFrequency);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, text, highFreqOperator, lowFreqOperator, analyzer,
-                lowFreqMinimumShouldMatch, highFreqMinimumShouldMatch, disableCoord, cutoffFrequency);
-    }
-
-    @Override
-    protected boolean doEquals(CommonTermsQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(text, other.text) &&
-                Objects.equals(highFreqOperator, other.highFreqOperator) &&
-                Objects.equals(lowFreqOperator, other.lowFreqOperator) &&
-                Objects.equals(analyzer, other.analyzer) &&
-                Objects.equals(lowFreqMinimumShouldMatch, other.lowFreqMinimumShouldMatch) &&
-                Objects.equals(highFreqMinimumShouldMatch, other.highFreqMinimumShouldMatch) &&
-                Objects.equals(disableCoord, other.disableCoord) &&
-                Objects.equals(cutoffFrequency, other.cutoffFrequency);
+        builder.endObject();
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java
index 65f4fa3..c18229e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/CommonTermsQueryParser.java
@@ -19,15 +19,36 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.queries.ExtendedCommonTermsQuery;
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.util.BytesRefBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
 
 /**
- * Parser for common terms query
+ *
  */
-public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuilder> {
+public class CommonTermsQueryParser implements QueryParser {
+
+    public static final String NAME = "common";
+
+    static final float DEFAULT_MAX_TERM_DOC_FREQ = 0.01f;
+
+    static final Occur DEFAULT_HIGH_FREQ_OCCUR = Occur.SHOULD;
+
+    static final Occur DEFAULT_LOW_FREQ_OCCUR = Occur.SHOULD;
+
+    static final boolean DEFAULT_DISABLE_COORD = true;
+
 
     @Inject
     public CommonTermsQueryParser() {
@@ -35,26 +56,26 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
 
     @Override
     public String[] names() {
-        return new String[] { CommonTermsQueryBuilder.NAME };
+        return new String[] { NAME };
     }
 
     @Override
-    public CommonTermsQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
         XContentParser.Token token = parser.nextToken();
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new QueryParsingException(parseContext, "[common] query malformed, no field");
         }
         String fieldName = parser.currentName();
-        Object text = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        String analyzer = null;
+        Object value = null;
+        float boost = 1.0f;
+        String queryAnalyzer = null;
         String lowFreqMinimumShouldMatch = null;
         String highFreqMinimumShouldMatch = null;
-        boolean disableCoord = CommonTermsQueryBuilder.DEFAULT_DISABLE_COORD;
-        Operator highFreqOperator = CommonTermsQueryBuilder.DEFAULT_HIGH_FREQ_OCCUR;
-        Operator lowFreqOperator = CommonTermsQueryBuilder.DEFAULT_LOW_FREQ_OCCUR;
-        float cutoffFrequency = CommonTermsQueryBuilder.DEFAULT_CUTOFF_FREQ;
+        boolean disableCoord = DEFAULT_DISABLE_COORD;
+        Occur highFreqOccur = DEFAULT_HIGH_FREQ_OCCUR;
+        Occur lowFreqOccur = DEFAULT_LOW_FREQ_OCCUR;
+        float maxTermFrequency = DEFAULT_MAX_TERM_DOC_FREQ;
         String queryName = null;
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
@@ -84,21 +105,41 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
                     }
                 } else if (token.isValue()) {
                     if ("query".equals(currentFieldName)) {
-                        text = parser.objectText();
+                        value = parser.objectText();
                     } else if ("analyzer".equals(currentFieldName)) {
-                        analyzer = parser.text();
+                        String analyzer = parser.text();
+                        if (parseContext.analysisService().analyzer(analyzer) == null) {
+                            throw new QueryParsingException(parseContext, "[common] analyzer [" + parser.text() + "] not found");
+                        }
+                        queryAnalyzer = analyzer;
                     } else if ("disable_coord".equals(currentFieldName) || "disableCoord".equals(currentFieldName)) {
                         disableCoord = parser.booleanValue();
                     } else if ("boost".equals(currentFieldName)) {
                         boost = parser.floatValue();
                     } else if ("high_freq_operator".equals(currentFieldName) || "highFreqOperator".equals(currentFieldName)) {
-                        highFreqOperator = Operator.fromString(parser.text());
+                        String op = parser.text();
+                        if ("or".equalsIgnoreCase(op)) {
+                            highFreqOccur = BooleanClause.Occur.SHOULD;
+                        } else if ("and".equalsIgnoreCase(op)) {
+                            highFreqOccur = BooleanClause.Occur.MUST;
+                        } else {
+                            throw new QueryParsingException(parseContext,
+                                    "[common] query requires operator to be either 'and' or 'or', not [" + op + "]");
+                        }
                     } else if ("low_freq_operator".equals(currentFieldName) || "lowFreqOperator".equals(currentFieldName)) {
-                        lowFreqOperator = Operator.fromString(parser.text());
+                        String op = parser.text();
+                        if ("or".equalsIgnoreCase(op)) {
+                            lowFreqOccur = BooleanClause.Occur.SHOULD;
+                        } else if ("and".equalsIgnoreCase(op)) {
+                            lowFreqOccur = BooleanClause.Occur.MUST;
+                        } else {
+                            throw new QueryParsingException(parseContext,
+                                    "[common] query requires operator to be either 'and' or 'or', not [" + op + "]");
+                        }
                     } else if ("minimum_should_match".equals(currentFieldName) || "minimumShouldMatch".equals(currentFieldName)) {
                         lowFreqMinimumShouldMatch = parser.text();
                     } else if ("cutoff_frequency".equals(currentFieldName)) {
-                        cutoffFrequency = parser.floatValue();
+                        maxTermFrequency = parser.floatValue();
                     } else if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
                     } else {
@@ -108,7 +149,7 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
             }
             parser.nextToken();
         } else {
-            text = parser.objectText();
+            value = parser.objectText();
             // move to the next token
             token = parser.nextToken();
             if (token != XContentParser.Token.END_OBJECT) {
@@ -118,23 +159,66 @@ public class CommonTermsQueryParser extends BaseQueryParser<CommonTermsQueryBuil
             }
         }
 
-        if (text == null) {
+        if (value == null) {
             throw new QueryParsingException(parseContext, "No text specified for text query");
         }
-        return new CommonTermsQueryBuilder(fieldName, text)
-                .lowFreqMinimumShouldMatch(lowFreqMinimumShouldMatch)
-                .highFreqMinimumShouldMatch(highFreqMinimumShouldMatch)
-                .analyzer(analyzer)
-                .highFreqOperator(highFreqOperator)
-                .lowFreqOperator(lowFreqOperator)
-                .disableCoord(disableCoord)
-                .cutoffFrequency(cutoffFrequency)
-                .boost(boost)
-                .queryName(queryName);
+        String field;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            field = fieldType.names().indexName();
+        } else {
+            field = fieldName;
+        }
+
+        Analyzer analyzer = null;
+        if (queryAnalyzer == null) {
+            if (fieldType != null) {
+                analyzer = fieldType.searchAnalyzer();
+            }
+            if (analyzer == null && fieldType != null) {
+                analyzer = parseContext.getSearchAnalyzer(fieldType);
+            }
+            if (analyzer == null) {
+                analyzer = parseContext.mapperService().searchAnalyzer();
+            }
+        } else {
+            analyzer = parseContext.mapperService().analysisService().analyzer(queryAnalyzer);
+            if (analyzer == null) {
+                throw new IllegalArgumentException("No analyzer found for [" + queryAnalyzer + "]");
+            }
+        }
+
+        ExtendedCommonTermsQuery commonsQuery = new ExtendedCommonTermsQuery(highFreqOccur, lowFreqOccur, maxTermFrequency, disableCoord, fieldType);
+        commonsQuery.setBoost(boost);
+        Query query = parseQueryString(commonsQuery, value.toString(), field, parseContext, analyzer, lowFreqMinimumShouldMatch, highFreqMinimumShouldMatch);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 
-    @Override
-    public CommonTermsQueryBuilder getBuilderPrototype() {
-        return CommonTermsQueryBuilder.PROTOTYPE;
+
+    private final Query parseQueryString(ExtendedCommonTermsQuery query, String queryString, String field, QueryParseContext parseContext,
+            Analyzer analyzer, String lowFreqMinimumShouldMatch, String highFreqMinimumShouldMatch) throws IOException {
+        // Logic similar to QueryParser#getFieldQuery
+        int count = 0;
+        try (TokenStream source = analyzer.tokenStream(field, queryString.toString())) {
+            source.reset();
+            CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class);
+            BytesRefBuilder builder = new BytesRefBuilder();
+            while (source.incrementToken()) {
+                // UTF-8
+                builder.copyChars(termAtt);
+                query.add(new Term(field, builder.toBytesRef()));
+                count++;
+            }
+        }
+
+        if (count == 0) {
+            return null;
+        }
+        query.setLowFreqMinimumNumberShouldMatch(lowFreqMinimumShouldMatch);
+        query.setHighFreqMinimumNumberShouldMatch(highFreqMinimumShouldMatch);
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java
index 10b14e0..bdcbe9c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryBuilder.java
@@ -19,10 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
@@ -32,84 +28,41 @@ import java.util.Objects;
  * A query that wraps a filter and simply returns a constant score equal to the
  * query boost for every document in the filter.
  */
-public class ConstantScoreQueryBuilder extends AbstractQueryBuilder<ConstantScoreQueryBuilder> {
-
-    public static final String NAME = "constant_score";
+public class ConstantScoreQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<ConstantScoreQueryBuilder> {
 
     private final QueryBuilder filterBuilder;
 
-    static final ConstantScoreQueryBuilder PROTOTYPE = new ConstantScoreQueryBuilder(null);
+    private float boost = -1;
 
     /**
-     * A query that wraps another query and simply returns a constant score equal to the
+     * A query that wraps a query and simply returns a constant score equal to the
      * query boost for every document in the query.
      *
      * @param filterBuilder The query to wrap in a constant score query
      */
     public ConstantScoreQueryBuilder(QueryBuilder filterBuilder) {
-        this.filterBuilder = filterBuilder;
+        this.filterBuilder = Objects.requireNonNull(filterBuilder);
     }
 
     /**
-     * @return the query that was wrapped in this constant score query
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public QueryBuilder innerQuery() {
-        return this.filterBuilder;
+    @Override
+    public ConstantScoreQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(ConstantScoreQueryParser.NAME);
         builder.field("filter");
         filterBuilder.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerFilter = filterBuilder.toFilter(context);
-        if (innerFilter == null ) {
-            // return null so that parent queries (e.g. bool) also ignore this
-            return null;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return new ConstantScoreQuery(innerFilter);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (filterBuilder == null) {
-            validationException = addValidationError("inner clause [filter] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(filterBuilder, validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(filterBuilder);
-    }
-
-    @Override
-    protected boolean doEquals(ConstantScoreQueryBuilder other) {
-        return Objects.equals(filterBuilder, other.filterBuilder);
-    }
-
-    @Override
-    protected ConstantScoreQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder innerFilterBuilder = in.readQuery();
-        return new ConstantScoreQueryBuilder(innerFilterBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(filterBuilder);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java
index ba261e8..d8a34b9 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
@@ -27,10 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for constant_score query
+ *
  */
-public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQueryBuilder> {
+public class ConstantScoreQueryParser implements QueryParser {
 
+    public static final String NAME = "constant_score";
     private static final ParseField INNER_QUERY_FIELD = new ParseField("filter", "query");
 
     @Inject
@@ -39,17 +42,16 @@ public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQuery
 
     @Override
     public String[] names() {
-        return new String[]{ConstantScoreQueryBuilder.NAME, Strings.toCamelCase(ConstantScoreQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public ConstantScoreQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder query = null;
+        Query filter = null;
         boolean queryFound = false;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -60,15 +62,13 @@ public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQuery
                 // skip
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, INNER_QUERY_FIELD)) {
-                    query = parseContext.parseInnerFilterToQueryBuilder();
+                    filter = parseContext.parseInnerFilter();
                     queryFound = true;
                 } else {
                     throw new QueryParsingException(parseContext, "[constant_score] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
+                if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[constant_score] query does not support [" + currentFieldName + "]");
@@ -79,14 +79,12 @@ public class ConstantScoreQueryParser extends BaseQueryParser<ConstantScoreQuery
             throw new QueryParsingException(parseContext, "[constant_score] requires a 'filter' element");
         }
 
-        ConstantScoreQueryBuilder constantScoreBuilder = new ConstantScoreQueryBuilder(query);
-        constantScoreBuilder.boost(boost);
-        constantScoreBuilder.queryName(queryName);
-        return constantScoreBuilder;
-    }
+        if (filter == null) {
+            return null;
+        }
 
-    @Override
-    public ConstantScoreQueryBuilder getBuilderPrototype() {
-        return ConstantScoreQueryBuilder.PROTOTYPE;
+        filter = new ConstantScoreQuery(filter);
+        filter.setBoost(boost);
+        return filter;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java
index 9b43de6..3724a05 100644
--- a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryBuilder.java
@@ -19,34 +19,25 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.DisjunctionMaxQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-import java.util.Objects;
 
 /**
  * A query that generates the union of documents produced by its sub-queries, and that scores each document
  * with the maximum score for that document as produced by any sub-query, plus a tie breaking increment for any
  * additional matching sub-queries.
  */
-public class DisMaxQueryBuilder extends AbstractQueryBuilder<DisMaxQueryBuilder> {
+public class DisMaxQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<DisMaxQueryBuilder> {
 
-    public static final String NAME = "dis_max";
+    private ArrayList<QueryBuilder> queries = new ArrayList<>();
 
-    private final ArrayList<QueryBuilder> queries = new ArrayList<>();
+    private float boost = -1;
 
-    /** Default multiplication factor for breaking ties in document scores.*/
-    public static float DEFAULT_TIE_BREAKER = 0.0f;
-    private float tieBreaker = DEFAULT_TIE_BREAKER;
+    private float tieBreaker = -1;
 
-    static final DisMaxQueryBuilder PROTOTYPE = new DisMaxQueryBuilder();
+    private String queryName;
 
     /**
      * Add a sub-query to this disjunction.
@@ -57,10 +48,13 @@ public class DisMaxQueryBuilder extends AbstractQueryBuilder<DisMaxQueryBuilder>
     }
 
     /**
-     * @return an immutable list copy of the current sub-queries of this disjunction
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public List<QueryBuilder> innerQueries() {
-        return this.queries;
+    @Override
+    public DisMaxQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
@@ -75,70 +69,30 @@ public class DisMaxQueryBuilder extends AbstractQueryBuilder<DisMaxQueryBuilder>
     }
 
     /**
-     * @return the tie breaker score
-     * @see DisMaxQueryBuilder#tieBreaker(float)
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public float tieBreaker() {
-        return this.tieBreaker;
+    public DisMaxQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("tie_breaker", tieBreaker);
+        builder.startObject(DisMaxQueryParser.NAME);
+        if (tieBreaker != -1) {
+            builder.field("tie_breaker", tieBreaker);
+        }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         builder.startArray("queries");
         for (QueryBuilder queryBuilder : queries) {
             queryBuilder.toXContent(builder, params);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // return null if there are no queries at all
-        Collection<Query> luceneQueries = toQueries(queries, context);
-        if (luceneQueries.isEmpty()) {
-            return null;
-        }
-
-        return new DisjunctionMaxQuery(luceneQueries, tieBreaker);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQueries(queries, null);
-    }
-
-    @Override
-    protected DisMaxQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        DisMaxQueryBuilder disMax = new DisMaxQueryBuilder();
-        List<QueryBuilder> queryBuilders = readQueries(in);
-        disMax.queries.addAll(queryBuilders);
-        disMax.tieBreaker = in.readFloat();
-        return disMax;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, queries);
-        out.writeFloat(tieBreaker);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queries, tieBreaker);
-    }
-
-    @Override
-    protected boolean doEquals(DisMaxQueryBuilder other) {
-        return Objects.equals(queries, other.queries) &&
-               Objects.equals(tieBreaker, other.tieBreaker);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java
index 39bad2d..dc901d6 100644
--- a/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/DisMaxQueryParser.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.DisjunctionMaxQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -28,9 +30,11 @@ import java.util.ArrayList;
 import java.util.List;
 
 /**
- * Parser for dis_max query
+ *
  */
-public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
+public class DisMaxQueryParser implements QueryParser {
+
+    public static final String NAME = "dis_max";
 
     @Inject
     public DisMaxQueryParser() {
@@ -38,17 +42,17 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{DisMaxQueryBuilder.NAME, Strings.toCamelCase(DisMaxQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public DisMaxQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        float tieBreaker = DisMaxQueryBuilder.DEFAULT_TIE_BREAKER;
+        float boost = 1.0f;
+        float tieBreaker = 0.0f;
 
-        final List<QueryBuilder> queries = new ArrayList<>();
+        List<Query> queries = new ArrayList<>();
         boolean queriesFound = false;
         String queryName = null;
 
@@ -60,8 +64,10 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("queries".equals(currentFieldName)) {
                     queriesFound = true;
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    queries.add(query);
+                    Query query = parseContext.parseInnerQuery();
+                    if (query != null) {
+                        queries.add(query);
+                    }
                 } else {
                     throw new QueryParsingException(parseContext, "[dis_max] query does not support [" + currentFieldName + "]");
                 }
@@ -69,8 +75,10 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
                 if ("queries".equals(currentFieldName)) {
                     queriesFound = true;
                     while (token != XContentParser.Token.END_ARRAY) {
-                        QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                        queries.add(query);
+                        Query query = parseContext.parseInnerQuery();
+                        if (query != null) {
+                            queries.add(query);
+                        }
                         token = parser.nextToken();
                     }
                 } else {
@@ -93,18 +101,15 @@ public class DisMaxQueryParser extends BaseQueryParser<DisMaxQueryBuilder> {
             throw new QueryParsingException(parseContext, "[dis_max] requires 'queries' field");
         }
 
-        DisMaxQueryBuilder disMaxQuery = new DisMaxQueryBuilder();
-        disMaxQuery.tieBreaker(tieBreaker);
-        disMaxQuery.queryName(queryName);
-        disMaxQuery.boost(boost);
-        for (QueryBuilder query : queries) {
-            disMaxQuery.add(query);
+        if (queries.isEmpty()) {
+            return null;
         }
-        return disMaxQuery;
-    }
 
-    @Override
-    public DisMaxQueryBuilder getBuilderPrototype() {
-        return DisMaxQueryBuilder.PROTOTYPE;
+        DisjunctionMaxQuery query = new DisjunctionMaxQuery(queries, tieBreaker);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/EmptyQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/EmptyQueryBuilder.java
deleted file mode 100644
index c59d8d3..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/EmptyQueryBuilder.java
+++ /dev/null
@@ -1,118 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.action.support.ToXContentToBytes;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentType;
-
-import java.io.IOException;
-
-/**
- * A {@link QueryBuilder} that is a stand in replacement for an empty query clause in the DSL.
- * The current DSL allows parsing inner queries / filters like "{ }", in order to have a
- * valid non-null representation of these clauses that actually do nothing we can use this class.
- *
- * This builder has no corresponding parser and it is not registered under the query name. It is
- * intended to be used internally as a stand-in for nested queries that are left empty and should
- * be ignored upstream.
- */
-public class EmptyQueryBuilder extends ToXContentToBytes implements QueryBuilder<EmptyQueryBuilder> {
-
-    public static final String NAME = "empty_query";
-
-    /** the one and only empty query builder */
-    public static final EmptyQueryBuilder PROTOTYPE = new EmptyQueryBuilder();
-
-    // prevent instances other than prototype
-    private EmptyQueryBuilder() {
-        super(XContentType.JSON);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public String getName() {
-        return getWriteableName();
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject();
-        builder.endObject();
-        return builder;
-    }
-
-    @Override
-    public Query toQuery(QueryShardContext context) throws IOException {
-        // empty
-        return null;
-    }
-
-    @Override
-    public Query toFilter(QueryShardContext context) throws IOException {
-        // empty
-        return null;
-    }
-
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-    }
-
-    @Override
-    public EmptyQueryBuilder readFrom(StreamInput in) throws IOException {
-        return EmptyQueryBuilder.PROTOTYPE;
-    }
-
-    @Override
-    public EmptyQueryBuilder queryName(String queryName) {
-        //no-op
-        return this;
-    }
-
-    @Override
-    public String queryName() {
-        return null;
-    }
-
-    @Override
-    public float boost() {
-        return -1;
-    }
-
-    @Override
-    public EmptyQueryBuilder boost(float boost) {
-        //no-op
-        return this;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java
index 67ea4c5..9980d81 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryBuilder.java
@@ -19,126 +19,38 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.*;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
-import java.util.Collection;
-import java.util.Objects;
 
 /**
  * Constructs a query that only match on documents that the field has a value in them.
  */
-public class ExistsQueryBuilder extends AbstractQueryBuilder<ExistsQueryBuilder> {
+public class ExistsQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "exists";
+    private String name;
 
-    private final String fieldName;
+    private String queryName;
 
-    static final ExistsQueryBuilder PROTOTYPE = new ExistsQueryBuilder(null);
-
-    public ExistsQueryBuilder(String fieldName) {
-        this.fieldName = fieldName;
+    public ExistsQueryBuilder(String name) {
+        this.name = name;
     }
 
     /**
-     * @return the field name that has to exist for this query to match
+     * Sets the query name for the query that can be used when searching for matched_queries per hit.
      */
-    public String fieldName() {
-        return this.fieldName;
+    public ExistsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("field", fieldName);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return newFilter(context, fieldName);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
-
-    public static Query newFilter(QueryShardContext context, String fieldPattern) {
-        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType)context.mapperService().fullName(FieldNamesFieldMapper.NAME);
-        if (fieldNamesFieldType == null) {
-            // can only happen when no types exist, so no docs exist either
-            return Queries.newMatchNoDocsQuery();
-        }
-
-        ObjectMapper objectMapper = context.getObjectMapper(fieldPattern);
-        if (objectMapper != null) {
-            // automatic make the object mapper pattern
-            fieldPattern = fieldPattern + ".*";
-        }
-
-        Collection<String> fields = context.simpleMatchToIndexNames(fieldPattern);
-        if (fields.isEmpty()) {
-            // no fields exists, so we should not match anything
-            return Queries.newMatchNoDocsQuery();
-        }
-
-        BooleanQuery.Builder boolFilterBuilder = new BooleanQuery.Builder();
-        for (String field : fields) {
-            MappedFieldType fieldType = context.fieldMapper(field);
-            Query filter = null;
-            if (fieldNamesFieldType.isEnabled()) {
-                final String f;
-                if (fieldType != null) {
-                    f = fieldType.names().indexName();
-                } else {
-                    f = field;
-                }
-                filter = fieldNamesFieldType.termQuery(f, context);
-            }
-            // if _field_names are not indexed, we need to go the slow way
-            if (filter == null && fieldType != null) {
-                filter = fieldType.rangeQuery(null, null, true, true);
-            }
-            if (filter == null) {
-                filter = new TermRangeQuery(field, null, null, true, true);
-            }
-            boolFilterBuilder.add(filter, BooleanClause.Occur.SHOULD);
+        builder.startObject(ExistsQueryParser.NAME);
+        builder.field("field", name);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return new ConstantScoreQuery(boolFilterBuilder.build());
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName);
-    }
-
-    @Override
-    protected boolean doEquals(ExistsQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName);
-    }
-
-    @Override
-    protected ExistsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new ExistsQueryBuilder(in.readString());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java
index bd584bc..9519667 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ExistsQueryParser.java
@@ -19,15 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.*;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
+import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
+import java.util.Collection;
 
 /**
- * Parser for exists query
+ *
  */
-public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
+public class ExistsQueryParser implements QueryParser {
+
+    public static final String NAME = "exists";
 
     @Inject
     public ExistsQueryParser() {
@@ -35,16 +43,15 @@ public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{ExistsQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public ExistsQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldPattern = null;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
 
         XContentParser.Token token;
         String currentFieldName = null;
@@ -56,8 +63,6 @@ public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
                     fieldPattern = parser.text();
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[exists] query does not support [" + currentFieldName + "]");
                 }
@@ -68,14 +73,56 @@ public class ExistsQueryParser extends BaseQueryParser<ExistsQueryBuilder> {
             throw new QueryParsingException(parseContext, "exists must be provided with a [field]");
         }
 
-        ExistsQueryBuilder builder = new ExistsQueryBuilder(fieldPattern);
-        builder.queryName(queryName);
-        builder.boost(boost);
-        return builder;
+        return newFilter(parseContext, fieldPattern, queryName);
     }
 
-    @Override
-    public ExistsQueryBuilder getBuilderPrototype() {
-        return ExistsQueryBuilder.PROTOTYPE;
+    public static Query newFilter(QueryParseContext parseContext, String fieldPattern, String queryName) {
+        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType)parseContext.mapperService().fullName(FieldNamesFieldMapper.NAME);
+        if (fieldNamesFieldType == null) {
+            // can only happen when no types exist, so no docs exist either
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        ObjectMapper objectMapper = parseContext.getObjectMapper(fieldPattern);
+        if (objectMapper != null) {
+            // automatic make the object mapper pattern
+            fieldPattern = fieldPattern + ".*";
+        }
+
+        Collection<String> fields = parseContext.simpleMatchToIndexNames(fieldPattern);
+        if (fields.isEmpty()) {
+            // no fields exists, so we should not match anything
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        BooleanQuery.Builder boolFilterBuilder = new BooleanQuery.Builder();
+        for (String field : fields) {
+            MappedFieldType fieldType = parseContext.fieldMapper(field);
+            Query filter = null;
+            if (fieldNamesFieldType.isEnabled()) {
+                final String f;
+                if (fieldType != null) {
+                    f = fieldType.names().indexName();
+                } else {
+                    f = field;
+                }
+                filter = fieldNamesFieldType.termQuery(f, parseContext);
+            }
+            // if _field_names are not indexed, we need to go the slow way
+            if (filter == null && fieldType != null) {
+                filter = fieldType.rangeQuery(null, null, true, true);
+            }
+            if (filter == null) {
+                filter = new TermRangeQuery(field, null, null, true, true);
+            }
+            boolFilterBuilder.add(filter, BooleanClause.Occur.SHOULD);
+        }
+
+        BooleanQuery boolFilter = boolFilterBuilder.build();
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, boolFilter);
+        }
+        return new ConstantScoreQuery(boolFilter);
     }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FQueryFilterBuilder.java b/core/src/main/java/org/elasticsearch/index/query/FQueryFilterBuilder.java
deleted file mode 100644
index 85fdad1..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/FQueryFilterBuilder.java
+++ /dev/null
@@ -1,111 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-
-import java.io.IOException;
-import java.util.Objects;
-
-/**
- * A filter that simply wraps a query. Same as the {@link QueryFilterBuilder} except that it allows also to
- * associate a name with the query filter.
- * @deprecated Useless now that queries and filters are merged: pass the
- *             query as a filter directly.
- */
-@Deprecated
-public class FQueryFilterBuilder extends AbstractQueryBuilder<FQueryFilterBuilder> {
-
-    public static final String NAME = "fquery";
-
-    static final FQueryFilterBuilder PROTOTYPE = new FQueryFilterBuilder(null);
-
-    private final QueryBuilder queryBuilder;
-
-    /**
-     * A filter that simply wraps a query.
-     *
-     * @param queryBuilder The query to wrap as a filter
-     */
-    public FQueryFilterBuilder(QueryBuilder queryBuilder) {
-        this.queryBuilder = queryBuilder;
-    }
-
-    /**
-     * @return the query builder that is wrapped by this {@link FQueryFilterBuilder}
-     */
-    public QueryBuilder innerQuery() {
-        return this.queryBuilder;
-    }
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(FQueryFilterBuilder.NAME);
-        builder.field("query");
-        queryBuilder.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerQuery = this.queryBuilder.toQuery(context);
-        if (innerQuery == null) {
-            return null;
-        }
-        return new ConstantScoreQuery(innerQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQuery(queryBuilder, null);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queryBuilder);
-    }
-
-    @Override
-    protected boolean doEquals(FQueryFilterBuilder other) {
-        return Objects.equals(queryBuilder, other.queryBuilder);
-    }
-
-    @Override
-    protected FQueryFilterBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder innerQueryBuilder = in.readQuery();
-        FQueryFilterBuilder fquery = new FQueryFilterBuilder(innerQueryBuilder);
-        return fquery;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(queryBuilder);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/FQueryFilterParser.java b/core/src/main/java/org/elasticsearch/index/query/FQueryFilterParser.java
index 46ab50f..4c0f782 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FQueryFilterParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FQueryFilterParser.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
@@ -27,11 +29,11 @@ import java.io.IOException;
 /**
  * The "fquery" filter is the same as the {@link QueryFilterParser} except that it allows also to
  * associate a name with the query filter.
- * @deprecated Useless now that queries and filters are merged: pass the
- *             query as a filter directly.
  */
 @Deprecated
-public class FQueryFilterParser extends BaseQueryParser<FQueryFilterBuilder> {
+public class FQueryFilterParser implements QueryParser {
+
+    public static final String NAME = "fquery";
 
     @Inject
     public FQueryFilterParser() {
@@ -39,17 +41,16 @@ public class FQueryFilterParser extends BaseQueryParser<FQueryFilterBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{FQueryFilterBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public FQueryFilterBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder wrappedQuery = null;
+        Query query = null;
         boolean queryFound = false;
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
         String currentFieldName = null;
         XContentParser.Token token;
@@ -61,15 +62,13 @@ public class FQueryFilterParser extends BaseQueryParser<FQueryFilterBuilder> {
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("query".equals(currentFieldName)) {
                     queryFound = true;
-                    wrappedQuery = parseContext.parseInnerQueryBuilder();
+                    query = parseContext.parseInnerQuery();
                 } else {
                     throw new QueryParsingException(parseContext, "[fquery] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[fquery] query does not support [" + currentFieldName + "]");
                 }
@@ -78,14 +77,13 @@ public class FQueryFilterParser extends BaseQueryParser<FQueryFilterBuilder> {
         if (!queryFound) {
             throw new QueryParsingException(parseContext, "[fquery] requires 'query' element");
         }
-        FQueryFilterBuilder queryBuilder = new FQueryFilterBuilder(wrappedQuery);
-        queryBuilder.queryName(queryName);
-        queryBuilder.boost(boost);
-        return queryBuilder;
-    }
-
-    @Override
-    public FQueryFilterBuilder getBuilderPrototype() {
-        return FQueryFilterBuilder.PROTOTYPE;
+        if (query == null) {
+            return null;
+        }
+        query = new ConstantScoreQuery(query);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java
index a577225..c118416 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilder.java
@@ -19,113 +19,52 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class FieldMaskingSpanQueryBuilder extends AbstractQueryBuilder<FieldMaskingSpanQueryBuilder> implements SpanQueryBuilder<FieldMaskingSpanQueryBuilder>{
-
-    public static final String NAME = "field_masking_span";
+public class FieldMaskingSpanQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<FieldMaskingSpanQueryBuilder> {
 
     private final SpanQueryBuilder queryBuilder;
 
-    private final String fieldName;
+    private final String field;
 
-    static final FieldMaskingSpanQueryBuilder PROTOTYPE = new FieldMaskingSpanQueryBuilder(null, null);
+    private float boost = -1;
 
-    /**
-     * Constructs a new {@link FieldMaskingSpanQueryBuilder} given an inner {@link SpanQueryBuilder} for
-     * a given field
-     * @param queryBuilder inner {@link SpanQueryBuilder}
-     * @param fieldName the field name
-     */
-    public FieldMaskingSpanQueryBuilder(SpanQueryBuilder queryBuilder, String fieldName) {
+    private String queryName;
+
+
+    public FieldMaskingSpanQueryBuilder(SpanQueryBuilder queryBuilder, String field) {
         this.queryBuilder = queryBuilder;
-        this.fieldName = fieldName;
+        this.field = field;
     }
 
-    /**
-     * @return the field name for this query
-     */
-    public String fieldName() {
-        return this.fieldName;
+    @Override
+    public FieldMaskingSpanQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
-     * @return the inner {@link QueryBuilder}
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public SpanQueryBuilder innerQuery() {
-        return this.queryBuilder;
+    public FieldMaskingSpanQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(FieldMaskingSpanQueryParser.NAME);
         builder.field("query");
         queryBuilder.toXContent(builder, params);
-        builder.field("field", fieldName);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected SpanQuery doToQuery(QueryShardContext context) throws IOException {
-        String fieldInQuery = fieldName;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            fieldInQuery = fieldType.names().indexName();
-        }
-        Query innerQuery = queryBuilder.toQuery(context);
-        assert innerQuery instanceof SpanQuery;
-        return new FieldMaskingSpanQuery((SpanQuery)innerQuery, fieldInQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (queryBuilder == null) {
-            validationException = addValidationError("inner clause [query] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(queryBuilder, validationException);
+        builder.field("field", field);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        if (fieldName == null || fieldName.isEmpty()) {
-            validationException = addValidationError("field name is null or empty", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    protected FieldMaskingSpanQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder innerQueryBuilder = in.readQuery();
-        return new FieldMaskingSpanQueryBuilder((SpanQueryBuilder) innerQueryBuilder, in.readString());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(queryBuilder);
-        out.writeString(fieldName);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queryBuilder, fieldName);
-    }
-
-    @Override
-    protected boolean doEquals(FieldMaskingSpanQueryBuilder other) {
-        return Objects.equals(queryBuilder, other.queryBuilder) &&
-               Objects.equals(fieldName, other.fieldName);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java
index ad77039..2980be1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FieldMaskingSpanQueryParser.java
@@ -19,15 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.FieldMapper;
+import org.elasticsearch.index.mapper.MappedFieldType;
+
 import java.io.IOException;
 
 /**
- * Parser for field_masking_span query
+ *
  */
-public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpanQueryBuilder> {
+public class FieldMaskingSpanQueryParser implements QueryParser {
+
+    public static final String NAME = "field_masking_span";
 
     @Inject
     public FieldMaskingSpanQueryParser() {
@@ -35,16 +43,16 @@ public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpa
 
     @Override
     public String[] names() {
-        return new String[]{FieldMaskingSpanQueryBuilder.NAME, Strings.toCamelCase(FieldMaskingSpanQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public FieldMaskingSpanQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
-        SpanQueryBuilder inner = null;
+        SpanQuery inner = null;
         String field = null;
         String queryName = null;
 
@@ -55,11 +63,11 @@ public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpa
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("query".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
-                        throw new QueryParsingException(parseContext, "[field_masking_span] query must be of type span query");
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
+                        throw new QueryParsingException(parseContext, "[field_masking_span] query] must be of type span query");
                     }
-                    inner = (SpanQueryBuilder) query;
+                    inner = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[field_masking_span] query does not support ["
                             + currentFieldName + "]");
@@ -83,14 +91,16 @@ public class FieldMaskingSpanQueryParser extends BaseQueryParser<FieldMaskingSpa
             throw new QueryParsingException(parseContext, "field_masking_span must have [field] set for it");
         }
 
-        FieldMaskingSpanQueryBuilder queryBuilder = new FieldMaskingSpanQueryBuilder(inner, field);
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
+        MappedFieldType fieldType = parseContext.fieldMapper(field);
+        if (fieldType != null) {
+            field = fieldType.names().indexName();
+        }
 
-    @Override
-    public FieldMaskingSpanQueryBuilder getBuilderPrototype() {
-        return FieldMaskingSpanQueryBuilder.PROTOTYPE;
+        FieldMaskingSpanQuery query = new FieldMaskingSpanQuery(inner, field);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/FilteredQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/FilteredQueryBuilder.java
index bebe592..93507cf 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FilteredQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FilteredQueryBuilder.java
@@ -19,131 +19,72 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
+import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A query that applies a filter to the results of another query.
  * @deprecated Use {@link BoolQueryBuilder} instead.
  */
 @Deprecated
-public class FilteredQueryBuilder extends AbstractQueryBuilder<FilteredQueryBuilder> {
+public class FilteredQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<FilteredQueryBuilder> {
 
-    /** Name of the query in the REST API. */
-    public static final String NAME = "filtered";
-    /** The query to filter. */
     private final QueryBuilder queryBuilder;
-    /** The filter to apply to the query. */
+
     private final QueryBuilder filterBuilder;
 
-    static final FilteredQueryBuilder PROTOTYPE = new FilteredQueryBuilder(null, null);
+    private float boost = -1;
 
-    /**
-     * Returns a {@link MatchAllQueryBuilder} instance that will be used as
-     * default queryBuilder if none is supplied by the user. Feel free to
-     * set queryName and boost on that instance - it's always a new one.
-     * */
-    private static QueryBuilder generateDefaultQuery() {
-        return new MatchAllQueryBuilder();
-    }
-
-    /**
-     * A query that applies a filter to the results of a match_all query.
-     * @param filterBuilder The filter to apply on the query (Can be null)
-     * */
-    public FilteredQueryBuilder(QueryBuilder filterBuilder) {
-        this(generateDefaultQuery(), filterBuilder);
-    }
+    private String queryName;
 
     /**
      * A query that applies a filter to the results of another query.
      *
-     * @param queryBuilder  The query to apply the filter to
+     * @param queryBuilder  The query to apply the filter to (Can be null)
      * @param filterBuilder The filter to apply on the query (Can be null)
      */
-    public FilteredQueryBuilder(QueryBuilder queryBuilder, QueryBuilder filterBuilder) {
-        this.queryBuilder = (queryBuilder != null) ? queryBuilder : generateDefaultQuery();
-        this.filterBuilder = (filterBuilder != null) ? filterBuilder : EmptyQueryBuilder.PROTOTYPE;
-    }
-
-    /** Returns the query to apply the filter to. */
-    public QueryBuilder innerQuery() {
-        return queryBuilder;
-    }
-
-    /** Returns the filter to apply to the query results. */
-    public QueryBuilder innerFilter() {
-        return filterBuilder;
-    }
-
-    @Override
-    protected boolean doEquals(FilteredQueryBuilder other) {
-        return Objects.equals(queryBuilder, other.queryBuilder) &&
-                Objects.equals(filterBuilder, other.filterBuilder);
+    public FilteredQueryBuilder(@Nullable QueryBuilder queryBuilder, @Nullable QueryBuilder filterBuilder) {
+        this.queryBuilder = queryBuilder;
+        this.filterBuilder = filterBuilder;
     }
 
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    public int doHashCode() {
-        return Objects.hash(queryBuilder, filterBuilder);
+    public FilteredQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    public Query doToQuery(QueryShardContext context) throws QueryShardException, IOException {
-        Query query = queryBuilder.toQuery(context);
-        Query filter = filterBuilder.toFilter(context);
-
-        if (query == null) {
-            // Most likely this query was generated from the JSON query DSL - it parsed to an EmptyQueryBuilder so we ignore
-            // the whole filtered query as there is nothing to filter on. See FilteredQueryParser for an example.
-            return null;
-        }
-
-        // use a BooleanQuery
-        return Queries.filtered(query, filter);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        validationException = validateInnerQuery(queryBuilder, validationException);
-        validationException = validateInnerQuery(filterBuilder, validationException);
-        return validationException;
-
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public FilteredQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("query");
-        queryBuilder.toXContent(builder, params);
-        builder.field("filter");
-        filterBuilder.toXContent(builder, params);
-        printBoostAndQueryName(builder);
+        builder.startObject(FilteredQueryParser.NAME);
+        if (queryBuilder != null) {
+            builder.field("query");
+            queryBuilder.toXContent(builder, params);
+        }
+        if (filterBuilder != null) {
+            builder.field("filter");
+            filterBuilder.toXContent(builder, params);
+        }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public FilteredQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder query = in.readQuery();
-        QueryBuilder filter = in.readQuery();
-        FilteredQueryBuilder qb = new FilteredQueryBuilder(query, filter);
-        return qb;
-    }
-
-    @Override
-    public void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(queryBuilder);
-        out.writeQuery(filterBuilder);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FilteredQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/FilteredQueryParser.java
index b010e61..919b685 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FilteredQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FilteredQueryParser.java
@@ -19,17 +19,21 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
 /**
- * Parser for filtered query.
- * @deprecated Use {@link BoolQueryParser} instead.
+ *
  */
 @Deprecated
-public class FilteredQueryParser extends BaseQueryParser<FilteredQueryBuilder> {
+public class FilteredQueryParser implements QueryParser {
+
+    public static final String NAME = "filtered";
 
     @Inject
     public FilteredQueryParser() {
@@ -37,16 +41,17 @@ public class FilteredQueryParser extends BaseQueryParser<FilteredQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{FilteredQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public FilteredQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder query = null;
-        QueryBuilder filter = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        Query query = Queries.newMatchAllQuery();
+        Query filter = null;
+        boolean filterFound = false;
+        float boost = 1.0f;
         String queryName = null;
 
         String currentFieldName = null;
@@ -59,9 +64,10 @@ public class FilteredQueryParser extends BaseQueryParser<FilteredQueryBuilder> {
                 // skip
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("query".equals(currentFieldName)) {
-                    query = parseContext.parseInnerQueryBuilder();
+                    query = parseContext.parseInnerQuery();
                 } else if ("filter".equals(currentFieldName)) {
-                    filter = parseContext.parseInnerFilterToQueryBuilder();
+                    filterFound = true;
+                    filter = parseContext.parseInnerFilter();
                 } else {
                     throw new QueryParsingException(parseContext, "[filtered] query does not support [" + currentFieldName + "]");
                 }
@@ -78,14 +84,16 @@ public class FilteredQueryParser extends BaseQueryParser<FilteredQueryBuilder> {
             }
         }
 
-        FilteredQueryBuilder qb = new FilteredQueryBuilder(query, filter);
-        qb.boost(boost);
-        qb.queryName(queryName);
-        return qb;
-    }
+        // parsed internally, but returned null during parsing...
+        if (query == null) {
+            return null;
+        }
 
-    @Override
-    public FilteredQueryBuilder getBuilderPrototype() {
-        return FilteredQueryBuilder.PROTOTYPE;
+        BooleanQuery filteredQuery = Queries.filtered(query, filter);
+        filteredQuery.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, filteredQuery);
+        }
+        return filteredQuery;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java
index 237b415..23557b1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryBuilder.java
@@ -19,273 +19,177 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that does fuzzy matching for a specific value.
  */
-public class FuzzyQueryBuilder extends AbstractQueryBuilder<FuzzyQueryBuilder> implements MultiTermQueryBuilder<FuzzyQueryBuilder> {
+public class FuzzyQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<FuzzyQueryBuilder> {
 
-    public static final String NAME = "fuzzy";
-
-    /** Default maximum edit distance. Defaults to AUTO. */
-    public static final Fuzziness DEFAULT_FUZZINESS = Fuzziness.AUTO;
-
-    /** Default number of initial characters which will not be fuzzified. Defaults to 0. */
-    public static final int DEFAULT_PREFIX_LENGTH = FuzzyQuery.defaultPrefixLength;
-
-    /** Default maximum number of terms that the fuzzy query will expand to. Defaults to 50. */
-    public static final int DEFAULT_MAX_EXPANSIONS = FuzzyQuery.defaultMaxExpansions;
-
-    /** Default as to whether transpositions should be treated as a primitive edit operation, 
-     * instead of classic Levenshtein algorithm. Defaults to false. */
-    public static final boolean DEFAULT_TRANSPOSITIONS = false;
-
-    private final String fieldName;
+    private final String name;
 
     private final Object value;
 
-    private Fuzziness fuzziness = DEFAULT_FUZZINESS;
+    private float boost = -1;
 
-    private int prefixLength = DEFAULT_PREFIX_LENGTH;
+    private Fuzziness fuzziness;
 
-    private int maxExpansions = DEFAULT_MAX_EXPANSIONS;
+    private Integer prefixLength;
 
+    private Integer maxExpansions;
+    
     //LUCENE 4 UPGRADE  we need a testcase for this + documentation
-    private boolean transpositions = DEFAULT_TRANSPOSITIONS;
+    private Boolean transpositions;
 
     private String rewrite;
 
-    static final FuzzyQueryBuilder PROTOTYPE = new FuzzyQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, String value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, Object value) {
+        this.name = name;
+        this.value = value;
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, int value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, String value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, long value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, int value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, float value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, long value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, double value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, float value) {
+        this(name, (Object) value);
     }
 
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
+     * @param name  The name of the field
      * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, boolean value) {
-        this(fieldName, (Object) value);
+    public FuzzyQueryBuilder(String name, double value) {
+        this(name, (Object) value);
     }
 
+    // NO COMMIT: not sure we should also allow boolean?
     /**
      * Constructs a new fuzzy query.
      *
-     * @param fieldName  The name of the field
-     * @param value The value of the term
+     * @param name  The name of the field
+     * @param value The value of the text
      */
-    public FuzzyQueryBuilder(String fieldName, Object value) {
-        this.fieldName = fieldName;
-        this.value = convertToBytesRefIfString(value);
+    public FuzzyQueryBuilder(String name, boolean value) {
+        this(name, (Object) value);
     }
 
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public Object value() {
-        return convertToStringIfBytesRef(this.value);
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public FuzzyQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     public FuzzyQueryBuilder fuzziness(Fuzziness fuzziness) {
-        this.fuzziness = (fuzziness == null) ? DEFAULT_FUZZINESS : fuzziness;
+        this.fuzziness = fuzziness;
         return this;
     }
-    
-    public Fuzziness fuzziness() {
-        return this.fuzziness;
-    }
 
     public FuzzyQueryBuilder prefixLength(int prefixLength) {
         this.prefixLength = prefixLength;
         return this;
     }
-    
-    public int prefixLength() {
-        return this.prefixLength;
-    }
 
     public FuzzyQueryBuilder maxExpansions(int maxExpansions) {
         this.maxExpansions = maxExpansions;
         return this;
     }
-
-    public int maxExpansions() {
-        return this.maxExpansions;
-    }
-
+    
     public FuzzyQueryBuilder transpositions(boolean transpositions) {
       this.transpositions = transpositions;
       return this;
     }
 
-    public boolean transpositions() {
-        return this.transpositions;
-    }
-
     public FuzzyQueryBuilder rewrite(String rewrite) {
         this.rewrite = rewrite;
         return this;
     }
 
-    public String rewrite() {
-        return this.rewrite;
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public FuzzyQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("value", convertToStringIfBytesRef(this.value));
-        fuzziness.toXContent(builder, params);
-        builder.field("prefix_length", prefixLength);
-        builder.field("max_expansions", maxExpansions);
-        builder.field("transpositions", transpositions);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
+        builder.startObject(FuzzyQueryParser.NAME);
+        builder.startObject(name);
+        builder.field("value", value);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public Query doToQuery(QueryShardContext context) throws QueryParsingException, IOException {
-        Query query = null;
-        if (rewrite == null && context.isFilter()) {
-            rewrite = QueryParsers.CONSTANT_SCORE.getPreferredName();
+        if (transpositions != null) {
+            builder.field("transpositions", transpositions);
         }
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            query = fieldType.fuzzyQuery(value, fuzziness, prefixLength, maxExpansions, transpositions);
+        if (fuzziness != null) {
+            fuzziness.toXContent(builder, params);
         }
-        if (query == null) {
-            int maxEdits = fuzziness.asDistance(BytesRefs.toString(value));
-            query = new FuzzyQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), maxEdits, prefixLength, maxExpansions, transpositions);
+        if (prefixLength != null) {
+            builder.field("prefix_length", prefixLength);
         }
-        if (query instanceof MultiTermQuery) {
-            MultiTermQuery.RewriteMethod rewriteMethod = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-            QueryParsers.setRewriteMethod((MultiTermQuery) query, rewriteMethod);
+        if (maxExpansions != null) {
+            builder.field("max_expansions", maxExpansions);
         }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
+        if (rewrite != null) {
+            builder.field("rewrite", rewrite);
         }
-        if (this.value == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    public FuzzyQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        FuzzyQueryBuilder fuzzyQueryBuilder = new FuzzyQueryBuilder(in.readString(), in.readGenericValue());
-        fuzzyQueryBuilder.fuzziness = Fuzziness.readFuzzinessFrom(in);
-        fuzzyQueryBuilder.prefixLength = in.readVInt();
-        fuzzyQueryBuilder.maxExpansions = in.readVInt();
-        fuzzyQueryBuilder.transpositions = in.readBoolean();
-        fuzzyQueryBuilder.rewrite = in.readOptionalString();
-        return fuzzyQueryBuilder;
-    }
-
-    @Override
-    public void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(this.fieldName);
-        out.writeGenericValue(this.value);
-        this.fuzziness.writeTo(out);
-        out.writeVInt(this.prefixLength);
-        out.writeVInt(this.maxExpansions);
-        out.writeBoolean(this.transpositions);
-        out.writeOptionalString(this.rewrite);
-    }
-
-    @Override
-    public int doHashCode() {
-        return Objects.hash(fieldName, value, fuzziness, prefixLength, maxExpansions, transpositions, rewrite);
-    }
-
-    @Override
-    public boolean doEquals(FuzzyQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(fuzziness, other.fuzziness) &&
-                Objects.equals(prefixLength, other.prefixLength) &&
-                Objects.equals(maxExpansions, other.maxExpansions) &&
-                Objects.equals(transpositions, other.transpositions) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java
index 694a303..aefdb4c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/FuzzyQueryParser.java
@@ -19,48 +19,60 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
-public class FuzzyQueryParser extends BaseQueryParser {
+/**
+ *
+ */
+public class FuzzyQueryParser implements QueryParser {
 
+    public static final String NAME = "fuzzy";
+    private static final Fuzziness DEFAULT_FUZZINESS = Fuzziness.AUTO;
     private static final ParseField FUZZINESS = Fuzziness.FIELD.withDeprecation("min_similarity");
 
+
     @Inject
     public FuzzyQueryParser() {
     }
 
     @Override
     public String[] names() {
-        return new String[]{ FuzzyQueryBuilder.NAME };
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.nextToken();
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new QueryParsingException(parseContext, "[fuzzy] query malformed, no field");
         }
-        
         String fieldName = parser.currentName();
-        Object value = null;
-
-        Fuzziness fuzziness = FuzzyQueryBuilder.DEFAULT_FUZZINESS;
-        int prefixLength = FuzzyQueryBuilder.DEFAULT_PREFIX_LENGTH;
-        int maxExpansions = FuzzyQueryBuilder.DEFAULT_MAX_EXPANSIONS;
-        boolean transpositions = FuzzyQueryBuilder.DEFAULT_TRANSPOSITIONS;
-        String rewrite = null;
 
+        Object value = null;
+        float boost = 1.0f;
+        Fuzziness fuzziness = DEFAULT_FUZZINESS;
+        int prefixLength = FuzzyQuery.defaultPrefixLength;
+        int maxExpansions = FuzzyQuery.defaultMaxExpansions;
+        boolean transpositions = FuzzyQuery.defaultTranspositions;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-
+        MultiTermQuery.RewriteMethod rewriteMethod = null;
+        if (parseContext.isFilter()) {
+            rewriteMethod = MultiTermQuery.CONSTANT_SCORE_REWRITE;
+        }
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
             String currentFieldName = null;
@@ -81,9 +93,9 @@ public class FuzzyQueryParser extends BaseQueryParser {
                     } else if ("max_expansions".equals(currentFieldName) || "maxExpansions".equals(currentFieldName)) {
                         maxExpansions = parser.intValue();
                     } else if ("transpositions".equals(currentFieldName)) {
-                        transpositions = parser.booleanValue();
+                      transpositions = parser.booleanValue();
                     } else if ("rewrite".equals(currentFieldName)) {
-                        rewrite = parser.textOrNull();
+                        rewriteMethod = QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), parser.textOrNull(), null);
                     } else if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
                     } else {
@@ -99,20 +111,26 @@ public class FuzzyQueryParser extends BaseQueryParser {
         }
 
         if (value == null) {
-            throw new QueryParsingException(parseContext, "no value specified for fuzzy query");
+            throw new QueryParsingException(parseContext, "No value specified for fuzzy query");
         }
-        return new FuzzyQueryBuilder(fieldName, value)
-                .fuzziness(fuzziness)
-                .prefixLength(prefixLength)
-                .maxExpansions(maxExpansions)
-                .transpositions(transpositions)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
+        
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.fuzzyQuery(value, fuzziness, prefixLength, maxExpansions, transpositions);
+        }
+        if (query == null) {
+            int maxEdits = fuzziness.asDistance(BytesRefs.toString(value));
+            query = new FuzzyQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), maxEdits, prefixLength, maxExpansions, transpositions);
+        }
+        if (query instanceof MultiTermQuery) {
+            QueryParsers.setRewriteMethod((MultiTermQuery) query, rewriteMethod);
+        }
+        query.setBoost(boost);
 
-    @Override
-    public FuzzyQueryBuilder getBuilderPrototype() {
-        return FuzzyQueryBuilder.PROTOTYPE;
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java
index 594cc6e..99b348e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryBuilder.java
@@ -25,9 +25,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 
-public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBoundingBoxQueryBuilder> {
-
-    public static final String NAME = "geo_bbox";
+public class GeoBoundingBoxQueryBuilder extends QueryBuilder {
 
     public static final String TOP_LEFT = GeoBoundingBoxQueryParser.TOP_LEFT;
     public static final String BOTTOM_RIGHT = GeoBoundingBoxQueryParser.BOTTOM_RIGHT;
@@ -36,17 +34,16 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
     private static final int LEFT = 1;
     private static final int BOTTOM = 2;
     private static final int RIGHT = 3;
-
+    
     private final String name;
 
     private double[] box = {Double.NaN, Double.NaN, Double.NaN, Double.NaN};
 
+    private String queryName;
     private String type;
     private Boolean coerce;
     private Boolean ignoreMalformed;
 
-    static final GeoBoundingBoxQueryBuilder PROTOTYPE = new GeoBoundingBoxQueryBuilder(null);
-
     public GeoBoundingBoxQueryBuilder(String name) {
         this.name = name;
     }
@@ -110,7 +107,7 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
     public GeoBoundingBoxQueryBuilder bottomLeft(String geohash) {
         return bottomLeft(GeoHashUtils.decode(geohash));
     }
-
+    
     /**
      * Adds top right point.
      *
@@ -131,6 +128,14 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
         return topRight(GeoHashUtils.decode(geohash));
     }
 
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoBoundingBoxQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     public GeoBoundingBoxQueryBuilder coerce(boolean coerce) {
         this.coerce = coerce;
         return this;
@@ -162,14 +167,17 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
         } else if(Double.isNaN(box[LEFT])) {
             throw new IllegalArgumentException("geo_bounding_box requires left longitude to be set");
         }
-
-        builder.startObject(NAME);
+                
+        builder.startObject(GeoBoundingBoxQueryParser.NAME);
 
         builder.startObject(name);
         builder.array(TOP_LEFT, box[LEFT], box[TOP]);
         builder.array(BOTTOM_RIGHT, box[RIGHT], box[BOTTOM]);
         builder.endObject();
 
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (type != null) {
             builder.field("type", type);
         }
@@ -180,13 +188,6 @@ public class GeoBoundingBoxQueryBuilder extends AbstractQueryBuilder<GeoBounding
             builder.field("ignore_malformed", ignoreMalformed);
         }
 
-        printBoostAndQueryName(builder);
-
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java
index 1476c2e..6dead6e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoBoundingBoxQueryParser.java
@@ -37,7 +37,7 @@ import java.io.IOException;
 /**
  *
  */
-public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
+public class GeoBoundingBoxQueryParser implements QueryParser {
 
     public static final String NAME = "geo_bbox";
 
@@ -64,12 +64,11 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{GeoBoundingBoxQueryBuilder.NAME, "geoBbox", "geo_bounding_box", "geoBoundingBox"};
+        return new String[]{NAME, "geoBbox", "geo_bounding_box", "geoBoundingBox"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
@@ -78,17 +77,16 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
         double bottom = Double.NaN;
         double left = Double.NaN;
         double right = Double.NaN;
-
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        
         String queryName = null;
         String currentFieldName = null;
         XContentParser.Token token;
-        final boolean indexCreatedBeforeV2_0 = parseContext.shardContext().indexVersionCreated().before(Version.V_2_0_0);
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
         boolean coerce = false;
         boolean ignoreMalformed = false;
 
         GeoPoint sparse = new GeoPoint();
-
+        
         String type = "memory";
 
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -141,11 +139,9 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
                     coerce = parser.booleanValue();
-                    if (coerce) {
+                    if (coerce == true) {
                         ignoreMalformed = true;
                     }
                 } else if ("type".equals(currentFieldName)) {
@@ -189,7 +185,7 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
             }
         }
 
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
             throw new QueryParsingException(parseContext, "failed to parse [{}] query. could not find [{}] field [{}]", NAME, GeoPointFieldMapper.CONTENT_TYPE, fieldName);
         }
@@ -202,22 +198,15 @@ public class GeoBoundingBoxQueryParser extends BaseQueryParserTemp {
         if ("indexed".equals(type)) {
             filter = IndexedGeoBoundingBoxQuery.create(topLeft, bottomRight, geoFieldType);
         } else if ("memory".equals(type)) {
-            IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+            IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
             filter = new InMemoryGeoBoundingBoxQuery(topLeft, bottomRight, indexFieldData);
         } else {
             throw new QueryParsingException(parseContext, "failed to parse [{}] query. geo bounding box type [{}] is not supported. either [indexed] or [memory] are allowed", NAME, type);
         }
-        if (filter != null) {
-            filter.setBoost(boost);
-        }
+
         if (queryName != null) {
-            context.addNamedQuery(queryName, filter);
+            parseContext.addNamedQuery(queryName, filter);
         }
         return filter;
-    }
-
-    @Override
-    public GeoBoundingBoxQueryBuilder getBuilderPrototype() {
-        return GeoBoundingBoxQueryBuilder.PROTOTYPE;
-    }
+    }    
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java
index 6f883bd..77c8f94 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryBuilder.java
@@ -26,9 +26,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import java.io.IOException;
 import java.util.Locale;
 
-public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQueryBuilder> {
-
-    public static final String NAME = "geo_distance";
+public class GeoDistanceQueryBuilder extends QueryBuilder {
 
     private final String name;
 
@@ -44,7 +42,7 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
 
     private String optimizeBbox;
 
-    static final GeoDistanceQueryBuilder PROTOTYPE = new GeoDistanceQueryBuilder(null);
+    private String queryName;
 
     private Boolean coerce;
 
@@ -95,6 +93,14 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
         return this;
     }
 
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoDistanceQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     public GeoDistanceQueryBuilder coerce(boolean coerce) {
         this.coerce = coerce;
         return this;
@@ -107,7 +113,7 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(GeoDistanceQueryParser.NAME);
         if (geohash != null) {
             builder.field(name, geohash);
         } else {
@@ -120,18 +126,15 @@ public class GeoDistanceQueryBuilder extends AbstractQueryBuilder<GeoDistanceQue
         if (optimizeBbox != null) {
             builder.field("optimize_bbox", optimizeBbox);
         }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (coerce != null) {
             builder.field("coerce", coerce);
         }
         if (ignoreMalformed != null) {
             builder.field("ignore_malformed", ignoreMalformed);
         }
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java
index 647e1d0..8201381 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceQueryParser.java
@@ -43,7 +43,9 @@ import java.io.IOException;
  * }
  * </pre>
  */
-public class GeoDistanceQueryParser extends BaseQueryParserTemp {
+public class GeoDistanceQueryParser implements QueryParser {
+
+    public static final String NAME = "geo_distance";
 
     @Inject
     public GeoDistanceQueryParser() {
@@ -51,17 +53,15 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{GeoDistanceQueryBuilder.NAME, "geoDistance"};
+        return new String[]{NAME, "geoDistance"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token;
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
         String currentFieldName = null;
         GeoPoint point = new GeoPoint();
@@ -71,7 +71,7 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         DistanceUnit unit = DistanceUnit.DEFAULT;
         GeoDistance geoDistance = GeoDistance.DEFAULT;
         String optimizeBbox = "memory";
-        final boolean indexCreatedBeforeV2_0 = parseContext.shardContext().indexVersionCreated().before(Version.V_2_0_0);
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
         boolean coerce = false;
         boolean ignoreMalformed = false;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -124,8 +124,6 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
                     fieldName = currentFieldName.substring(0, currentFieldName.length() - GeoPointFieldMapper.Names.GEOHASH_SUFFIX.length());
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if ("optimize_bbox".equals(currentFieldName) || "optimizeBbox".equals(currentFieldName)) {
                     optimizeBbox = parser.textOrNull();
                 } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
@@ -145,10 +143,10 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed on 2.x created indexes
         if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
             if (point.lat() > 90.0 || point.lat() < -90.0) {
-                throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), GeoDistanceQueryBuilder.NAME);
+                throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), NAME);
             }
             if (point.lon() > 180.0 || point.lon() < -180) {
-                throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), GeoDistanceQueryBuilder.NAME);
+                throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), NAME);
             }
         }
 
@@ -165,7 +163,7 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         }
         distance = geoDistance.normalize(distance, DistanceUnit.DEFAULT);
 
-        MappedFieldType fieldType = parseContext.shardContext().fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
             throw new QueryParsingException(parseContext, "failed to find geo_point field [" + fieldName + "]");
         }
@@ -175,17 +173,11 @@ public class GeoDistanceQueryParser extends BaseQueryParserTemp {
         GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
 
 
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
         Query query = new GeoDistanceRangeQuery(point, null, distance, true, false, geoDistance, geoFieldType, indexFieldData, optimizeBbox);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
-        query.setBoost(boost);
         return query;
     }
-
-    @Override
-    public GeoDistanceQueryBuilder getBuilderPrototype() {
-        return GeoDistanceQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java
index 2f69dfa..6aa6f0f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java
@@ -19,76 +19,55 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.Version;
 import org.elasticsearch.common.geo.GeoDistance;
-import org.elasticsearch.common.geo.GeoPoint;
-import org.elasticsearch.common.geo.GeoUtils;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.unit.DistanceUnit;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.fielddata.IndexGeoPointFieldData;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
-import org.elasticsearch.index.search.geo.GeoDistanceRangeQuery;
 
 import java.io.IOException;
 import java.util.Locale;
-import java.util.Objects;
 
-public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistanceRangeQueryBuilder> {
+public class GeoDistanceRangeQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "geo_distance_range";
-    public static final boolean DEFAULT_INCLUDE_LOWER = true;
-    public static final boolean DEFAULT_INCLUDE_UPPER = true;
-    public static final GeoDistance DEFAULT_GEO_DISTANCE = GeoDistance.DEFAULT;
-    public static final DistanceUnit DEFAULT_UNIT = DistanceUnit.DEFAULT;
-    public static final String DEFAULT_OPTIMIZE_BBOX = "memory";
-    public static final boolean DEFAULT_COERCE = false;
-    public static final boolean DEFAULT_IGNORE_MALFORMED = false;
-
-    private final String fieldName;
+    private final String name;
 
     private Object from;
     private Object to;
-    private boolean includeLower = DEFAULT_INCLUDE_LOWER;
-    private boolean includeUpper = DEFAULT_INCLUDE_UPPER;
+    private boolean includeLower = true;
+    private boolean includeUpper = true;
 
-    private GeoPoint point;
+    private double lat;
 
-    private GeoDistance geoDistance = DEFAULT_GEO_DISTANCE;
+    private double lon;
 
-    private DistanceUnit unit = DEFAULT_UNIT;
+    private String geohash;
 
-    private String optimizeBbox = DEFAULT_OPTIMIZE_BBOX;
+    private GeoDistance geoDistance;
 
-    private boolean coerce = DEFAULT_COERCE;
+    private String queryName;
 
-    private boolean ignoreMalformed = DEFAULT_IGNORE_MALFORMED;
+    private String optimizeBbox;
 
-    static final GeoDistanceRangeQueryBuilder PROTOTYPE = new GeoDistanceRangeQueryBuilder(null);
+    private Boolean coerce;
 
-    public GeoDistanceRangeQueryBuilder(String fieldName) {
-        this.fieldName = fieldName;
-    }
+    private Boolean ignoreMalformed;
 
-    public String fieldName() {
-        return fieldName;
+    public GeoDistanceRangeQueryBuilder(String name) {
+        this.name = name;
     }
 
     public GeoDistanceRangeQueryBuilder point(double lat, double lon) {
-        this.point = new GeoPoint(lat, lon);
+        this.lat = lat;
+        this.lon = lon;
         return this;
     }
 
-    public GeoDistanceRangeQueryBuilder point(GeoPoint point) {
-        this.point = point;
+    public GeoDistanceRangeQueryBuilder lat(double lat) {
+        this.lat = lat;
         return this;
     }
 
-    public GeoPoint point() {
-        return point;
+    public GeoDistanceRangeQueryBuilder lon(double lon) {
+        this.lon = lon;
+        return this;
     }
 
     public GeoDistanceRangeQueryBuilder from(Object from) {
@@ -96,19 +75,11 @@ public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistan
         return this;
     }
 
-    public Object from() {
-        return from;
-    }
-
     public GeoDistanceRangeQueryBuilder to(Object to) {
         this.to = to;
         return this;
     }
 
-    public Object to() {
-        return to;
-    }
-
     public GeoDistanceRangeQueryBuilder gt(Object from) {
         this.from = from;
         this.includeLower = false;
@@ -138,21 +109,13 @@ public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistan
         return this;
     }
 
-    public boolean includeLower() {
-        return includeLower;
-    }
-
     public GeoDistanceRangeQueryBuilder includeUpper(boolean includeUpper) {
         this.includeUpper = includeUpper;
         return this;
     }
 
-    public boolean includeUpper() {
-        return includeUpper;
-    }
-
     public GeoDistanceRangeQueryBuilder geohash(String geohash) {
-        this.point = new GeoPoint().resetFromGeoHash(geohash);
+        this.geohash = geohash;
         return this;
     }
 
@@ -161,235 +124,56 @@ public class GeoDistanceRangeQueryBuilder extends AbstractQueryBuilder<GeoDistan
         return this;
     }
 
-    public GeoDistance geoDistance() {
-        return geoDistance;
-    }
-
-    public GeoDistanceRangeQueryBuilder unit(DistanceUnit unit) {
-        this.unit = unit;
-        return this;
-    }
-
-    public DistanceUnit unit() {
-        return unit;
-    }
-
     public GeoDistanceRangeQueryBuilder optimizeBbox(String optimizeBbox) {
         this.optimizeBbox = optimizeBbox;
         return this;
     }
 
-    public String optimizeBbox() {
-        return optimizeBbox;
-    }
-
     public GeoDistanceRangeQueryBuilder coerce(boolean coerce) {
-        if (coerce) {
-            this.ignoreMalformed = true;
-        }
         this.coerce = coerce;
         return this;
     }
 
-    public boolean coerce() {
-        return this.coerce;
-    }
-
     public GeoDistanceRangeQueryBuilder ignoreMalformed(boolean ignoreMalformed) {
-        if (coerce == false) {
-            this.ignoreMalformed = ignoreMalformed;
-        }
+        this.ignoreMalformed = ignoreMalformed;
         return this;
     }
 
-    public boolean ignoreMalformed() {
-        return ignoreMalformed;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException errors = null;
-        if (fieldName == null) {
-            errors = QueryValidationException.addValidationError(NAME, "fieldName must not be null", errors);
-        }
-        if (point == null) {
-            errors = QueryValidationException.addValidationError(NAME, "point must not be null", errors);
-        }
-        if (from == null && to == null) {
-            errors = QueryValidationException.addValidationError(NAME, "Must define at least one parameter from [from, to]", errors);
-        }
-        if (from != null && !(from instanceof Number || from instanceof String)) {
-            errors = QueryValidationException.addValidationError(NAME, "from must either be a number or a string. Found ["
-                    + from.getClass().getName() + "]", errors);
-        }
-        if (to != null && !(to instanceof Number || to instanceof String)) {
-            errors = QueryValidationException.addValidationError(NAME, "to must either be a number or a string. Found ["
-                    + to.getClass().getName() + "]", errors);
-        }
-        if (optimizeBbox != null && !(optimizeBbox.equals("none") || optimizeBbox.equals("memory") || optimizeBbox.equals("indexed"))) {
-            errors = QueryValidationException.addValidationError(NAME, "optimizeBbox must be one of [none, memory, indexed]", errors);
-        }
-        return errors;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-
-        final boolean indexCreatedBeforeV2_0 = context.indexVersionCreated().before(Version.V_2_0_0);
-        // validation was not available prior to 2.x, so to support bwc
-        // percolation queries we only ignore_malformed on 2.x created indexes
-        if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
-            if (point.lat() > 90.0 || point.lat() < -90.0) {
-                throw new QueryShardException(context, "illegal latitude value [{}] for [{}]", point.lat(), NAME);
-            }
-            if (point.lon() > 180.0 || point.lon() < -180) {
-                throw new QueryShardException(context, "illegal longitude value [{}] for [{}]", point.lon(), NAME);
-            }
-        }
-
-        if (coerce) {
-            GeoUtils.normalizePoint(point, coerce, coerce);
-        }
-
-        Double fromValue = null;
-        Double toValue = null;
-        if (from != null) {
-            if (from instanceof Number) {
-                fromValue = unit.toMeters(((Number) from).doubleValue());
-            } else {
-                fromValue = DistanceUnit.parse((String) from, unit, DistanceUnit.DEFAULT);
-            }
-            fromValue = geoDistance.normalize(fromValue, DistanceUnit.DEFAULT);
-        }
-        if (to != null) {
-            if (to instanceof Number) {
-                toValue = unit.toMeters(((Number) to).doubleValue());
-            } else {
-                toValue = DistanceUnit.parse((String) to, unit, DistanceUnit.DEFAULT);
-            }
-            toValue = geoDistance.normalize(toValue, DistanceUnit.DEFAULT);
-        }
-
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType == null) {
-            throw new QueryShardException(context, "failed to find geo_point field [" + fieldName + "]");
-        }
-        if (!(fieldType instanceof GeoPointFieldMapper.GeoPointFieldType)) {
-            throw new QueryShardException(context, "field [" + fieldName + "] is not a geo_point field");
-        }
-        GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
-
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
-        return new GeoDistanceRangeQuery(point, fromValue, toValue, includeLower, includeUpper, geoDistance, geoFieldType,
-                indexFieldData, optimizeBbox);
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoDistanceRangeQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startArray(fieldName).value(point.lon()).value(point.lat()).endArray();
-        builder.field(GeoDistanceRangeQueryParser.FROM_FIELD.getPreferredName(), from);
-        builder.field(GeoDistanceRangeQueryParser.TO_FIELD.getPreferredName(), to);
-        builder.field(GeoDistanceRangeQueryParser.INCLUDE_LOWER_FIELD.getPreferredName(), includeLower);
-        builder.field(GeoDistanceRangeQueryParser.INCLUDE_UPPER_FIELD.getPreferredName(), includeUpper);
-        if (unit != null) {
-            builder.field(GeoDistanceRangeQueryParser.UNIT_FIELD.getPreferredName(), unit);
-        }
+        builder.startObject(GeoDistanceRangeQueryParser.NAME);
+        if (geohash != null) {
+            builder.field(name, geohash);
+        } else {
+            builder.startArray(name).value(lon).value(lat).endArray();
+        }
+        builder.field("from", from);
+        builder.field("to", to);
+        builder.field("include_lower", includeLower);
+        builder.field("include_upper", includeUpper);
         if (geoDistance != null) {
-            builder.field(GeoDistanceRangeQueryParser.DISTANCE_TYPE_FIELD.getPreferredName(), geoDistance.name().toLowerCase(Locale.ROOT));
+            builder.field("distance_type", geoDistance.name().toLowerCase(Locale.ROOT));
         }
         if (optimizeBbox != null) {
-            builder.field(GeoDistanceRangeQueryParser.OPTIMIZE_BBOX_FIELD.getPreferredName(), optimizeBbox);
+            builder.field("optimize_bbox", optimizeBbox);
         }
-        builder.field(GeoDistanceRangeQueryParser.COERCE_FIELD.getPreferredName(), coerce);
-        builder.field(GeoDistanceRangeQueryParser.IGNORE_MALFORMED_FIELD.getPreferredName(), ignoreMalformed);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected GeoDistanceRangeQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        GeoDistanceRangeQueryBuilder queryBuilder = new GeoDistanceRangeQueryBuilder(in.readString());
-        double lat = in.readDouble();
-        double lon = in.readDouble();
-        queryBuilder.point = new GeoPoint(lat, lon);
-        queryBuilder.from = in.readGenericValue();
-        queryBuilder.to = in.readGenericValue();
-        queryBuilder.includeLower = in.readBoolean();
-        queryBuilder.includeUpper = in.readBoolean();
-        String unit = in.readOptionalString();
-        if (unit != null) {
-            queryBuilder.unit = DistanceUnit.valueOf(unit);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        String geoDistance = in.readOptionalString();
-        if (geoDistance != null) {
-            queryBuilder.geoDistance = GeoDistance.fromString(geoDistance);
+        if (coerce != null) {
+            builder.field("coerce", coerce);
         }
-        queryBuilder.optimizeBbox = in.readOptionalString();
-        queryBuilder.coerce = in.readBoolean();
-        queryBuilder.ignoreMalformed = in.readBoolean();
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeDouble(point.lat());
-        out.writeDouble(point.lon());
-        out.writeGenericValue(from);
-        out.writeGenericValue(to);
-        out.writeBoolean(includeLower);
-        out.writeBoolean(includeUpper);
-        out.writeOptionalString(unit.name());
-        out.writeOptionalString(geoDistance.name());
-        out.writeOptionalString(optimizeBbox);
-        out.writeBoolean(coerce);
-        out.writeBoolean(ignoreMalformed);
-    }
-
-    @Override
-    protected boolean doEquals(GeoDistanceRangeQueryBuilder other) {
-        if (!Objects.equals(fieldName, other.fieldName)) {
-            return false;
-        }
-        if (!Objects.equals(point, other.point)) {
-            return false;
-        }
-        if (!Objects.equals(from, other.from)) {
-            return false;
-        }
-        if (!Objects.equals(to, other.to)) {
-            return false;
-        }
-        if (!Objects.equals(includeUpper, other.includeUpper)) {
-            return false;
-        }
-        if (!Objects.equals(includeLower, other.includeLower)) {
-            return false;
-        }
-        if (!Objects.equals(geoDistance, other.geoDistance)) {
-            return false;
-        }
-        if (!Objects.equals(optimizeBbox, other.optimizeBbox)) {
-            return false;
+        if (ignoreMalformed != null) {
+            builder.field("ignore_malformed", ignoreMalformed);
         }
-        if (!Objects.equals(coerce, other.coerce)) {
-            return false;
-        }
-        if (!Objects.equals(ignoreMalformed, other.ignoreMalformed)) {
-            return false;
-        }
-        return true;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, point, from, to, includeUpper, includeLower, geoDistance, optimizeBbox, coerce,
-                ignoreMalformed);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java
index 7f16aea..f60d944 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryParser.java
@@ -19,14 +19,19 @@
 
 package org.elasticsearch.index.query;
 
-import org.elasticsearch.common.ParseField;
+import org.apache.lucene.search.Query;
+import org.elasticsearch.Version;
 import org.elasticsearch.common.geo.GeoDistance;
+import org.elasticsearch.common.geo.GeoHashUtils;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.geo.GeoUtils;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.unit.DistanceUnit;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.fielddata.IndexGeoPointFieldData;
+import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
+import org.elasticsearch.index.search.geo.GeoDistanceRangeQuery;
 
 import java.io.IOException;
 
@@ -38,23 +43,9 @@ import java.io.IOException;
  * }
  * </pre>
  */
-public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRangeQueryBuilder> {
+public class GeoDistanceRangeQueryParser implements QueryParser {
 
-    public static final ParseField FROM_FIELD = new ParseField("from");
-    public static final ParseField TO_FIELD = new ParseField("to");
-    public static final ParseField INCLUDE_LOWER_FIELD = new ParseField("include_lower");
-    public static final ParseField INCLUDE_UPPER_FIELD = new ParseField("include_upper");
-    public static final ParseField GT_FIELD = new ParseField("gt");
-    public static final ParseField GTE_FIELD = new ParseField("gte", "ge");
-    public static final ParseField LT_FIELD = new ParseField("lt");
-    public static final ParseField LTE_FIELD = new ParseField("lte", "le");
-    public static final ParseField UNIT_FIELD = new ParseField("unit");
-    public static final ParseField DISTANCE_TYPE_FIELD = new ParseField("distance_type");
-    public static final ParseField NAME_FIELD = new ParseField("_name");
-    public static final ParseField BOOST_FIELD = new ParseField("boost");
-    public static final ParseField OPTIMIZE_BBOX_FIELD = new ParseField("optimize_bbox");
-    public static final ParseField COERCE_FIELD = new ParseField("coerce", "normalize");
-    public static final ParseField IGNORE_MALFORMED_FIELD = new ParseField("ignore_malformed");
+    public static final String NAME = "geo_distance_range";
 
     @Inject
     public GeoDistanceRangeQueryParser() {
@@ -62,73 +53,61 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRang
 
     @Override
     public String[] names() {
-        return new String[]{GeoDistanceRangeQueryBuilder.NAME, "geoDistanceRange"};
+        return new String[]{NAME, "geoDistanceRange"};
     }
 
     @Override
-    public GeoDistanceRangeQueryBuilder getBuilderPrototype() {
-        return GeoDistanceRangeQueryBuilder.PROTOTYPE;
-    }
-
-    @Override
-    public GeoDistanceRangeQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token;
 
-        Float boost = null;
         String queryName = null;
         String currentFieldName = null;
-        GeoPoint point = null;
-        String geohash = null;
+        GeoPoint point = new GeoPoint();
         String fieldName = null;
         Object vFrom = null;
         Object vTo = null;
-        Boolean includeLower = null;
-        Boolean includeUpper = null;
-        DistanceUnit unit = null;
-        GeoDistance geoDistance = null;
-        String optimizeBbox = null;
-        Boolean coerce = null;
-        Boolean ignoreMalformed = null;
+        boolean includeLower = true;
+        boolean includeUpper = true;
+        DistanceUnit unit = DistanceUnit.DEFAULT;
+        GeoDistance geoDistance = GeoDistance.DEFAULT;
+        String optimizeBbox = "memory";
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
+        boolean coerce = false;
+        boolean ignoreMalformed = false;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (parseContext.isDeprecatedSetting(currentFieldName)) {
                 // skip
             } else if (token == XContentParser.Token.START_ARRAY) {
-                if (point == null) {
-                    point = new GeoPoint();
-                }
                 GeoUtils.parseGeoPoint(parser, point);
                 fieldName = currentFieldName;
             } else if (token == XContentParser.Token.START_OBJECT) {
                 // the json in the format of -> field : { lat : 30, lon : 12 }
                 fieldName = currentFieldName;
-                if (point == null) {
-                    point = new GeoPoint();
-                }
                 GeoUtils.parseGeoPoint(parser, point);
             } else if (token.isValue()) {
-                if (parseContext.parseFieldMatcher().match(currentFieldName, FROM_FIELD)) {
+                if (currentFieldName.equals("from")) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vFrom = parser.text(); // a String
                     } else {
                         vFrom = parser.numberValue(); // a Number
                     }
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, TO_FIELD)) {
+                } else if (currentFieldName.equals("to")) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vTo = parser.text(); // a String
                     } else {
                         vTo = parser.numberValue(); // a Number
                     }
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, INCLUDE_LOWER_FIELD)) {
+                } else if ("include_lower".equals(currentFieldName) || "includeLower".equals(currentFieldName)) {
                     includeLower = parser.booleanValue();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, INCLUDE_UPPER_FIELD)) {
+                } else if ("include_upper".equals(currentFieldName) || "includeUpper".equals(currentFieldName)) {
                     includeUpper = parser.booleanValue();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, GT_FIELD)) {
+                } else if ("gt".equals(currentFieldName)) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vFrom = parser.text(); // a String
@@ -136,7 +115,7 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRang
                         vFrom = parser.numberValue(); // a Number
                     }
                     includeLower = false;
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, GTE_FIELD)) {
+                } else if ("gte".equals(currentFieldName) || "ge".equals(currentFieldName)) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vFrom = parser.text(); // a String
@@ -144,7 +123,7 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRang
                         vFrom = parser.numberValue(); // a Number
                     }
                     includeLower = true;
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, LT_FIELD)) {
+                } else if ("lt".equals(currentFieldName)) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vTo = parser.text(); // a String
@@ -152,7 +131,7 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRang
                         vTo = parser.numberValue(); // a Number
                     }
                     includeUpper = false;
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, LTE_FIELD)) {
+                } else if ("lte".equals(currentFieldName) || "le".equals(currentFieldName)) {
                     if (token == XContentParser.Token.VALUE_NULL) {
                     } else if (token == XContentParser.Token.VALUE_STRING) {
                         vTo = parser.text(); // a String
@@ -160,98 +139,84 @@ public class GeoDistanceRangeQueryParser extends BaseQueryParser<GeoDistanceRang
                         vTo = parser.numberValue(); // a Number
                     }
                     includeUpper = true;
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, UNIT_FIELD)) {
+                } else if (currentFieldName.equals("unit")) {
                     unit = DistanceUnit.fromString(parser.text());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, DISTANCE_TYPE_FIELD)) {
+                } else if (currentFieldName.equals("distance_type") || currentFieldName.equals("distanceType")) {
                     geoDistance = GeoDistance.fromString(parser.text());
                 } else if (currentFieldName.endsWith(GeoPointFieldMapper.Names.LAT_SUFFIX)) {
-                    if (point == null) {
-                        point = new GeoPoint();
-                    }
                     point.resetLat(parser.doubleValue());
                     fieldName = currentFieldName.substring(0, currentFieldName.length() - GeoPointFieldMapper.Names.LAT_SUFFIX.length());
                 } else if (currentFieldName.endsWith(GeoPointFieldMapper.Names.LON_SUFFIX)) {
-                    if (point == null) {
-                        point = new GeoPoint();
-                    }
                     point.resetLon(parser.doubleValue());
                     fieldName = currentFieldName.substring(0, currentFieldName.length() - GeoPointFieldMapper.Names.LON_SUFFIX.length());
                 } else if (currentFieldName.endsWith(GeoPointFieldMapper.Names.GEOHASH_SUFFIX)) {
-                    geohash = parser.text();
+                    GeoHashUtils.decode(parser.text(), point);
                     fieldName = currentFieldName.substring(0, currentFieldName.length() - GeoPointFieldMapper.Names.GEOHASH_SUFFIX.length());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, NAME_FIELD)) {
+                } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, BOOST_FIELD)) {
-                    boost = parser.floatValue();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, OPTIMIZE_BBOX_FIELD)) {
+                } else if ("optimize_bbox".equals(currentFieldName) || "optimizeBbox".equals(currentFieldName)) {
                     optimizeBbox = parser.textOrNull();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, COERCE_FIELD)) {
+                } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
                     coerce = parser.booleanValue();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, IGNORE_MALFORMED_FIELD)) {
+                    if (coerce == true) {
+                        ignoreMalformed = true;
+                    }
+                } else if ("ignore_malformed".equals(currentFieldName) && coerce == false) {
                     ignoreMalformed = parser.booleanValue();
                 } else {
-                    if (point == null) {
-                        point = new GeoPoint();
-                    }
                     point.resetFromString(parser.text());
                     fieldName = currentFieldName;
                 }
             }
         }
 
-        GeoDistanceRangeQueryBuilder queryBuilder = new GeoDistanceRangeQueryBuilder(fieldName);
-
-        if (boost != null) {
-            queryBuilder.boost(boost);
-        }
-
-        if (queryName != null) {
-            queryBuilder.queryName(queryName);
-        }
-
-        if (point != null) {
-            queryBuilder.point(point.lat(), point.lon());
+        // validation was not available prior to 2.x, so to support bwc percolation queries we only ignore_malformed on 2.x created indexes
+        if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
+            if (point.lat() > 90.0 || point.lat() < -90.0) {
+                throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), NAME);
+            }
+            if (point.lon() > 180.0 || point.lon() < -180) {
+                throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), NAME);
+            }
         }
 
-        if (geohash != null) {
-            queryBuilder.geohash(geohash);
+        if (coerce) {
+            GeoUtils.normalizePoint(point, coerce, coerce);
         }
 
+        Double from = null;
+        Double to = null;
         if (vFrom != null) {
-            queryBuilder.from(vFrom);
+            if (vFrom instanceof Number) {
+                from = unit.toMeters(((Number) vFrom).doubleValue());
+            } else {
+                from = DistanceUnit.parse((String) vFrom, unit, DistanceUnit.DEFAULT);
+            }
+            from = geoDistance.normalize(from, DistanceUnit.DEFAULT);
         }
-
         if (vTo != null) {
-            queryBuilder.to(vTo);
-        }
-
-        if (includeUpper != null) {
-            queryBuilder.includeUpper(includeUpper);
-        }
-
-        if (includeLower != null) {
-            queryBuilder.includeLower(includeLower);
-        }
-
-        if (unit != null) {
-            queryBuilder.unit(unit);
-        }
-
-        if (geoDistance != null) {
-            queryBuilder.geoDistance(geoDistance);
+            if (vTo instanceof Number) {
+                to = unit.toMeters(((Number) vTo).doubleValue());
+            } else {
+                to = DistanceUnit.parse((String) vTo, unit, DistanceUnit.DEFAULT);
+            }
+            to = geoDistance.normalize(to, DistanceUnit.DEFAULT);
         }
 
-        if (optimizeBbox != null) {
-            queryBuilder.optimizeBbox(optimizeBbox);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType == null) {
+            throw new QueryParsingException(parseContext, "failed to find geo_point field [" + fieldName + "]");
         }
-
-        if (coerce != null) {
-            queryBuilder.coerce(coerce);
+        if (!(fieldType instanceof GeoPointFieldMapper.GeoPointFieldType)) {
+            throw new QueryParsingException(parseContext, "field [" + fieldName + "] is not a geo_point field");
         }
+        GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
 
-        if (ignoreMalformed != null) {
-            queryBuilder.ignoreMalformed(ignoreMalformed);
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
+        Query query = new GeoDistanceRangeQuery(point, from, to, includeLower, includeUpper, geoDistance, geoFieldType, indexFieldData, optimizeBbox);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
         }
-        return queryBuilder;
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java
index 4f4ce47..400384b 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryBuilder.java
@@ -27,17 +27,15 @@ import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 
-public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQueryBuilder> {
-
-    public static final String NAME = "geo_polygon";
+public class GeoPolygonQueryBuilder extends QueryBuilder {
 
     public static final String POINTS = GeoPolygonQueryParser.POINTS;
-
+    
     private final String name;
 
     private final List<GeoPoint> shell = new ArrayList<>();
 
-    static final GeoPolygonQueryBuilder PROTOTYPE = new GeoPolygonQueryBuilder(null);
+    private String queryName;
 
     private Boolean coerce;
 
@@ -52,7 +50,7 @@ public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQuery
      *
      * @param lat The latitude
      * @param lon The longitude
-     * @return the current builder
+     * @return
      */
     public GeoPolygonQueryBuilder addPoint(double lat, double lon) {
         return addPoint(new GeoPoint(lat, lon));
@@ -66,6 +64,14 @@ public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQuery
         shell.add(point);
         return this;
     }
+    
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public GeoPolygonQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
 
     public GeoPolygonQueryBuilder coerce(boolean coerce) {
         this.coerce = coerce;
@@ -79,7 +85,7 @@ public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQuery
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(GeoPolygonQueryParser.NAME);
 
         builder.startObject(name);
         builder.startArray(POINTS);
@@ -89,18 +95,16 @@ public class GeoPolygonQueryBuilder extends AbstractQueryBuilder<GeoPolygonQuery
         builder.endArray();
         builder.endObject();
 
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (coerce != null) {
             builder.field("coerce", coerce);
         }
         if (ignoreMalformed != null) {
             builder.field("ignore_malformed", ignoreMalformed);
         }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java
index 2dae22b..e4cf677 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoPolygonQueryParser.java
@@ -47,8 +47,9 @@ import java.util.List;
  * }
  * </pre>
  */
-public class GeoPolygonQueryParser extends BaseQueryParserTemp {
+public class GeoPolygonQueryParser implements QueryParser {
 
+    public static final String NAME = "geo_polygon";
     public static final String POINTS = "points";
 
     @Inject
@@ -57,20 +58,18 @@ public class GeoPolygonQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{GeoPolygonQueryBuilder.NAME, "geoPolygon"};
+        return new String[]{NAME, "geoPolygon"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
 
         List<GeoPoint> shell = new ArrayList<>();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        final boolean indexCreatedBeforeV2_0 = parseContext.shardContext().indexVersionCreated().before(Version.V_2_0_0);
+        final boolean indexCreatedBeforeV2_0 = parseContext.indexVersionCreated().before(Version.V_2_0_0);
         boolean coerce = false;
         boolean ignoreMalformed = false;
         String queryName = null;
@@ -108,8 +107,6 @@ public class GeoPolygonQueryParser extends BaseQueryParserTemp {
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if ("coerce".equals(currentFieldName) || (indexCreatedBeforeV2_0 && "normalize".equals(currentFieldName))) {
                     coerce = parser.booleanValue();
                     if (coerce == true) {
@@ -144,10 +141,10 @@ public class GeoPolygonQueryParser extends BaseQueryParserTemp {
         if (!indexCreatedBeforeV2_0 && !ignoreMalformed) {
             for (GeoPoint point : shell) {
                 if (point.lat() > 90.0 || point.lat() < -90.0) {
-                    throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), GeoPolygonQueryBuilder.NAME);
+                    throw new QueryParsingException(parseContext, "illegal latitude value [{}] for [{}]", point.lat(), NAME);
                 }
                 if (point.lon() > 180.0 || point.lon() < -180) {
-                    throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), GeoPolygonQueryBuilder.NAME);
+                    throw new QueryParsingException(parseContext, "illegal longitude value [{}] for [{}]", point.lon(), NAME);
                 }
             }
         }
@@ -158,7 +155,7 @@ public class GeoPolygonQueryParser extends BaseQueryParserTemp {
             }
         }
 
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
             throw new QueryParsingException(parseContext, "failed to find geo_point field [" + fieldName + "]");
         }
@@ -166,17 +163,11 @@ public class GeoPolygonQueryParser extends BaseQueryParserTemp {
             throw new QueryParsingException(parseContext, "field [" + fieldName + "] is not a geo_point field");
         }
 
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
         Query query = new GeoPolygonQuery(indexFieldData, shell.toArray(new GeoPoint[shell.size()]));
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
-        query.setBoost(boost);
         return query;
     }
-
-    @Override
-    public GeoPolygonQueryBuilder getBuilderPrototype() {
-        return GeoPolygonQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
index 9180d0e..3887874 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
@@ -29,11 +29,7 @@ import java.io.IOException;
 /**
  * {@link QueryBuilder} that builds a GeoShape Filter
  */
-public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuilder> {
-
-    public static final String NAME = "geo_shape";
-
-    static final GeoShapeQueryBuilder PROTOTYPE = new GeoShapeQueryBuilder(null, null);
+public class GeoShapeQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<GeoShapeQueryBuilder> {
 
     private final String name;
 
@@ -41,6 +37,8 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
 
     private SpatialStrategy strategy = null;
 
+    private String queryName;
+
     private final String indexedShapeId;
     private final String indexedShapeType;
 
@@ -49,6 +47,8 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
 
     private ShapeRelation relation = null;
 
+    private float boost = -1;
+    
     /**
      * Creates a new GeoShapeQueryBuilder whose Filter will be against the
      * given field name using the given Shape
@@ -93,6 +93,17 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
     }
 
     /**
+     * Sets the name of the filter
+     *
+     * @param queryName Name of the filter
+     * @return this
+     */
+    public GeoShapeQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
+    /**
      * Defines which spatial strategy will be used for building the geo shape filter. When not set, the strategy that
      * will be used will be the one that is associated with the geo shape field in the mappings.
      *
@@ -138,8 +149,14 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
     }
 
     @Override
+    public GeoShapeQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(GeoShapeQueryParser.NAME);
 
         builder.startObject(name);
 
@@ -168,13 +185,14 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
 
         builder.endObject();
 
-        printBoostAndQueryName(builder);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+
+        if (name != null) {
+            builder.field("_name", queryName);
+        }
 
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java
index 9c1eeb3..e959c42 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryParser.java
@@ -31,6 +31,7 @@ import org.elasticsearch.common.geo.ShapeRelation;
 import org.elasticsearch.common.geo.builders.ShapeBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.geo.GeoShapeFieldMapper;
 import org.elasticsearch.index.search.shape.ShapeFetchService;
@@ -38,7 +39,9 @@ import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 
-public class GeoShapeQueryParser extends BaseQueryParserTemp {
+public class GeoShapeQueryParser implements QueryParser {
+
+    public static final String NAME = "geo_shape";
 
     private ShapeFetchService fetchService;
 
@@ -49,12 +52,11 @@ public class GeoShapeQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{GeoShapeQueryBuilder.NAME, Strings.toCamelCase(GeoShapeQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
@@ -137,7 +139,7 @@ public class GeoShapeQueryParser extends BaseQueryParserTemp {
             throw new QueryParsingException(parseContext, "No Shape Relation defined");
         }
 
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
             throw new QueryParsingException(parseContext, "Failed to find geo_shape field [" + fieldName + "]");
         }
@@ -158,7 +160,7 @@ public class GeoShapeQueryParser extends BaseQueryParserTemp {
             // this strategy doesn't support disjoint anymore: but it did before, including creating lucene fieldcache (!)
             // in this case, execute disjoint as exists && !intersects
             BooleanQuery.Builder bool = new BooleanQuery.Builder();
-            Query exists = ExistsQueryBuilder.newFilter(context, fieldName);
+            Query exists = ExistsQueryParser.newFilter(parseContext, fieldName, null);
             Filter intersects = strategy.makeFilter(getArgs(shape, ShapeRelation.INTERSECTS));
             bool.add(exists, BooleanClause.Occur.MUST);
             bool.add(intersects, BooleanClause.Occur.MUST_NOT);
@@ -168,7 +170,7 @@ public class GeoShapeQueryParser extends BaseQueryParserTemp {
         }
         query.setBoost(boost);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
         return query;
     }
@@ -188,11 +190,7 @@ public class GeoShapeQueryParser extends BaseQueryParserTemp {
             return new SpatialArgs(SpatialOperation.IsWithin, shape.build());
         default:
             throw new IllegalArgumentException("");
-        }
-    }
 
-    @Override
-    public GeoShapeQueryBuilder getBuilderPrototype() {
-        return GeoShapeQueryBuilder.PROTOTYPE;
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java b/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java
index 7b00ea7..814aca4 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeohashCellQuery.java
@@ -22,25 +22,23 @@ package org.elasticsearch.index.query;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.geo.GeoHashUtils;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.geo.GeoUtils;
 import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.unit.DistanceUnit;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentParser.Token;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.core.StringFieldMapper;
 import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Objects;
 
 /**
  * A geohash cell filter that filters {@link GeoPoint}s by their geohashes. Basically the a
@@ -60,9 +58,8 @@ import java.util.Objects;
 public class GeohashCellQuery {
 
     public static final String NAME = "geohash_cell";
-    public static final ParseField NEIGHBORS_FIELD = new ParseField("neighbors");
-    public static final ParseField PRECISION_FIELD = new ParseField("precision");
-    public static final boolean DEFAULT_NEIGHBORS = false;
+    public static final String NEIGHBORS = "neighbors";
+    public static final String PRECISION = "precision";
 
     /**
      * Create a new geohash filter for a given set of geohashes. In general this method
@@ -74,7 +71,7 @@ public class GeohashCellQuery {
      * @param geohashes   optional array of additional geohashes
      * @return a new GeoBoundinboxfilter
      */
-    public static Query create(QueryShardContext context, GeoPointFieldMapper.GeoPointFieldType fieldType, String geohash, @Nullable List<CharSequence> geohashes) {
+    public static Query create(QueryParseContext context, GeoPointFieldMapper.GeoPointFieldType fieldType, String geohash, @Nullable List<CharSequence> geohashes) {
         MappedFieldType geoHashMapper = fieldType.geohashFieldType();
         if (geoHashMapper == null) {
             throw new IllegalArgumentException("geohash filter needs geohash_prefix to be enabled");
@@ -93,16 +90,15 @@ public class GeohashCellQuery {
      * <code>geohash</code> to be set. the default for a neighbor filteing is
      * <code>false</code>.
      */
-    public static class Builder extends AbstractQueryBuilder<Builder> {
+    public static class Builder extends QueryBuilder {
         // we need to store the geohash rather than the corresponding point,
         // because a transformation from a geohash to a point an back to the
         // geohash will extend the accuracy of the hash to max precision
         // i.e. by filing up with z's.
-        private String fieldName;
+        private String field;
         private String geohash;
-        private Integer levels = null;
-        private boolean neighbors = DEFAULT_NEIGHBORS;
-        private static final Builder PROTOTYPE = new Builder(null);
+        private int levels = -1;
+        private boolean neighbors;
 
 
         public Builder(String field) {
@@ -119,7 +115,7 @@ public class GeohashCellQuery {
 
         public Builder(String field, String geohash, boolean neighbors) {
             super();
-            this.fieldName = field;
+            this.field = field;
             this.geohash = geohash;
             this.neighbors = neighbors;
         }
@@ -139,19 +135,11 @@ public class GeohashCellQuery {
             return this;
         }
 
-        public String geohash() {
-            return geohash;
-        }
-
         public Builder precision(int levels) {
             this.levels = levels;
             return this;
         }
 
-        public Integer precision() {
-            return levels;
-        }
-
         public Builder precision(String precision) {
             double meters = DistanceUnit.parse(precision, DistanceUnit.DEFAULT, DistanceUnit.METERS);
             return precision(GeoUtils.geoHashLevelsForPrecision(meters));
@@ -162,123 +150,27 @@ public class GeohashCellQuery {
             return this;
         }
 
-        public boolean neighbors() {
-            return neighbors;
-        }
-
-        public Builder fieldName(String fieldName) {
-            this.fieldName = fieldName;
+        public Builder field(String field) {
+            this.field = field;
             return this;
         }
 
-        public String fieldName() {
-            return fieldName;
-        }
-
-        @Override
-        public QueryValidationException validate() {
-            QueryValidationException errors = null;
-            if (fieldName == null) {
-                errors = QueryValidationException.addValidationError(NAME, "fieldName must not be null", errors);
-            }
-            if (geohash == null) {
-                errors = QueryValidationException.addValidationError(NAME, "geohash or point must be defined", errors);
-            }
-            if (levels != null && levels <= 0) {
-                errors = QueryValidationException.addValidationError(NAME, "precision must be greater than 0. Found [" + levels + "]",
-                        errors);
-            }
-            return errors;
-        }
-
-        @Override
-        protected Query doToQuery(QueryShardContext context) throws IOException {
-            MappedFieldType fieldType = context.fieldMapper(fieldName);
-            if (fieldType == null) {
-                throw new QueryShardException(context, "failed to parse [{}] query. missing [{}] field [{}]", NAME,
-                        GeoPointFieldMapper.CONTENT_TYPE, fieldName);
-            }
-
-            if (!(fieldType instanceof GeoPointFieldMapper.GeoPointFieldType)) {
-                throw new QueryShardException(context, "failed to parse [{}] query. field [{}] is not a geo_point field", NAME, fieldName);
-            }
-
-            GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
-            if (!geoFieldType.isGeohashPrefixEnabled()) {
-                throw new QueryShardException(context, "failed to parse [{}] query. [geohash_prefix] is not enabled for field [{}]", NAME,
-                        fieldName);
-            }
-
-            if (levels != null) {
-                int len = Math.min(levels, geohash.length());
-                geohash = geohash.substring(0, len);
-            }
-
-            Query query;
-            if (neighbors) {
-                query = create(context, geoFieldType, geohash, GeoHashUtils.addNeighbors(geohash, new ArrayList<CharSequence>(8)));
-            } else {
-                query = create(context, geoFieldType, geohash, null);
-            }
-            return query;
-        }
-
         @Override
         protected void doXContent(XContentBuilder builder, Params params) throws IOException {
             builder.startObject(NAME);
-            builder.field(NEIGHBORS_FIELD.getPreferredName(), neighbors);
-            if (levels != null) {
-                builder.field(PRECISION_FIELD.getPreferredName(), levels);
-            }
-            builder.field(fieldName, geohash);
-            printBoostAndQueryName(builder);
-            builder.endObject();
-        }
-
-        @Override
-        protected Builder doReadFrom(StreamInput in) throws IOException {
-            String field = in.readString();
-            String geohash = in.readString();
-            Builder builder = new Builder(field, geohash);
-            if (in.readBoolean()) {
-                builder.precision(in.readVInt());
+            if (neighbors) {
+                builder.field(NEIGHBORS, neighbors);
             }
-            builder.neighbors(in.readBoolean());
-            return builder;
-        }
-
-        @Override
-        protected void doWriteTo(StreamOutput out) throws IOException {
-            out.writeString(fieldName);
-            out.writeString(geohash);
-            boolean hasLevels = levels != null;
-            out.writeBoolean(hasLevels);
-            if (hasLevels) {
-                out.writeVInt(levels);
+            if(levels > 0) {
+                builder.field(PRECISION, levels);
             }
-            out.writeBoolean(neighbors);
-        }
-
-        @Override
-        protected boolean doEquals(Builder other) {
-            return Objects.equals(fieldName, other.fieldName)
-                    && Objects.equals(geohash, other.geohash)
-                    && Objects.equals(levels, other.levels)
-                    && Objects.equals(neighbors, other.neighbors);
-        }
+            builder.field(field, geohash);
 
-        @Override
-        protected int doHashCode() {
-            return Objects.hash(fieldName, geohash, levels, neighbors);
-        }
-
-        @Override
-        public String getWriteableName() {
-            return NAME;
+            builder.endObject();
         }
     }
 
-    public static class Parser extends BaseQueryParser<Builder> {
+    public static class Parser implements QueryParser {
 
         @Inject
         public Parser() {
@@ -290,15 +182,14 @@ public class GeohashCellQuery {
         }
 
         @Override
-        public Builder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+        public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
             XContentParser parser = parseContext.parser();
 
             String fieldName = null;
             String geohash = null;
-            Integer levels = null;
-            Boolean neighbors = null;
-            String queryName = null;
-            Float boost = null;
+            int levels = -1;
+            boolean neighbors = false;
+
 
             XContentParser.Token token;
             if ((token = parser.currentToken()) != Token.START_OBJECT) {
@@ -311,31 +202,24 @@ public class GeohashCellQuery {
 
                     if (parseContext.isDeprecatedSetting(field)) {
                         // skip
-                    } else if (parseContext.parseFieldMatcher().match(field, PRECISION_FIELD)) {
+                    } else if (PRECISION.equals(field)) {
                         token = parser.nextToken();
-                        if (token == Token.VALUE_NUMBER) {
+                        if(token == Token.VALUE_NUMBER) {
                             levels = parser.intValue();
-                        } else if (token == Token.VALUE_STRING) {
+                        } else if(token == Token.VALUE_STRING) {
                             double meters = DistanceUnit.parse(parser.text(), DistanceUnit.DEFAULT, DistanceUnit.METERS);
                             levels = GeoUtils.geoHashLevelsForPrecision(meters);
                         }
-                    } else if (parseContext.parseFieldMatcher().match(field, NEIGHBORS_FIELD)) {
+                    } else if (NEIGHBORS.equals(field)) {
                         parser.nextToken();
                         neighbors = parser.booleanValue();
-                    } else if (parseContext.parseFieldMatcher().match(field, AbstractQueryBuilder.NAME_FIELD)) {
-                        parser.nextToken();
-                        queryName = parser.text();
-                    } else if (parseContext.parseFieldMatcher().match(field, AbstractQueryBuilder.BOOST_FIELD)) {
-                        parser.nextToken();
-                        boost = parser.floatValue();
                     } else {
                         fieldName = field;
                         token = parser.nextToken();
-                        if (token == Token.VALUE_STRING) {
-                            // A string indicates either a geohash or a lat/lon
-                            // string
+                        if(token == Token.VALUE_STRING) {
+                            // A string indicates either a gehash or a lat/lon string
                             String location = parser.text();
-                            if (location.indexOf(",") > 0) {
+                            if(location.indexOf(",")>0) {
                                 geohash = GeoUtils.parseGeoPoint(parser).geohash();
                             } else {
                                 geohash = location;
@@ -348,26 +232,38 @@ public class GeohashCellQuery {
                     throw new ElasticsearchParseException("failed to parse [{}] query. unexpected token [{}]", NAME, token);
                 }
             }
-            Builder builder = new Builder(fieldName);
-            builder.geohash(geohash);
-            if (levels != null) {
-                builder.precision(levels);
+
+            if (geohash == null) {
+                throw new QueryParsingException(parseContext, "failed to parse [{}] query. missing geohash value", NAME);
             }
-            if (neighbors != null) {
-                builder.neighbors(neighbors);
+
+            MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+            if (fieldType == null) {
+                throw new QueryParsingException(parseContext, "failed to parse [{}] query. missing [{}] field [{}]", NAME, GeoPointFieldMapper.CONTENT_TYPE, fieldName);
             }
-            if (queryName != null) {
-                builder.queryName(queryName);
+
+            if (!(fieldType instanceof GeoPointFieldMapper.GeoPointFieldType)) {
+                throw new QueryParsingException(parseContext, "failed to parse [{}] query. field [{}] is not a geo_point field", NAME, fieldName);
             }
-            if (boost != null) {
-                builder.boost(boost);
+
+            GeoPointFieldMapper.GeoPointFieldType geoFieldType = ((GeoPointFieldMapper.GeoPointFieldType) fieldType);
+            if (!geoFieldType.isGeohashPrefixEnabled()) {
+                throw new QueryParsingException(parseContext, "failed to parse [{}] query. [geohash_prefix] is not enabled for field [{}]", NAME, fieldName);
             }
-            return builder;
-        }
 
-        @Override
-        public GeohashCellQuery.Builder getBuilderPrototype() {
-            return Builder.PROTOTYPE;
+            if(levels > 0) {
+                int len = Math.min(levels, geohash.length());
+                geohash = geohash.substring(0, len);
+            }
+
+            Query filter;
+            if (neighbors) {
+                filter = create(parseContext, geoFieldType, geohash, GeoHashUtils.addNeighbors(geohash, new ArrayList<CharSequence>(8)));
+            } else {
+                filter = create(parseContext, geoFieldType, geohash, null);
+            }
+
+            return filter;
         }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java
index 0652335..35ff6cb 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryBuilder.java
@@ -18,103 +18,48 @@
  */
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.MultiDocValues;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.join.BitSetProducer;
-import org.apache.lucene.search.join.JoinUtil;
-import org.apache.lucene.search.join.ScoreMode;
-import org.elasticsearch.Version;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.xcontent.*;
-import org.elasticsearch.index.fielddata.IndexParentChildFieldData;
-import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.index.search.child.ChildrenConstantScoreQuery;
-import org.elasticsearch.index.search.child.ChildrenQuery;
-import org.elasticsearch.index.search.child.ScoreType;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
-import org.elasticsearch.search.internal.SearchContext;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 
 import java.io.IOException;
-import java.util.Locale;
-import java.util.Objects;
 
-/**
- * A query builder for <tt>has_child</tt> queries.
- */
-public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuilder> {
-
-    /**
-     * The queries name
-     */
-    public static final String NAME = "has_child";
-
-    /**
-     * The default cut off point only to evaluate parent documents that contain the matching parent id terms
-     * instead of evaluating all parent docs.
-     */
-    public static final int DEFAULT_SHORT_CIRCUIT_CUTOFF = 8192;
-    /**
-     * The default maximum number of children that are required to match for the parent to be considered a match.
-     */
-    public static final int DEFAULT_MAX_CHILDREN = Integer.MAX_VALUE;
-    /**
-     * The default minimum number of children that are required to match for the parent to be considered a match.
-     */
-    public static final int DEFAULT_MIN_CHILDREN = 0;
+public class HasChildQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<HasChildQueryBuilder> {
 
-    private final QueryBuilder query;
+    private final QueryBuilder queryBuilder;
 
-    private final String type;
+    private String childType;
 
-    private ScoreType scoreType = ScoreType.NONE;
+    private float boost = 1.0f;
 
-    private int minChildren = DEFAULT_MIN_CHILDREN;
+    private String scoreType;
 
-    private int maxChildren = DEFAULT_MAX_CHILDREN;
+    private Integer minChildren;
 
-    private int shortCircuitCutoff = DEFAULT_SHORT_CIRCUIT_CUTOFF;
+    private Integer maxChildren;
 
-    private QueryInnerHits queryInnerHits;
+    private String queryName;
 
-    static final HasChildQueryBuilder PROTOTYPE = new HasChildQueryBuilder("", EmptyQueryBuilder.PROTOTYPE);
+    private QueryInnerHitBuilder innerHit = null;
 
-    public HasChildQueryBuilder(String type, QueryBuilder query, Integer maxChildren, Integer minChildren, Integer shortCircuitCutoff, ScoreType scoreType, QueryInnerHits queryInnerHits) {
-        this(type, query);
-        scoreType(scoreType);
-        this.maxChildren = maxChildren;
-        this.minChildren = minChildren;
-        this.shortCircuitCutoff = shortCircuitCutoff;
-        this.queryInnerHits = queryInnerHits;
+    public HasChildQueryBuilder(String type, QueryBuilder queryBuilder) {
+        this.childType = type;
+        this.queryBuilder = queryBuilder;
     }
 
-    public HasChildQueryBuilder(String type, QueryBuilder query) {
-        if (type == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires 'type' field");
-        }
-        if (query == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires 'query' field");
-        }
-        this.type = type;
-        this.query = query;
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public HasChildQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
      * Defines how the scores from the matching child documents are mapped into the parent document.
      */
-    public HasChildQueryBuilder scoreType(ScoreType scoreType) {
-        if (scoreType == null) {
-            throw new IllegalArgumentException("[" + NAME + "]  requires 'score_type' field");
-        }
+    public HasChildQueryBuilder scoreType(String scoreType) {
         this.scoreType = scoreType;
         return this;
     }
@@ -123,9 +68,6 @@ public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuil
      * Defines the minimum number of children that are required to match for the parent to be considered a match.
      */
     public HasChildQueryBuilder minChildren(int minChildren) {
-        if (minChildren < 0) {
-            throw new IllegalArgumentException("[" + NAME + "]  requires non-negative 'min_children' field");
-        }
         this.minChildren = minChildren;
         return this;
     }
@@ -134,331 +76,52 @@ public class HasChildQueryBuilder extends AbstractQueryBuilder<HasChildQueryBuil
      * Defines the maximum number of children that are required to match for the parent to be considered a match.
      */
     public HasChildQueryBuilder maxChildren(int maxChildren) {
-        if (maxChildren < 0) {
-            throw new IllegalArgumentException("[" + NAME + "]  requires non-negative 'max_children' field");
-        }
         this.maxChildren = maxChildren;
         return this;
     }
 
     /**
-     * Configures at what cut off point only to evaluate parent documents that contain the matching parent id terms
-     * instead of evaluating all parent docs.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public HasChildQueryBuilder shortCircuitCutoff(int shortCircuitCutoff) {
-        if (shortCircuitCutoff < 0) {
-            throw new IllegalArgumentException("[" + NAME + "]  requires non-negative 'short_circuit_cutoff' field");
-        }
-        this.shortCircuitCutoff = shortCircuitCutoff;
+    public HasChildQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
         return this;
     }
 
     /**
      * Sets inner hit definition in the scope of this query and reusing the defined type and query.
      */
-    public HasChildQueryBuilder innerHit(QueryInnerHits queryInnerHits) {
-        this.queryInnerHits = queryInnerHits;
+    public HasChildQueryBuilder innerHit(QueryInnerHitBuilder innerHit) {
+        this.innerHit = innerHit;
         return this;
     }
 
-    /**
-     * Returns inner hit definition in the scope of this query and reusing the defined type and query.
-     */
-    public QueryInnerHits innerHit() {
-        return queryInnerHits;
-    }
-
-    /**
-     * Returns the children query to execute.
-     */
-    public QueryBuilder query() {
-        return query;
-    }
-
-    /**
-     * Returns the child type
-     */
-    public String childType() {
-        return type;
-    }
-
-    /**
-     * Returns how the scores from the matching child documents are mapped into the parent document.
-     */
-    public ScoreType scoreType() {
-        return scoreType;
-    }
-
-    /**
-     * Returns the minimum number of children that are required to match for the parent to be considered a match.
-     * The default is {@value #DEFAULT_MAX_CHILDREN}
-     */
-    public int minChildren() {
-        return minChildren;
-    }
-
-    /**
-     * Returns the maximum number of children that are required to match for the parent to be considered a match.
-     * The default is {@value #DEFAULT_MIN_CHILDREN}
-     */
-    public int maxChildren() { return maxChildren; }
-
-    /**
-     * Returns what cut off point only to evaluate parent documents that contain the matching parent id terms
-     * instead of evaluating all parent docs. The default is {@value #DEFAULT_SHORT_CIRCUIT_CUTOFF}
-     */
-    public int shortCircuitCutoff() {
-        return shortCircuitCutoff;
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(HasChildQueryParser.NAME);
         builder.field("query");
-        query.toXContent(builder, params);
-        builder.field("child_type", type);
-        builder.field("score_type", scoreType.name().toLowerCase(Locale.ROOT));
-        builder.field("min_children", minChildren);
-        builder.field("max_children", maxChildren);
-        builder.field("short_circuit_cutoff", shortCircuitCutoff);
-        printBoostAndQueryName(builder);
-        if (queryInnerHits != null) {
-            queryInnerHits.toXContent(builder, params);
-        }
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerQuery = query.toQuery(context);
-        if (innerQuery == null) {
-            return null;
-        }
-        innerQuery.setBoost(boost);
-
-        DocumentMapper childDocMapper = context.mapperService().documentMapper(type);
-        if (childDocMapper == null) {
-            throw new QueryShardException(context, "[" + NAME + "] no mapping for for type [" + type + "]");
-        }
-        ParentFieldMapper parentFieldMapper = childDocMapper.parentFieldMapper();
-        if (parentFieldMapper.active() == false) {
-            throw new QueryShardException(context, "[" + NAME + "] _parent field has no parent type configured");
-        }
-        if (queryInnerHits != null) {
-            try (XContentParser parser = queryInnerHits.getXcontentParser()) {
-                XContentParser.Token token = parser.nextToken();
-                if (token != XContentParser.Token.START_OBJECT) {
-                    throw new IllegalStateException("start object expected but was: [" + token + "]");
-                }
-                InnerHitsSubSearchContext innerHits = context.indexQueryParserService().getInnerHitsQueryParserHelper().parse(parser);
-                if (innerHits != null) {
-                    ParsedQuery parsedQuery = new ParsedQuery(innerQuery, context.copyNamedQueries());
-                    InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, context.mapperService(), childDocMapper);
-                    String name = innerHits.getName() != null ? innerHits.getName() : type;
-                    context.addInnerHits(name, parentChildInnerHits);
-                }
-            }
-        }
-
-        String parentType = parentFieldMapper.type();
-        DocumentMapper parentDocMapper = context.mapperService().documentMapper(parentType);
-        if (parentDocMapper == null) {
-            throw new QueryShardException(context, "[" + NAME + "] Type [" + type + "] points to a non existent parent type ["
-                    + parentType + "]");
-        }
-
-        if (maxChildren > 0 && maxChildren < minChildren) {
-            throw new QueryShardException(context, "[" + NAME + "] 'max_children' is less than 'min_children'");
-        }
-
-        BitSetProducer nonNestedDocsFilter = null;
-        if (parentDocMapper.hasNestedObjects()) {
-            nonNestedDocsFilter = context.bitsetFilter(Queries.newNonNestedFilter());
-        }
-
-        // wrap the query with type query
-        innerQuery = Queries.filtered(innerQuery, childDocMapper.typeFilter());
-
-        final Query query;
-        final ParentChildIndexFieldData parentChildIndexFieldData = context.getForField(parentFieldMapper.fieldType());
-        if (context.indexVersionCreated().onOrAfter(Version.V_2_0_0_beta1)) {
-            int maxChildren = maxChildren();
-            // 0 in pre 2.x p/c impl means unbounded
-            if (maxChildren == 0) {
-                maxChildren = Integer.MAX_VALUE;
-            }
-            query = new LateParsingQuery(parentDocMapper.typeFilter(), innerQuery, minChildren(), maxChildren, parentType, scoreTypeToScoreMode(scoreType), parentChildIndexFieldData);
-        } else {
-            // TODO: use the query API
-            Filter parentFilter = new QueryWrapperFilter(parentDocMapper.typeFilter());
-            if (minChildren > 1 || maxChildren > 0 || scoreType != ScoreType.NONE) {
-                query = new ChildrenQuery(parentChildIndexFieldData, parentType, type, parentFilter, innerQuery, scoreType, minChildren,
-                        maxChildren, shortCircuitCutoff, nonNestedDocsFilter);
-            } else {
-                query = new ChildrenConstantScoreQuery(parentChildIndexFieldData, innerQuery, parentType, type, parentFilter,
-                        shortCircuitCutoff, nonNestedDocsFilter);
-            }
-        }
-        return query;
-    }
-
-    static ScoreMode scoreTypeToScoreMode(ScoreType scoreType) {
-        ScoreMode scoreMode;
-        // TODO: move entirely over from ScoreType to org.apache.lucene.join.ScoreMode, when we drop the 1.x parent child code.
-        switch (scoreType) {
-            case NONE:
-                scoreMode = ScoreMode.None;
-                break;
-            case MIN:
-                scoreMode = ScoreMode.Min;
-                break;
-            case MAX:
-                scoreMode = ScoreMode.Max;
-                break;
-            case SUM:
-                scoreMode = ScoreMode.Total;
-                break;
-            case AVG:
-                scoreMode = ScoreMode.Avg;
-                break;
-            default:
-                throw new IllegalArgumentException("score type [" + scoreType + "] not supported");
-        }
-        return scoreMode;
-    }
-
-    final static class LateParsingQuery extends Query {
-
-        private final Query toQuery;
-        private final Query innerQuery;
-        private final int minChildren;
-        private final int maxChildren;
-        private final String parentType;
-        private final ScoreMode scoreMode;
-        private final ParentChildIndexFieldData parentChildIndexFieldData;
-
-        LateParsingQuery(Query toQuery, Query innerQuery, int minChildren, int maxChildren, String parentType, ScoreMode scoreMode, ParentChildIndexFieldData parentChildIndexFieldData) {
-            this.toQuery = toQuery;
-            this.innerQuery = innerQuery;
-            this.minChildren = minChildren;
-            this.maxChildren = maxChildren;
-            this.parentType = parentType;
-            this.scoreMode = scoreMode;
-            this.parentChildIndexFieldData = parentChildIndexFieldData;
-        }
-
-        @Override
-        public Query rewrite(IndexReader reader) throws IOException {
-            SearchContext searchContext = SearchContext.current();
-            if (searchContext == null) {
-                throw new IllegalArgumentException("Search context is required to be set");
-            }
-
-            IndexSearcher indexSearcher = searchContext.searcher();
-            String joinField = ParentFieldMapper.joinField(parentType);
-            IndexParentChildFieldData indexParentChildFieldData = parentChildIndexFieldData.loadGlobal(indexSearcher.getIndexReader());
-            MultiDocValues.OrdinalMap ordinalMap = ParentChildIndexFieldData.getOrdinalMap(indexParentChildFieldData, parentType);
-            return JoinUtil.createJoinQuery(joinField, innerQuery, toQuery, indexSearcher, scoreMode, ordinalMap, minChildren, maxChildren);
+        queryBuilder.toXContent(builder, params);
+        builder.field("child_type", childType);
+        if (boost != 1.0f) {
+            builder.field("boost", boost);
         }
-
-        @Override
-        public boolean equals(Object o) {
-            if (this == o) return true;
-            if (o == null || getClass() != o.getClass()) return false;
-            if (!super.equals(o)) return false;
-
-            LateParsingQuery that = (LateParsingQuery) o;
-
-            if (minChildren != that.minChildren) return false;
-            if (maxChildren != that.maxChildren) return false;
-            if (!toQuery.equals(that.toQuery)) return false;
-            if (!innerQuery.equals(that.innerQuery)) return false;
-            if (!parentType.equals(that.parentType)) return false;
-            return scoreMode == that.scoreMode;
+        if (scoreType != null) {
+            builder.field("score_type", scoreType);
         }
-
-        @Override
-        public int hashCode() {
-            int result = super.hashCode();
-            result = 31 * result + toQuery.hashCode();
-            result = 31 * result + innerQuery.hashCode();
-            result = 31 * result + minChildren;
-            result = 31 * result + maxChildren;
-            result = 31 * result + parentType.hashCode();
-            result = 31 * result + scoreMode.hashCode();
-            return result;
-        }
-
-        @Override
-        public String toString(String s) {
-            return "LateParsingQuery {parentType=" + parentType + "}";
+        if (minChildren != null) {
+            builder.field("min_children", minChildren);
         }
-
-        public int getMinChildren() {
-            return minChildren;
+        if (maxChildren != null) {
+            builder.field("max_children", maxChildren);
         }
-
-        public int getMaxChildren() {
-            return maxChildren;
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-
-        public ScoreMode getScoreMode() {
-            return scoreMode;
-        }
-    }
-
-    @Override
-    protected boolean doEquals(HasChildQueryBuilder that) {
-        return Objects.equals(query, that.query)
-                && Objects.equals(type, that.type)
-                && Objects.equals(scoreType, that.scoreType)
-                && Objects.equals(minChildren, that.minChildren)
-                && Objects.equals(maxChildren, that.maxChildren)
-                && Objects.equals(shortCircuitCutoff, that.shortCircuitCutoff)
-                && Objects.equals(queryInnerHits, that.queryInnerHits);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(query, type, scoreType, minChildren, maxChildren, shortCircuitCutoff, queryInnerHits);
-    }
-
-    protected HasChildQueryBuilder(StreamInput in) throws IOException {
-        type = in.readString();
-        minChildren = in.readInt();
-        maxChildren = in.readInt();
-        shortCircuitCutoff = in.readInt();
-        final int ordinal = in.readVInt();
-        scoreType = ScoreType.values()[ordinal];
-        query = in.readQuery();
-        if (in.readBoolean()) {
-            queryInnerHits = new QueryInnerHits(in);
-        }
-    }
-
-    @Override
-    protected HasChildQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new HasChildQueryBuilder(in);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(type);
-        out.writeInt(minChildren());
-        out.writeInt(maxChildren());
-        out.writeInt(shortCircuitCutoff());
-        out.writeVInt(scoreType.ordinal());
-        out.writeQuery(query);
-        if (queryInnerHits != null) {
-            out.writeBoolean(true);
-            queryInnerHits.writeTo(out);
-        } else {
-            out.writeBoolean(false);
+        if (innerHit != null) {
+            builder.startObject("inner_hits");
+            builder.value(innerHit);
+            builder.endObject();
         }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java
index 27a51e9..77e04a1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasChildQueryParser.java
@@ -19,50 +19,80 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.MultiDocValues;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.join.JoinUtil;
+import org.apache.lucene.search.join.ScoreMode;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.index.search.child.ScoreType;
+import org.elasticsearch.index.fielddata.IndexParentChildFieldData;
+import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
+import org.elasticsearch.index.mapper.DocumentMapper;
+import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
+import org.elasticsearch.index.query.support.InnerHitsQueryParserHelper;
+import org.elasticsearch.index.query.support.XContentStructure;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
+import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 
 /**
- * A query parser for <tt>has_child</tt> queries.
+ *
  */
-public class HasChildQueryParser extends BaseQueryParser {
+public class HasChildQueryParser implements QueryParser {
 
+    public static final String NAME = "has_child";
     private static final ParseField QUERY_FIELD = new ParseField("query", "filter");
 
+    private final InnerHitsQueryParserHelper innerHitsQueryParserHelper;
+
+    @Inject
+    public HasChildQueryParser(InnerHitsQueryParserHelper innerHitsQueryParserHelper) {
+        this.innerHitsQueryParserHelper = innerHitsQueryParserHelper;
+    }
+
     @Override
     public String[] names() {
-        return new String[] { HasChildQueryBuilder.NAME, Strings.toCamelCase(HasChildQueryBuilder.NAME) };
+        return new String[] { NAME, Strings.toCamelCase(NAME) };
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+
+        boolean queryFound = false;
+        float boost = 1.0f;
         String childType = null;
         ScoreType scoreType = ScoreType.NONE;
-        int minChildren = HasChildQueryBuilder.DEFAULT_MIN_CHILDREN;
-        int maxChildren = HasChildQueryBuilder.DEFAULT_MAX_CHILDREN;
-        int shortCircuitParentDocSet = HasChildQueryBuilder.DEFAULT_SHORT_CIRCUIT_CUTOFF;
+        int minChildren = 0;
+        int maxChildren = 0;
         String queryName = null;
-        QueryInnerHits queryInnerHits = null;
+        InnerHitsSubSearchContext innerHits = null;
+
         String currentFieldName = null;
         XContentParser.Token token;
-        QueryBuilder iqb = null;
+        XContentStructure.InnerQuery iq = null;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (parseContext.isDeprecatedSetting(currentFieldName)) {
                 // skip
             } else if (token == XContentParser.Token.START_OBJECT) {
+                // Usually, the query would be parsed here, but the child
+                // type may not have been extracted yet, so use the
+                // XContentStructure.<type> facade to parse if available,
+                // or delay parsing if not.
                 if (parseContext.parseFieldMatcher().match(currentFieldName, QUERY_FIELD)) {
-                    iqb = parseContext.parseInnerQueryBuilder();
+                    iq = new XContentStructure.InnerQuery(parseContext, childType == null ? null : new String[] { childType });
+                    queryFound = true;
                 } else if ("inner_hits".equals(currentFieldName)) {
-                    queryInnerHits = new QueryInnerHits(parser);
+                    innerHits = innerHitsQueryParserHelper.parse(parseContext);
                 } else {
                     throw new QueryParsingException(parseContext, "[has_child] query does not support [" + currentFieldName + "]");
                 }
@@ -79,8 +109,6 @@ public class HasChildQueryParser extends BaseQueryParser {
                     minChildren = parser.intValue(true);
                 } else if ("max_children".equals(currentFieldName) || "maxChildren".equals(currentFieldName)) {
                     maxChildren = parser.intValue(true);
-                } else if ("short_circuit_cutoff".equals(currentFieldName)) {
-                    shortCircuitParentDocSet = parser.intValue();
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
                 } else {
@@ -88,14 +116,148 @@ public class HasChildQueryParser extends BaseQueryParser {
                 }
             }
         }
-        HasChildQueryBuilder hasChildQueryBuilder = new HasChildQueryBuilder(childType, iqb, maxChildren, minChildren, shortCircuitParentDocSet, scoreType, queryInnerHits);
-        hasChildQueryBuilder.queryName(queryName);
-        hasChildQueryBuilder.boost(boost);
-        return hasChildQueryBuilder;
+        if (!queryFound) {
+            throw new QueryParsingException(parseContext, "[has_child] requires 'query' field");
+        }
+        if (childType == null) {
+            throw new QueryParsingException(parseContext, "[has_child] requires 'type' field");
+        }
+
+        Query innerQuery = iq.asQuery(childType);
+
+        if (innerQuery == null) {
+            return null;
+        }
+        innerQuery.setBoost(boost);
+
+        DocumentMapper childDocMapper = parseContext.mapperService().documentMapper(childType);
+        if (childDocMapper == null) {
+            throw new QueryParsingException(parseContext, "[has_child] No mapping for for type [" + childType + "]");
+        }
+        ParentFieldMapper parentFieldMapper = childDocMapper.parentFieldMapper();
+        if (parentFieldMapper.active() == false) {
+            throw new QueryParsingException(parseContext, "[has_child] _parent field has no parent type configured");
+        }
+
+        if (innerHits != null) {
+            ParsedQuery parsedQuery = new ParsedQuery(innerQuery, parseContext.copyNamedQueries());
+            InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, parseContext.mapperService(), childDocMapper);
+            String name = innerHits.getName() != null ? innerHits.getName() : childType;
+            parseContext.addInnerHits(name, parentChildInnerHits);
+        }
+
+        String parentType = parentFieldMapper.type();
+        DocumentMapper parentDocMapper = parseContext.mapperService().documentMapper(parentType);
+        if (parentDocMapper == null) {
+            throw new QueryParsingException(parseContext, "[has_child]  Type [" + childType + "] points to a non existent parent type ["
+                    + parentType + "]");
+        }
+
+        if (maxChildren > 0 && maxChildren < minChildren) {
+            throw new QueryParsingException(parseContext, "[has_child] 'max_children' is less than 'min_children'");
+        }
+
+        // wrap the query with type query
+        innerQuery = Queries.filtered(innerQuery, childDocMapper.typeFilter());
+
+        final Query query;
+        final ParentChildIndexFieldData parentChildIndexFieldData = parseContext.getForField(parentFieldMapper.fieldType());
+        query = joinUtilHelper(parentType, parentChildIndexFieldData, parentDocMapper.typeFilter(), scoreType, innerQuery, minChildren, maxChildren);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        query.setBoost(boost);
+        return query;
     }
 
-    @Override
-    public HasChildQueryBuilder getBuilderPrototype() {
-        return HasChildQueryBuilder.PROTOTYPE;
+    public static Query joinUtilHelper(String parentType, ParentChildIndexFieldData parentChildIndexFieldData, Query toQuery, ScoreType scoreType, Query innerQuery, int minChildren, int maxChildren) throws IOException {
+        ScoreMode scoreMode;
+        // TODO: move entirely over from ScoreType to org.apache.lucene.join.ScoreMode, when we drop the 1.x parent child code.
+        switch (scoreType) {
+            case NONE:
+                scoreMode = ScoreMode.None;
+                break;
+            case MIN:
+                scoreMode = ScoreMode.Min;
+                break;
+            case MAX:
+                scoreMode = ScoreMode.Max;
+                break;
+            case SUM:
+                scoreMode = ScoreMode.Total;
+                break;
+            case AVG:
+                scoreMode = ScoreMode.Avg;
+                break;
+            default:
+                throw new UnsupportedOperationException("score type [" + scoreType + "] not supported");
+        }
+        // 0 in pre 2.x p/c impl means unbounded
+        if (maxChildren == 0) {
+            maxChildren = Integer.MAX_VALUE;
+        }
+        return new LateParsingQuery(toQuery, innerQuery, minChildren, maxChildren, parentType, scoreMode, parentChildIndexFieldData);
+    }
+
+    final static class LateParsingQuery extends Query {
+
+        private final Query toQuery;
+        private final Query innerQuery;
+        private final int minChildren;
+        private final int maxChildren;
+        private final String parentType;
+        private final ScoreMode scoreMode;
+        private final ParentChildIndexFieldData parentChildIndexFieldData;
+        private final Object identity = new Object();
+
+        LateParsingQuery(Query toQuery, Query innerQuery, int minChildren, int maxChildren, String parentType, ScoreMode scoreMode, ParentChildIndexFieldData parentChildIndexFieldData) {
+            this.toQuery = toQuery;
+            this.innerQuery = innerQuery;
+            this.minChildren = minChildren;
+            this.maxChildren = maxChildren;
+            this.parentType = parentType;
+            this.scoreMode = scoreMode;
+            this.parentChildIndexFieldData = parentChildIndexFieldData;
+        }
+
+        @Override
+        public Query rewrite(IndexReader reader) throws IOException {
+            SearchContext searchContext = SearchContext.current();
+            if (searchContext == null) {
+                throw new IllegalArgumentException("Search context is required to be set");
+            }
+
+            IndexSearcher indexSearcher = searchContext.searcher();
+            String joinField = ParentFieldMapper.joinField(parentType);
+            IndexParentChildFieldData indexParentChildFieldData = parentChildIndexFieldData.loadGlobal(indexSearcher.getIndexReader());
+            MultiDocValues.OrdinalMap ordinalMap = ParentChildIndexFieldData.getOrdinalMap(indexParentChildFieldData, parentType);
+            return JoinUtil.createJoinQuery(joinField, innerQuery, toQuery, indexSearcher, scoreMode, ordinalMap, minChildren, maxChildren);
+        }
+
+        // Even though we only cache rewritten queries it is good to let all queries implement hashCode() and equals():
+
+        // We can't check for actually equality here, since we need to IndexReader for this, but
+        // that isn't available on all cases during query parse time, so instead rely on identity:
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) return true;
+            if (o == null || getClass() != o.getClass()) return false;
+            if (!super.equals(o)) return false;
+
+            LateParsingQuery that = (LateParsingQuery) o;
+            return identity.equals(that.identity);
+        }
+
+        @Override
+        public int hashCode() {
+            int result = super.hashCode();
+            result = 31 * result + identity.hashCode();
+            return result;
+        }
+
+        @Override
+        public String toString(String s) {
+            return "LateParsingQuery {parentType=" + parentType + "}";
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java
index 28a803b..743ad76 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryBuilder.java
@@ -18,236 +18,83 @@
  */
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.*;
-import org.apache.lucene.search.join.ScoreMode;
-import org.elasticsearch.Version;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.index.search.child.ParentConstantScoreQuery;
-import org.elasticsearch.index.search.child.ParentQuery;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
+import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 
 import java.io.IOException;
-import java.util.HashSet;
-import java.util.Locale;
-import java.util.Objects;
-import java.util.Set;
 
 /**
  * Builder for the 'has_parent' query.
  */
-public class HasParentQueryBuilder extends AbstractQueryBuilder<HasParentQueryBuilder> {
+public class HasParentQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<HasParentQueryBuilder> {
 
-    public static final String NAME = "has_parent";
-    private final QueryBuilder query;
-    private final String type;
-    private boolean score = false;
-    private QueryInnerHits innerHit;
+    private final QueryBuilder queryBuilder;
+    private final String parentType;
+    private String scoreType;
+    private float boost = 1.0f;
+    private String queryName;
+    private QueryInnerHitBuilder innerHit = null;
 
     /**
-     * @param type  The parent type
-     * @param query The query that will be matched with parent documents
+     * @param parentType  The parent type
+     * @param parentQuery The query that will be matched with parent documents
      */
-    public HasParentQueryBuilder(String type, QueryBuilder query) {
-        if (type == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires 'parent_type' field");
-        }
-        if (query == null) {
-            throw new IllegalArgumentException("[" + NAME + "] requires 'query' field");
-        }
-        this.type = type;
-        this.query = query;
-    }
-
-    public HasParentQueryBuilder(String type, QueryBuilder query, boolean score, QueryInnerHits innerHits) {
-        this(type, query);
-        this.score = score;
-        this.innerHit = innerHits;
+    public HasParentQueryBuilder(String parentType, QueryBuilder parentQuery) {
+        this.parentType = parentType;
+        this.queryBuilder = parentQuery;
     }
 
-    /**
-     * Defines if the parent score is mapped into the child documents.
-     */
-    public HasParentQueryBuilder score(boolean score) {
-        this.score = score;
+    @Override
+    public HasParentQueryBuilder boost(float boost) {
+        this.boost = boost;
         return this;
     }
 
     /**
-     * Sets inner hit definition in the scope of this query and reusing the defined type and query.
+     * Defines how the parent score is mapped into the child documents.
      */
-    public HasParentQueryBuilder innerHit(QueryInnerHits innerHit) {
-        this.innerHit = innerHit;
+    public HasParentQueryBuilder scoreType(String scoreType) {
+        this.scoreType = scoreType;
         return this;
     }
 
     /**
-     * Returns the query to execute.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public QueryBuilder query() {
-        return query;
-    }
-
-    /**
-     * Returns <code>true</code> if the parent score is mapped into the child documents
-     */
-    public boolean score() {
-        return score;
+    public HasParentQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     /**
-     *  Returns inner hit definition in the scope of this query and reusing the defined type and query.
+     * Sets inner hit definition in the scope of this query and reusing the defined type and query.
      */
-    public QueryInnerHits innerHit() {
-        return innerHit;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerQuery = query.toQuery(context);
-        if (innerQuery == null) {
-            return null;
-        }
-        innerQuery.setBoost(boost);
-        DocumentMapper parentDocMapper = context.mapperService().documentMapper(type);
-        if (parentDocMapper == null) {
-            throw new QueryParsingException(context.parseContext(), "[has_parent] query configured 'parent_type' [" + type
-                    + "] is not a valid type");
-        }
-
-        if (innerHit != null) {
-            try (XContentParser parser = innerHit.getXcontentParser()) {
-                XContentParser.Token token = parser.nextToken();
-                if (token != XContentParser.Token.START_OBJECT) {
-                    throw new IllegalStateException("start object expected but was: [" + token + "]");
-                }
-                InnerHitsSubSearchContext innerHits = context.indexQueryParserService().getInnerHitsQueryParserHelper().parse(parser);
-                if (innerHits != null) {
-                    ParsedQuery parsedQuery = new ParsedQuery(innerQuery, context.copyNamedQueries());
-                    InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, context.mapperService(), parentDocMapper);
-                    String name = innerHits.getName() != null ? innerHits.getName() : type;
-                    context.addInnerHits(name, parentChildInnerHits);
-                }
-            }
-        }
-
-        Set<String> parentTypes = new HashSet<>(5);
-        parentTypes.add(parentDocMapper.type());
-        ParentChildIndexFieldData parentChildIndexFieldData = null;
-        for (DocumentMapper documentMapper : context.mapperService().docMappers(false)) {
-            ParentFieldMapper parentFieldMapper = documentMapper.parentFieldMapper();
-            if (parentFieldMapper.active()) {
-                DocumentMapper parentTypeDocumentMapper = context.mapperService().documentMapper(parentFieldMapper.type());
-                parentChildIndexFieldData = context.getForField(parentFieldMapper.fieldType());
-                if (parentTypeDocumentMapper == null) {
-                    // Only add this, if this parentFieldMapper (also a parent)  isn't a child of another parent.
-                    parentTypes.add(parentFieldMapper.type());
-                }
-            }
-        }
-        if (parentChildIndexFieldData == null) {
-            throw new QueryParsingException(context.parseContext(), "[has_parent] no _parent field configured");
-        }
-
-        Query parentFilter = null;
-        if (parentTypes.size() == 1) {
-            DocumentMapper documentMapper = context.mapperService().documentMapper(parentTypes.iterator().next());
-            if (documentMapper != null) {
-                parentFilter = documentMapper.typeFilter();
-            }
-        } else {
-            BooleanQuery.Builder parentsFilter = new BooleanQuery.Builder();
-            for (String parentTypeStr : parentTypes) {
-                DocumentMapper documentMapper = context.mapperService().documentMapper(parentTypeStr);
-                if (documentMapper != null) {
-                    parentsFilter.add(documentMapper.typeFilter(), BooleanClause.Occur.SHOULD);
-                }
-            }
-            parentFilter = parentsFilter.build();
-        }
-
-        if (parentFilter == null) {
-            return null;
-        }
-
-        // wrap the query with type query
-        innerQuery = Queries.filtered(innerQuery, parentDocMapper.typeFilter());
-        Filter childrenFilter = new QueryWrapperFilter(Queries.not(parentFilter));
-        if (context.indexVersionCreated().onOrAfter(Version.V_2_0_0_beta1)) {
-            return new HasChildQueryBuilder.LateParsingQuery(childrenFilter, innerQuery, HasChildQueryBuilder.DEFAULT_MIN_CHILDREN, HasChildQueryBuilder.DEFAULT_MAX_CHILDREN, type, score ? ScoreMode.Max : ScoreMode.None, parentChildIndexFieldData);
-        } else {
-            if (score) {
-                return new ParentQuery(parentChildIndexFieldData, innerQuery, parentDocMapper.type(), childrenFilter);
-            } else {
-                return new ParentConstantScoreQuery(parentChildIndexFieldData, innerQuery, parentDocMapper.type(), childrenFilter);
-            }
-        }
+    public HasParentQueryBuilder innerHit(QueryInnerHitBuilder innerHit) {
+        this.innerHit = innerHit;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(HasParentQueryParser.NAME);
         builder.field("query");
-        query.toXContent(builder, params);
-        builder.field("parent_type", type);
-        builder.field("score", score);
-        printBoostAndQueryName(builder);
-        if (innerHit != null) {
-           innerHit.toXContent(builder, params);
+        queryBuilder.toXContent(builder, params);
+        builder.field("parent_type", parentType);
+        if (scoreType != null) {
+            builder.field("score_type", scoreType);
         }
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    protected HasParentQueryBuilder(StreamInput in) throws IOException {
-        type = in.readString();
-        score = in.readBoolean();
-        query = in.readQuery();
-        if (in.readBoolean()) {
-            innerHit = new QueryInnerHits(in);
+        if (boost != 1.0f) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-    }
-
-    @Override
-    protected HasParentQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new HasParentQueryBuilder(in);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(type);
-        out.writeBoolean(score);
-        out.writeQuery(query);
         if (innerHit != null) {
-            out.writeBoolean(true);
-            innerHit.writeTo(out);
-        } else {
-            out.writeBoolean(false);
+            builder.startObject("inner_hits");
+            builder.value(innerHit);
+            builder.endObject();
         }
+        builder.endObject();
     }
+}
 
-    @Override
-    protected boolean doEquals(HasParentQueryBuilder that) {
-        return Objects.equals(query, that.query)
-                && Objects.equals(type, that.type)
-                && Objects.equals(score, that.score)
-                && Objects.equals(innerHit, that.innerHit);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(query, type, score, innerHit);
-    }
-}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java
index b292a4c..b8d4db8 100644
--- a/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/HasParentQueryParser.java
@@ -19,8 +19,6 @@
 package org.elasticsearch.index.query;
 
 import org.apache.lucene.search.*;
-import org.apache.lucene.search.join.ScoreMode;
-import org.elasticsearch.Version;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
@@ -30,11 +28,7 @@ import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
 import org.elasticsearch.index.mapper.DocumentMapper;
 import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
 import org.elasticsearch.index.query.support.InnerHitsQueryParserHelper;
-import org.elasticsearch.index.query.support.QueryInnerHits;
 import org.elasticsearch.index.query.support.XContentStructure;
-import org.elasticsearch.index.search.child.ParentConstantScoreQuery;
-import org.elasticsearch.index.search.child.ParentQuery;
-import org.elasticsearch.index.search.child.ScoreType;
 import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
 import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
 
@@ -42,32 +36,39 @@ import java.io.IOException;
 import java.util.HashSet;
 import java.util.Set;
 
+import static org.elasticsearch.index.query.HasChildQueryParser.joinUtilHelper;
 
-public class HasParentQueryParser extends BaseQueryParser  {
+public class HasParentQueryParser implements QueryParser {
 
-    private static final HasParentQueryBuilder PROTOTYPE = new HasParentQueryBuilder("", EmptyQueryBuilder.PROTOTYPE);
+    public static final String NAME = "has_parent";
     private static final ParseField QUERY_FIELD = new ParseField("query", "filter");
-    private static final ParseField SCORE_FIELD = new ParseField("score_type", "score_mode").withAllDeprecated("score");
-    private static final ParseField TYPE_FIELD = new ParseField("parent_type", "type");
+
+    private final InnerHitsQueryParserHelper innerHitsQueryParserHelper;
+
+    @Inject
+    public HasParentQueryParser(InnerHitsQueryParserHelper innerHitsQueryParserHelper) {
+        this.innerHitsQueryParserHelper = innerHitsQueryParserHelper;
+    }
 
     @Override
     public String[] names() {
-        return new String[]{HasParentQueryBuilder.NAME, Strings.toCamelCase(HasParentQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        boolean queryFound = false;
+        float boost = 1.0f;
         String parentType = null;
         boolean score = false;
         String queryName = null;
-        QueryInnerHits innerHits = null;
+        InnerHitsSubSearchContext innerHits = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
-        QueryBuilder iqb = null;
+        XContentStructure.InnerQuery iq = null;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -77,25 +78,30 @@ public class HasParentQueryParser extends BaseQueryParser  {
                 // XContentStructure.<type> facade to parse if available,
                 // or delay parsing if not.
                 if (parseContext.parseFieldMatcher().match(currentFieldName, QUERY_FIELD)) {
-                    iqb = parseContext.parseInnerQueryBuilder();
+                    iq = new XContentStructure.InnerQuery(parseContext, parentType == null ? null : new String[] {parentType});
+                    queryFound = true;
                 } else if ("inner_hits".equals(currentFieldName)) {
-                    innerHits = new QueryInnerHits(parser);
+                    innerHits = innerHitsQueryParserHelper.parse(parseContext);
                 } else {
                     throw new QueryParsingException(parseContext, "[has_parent] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
-                if (parseContext.parseFieldMatcher().match(currentFieldName, TYPE_FIELD)) {
+                if ("type".equals(currentFieldName) || "parent_type".equals(currentFieldName) || "parentType".equals(currentFieldName)) {
                     parentType = parser.text();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, SCORE_FIELD)) {
-                    // deprecated we use a boolean now
+                } else if ("score_type".equals(currentFieldName) || "scoreType".equals(currentFieldName)) {
                     String scoreTypeValue = parser.text();
                     if ("score".equals(scoreTypeValue)) {
                         score = true;
                     } else if ("none".equals(scoreTypeValue)) {
                         score = false;
                     }
-                } else if ("score".equals(currentFieldName)) {
-                    score = parser.booleanValue();
+                } else if ("score_mode".equals(currentFieldName) || "scoreMode".equals(currentFieldName)) {
+                    String scoreModeValue = parser.text();
+                    if ("score".equals(scoreModeValue)) {
+                        score = true;
+                    } else if ("none".equals(scoreModeValue)) {
+                        score = false;
+                    }
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else if ("_name".equals(currentFieldName)) {
@@ -105,11 +111,90 @@ public class HasParentQueryParser extends BaseQueryParser  {
                 }
             }
         }
-        return new HasParentQueryBuilder(parentType, iqb, score, innerHits).queryName(queryName).boost(boost);
+        if (!queryFound) {
+            throw new QueryParsingException(parseContext, "[has_parent] query requires 'query' field");
+        }
+        if (parentType == null) {
+            throw new QueryParsingException(parseContext, "[has_parent] query requires 'parent_type' field");
+        }
+
+        Query innerQuery = iq.asQuery(parentType);
+
+        if (innerQuery == null) {
+            return null;
+        }
+
+        innerQuery.setBoost(boost);
+        Query query = createParentQuery(innerQuery, parentType, score, parseContext, innerHits);
+        if (query == null) {
+            return null;
+        }
+
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 
-    @Override
-    public HasParentQueryBuilder getBuilderPrototype() {
-        return PROTOTYPE;
+    static Query createParentQuery(Query innerQuery, String parentType, boolean score, QueryParseContext parseContext, InnerHitsSubSearchContext innerHits) throws IOException {
+        DocumentMapper parentDocMapper = parseContext.mapperService().documentMapper(parentType);
+        if (parentDocMapper == null) {
+            throw new QueryParsingException(parseContext, "[has_parent] query configured 'parent_type' [" + parentType
+                    + "] is not a valid type");
+        }
+
+        if (innerHits != null) {
+            ParsedQuery parsedQuery = new ParsedQuery(innerQuery, parseContext.copyNamedQueries());
+            InnerHitsContext.ParentChildInnerHits parentChildInnerHits = new InnerHitsContext.ParentChildInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, parseContext.mapperService(), parentDocMapper);
+            String name = innerHits.getName() != null ? innerHits.getName() : parentType;
+            parseContext.addInnerHits(name, parentChildInnerHits);
+        }
+
+        Set<String> parentTypes = new HashSet<>(5);
+        parentTypes.add(parentDocMapper.type());
+        ParentChildIndexFieldData parentChildIndexFieldData = null;
+        for (DocumentMapper documentMapper : parseContext.mapperService().docMappers(false)) {
+            ParentFieldMapper parentFieldMapper = documentMapper.parentFieldMapper();
+            if (parentFieldMapper.active()) {
+                DocumentMapper parentTypeDocumentMapper = parseContext.mapperService().documentMapper(parentFieldMapper.type());
+                parentChildIndexFieldData = parseContext.getForField(parentFieldMapper.fieldType());
+                if (parentTypeDocumentMapper == null) {
+                    // Only add this, if this parentFieldMapper (also a parent)  isn't a child of another parent.
+                    parentTypes.add(parentFieldMapper.type());
+                }
+            }
+        }
+        if (parentChildIndexFieldData == null) {
+            throw new QueryParsingException(parseContext, "[has_parent] no _parent field configured");
+        }
+
+        Query parentTypeQuery = null;
+        if (parentTypes.size() == 1) {
+            DocumentMapper documentMapper = parseContext.mapperService().documentMapper(parentTypes.iterator().next());
+            if (documentMapper != null) {
+                parentTypeQuery = documentMapper.typeFilter();
+            }
+        } else {
+            BooleanQuery.Builder parentsFilter = new BooleanQuery.Builder();
+            for (String parentTypeStr : parentTypes) {
+                DocumentMapper documentMapper = parseContext.mapperService().documentMapper(parentTypeStr);
+                if (documentMapper != null) {
+                    parentsFilter.add(documentMapper.typeFilter(), BooleanClause.Occur.SHOULD);
+                }
+            }
+            parentTypeQuery = parentsFilter.build();
+        }
+
+        if (parentTypeQuery == null) {
+            return null;
+        }
+
+        // wrap the query with type query
+        innerQuery = Queries.filtered(innerQuery, parentDocMapper.typeFilter());
+        Query childrenFilter = Queries.not(parentTypeQuery);
+        ScoreType scoreMode = score ? ScoreType.MAX : ScoreType.NONE;
+        return joinUtilHelper(parentType, parentChildIndexFieldData, childrenFilter, scoreMode, innerQuery, 0, Integer.MAX_VALUE);
     }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
index 461a800..02c2a17 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
@@ -19,62 +19,44 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Sets;
-
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 
 import java.io.IOException;
-import java.util.*;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.List;
 
 /**
  * A query that will return only documents matching specific ids (and a type).
  */
-public class IdsQueryBuilder extends AbstractQueryBuilder<IdsQueryBuilder> {
+public class IdsQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<IdsQueryBuilder> {
 
-    public static final String NAME = "ids";
+    private final List<String> types;
 
-    private final Set<String> ids = Sets.newHashSet();
+    private List<String> values = new ArrayList<>();
 
-    private final String[] types;
+    private float boost = -1;
 
-    static final IdsQueryBuilder PROTOTYPE = new IdsQueryBuilder();
+    private String queryName;
 
-    /**
-     * Creates a new IdsQueryBuilder by optionally providing the types of the documents to look for
-     */
-    public IdsQueryBuilder(@Nullable String... types) {
-        this.types = types;
-    }
-
-    /**
-     * Returns the types used in this query
-     */
-    public String[] types() {
-        return this.types;
+    public IdsQueryBuilder(String... types) {
+        this.types = types == null ? null : Arrays.asList(types);
     }
 
     /**
-     * Adds ids to the query.
+     * Adds ids to the filter.
      */
     public IdsQueryBuilder addIds(String... ids) {
-        Collections.addAll(this.ids, ids);
+        values.addAll(Arrays.asList(ids));
         return this;
     }
 
     /**
-     * Adds ids to the query.
+     * Adds ids to the filter.
      */
     public IdsQueryBuilder addIds(Collection<String> ids) {
-        this.ids.addAll(ids);
+        values.addAll(ids);
         return this;
     }
 
@@ -93,83 +75,48 @@ public class IdsQueryBuilder extends AbstractQueryBuilder<IdsQueryBuilder> {
     }
 
     /**
-     * Returns the ids for the query.
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public Set<String> ids() {
-        return this.ids;
+    @Override
+    public IdsQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public IdsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(IdsQueryParser.NAME);
         if (types != null) {
-            if (types.length == 1) {
-                builder.field("type", types[0]);
+            if (types.size() == 1) {
+                builder.field("type", types.get(0));
             } else {
-                builder.array("types", types);
+                builder.startArray("types");
+                for (Object type : types) {
+                    builder.value(type);
+                }
+                builder.endArray();
             }
         }
         builder.startArray("values");
-        for (String value : ids) {
+        for (Object value : values) {
             builder.value(value);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query query;
-        if (this.ids.isEmpty()) {
-             query = Queries.newMatchNoDocsQuery();
-        } else {
-            Collection<String> typesForQuery;
-            if (types == null || types.length == 0) {
-                typesForQuery = context.queryTypes();
-            } else if (types.length == 1 && MetaData.ALL.equals(types[0])) {
-                typesForQuery = context.mapperService().types();
-            } else {
-                typesForQuery = Sets.newHashSet(types);
-            }
-
-            query = new TermsQuery(UidFieldMapper.NAME, Uid.createUidsForTypesAndIds(typesForQuery, ids));
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // all fields can be empty or null
-        return null;
-    }
-
-    @Override
-    protected IdsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        IdsQueryBuilder idsQueryBuilder = new IdsQueryBuilder(in.readStringArray());
-        idsQueryBuilder.addIds(in.readStringArray());
-        return idsQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeStringArray(types);
-        out.writeStringArray(ids.toArray(new String[ids.size()]));
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(ids, Arrays.hashCode(types));
-    }
-
-    @Override
-    protected boolean doEquals(IdsQueryBuilder other) {
-        return Objects.equals(ids, other.ids) &&
-               Arrays.equals(types, other.types);
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
index 6612140..dcbb19f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
@@ -19,18 +19,29 @@
 
 package org.elasticsearch.index.query;
 
+import com.google.common.collect.Iterables;
+
+import org.apache.lucene.queries.TermsQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.Uid;
+import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Collection;
 import java.util.Collections;
 import java.util.List;
 
 /**
- * Parser for ids query
+ *
  */
-public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
+public class IdsQueryParser implements QueryParser {
+
+    public static final String NAME = "ids";
 
     @Inject
     public IdsQueryParser() {
@@ -38,21 +49,18 @@ public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{IdsQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
-    /**
-     * @return a QueryBuilder representation of the query passed in as XContent in the parse context
-     */
     @Override
-    public IdsQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        List<String> ids = new ArrayList<>();
-        List<String> types = new ArrayList<>();
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        String queryName = null;
 
+        List<BytesRef> ids = new ArrayList<>();
+        Collection<String> types = null;
         String currentFieldName = null;
+        float boost = 1.0f;
+        String queryName = null;
         XContentParser.Token token;
         boolean idsProvided = false;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -64,17 +72,18 @@ public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         if ((token == XContentParser.Token.VALUE_STRING) ||
                                 (token == XContentParser.Token.VALUE_NUMBER)) {
-                            String id = parser.textOrNull();
-                            if (id == null) {
+                            BytesRef value = parser.utf8BytesOrNull();
+                            if (value == null) {
                                 throw new QueryParsingException(parseContext, "No value specified for term filter");
                             }
-                            ids.add(id);
+                            ids.add(value);
                         } else {
                             throw new QueryParsingException(parseContext, "Illegal value for id, expecting a string or number, got: "
                                     + token);
                         }
                     }
                 } else if ("types".equals(currentFieldName) || "type".equals(currentFieldName)) {
+                    types = new ArrayList<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         String value = parser.textOrNull();
                         if (value == null) {
@@ -97,18 +106,26 @@ public class IdsQueryParser extends BaseQueryParser<IdsQueryBuilder> {
                 }
             }
         }
+
         if (!idsProvided) {
             throw new QueryParsingException(parseContext, "[ids] query, no ids values provided");
         }
 
-        IdsQueryBuilder query = new IdsQueryBuilder(types.toArray(new String[types.size()]));
-        query.addIds(ids.toArray(new String[ids.size()]));
-        query.boost(boost).queryName(queryName);
-        return query;
-    }
+        if (ids.isEmpty()) {
+            return Queries.newMatchNoDocsQuery();
+        }
 
-    @Override
-    public IdsQueryBuilder getBuilderPrototype() {
-        return IdsQueryBuilder.PROTOTYPE;
+        if (types == null || types.isEmpty()) {
+            types = parseContext.queryTypes();
+        } else if (types.size() == 1 && Iterables.getFirst(types, null).equals("_all")) {
+            types = parseContext.mapperService().types();
+        }
+
+        TermsQuery query = new TermsQuery(UidFieldMapper.NAME, Uid.createUidsForTypesAndIds(types, ids));
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java b/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
index e2c8f67..810504a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
@@ -22,15 +22,11 @@ package org.elasticsearch.index.query;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.util.CloseableThreadLocal;
 import org.elasticsearch.Version;
-import org.elasticsearch.action.support.IndicesOptions;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
@@ -43,16 +39,12 @@ import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.internal.AllFieldMapper;
-import org.elasticsearch.index.query.support.InnerHitsQueryParserHelper;
-import org.elasticsearch.index.search.termslookup.TermsLookupFetchService;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.similarity.SimilarityService;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
 import org.elasticsearch.indices.query.IndicesQueriesRegistry;
 import org.elasticsearch.script.ScriptService;
 
 import java.io.IOException;
-import java.util.List;
 
 public class IndexQueryParserService extends AbstractIndexComponent {
 
@@ -60,12 +52,11 @@ public class IndexQueryParserService extends AbstractIndexComponent {
     public static final String QUERY_STRING_LENIENT = "index.query_string.lenient";
     public static final String PARSE_STRICT = "index.query.parse.strict";
     public static final String ALLOW_UNMAPPED = "index.query.parse.allow_unmapped_fields";
-    private final InnerHitsQueryParserHelper innerHitsQueryParserHelper;
 
-    private CloseableThreadLocal<QueryShardContext> cache = new CloseableThreadLocal<QueryShardContext>() {
+    private CloseableThreadLocal<QueryParseContext> cache = new CloseableThreadLocal<QueryParseContext>() {
         @Override
-        protected QueryShardContext initialValue() {
-            return new QueryShardContext(index, IndexQueryParserService.this);
+        protected QueryParseContext initialValue() {
+            return new QueryParseContext(index, IndexQueryParserService.this);
         }
     };
 
@@ -81,10 +72,6 @@ public class IndexQueryParserService extends AbstractIndexComponent {
 
     final IndexFieldDataService fieldDataService;
 
-    final ClusterService clusterService;
-
-    final IndexNameExpressionResolver indexNameExpressionResolver;
-
     final BitsetFilterCache bitsetFilterCache;
 
     private final IndicesQueriesRegistry indicesQueriesRegistry;
@@ -94,17 +81,13 @@ public class IndexQueryParserService extends AbstractIndexComponent {
     private final ParseFieldMatcher parseFieldMatcher;
     private final boolean defaultAllowUnmappedFields;
 
-    private TermsLookupFetchService termsLookupFetchService;
-
     @Inject
     public IndexQueryParserService(Index index, @IndexSettings Settings indexSettings,
                                    IndicesQueriesRegistry indicesQueriesRegistry,
                                    ScriptService scriptService, AnalysisService analysisService,
                                    MapperService mapperService, IndexCache indexCache, IndexFieldDataService fieldDataService,
                                    BitsetFilterCache bitsetFilterCache,
-                                   @Nullable SimilarityService similarityService, ClusterService clusterService,
-                                   IndexNameExpressionResolver indexNameExpressionResolver,
-                                   InnerHitsQueryParserHelper innerHitsQueryParserHelper) {
+                                   @Nullable SimilarityService similarityService) {
         super(index, indexSettings);
         this.scriptService = scriptService;
         this.analysisService = analysisService;
@@ -113,20 +96,12 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         this.indexCache = indexCache;
         this.fieldDataService = fieldDataService;
         this.bitsetFilterCache = bitsetFilterCache;
-        this.clusterService = clusterService;
-        this.indexNameExpressionResolver = indexNameExpressionResolver;
 
         this.defaultField = indexSettings.get(DEFAULT_FIELD, AllFieldMapper.NAME);
         this.queryStringLenient = indexSettings.getAsBoolean(QUERY_STRING_LENIENT, false);
         this.parseFieldMatcher = new ParseFieldMatcher(indexSettings);
         this.defaultAllowUnmappedFields = indexSettings.getAsBoolean(ALLOW_UNMAPPED, true);
         this.indicesQueriesRegistry = indicesQueriesRegistry;
-        this.innerHitsQueryParserHelper = innerHitsQueryParserHelper;
-    }
-
-    @Inject(optional=true)
-    public void setTermsLookupFetchService(@Nullable  TermsLookupFetchService termsLookupFetchService) {
-        this.termsLookupFetchService = termsLookupFetchService;
     }
 
     public void close() {
@@ -141,8 +116,8 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         return this.queryStringLenient;
     }
 
-    IndicesQueriesRegistry indicesQueriesRegistry() {
-        return indicesQueriesRegistry;
+    public QueryParser queryParser(String name) {
+        return indicesQueriesRegistry.queryParsers().get(name);
     }
 
     public ParsedQuery parse(QueryBuilder queryBuilder) {
@@ -151,10 +126,10 @@ public class IndexQueryParserService extends AbstractIndexComponent {
             BytesReference bytes = queryBuilder.buildAsBytes();
             parser = XContentFactory.xContent(bytes).createParser(bytes);
             return parse(cache.get(), parser);
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -171,10 +146,10 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         try {
             parser = XContentFactory.xContent(source, offset, length).createParser(source, offset, length);
             return parse(cache.get(), parser);
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -186,8 +161,7 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         return parse(cache.get(), source);
     }
 
-    //norelease
-    public ParsedQuery parse(QueryShardContext context, BytesReference source) {
+    public ParsedQuery parse(QueryParseContext context, BytesReference source) {
         XContentParser parser = null;
         try {
             parser = XContentFactory.xContent(source).createParser(source);
@@ -195,7 +169,7 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(context.parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(context, "Failed to parse", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -203,15 +177,15 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         }
     }
 
-    public ParsedQuery parse(String source) throws QueryParsingException, QueryShardException {
+    public ParsedQuery parse(String source) throws QueryParsingException {
         XContentParser parser = null;
         try {
             parser = XContentFactory.xContent(source).createParser(source);
             return innerParse(cache.get(), parser);
-        } catch (QueryShardException|QueryParsingException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Exception e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse [" + source + "]", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse [" + source + "]", e);
         } finally {
             if (parser != null) {
                 parser.close();
@@ -223,12 +197,11 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         return parse(cache.get(), parser);
     }
 
-    //norelease
-    public ParsedQuery parse(QueryShardContext context, XContentParser parser) {
+    public ParsedQuery parse(QueryParseContext context, XContentParser parser) {
         try {
             return innerParse(context, parser);
         } catch (IOException e) {
-            throw new QueryParsingException(context.parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(context, "Failed to parse", e);
         }
     }
 
@@ -236,12 +209,11 @@ public class IndexQueryParserService extends AbstractIndexComponent {
      * Parses an inner filter, returning null if the filter should be ignored.
      */
     @Nullable
-    //norelease
     public ParsedQuery parseInnerFilter(XContentParser parser) throws IOException {
-        QueryShardContext context = cache.get();
+        QueryParseContext context = cache.get();
         context.reset(parser);
         try {
-            Query filter = context.parseContext().parseInnerFilter();
+            Query filter = context.parseInnerFilter();
             if (filter == null) {
                 return null;
             }
@@ -252,22 +224,27 @@ public class IndexQueryParserService extends AbstractIndexComponent {
     }
 
     @Nullable
-    public QueryBuilder parseInnerQueryBuilder(QueryParseContext parseContext) throws IOException {
-        parseContext.parseFieldMatcher(parseFieldMatcher);
-        return parseContext.parseInnerQueryBuilder();
+    public Query parseInnerQuery(XContentParser parser) throws IOException {
+        QueryParseContext context = cache.get();
+        context.reset(parser);
+        try {
+            return context.parseInnerQuery();
+        } finally {
+            context.reset(null);
+        }
     }
 
     @Nullable
-    //norelease
-    public Query parseInnerQuery(QueryShardContext context) throws IOException {
-        Query query = context.parseContext().parseInnerQueryBuilder().toQuery(context);
+    public Query parseInnerQuery(QueryParseContext parseContext) throws IOException {
+        parseContext.parseFieldMatcher(parseFieldMatcher);
+        Query query = parseContext.parseInnerQuery();
         if (query == null) {
             query = Queries.newMatchNoDocsQuery();
         }
         return query;
     }
 
-    public QueryShardContext getShardContext() {
+    public QueryParseContext getParseContext() {
         return cache.get();
     }
 
@@ -299,60 +276,37 @@ public class IndexQueryParserService extends AbstractIndexComponent {
                         XContentParser qSourceParser = XContentFactory.xContent(querySource).createParser(querySource);
                         parsedQuery = parse(qSourceParser);
                     } else {
-                        throw new QueryParsingException(getShardContext().parseContext(), "request does not support [" + fieldName + "]");
+                        throw new QueryParsingException(getParseContext(), "request does not support [" + fieldName + "]");
                     }
                 }
             }
             if (parsedQuery != null) {
                 return parsedQuery;
             }
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             throw e;
         } catch (Throwable e) {
-            throw new QueryParsingException(getShardContext().parseContext(), "Failed to parse", e);
+            throw new QueryParsingException(getParseContext(), "Failed to parse", e);
         }
 
-        throw new QueryParsingException(getShardContext().parseContext(), "Required query is missing");
+        throw new QueryParsingException(getParseContext(), "Required query is missing");
     }
 
-    //norelease
-    private ParsedQuery innerParse(QueryShardContext context, XContentParser parser) throws IOException, QueryShardException {
-        context.reset(parser);
+    private ParsedQuery innerParse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
+        parseContext.reset(parser);
         try {
-            context.parseFieldMatcher(parseFieldMatcher);
-            return innerParse(context, context.parseContext().parseInnerQueryBuilder());
+            parseContext.parseFieldMatcher(parseFieldMatcher);
+            Query query = parseContext.parseInnerQuery();
+            if (query == null) {
+                query = Queries.newMatchNoDocsQuery();
+            }
+            return new ParsedQuery(query, parseContext.copyNamedQueries());
         } finally {
-            context.reset(null);
-        }
-    }
-
-    private static ParsedQuery innerParse(QueryShardContext context, QueryBuilder queryBuilder) throws IOException, QueryShardException {
-        Query query = queryBuilder.toQuery(context);
-        if (query == null) {
-            query = Queries.newMatchNoDocsQuery();
+            parseContext.reset(null);
         }
-        return new ParsedQuery(query, context.copyNamedQueries());
     }
 
     public ParseFieldMatcher parseFieldMatcher() {
         return parseFieldMatcher;
     }
-
-    public boolean matchesIndices(String... indices) {
-        final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices);
-        for (String index : concreteIndices) {
-            if (Regex.simpleMatch(index, this.index.name())) {
-                return true;
-            }
-        }
-        return false;
-    }
-
-    public List<Object> handleTermsLookup(TermsLookup termsLookup) {
-        return this.termsLookupFetchService.fetch(termsLookup);
-    }
-
-    public InnerHitsQueryParserHelper getInnerHitsQueryParserHelper() {
-        return innerHitsQueryParserHelper;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java
index 23e44df..7c2af81 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryBuilder.java
@@ -19,143 +19,69 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Arrays;
-import java.util.Objects;
 
 /**
  * A query that will execute the wrapped query only for the specified indices, and "match_all" when
  * it does not match those indices (by default).
  */
-public class IndicesQueryBuilder extends AbstractQueryBuilder<IndicesQueryBuilder> {
+public class IndicesQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "indices";
-
-    private final QueryBuilder innerQuery;
+    private final QueryBuilder queryBuilder;
 
     private final String[] indices;
 
-    private QueryBuilder noMatchQuery = defaultNoMatchQuery();
-
-    static final IndicesQueryBuilder PROTOTYPE = new IndicesQueryBuilder();
+    private String sNoMatchQuery;
+    private QueryBuilder noMatchQuery;
 
-    private IndicesQueryBuilder() {
-        this.innerQuery = null;
-        this.indices = null;
-    }
+    private String queryName;
 
-    public IndicesQueryBuilder(QueryBuilder innerQuery, String... indices) {
-        this.innerQuery = Objects.requireNonNull(innerQuery);
+    public IndicesQueryBuilder(QueryBuilder queryBuilder, String... indices) {
+        this.queryBuilder = queryBuilder;
         this.indices = indices;
     }
 
-    public QueryBuilder innerQuery() {
-        return this.innerQuery;
-    }
-
-    public String[] indices() {
-        return this.indices;
+    /**
+     * Sets the no match query, can either be <tt>all</tt> or <tt>none</tt>.
+     */
+    public IndicesQueryBuilder noMatchQuery(String type) {
+        this.sNoMatchQuery = type;
+        return this;
     }
 
     /**
      * Sets the query to use when it executes on an index that does not match the indices provided.
      */
     public IndicesQueryBuilder noMatchQuery(QueryBuilder noMatchQuery) {
-        this.noMatchQuery = (noMatchQuery != null) ? noMatchQuery : defaultNoMatchQuery();
+        this.noMatchQuery = noMatchQuery;
         return this;
     }
 
     /**
-     * Sets the no match query, can either be <tt>all</tt> or <tt>none</tt>.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public IndicesQueryBuilder noMatchQuery(String type) {
-        this.noMatchQuery = IndicesQueryParser.parseNoMatchQuery(type);
+    public IndicesQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
         return this;
     }
 
-    public QueryBuilder noMatchQuery() {
-        return this.noMatchQuery;
-    }
-
-    static QueryBuilder defaultNoMatchQuery() {
-        return QueryBuilders.matchAllQuery();
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(IndicesQueryParser.NAME);
         builder.field("indices", indices);
         builder.field("query");
-        innerQuery.toXContent(builder, params);
-        builder.field("no_match_query");
-        noMatchQuery.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        if (context.matchesIndices(indices)) {
-            return innerQuery.toQuery(context);
-        }
-        return noMatchQuery.toQuery(context);
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        if (boost != DEFAULT_BOOST) {
-            //if both the wrapped query and the wrapper hold a boost, the main one coming from the wrapper wins
-            query.setBoost(boost);
+        queryBuilder.toXContent(builder, params);
+        if (noMatchQuery != null) {
+            builder.field("no_match_query");
+            noMatchQuery.toXContent(builder, params);
+        } else if (sNoMatchQuery != null) {
+            builder.field("no_match_query", sNoMatchQuery);
         }
-    }
-    
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.innerQuery == null) {
-            validationException = addValidationError("inner query cannot be null", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        if (this.indices == null || this.indices.length == 0) {
-            validationException = addValidationError("list of indices cannot be null or empty", validationException);
-        }
-        validationException = validateInnerQuery(innerQuery, validationException);
-        validationException = validateInnerQuery(noMatchQuery, validationException);
-        return validationException;
-    }
-
-    @Override
-    protected IndicesQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        IndicesQueryBuilder indicesQueryBuilder = new IndicesQueryBuilder(in.readQuery(), in.readStringArray());
-        indicesQueryBuilder.noMatchQuery = in.readQuery();
-        return indicesQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(innerQuery);
-        out.writeStringArray(indices);
-        out.writeQuery(noMatchQuery);
-    }
-    
-    @Override
-    public int doHashCode() {
-        return Objects.hash(innerQuery, noMatchQuery, Arrays.hashCode(indices));
-    }
-    
-    @Override
-    protected boolean doEquals(IndicesQueryBuilder other) {
-        return Objects.equals(innerQuery, other.innerQuery) &&
-                Arrays.equals(indices, other.indices) &&  // otherwise we are comparing pointers
-                Objects.equals(noMatchQuery, other.noMatchQuery);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java
index b7a93ac..a18c865 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IndicesQueryParser.java
@@ -19,60 +19,78 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.elasticsearch.action.support.IndicesOptions;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
+import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
+import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.query.support.XContentStructure;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collection;
 
 /**
- * Parser for {@link IndicesQueryBuilder}.
  */
-public class IndicesQueryParser extends BaseQueryParser {
+public class IndicesQueryParser implements QueryParser {
 
+    public static final String NAME = "indices";
     private static final ParseField QUERY_FIELD = new ParseField("query", "filter");
     private static final ParseField NO_MATCH_QUERY = new ParseField("no_match_query", "no_match_filter");
 
+    @Nullable
+    private final ClusterService clusterService;
+    private final IndexNameExpressionResolver indexNameExpressionResolver;
+
     @Inject
-    public IndicesQueryParser() {
+    public IndicesQueryParser(@Nullable ClusterService clusterService, IndexNameExpressionResolver indexNameExpressionResolver) {
+        this.clusterService = clusterService;
+        this.indexNameExpressionResolver = indexNameExpressionResolver;
     }
 
     @Override
     public String[] names() {
-        return new String[]{IndicesQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder innerQuery = null;
-        Collection<String> indices = new ArrayList<>();
-        QueryBuilder noMatchQuery = IndicesQueryBuilder.defaultNoMatchQuery();
-
+        Query noMatchQuery = null;
+        boolean queryFound = false;
+        boolean indicesFound = false;
+        boolean currentIndexMatchesIndices = false;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
 
         String currentFieldName = null;
         XContentParser.Token token;
+        XContentStructure.InnerQuery innerQuery = null;
+        XContentStructure.InnerQuery innerNoMatchQuery = null;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, QUERY_FIELD)) {
-                    innerQuery = parseContext.parseInnerQueryBuilder();
+                    innerQuery = new XContentStructure.InnerQuery(parseContext, null);
+                    queryFound = true;
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, NO_MATCH_QUERY)) {
-                    noMatchQuery = parseContext.parseInnerQueryBuilder();
+                    innerNoMatchQuery = new XContentStructure.InnerQuery(parseContext, null);
                 } else {
                     throw new QueryParsingException(parseContext, "[indices] query does not support [" + currentFieldName + "]");
                 }
             } else if (token == XContentParser.Token.START_ARRAY) {
                 if ("indices".equals(currentFieldName)) {
-                    if (indices.isEmpty() == false) {
+                    if (indicesFound) {
                         throw new QueryParsingException(parseContext, "[indices] indices or index already specified");
                     }
+                    indicesFound = true;
+                    Collection<String> indices = new ArrayList<>();
                     while (parser.nextToken() != XContentParser.Token.END_ARRAY) {
                         String value = parser.textOrNull();
                         if (value == null) {
@@ -80,50 +98,67 @@ public class IndicesQueryParser extends BaseQueryParser {
                         }
                         indices.add(value);
                     }
+                    currentIndexMatchesIndices = matchesIndices(parseContext.index().name(), indices.toArray(new String[indices.size()]));
                 } else {
                     throw new QueryParsingException(parseContext, "[indices] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("index".equals(currentFieldName)) {
-                    if (indices.isEmpty() == false) {
+                    if (indicesFound) {
                         throw new QueryParsingException(parseContext, "[indices] indices or index already specified");
                     }
-                    indices.add(parser.text());
+                    indicesFound = true;
+                    currentIndexMatchesIndices = matchesIndices(parseContext.index().name(), parser.text());
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, NO_MATCH_QUERY)) {
-                    noMatchQuery = parseNoMatchQuery(parser.text());
+                    String type = parser.text();
+                    if ("all".equals(type)) {
+                        noMatchQuery = Queries.newMatchAllQuery();
+                    } else if ("none".equals(type)) {
+                        noMatchQuery = Queries.newMatchNoDocsQuery();
+                    }
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[indices] query does not support [" + currentFieldName + "]");
                 }
             }
         }
-        
-        if (innerQuery == null) {
+        if (!queryFound) {
             throw new QueryParsingException(parseContext, "[indices] requires 'query' element");
         }
-        if (indices.isEmpty()) {
+        if (!indicesFound) {
             throw new QueryParsingException(parseContext, "[indices] requires 'indices' or 'index' element");
         }
-        return new IndicesQueryBuilder(innerQuery, indices.toArray(new String[indices.size()]))
-                .noMatchQuery(noMatchQuery)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    static QueryBuilder parseNoMatchQuery(String type) {
-        if ("all".equals(type)) {
-            return QueryBuilders.matchAllQuery();
-        } else if ("none".equals(type)) {
-            return new MatchNoneQueryBuilder();
+        Query chosenQuery;
+        if (currentIndexMatchesIndices) {
+            chosenQuery = innerQuery.asQuery();
+        } else {
+            // If noMatchQuery is set, it means "no_match_query" was "all" or "none"
+            if (noMatchQuery != null) {
+                chosenQuery = noMatchQuery;
+            } else {
+                // There might be no "no_match_query" set, so default to the match_all if not set
+                if (innerNoMatchQuery == null) {
+                    chosenQuery = Queries.newMatchAllQuery();
+                } else {
+                    chosenQuery = innerNoMatchQuery.asQuery();
+                }
+            }
+        }
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, chosenQuery);
         }
-        throw new IllegalArgumentException("query type can only be [all] or [none] but not " + "[" + type + "]");
+        return chosenQuery;
     }
 
-    @Override
-    public IndicesQueryBuilder getBuilderPrototype() {
-        return IndicesQueryBuilder.PROTOTYPE;
+    protected boolean matchesIndices(String currentIndex, String... indices) {
+        final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices);
+        for (String index : concreteIndices) {
+            if (Regex.simpleMatch(index, currentIndex)) {
+                return true;
+            }
+        }
+        return false;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java
index b217a5e..9d44f39 100644
--- a/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/LimitQueryBuilder.java
@@ -19,11 +19,7 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
 import org.elasticsearch.action.search.SearchRequestBuilder;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
@@ -32,62 +28,18 @@ import java.io.IOException;
  * @deprecated Use {@link SearchRequestBuilder#setTerminateAfter(int)} instead.
  */
 @Deprecated
-public class LimitQueryBuilder extends AbstractQueryBuilder<LimitQueryBuilder> {
+public class LimitQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "limit";
     private final int limit;
-    static final LimitQueryBuilder PROTOTYPE = new LimitQueryBuilder(-1);
 
     public LimitQueryBuilder(int limit) {
         this.limit = limit;
     }
 
-    public int limit() {
-        return limit;
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(LimitQueryParser.NAME);
         builder.field("value", limit);
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // this filter is deprecated and parses to a filter that matches everything
-        return Queries.newMatchAllQuery();
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
-
-    @Override
-    protected boolean doEquals(LimitQueryBuilder other) {
-        return Integer.compare(other.limit, limit) == 0;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return this.limit;
-    }
-
-    @Override
-    protected LimitQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new LimitQueryBuilder(in.readInt());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeInt(limit);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/LimitQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/LimitQueryParser.java
index ed47198..3419f61 100644
--- a/core/src/main/java/org/elasticsearch/index/query/LimitQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/LimitQueryParser.java
@@ -19,17 +19,17 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
-/**
- * Parser for limit query
- * @deprecated use terminate_after feature instead
- */
 @Deprecated
-public class LimitQueryParser extends BaseQueryParser<LimitQueryBuilder> {
+public class LimitQueryParser implements QueryParser {
+
+    public static final String NAME = "limit";
 
     @Inject
     public LimitQueryParser() {
@@ -37,16 +37,14 @@ public class LimitQueryParser extends BaseQueryParser<LimitQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{LimitQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public LimitQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         int limit = -1;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String currentFieldName = null;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -55,10 +53,6 @@ public class LimitQueryParser extends BaseQueryParser<LimitQueryBuilder> {
             } else if (token.isValue()) {
                 if ("value".equals(currentFieldName)) {
                     limit = parser.intValue();
-                } else if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[limit] query does not support [" + currentFieldName + "]");
                 }
@@ -69,11 +63,7 @@ public class LimitQueryParser extends BaseQueryParser<LimitQueryBuilder> {
             throw new QueryParsingException(parseContext, "No value specified for limit query");
         }
 
-        return new LimitQueryBuilder(limit).boost(boost).queryName(queryName);
-    }
-
-    @Override
-    public LimitQueryBuilder getBuilderPrototype() {
-        return LimitQueryBuilder.PROTOTYPE;
+        // this filter is deprecated and parses to a filter that matches everything
+        return Queries.newMatchAllQuery();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java
index 00c5019..b09bc9f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryBuilder.java
@@ -19,10 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
@@ -30,52 +26,26 @@ import java.io.IOException;
 /**
  * A query that matches on all documents.
  */
-public class MatchAllQueryBuilder extends AbstractQueryBuilder<MatchAllQueryBuilder> {
+public class MatchAllQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MatchAllQueryBuilder> {
 
-    public static final String NAME = "match_all";
-
-    static final MatchAllQueryBuilder PROTOTYPE = new MatchAllQueryBuilder();
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return Queries.newMatchAllQuery();
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
+    private float boost = -1;
 
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    protected boolean doEquals(MatchAllQueryBuilder other) {
-        return true;
+    public MatchAllQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     @Override
-    protected int doHashCode() {
-        return 0;
-    }
-
-    @Override
-    protected MatchAllQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new MatchAllQueryBuilder();
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        //nothing to write really
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(MatchAllQueryParser.NAME);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java
index 4066c75..933d3d3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchAllQueryParser.java
@@ -19,16 +19,21 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
 /**
- * Parser for match_all query
+ *
  */
-public class MatchAllQueryParser extends BaseQueryParser<MatchAllQueryBuilder> {
+public class MatchAllQueryParser implements QueryParser {
+
+    public static final String NAME = "match_all";
 
     @Inject
     public MatchAllQueryParser() {
@@ -36,38 +41,35 @@ public class MatchAllQueryParser extends BaseQueryParser<MatchAllQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{MatchAllQueryBuilder.NAME, Strings.toCamelCase(MatchAllQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public MatchAllQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
+        float boost = 1.0f;
         String currentFieldName = null;
+
         XContentParser.Token token;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         while (((token = parser.nextToken()) != XContentParser.Token.END_OBJECT && token != XContentParser.Token.END_ARRAY)) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
+                if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[match_all] query does not support [" + currentFieldName + "]");
                 }
             }
         }
-        MatchAllQueryBuilder queryBuilder = new MatchAllQueryBuilder();
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
 
-    @Override
-    public MatchAllQueryBuilder getBuilderPrototype() {
-        return MatchAllQueryBuilder.PROTOTYPE;
+        if (boost == 1.0f) {
+            return Queries.newMatchAllQuery();
+        }
+
+        MatchAllDocsQuery query = new MatchAllDocsQuery();
+        query.setBoost(boost);
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryBuilder.java
deleted file mode 100644
index e6d6a7d..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryBuilder.java
+++ /dev/null
@@ -1,85 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-
-import java.io.IOException;
-
-/**
- * A query that matches no document.
- */
-public class MatchNoneQueryBuilder extends AbstractQueryBuilder<MatchNoneQueryBuilder> {
-
-    public static final String NAME = "match_none";
-
-    public static final MatchNoneQueryBuilder PROTOTYPE = new MatchNoneQueryBuilder();
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return Queries.newMatchNoDocsQuery();
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        //no-op this query doesn't support boost
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        // nothing to validate
-        return null;
-    }
-
-    @Override
-    protected boolean doEquals(MatchNoneQueryBuilder other) {
-        return true;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return 0;
-    }
-
-    @Override
-    protected MatchNoneQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new MatchNoneQueryBuilder();
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        //nothing to write really
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryParser.java
deleted file mode 100644
index 3536a5d..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/MatchNoneQueryParser.java
+++ /dev/null
@@ -1,55 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.xcontent.XContentParser;
-
-import java.io.IOException;
-
-public class MatchNoneQueryParser extends BaseQueryParser {
-
-    @Inject
-    public MatchNoneQueryParser() {
-    }
-
-    @Override
-    public String[] names() {
-        return new String[]{MatchNoneQueryBuilder.NAME, Strings.toCamelCase(MatchNoneQueryBuilder.NAME)};
-    }
-
-    @Override
-    public MatchNoneQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException {
-        XContentParser parser = parseContext.parser();
-
-        XContentParser.Token token = parser.nextToken();
-        if (token != XContentParser.Token.END_OBJECT) {
-            throw new QueryParsingException(parseContext, "[match_none] query malformed");
-        }
-
-        return new MatchNoneQueryBuilder();
-    }
-
-    @Override
-    public MatchNoneQueryBuilder getBuilderPrototype() {
-        return MatchNoneQueryBuilder.PROTOTYPE;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java
index 5fbfff7..6f73f08 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java
@@ -29,9 +29,12 @@ import java.util.Locale;
  * Match query is a query that analyzes the text and constructs a query as the result of the analysis. It
  * can construct different queries based on the type provided.
  */
-public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
+public class MatchQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MatchQueryBuilder> {
 
-    public static final String NAME = "match";
+    public enum Operator {
+        OR,
+        AND
+    }
 
     public enum Type {
         /**
@@ -63,6 +66,8 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
 
     private String analyzer;
 
+    private Float boost;
+
     private Integer slop;
 
     private Fuzziness fuzziness;
@@ -83,7 +88,7 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
 
     private Float cutoff_Frequency = null;
 
-    static final MatchQueryBuilder PROTOTYPE = new MatchQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * Constructs a new text query.
@@ -119,6 +124,15 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
     }
 
     /**
+     * Set the boost to apply to the query.
+     */
+    @Override
+    public MatchQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
      * Set the phrase slop if evaluated to a phrase query type.
      */
     public MatchQueryBuilder slop(int slop) {
@@ -187,9 +201,17 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
         return this;
     }
 
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public MatchQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(MatchQueryParser.NAME);
         builder.startObject(name);
 
         builder.field("query", text);
@@ -202,6 +224,9 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
         if (analyzer != null) {
             builder.field("analyzer", analyzer);
         }
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
         if (slop != null) {
             builder.field("slop", slop);
         }
@@ -233,13 +258,12 @@ public class MatchQueryBuilder extends AbstractQueryBuilder<MatchQueryBuilder> {
         if (cutoff_Frequency != null) {
             builder.field("cutoff_frequency", cutoff_Frequency);
         }
-        printBoostAndQueryName(builder);
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+
+
         builder.endObject();
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java
index 7997af6..2bf0d7c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MatchQueryParser.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.index.query;
 
 import org.apache.lucene.queries.ExtendedCommonTermsQuery;
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
@@ -34,7 +35,9 @@ import java.io.IOException;
 /**
  *
  */
-public class MatchQueryParser extends BaseQueryParserTemp {
+public class MatchQueryParser implements QueryParser {
+
+    public static final String NAME = "match";
 
     @Inject
     public MatchQueryParser() {
@@ -43,13 +46,12 @@ public class MatchQueryParser extends BaseQueryParserTemp {
     @Override
     public String[] names() {
         return new String[]{
-                MatchQueryBuilder.NAME, "match_phrase", "matchPhrase", "match_phrase_prefix", "matchPhrasePrefix", "matchFuzzy", "match_fuzzy", "fuzzy_match"
+                NAME, "match_phrase", "matchPhrase", "match_phrase_prefix", "matchPhrasePrefix", "matchFuzzy", "match_fuzzy", "fuzzy_match"
         };
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         MatchQuery.Type type = MatchQuery.Type.BOOLEAN;
@@ -68,8 +70,8 @@ public class MatchQueryParser extends BaseQueryParserTemp {
         String fieldName = parser.currentName();
 
         Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        MatchQuery matchQuery = new MatchQuery(context);
+        float boost = 1.0f;
+        MatchQuery matchQuery = new MatchQuery(parseContext);
         String minimumShouldMatch = null;
         String queryName = null;
 
@@ -95,7 +97,7 @@ public class MatchQueryParser extends BaseQueryParserTemp {
                         }
                     } else if ("analyzer".equals(currentFieldName)) {
                         String analyzer = parser.text();
-                        if (context.analysisService().analyzer(analyzer) == null) {
+                        if (parseContext.analysisService().analyzer(analyzer) == null) {
                             throw new QueryParsingException(parseContext, "[match] analyzer [" + parser.text() + "] not found");
                         }
                         matchQuery.setAnalyzer(analyzer);
@@ -110,7 +112,15 @@ public class MatchQueryParser extends BaseQueryParserTemp {
                     } else if ("max_expansions".equals(currentFieldName) || "maxExpansions".equals(currentFieldName)) {
                         matchQuery.setMaxExpansions(parser.intValue());
                     } else if ("operator".equals(currentFieldName)) {
-                        matchQuery.setOccur(Operator.fromString(parser.text()).toBooleanClauseOccur());
+                        String op = parser.text();
+                        if ("or".equalsIgnoreCase(op)) {
+                            matchQuery.setOccur(BooleanClause.Occur.SHOULD);
+                        } else if ("and".equalsIgnoreCase(op)) {
+                            matchQuery.setOccur(BooleanClause.Occur.MUST);
+                        } else {
+                            throw new QueryParsingException(parseContext, "text query requires operator to be either 'and' or 'or', not ["
+                                    + op + "]");
+                        }
                     } else if ("minimum_should_match".equals(currentFieldName) || "minimumShouldMatch".equals(currentFieldName)) {
                         minimumShouldMatch = parser.textOrNull();
                     } else if ("fuzzy_rewrite".equals(currentFieldName) || "fuzzyRewrite".equals(currentFieldName)) {
@@ -164,13 +174,8 @@ public class MatchQueryParser extends BaseQueryParserTemp {
         }
         query.setBoost(boost);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
         return query;
     }
-
-    @Override
-    public MatchQueryBuilder getBuilderPrototype() {
-        return MatchQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java
index 4d3115c..ac3f279 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MissingQueryBuilder.java
@@ -19,45 +19,25 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.*;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
-import java.util.Collection;
-import java.util.Objects;
 
 /**
- * Constructs a filter that have only null values or no value in the original field.
+ * Constructs a filter that only match on documents that the field has a value in them.
  */
-public class MissingQueryBuilder extends AbstractQueryBuilder<MissingQueryBuilder> {
+public class MissingQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "missing";
+    private String name;
 
-    public static final boolean DEFAULT_NULL_VALUE = false;
+    private String queryName;
 
-    public static final boolean DEFAULT_EXISTENCE_VALUE = true;
+    private Boolean nullValue;
 
-    private final String fieldPattern;
+    private Boolean existence;
 
-    private boolean nullValue = DEFAULT_NULL_VALUE;
-
-    private boolean existence = DEFAULT_EXISTENCE_VALUE;
-
-    static final MissingQueryBuilder PROTOTYPE = new MissingQueryBuilder(null);
-
-    public MissingQueryBuilder(String fieldPattern) {
-        this.fieldPattern = fieldPattern;
-    }
-
-    public String fieldPattern() {
-        return this.fieldPattern;
+    public MissingQueryBuilder(String name) {
+        this.name = name;
     }
 
     /**
@@ -70,15 +50,7 @@ public class MissingQueryBuilder extends AbstractQueryBuilder<MissingQueryBuilde
     }
 
     /**
-     * Returns true if the missing filter will include documents where the field contains a null value, otherwise
-     * these documents will not be included.
-     */
-    public boolean nullValue() {
-        return this.nullValue;
-    }
-
-    /**
-     * Should the missing filter include documents where the field doesn't exist in the docs.
+     * Should the missing filter include documents where the field doesn't exists in the docs.
      * Defaults to <tt>true</tt>.
      */
     public MissingQueryBuilder existence(boolean existence) {
@@ -87,156 +59,26 @@ public class MissingQueryBuilder extends AbstractQueryBuilder<MissingQueryBuilde
     }
 
     /**
-     * Returns true if the missing filter will include documents where the field has no values, otherwise
-     * these documents will not be included.
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
      */
-    public boolean existence() {
-        return this.existence;
+    public MissingQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("field", fieldPattern);
-        builder.field("null_value", nullValue);
-        builder.field("existence", existence);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return newFilter(context, fieldPattern, existence, nullValue);
-    }
-
-    public static Query newFilter(QueryShardContext context, String fieldPattern, boolean existence, boolean nullValue) {
-        if (!existence && !nullValue) {
-            throw new QueryShardException(context, "missing must have either existence, or null_value, or both set to true");
-        }
-
-        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType) context.mapperService().fullName(FieldNamesFieldMapper.NAME);
-        if (fieldNamesFieldType == null) {
-            // can only happen when no types exist, so no docs exist either
-            return Queries.newMatchNoDocsQuery();
-        }
-
-        ObjectMapper objectMapper = context.getObjectMapper(fieldPattern);
-        if (objectMapper != null) {
-            // automatic make the object mapper pattern
-            fieldPattern = fieldPattern + ".*";
-        }
-
-        Collection<String> fields = context.simpleMatchToIndexNames(fieldPattern);
-        if (fields.isEmpty()) {
-            if (existence) {
-                // if we ask for existence of fields, and we found none, then we should match on all
-                return Queries.newMatchAllQuery();
-            }
-            return null;
-        }
-
-        Query existenceFilter = null;
-        Query nullFilter = null;
-
-        if (existence) {
-            BooleanQuery.Builder boolFilter = new BooleanQuery.Builder();
-            for (String field : fields) {
-                MappedFieldType fieldType = context.fieldMapper(field);
-                Query filter = null;
-                if (fieldNamesFieldType.isEnabled()) {
-                    final String f;
-                    if (fieldType != null) {
-                        f = fieldType.names().indexName();
-                    } else {
-                        f = field;
-                    }
-                    filter = fieldNamesFieldType.termQuery(f, context);
-                }
-                // if _field_names are not indexed, we need to go the slow way
-                if (filter == null && fieldType != null) {
-                    filter = fieldType.rangeQuery(null, null, true, true);
-                }
-                if (filter == null) {
-                    filter = new TermRangeQuery(field, null, null, true, true);
-                }
-                boolFilter.add(filter, BooleanClause.Occur.SHOULD);
-            }
-
-            existenceFilter = boolFilter.build();
-            existenceFilter = Queries.not(existenceFilter);;
-        }
-
-        if (nullValue) {
-            for (String field : fields) {
-                MappedFieldType fieldType = context.fieldMapper(field);
-                if (fieldType != null) {
-                    nullFilter = fieldType.nullValueQuery();
-                }
-            }
-        }
-
-        Query filter;
-        if (nullFilter != null) {
-            if (existenceFilter != null) {
-                filter = new BooleanQuery.Builder()
-                        .add(existenceFilter, BooleanClause.Occur.SHOULD)
-                        .add(nullFilter, BooleanClause.Occur.SHOULD)
-                        .build();
-            } else {
-                filter = nullFilter;
-            }
-        } else {
-            filter = existenceFilter;
+        builder.startObject(MissingQueryParser.NAME);
+        builder.field("field", name);
+        if (nullValue != null) {
+            builder.field("null_value", nullValue);
         }
-
-        if (filter == null) {
-            return null;
-        }
-
-        return new ConstantScoreQuery(filter);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldPattern)) {
-            validationException = addValidationError("missing must be provided with a [field]", validationException);
+        if (existence != null) {
+            builder.field("existence", existence);
         }
-        if (!existence && !nullValue) {
-            validationException = addValidationError("missing must have either existence, or null_value, or both set to true", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    protected MissingQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        MissingQueryBuilder missingQueryBuilder = new MissingQueryBuilder(in.readString());
-        missingQueryBuilder.nullValue = in.readBoolean();
-        missingQueryBuilder.existence = in.readBoolean();
-        return missingQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldPattern);
-        out.writeBoolean(nullValue);
-        out.writeBoolean(existence);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldPattern, nullValue, existence);
-    }
-
-    @Override
-    protected boolean doEquals(MissingQueryBuilder other) {
-        return Objects.equals(fieldPattern, other.fieldPattern) &&
-                Objects.equals(nullValue, other.nullValue) &&
-                Objects.equals(existence, other.existence);
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java
index 1dd6bd1..8d13caa 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MissingQueryParser.java
@@ -19,15 +19,29 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermRangeQuery;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
+import org.elasticsearch.index.mapper.object.ObjectMapper;
 
 import java.io.IOException;
+import java.util.Collection;
 
 /**
- * Parser for missing query
+ *
  */
-public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
+public class MissingQueryParser implements QueryParser {
+
+    public static final String NAME = "missing";
+    public static final boolean DEFAULT_NULL_VALUE = false;
+    public static final boolean DEFAULT_EXISTENCE_VALUE = true;
 
     @Inject
     public MissingQueryParser() {
@@ -35,18 +49,17 @@ public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{MissingQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public MissingQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldPattern = null;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        boolean nullValue = MissingQueryBuilder.DEFAULT_NULL_VALUE;
-        boolean existence = MissingQueryBuilder.DEFAULT_EXISTENCE_VALUE;
+        boolean nullValue = DEFAULT_NULL_VALUE;
+        boolean existence = DEFAULT_EXISTENCE_VALUE;
 
         XContentParser.Token token;
         String currentFieldName = null;
@@ -62,8 +75,6 @@ public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
                     existence = parser.booleanValue();
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[missing] query does not support [" + currentFieldName + "]");
                 }
@@ -73,15 +84,97 @@ public class MissingQueryParser extends BaseQueryParser<MissingQueryBuilder> {
         if (fieldPattern == null) {
             throw new QueryParsingException(parseContext, "missing must be provided with a [field]");
         }
-        return new MissingQueryBuilder(fieldPattern)
-                .nullValue(nullValue)
-                .existence(existence)
-                .boost(boost)
-                .queryName(queryName);
+
+        return newFilter(parseContext, fieldPattern, existence, nullValue, queryName);
     }
 
-    @Override
-    public MissingQueryBuilder getBuilderPrototype() {
-        return MissingQueryBuilder.PROTOTYPE;
+    public static Query newFilter(QueryParseContext parseContext, String fieldPattern, boolean existence, boolean nullValue, String queryName) {
+        if (!existence && !nullValue) {
+            throw new QueryParsingException(parseContext, "missing must have either existence, or null_value, or both set to true");
+        }
+
+        final FieldNamesFieldMapper.FieldNamesFieldType fieldNamesFieldType = (FieldNamesFieldMapper.FieldNamesFieldType)parseContext.mapperService().fullName(FieldNamesFieldMapper.NAME);
+        if (fieldNamesFieldType == null) {
+            // can only happen when no types exist, so no docs exist either
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        ObjectMapper objectMapper = parseContext.getObjectMapper(fieldPattern);
+        if (objectMapper != null) {
+            // automatic make the object mapper pattern
+            fieldPattern = fieldPattern + ".*";
+        }
+
+        Collection<String> fields = parseContext.simpleMatchToIndexNames(fieldPattern);
+        if (fields.isEmpty()) {
+            if (existence) {
+                // if we ask for existence of fields, and we found none, then we should match on all
+                return Queries.newMatchAllQuery();
+            }
+            return null;
+        }
+
+        Query existenceFilter = null;
+        Query nullFilter = null;
+
+        if (existence) {
+            BooleanQuery.Builder boolFilter = new BooleanQuery.Builder();
+            for (String field : fields) {
+                MappedFieldType fieldType = parseContext.fieldMapper(field);
+                Query filter = null;
+                if (fieldNamesFieldType.isEnabled()) {
+                    final String f;
+                    if (fieldType != null) {
+                        f = fieldType.names().indexName();
+                    } else {
+                        f = field;
+                    }
+                    filter = fieldNamesFieldType.termQuery(f, parseContext);
+                }
+                // if _field_names are not indexed, we need to go the slow way
+                if (filter == null && fieldType != null) {
+                    filter = fieldType.rangeQuery(null, null, true, true);
+                }
+                if (filter == null) {
+                    filter = new TermRangeQuery(field, null, null, true, true);
+                }
+                boolFilter.add(filter, BooleanClause.Occur.SHOULD);
+            }
+
+            existenceFilter = boolFilter.build();
+            existenceFilter = Queries.not(existenceFilter);;
+        }
+
+        if (nullValue) {
+            for (String field : fields) {
+                MappedFieldType fieldType = parseContext.fieldMapper(field);
+                if (fieldType != null) {
+                    nullFilter = fieldType.nullValueQuery();
+                }
+            }
+        }
+
+        Query filter;
+        if (nullFilter != null) {
+            if (existenceFilter != null) {
+                filter = new BooleanQuery.Builder()
+                    .add(existenceFilter, BooleanClause.Occur.SHOULD)
+                    .add(nullFilter, BooleanClause.Occur.SHOULD)
+                    .build();
+            } else {
+                filter = nullFilter;
+            }
+        } else {
+            filter = existenceFilter;
+        }
+
+        if (filter == null) {
+            return null;
+        }
+
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, existenceFilter);
+        }
+        return new ConstantScoreQuery(filter);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
index fbd13ea..4994070 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
@@ -19,138 +19,358 @@
 
 package org.elasticsearch.index.query;
 
-import org.elasticsearch.action.get.MultiGetRequest;
+import org.elasticsearch.ElasticsearchParseException;
+import org.elasticsearch.ExceptionsHelper;
+import org.elasticsearch.action.termvectors.TermVectorsRequest;
 import org.elasticsearch.common.Nullable;
+import org.elasticsearch.common.ParseField;
+import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.lucene.uid.Versions;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.common.xcontent.XContentType;
+import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.index.VersionType;
-import org.elasticsearch.search.fetch.source.FetchSourceContext;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-import java.util.Locale;
+import java.util.*;
+
+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 
 /**
- * A more like this query that finds documents that are "like" the provided {@link #likeText(String)}
- * which is checked against the fields the query is constructed with.
+ * A more like this query that finds documents that are "like" the provided set of document(s).
+ *
+ * The documents are provided as a set of strings and/or a list of {@link Item}.
  */
-public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQueryBuilder> {
+public class MoreLikeThisQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MoreLikeThisQueryBuilder> {
 
     /**
-     * A single get item. Pure delegate to multi get.
+     * A single item to be used for a {@link MoreLikeThisQueryBuilder}.
      */
-    public static final class Item extends MultiGetRequest.Item implements ToXContent {
+    public static final class Item implements ToXContent {
         public static final Item[] EMPTY_ARRAY = new Item[0];
 
+        public interface Field {
+            ParseField INDEX = new ParseField("_index");
+            ParseField TYPE = new ParseField("_type");
+            ParseField ID = new ParseField("_id");
+            ParseField DOC = new ParseField("doc");
+            ParseField FIELDS = new ParseField("fields");
+            ParseField PER_FIELD_ANALYZER = new ParseField("per_field_analyzer");
+            ParseField ROUTING = new ParseField("_routing");
+            ParseField VERSION = new ParseField("_version");
+            ParseField VERSION_TYPE = new ParseField("_version_type");
+        }
+
+        private String index;
+        private String type;
+        private String id;
         private BytesReference doc;
-        private String likeText;
+        private String[] fields;
+        private Map<String, String> perFieldAnalyzer;
+        private String routing;
+        private long version = Versions.MATCH_ANY;
+        private VersionType versionType = VersionType.INTERNAL;
 
         public Item() {
-            super();
+
         }
 
+        /**
+         * Constructor for a given item / document request
+         *
+         * @param index the index where the document is located
+         * @param type the type of the document
+         * @param id and its id
+         */
         public Item(String index, @Nullable String type, String id) {
-            super(index, type, id);
+            this.index = index;
+            this.type = type;
+            this.id = id;
+        }
+
+        /**
+         * Constructor for an artificial document request, that is not present in the index.
+         *
+         * @param index the index to be used for parsing the doc
+         * @param type the type to be used for parsing the doc
+         * @param doc the document specification
+         */
+        public Item(String index, String type, XContentBuilder doc) {
+            this.index = index;
+            this.type = type;
+            this.doc(doc);
+        }
+
+        public String index() {
+            return index;
+        }
+
+        public Item index(String index) {
+            this.index = index;
+            return this;
+        }
+
+        public String type() {
+            return type;
+        }
+
+        public Item type(String type) {
+            this.type = type;
+            return this;
         }
 
-        public Item(String likeText) {
-            this.likeText = likeText;
+        public String id() {
+            return id;
+        }
+
+        public Item id(String id) {
+            this.id = id;
+            return this;
         }
 
         public BytesReference doc() {
             return doc;
         }
 
+        /**
+         * Sets to a given artificial document, that is a document that is not present in the index.
+         */
+        public Item doc(BytesReference doc) {
+            this.doc = doc;
+            return this;
+        }
+
+        /**
+         * Sets to a given artificial document, that is a document that is not present in the index.
+         */
         public Item doc(XContentBuilder doc) {
-            this.doc = doc.bytes();
+            return this.doc(doc.bytes());
+        }
+
+        public String[] fields() {
+            return fields;
+        }
+
+        public Item fields(String... fields) {
+            this.fields = fields;
+            return this;
+        }
+
+        public Map<String, String> perFieldAnalyzer() {
+            return perFieldAnalyzer;
+        }
+
+        /**
+         * Sets the analyzer(s) to use at any given field.
+         */
+        public Item perFieldAnalyzer(Map<String, String> perFieldAnalyzer) {
+            this.perFieldAnalyzer = perFieldAnalyzer;
             return this;
         }
 
+        public String routing() {
+            return routing;
+        }
+
+        public Item routing(String routing) {
+            this.routing = routing;
+            return this;
+        }
+
+        public long version() {
+            return version;
+        }
+
+        public Item version(long version) {
+            this.version = version;
+            return this;
+        }
+
+        public VersionType versionType() {
+            return versionType;
+        }
+
+        public Item versionType(VersionType versionType) {
+            this.versionType = versionType;
+            return this;
+        }
+
+        /**
+         * Convert this to a {@link TermVectorsRequest} for fetching the terms of the document.
+         */
+        public TermVectorsRequest toTermVectorsRequest() {
+            TermVectorsRequest termVectorsRequest = new TermVectorsRequest(index, type, id)
+                    .selectedFields(fields)
+                    .routing(routing)
+                    .version(version)
+                    .versionType(versionType)
+                    .perFieldAnalyzer(perFieldAnalyzer)
+                    .positions(false)  // ensures these following parameters are never set
+                    .offsets(false)
+                    .payloads(false)
+                    .fieldStatistics(false)
+                    .termStatistics(false)
+                    .dfs(false);
+            // for artificial docs to make sure that the id has changed in the item too
+            if (doc != null) {
+                termVectorsRequest.doc(doc, true);
+                this.id(termVectorsRequest.id());
+            }
+            return termVectorsRequest;
+        }
+
+        /**
+         * Parses and returns the given item.
+         */
+        public static Item parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, Item item) throws IOException {
+            XContentParser.Token token;
+            String currentFieldName = null;
+            while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
+                if (token == XContentParser.Token.FIELD_NAME) {
+                    currentFieldName = parser.currentName();
+                } else if (currentFieldName != null) {
+                    if (parseFieldMatcher.match(currentFieldName, Field.INDEX)) {
+                        item.index = parser.text();
+                    } else if (parseFieldMatcher.match(currentFieldName, Field.TYPE)) {
+                        item.type = parser.text();
+                    } else if (parseFieldMatcher.match(currentFieldName, Field.ID)) {
+                        item.id = parser.text();
+                    } else if (parseFieldMatcher.match(currentFieldName, Field.DOC)) {
+                        item.doc(jsonBuilder().copyCurrentStructure(parser));
+                    } else if (parseFieldMatcher.match(currentFieldName, Field.FIELDS)) {
+                        if (token == XContentParser.Token.START_ARRAY) {
+                            List<String> fields = new ArrayList<>();
+                            while (parser.nextToken() != XContentParser.Token.END_ARRAY) {
+                                fields.add(parser.text());
+                            }
+                            item.fields(fields.toArray(new String[fields.size()]));
+                        } else {
+                            throw new ElasticsearchParseException(
+                                    "failed to parse More Like This item. field [fields] must be an array");
+                        }
+                    } else if (parseFieldMatcher.match(currentFieldName, Field.PER_FIELD_ANALYZER)) {
+                        item.perFieldAnalyzer(TermVectorsRequest.readPerFieldAnalyzer(parser.map()));
+                    } else if ("_routing".equals(currentFieldName) || "routing".equals(currentFieldName)) {
+                        item.routing = parser.text();
+                    } else if ("_version".equals(currentFieldName) || "version".equals(currentFieldName)) {
+                        item.version = parser.longValue();
+                    } else if ("_version_type".equals(currentFieldName) || "_versionType".equals(currentFieldName)
+                            || "version_type".equals(currentFieldName) || "versionType".equals(currentFieldName)) {
+                        item.versionType = VersionType.fromString(parser.text());
+                    } else {
+                        throw new ElasticsearchParseException(
+                                "failed to parse More Like This item. unknown field [{}]", currentFieldName);
+                    }
+                }
+            }
+            if (item.id != null && item.doc != null) {
+                throw new ElasticsearchParseException(
+                        "failed to parse More Like This item. either [id] or [doc] can be specified, but not both!");
+            }
+            return item;
+        }
+
         @Override
         public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-            if (this.likeText != null) {
-                return builder.value(this.likeText);
-            }
             builder.startObject();
-            if (this.index() != null) {
-                builder.field("_index", this.index());
+            if (this.index != null) {
+                builder.field(Field.INDEX.getPreferredName(), this.index);
             }
-            if (this.type() != null) {
-                builder.field("_type", this.type());
+            if (this.type != null) {
+                builder.field(Field.TYPE.getPreferredName(), this.type);
             }
-            if (this.id() != null) {
-                builder.field("_id", this.id());
+            if (this.id != null && this.doc == null) {
+                builder.field(Field.ID.getPreferredName(), this.id);
             }
-            if (this.doc() != null) {
-                XContentType contentType = XContentFactory.xContentType(doc);
+            if (this.doc != null) {
+                XContentType contentType = XContentFactory.xContentType(this.doc);
                 if (contentType == builder.contentType()) {
-                    builder.rawField("doc", doc);
+                    builder.rawField(Field.DOC.getPreferredName(), this.doc);
                 } else {
-                    XContentParser parser = XContentFactory.xContent(contentType).createParser(doc);
+                    XContentParser parser = XContentFactory.xContent(contentType).createParser(this.doc);
                     parser.nextToken();
-                    builder.field("doc");
+                    builder.field(Field.DOC.getPreferredName());
                     builder.copyCurrentStructure(parser);
                 }
             }
-            if (this.fields() != null) {
-                builder.array("fields", this.fields());
+            if (this.fields != null) {
+                builder.array(Field.FIELDS.getPreferredName(), this.fields);
             }
-            if (this.routing() != null) {
-                builder.field("_routing", this.routing());
+            if (this.perFieldAnalyzer != null) {
+                builder.field(Field.PER_FIELD_ANALYZER.getPreferredName(), this.perFieldAnalyzer);
             }
-            if (this.fetchSourceContext() != null) {
-                FetchSourceContext source = this.fetchSourceContext();
-                String[] includes = source.includes();
-                String[] excludes = source.excludes();
-                if (includes.length == 0 && excludes.length == 0) {
-                    builder.field("_source", source.fetchSource());
-                } else if (includes.length > 0 && excludes.length == 0) {
-                    builder.array("_source", source.includes());
-                } else if (excludes.length > 0) {
-                    builder.startObject("_source");
-                    if (includes.length > 0) {
-                        builder.array("includes", source.includes());
-                    }
-                    builder.array("excludes", source.excludes());
-                    builder.endObject();
-                }
+            if (this.routing != null) {
+                builder.field(Field.ROUTING.getPreferredName(), this.routing);
             }
-            if (this.version() != Versions.MATCH_ANY) {
-                builder.field("_version", this.version());
+            if (this.version != Versions.MATCH_ANY) {
+                builder.field(Field.VERSION.getPreferredName(), this.version);
             }
-            if (this.versionType() != VersionType.INTERNAL) {
-                builder.field("_version_type", this.versionType().toString().toLowerCase(Locale.ROOT));
+            if (this.versionType != VersionType.INTERNAL) {
+                builder.field(Field.VERSION_TYPE.getPreferredName(), this.versionType.toString().toLowerCase(Locale.ROOT));
             }
             return builder.endObject();
         }
-    }
 
-    public static final String NAME = "mlt";
+        @Override
+        public final String toString() {
+            try {
+                XContentBuilder builder = XContentFactory.jsonBuilder();
+                builder.prettyPrint();
+                toXContent(builder, EMPTY_PARAMS);
+                return builder.string();
+            } catch (Exception e) {
+                return "{ \"error\" : \"" + ExceptionsHelper.detailedMessage(e) + "\"}";
+            }
+        }
+
+        @Override
+        public int hashCode() {
+            return Objects.hash(index, type, id, doc, Arrays.hashCode(fields), perFieldAnalyzer, routing,
+                    version, versionType);
+        }
+
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) return true;
+            if (!(o instanceof Item)) return false;
+            Item other = (Item) o;
+            return Objects.equals(index, other.index) &&
+                    Objects.equals(type, other.type) &&
+                    Objects.equals(id, other.id) &&
+                    Objects.equals(doc, other.doc) &&
+                    Arrays.equals(fields, other.fields) &&  // otherwise we are comparing pointers
+                    Objects.equals(perFieldAnalyzer, other.perFieldAnalyzer) &&
+                    Objects.equals(routing, other.routing) &&
+                    Objects.equals(version, other.version) &&
+                    Objects.equals(versionType, other.versionType);
+        }
+    }
 
+    // document inputs
+    private List<String> likeTexts = new ArrayList<>();
+    private List<String> unlikeTexts = new ArrayList<>();
+    private List<Item> likeItems = new ArrayList<>();
+    private List<Item> unlikeItems = new ArrayList<>();
     private final String[] fields;
-    private List<Item> docs = new ArrayList<>();
-    private List<Item> unlikeDocs = new ArrayList<>();
-    private Boolean include = null;
-    private String minimumShouldMatch = null;
-    private int minTermFreq = -1;
+
+    // term selection parameters
     private int maxQueryTerms = -1;
-    private String[] stopWords = null;
+    private int minTermFreq = -1;
     private int minDocFreq = -1;
     private int maxDocFreq = -1;
     private int minWordLength = -1;
     private int maxWordLength = -1;
-    private float boostTerms = -1;
+    private String[] stopWords = null;
     private String analyzer;
-    private Boolean failOnUnsupportedField;
 
-    static final MoreLikeThisQueryBuilder PROTOTYPE = new MoreLikeThisQueryBuilder();
+    // query formation parameters
+    private String minimumShouldMatch = null;
+    private float boostTerms = -1;
+    private Boolean include = null;
+
+    // other parameters
+    private Boolean failOnUnsupportedField;
+    private float boost = -1;
+    private String queryName;
 
     /**
      * Constructs a new more like this query which uses the "_all" field.
@@ -169,107 +389,70 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
     }
 
     /**
-     * Sets the documents to use in order to find documents that are "like" this.
-     *
-     * @param docs the documents to use when generating the 'More Like This' query.
-     */
-    public MoreLikeThisQueryBuilder like(Item... docs) {
-        this.docs = Arrays.asList(docs);
-        return this;
-    }
-
-    /**
      * Sets the text to use in order to find documents that are "like" this.
      *
-     * @param likeText the text to use when generating the 'More Like This' query.
+     * @param likeTexts the text to use when generating the 'More Like This' query.
      */
-    public MoreLikeThisQueryBuilder like(String... likeText) {
-        this.docs = new ArrayList<>();
-        for (String text : likeText) {
-            this.docs.add(new Item(text));
-        }
-        return this;
+    public MoreLikeThisQueryBuilder like(String... likeTexts) {
+        this.likeTexts = new ArrayList<>();
+        return addLikeText(likeTexts);
     }
 
     /**
-     * Sets the documents from which the terms should not be selected from.
+     * Sets the documents to use in order to find documents that are "like" this.
+     *
+     * @param likeItems the documents to use when generating the 'More Like This' query.
      */
-    public MoreLikeThisQueryBuilder ignoreLike(Item... docs) {
-        this.unlikeDocs = Arrays.asList(docs);
-        return this;
+    public MoreLikeThisQueryBuilder like(Item... likeItems) {
+        this.likeItems = new ArrayList<>();
+        return addLikeItem(likeItems);
     }
 
     /**
-     * Sets the text from which the terms should not be selected from.
+     * Adds some text to use in order to find documents that are "like" this.
      */
-    public MoreLikeThisQueryBuilder ignoreLike(String... likeText) {
-        this.unlikeDocs = new ArrayList<>();
-        for (String text : likeText) {
-            this.unlikeDocs.add(new Item(text));
-        }
+    public MoreLikeThisQueryBuilder addLikeText(String... likeTexts) {
+        Collections.addAll(this.likeTexts, likeTexts);
         return this;
     }
 
     /**
      * Adds a document to use in order to find documents that are "like" this.
      */
-    public MoreLikeThisQueryBuilder addItem(Item item) {
-        this.docs.add(item);
+    public MoreLikeThisQueryBuilder addLikeItem(Item... likeItems) {
+        Collections.addAll(this.likeItems, likeItems);
         return this;
     }
 
     /**
-     * Adds some text to use in order to find documents that are "like" this.
+     * Sets the text from which the terms should not be selected from.
      */
-    public MoreLikeThisQueryBuilder addLikeText(String likeText) {
-        this.docs.add(new Item(likeText));
-        return this;
+    public MoreLikeThisQueryBuilder unlike(String... unlikeTexts) {
+        this.unlikeTexts = new ArrayList<>();
+        return addUnlikeText(unlikeTexts);
     }
 
     /**
-     * The text to use in order to find documents that are "like" this.
+     * Sets the documents from which the terms should not be selected from.
      */
-    @Deprecated
-    public MoreLikeThisQueryBuilder likeText(String likeText) {
-        return like(likeText);
-    }
-
-    @Deprecated
-    public MoreLikeThisQueryBuilder ids(String... ids) {
-        Item[] items = new Item[ids.length];
-        for (int i = 0; i < items.length; i++) {
-            items[i] = new Item(null, null, ids[i]);
-        }
-        return like(items);
-    }
-
-    @Deprecated
-    public MoreLikeThisQueryBuilder docs(Item... docs) {
-        return like(docs);
-    }
-
-    public MoreLikeThisQueryBuilder include(boolean include) {
-        this.include = include;
-        return this;
+    public MoreLikeThisQueryBuilder unlike(Item... unlikeItems) {
+        this.unlikeItems = new ArrayList<>();
+        return addUnlikeItem(unlikeItems);
     }
 
     /**
-     * Number of terms that must match the generated query expressed in the
-     * common syntax for minimum should match. Defaults to <tt>30%</tt>.
-     *
-     * @see    org.elasticsearch.common.lucene.search.Queries#calculateMinShouldMatch(int, String)
+     * Adds some text to use in order to find documents that are "unlike" this.
      */
-    public MoreLikeThisQueryBuilder minimumShouldMatch(String minimumShouldMatch) {
-        this.minimumShouldMatch = minimumShouldMatch;
+    public MoreLikeThisQueryBuilder addUnlikeText(String... unlikeTexts) {
+        Collections.addAll(this.unlikeTexts, unlikeTexts);
         return this;
     }
 
     /**
-     * The frequency below which terms will be ignored in the source doc. The default
-     * frequency is <tt>2</tt>.
+     * Adds a document to use in order to find documents that are "unlike" this.
      */
-    public MoreLikeThisQueryBuilder minTermFreq(int minTermFreq) {
-        this.minTermFreq = minTermFreq;
+    public MoreLikeThisQueryBuilder addUnlikeItem(Item... unlikeItems) {
+        Collections.addAll(this.unlikeItems, unlikeItems);
         return this;
     }
 
@@ -283,14 +466,11 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
     }
 
     /**
-     * Set the set of stopwords.
-     * <p/>
-     * <p>Any word in this set is considered "uninteresting" and ignored. Even if your Analyzer allows stopwords, you
-     * might want to tell the MoreLikeThis code to ignore them, as for the purposes of document similarity it seems
-     * reasonable to assume that "a stop word is never interesting".
+     * The frequency below which terms will be ignored in the source doc. The default
+     * frequency is <tt>2</tt>.
      */
-    public MoreLikeThisQueryBuilder stopWords(String... stopWords) {
-        this.stopWords = stopWords;
+    public MoreLikeThisQueryBuilder minTermFreq(int minTermFreq) {
+        this.minTermFreq = minTermFreq;
         return this;
     }
 
@@ -331,10 +511,14 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
     }
 
     /**
-     * Sets the boost factor to use when boosting terms. Defaults to <tt>1</tt>.
+     * Set the set of stopwords.
+     * <p/>
+     * <p>Any word in this set is considered "uninteresting" and ignored. Even if your Analyzer allows stopwords, you
+     * might want to tell the MoreLikeThis code to ignore them, as for the purposes of document similarity it seems
+     * reasonable to assume that "a stop word is never interesting".
      */
-    public MoreLikeThisQueryBuilder boostTerms(float boostTerms) {
-        this.boostTerms = boostTerms;
+    public MoreLikeThisQueryBuilder stopWords(String... stopWords) {
+        this.stopWords = stopWords;
         return this;
     }
 
@@ -347,6 +531,33 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
     }
 
     /**
+     * Number of terms that must match the generated query expressed in the
+     * common syntax for minimum should match. Defaults to <tt>30%</tt>.
+     *
+     * @see    org.elasticsearch.common.lucene.search.Queries#calculateMinShouldMatch(int, String)
+     */
+    public MoreLikeThisQueryBuilder minimumShouldMatch(String minimumShouldMatch) {
+        this.minimumShouldMatch = minimumShouldMatch;
+        return this;
+    }
+
+    /**
+     * Sets the boost factor to use when boosting terms. Defaults to <tt>1</tt>.
+     */
+    public MoreLikeThisQueryBuilder boostTerms(float boostTerms) {
+        this.boostTerms = boostTerms;
+        return this;
+    }
+
+    /**
+     * Whether to include the input documents. Defaults to <tt>false</tt>
+     */
+    public MoreLikeThisQueryBuilder include(boolean include) {
+        this.include = include;
+        return this;
+    }
+
+    /**
      * Whether to fail or return no result when this query is run against a field which is not supported such as binary/numeric fields.
      */
     public MoreLikeThisQueryBuilder failOnUnsupportedField(boolean fail) {
@@ -355,70 +566,136 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
     }
 
     @Override
+    public MoreLikeThisQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public MoreLikeThisQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
+    /**
+     * The text to use in order to find documents that are "like" this.
+     */
+    @Deprecated
+    public MoreLikeThisQueryBuilder likeText(String likeText) {
+        return like(likeText);
+    }
+
+    @Deprecated
+    public MoreLikeThisQueryBuilder ids(String... ids) {
+        Item[] items = new Item[ids.length];
+        for (int i = 0; i < items.length; i++) {
+            items[i] = new Item(null, null, ids[i]);
+        }
+        return like(items);
+    }
+
+    @Deprecated
+    public MoreLikeThisQueryBuilder docs(Item... docs) {
+        return like(docs);
+    }
+
+    /**
+     * Sets the documents from which the terms should not be selected from.
+     *
+     * @Deprecated Use {@link #unlike(Item...)} instead
+     */
+    @Deprecated
+    public MoreLikeThisQueryBuilder ignoreLike(Item... docs) {
+        return unlike(docs);
+    }
+
+    /**
+     * Sets the text from which the terms should not be selected from.
+     *
+     * @Deprecated Use {@link #unlike(String...)} instead.
+     */
+    @Deprecated
+    public MoreLikeThisQueryBuilder ignoreLike(String... likeText) {
+        return unlike(likeText);
+    }
+
+    /**
+     * Adds a document to use in order to find documents that are "like" this.
+     */
+    @Deprecated
+    public MoreLikeThisQueryBuilder addItem(Item... likeItems) {
+        return addLikeItem(likeItems);
+    }
+
+    @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        String likeFieldName = MoreLikeThisQueryParser.Fields.LIKE.getPreferredName();
-        builder.startObject(NAME);
+        builder.startObject(MoreLikeThisQueryParser.NAME);
         if (fields != null) {
-            builder.startArray("fields");
-            for (String field : fields) {
-                builder.value(field);
-            }
-            builder.endArray();
+            builder.field(MoreLikeThisQueryParser.Field.FIELDS.getPreferredName(), fields);
         }
-        if (this.docs.isEmpty()) {
-            throw new IllegalArgumentException("more_like_this requires '" + likeFieldName + "' to be provided");
+        if (this.likeTexts.isEmpty() && this.likeItems.isEmpty()) {
+            throw new IllegalArgumentException("more_like_this requires '" + MoreLikeThisQueryParser.Field.LIKE.getPreferredName() + "' to be provided");
         } else {
-            builder.field(likeFieldName, docs);
+            buildLikeField(builder, MoreLikeThisQueryParser.Field.LIKE.getPreferredName(), likeTexts, likeItems);
         }
-        if (!unlikeDocs.isEmpty()) {
-            builder.field(MoreLikeThisQueryParser.Fields.UNLIKE.getPreferredName(), unlikeDocs);
-        }
-        if (minimumShouldMatch != null) {
-            builder.field(MoreLikeThisQueryParser.Fields.MINIMUM_SHOULD_MATCH.getPreferredName(), minimumShouldMatch);
-        }
-        if (minTermFreq != -1) {
-            builder.field(MoreLikeThisQueryParser.Fields.MIN_TERM_FREQ.getPreferredName(), minTermFreq);
+        if (!unlikeTexts.isEmpty() || !unlikeItems.isEmpty()) {
+            buildLikeField(builder, MoreLikeThisQueryParser.Field.UNLIKE.getPreferredName(), unlikeTexts, unlikeItems);
         }
         if (maxQueryTerms != -1) {
-            builder.field(MoreLikeThisQueryParser.Fields.MAX_QUERY_TERMS.getPreferredName(), maxQueryTerms);
+            builder.field(MoreLikeThisQueryParser.Field.MAX_QUERY_TERMS.getPreferredName(), maxQueryTerms);
         }
-        if (stopWords != null && stopWords.length > 0) {
-            builder.startArray(MoreLikeThisQueryParser.Fields.STOP_WORDS.getPreferredName());
-            for (String stopWord : stopWords) {
-                builder.value(stopWord);
-            }
-            builder.endArray();
+        if (minTermFreq != -1) {
+            builder.field(MoreLikeThisQueryParser.Field.MIN_TERM_FREQ.getPreferredName(), minTermFreq);
         }
         if (minDocFreq != -1) {
-            builder.field(MoreLikeThisQueryParser.Fields.MIN_DOC_FREQ.getPreferredName(), minDocFreq);
+            builder.field(MoreLikeThisQueryParser.Field.MIN_DOC_FREQ.getPreferredName(), minDocFreq);
         }
         if (maxDocFreq != -1) {
-            builder.field(MoreLikeThisQueryParser.Fields.MAX_DOC_FREQ.getPreferredName(), maxDocFreq);
+            builder.field(MoreLikeThisQueryParser.Field.MAX_DOC_FREQ.getPreferredName(), maxDocFreq);
         }
         if (minWordLength != -1) {
-            builder.field(MoreLikeThisQueryParser.Fields.MIN_WORD_LENGTH.getPreferredName(), minWordLength);
+            builder.field(MoreLikeThisQueryParser.Field.MIN_WORD_LENGTH.getPreferredName(), minWordLength);
         }
         if (maxWordLength != -1) {
-            builder.field(MoreLikeThisQueryParser.Fields.MAX_WORD_LENGTH.getPreferredName(), maxWordLength);
+            builder.field(MoreLikeThisQueryParser.Field.MAX_WORD_LENGTH.getPreferredName(), maxWordLength);
         }
-        if (boostTerms != -1) {
-            builder.field(MoreLikeThisQueryParser.Fields.BOOST_TERMS.getPreferredName(), boostTerms);
+        if (stopWords != null && stopWords.length > 0) {
+            builder.field(MoreLikeThisQueryParser.Field.STOP_WORDS.getPreferredName(), stopWords);
         }
         if (analyzer != null) {
-            builder.field("analyzer", analyzer);
+            builder.field(MoreLikeThisQueryParser.Field.ANALYZER.getPreferredName(), analyzer);
         }
-        if (failOnUnsupportedField != null) {
-            builder.field(MoreLikeThisQueryParser.Fields.FAIL_ON_UNSUPPORTED_FIELD.getPreferredName(), failOnUnsupportedField);
+        if (minimumShouldMatch != null) {
+            builder.field(MoreLikeThisQueryParser.Field.MINIMUM_SHOULD_MATCH.getPreferredName(), minimumShouldMatch);
+        }
+        if (boostTerms != -1) {
+            builder.field(MoreLikeThisQueryParser.Field.BOOST_TERMS.getPreferredName(), boostTerms);
         }
         if (include != null) {
-            builder.field("include", include);
+            builder.field(MoreLikeThisQueryParser.Field.INCLUDE.getPreferredName(), include);
+        }
+        if (failOnUnsupportedField != null) {
+            builder.field(MoreLikeThisQueryParser.Field.FAIL_ON_UNSUPPORTED_FIELD.getPreferredName(), failOnUnsupportedField);
+        }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+    private static void buildLikeField(XContentBuilder builder, String fieldName, List<String> texts, List<Item> items) throws IOException {
+        builder.startArray(fieldName);
+        for (String text : texts) {
+            builder.value(text);
+        }
+        for (Item item : items) {
+            builder.value(item);
+        }
+        builder.endArray();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
index 2620c63..ff39031 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
@@ -20,16 +20,13 @@
 package org.elasticsearch.index.query;
 
 import com.google.common.collect.Sets;
-
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.queries.TermsQuery;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.action.termvectors.MultiTermVectorsRequest;
 import org.elasticsearch.action.termvectors.MultiTermVectorsResponse;
-import org.elasticsearch.action.termvectors.TermVectorsRequest;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.Strings;
@@ -39,43 +36,44 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.analysis.Analysis;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
+import org.elasticsearch.index.query.MoreLikeThisQueryBuilder.Item;
 import org.elasticsearch.index.search.morelikethis.MoreLikeThisFetchService;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Set;
+import java.util.*;
 
 import static org.elasticsearch.index.mapper.Uid.createUidAsBytes;
 
 /**
+ * Parser for the The More Like This Query (MLT Query) which finds documents that are "like" a given set of documents.
  *
+ * The documents are provided as a set of strings and/or a list of {@link Item}.
  */
-public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
+public class MoreLikeThisQueryParser implements QueryParser {
 
+    public static final String NAME = "mlt";
     private MoreLikeThisFetchService fetchService = null;
 
-    public static class Fields {
-        public static final ParseField LIKE_TEXT = new ParseField("like_text").withAllDeprecated("like");
-        public static final ParseField MIN_TERM_FREQ = new ParseField("min_term_freq");
-        public static final ParseField MAX_QUERY_TERMS = new ParseField("max_query_terms");
-        public static final ParseField MIN_WORD_LENGTH = new ParseField("min_word_length", "min_word_len");
-        public static final ParseField MAX_WORD_LENGTH = new ParseField("max_word_length", "max_word_len");
-        public static final ParseField MIN_DOC_FREQ = new ParseField("min_doc_freq");
-        public static final ParseField MAX_DOC_FREQ = new ParseField("max_doc_freq");
-        public static final ParseField BOOST_TERMS = new ParseField("boost_terms");
-        public static final ParseField MINIMUM_SHOULD_MATCH = new ParseField("minimum_should_match");
-        public static final ParseField FAIL_ON_UNSUPPORTED_FIELD = new ParseField("fail_on_unsupported_field");
-        public static final ParseField STOP_WORDS = new ParseField("stop_words");
-        public static final ParseField DOCUMENT_IDS = new ParseField("ids").withAllDeprecated("like");
-        public static final ParseField DOCUMENTS = new ParseField("docs").withAllDeprecated("like");
-        public static final ParseField LIKE = new ParseField("like");
-        public static final ParseField UNLIKE = new ParseField("unlike");
-        public static final ParseField INCLUDE = new ParseField("include");
+    public interface Field {
+        ParseField FIELDS = new ParseField("fields");
+        ParseField LIKE = new ParseField("like");
+        ParseField UNLIKE = new ParseField("unlike");
+        ParseField LIKE_TEXT = new ParseField("like_text").withAllDeprecated("like");
+        ParseField IDS = new ParseField("ids").withAllDeprecated("like");
+        ParseField DOCS = new ParseField("docs").withAllDeprecated("like");
+        ParseField MAX_QUERY_TERMS = new ParseField("max_query_terms");
+        ParseField MIN_TERM_FREQ = new ParseField("min_term_freq");
+        ParseField MIN_DOC_FREQ = new ParseField("min_doc_freq");
+        ParseField MAX_DOC_FREQ = new ParseField("max_doc_freq");
+        ParseField MIN_WORD_LENGTH = new ParseField("min_word_length", "min_word_len");
+        ParseField MAX_WORD_LENGTH = new ParseField("max_word_length", "max_word_len");
+        ParseField STOP_WORDS = new ParseField("stop_words");
+        ParseField ANALYZER = new ParseField("analyzer");
+        ParseField MINIMUM_SHOULD_MATCH = new ParseField("minimum_should_match");
+        ParseField BOOST_TERMS = new ParseField("boost_terms");
+        ParseField INCLUDE = new ParseField("include");
+        ParseField FAIL_ON_UNSUPPORTED_FIELD = new ParseField("fail_on_unsupported_field");
     }
 
     public MoreLikeThisQueryParser() {
@@ -89,119 +87,117 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{MoreLikeThisQueryBuilder.NAME, "more_like_this", "moreLikeThis"};
+        return new String[]{NAME, "more_like_this", "moreLikeThis"};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         MoreLikeThisQuery mltQuery = new MoreLikeThisQuery();
-        mltQuery.setSimilarity(context.searchSimilarity());
-        Analyzer analyzer = null;
+        mltQuery.setSimilarity(parseContext.searchSimilarity());
+
+        List<String> likeTexts = new ArrayList<>();
+        List<String> unlikeTexts = new ArrayList<>();
+        List<Item> likeItems = new ArrayList<>();
+        List<Item> unlikeItems = new ArrayList<>();
+
         List<String> moreLikeFields = null;
+        Analyzer analyzer = null;
+        boolean include = false;
+
         boolean failOnUnsupportedField = true;
         String queryName = null;
-        boolean include = false;
 
         XContentParser.Token token;
         String currentFieldName = null;
-
-        List<String> likeTexts = new ArrayList<>();
-        MultiTermVectorsRequest likeItems = new MultiTermVectorsRequest();
-
-        List<String> unlikeTexts = new ArrayList<>();
-        MultiTermVectorsRequest unlikeItems = new MultiTermVectorsRequest();
-
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if (token.isValue()) {
-                if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.LIKE_TEXT)) {
+                if (parseContext.parseFieldMatcher().match(currentFieldName, Field.LIKE)) {
+                    parseLikeField(parseContext, likeTexts, likeItems);
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.UNLIKE)) {
+                    parseLikeField(parseContext, unlikeTexts, unlikeItems);
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.LIKE_TEXT)) {
                     likeTexts.add(parser.text());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.LIKE)) {
-                    parseLikeField(parser, likeTexts, likeItems);
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.UNLIKE)) {
-                    parseLikeField(parser, unlikeTexts, unlikeItems);
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.MIN_TERM_FREQ)) {
-                    mltQuery.setMinTermFrequency(parser.intValue());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.MAX_QUERY_TERMS)) {
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.MAX_QUERY_TERMS)) {
                     mltQuery.setMaxQueryTerms(parser.intValue());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.MIN_DOC_FREQ)) {
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.MIN_TERM_FREQ)) {
+                    mltQuery.setMinTermFrequency(parser.intValue());
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.MIN_DOC_FREQ)) {
                     mltQuery.setMinDocFreq(parser.intValue());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.MAX_DOC_FREQ)) {
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.MAX_DOC_FREQ)) {
                     mltQuery.setMaxDocFreq(parser.intValue());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.MIN_WORD_LENGTH)) {
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.MIN_WORD_LENGTH)) {
                     mltQuery.setMinWordLen(parser.intValue());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.MAX_WORD_LENGTH)) {
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.MAX_WORD_LENGTH)) {
                     mltQuery.setMaxWordLen(parser.intValue());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.BOOST_TERMS)) {
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.ANALYZER)) {
+                    analyzer = parseContext.analysisService().analyzer(parser.text());
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.MINIMUM_SHOULD_MATCH)) {
+                    mltQuery.setMinimumShouldMatch(parser.text());
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.BOOST_TERMS)) {
                     float boostFactor = parser.floatValue();
                     if (boostFactor != 0) {
                         mltQuery.setBoostTerms(true);
                         mltQuery.setBoostTermsFactor(boostFactor);
                     }
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.MINIMUM_SHOULD_MATCH)) {
-                    mltQuery.setMinimumShouldMatch(parser.text());
-                } else if ("analyzer".equals(currentFieldName)) {
-                    analyzer = context.analysisService().analyzer(parser.text());
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.INCLUDE)) {
+                    include = parser.booleanValue();
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.FAIL_ON_UNSUPPORTED_FIELD)) {
+                    failOnUnsupportedField = parser.booleanValue();
                 } else if ("boost".equals(currentFieldName)) {
                     mltQuery.setBoost(parser.floatValue());
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.FAIL_ON_UNSUPPORTED_FIELD)) {
-                    failOnUnsupportedField = parser.booleanValue();
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.INCLUDE)) {
-                    include = parser.booleanValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[mlt] query does not support [" + currentFieldName + "]");
                 }
             } else if (token == XContentParser.Token.START_ARRAY) {
-                if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.STOP_WORDS)) {
-                    Set<String> stopWords = Sets.newHashSet();
-                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        stopWords.add(parser.text());
-                    }
-                    mltQuery.setStopWords(stopWords);
-                } else if ("fields".equals(currentFieldName)) {
+                if (parseContext.parseFieldMatcher().match(currentFieldName, Field.FIELDS)) {
                     moreLikeFields = new LinkedList<>();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         String field = parser.text();
-                        MappedFieldType fieldType = context.fieldMapper(field);
+                        MappedFieldType fieldType = parseContext.fieldMapper(field);
                         moreLikeFields.add(fieldType == null ? field : fieldType.names().indexName());
                     }
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.DOCUMENT_IDS)) {
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.LIKE)) {
+                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
+                        parseLikeField(parseContext, likeTexts, likeItems);
+                    }
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.UNLIKE)) {
+                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
+                        parseLikeField(parseContext, unlikeTexts, unlikeItems);
+                    }
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.IDS)) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         if (!token.isValue()) {
                             throw new IllegalArgumentException("ids array element should only contain ids");
                         }
-                        likeItems.add(newTermVectorsRequest().id(parser.text()));
+                        likeItems.add(new Item(null, null, parser.text()));
                     }
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.DOCUMENTS)) {
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.DOCS)) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                         if (token != XContentParser.Token.START_OBJECT) {
                             throw new IllegalArgumentException("docs array element should include an object");
                         }
-                        likeItems.add(parseDocument(parser));
-                    }
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.LIKE)) {
-                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        parseLikeField(parser, likeTexts, likeItems);
+                        likeItems.add(Item.parse(parser, parseContext.parseFieldMatcher(), new Item()));
                     }
-                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.UNLIKE)) {
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.STOP_WORDS)) {
+                    Set<String> stopWords = Sets.newHashSet();
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        parseLikeField(parser, unlikeTexts, unlikeItems);
+                        stopWords.add(parser.text());
                     }
+                    mltQuery.setStopWords(stopWords);
                 } else {
                     throw new QueryParsingException(parseContext, "[mlt] query does not support [" + currentFieldName + "]");
                 }
             } else if (token == XContentParser.Token.START_OBJECT) {
-                if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.LIKE)) {
-                    parseLikeField(parser, likeTexts, likeItems);
-                }
-                else if (parseContext.parseFieldMatcher().match(currentFieldName, Fields.UNLIKE)) {
-                    parseLikeField(parser, unlikeTexts, unlikeItems);
+                if (parseContext.parseFieldMatcher().match(currentFieldName, Field.LIKE)) {
+                    parseLikeField(parseContext, likeTexts, likeItems);
+                } else if (parseContext.parseFieldMatcher().match(currentFieldName, Field.UNLIKE)) {
+                    parseLikeField(parseContext, unlikeTexts, unlikeItems);
                 } else {
                     throw new QueryParsingException(parseContext, "[mlt] query does not support [" + currentFieldName + "]");
                 }
@@ -217,15 +213,16 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
 
         // set analyzer
         if (analyzer == null) {
-            analyzer = context.mapperService().searchAnalyzer();
+            analyzer = parseContext.mapperService().searchAnalyzer();
         }
         mltQuery.setAnalyzer(analyzer);
 
         // set like text fields
         boolean useDefaultField = (moreLikeFields == null);
         if (useDefaultField) {
-            moreLikeFields = Collections.singletonList(context.defaultField());
+            moreLikeFields = Collections.singletonList(parseContext.defaultField());
         }
+
         // possibly remove unsupported fields
         removeUnsupportedFields(moreLikeFields, analyzer, failOnUnsupportedField);
         if (moreLikeFields.isEmpty()) {
@@ -235,7 +232,7 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
 
         // support for named query
         if (queryName != null) {
-            context.addNamedQuery(queryName, mltQuery);
+            parseContext.addNamedQuery(queryName, mltQuery);
         }
 
         // handle like texts
@@ -243,93 +240,29 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
             mltQuery.setLikeText(likeTexts);
         }
         if (!unlikeTexts.isEmpty()) {
-            mltQuery.setIgnoreText(unlikeTexts);
+            mltQuery.setUnlikeText(unlikeTexts);
         }
 
         // handle items
         if (!likeItems.isEmpty()) {
-            // set default index, type and fields if not specified
-            MultiTermVectorsRequest items = likeItems;
-            for (TermVectorsRequest item : unlikeItems) {
-                items.add(item);
-            }
-
-            for (TermVectorsRequest item : items) {
-                if (item.index() == null) {
-                    item.index(context.index().name());
-                }
-                if (item.type() == null) {
-                    if (context.queryTypes().size() > 1) {
-                        throw new QueryParsingException(parseContext,
-                                    "ambiguous type for item with id: " + item.id()
-                                + " and index: " + item.index());
-                    } else {
-                        item.type(context.queryTypes().iterator().next());
-                    }
-                }
-                // default fields if not present but don't override for artificial docs
-                if (item.selectedFields() == null && item.doc() == null) {
-                    if (useDefaultField) {
-                        item.selectedFields("*");
-                    } else {
-                        item.selectedFields(moreLikeFields.toArray(new String[moreLikeFields.size()]));
-                    }
-                }
-            }
-            // fetching the items with multi-termvectors API
-            items.copyContextAndHeadersFrom(SearchContext.current());
-            MultiTermVectorsResponse responses = fetchService.fetchResponse(items);
-
-            // getting the Fields for liked items
-            mltQuery.setLikeText(MoreLikeThisFetchService.getFields(responses, likeItems));
-
-            // getting the Fields for ignored items
-            if (!unlikeItems.isEmpty()) {
-                org.apache.lucene.index.Fields[] ignoreFields = MoreLikeThisFetchService.getFields(responses, unlikeItems);
-                if (ignoreFields.length > 0) {
-                    mltQuery.setUnlikeText(ignoreFields);
-                }
-            }
-
-            BooleanQuery.Builder boolQuery = new BooleanQuery.Builder();
-            boolQuery.add(mltQuery, BooleanClause.Occur.SHOULD);
-
-            // exclude the items from the search
-            if (!include) {
-                handleExclude(boolQuery, likeItems);
-            }
-            return boolQuery.build();
+            return handleItems(parseContext, mltQuery, likeItems, unlikeItems, include, moreLikeFields, useDefaultField);
+        } else {
+            return mltQuery;
         }
-
-        return mltQuery;
-    }
-
-    private TermVectorsRequest parseDocument(XContentParser parser) throws IOException {
-        TermVectorsRequest termVectorsRequest = newTermVectorsRequest();
-        TermVectorsRequest.parseRequest(termVectorsRequest, parser);
-        return termVectorsRequest;
     }
 
-    private void parseLikeField(XContentParser parser, List<String> likeTexts, MultiTermVectorsRequest items) throws IOException {
+    private static void parseLikeField(QueryParseContext parseContext, List<String> texts, List<Item> items) throws IOException {
+        XContentParser parser = parseContext.parser();
         if (parser.currentToken().isValue()) {
-            likeTexts.add(parser.text());
+            texts.add(parser.text());
         } else if (parser.currentToken() == XContentParser.Token.START_OBJECT) {
-            items.add(parseDocument(parser));
+            items.add(Item.parse(parser, parseContext.parseFieldMatcher(), new Item()));
         } else {
             throw new IllegalArgumentException("Content of 'like' parameter should either be a string or an object");
         }
     }
 
-    private TermVectorsRequest newTermVectorsRequest() {
-        return new TermVectorsRequest()
-                .positions(false)
-                .offsets(false)
-                .payloads(false)
-                .fieldStatistics(false)
-                .termStatistics(false);
-    }
-
-    private List<String> removeUnsupportedFields(List<String> moreLikeFields, Analyzer analyzer, boolean failOnUnsupportedField) throws IOException {
+    private static List<String> removeUnsupportedFields(List<String> moreLikeFields, Analyzer analyzer, boolean failOnUnsupportedField) throws IOException {
         for (Iterator<String> it = moreLikeFields.iterator(); it.hasNext(); ) {
             final String fieldName = it.next();
             if (!Analysis.generatesCharacterTokenStream(analyzer, fieldName)) {
@@ -343,10 +276,67 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
         return moreLikeFields;
     }
 
-    private void handleExclude(BooleanQuery.Builder boolQuery, MultiTermVectorsRequest likeItems) {
+    private Query handleItems(QueryParseContext parseContext, MoreLikeThisQuery mltQuery, List<Item> likeItems, List<Item> unlikeItems,
+                              boolean include, List<String> moreLikeFields, boolean useDefaultField) throws IOException {
+        // set default index, type and fields if not specified
+        for (Item item : likeItems) {
+            setDefaultIndexTypeFields(parseContext, item, moreLikeFields, useDefaultField);
+        }
+        for (Item item : unlikeItems) {
+            setDefaultIndexTypeFields(parseContext, item, moreLikeFields, useDefaultField);
+        }
+
+        // fetching the items with multi-termvectors API
+        MultiTermVectorsResponse responses = fetchService.fetchResponse(likeItems, unlikeItems, SearchContext.current());
+
+        // getting the Fields for liked items
+        mltQuery.setLikeText(MoreLikeThisFetchService.getFieldsFor(responses, likeItems));
+
+        // getting the Fields for unliked items
+        if (!unlikeItems.isEmpty()) {
+            org.apache.lucene.index.Fields[] unlikeFields = MoreLikeThisFetchService.getFieldsFor(responses, unlikeItems);
+            if (unlikeFields.length > 0) {
+                mltQuery.setUnlikeText(unlikeFields);
+            }
+        }
+
+        BooleanQuery boolQuery = new BooleanQuery();
+        boolQuery.add(mltQuery, BooleanClause.Occur.SHOULD);
+
+        // exclude the items from the search
+        if (!include) {
+            handleExclude(boolQuery, likeItems);
+        }
+        return boolQuery;
+    }
+
+    private static void setDefaultIndexTypeFields(QueryParseContext parseContext, Item item, List<String> moreLikeFields,
+                                                  boolean useDefaultField) {
+        if (item.index() == null) {
+            item.index(parseContext.index().name());
+        }
+        if (item.type() == null) {
+            if (parseContext.queryTypes().size() > 1) {
+                throw new QueryParsingException(parseContext,
+                            "ambiguous type for item with id: " + item.id() + " and index: " + item.index());
+            } else {
+                item.type(parseContext.queryTypes().iterator().next());
+            }
+        }
+        // default fields if not present but don't override for artificial docs
+        if ((item.fields() == null || item.fields().length == 0) && item.doc() == null) {
+            if (useDefaultField) {
+                item.fields("*");
+            } else {
+                item.fields(moreLikeFields.toArray(new String[moreLikeFields.size()]));
+            }
+        }
+    }
+
+    private static void handleExclude(BooleanQuery boolQuery, List<Item> likeItems) {
         // artificial docs get assigned a random id and should be disregarded
         List<BytesRef> uids = new ArrayList<>();
-        for (TermVectorsRequest item : likeItems) {
+        for (Item item : likeItems) {
             if (item.doc() != null) {
                 continue;
             }
@@ -357,9 +347,4 @@ public class MoreLikeThisQueryParser extends BaseQueryParserTemp {
             boolQuery.add(query, BooleanClause.Occur.MUST_NOT);
         }
     }
-
-    @Override
-    public MoreLikeThisQueryBuilder getBuilderPrototype() {
-        return MoreLikeThisQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java
index e46d2fd..9059865 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.index.query;
 
 import com.carrotsearch.hppc.ObjectFloatHashMap;
-
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.ParseFieldMatcher;
@@ -37,9 +36,7 @@ import java.util.Locale;
 /**
  * Same as {@link MatchQueryBuilder} but supports multiple fields.
  */
-public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQueryBuilder> {
-
-    public static final String NAME = "multi_match";
+public class MultiMatchQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<MultiMatchQueryBuilder> {
 
     private final Object text;
 
@@ -48,10 +45,12 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
 
     private MultiMatchQueryBuilder.Type type;
 
-    private Operator operator;
+    private MatchQueryBuilder.Operator operator;
 
     private String analyzer;
 
+    private Float boost;
+
     private Integer slop;
 
     private Fuzziness fuzziness;
@@ -74,7 +73,8 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
 
     private MatchQueryBuilder.ZeroTermsQuery zeroTermsQuery = null;
 
-    static final MultiMatchQueryBuilder PROTOTYPE = new MultiMatchQueryBuilder(null);
+    private String queryName;
+
 
     public enum Type {
 
@@ -141,7 +141,7 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
                 }
             }
             if (type == null) {
-                throw new ElasticsearchParseException("failed to parse [{}] query type [{}]. unknown type.", NAME, value);
+                throw new ElasticsearchParseException("failed to parse [{}] query type [{}]. unknown type.", MultiMatchQueryParser.NAME, value);
             }
             return type;
         }
@@ -195,7 +195,7 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
     /**
      * Sets the operator to use when using a boolean query. Defaults to <tt>OR</tt>.
      */
-    public MultiMatchQueryBuilder operator(Operator operator) {
+    public MultiMatchQueryBuilder operator(MatchQueryBuilder.Operator operator) {
         this.operator = operator;
         return this;
     }
@@ -210,6 +210,15 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
     }
 
     /**
+     * Set the boost to apply to the query.
+     */
+    @Override
+    public MultiMatchQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
      * Set the phrase slop if evaluated to a phrase query type.
      */
     public MultiMatchQueryBuilder slop(int slop) {
@@ -301,9 +310,17 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
         return this;
     }
 
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public MultiMatchQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(MultiMatchQueryParser.NAME);
 
         builder.field("query", text);
         builder.startArray("fields");
@@ -325,6 +342,9 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
         if (analyzer != null) {
             builder.field("analyzer", analyzer);
         }
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
         if (slop != null) {
             builder.field("slop", slop);
         }
@@ -364,13 +384,11 @@ public class MultiMatchQueryBuilder extends AbstractQueryBuilder<MultiMatchQuery
             builder.field("zero_terms_query", zeroTermsQuery.toString());
         }
 
-        printBoostAndQueryName(builder);
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
 
         builder.endObject();
     }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java
index fcd79d8..5922f52 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MultiMatchQueryParser.java
@@ -21,6 +21,7 @@ package org.elasticsearch.index.query;
 
 import com.google.common.collect.Maps;
 
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.regex.Regex;
@@ -36,7 +37,9 @@ import java.util.Map;
 /**
  * Same as {@link MatchQueryParser} but has support for multiple fields.
  */
-public class MultiMatchQueryParser extends BaseQueryParserTemp {
+public class MultiMatchQueryParser implements QueryParser {
+
+    public static final String NAME = "multi_match";
 
     @Inject
     public MultiMatchQueryParser() {
@@ -45,20 +48,19 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
     @Override
     public String[] names() {
         return new String[]{
-                MultiMatchQueryBuilder.NAME, "multiMatch"
+                NAME, "multiMatch"
         };
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         Float tieBreaker = null;
         MultiMatchQueryBuilder.Type type = null;
-        MultiMatchQuery multiMatchQuery = new MultiMatchQuery(context);
+        MultiMatchQuery multiMatchQuery = new MultiMatchQuery(parseContext);
         String minimumShouldMatch = null;
         Map<String, Float> fieldNameWithBoosts = Maps.newHashMap();
         String queryName = null;
@@ -71,12 +73,12 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
             } else if ("fields".equals(currentFieldName)) {
                 if (token == XContentParser.Token.START_ARRAY) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        extractFieldAndBoost(context, parser, fieldNameWithBoosts);
+                        extractFieldAndBoost(parseContext, parser, fieldNameWithBoosts);
                     }
                 } else if (token.isValue()) {
-                    extractFieldAndBoost(context, parser, fieldNameWithBoosts);
+                    extractFieldAndBoost(parseContext, parser, fieldNameWithBoosts);
                 } else {
-                    throw new QueryParsingException(parseContext, "[" + MultiMatchQueryBuilder.NAME + "] query does not support [" + currentFieldName + "]");
+                    throw new QueryParsingException(parseContext, "[" + NAME + "] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("query".equals(currentFieldName)) {
@@ -85,8 +87,8 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
                     type = MultiMatchQueryBuilder.Type.parse(parser.text(), parseContext.parseFieldMatcher());
                 } else if ("analyzer".equals(currentFieldName)) {
                     String analyzer = parser.text();
-                    if (context.analysisService().analyzer(analyzer) == null) {
-                        throw new QueryParsingException(parseContext, "[" + MultiMatchQueryBuilder.NAME + "] analyzer [" + parser.text() + "] not found");
+                    if (parseContext.analysisService().analyzer(analyzer) == null) {
+                        throw new QueryParsingException(parseContext, "[" + NAME + "] analyzer [" + parser.text() + "] not found");
                     }
                     multiMatchQuery.setAnalyzer(analyzer);
                 } else if ("boost".equals(currentFieldName)) {
@@ -100,7 +102,15 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
                 } else if ("max_expansions".equals(currentFieldName) || "maxExpansions".equals(currentFieldName)) {
                     multiMatchQuery.setMaxExpansions(parser.intValue());
                 } else if ("operator".equals(currentFieldName)) {
-                    multiMatchQuery.setOccur(Operator.fromString(parser.text()).toBooleanClauseOccur());
+                    String op = parser.text();
+                    if ("or".equalsIgnoreCase(op)) {
+                        multiMatchQuery.setOccur(BooleanClause.Occur.SHOULD);
+                    } else if ("and".equalsIgnoreCase(op)) {
+                        multiMatchQuery.setOccur(BooleanClause.Occur.MUST);
+                    } else {
+                        throw new QueryParsingException(parseContext, "text query requires operator to be either 'and' or 'or', not [" + op
+                                + "]");
+                    }
                 } else if ("minimum_should_match".equals(currentFieldName) || "minimumShouldMatch".equals(currentFieldName)) {
                     minimumShouldMatch = parser.textOrNull();
                 } else if ("fuzzy_rewrite".equals(currentFieldName) || "fuzzyRewrite".equals(currentFieldName)) {
@@ -157,12 +167,12 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
 
         query.setBoost(boost);
         if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            parseContext.addNamedQuery(queryName, query);
         }
         return query;
     }
 
-    private void extractFieldAndBoost(QueryShardContext context, XContentParser parser, Map<String, Float> fieldNameWithBoosts) throws IOException {
+    private void extractFieldAndBoost(QueryParseContext parseContext, XContentParser parser, Map<String, Float> fieldNameWithBoosts) throws IOException {
         String fField = null;
         Float fBoost = null;
         char[] fieldText = parser.textCharacters();
@@ -180,16 +190,11 @@ public class MultiMatchQueryParser extends BaseQueryParserTemp {
         }
 
         if (Regex.isSimpleMatchPattern(fField)) {
-            for (String field : context.mapperService().simpleMatchToIndexNames(fField)) {
+            for (String field : parseContext.mapperService().simpleMatchToIndexNames(fField)) {
                 fieldNameWithBoosts.put(field, fBoost);
             }
         } else {
             fieldNameWithBoosts.put(fField, fBoost);
         }
     }
-
-    @Override
-    public MultiMatchQueryBuilder getBuilderPrototype() {
-        return MultiMatchQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java
index 0e946d6..9c7383d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MultiTermQueryBuilder.java
@@ -18,6 +18,6 @@
  */
 package org.elasticsearch.index.query;
 
-public interface MultiTermQueryBuilder<QB extends MultiTermQueryBuilder<QB>> extends QueryBuilder<QB> {
+public abstract class MultiTermQueryBuilder extends QueryBuilder {
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java
index 6b27816..63b40dc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NestedQueryBuilder.java
@@ -20,14 +20,12 @@
 package org.elasticsearch.index.query;
 
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.support.QueryInnerHits;
+import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 
 import java.io.IOException;
 import java.util.Objects;
 
-public class NestedQueryBuilder extends AbstractQueryBuilder<NestedQueryBuilder> {
-
-    public static final String NAME = "nested";
+public class NestedQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<NestedQueryBuilder> {
 
     private final QueryBuilder queryBuilder;
 
@@ -35,57 +33,71 @@ public class NestedQueryBuilder extends AbstractQueryBuilder<NestedQueryBuilder>
 
     private String scoreMode;
 
-    private QueryInnerHits innerHit;
+    private float boost = 1.0f;
+
+    private String queryName;
 
-    static final NestedQueryBuilder PROTOTYPE = new NestedQueryBuilder();
+    private QueryInnerHitBuilder innerHit;
 
     public NestedQueryBuilder(String path, QueryBuilder queryBuilder) {
         this.path = path;
         this.queryBuilder = Objects.requireNonNull(queryBuilder);
     }
+    /**
+     * The score mode.
+     */
+    public NestedQueryBuilder scoreMode(String scoreMode) {
+        this.scoreMode = scoreMode;
+        return this;
+    }
 
     /**
-     * private constructor only used internally
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    private NestedQueryBuilder() {
-        this.path = null;
-        this.queryBuilder = null;
+    @Override
+    public NestedQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
-     * The score mode.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public NestedQueryBuilder scoreMode(String scoreMode) {
-        this.scoreMode = scoreMode;
+    public NestedQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
         return this;
     }
 
     /**
      * Sets inner hit definition in the scope of this nested query and reusing the defined path and query.
      */
-    public NestedQueryBuilder innerHit(QueryInnerHits innerHit) {
+    public NestedQueryBuilder innerHit(QueryInnerHitBuilder innerHit) {
         this.innerHit = innerHit;
         return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(NestedQueryParser.NAME);
         builder.field("query");
         queryBuilder.toXContent(builder, params);
         builder.field("path", path);
         if (scoreMode != null) {
             builder.field("score_mode", scoreMode);
         }
-        printBoostAndQueryName(builder);
+        if (boost != 1.0f) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (innerHit != null) {
-            innerHit.toXContent(builder, params);
+            builder.startObject("inner_hits");
+            builder.value(innerHit);
+            builder.endObject();
         }
         builder.endObject();
     }
 
-    @Override
-    public final String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java
index 39cacce..e14720b 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NestedQueryParser.java
@@ -36,8 +36,9 @@ import org.elasticsearch.search.fetch.innerhits.InnerHitsSubSearchContext;
 
 import java.io.IOException;
 
-public class NestedQueryParser extends BaseQueryParserTemp {
+public class NestedQueryParser implements QueryParser {
 
+    public static final String NAME = "nested";
     private static final ParseField FILTER_FIELD = new ParseField("filter").withAllDeprecated("query");
 
     private final InnerHitsQueryParserHelper innerHitsQueryParserHelper;
@@ -49,16 +50,15 @@ public class NestedQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{NestedQueryBuilder.NAME, Strings.toCamelCase(NestedQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        final ToBlockJoinQueryBuilder builder = new ToBlockJoinQueryBuilder(context);
+        final ToBlockJoinQueryBuilder builder = new ToBlockJoinQueryBuilder(parseContext);
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         ScoreMode scoreMode = ScoreMode.Avg;
         String queryName = null;
 
@@ -73,7 +73,7 @@ public class NestedQueryParser extends BaseQueryParserTemp {
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, FILTER_FIELD)) {
                     builder.filter();
                 } else if ("inner_hits".equals(currentFieldName)) {
-                    builder.setInnerHits(innerHitsQueryParserHelper.parse(parser));
+                    builder.setInnerHits(innerHitsQueryParserHelper.parse(parseContext));
                 } else {
                     throw new QueryParsingException(parseContext, "[nested] query does not support [" + currentFieldName + "]");
                 }
@@ -110,7 +110,7 @@ public class NestedQueryParser extends BaseQueryParserTemp {
         if (joinQuery != null) {
             joinQuery.setBoost(boost);
             if (queryName != null) {
-                context.addNamedQuery(queryName, joinQuery);
+                parseContext.addNamedQuery(queryName, joinQuery);
             }
         }
         return joinQuery;
@@ -121,8 +121,8 @@ public class NestedQueryParser extends BaseQueryParserTemp {
         private ScoreMode scoreMode;
         private InnerHitsSubSearchContext innerHits;
 
-        public ToBlockJoinQueryBuilder(QueryShardContext context) throws IOException {
-            super(context);
+        public ToBlockJoinQueryBuilder(QueryParseContext parseContext) throws IOException {
+            super(parseContext);
         }
 
         public void setScoreMode(ScoreMode scoreMode) {
@@ -146,14 +146,14 @@ public class NestedQueryParser extends BaseQueryParserTemp {
                     innerQuery = null;
                 }
             } else {
-                throw new QueryShardException(shardContext, "[nested] requires either 'query' or 'filter' field");
+                throw new QueryParsingException(parseContext, "[nested] requires either 'query' or 'filter' field");
             }
 
             if (innerHits != null) {
-                ParsedQuery parsedQuery = new ParsedQuery(innerQuery, shardContext.copyNamedQueries());
+                ParsedQuery parsedQuery = new ParsedQuery(innerQuery, parseContext.copyNamedQueries());
                 InnerHitsContext.NestedInnerHits nestedInnerHits = new InnerHitsContext.NestedInnerHits(innerHits.getSubSearchContext(), parsedQuery, null, getParentObjectMapper(), nestedObjectMapper);
                 String name = innerHits.getName() != null ? innerHits.getName() : path;
-                shardContext.addInnerHits(name, nestedInnerHits);
+                parseContext.addInnerHits(name, nestedInnerHits);
             }
 
             if (innerQuery != null) {
@@ -164,9 +164,4 @@ public class NestedQueryParser extends BaseQueryParserTemp {
         }
 
     }
-
-    @Override
-    public NestedQueryBuilder getBuilderPrototype() {
-        return NestedQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java
index a26ebb7..c16cf64 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NotQueryBuilder.java
@@ -19,10 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
@@ -31,71 +27,29 @@ import java.util.Objects;
 /**
  * A filter that matches documents matching boolean combinations of other filters.
  */
-public class NotQueryBuilder extends AbstractQueryBuilder<NotQueryBuilder> {
-
-    public static final String NAME = "not";
+public class NotQueryBuilder extends QueryBuilder {
 
     private final QueryBuilder filter;
 
-    static final NotQueryBuilder PROTOTYPE = new NotQueryBuilder(null);
+    private String queryName;
 
     public NotQueryBuilder(QueryBuilder filter) {
-        this.filter = filter;
+        this.filter = Objects.requireNonNull(filter);
     }
 
-    /**
-     * @return the query added to "not".
-     */
-    public QueryBuilder innerQuery() {
-        return this.filter;
+    public NotQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(NotQueryParser.NAME);
         builder.field("query");
         filter.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query luceneQuery = filter.toFilter(context);
-        if (luceneQuery == null) {
-            return null;
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return Queries.not(luceneQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQuery(filter, null);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(filter);
-    }
-
-    @Override
-    protected boolean doEquals(NotQueryBuilder other) {
-        return Objects.equals(filter, other.filter);
-    }
-
-    @Override
-    protected NotQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder queryBuilder = in.readQuery();
-        return new NotQueryBuilder(queryBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(filter);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java
index 2388eb1..6bfe4c7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/NotQueryParser.java
@@ -19,17 +19,20 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 
 /**
- * Parser for not query
+ *
  */
-public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
+public class NotQueryParser implements QueryParser {
 
+    public static final String NAME = "not";
     private static final ParseField QUERY_FIELD = new ParseField("filter", "query");
 
     @Inject
@@ -38,19 +41,18 @@ public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{NotQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public NotQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        QueryBuilder query = null;
+        Query query = null;
         boolean queryFound = false;
 
         String queryName = null;
         String currentFieldName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
@@ -59,18 +61,16 @@ public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
                 // skip
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, QUERY_FIELD)) {
-                    query = parseContext.parseInnerFilterToQueryBuilder();
+                    query = parseContext.parseInnerFilter();
                     queryFound = true;
                 } else {
                     queryFound = true;
                     // its the filter, and the name is the field
-                    query = parseContext.parseInnerFilterToQueryBuilder(currentFieldName);
+                    query = parseContext.parseInnerFilter(currentFieldName);
                 }
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else {
                     throw new QueryParsingException(parseContext, "[not] query does not support [" + currentFieldName + "]");
                 }
@@ -81,14 +81,14 @@ public class NotQueryParser extends BaseQueryParser<NotQueryBuilder> {
             throw new QueryParsingException(parseContext, "filter is required when using `not` query");
         }
 
-        NotQueryBuilder notQueryBuilder = new NotQueryBuilder(query);
-        notQueryBuilder.queryName(queryName);
-        notQueryBuilder.boost(boost);
-        return notQueryBuilder;
-    }
+        if (query == null) {
+            return null;
+        }
 
-    @Override
-    public NotQueryBuilder getBuilderPrototype() {
-        return NotQueryBuilder.PROTOTYPE;
+        Query notQuery = Queries.not(query);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, notQuery);
+        }
+        return notQuery;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/Operator.java b/core/src/main/java/org/elasticsearch/index/query/Operator.java
deleted file mode 100644
index 1470737..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/Operator.java
+++ /dev/null
@@ -1,84 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
-import org.elasticsearch.common.util.CollectionUtils;
-
-import java.io.IOException;
-
-public enum Operator implements Writeable<Operator> {
-    OR(0), AND(1);
-
-    private final int ordinal;
-
-    private static final Operator PROTOTYPE = OR;
-
-    private Operator(int ordinal) {
-        this.ordinal = ordinal;
-    }
-
-    public BooleanClause.Occur toBooleanClauseOccur() {
-        switch (this) {
-            case OR:
-                return BooleanClause.Occur.SHOULD;
-            case AND:
-                return BooleanClause.Occur.MUST;
-            default:
-                throw Operator.newOperatorException(this.toString());
-        }
-    }
-
-    @Override
-    public Operator readFrom(StreamInput in) throws IOException {
-        int ord = in.readVInt();
-        for (Operator operator : Operator.values()) {
-            if (operator.ordinal == ord) {
-                return operator;
-            }
-        }
-        throw new ElasticsearchException("unknown serialized operator [" + ord + "]");
-    }
-
-    public static Operator readOperatorFrom(StreamInput in) throws IOException {
-        return PROTOTYPE.readFrom(in);
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeVInt(this.ordinal);
-    }
-
-    public static Operator fromString(String op) {
-        for (Operator operator : Operator.values()) {
-            if (operator.name().equalsIgnoreCase(op)) {
-                return operator;
-            }
-        }
-        throw Operator.newOperatorException(op);
-    }
-
-    private static IllegalArgumentException newOperatorException(String op) {
-        return new IllegalArgumentException("operator needs to be either " + CollectionUtils.arrayAsArrayList(Operator.values()) + ", but not [" + op + "]");
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/OrQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/OrQueryBuilder.java
index 29180ea..e8ad48b 100644
--- a/core/src/main/java/org/elasticsearch/index/query/OrQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/OrQueryBuilder.java
@@ -19,31 +19,22 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collections;
-import java.util.List;
-import java.util.Objects;
 
 /**
  * A filter that matches documents matching boolean combinations of other filters.
  * @deprecated Use {@link BoolQueryBuilder} instead
  */
 @Deprecated
-public class OrQueryBuilder extends AbstractQueryBuilder<OrQueryBuilder> {
+public class OrQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "or";
+    private ArrayList<QueryBuilder> filters = new ArrayList<>();
 
-    private final ArrayList<QueryBuilder> filters = new ArrayList<>();
-
-    static final OrQueryBuilder PROTOTYPE = new OrQueryBuilder();
+    private String queryName;
 
     public OrQueryBuilder(QueryBuilder... filters) {
         Collections.addAll(this.filters, filters);
@@ -51,87 +42,28 @@ public class OrQueryBuilder extends AbstractQueryBuilder<OrQueryBuilder> {
 
     /**
      * Adds a filter to the list of filters to "or".
-     * No <tt>null</tt> value allowed.
      */
     public OrQueryBuilder add(QueryBuilder filterBuilder) {
         filters.add(filterBuilder);
         return this;
     }
 
-    /**
-     * @return the list of queries added to "or".
-     */
-    public List<QueryBuilder> innerQueries() {
-        return this.filters;
+    public OrQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(OrQueryParser.NAME);
         builder.startArray("filters");
         for (QueryBuilder filter : filters) {
             filter.toXContent(builder, params);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        if (filters.isEmpty()) {
-            // no filters provided, this should be ignored upstream
-            return null;
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();
-        for (QueryBuilder f : filters) {
-            Query innerQuery = f.toFilter(context);
-            // ignore queries that are null
-            if (innerQuery != null) {
-                queryBuilder.add(innerQuery, Occur.SHOULD);
-            }
-        }
-        BooleanQuery booleanQuery = queryBuilder.build();
-        if (booleanQuery.clauses().isEmpty()) {
-            // no inner lucene query exists, ignore upstream
-            return null;
-        }
-        return booleanQuery;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQueries(filters, null);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(filters);
-    }
-
-    @Override
-    protected boolean doEquals(OrQueryBuilder other) {
-        return Objects.equals(filters, other.filters);
-    }
-
-    @Override
-    protected OrQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        OrQueryBuilder orQueryBuilder = new OrQueryBuilder();
-        List<QueryBuilder> queryBuilders = readQueries(in);
-        for (QueryBuilder queryBuilder : queryBuilders) {
-            orQueryBuilder.add(queryBuilder);
-        }
-        return orQueryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, filters);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/OrQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/OrQueryParser.java
index f1b38e4..fca3f93 100644
--- a/core/src/main/java/org/elasticsearch/index/query/OrQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/OrQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
@@ -26,11 +29,12 @@ import java.io.IOException;
 import java.util.ArrayList;
 
 /**
- * Parser for or query
- * @deprecated use bool query instead
+ *
  */
 @Deprecated
-public class OrQueryParser extends BaseQueryParser<OrQueryBuilder> {
+public class OrQueryParser implements QueryParser {
+
+    public static final String NAME = "or";
 
     @Inject
     public OrQueryParser() {
@@ -38,24 +42,23 @@ public class OrQueryParser extends BaseQueryParser<OrQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{OrQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public OrQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        final ArrayList<QueryBuilder> queries = new ArrayList<>();
+        ArrayList<Query> queries = new ArrayList<>();
         boolean queriesFound = false;
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
         String currentFieldName = null;
         XContentParser.Token token = parser.currentToken();
         if (token == XContentParser.Token.START_ARRAY) {
             while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                 queriesFound = true;
-                QueryBuilder filter = parseContext.parseInnerFilterToQueryBuilder();
+                Query filter = parseContext.parseInnerFilter();
                 if (filter != null) {
                     queries.add(filter);
                 }
@@ -68,7 +71,15 @@ public class OrQueryParser extends BaseQueryParser<OrQueryBuilder> {
                     if ("filters".equals(currentFieldName)) {
                         queriesFound = true;
                         while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                            QueryBuilder filter = parseContext.parseInnerFilterToQueryBuilder();
+                            Query filter = parseContext.parseInnerFilter();
+                            if (filter != null) {
+                                queries.add(filter);
+                            }
+                        }
+                    } else {
+                        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
+                            queriesFound = true;
+                            Query filter = parseContext.parseInnerFilter();
                             if (filter != null) {
                                 queries.add(filter);
                             }
@@ -77,8 +88,6 @@ public class OrQueryParser extends BaseQueryParser<OrQueryBuilder> {
                 } else if (token.isValue()) {
                     if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
-                    } else if ("boost".equals(currentFieldName)) {
-                        boost = parser.floatValue();
                     } else {
                         throw new QueryParsingException(parseContext, "[or] query does not support [" + currentFieldName + "]");
                     }
@@ -90,17 +99,18 @@ public class OrQueryParser extends BaseQueryParser<OrQueryBuilder> {
             throw new QueryParsingException(parseContext, "[or] query requires 'filters' to be set on it'");
         }
 
-        OrQueryBuilder orQuery = new OrQueryBuilder();
-        for (QueryBuilder query : queries) {
-            orQuery.add(query);
+        if (queries.isEmpty()) {
+            return null;
         }
-        orQuery.queryName(queryName);
-        orQuery.boost(boost);
-        return orQuery;
-    }
 
-    @Override
-    public OrQueryBuilder getBuilderPrototype() {
-        return OrQueryBuilder.PROTOTYPE;
+        BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder();
+        for (Query f : queries) {
+            queryBuilder.add(f, Occur.SHOULD);
+        }
+        BooleanQuery query = queryBuilder.build();
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java
index a49580c..e0e5b2f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryBuilder.java
@@ -19,53 +19,44 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that matches documents containing terms with a specified prefix.
  */
-public class PrefixQueryBuilder extends AbstractQueryBuilder<PrefixQueryBuilder> implements MultiTermQueryBuilder<PrefixQueryBuilder> {
+public class PrefixQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<PrefixQueryBuilder> {
 
-    public static final String NAME = "prefix";
+    private final String name;
 
-    private final String fieldName;
+    private final String prefix;
 
-    private final String value;
+    private float boost = -1;
 
     private String rewrite;
 
-    static final PrefixQueryBuilder PROTOTYPE = new PrefixQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * A Query that matches documents containing terms with a specified prefix.
      *
-     * @param fieldName The name of the field
-     * @param value The prefix query
+     * @param name   The name of the field
+     * @param prefix The prefix query
      */
-    public PrefixQueryBuilder(String fieldName, String value) {
-        this.fieldName = fieldName;
-        this.value = value;
+    public PrefixQueryBuilder(String name, String prefix) {
+        this.name = name;
+        this.prefix = prefix;
     }
 
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public String value() {
-        return this.value;
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public PrefixQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     public PrefixQueryBuilder rewrite(String rewrite) {
@@ -73,83 +64,33 @@ public class PrefixQueryBuilder extends AbstractQueryBuilder<PrefixQueryBuilder>
         return this;
     }
 
-    public String rewrite() {
-        return this.rewrite;
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public PrefixQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("prefix", this.value);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
-        }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-
-        Query query = null;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            query = fieldType.prefixQuery(value, method, context);
-        }
-        if (query == null) {
-            PrefixQuery prefixQuery = new PrefixQuery(new Term(fieldName, BytesRefs.toBytesRef(value)));
-            if (method != null) {
-                prefixQuery.setRewriteMethod(method);
+        builder.startObject(PrefixQueryParser.NAME);
+        if (boost == -1 && rewrite == null && queryName == null) {
+            builder.field(name, prefix);
+        } else {
+            builder.startObject(name);
+            builder.field("prefix", prefix);
+            if (boost != -1) {
+                builder.field("boost", boost);
             }
-            query = prefixQuery;
-        }
-
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.value == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
+            if (rewrite != null) {
+                builder.field("rewrite", rewrite);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
         }
-        return validationException;
-    }
-
-    @Override
-    protected PrefixQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        PrefixQueryBuilder prefixQueryBuilder = new PrefixQueryBuilder(in.readString(), in.readString());
-        prefixQueryBuilder.rewrite = in.readOptionalString();
-        return prefixQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeString(value);
-        out.writeOptionalString(rewrite);
-    }
-
-    @Override
-    protected final int doHashCode() {
-        return Objects.hash(fieldName, value, rewrite);
-    }
-
-    @Override
-    protected boolean doEquals(PrefixQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java
index eac29fa..d61fec7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/PrefixQueryParser.java
@@ -19,16 +19,25 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.PrefixQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
 /**
- * Parser for prefix query
+ *
  */
-public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
+public class PrefixQueryParser implements QueryParser {
+
+    public static final String NAME = "prefix";
 
     private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of prefix query");
 
@@ -38,19 +47,19 @@ public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{PrefixQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public PrefixQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = parser.currentName();
-        String value = null;
-        String rewrite = null;
-
+        String rewriteMethod = null;
         String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+
+        String value = null;
+        float boost = 1.0f;
         String currentFieldName = null;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -71,7 +80,7 @@ public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
                         } else if ("boost".equals(currentFieldName)) {
                             boost = parser.floatValue();
                         } else if ("rewrite".equals(currentFieldName)) {
-                            rewrite = parser.textOrNull();
+                            rewriteMethod = parser.textOrNull();
                         } else {
                             throw new QueryParsingException(parseContext, "[regexp] query does not support [" + currentFieldName + "]");
                         }
@@ -90,14 +99,25 @@ public class PrefixQueryParser extends BaseQueryParser<PrefixQueryBuilder> {
         if (value == null) {
             throw new QueryParsingException(parseContext, "No value specified for prefix query");
         }
-        return new PrefixQueryBuilder(fieldName, value)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    @Override
-    public PrefixQueryBuilder getBuilderPrototype() {
-        return PrefixQueryBuilder.PROTOTYPE;
+        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), rewriteMethod, null);
+
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.prefixQuery(value, method, parseContext);
+        }
+        if (query == null) {
+            PrefixQuery prefixQuery = new PrefixQuery(new Term(fieldName, BytesRefs.toBytesRef(value)));
+            if (method != null) {
+                prefixQuery.setRewriteMethod(method);
+            }
+            query = prefixQuery;
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return  query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java
index 3f69375..fa11d32 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryBuilder.java
@@ -19,79 +19,25 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.client.Requests;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.NamedWriteable;
-import org.elasticsearch.common.xcontent.ToXContent;
+import org.elasticsearch.action.support.ToXContentToBytes;
+import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentType;
 
 import java.io.IOException;
 
-public interface QueryBuilder<QB extends QueryBuilder> extends NamedWriteable<QB>, ToXContent {
+public abstract class QueryBuilder extends ToXContentToBytes {
 
-    /**
-     * Validate the query.
-     * @return a {@link QueryValidationException} containing error messages, {@code null} if query is valid.
-     * e.g. if fields that are needed to create the lucene query are missing.
-     */
-    QueryValidationException validate();
+    protected QueryBuilder() {
+        super(XContentType.JSON);
+    }
 
-    /**
-     * Converts this QueryBuilder to a lucene {@link Query}.
-     * Returns <tt>null</tt> if this query should be ignored in the context of
-     * parent queries.
-     *
-     * @param context additional information needed to construct the queries
-     * @return the {@link Query} or <tt>null</tt> if this query should be ignored upstream
-     * @throws QueryShardException
-     * @throws IOException
-     */
-    Query toQuery(QueryShardContext context) throws IOException;
+    @Override
+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject();
+        doXContent(builder, params);
+        builder.endObject();
+        return builder;
+    }
 
-    /**
-     * Converts this QueryBuilder to an unscored lucene {@link Query} that acts as a filter.
-     * Returns <tt>null</tt> if this query should be ignored in the context of
-     * parent queries.
-     *
-     * @param context additional information needed to construct the queries
-     * @return the {@link Query} or <tt>null</tt> if this query should be ignored upstream
-     * @throws QueryShardException
-     * @throws IOException
-     */
-    Query toFilter(QueryShardContext context) throws IOException;
-
-    /**
-     * Returns a {@link org.elasticsearch.common.bytes.BytesReference}
-     * containing the {@link ToXContent} output in binary format.
-     * Builds the request based on the default {@link XContentType}, either {@link Requests#CONTENT_TYPE} or provided as a constructor argument
-     */
-    //norelease once we move to serializing queries over the wire in Streamable format, this method shouldn't be needed anymore
-    BytesReference buildAsBytes();
-
-    /**
-     * Sets the arbitrary name to be assigned to the query (see named queries).
-     */
-    QB queryName(String queryName);
-
-    /**
-     * Returns the arbitrary name assigned to the query (see named queries).
-     */
-    String queryName();
-
-    /**
-     * Returns the boost for this query.
-     */
-    float boost();
-
-    /**
-     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
-     * weightings) have their score multiplied by the boost provided.
-     */
-    QB boost(float boost);
-
-    /**
-     * Returns the name that identifies uniquely the query
-     */
-    String getName();
+    protected abstract void doXContent(XContentBuilder builder, Params params) throws IOException;
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java b/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
index 9b6ac01..fe2852d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
@@ -40,7 +40,7 @@ import java.util.Map;
 public abstract class QueryBuilders {
 
     /**
-     * A query that matches on all documents.
+     * A query that match on all documents.
      */
     public static MatchAllQueryBuilder matchAllQuery() {
         return new MatchAllQueryBuilder();
@@ -59,11 +59,11 @@ public abstract class QueryBuilders {
     /**
      * Creates a common query for the provided field name and text.
      *
-     * @param fieldName The field name.
+     * @param name The field name.
      * @param text The query text (to be analyzed).
      */
-    public static CommonTermsQueryBuilder commonTermsQuery(String fieldName, Object text) {
-        return new CommonTermsQueryBuilder(fieldName, text);
+    public static CommonTermsQueryBuilder commonTermsQuery(String name, Object text) {
+        return new CommonTermsQueryBuilder(name, text);
     }
 
     /**
@@ -277,8 +277,8 @@ public abstract class QueryBuilders {
      * Unlike the "NOT" clause, this still selects documents that contain undesirable terms,
      * but reduces their overall score:
      */
-    public static BoostingQueryBuilder boostingQuery(QueryBuilder positiveQuery, QueryBuilder negativeQuery) {
-        return new BoostingQueryBuilder(positiveQuery, negativeQuery);
+    public static BoostingQueryBuilder boostingQuery() {
+        return new BoostingQueryBuilder();
     }
 
     /**
@@ -312,33 +312,26 @@ public abstract class QueryBuilders {
         return new SpanFirstQueryBuilder(match, end);
     }
 
-    public static SpanNearQueryBuilder spanNearQuery(int slop) {
-        return new SpanNearQueryBuilder(slop);
+    public static SpanNearQueryBuilder spanNearQuery() {
+        return new SpanNearQueryBuilder();
     }
 
-    public static SpanNotQueryBuilder spanNotQuery(SpanQueryBuilder include, SpanQueryBuilder exclude) {
-        return new SpanNotQueryBuilder(include, exclude);
+    public static SpanNotQueryBuilder spanNotQuery() {
+        return new SpanNotQueryBuilder();
     }
 
     public static SpanOrQueryBuilder spanOrQuery() {
         return new SpanOrQueryBuilder();
     }
 
-    /** Creates a new {@code span_within} builder.
-    * @param big the big clause, it must enclose {@code little} for a match.
-    * @param little the little clause, it must be contained within {@code big} for a match.
-    */
-    public static SpanWithinQueryBuilder spanWithinQuery(SpanQueryBuilder big, SpanQueryBuilder little) {
-        return new SpanWithinQueryBuilder(big, little);
+    /** Creates a new {@code span_within} builder. */
+    public static SpanWithinQueryBuilder spanWithinQuery() {
+        return new SpanWithinQueryBuilder();
     }
 
-    /**
-     * Creates a new {@code span_containing} builder.
-     * @param big the big clause, it must enclose {@code little} for a match.
-     * @param little the little clause, it must be contained within {@code big} for a match.
-     */
-    public static SpanContainingQueryBuilder spanContainingQuery(SpanQueryBuilder big, SpanQueryBuilder little) {
-        return new SpanContainingQueryBuilder(big, little);
+    /** Creates a new {@code span_containing} builder. */
+    public static SpanContainingQueryBuilder spanContainingQuery() {
+        return new SpanContainingQueryBuilder();
     }
 
     /**
@@ -556,8 +549,8 @@ public abstract class QueryBuilders {
     /**
      * A Query builder which allows building a query thanks to a JSON string or binary data.
      */
-    public static WrapperQueryBuilder wrapperQuery(byte[] source) {
-        return new WrapperQueryBuilder(source);
+    public static WrapperQueryBuilder wrapperQuery(byte[] source, int offset, int length) {
+        return new WrapperQueryBuilder(source, offset, length);
     }
 
     /**
@@ -600,10 +593,11 @@ public abstract class QueryBuilders {
     }
 
     /**
-     * A terms query that can extract the terms from another doc in an index.
+     * A terms lookup filter for the provided field name. A lookup terms filter can
+     * extract the terms to filter by from another doc in an index.
      */
-    public static TermsQueryBuilder termsLookupQuery(String name) {
-        return new TermsQueryBuilder(name);
+    public static TermsLookupQueryBuilder termsLookupQuery(String name) {
+        return new TermsLookupQueryBuilder(name);
     }
 
     /**
@@ -690,7 +684,7 @@ public abstract class QueryBuilders {
     public static GeohashCellQuery.Builder geoHashCellQuery(String name, String geohash, boolean neighbors) {
         return new GeohashCellQuery.Builder(name, geohash, neighbors);
     }
-
+    
     /**
      * A filter to filter based on a polygon defined by a set of locations  / points.
      *
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java
index 3c530b8..936e466 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryFilterBuilder.java
@@ -19,14 +19,9 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A filter that simply wraps a query.
@@ -34,13 +29,11 @@ import java.util.Objects;
  *             query as a filter directly.
  */
 @Deprecated
-public class QueryFilterBuilder extends AbstractQueryBuilder<QueryFilterBuilder> {
-
-    public static final String NAME = "query";
+public class QueryFilterBuilder extends QueryBuilder {
 
     private final QueryBuilder queryBuilder;
 
-    static final QueryFilterBuilder PROTOTYPE = new QueryFilterBuilder(null);
+    private String queryName;
 
     /**
      * A filter that simply wraps a query.
@@ -52,61 +45,26 @@ public class QueryFilterBuilder extends AbstractQueryBuilder<QueryFilterBuilder>
     }
 
     /**
-     * @return the query builder that is wrapped by this {@link QueryFilterBuilder}
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public QueryBuilder innerQuery() {
-        return this.queryBuilder;
+    public QueryFilterBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.field(NAME);
-        queryBuilder.toXContent(builder, params);
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // inner query builder can potentially be `null`, in that case we ignore it
-        Query innerQuery = this.queryBuilder.toQuery(context);
-        if (innerQuery == null) {
-            return null;
+        if (queryName == null) {
+            builder.field(QueryFilterParser.NAME);
+            queryBuilder.toXContent(builder, params);
+        } else {
+            builder.startObject(FQueryFilterParser.NAME);
+            builder.field("query");
+            queryBuilder.toXContent(builder, params);
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
         }
-        return new ConstantScoreQuery(innerQuery);
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        //no-op this query doesn't support boost
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        return validateInnerQuery(queryBuilder, null);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(queryBuilder);
-    }
-
-    @Override
-    protected boolean doEquals(QueryFilterBuilder other) {
-        return Objects.equals(queryBuilder, other.queryBuilder);
-    }
-
-    @Override
-    protected QueryFilterBuilder doReadFrom(StreamInput in) throws IOException {
-        QueryBuilder innerQueryBuilder = in.readQuery();
-        return new QueryFilterBuilder(innerQueryBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(queryBuilder);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java b/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java
index 03513ab..fdb9cb3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryFilterParser.java
@@ -19,16 +19,16 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
 
 import java.io.IOException;
 
-/**
- * Parser for query filter
- * @deprecated use any query instead directly, possible since queries and filters are merged.
- */
 @Deprecated
-public class QueryFilterParser extends BaseQueryParser<QueryFilterBuilder> {
+public class QueryFilterParser implements QueryParser {
+
+    public static final String NAME = "query";
 
     @Inject
     public QueryFilterParser() {
@@ -36,16 +36,11 @@ public class QueryFilterParser extends BaseQueryParser<QueryFilterBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{QueryFilterBuilder.NAME};
-    }
-
-    @Override
-    public QueryFilterBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-        return new QueryFilterBuilder(parseContext.parseInnerQueryBuilder());
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryFilterBuilder getBuilderPrototype() {
-        return QueryFilterBuilder.PROTOTYPE;
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
+        return new ConstantScoreQuery(parseContext.parseInnerQuery());
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java b/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java
index a8e055f..f152d22 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParseContext.java
@@ -19,105 +19,214 @@
 
 package org.elasticsearch.index.query;
 
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.Maps;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.queryparser.classic.MapperQueryParser;
+import org.apache.lucene.queryparser.classic.QueryParserSettings;
+import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.search.join.BitSetProducer;
+import org.apache.lucene.search.similarities.Similarity;
+import org.elasticsearch.Version;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.ParseFieldMatcher;
+import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.Index;
-import org.elasticsearch.indices.query.IndicesQueriesRegistry;
+import org.elasticsearch.index.analysis.AnalysisService;
+import org.elasticsearch.index.fielddata.IndexFieldData;
+import org.elasticsearch.index.mapper.ContentPath;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.Mapper;
+import org.elasticsearch.index.mapper.MapperBuilders;
+import org.elasticsearch.index.mapper.MapperService;
+import org.elasticsearch.index.mapper.core.StringFieldMapper;
+import org.elasticsearch.index.mapper.object.ObjectMapper;
+import org.elasticsearch.index.query.support.NestedScope;
+import org.elasticsearch.index.similarity.SimilarityService;
+import org.elasticsearch.script.ScriptService;
+import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
+import org.elasticsearch.search.internal.SearchContext;
+import org.elasticsearch.search.lookup.SearchLookup;
 
 import java.io.IOException;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.Map;
 
 public class QueryParseContext {
 
     private static final ParseField CACHE = new ParseField("_cache").withAllDeprecated("Elasticsearch makes its own caching decisions");
     private static final ParseField CACHE_KEY = new ParseField("_cache_key").withAllDeprecated("Filters are always used as cache keys");
 
-    private XContentParser parser;
+    private static ThreadLocal<String[]> typesContext = new ThreadLocal<>();
+
+    public static void setTypes(String[] types) {
+        typesContext.set(types);
+    }
+
+    public static String[] getTypes() {
+        return typesContext.get();
+    }
+
+    public static String[] setTypesWithPrevious(String[] types) {
+        String[] old = typesContext.get();
+        setTypes(types);
+        return old;
+    }
+
+    public static void removeTypes() {
+        typesContext.remove();
+    }
+
     private final Index index;
-    //norelease this flag is also used in the QueryShardContext, we need to make sure we set it there correctly in doToQuery()
+
+    private final Version indexVersionCreated;
+
+    private final IndexQueryParserService indexQueryParser;
+
+    private final Map<String, Query> namedQueries = Maps.newHashMap();
+
+    private final MapperQueryParser queryParser = new MapperQueryParser(this);
+
+    private XContentParser parser;
+
     private ParseFieldMatcher parseFieldMatcher;
 
-    //norelease this can eventually be deleted when context() method goes away
-    private final QueryShardContext shardContext;
-    private IndicesQueriesRegistry indicesQueriesRegistry;
+    private boolean allowUnmappedFields;
+
+    private boolean mapUnmappedFieldAsString;
 
-    public QueryParseContext(Index index, IndicesQueriesRegistry registry) {
+    private NestedScope nestedScope;
+
+    private boolean isFilter;
+
+    public QueryParseContext(Index index, IndexQueryParserService indexQueryParser) {
         this.index = index;
-        this.indicesQueriesRegistry = registry;
-        this.shardContext = null;
+        this.indexVersionCreated = Version.indexCreated(indexQueryParser.indexSettings());
+        this.indexQueryParser = indexQueryParser;
+    }
+
+    public void parseFieldMatcher(ParseFieldMatcher parseFieldMatcher) {
+        this.parseFieldMatcher = parseFieldMatcher;
     }
 
-    QueryParseContext(QueryShardContext context) {
-        this.shardContext = context;
-        this.index = context.index();
-        this.indicesQueriesRegistry = context.indexQueryParserService().indicesQueriesRegistry();
+    public ParseFieldMatcher parseFieldMatcher() {
+        return parseFieldMatcher;
     }
 
     public void reset(XContentParser jp) {
+        allowUnmappedFields = indexQueryParser.defaultAllowUnmappedFields();
         this.parseFieldMatcher = ParseFieldMatcher.EMPTY;
+        this.lookup = null;
         this.parser = jp;
+        this.namedQueries.clear();
+        this.nestedScope = new NestedScope();
+        this.isFilter = false;
     }
 
-    //norelease this is still used in BaseQueryParserTemp and FunctionScoreQueryParser, remove if not needed there anymore
-    @Deprecated
-    public QueryShardContext shardContext() {
-        return this.shardContext;
+    public Index index() {
+        return this.index;
+    }
+
+    public void parser(XContentParser parser) {
+        this.parser = parser;
     }
 
     public XContentParser parser() {
-        return this.parser;
+        return parser;
+    }
+    
+    public IndexQueryParserService indexQueryParserService() {
+        return indexQueryParser;
     }
 
-    public void parseFieldMatcher(ParseFieldMatcher parseFieldMatcher) {
-        this.parseFieldMatcher = parseFieldMatcher;
+    public AnalysisService analysisService() {
+        return indexQueryParser.analysisService;
     }
 
-    public boolean isDeprecatedSetting(String setting) {
-        return parseFieldMatcher.match(setting, CACHE) || parseFieldMatcher.match(setting, CACHE_KEY);
+    public ScriptService scriptService() {
+        return indexQueryParser.scriptService;
     }
 
-    public Index index() {
-        return this.index;
+    public MapperService mapperService() {
+        return indexQueryParser.mapperService;
     }
 
-    /**
-     * @deprecated replaced by calls to parseInnerFilterToQueryBuilder() for the resulting queries
-     */
     @Nullable
-    @Deprecated
-    //norelease should be possible to remove after refactoring all queries
-    public Query parseInnerFilter() throws QueryShardException, IOException {
-        assert this.shardContext != null;
-        QueryBuilder builder = parseInnerFilterToQueryBuilder();
-        Query result = null;
-        if (builder != null) {
-            result = builder.toQuery(this.shardContext);
+    public SimilarityService similarityService() {
+        return indexQueryParser.similarityService;
+    }
+
+    public Similarity searchSimilarity() {
+        return indexQueryParser.similarityService != null ? indexQueryParser.similarityService.similarity() : null;
+    }
+
+    public String defaultField() {
+        return indexQueryParser.defaultField();
+    }
+
+    public boolean queryStringLenient() {
+        return indexQueryParser.queryStringLenient();
+    }
+
+    public MapperQueryParser queryParser(QueryParserSettings settings) {
+        queryParser.reset(settings);
+        return queryParser;
+    }
+
+    public BitSetProducer bitsetFilter(Filter filter) {
+        return indexQueryParser.bitsetFilterCache.getBitSetProducer(filter);
+    }
+
+    public <IFD extends IndexFieldData<?>> IFD getForField(MappedFieldType mapper) {
+        return indexQueryParser.fieldDataService.getForField(mapper);
+    }
+
+    public void addNamedQuery(String name, Query query) {
+        if (query != null) {
+            namedQueries.put(name, query);
         }
-        return result;
+    }
+
+    public ImmutableMap<String, Query> copyNamedQueries() {
+        return ImmutableMap.copyOf(namedQueries);
+    }
+
+    public void combineNamedQueries(QueryParseContext context) {
+        namedQueries.putAll(context.namedQueries);
     }
 
     /**
-     * @deprecated replaced by calls to parseInnerQueryBuilder() for the resulting queries
+     * Return whether we are currently parsing a filter or a query.
      */
-    @Nullable
-    @Deprecated
-    //norelease this method will be removed once all queries are refactored
-    public Query parseInnerQuery() throws IOException, QueryShardException {
-        QueryBuilder builder = parseInnerQueryBuilder();
-        Query result = null;
-        if (builder != null) {
-            result = builder.toQuery(this.shardContext);
+    public boolean isFilter() {
+        return isFilter;
+    }
+
+    public void addInnerHits(String name, InnerHitsContext.BaseInnerHits context) {
+        SearchContext sc = SearchContext.current();
+        if (sc == null) {
+            throw new QueryParsingException(this, "inner_hits unsupported");
         }
-        return result;
+
+        InnerHitsContext innerHitsContext;
+        if (sc.innerHits() == null) {
+            innerHitsContext = new InnerHitsContext(new HashMap<String, InnerHitsContext.BaseInnerHits>());
+            sc.innerHits(innerHitsContext);
+        } else {
+            innerHitsContext = sc.innerHits();
+        }
+        innerHitsContext.addInnerHitDefinition(name, context);
     }
 
-    /**
-     * @return a new QueryBuilder based on the current state of the parser
-     * @throws IOException
-     */
-    public QueryBuilder parseInnerQueryBuilder() throws IOException {
+    @Nullable
+    public Query parseInnerQuery() throws QueryParsingException, IOException {
         // move to START object
         XContentParser.Token token;
         if (parser.currentToken() != XContentParser.Token.START_OBJECT) {
@@ -129,7 +238,7 @@ public class QueryParseContext {
         token = parser.nextToken();
         if (token == XContentParser.Token.END_OBJECT) {
             // empty query
-            return EmptyQueryBuilder.PROTOTYPE;
+            return null;
         }
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new QueryParsingException(this, "[_na] query malformed, no field after start_object");
@@ -141,11 +250,11 @@ public class QueryParseContext {
             throw new QueryParsingException(this, "[_na] query malformed, no field after start_object");
         }
 
-        QueryParser queryParser = queryParser(queryName);
+        QueryParser queryParser = indexQueryParser.queryParser(queryName);
         if (queryParser == null) {
             throw new QueryParsingException(this, "No query registered for [" + queryName + "]");
         }
-        QueryBuilder result = queryParser.fromXContent(this);
+        Query result = queryParser.parse(this);
         if (parser.currentToken() == XContentParser.Token.END_OBJECT || parser.currentToken() == XContentParser.Token.END_ARRAY) {
             // if we are at END_OBJECT, move to the next one...
             parser.nextToken();
@@ -153,46 +262,137 @@ public class QueryParseContext {
         return result;
     }
 
-    /**
-     * @return a new QueryBuilder based on the current state of the parser, but does so that the inner query
-     * is parsed to a filter
-     * @throws IOException
-     */
-    //norelease setting and checking the isFilter Flag should completely be moved to toQuery/toFilter after query refactoring
-    public QueryBuilder parseInnerFilterToQueryBuilder() throws IOException {
-        final boolean originalIsFilter = this.shardContext.isFilter;
+    @Nullable
+    public Query parseInnerFilter() throws QueryParsingException, IOException {
+        final boolean originalIsFilter = isFilter;
         try {
-            this.shardContext.isFilter = true;
-            return parseInnerQueryBuilder();
+            isFilter = true;
+            return parseInnerQuery();
         } finally {
-            this.shardContext.isFilter = originalIsFilter;
+            isFilter = originalIsFilter;
         }
     }
 
-    //norelease setting and checking the isFilter Flag should completely be moved to toQuery/toFilter after query refactoring
-    public QueryBuilder parseInnerFilterToQueryBuilder(String queryName) throws IOException, QueryParsingException {
-        final boolean originalIsFilter = this.shardContext.isFilter;
+    public Query parseInnerFilter(String queryName) throws IOException, QueryParsingException {
+        final boolean originalIsFilter = isFilter;
         try {
-            this.shardContext.isFilter = true;
-            QueryParser queryParser = queryParser(queryName);
+            isFilter = true;
+            QueryParser queryParser = indexQueryParser.queryParser(queryName);
             if (queryParser == null) {
                 throw new QueryParsingException(this, "No query registered for [" + queryName + "]");
             }
-            return queryParser.fromXContent(this);
+            return queryParser.parse(this);
         } finally {
-            this.shardContext.isFilter = originalIsFilter;
+            isFilter = originalIsFilter;
         }
     }
 
-    public ParseFieldMatcher parseFieldMatcher() {
-        return parseFieldMatcher;
+    public Collection<String> simpleMatchToIndexNames(String pattern) {
+        return indexQueryParser.mapperService.simpleMatchToIndexNames(pattern, getTypes());
+    }
+
+    public MappedFieldType fieldMapper(String name) {
+        return failIfFieldMappingNotFound(name, indexQueryParser.mapperService.smartNameFieldType(name, getTypes()));
+    }
+
+    public ObjectMapper getObjectMapper(String name) {
+        return indexQueryParser.mapperService.getObjectMapper(name, getTypes());
+    }
+
+    /** Gets the search analyzer for the given field, or the default if there is none present for the field
+     * TODO: remove this by moving defaults into mappers themselves
+     */
+    public Analyzer getSearchAnalyzer(MappedFieldType fieldType) {
+        if (fieldType.searchAnalyzer() != null) {
+            return fieldType.searchAnalyzer();
+        }
+        return mapperService().searchAnalyzer();
+    }
+
+    /** Gets the search quote nalyzer for the given field, or the default if there is none present for the field
+     * TODO: remove this by moving defaults into mappers themselves
+     */
+    public Analyzer getSearchQuoteAnalyzer(MappedFieldType fieldType) {
+        if (fieldType.searchQuoteAnalyzer() != null) {
+            return fieldType.searchQuoteAnalyzer();
+        }
+        return mapperService().searchQuoteAnalyzer();
     }
 
-    public void parser(XContentParser innerParser) {
-        this.parser = innerParser;
+    public void setAllowUnmappedFields(boolean allowUnmappedFields) {
+        this.allowUnmappedFields = allowUnmappedFields;
+    }
+
+    public void setMapUnmappedFieldAsString(boolean mapUnmappedFieldAsString) {
+        this.mapUnmappedFieldAsString = mapUnmappedFieldAsString;
+    }
+
+    private MappedFieldType failIfFieldMappingNotFound(String name, MappedFieldType fieldMapping) {
+        if (allowUnmappedFields) {
+            return fieldMapping;
+        } else if (mapUnmappedFieldAsString){
+            StringFieldMapper.Builder builder = MapperBuilders.stringField(name);
+            // it would be better to pass the real index settings, but they are not easily accessible from here...
+            Settings settings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, indexQueryParser.getIndexCreatedVersion()).build();
+            return builder.build(new Mapper.BuilderContext(settings, new ContentPath(1))).fieldType();
+        } else {
+            Version indexCreatedVersion = indexQueryParser.getIndexCreatedVersion();
+            if (fieldMapping == null && indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta1)) {
+                throw new QueryParsingException(this, "Strict field resolution and no field mapping can be found for the field with name ["
+                        + name + "]");
+            } else {
+                return fieldMapping;
+            }
+        }
+    }
+
+    /**
+     * Returns the narrowed down explicit types, or, if not set, all types.
+     */
+    public Collection<String> queryTypes() {
+        String[] types = getTypes();
+        if (types == null || types.length == 0) {
+            return mapperService().types();
+        }
+        if (types.length == 1 && types[0].equals("_all")) {
+            return mapperService().types();
+        }
+        return Arrays.asList(types);
+    }
+
+    private SearchLookup lookup = null;
+
+    public SearchLookup lookup() {
+        SearchContext current = SearchContext.current();
+        if (current != null) {
+            return current.lookup();
+        }
+        if (lookup == null) {
+            lookup = new SearchLookup(mapperService(), indexQueryParser.fieldDataService, null);
+        }
+        return lookup;
+    }
+
+    public long nowInMillis() {
+        SearchContext current = SearchContext.current();
+        if (current != null) {
+            return current.nowInMillis();
+        }
+        return System.currentTimeMillis();
+    }
+
+    public NestedScope nestedScope() {
+        return nestedScope;
+    }
+
+    /**
+     * Return whether the setting is deprecated.
+     */
+    public boolean isDeprecatedSetting(String setting) {
+        return parseFieldMatcher.match(setting, CACHE) || parseFieldMatcher.match(setting, CACHE_KEY);
     }
 
-    QueryParser queryParser(String name) {
-        return indicesQueriesRegistry.queryParsers().get(name);
+    public Version indexVersionCreated() {
+        return indexVersionCreated;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParser.java b/core/src/main/java/org/elasticsearch/index/query/QueryParser.java
index d54971b..eff585a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParser.java
@@ -25,10 +25,9 @@ import org.elasticsearch.common.Nullable;
 import java.io.IOException;
 
 /**
- * Defines a query parser that is able to read and parse a query object in {@link org.elasticsearch.common.xcontent.XContent}
- * format and create an internal object representing the query, implementing {@link QueryBuilder}, which can be streamed to other nodes.
+ *
  */
-public interface QueryParser<QB extends QueryBuilder<QB>> {
+public interface QueryParser {
 
     /**
      * The names this query parser is registered under.
@@ -36,33 +35,11 @@ public interface QueryParser<QB extends QueryBuilder<QB>> {
     String[] names();
 
     /**
-     * Parses the into a query from the current parser location. Will be at
-     * "START_OBJECT" location, and should end when the token is at the matching
-     * "END_OBJECT".
+     * Parses the into a query from the current parser location. Will be at "START_OBJECT" location,
+     * and should end when the token is at the matching "END_OBJECT".
      * <p/>
-     * Returns <tt>null</tt> if this query should be ignored in the context of
-     * the DSL.
+     * Returns <tt>null</tt> if this query should be ignored in the context of the DSL.
      */
-    //norelease can be removed in favour of fromXContent once search requests can be parsed on the coordinating node
     @Nullable
-    Query parse(QueryShardContext context) throws IOException, QueryParsingException;
-
-    /**
-     * Creates a new {@link QueryBuilder} from the query held by the {@link QueryShardContext}
-     * in {@link org.elasticsearch.common.xcontent.XContent} format
-     *
-     * @param parseContext
-     *            the input parse context. The state on the parser contained in
-     *            this context will be changed as a side effect of this method
-     *            call
-     * @return the new QueryBuilder
-     * @throws IOException
-     * @throws QueryParsingException
-     */
-    QB fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException;
-
-    /**
-     * @return an empty {@link QueryBuilder} instance for this parser that can be used for deserialization
-     */
-    QB getBuilderPrototype();
+    Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException;
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java b/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java
index 80acae7..c606953 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryParsingException.java
@@ -31,8 +31,7 @@ import org.elasticsearch.rest.RestStatus;
 import java.io.IOException;
 
 /**
- * Exception that can be used when parsing queries with a given {@link QueryParseContext}.
- * Can contain information about location of the error.
+ *
  */
 public class QueryParsingException extends ElasticsearchException {
 
@@ -72,15 +71,9 @@ public class QueryParsingException extends ElasticsearchException {
         this.columnNumber = col;
     }
 
-    public QueryParsingException(StreamInput in) throws IOException{
-        super(in);
-        lineNumber = in.readInt();
-        columnNumber = in.readInt();
-    }
-
     /**
      * Line number of the location of the error
-     *
+     * 
      * @return the line number or -1 if unknown
      */
     public int getLineNumber() {
@@ -89,7 +82,7 @@ public class QueryParsingException extends ElasticsearchException {
 
     /**
      * Column number of the location of the error
-     *
+     * 
      * @return the column number or -1 if unknown
      */
     public int getColumnNumber() {
@@ -116,4 +109,11 @@ public class QueryParsingException extends ElasticsearchException {
         out.writeInt(lineNumber);
         out.writeInt(columnNumber);
     }
+
+    public QueryParsingException(StreamInput in) throws IOException{
+        super(in);
+        lineNumber = in.readInt();
+        columnNumber = in.readInt();
+    }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java b/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
deleted file mode 100644
index 025f24b..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
+++ /dev/null
@@ -1,338 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Maps;
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.queryparser.classic.MapperQueryParser;
-import org.apache.lucene.queryparser.classic.QueryParserSettings;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.join.BitSetProducer;
-import org.apache.lucene.search.similarities.Similarity;
-import org.elasticsearch.Version;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.index.analysis.AnalysisService;
-import org.elasticsearch.index.fielddata.IndexFieldData;
-import org.elasticsearch.index.mapper.*;
-import org.elasticsearch.index.mapper.core.StringFieldMapper;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
-import org.elasticsearch.index.query.support.NestedScope;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
-import org.elasticsearch.script.ExecutableScript;
-import org.elasticsearch.script.ScriptContext;
-import org.elasticsearch.script.ScriptService;
-import org.elasticsearch.script.Template;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.lookup.SearchLookup;
-
-import java.util.*;
-
-/**
- * Context object used to create lucene queries on the shard level.
- */
-public class QueryShardContext {
-
-    private static ThreadLocal<String[]> typesContext = new ThreadLocal<>();
-
-    public static void setTypes(String[] types) {
-        typesContext.set(types);
-    }
-
-    public static String[] getTypes() {
-        return typesContext.get();
-    }
-
-    public static String[] setTypesWithPrevious(String[] types) {
-        String[] old = typesContext.get();
-        setTypes(types);
-        return old;
-    }
-
-    public static void removeTypes() {
-        typesContext.remove();
-    }
-
-    private final Index index;
-
-    private final Version indexVersionCreated;
-
-    private final IndexQueryParserService indexQueryParser;
-
-    private final Map<String, Query> namedQueries = Maps.newHashMap();
-
-    private final MapperQueryParser queryParser = new MapperQueryParser(this);
-
-    private ParseFieldMatcher parseFieldMatcher;
-
-    private boolean allowUnmappedFields;
-
-    private boolean mapUnmappedFieldAsString;
-
-    private NestedScope nestedScope;
-
-    //norelease this should be possible to remove once query context are completely separated
-    private QueryParseContext parseContext;
-
-    boolean isFilter;
-
-    public QueryShardContext(Index index, IndexQueryParserService indexQueryParser) {
-        this.index = index;
-        this.indexVersionCreated = Version.indexCreated(indexQueryParser.indexSettings());
-        this.indexQueryParser = indexQueryParser;
-        this.parseContext = new QueryParseContext(this);
-    }
-
-    public void parseFieldMatcher(ParseFieldMatcher parseFieldMatcher) {
-        this.parseFieldMatcher = parseFieldMatcher;
-    }
-
-    public ParseFieldMatcher parseFieldMatcher() {
-        return parseFieldMatcher;
-    }
-
-    private void reset() {
-        allowUnmappedFields = indexQueryParser.defaultAllowUnmappedFields();
-        this.parseFieldMatcher = ParseFieldMatcher.EMPTY;
-        this.lookup = null;
-        this.namedQueries.clear();
-        this.nestedScope = new NestedScope();
-    }
-
-    //norelease remove parser argument once query contexts are separated
-    public void reset(XContentParser jp) {
-        this.reset();
-        this.parseContext.reset(jp);
-    }
-
-    public Index index() {
-        return this.index;
-    }
-
-    //norelease we might be able to avoid exposing the service to the outside world once all queries are refactored
-    public IndexQueryParserService indexQueryParserService() {
-        return indexQueryParser;
-    }
-
-    public AnalysisService analysisService() {
-        return indexQueryParser.analysisService;
-    }
-
-    public ScriptService scriptService() {
-        return indexQueryParser.scriptService;
-    }
-
-    public MapperService mapperService() {
-        return indexQueryParser.mapperService;
-    }
-
-    public Similarity searchSimilarity() {
-        return indexQueryParser.similarityService != null ? indexQueryParser.similarityService.similarity() : null;
-    }
-
-    public String defaultField() {
-        return indexQueryParser.defaultField();
-    }
-
-    public boolean queryStringLenient() {
-        return indexQueryParser.queryStringLenient();
-    }
-
-    public MapperQueryParser queryParser(QueryParserSettings settings) {
-        queryParser.reset(settings);
-        return queryParser;
-    }
-
-    public BitSetProducer bitsetFilter(Filter filter) {
-        return indexQueryParser.bitsetFilterCache.getBitSetProducer(filter);
-    }
-
-    public <IFD extends IndexFieldData<?>> IFD getForField(MappedFieldType mapper) {
-        return indexQueryParser.fieldDataService.getForField(mapper);
-    }
-
-    public void addNamedQuery(String name, Query query) {
-        if (query != null) {
-            namedQueries.put(name, query);
-        }
-    }
-
-    public ImmutableMap<String, Query> copyNamedQueries() {
-        return ImmutableMap.copyOf(namedQueries);
-    }
-
-    public void combineNamedQueries(QueryShardContext context) {
-        namedQueries.putAll(context.namedQueries);
-    }
-
-    /**
-     * Return whether we are currently parsing a filter or a query.
-     */
-    public boolean isFilter() {
-        return isFilter;
-    }
-
-    public void addInnerHits(String name, InnerHitsContext.BaseInnerHits context) {
-        SearchContext sc = SearchContext.current();
-        if (sc == null) {
-            throw new QueryShardException(this, "inner_hits unsupported");
-        }
-
-        InnerHitsContext innerHitsContext;
-        if (sc.innerHits() == null) {
-            innerHitsContext = new InnerHitsContext(new HashMap<String, InnerHitsContext.BaseInnerHits>());
-            sc.innerHits(innerHitsContext);
-        } else {
-            innerHitsContext = sc.innerHits();
-        }
-        innerHitsContext.addInnerHitDefinition(name, context);
-    }
-
-    public Collection<String> simpleMatchToIndexNames(String pattern) {
-        return indexQueryParser.mapperService.simpleMatchToIndexNames(pattern);
-    }
-
-    public MappedFieldType fieldMapper(String name) {
-        return failIfFieldMappingNotFound(name, indexQueryParser.mapperService.smartNameFieldType(name, getTypes()));
-    }
-
-    public ObjectMapper getObjectMapper(String name) {
-        return indexQueryParser.mapperService.getObjectMapper(name, getTypes());
-    }
-
-    /**
-     * Gets the search analyzer for the given field, or the default if there is none present for the field
-     * TODO: remove this by moving defaults into mappers themselves
-     */
-    public Analyzer getSearchAnalyzer(MappedFieldType fieldType) {
-        if (fieldType.searchAnalyzer() != null) {
-            return fieldType.searchAnalyzer();
-        }
-        return mapperService().searchAnalyzer();
-    }
-
-    /**
-     * Gets the search quote analyzer for the given field, or the default if there is none present for the field
-     * TODO: remove this by moving defaults into mappers themselves
-     */
-    public Analyzer getSearchQuoteAnalyzer(MappedFieldType fieldType) {
-        if (fieldType.searchQuoteAnalyzer() != null) {
-            return fieldType.searchQuoteAnalyzer();
-        }
-        return mapperService().searchQuoteAnalyzer();
-    }
-
-    public void setAllowUnmappedFields(boolean allowUnmappedFields) {
-        this.allowUnmappedFields = allowUnmappedFields;
-    }
-
-    public void setMapUnmappedFieldAsString(boolean mapUnmappedFieldAsString) {
-        this.mapUnmappedFieldAsString = mapUnmappedFieldAsString;
-    }
-
-    private MappedFieldType failIfFieldMappingNotFound(String name, MappedFieldType fieldMapping) {
-        if (allowUnmappedFields) {
-            return fieldMapping;
-        } else if (mapUnmappedFieldAsString) {
-            StringFieldMapper.Builder builder = MapperBuilders.stringField(name);
-            // it would be better to pass the real index settings, but they are not easily accessible from here...
-            Settings settings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, indexQueryParser.getIndexCreatedVersion()).build();
-            return builder.build(new Mapper.BuilderContext(settings, new ContentPath(1))).fieldType();
-        } else {
-            Version indexCreatedVersion = indexQueryParser.getIndexCreatedVersion();
-            if (fieldMapping == null && indexCreatedVersion.onOrAfter(Version.V_1_4_0_Beta1)) {
-                throw new QueryShardException(this, "Strict field resolution and no field mapping can be found for the field with name ["
-                        + name + "]");
-            } else {
-                return fieldMapping;
-            }
-        }
-    }
-
-    /**
-     * Returns the narrowed down explicit types, or, if not set, all types.
-     */
-    public Collection<String> queryTypes() {
-        String[] types = getTypes();
-        if (types == null || types.length == 0) {
-            return mapperService().types();
-        }
-        if (types.length == 1 && types[0].equals("_all")) {
-            return mapperService().types();
-        }
-        return Arrays.asList(types);
-    }
-
-    private SearchLookup lookup = null;
-
-    public SearchLookup lookup() {
-        SearchContext current = SearchContext.current();
-        if (current != null) {
-            return current.lookup();
-        }
-        if (lookup == null) {
-            lookup = new SearchLookup(mapperService(), indexQueryParser.fieldDataService, null);
-        }
-        return lookup;
-    }
-
-    public long nowInMillis() {
-        SearchContext current = SearchContext.current();
-        if (current != null) {
-            return current.nowInMillis();
-        }
-        return System.currentTimeMillis();
-    }
-
-    public NestedScope nestedScope() {
-        return nestedScope;
-    }
-
-    public Version indexVersionCreated() {
-        return indexVersionCreated;
-    }
-
-    public QueryParseContext parseContext() {
-        return this.parseContext;
-    }
-
-    public boolean matchesIndices(String... indices) {
-        return this.indexQueryParser.matchesIndices(indices);
-    }
-
-    public List<Object> handleTermsLookup(TermsLookup termsLookup) {
-        return this.indexQueryParser.handleTermsLookup(termsLookup);
-    }
-
-    /*
-    * Executes the given template, and returns the response.
-    */
-    public BytesReference executeQueryTemplate(Template template, SearchContext searchContext) {
-        ExecutableScript executable = scriptService().executable(template, ScriptContext.Standard.SEARCH, searchContext);
-        return (BytesReference) executable.run();
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryShardException.java b/core/src/main/java/org/elasticsearch/index/query/QueryShardException.java
deleted file mode 100644
index 1e31c7c..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryShardException.java
+++ /dev/null
@@ -1,72 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.rest.RestStatus;
-
-import java.io.IOException;
-
-/**
- * Exception that is thrown when creating lucene queries on the shard
- */
-public class QueryShardException extends ElasticsearchException {
-
-    public QueryShardException(QueryShardContext context, String msg, Object... args) {
-        this(context, msg, null, args);
-    }
-
-    public QueryShardException(QueryShardContext context, String msg, Throwable cause, Object... args) {
-        super(msg, cause, args);
-        setIndex(context.index());
-    }
-
-    /**
-     * This constructor is provided for use in unit tests where a
-     * {@link QueryShardContext} may not be available
-     */
-    public QueryShardException(Index index, String msg, Throwable cause) {
-        super(msg, cause);
-        setIndex(index);
-    }
-
-    public QueryShardException(StreamInput in) throws IOException{
-        super(in);
-    }
-
-    @Override
-    public RestStatus status() {
-        return RestStatus.BAD_REQUEST;
-    }
-
-    @Override
-    protected void innerToXContent(XContentBuilder builder, Params params) throws IOException {
-        super.innerToXContent(builder, params);
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        super.writeTo(out);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java
index a6efa2f..c7a297e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryBuilder.java
@@ -36,9 +36,12 @@ import java.util.Locale;
  * them either using DisMax or a plain boolean query (see {@link #useDisMax(boolean)}).
  * <p/>
  */
-public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQueryBuilder> {
+public class QueryStringQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<QueryStringQueryBuilder> {
 
-    public static final String NAME = "query_string";
+    public enum Operator {
+        OR,
+        AND
+    }
 
     private final String queryString;
 
@@ -63,6 +66,8 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
 
     private Locale locale;
 
+    private float boost = -1;
+
     private Fuzziness fuzziness;
     private int fuzzyPrefixLength = -1;
     private int fuzzyMaxExpansions = -1;
@@ -84,14 +89,14 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
 
     private Boolean lenient;
 
-    private String timeZone;
+    private String queryName;
 
-    private Boolean escape;
+    private String timeZone;
 
     /** To limit effort spent determinizing regexp queries. */
     private Integer maxDeterminizedStates;
 
-    static final QueryStringQueryBuilder PROTOTYPE = new QueryStringQueryBuilder(null);
+    private Boolean escape;
 
     public QueryStringQueryBuilder(String queryString) {
         this.queryString = queryString;
@@ -289,6 +294,16 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
     }
 
     /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
+    @Override
+    public QueryStringQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
      * An optional field name suffix to automatically try and add to the field searched when using quoted text.
      */
     public QueryStringQueryBuilder quoteFieldSuffix(String quoteFieldSuffix) {
@@ -305,6 +320,14 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         return this;
     }
 
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public QueryStringQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
     public QueryStringQueryBuilder locale(Locale locale) {
         this.locale = locale;
         return this;
@@ -328,7 +351,7 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(QueryStringQueryParser.NAME);
         builder.field("query", queryString);
         if (defaultField != null) {
             builder.field("default_field", defaultField);
@@ -376,6 +399,9 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         if (fuzziness != null) {
             fuzziness.toXContent(builder, params);
         }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
         if (fuzzyPrefixLength != -1) {
             builder.field("fuzzy_prefix_length", fuzzyPrefixLength);
         }
@@ -403,6 +429,9 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         if (lenient != null) {
             builder.field("lenient", lenient);
         }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
         if (locale != null) {
             builder.field("locale", locale.toString());
         }
@@ -412,12 +441,6 @@ public class QueryStringQueryBuilder extends AbstractQueryBuilder<QueryStringQue
         if (escape != null) {
             builder.field("escape", escape);
         }
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java
index dcca133..64afdd2 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryStringQueryParser.java
@@ -46,8 +46,9 @@ import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfN
 /**
  *
  */
-public class QueryStringQueryParser extends BaseQueryParserTemp {
+public class QueryStringQueryParser implements QueryParser {
 
+    public static final String NAME = "query_string";
     private static final ParseField FUZZINESS = Fuzziness.FIELD.withDeprecation("fuzzy_min_sim");
 
     private final boolean defaultAnalyzeWildcard;
@@ -61,18 +62,17 @@ public class QueryStringQueryParser extends BaseQueryParserTemp {
 
     @Override
     public String[] names() {
-        return new String[]{QueryStringQueryBuilder.NAME, Strings.toCamelCase(QueryStringQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String queryName = null;
         QueryParserSettings qpSettings = new QueryParserSettings();
-        qpSettings.defaultField(context.defaultField());
-        qpSettings.lenient(context.queryStringLenient());
+        qpSettings.defaultField(parseContext.defaultField());
+        qpSettings.lenient(parseContext.queryStringLenient());
         qpSettings.analyzeWildcard(defaultAnalyzeWildcard);
         qpSettings.allowLeadingWildcard(defaultAllowLeadingWildcard);
         qpSettings.locale(Locale.ROOT);
@@ -105,7 +105,7 @@ public class QueryStringQueryParser extends BaseQueryParserTemp {
                         }
 
                         if (Regex.isSimpleMatchPattern(fField)) {
-                            for (String field : context.mapperService().simpleMatchToIndexNames(fField)) {
+                            for (String field : parseContext.mapperService().simpleMatchToIndexNames(fField)) {
                                 qpSettings.fields().add(field);
                                 if (fBoost != -1) {
                                     if (qpSettings.boosts() == null) {
@@ -143,13 +143,13 @@ public class QueryStringQueryParser extends BaseQueryParserTemp {
                         throw new QueryParsingException(parseContext, "Query default operator [" + op + "] is not allowed");
                     }
                 } else if ("analyzer".equals(currentFieldName)) {
-                    NamedAnalyzer analyzer = context.analysisService().analyzer(parser.text());
+                    NamedAnalyzer analyzer = parseContext.analysisService().analyzer(parser.text());
                     if (analyzer == null) {
                         throw new QueryParsingException(parseContext, "[query_string] analyzer [" + parser.text() + "] not found");
                     }
                     qpSettings.forcedAnalyzer(analyzer);
                 } else if ("quote_analyzer".equals(currentFieldName) || "quoteAnalyzer".equals(currentFieldName)) {
-                    NamedAnalyzer analyzer = context.analysisService().analyzer(parser.text());
+                    NamedAnalyzer analyzer = parseContext.analysisService().analyzer(parser.text());
                     if (analyzer == null) {
                         throw new QueryParsingException(parseContext, "[query_string] quote_analyzer [" + parser.text()
                                 + "] not found");
@@ -214,14 +214,14 @@ public class QueryStringQueryParser extends BaseQueryParserTemp {
         if (qpSettings.queryString() == null) {
             throw new QueryParsingException(parseContext, "query_string must be provided with a [query]");
         }
-        qpSettings.defaultAnalyzer(context.mapperService().searchAnalyzer());
-        qpSettings.defaultQuoteAnalyzer(context.mapperService().searchQuoteAnalyzer());
+        qpSettings.defaultAnalyzer(parseContext.mapperService().searchAnalyzer());
+        qpSettings.defaultQuoteAnalyzer(parseContext.mapperService().searchQuoteAnalyzer());
 
         if (qpSettings.escape()) {
             qpSettings.queryString(org.apache.lucene.queryparser.classic.QueryParser.escape(qpSettings.queryString()));
         }
 
-        MapperQueryParser queryParser = context.queryParser(qpSettings);
+        MapperQueryParser queryParser = parseContext.queryParser(qpSettings);
 
         try {
             Query query = queryParser.parse(qpSettings.queryString());
@@ -236,16 +236,11 @@ public class QueryStringQueryParser extends BaseQueryParserTemp {
                 query = Queries.applyMinimumShouldMatch((BooleanQuery) query, qpSettings.minimumShouldMatch());
             }
             if (queryName != null) {
-                context.addNamedQuery(queryName, query);
+                parseContext.addNamedQuery(queryName, query);
             }
             return query;
         } catch (org.apache.lucene.queryparser.classic.ParseException e) {
             throw new QueryParsingException(parseContext, "Failed to parse query [" + qpSettings.queryString() + "]", e);
         }
     }
-
-    @Override
-    public QueryStringQueryBuilder getBuilderPrototype() {
-        return QueryStringQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryValidationException.java b/core/src/main/java/org/elasticsearch/index/query/QueryValidationException.java
deleted file mode 100644
index 9e0ee2a..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryValidationException.java
+++ /dev/null
@@ -1,62 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.elasticsearch.common.ValidationException;
-
-import java.util.List;
-
-/**
- * This exception can be used to indicate various reasons why validation of a query has failed.
- */
-public class QueryValidationException extends ValidationException {
-
-    /**
-     * Helper method than can be used to add error messages to an existing {@link QueryValidationException}.
-     * When passing {@code null} as the initial exception, a new exception is created.
-     *
-     * @param queryId the query that caused the error
-     * @param validationError the error message to add to an initial exception
-     * @param validationException an initial exception. Can be {@code null}, in which case a new exception is created.
-     * @return a {@link QueryValidationException} with added validation error message
-     */
-    public static QueryValidationException addValidationError(String queryId, String validationError, QueryValidationException validationException) {
-        if (validationException == null) {
-            validationException = new QueryValidationException();
-        }
-        validationException.addValidationError("[" + queryId + "] " + validationError);
-        return validationException;
-    }
-
-    /**
-     * Helper method than can be used to add error messages to an existing {@link QueryValidationException}.
-     * When passing {@code null} as the initial exception, a new exception is created.
-     * @param validationErrors the error messages to add to an initial exception
-     * @param validationException an initial exception. Can be {@code null}, in which case a new exception is created.
-     * @return a {@link QueryValidationException} with added validation error message
-     */
-    public static QueryValidationException addValidationErrors(List<String> validationErrors, QueryValidationException validationException) {
-        if (validationException == null) {
-            validationException = new QueryValidationException();
-        }
-        validationException.addValidationErrors(validationErrors);
-        return validationException;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryWrappingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/QueryWrappingQueryBuilder.java
deleted file mode 100644
index e905de1..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/QueryWrappingQueryBuilder.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-
-import java.io.IOException;
-
-/**
- * QueryBuilder implementation that  holds a lucene query, which can be returned by {@link QueryBuilder#toQuery(QueryShardContext)}.
- * Doesn't support conversion to {@link org.elasticsearch.common.xcontent.XContent} via {@link #doXContent(XContentBuilder, Params)}.
- */
-//norelease to be removed once all queries support separate fromXContent and toQuery methods. Make AbstractQueryBuilder#toQuery final as well then.
-public class QueryWrappingQueryBuilder extends AbstractQueryBuilder<QueryWrappingQueryBuilder> implements SpanQueryBuilder<QueryWrappingQueryBuilder>, MultiTermQueryBuilder<QueryWrappingQueryBuilder>{
-
-    private Query query;
-
-    public QueryWrappingQueryBuilder(Query query) {
-        this.query = query;
-    }
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return query;
-    }
-
-    @Override
-    public String getWriteableName() {
-        // this should not be called since we overwrite BaseQueryBuilder#toQuery() in this class
-        throw new UnsupportedOperationException();
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        //no-op the wrapper lucene query has already its boost set
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java
index 0db4152..da23698 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RangeQueryBuilder.java
@@ -19,111 +19,187 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermRangeQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.joda.DateMathParser;
-import org.elasticsearch.common.joda.Joda;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.core.DateFieldMapper;
-import org.joda.time.DateTimeZone;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that matches documents within an range of terms.
  */
-public class RangeQueryBuilder extends AbstractQueryBuilder<RangeQueryBuilder> implements MultiTermQueryBuilder<RangeQueryBuilder> {
+public class RangeQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<RangeQueryBuilder> {
 
-    public static final boolean DEFAULT_INCLUDE_UPPER = true;
+    private final String name;
+    private Object from;
+    private Object to;
+    private String timeZone;
+    private boolean includeLower = true;
+    private boolean includeUpper = true;
+    private float boost = -1;
+    private String queryName;
+    private String format;
 
-    public static final boolean DEFAULT_INCLUDE_LOWER = true;
+    /**
+     * A Query that matches documents within an range of terms.
+     *
+     * @param name The field name
+     */
+    public RangeQueryBuilder(String name) {
+        this.name = name;
+    }
 
-    public static final String NAME = "range";
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(Object from) {
+        this.from = from;
+        return this;
+    }
 
-    private final String fieldName;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(String from) {
+        this.from = from;
+        return this;
+    }
 
-    private Object from;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(int from) {
+        this.from = from;
+        return this;
+    }
 
-    private Object to;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(long from) {
+        this.from = from;
+        return this;
+    }
 
-    private String timeZone;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(float from) {
+        this.from = from;
+        return this;
+    }
 
-    private boolean includeLower = DEFAULT_INCLUDE_LOWER;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder from(double from) {
+        this.from = from;
+        return this;
+    }
 
-    private boolean includeUpper = DEFAULT_INCLUDE_UPPER;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gt(String from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
+    }
 
-    private String format;
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gt(Object from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
+    }
 
-    static final RangeQueryBuilder PROTOTYPE = new RangeQueryBuilder(null);
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gt(int from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
+    }
 
     /**
-     * A Query that matches documents within an range of terms.
-     *
-     * @param fieldName The field name
+     * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder(String fieldName) {
-        this.fieldName = fieldName;
+    public RangeQueryBuilder gt(long from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
     }
 
     /**
-     * Get the field name for this query.
+     * The from part of the range query. Null indicates unbounded.
      */
-    public String fieldName() {
-        return this.fieldName;
+    public RangeQueryBuilder gt(float from) {
+        this.from = from;
+        this.includeLower = false;
+        return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
-     * In case lower bound is assigned to a string, we internally convert it to a {@link BytesRef} because
-     * in {@link RangeQueryParser} field are later parsed as {@link BytesRef} and we need internal representation
-     * of query to be equal regardless of whether it was created from XContent or via Java API.
      */
-    public RangeQueryBuilder from(Object from, boolean includeLower) {
-        this.from = convertToBytesRefIfString(from);
-        this.includeLower = includeLower;
+    public RangeQueryBuilder gt(double from) {
+        this.from = from;
+        this.includeLower = false;
         return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder from(Object from) {
-        return from(from, this.includeLower);
+    public RangeQueryBuilder gte(String from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
-     * Gets the lower range value for this query.
+     * The from part of the range query. Null indicates unbounded.
      */
-    public Object from() {
-        return convertToStringIfBytesRef(this.from);
+    public RangeQueryBuilder gte(Object from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder gt(Object from) {
-        return from(from, false);
+    public RangeQueryBuilder gte(int from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
      * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder gte(Object from) {
-        return from(from, true);
+    public RangeQueryBuilder gte(long from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
     }
 
     /**
-     * The to part of the range query. Null indicates unbounded.
+     * The from part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder to(Object to, boolean includeUpper) {
-        this.to = convertToBytesRefIfString(to);
-        this.includeUpper = includeUpper;
+    public RangeQueryBuilder gte(float from) {
+        this.from = from;
+        this.includeLower = true;
+        return this;
+    }
+
+    /**
+     * The from part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder gte(double from) {
+        this.from = from;
+        this.includeLower = true;
         return this;
     }
 
@@ -131,214 +207,229 @@ public class RangeQueryBuilder extends AbstractQueryBuilder<RangeQueryBuilder> i
      * The to part of the range query. Null indicates unbounded.
      */
     public RangeQueryBuilder to(Object to) {
-        return to(to, this.includeUpper);
+        this.to = to;
+        return this;
     }
 
     /**
-     * Gets the upper range value for this query.
-     * In case upper bound is assigned to a string, we internally convert it to a {@link BytesRef} because
-     * in {@link RangeQueryParser} field are later parsed as {@link BytesRef} and we need internal representation
-     * of query to be equal regardless of whether it was created from XContent or via Java API.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public Object to() {
-        return convertToStringIfBytesRef(this.to);
+    public RangeQueryBuilder to(String to) {
+        this.to = to;
+        return this;
     }
 
     /**
      * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder lt(Object to) {
-        return to(to, false);
+    public RangeQueryBuilder to(int to) {
+        this.to = to;
+        return this;
     }
 
     /**
      * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder lte(Object to) {
-        return to(to, true);
+    public RangeQueryBuilder to(long to) {
+        this.to = to;
+        return this;
     }
 
     /**
-     * Should the lower bound be included or not. Defaults to <tt>true</tt>.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder includeLower(boolean includeLower) {
-        this.includeLower = includeLower;
+    public RangeQueryBuilder to(float to) {
+        this.to = to;
         return this;
     }
 
     /**
-     * Gets the includeLower flag for this query.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public boolean includeLower() {
-        return this.includeLower;
+    public RangeQueryBuilder to(double to) {
+        this.to = to;
+        return this;
     }
 
     /**
-     * Should the upper bound be included or not. Defaults to <tt>true</tt>.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder includeUpper(boolean includeUpper) {
-        this.includeUpper = includeUpper;
+    public RangeQueryBuilder lt(String to) {
+        this.to = to;
+        this.includeUpper = false;
         return this;
     }
 
     /**
-     * Gets the includeUpper flag for this query.
+     * The to part of the range query. Null indicates unbounded.
      */
-    public boolean includeUpper() {
-        return this.includeUpper;
+    public RangeQueryBuilder lt(Object to) {
+        this.to = to;
+        this.includeUpper = false;
+        return this;
     }
 
     /**
-     * In case of date field, we can adjust the from/to fields using a timezone
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder timeZone(String timezone) {
-        this.timeZone = timezone;
+    public RangeQueryBuilder lt(int to) {
+        this.to = to;
+        this.includeUpper = false;
         return this;
     }
 
     /**
-     * In case of date field, gets the from/to fields timezone adjustment
+     * The to part of the range query. Null indicates unbounded.
      */
-    public String timeZone() {
-        return this.timeZone;
+    public RangeQueryBuilder lt(long to) {
+        this.to = to;
+        this.includeUpper = false;
+        return this;
     }
 
     /**
-     * In case of format field, we can parse the from/to fields using this time format
+     * The to part of the range query. Null indicates unbounded.
      */
-    public RangeQueryBuilder format(String format) {
-        this.format = format;
+    public RangeQueryBuilder lt(float to) {
+        this.to = to;
+        this.includeUpper = false;
         return this;
     }
 
     /**
-     * Gets the format field to parse the from/to fields
+     * The to part of the range query. Null indicates unbounded.
      */
-    public String format() {
-        return this.format;
+    public RangeQueryBuilder lt(double to) {
+        this.to = to;
+        this.includeUpper = false;
+        return this;
     }
 
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("from", convertToStringIfBytesRef(this.from));
-        builder.field("to", convertToStringIfBytesRef(this.to));
-        builder.field("include_lower", includeLower);
-        builder.field("include_upper", includeUpper);
-        if (timeZone != null) {
-            builder.field("time_zone", timeZone);
-        }
-        if (format != null) {
-            builder.field("format", format);
-        }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(String to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(Object to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query query = null;
-        MappedFieldType mapper = context.fieldMapper(this.fieldName);
-        if (mapper != null) {
-            if (mapper instanceof DateFieldMapper.DateFieldType) {
-                DateMathParser forcedDateParser = null;
-                if (this.format  != null) {
-                    forcedDateParser = new DateMathParser(Joda.forPattern(this.format));
-                }
-                DateTimeZone dateTimeZone = null;
-                if (this.timeZone != null) {
-                    dateTimeZone = DateTimeZone.forID(this.timeZone);
-                }
-                query = ((DateFieldMapper.DateFieldType) mapper).rangeQuery(from, to, includeLower, includeUpper, dateTimeZone, forcedDateParser);
-            } else  {
-                if (timeZone != null) {
-                    throw new QueryShardException(context, "[range] time_zone can not be applied to non date field ["
-                            + fieldName + "]");
-                }
-                //LUCENE 4 UPGRADE Mapper#rangeQuery should use bytesref as well?
-                query = mapper.rangeQuery(from, to, includeLower, includeUpper);
-            }
-        } else {
-            if (timeZone != null) {
-                throw new QueryShardException(context, "[range] time_zone can not be applied to non unmapped field ["
-                        + fieldName + "]");
-            }
-        }
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(int to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
+    }
 
-        if (query == null) {
-            query = new TermRangeQuery(this.fieldName, BytesRefs.toBytesRef(from), BytesRefs.toBytesRef(to), includeLower, includeUpper);
-        }
-        return query;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(long to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.fieldName == null || this.fieldName.isEmpty()) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.timeZone != null) {
-            try {
-                DateTimeZone.forID(this.timeZone);
-            } catch (Exception e) {
-                validationException = addValidationError("error parsing timezone." + e.getMessage(),
-                        validationException);
-            }
-        }
-        if (this.format != null) {
-            try {
-                Joda.forPattern(this.format);
-            } catch (Exception e) {
-                validationException = addValidationError("error parsing format." + e.getMessage(),
-                        validationException);
-            }
-        }
-        return validationException;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(float to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    protected RangeQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        RangeQueryBuilder rangeQueryBuilder = new RangeQueryBuilder(in.readString());
-        rangeQueryBuilder.from = in.readGenericValue();
-        rangeQueryBuilder.to = in.readGenericValue();
-        rangeQueryBuilder.includeLower = in.readBoolean();
-        rangeQueryBuilder.includeUpper = in.readBoolean();
-        rangeQueryBuilder.timeZone = in.readOptionalString();
-        rangeQueryBuilder.format = in.readOptionalString();
-        return rangeQueryBuilder;
+    /**
+     * The to part of the range query. Null indicates unbounded.
+     */
+    public RangeQueryBuilder lte(double to) {
+        this.to = to;
+        this.includeUpper = true;
+        return this;
     }
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(this.fieldName);
-        out.writeGenericValue(this.from);
-        out.writeGenericValue(this.to);
-        out.writeBoolean(this.includeLower);
-        out.writeBoolean(this.includeUpper);
-        out.writeOptionalString(this.timeZone);
-        out.writeOptionalString(this.format);
+    /**
+     * Should the lower bound be included or not. Defaults to <tt>true</tt>.
+     */
+    public RangeQueryBuilder includeLower(boolean includeLower) {
+        this.includeLower = includeLower;
+        return this;
     }
 
+    /**
+     * Should the upper bound be included or not. Defaults to <tt>true</tt>.
+     */
+    public RangeQueryBuilder includeUpper(boolean includeUpper) {
+        this.includeUpper = includeUpper;
+        return this;
+    }
+
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, from, to, timeZone, includeLower, includeUpper, format);
+    public RangeQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public RangeQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
+    /**
+     * In case of date field, we can adjust the from/to fields using a timezone
+     */
+    public RangeQueryBuilder timeZone(String timezone) {
+        this.timeZone = timezone;
+        return this;
+    }
+
+    /**
+     * In case of date field, we can set the format to be used instead of the mapper format
+     */
+    public RangeQueryBuilder format(String format) {
+        this.format = format;
+        return this;
     }
 
     @Override
-    protected boolean doEquals(RangeQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-               Objects.equals(from, other.from) &&
-               Objects.equals(to, other.to) &&
-               Objects.equals(timeZone, other.timeZone) &&
-               Objects.equals(includeLower, other.includeLower) &&
-               Objects.equals(includeUpper, other.includeUpper) &&
-               Objects.equals(format, other.format);
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(RangeQueryParser.NAME);
+        builder.startObject(name);
+        builder.field("from", from);
+        builder.field("to", to);
+        if (timeZone != null) {
+            builder.field("time_zone", timeZone);
+        }
+        if (format != null) {
+            builder.field("format", format);
+        }
+        builder.field("include_lower", includeLower);
+        builder.field("include_upper", includeUpper);
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
+        builder.endObject();
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java
index d10f6b0..355f9f2 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RangeQueryParser.java
@@ -19,17 +19,26 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermRangeQuery;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.joda.DateMathParser;
+import org.elasticsearch.common.joda.Joda;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.core.DateFieldMapper;
+import org.joda.time.DateTimeZone;
 
 import java.io.IOException;
 
 /**
- * Parser for range query
+ *
  */
-public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
+public class RangeQueryParser implements QueryParser {
 
+    public static final String NAME = "range";
     private static final ParseField FIELDDATA_FIELD = new ParseField("fielddata").withAllDeprecated("[no replacement]");
     private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of range query");
 
@@ -39,22 +48,22 @@ public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{RangeQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public RangeQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = null;
         Object from = null;
         Object to = null;
-        boolean includeLower = RangeQueryBuilder.DEFAULT_INCLUDE_LOWER;
-        boolean includeUpper = RangeQueryBuilder.DEFAULT_INCLUDE_UPPER;
-        String timeZone = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        boolean includeLower = true;
+        boolean includeUpper = true;
+        DateTimeZone timeZone = null;
+        DateMathParser forcedDateParser = null;
+        float boost = 1.0f;
         String queryName = null;
-        String format = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -92,11 +101,9 @@ public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
                             to = parser.objectBytes();
                             includeUpper = true;
                         } else if ("time_zone".equals(currentFieldName) || "timeZone".equals(currentFieldName)) {
-                            timeZone = parser.text();
+                            timeZone = DateTimeZone.forID(parser.text());
                         } else if ("format".equals(currentFieldName)) {
-                            format = parser.text();
-                        } else if ("_name".equals(currentFieldName)) {
-                            queryName = parser.text();
+                            forcedDateParser = new DateMathParser(Joda.forPattern(parser.text()));
                         } else {
                             throw new QueryParsingException(parseContext, "[range] query does not support [" + currentFieldName + "]");
                         }
@@ -113,20 +120,27 @@ public class RangeQueryParser extends BaseQueryParser<RangeQueryBuilder> {
             }
         }
 
-        RangeQueryBuilder rangeQuery = new RangeQueryBuilder(fieldName);
-        rangeQuery.from(from);
-        rangeQuery.to(to);
-        rangeQuery.includeLower(includeLower);
-        rangeQuery.includeUpper(includeUpper);
-        rangeQuery.timeZone(timeZone);
-        rangeQuery.boost(boost);
-        rangeQuery.queryName(queryName);
-        rangeQuery.format(format);
-        return rangeQuery;
-    }
-
-    @Override
-    public RangeQueryBuilder getBuilderPrototype() {
-        return RangeQueryBuilder.PROTOTYPE;
+        Query query = null;
+        MappedFieldType mapper = parseContext.fieldMapper(fieldName);
+        if (mapper != null) {
+            if (mapper instanceof DateFieldMapper.DateFieldType) {
+                query = ((DateFieldMapper.DateFieldType) mapper).rangeQuery(from, to, includeLower, includeUpper, timeZone, forcedDateParser);
+            } else  {
+                if (timeZone != null) {
+                    throw new QueryParsingException(parseContext, "[range] time_zone can not be applied to non date field ["
+                            + fieldName + "]");
+                }
+                //LUCENE 4 UPGRADE Mapper#rangeQuery should use bytesref as well?
+                query = mapper.rangeQuery(from, to, includeLower, includeUpper);
+            }
+        }
+        if (query == null) {
+            query = new TermRangeQuery(fieldName, BytesRefs.toBytesRef(from), BytesRefs.toBytesRef(to), includeLower, includeUpper);
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java
index 6399089..ee143eb 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryBuilder.java
@@ -19,73 +19,48 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.RegexpQuery;
 import org.apache.lucene.util.automaton.Operations;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * A Query that does fuzzy matching for a specific value.
  */
-public class RegexpQueryBuilder extends AbstractQueryBuilder<RegexpQueryBuilder> implements MultiTermQueryBuilder<RegexpQueryBuilder> {
+public class RegexpQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<RegexpQueryBuilder> {
 
-    public static final String NAME = "regexp";
+    private final String name;
+    private final String regexp;
 
-    public static final int DEFAULT_FLAGS_VALUE = RegexpFlag.ALL.value();
-
-    public static final int DEFAULT_MAX_DETERMINIZED_STATES = Operations.DEFAULT_MAX_DETERMINIZED_STATES;
-
-    private final String fieldName;
-    
-    private final String value;
-    
-    private int flagsValue = DEFAULT_FLAGS_VALUE;
-    
-    private int maxDeterminizedStates = DEFAULT_MAX_DETERMINIZED_STATES;
-    
+    private int flags = RegexpQueryParser.DEFAULT_FLAGS_VALUE;
+    private float boost = -1;
     private String rewrite;
-    
-    static final RegexpQueryBuilder PROTOTYPE = new RegexpQueryBuilder(null, null);
+    private String queryName;
+    private int maxDeterminizedStates = Operations.DEFAULT_MAX_DETERMINIZED_STATES;
+    private boolean maxDetermizedStatesSet;
 
     /**
-     * Constructs a new regex query.
-     * 
-     * @param fieldName  The name of the field
-     * @param value The regular expression
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param regexp The regular expression
      */
-    public RegexpQueryBuilder(String fieldName, String value) {
-        this.fieldName = fieldName;
-        this.value = value;
-    }
-
-    /** Returns the field name used in this query. */
-    public String fieldName() {
-        return this.fieldName;
+    public RegexpQueryBuilder(String name, String regexp) {
+        this.name = name;
+        this.regexp = regexp;
     }
 
     /**
-     *  Returns the value used in this query.
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
      */
-    public String value() {
-        return this.value;
+    @Override
+    public RegexpQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     public RegexpQueryBuilder flags(RegexpFlag... flags) {
-        if (flags == null) {
-            this.flagsValue = DEFAULT_FLAGS_VALUE;
-            return this;
-        }
         int value = 0;
         if (flags.length == 0) {
             value = RegexpFlag.ALL.value;
@@ -94,120 +69,53 @@ public class RegexpQueryBuilder extends AbstractQueryBuilder<RegexpQueryBuilder>
                 value |= flag.value;
             }
         }
-        this.flagsValue = value;
-        return this;
-    }
-
-    public RegexpQueryBuilder flags(int flags) {
-        this.flagsValue = flags;
+        this.flags = value;
         return this;
     }
 
-    public int flags() {
-        return this.flagsValue;
-    }
-
     /**
      * Sets the regexp maxDeterminizedStates.
      */
     public RegexpQueryBuilder maxDeterminizedStates(int value) {
         this.maxDeterminizedStates = value;
+        this.maxDetermizedStatesSet = true;
         return this;
     }
-    
-    public int maxDeterminizedStates() {
-        return this.maxDeterminizedStates;
-    }
 
     public RegexpQueryBuilder rewrite(String rewrite) {
         this.rewrite = rewrite;
         return this;
     }
-    
-    public String rewrite() {
-        return this.rewrite;
+
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public RegexpQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("value", this.value);
-        builder.field("flags_value", flagsValue);
-        builder.field("max_determinized_states", maxDeterminizedStates);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
+        builder.startObject(RegexpQueryParser.NAME);
+        builder.startObject(name);
+        builder.field("value", regexp);
+        if (flags != -1) {
+            builder.field("flags_value", flags);
         }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    public Query doToQuery(QueryShardContext context) throws QueryShardException, IOException {
-        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-
-        Query query = null;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            query = fieldType.regexpQuery(value, flagsValue, maxDeterminizedStates, method, context);
+        if (maxDetermizedStatesSet) {
+            builder.field("max_determinized_states", maxDeterminizedStates);
         }
-        if (query == null) {
-            RegexpQuery regexpQuery = new RegexpQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), flagsValue, maxDeterminizedStates);
-            if (method != null) {
-                regexpQuery.setRewriteMethod(method);
-            }
-            query = regexpQuery;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
+        if (rewrite != null) {
+            builder.field("rewrite", rewrite);
         }
-        if (this.value == null) {
-            validationException = addValidationError("query text cannot be null", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    public RegexpQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        RegexpQueryBuilder regexpQueryBuilder = new RegexpQueryBuilder(in.readString(), in.readString());
-        regexpQueryBuilder.flagsValue = in.readVInt();
-        regexpQueryBuilder.maxDeterminizedStates = in.readVInt();
-        regexpQueryBuilder.rewrite = in.readOptionalString();
-        return regexpQueryBuilder;
-    }
-
-    @Override
-    public void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeString(value);
-        out.writeVInt(flagsValue);
-        out.writeVInt(maxDeterminizedStates);
-        out.writeOptionalString(rewrite);
-    }
-
-    @Override
-    public int doHashCode() {
-        return Objects.hash(fieldName, value, flagsValue, maxDeterminizedStates, rewrite);
-    }
-
-    @Override
-    public boolean doEquals(RegexpQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(flagsValue, other.flagsValue) &&
-                Objects.equals(maxDeterminizedStates, other.maxDeterminizedStates) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java
index 66fd44a..5844c17 100644
--- a/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/RegexpQueryParser.java
@@ -19,16 +19,28 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.RegexpQuery;
+import org.apache.lucene.util.automaton.Operations;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
 /**
- * Parser for regexp query
+ *
  */
-public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
+public class RegexpQueryParser implements QueryParser {
+
+    public static final String NAME = "regexp";
+
+    public static final int DEFAULT_FLAGS_VALUE = RegexpFlag.ALL.value();
 
     private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of regexp query");
 
@@ -38,20 +50,20 @@ public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{RegexpQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public RegexpQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String fieldName = parser.currentName();
-        String rewrite = null;
+        String rewriteMethod = null;
 
         String value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        int flagsValue = RegexpQueryBuilder.DEFAULT_FLAGS_VALUE;
-        int maxDeterminizedStates = RegexpQueryBuilder.DEFAULT_MAX_DETERMINIZED_STATES;
+        float boost = 1.0f;
+        int flagsValue = DEFAULT_FLAGS_VALUE;
+        int maxDeterminizedStates = Operations.DEFAULT_MAX_DETERMINIZED_STATES;
         String queryName = null;
         String currentFieldName = null;
         XContentParser.Token token;
@@ -71,7 +83,7 @@ public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
                         } else if ("boost".equals(currentFieldName)) {
                             boost = parser.floatValue();
                         } else if ("rewrite".equals(currentFieldName)) {
-                            rewrite = parser.textOrNull();
+                            rewriteMethod = parser.textOrNull();
                         } else if ("flags".equals(currentFieldName)) {
                             String flags = parser.textOrNull();
                             flagsValue = RegexpFlag.resolveValue(flags);
@@ -99,16 +111,27 @@ public class RegexpQueryParser extends BaseQueryParser<RegexpQueryBuilder> {
         if (value == null) {
             throw new QueryParsingException(parseContext, "No value specified for regexp query");
         }
-        return new RegexpQueryBuilder(fieldName, value)
-                .flags(flagsValue)
-                .maxDeterminizedStates(maxDeterminizedStates)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    @Override
-    public RegexpQueryBuilder getBuilderPrototype() {
-        return RegexpQueryBuilder.PROTOTYPE;
+        MultiTermQuery.RewriteMethod method = QueryParsers.parseRewriteMethod(parseContext.parseFieldMatcher(), rewriteMethod, null);
+
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.regexpQuery(value, flagsValue, maxDeterminizedStates, method, parseContext);
+        }
+        if (query == null) {
+            RegexpQuery regexpQuery = new RegexpQuery(new Term(fieldName, BytesRefs.toBytesRef(value)), flagsValue, maxDeterminizedStates);
+            if (method != null) {
+                regexpQuery.setRewriteMethod(method);
+            }
+            query = regexpQuery;
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
+
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/ScoreType.java b/core/src/main/java/org/elasticsearch/index/query/ScoreType.java
new file mode 100644
index 0000000..6286a9d
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/query/ScoreType.java
@@ -0,0 +1,71 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.index.query;
+
+
+/**
+ * Defines how scores from child documents are mapped into the parent document.
+ */
+public enum ScoreType {
+    /**
+     * Only the lowest score of all matching child documents is mapped into the
+     * parent.
+     */
+    MIN,
+    /**
+     * Only the highest score of all matching child documents is mapped into the
+     * parent.
+     */
+    MAX,
+
+    /**
+     * The average score based on all matching child documents are mapped into
+     * the parent.
+     */
+    AVG,
+
+    /**
+     * The matching children scores is summed up and mapped into the parent.
+     */
+    SUM,
+
+    /**
+     * Scores are not taken into account
+     */
+    NONE;
+
+
+    public static ScoreType fromString(String type) {
+        if ("none".equals(type)) {
+            return NONE;
+        } else if ("min".equals(type)) {
+            return MIN;
+        } else if ("max".equals(type)) {
+            return MAX;
+        } else if ("avg".equals(type)) {
+            return AVG;
+        } else if ("sum".equals(type)) {
+            return SUM;
+        } else if ("total".equals(type)) { // This name is consistent with: ScoreMode.Total
+            return SUM;
+        }
+        throw new IllegalArgumentException("No score type for child query [" + type + "] found");
+    }
+
+}
diff --git a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java
index 519f065..a9a35ac 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryBuilder.java
@@ -19,155 +19,40 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.RandomAccessWeight;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.util.Bits;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.script.*;
+import org.elasticsearch.script.Script;
 import org.elasticsearch.script.Script.ScriptField;
-import org.elasticsearch.search.lookup.SearchLookup;
 
 import java.io.IOException;
-import java.util.Objects;
+import java.util.HashMap;
+import java.util.Map;
 
-public class ScriptQueryBuilder extends AbstractQueryBuilder<ScriptQueryBuilder> {
+public class ScriptQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "script";
+    private Script script;
 
-    static final ScriptQueryBuilder PROTOTYPE = new ScriptQueryBuilder(null);
-
-    private final Script script;
+    private String queryName;
 
     public ScriptQueryBuilder(Script script) {
         this.script = script;
     }
 
-    public Script script() {
-        return this.script;
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public ScriptQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params builderParams) throws IOException {
-        builder.startObject(NAME);
-        builder.field(ScriptField.SCRIPT.getPreferredName(), script);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        return new ScriptQuery(script, context.scriptService(), context.lookup());
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.script == null) {
-            validationException = addValidationError("script cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    static class ScriptQuery extends Query {
-
-        private final Script script;
-
-        private final SearchScript searchScript;
-
-        public ScriptQuery(Script script, ScriptService scriptService, SearchLookup searchLookup) {
-            this.script = script;
-            this.searchScript = scriptService.search(searchLookup, script, ScriptContext.Standard.SEARCH);
-        }
-
-        @Override
-        public String toString(String field) {
-            StringBuilder buffer = new StringBuilder();
-            buffer.append("ScriptFilter(");
-            buffer.append(script);
-            buffer.append(")");
-            return buffer.toString();
-        }
 
-        @Override
-        public boolean equals(Object obj) {
-            if (this == obj)
-                return true;
-            if (!super.equals(obj))
-                return false;
-            ScriptQuery other = (ScriptQuery) obj;
-            return Objects.equals(script, other.script);
-        }
-
-        @Override
-        public int hashCode() {
-            final int prime = 31;
-            int result = super.hashCode();
-            result = prime * result + Objects.hashCode(script);
-            return result;
-        }
-
-        @Override
-        public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-            return new RandomAccessWeight(this) {
-                @Override
-                protected Bits getMatchingDocs(final LeafReaderContext context) throws IOException {
-                    final LeafSearchScript leafScript = searchScript.getLeafSearchScript(context);
-                    return new Bits() {
-
-                        @Override
-                        public boolean get(int doc) {
-                            leafScript.setDocument(doc);
-                            Object val = leafScript.run();
-                            if (val == null) {
-                                return false;
-                            }
-                            if (val instanceof Boolean) {
-                                return (Boolean) val;
-                            }
-                            if (val instanceof Number) {
-                                return ((Number) val).longValue() != 0;
-                            }
-                            throw new IllegalArgumentException("Can't handle type [" + val + "] in script filter");
-                        }
-
-                        @Override
-                        public int length() {
-                            return context.reader().maxDoc();
-                        }
-
-                    };
-                }
-            };
+        builder.startObject(ScriptQueryParser.NAME);
+        builder.field(ScriptField.SCRIPT.getPreferredName(), script);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-    }
-
-    @Override
-    protected ScriptQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new ScriptQueryBuilder(Script.readScript(in));
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        script.writeTo(out);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(script);
-    }
-
-    @Override
-    protected boolean doEquals(ScriptQueryBuilder other) {
-        return Objects.equals(script, other.script);
+        builder.endObject();
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java
index 168581f..bda1342 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ScriptQueryParser.java
@@ -19,13 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.RandomAccessWeight;
+import org.apache.lucene.search.Weight;
+import org.apache.lucene.util.Bits;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.script.LeafSearchScript;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.Script.ScriptField;
+import org.elasticsearch.script.ScriptContext;
 import org.elasticsearch.script.ScriptParameterParser;
 import org.elasticsearch.script.ScriptParameterParser.ScriptParameterValue;
+import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.script.SearchScript;
+import org.elasticsearch.search.lookup.SearchLookup;
 
 import java.io.IOException;
 import java.util.Map;
@@ -33,11 +43,12 @@ import java.util.Objects;
 
 import static com.google.common.collect.Maps.newHashMap;
 
-
 /**
- * Parser for script query
+ *
  */
-public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
+public class ScriptQueryParser implements QueryParser {
+
+    public static final String NAME = "script";
 
     @Inject
     public ScriptQueryParser() {
@@ -45,23 +56,23 @@ public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{ScriptQueryBuilder.NAME};
+        return new String[] { NAME };
     }
 
     @Override
-    public ScriptQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
         ScriptParameterParser scriptParameterParser = new ScriptParameterParser();
-        
+
+        XContentParser.Token token;
+
         // also, when caching, since its isCacheable is false, will result in loading all bit set...
         Script script = null;
         Map<String, Object> params = null;
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
-
-        XContentParser.Token token;
         String currentFieldName = null;
+
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -78,8 +89,6 @@ public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
             } else if (token.isValue()) {
                 if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
                 } else if (!scriptParameterParser.token(currentFieldName, token, parser, parseContext.parseFieldMatcher())) {
                     throw new QueryParsingException(parseContext, "[script] query does not support [" + currentFieldName + "]");
                 }
@@ -102,13 +111,83 @@ public class ScriptQueryParser extends BaseQueryParser<ScriptQueryBuilder> {
             throw new QueryParsingException(parseContext, "script must be provided with a [script] filter");
         }
 
-        return new ScriptQueryBuilder(script)
-                .boost(boost)
-                .queryName(queryName);
+        Query query = new ScriptQuery(script, parseContext.scriptService(), parseContext.lookup());
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 
-    @Override
-    public ScriptQueryBuilder getBuilderPrototype() {
-        return ScriptQueryBuilder.PROTOTYPE;
+    static class ScriptQuery extends Query {
+
+        private final Script script;
+
+        private final SearchScript searchScript;
+
+        public ScriptQuery(Script script, ScriptService scriptService, SearchLookup searchLookup) {
+            this.script = script;
+            this.searchScript = scriptService.search(searchLookup, script, ScriptContext.Standard.SEARCH);
+        }
+
+        @Override
+        public String toString(String field) {
+            StringBuilder buffer = new StringBuilder();
+            buffer.append("ScriptFilter(");
+            buffer.append(script);
+            buffer.append(")");
+            return buffer.toString();
+        }
+
+        @Override
+        public boolean equals(Object obj) {
+            if (this == obj)
+                return true;
+            if (!super.equals(obj))
+                return false;
+            ScriptQuery other = (ScriptQuery) obj;
+            return Objects.equals(script, other.script);
+        }
+
+        @Override
+        public int hashCode() {
+            final int prime = 31;
+            int result = super.hashCode();
+            result = prime * result + Objects.hashCode(script);
+            return result;
+        }
+
+        @Override
+        public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+            return new RandomAccessWeight(this) {
+                @Override
+                protected Bits getMatchingDocs(final LeafReaderContext context) throws IOException {
+                    final LeafSearchScript leafScript = searchScript.getLeafSearchScript(context);
+                    return new Bits() {
+
+                        @Override
+                        public boolean get(int doc) {
+                            leafScript.setDocument(doc);
+                            Object val = leafScript.run();
+                            if (val == null) {
+                                return false;
+                            }
+                            if (val instanceof Boolean) {
+                                return (Boolean) val;
+                            }
+                            if (val instanceof Number) {
+                                return ((Number) val).longValue() != 0;
+                            }
+                            throw new IllegalArgumentException("Can't handle type [" + val + "] in script filter");
+                        }
+
+                        @Override
+                        public int length() {
+                            return context.reader().maxDoc();
+                        }
+
+                    };
+                }
+            };
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java
index f8b0dea..9ae0703 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryParser.java
@@ -29,7 +29,6 @@ import org.apache.lucene.util.BytesRef;
 import java.io.IOException;
 import java.util.Locale;
 import java.util.Map;
-import java.util.Objects;
 
 /**
  * Wrapper class for Lucene's SimpleQueryParser that allows us to redefine
@@ -202,102 +201,51 @@ public class SimpleQueryParser extends org.apache.lucene.queryparser.simple.Simp
             return new PrefixQuery(new Term(field, termStr));
         }
     }
+
     /**
      * Class encapsulating the settings for the SimpleQueryString query, with
      * their default values
      */
-    static class Settings {
-        /** Locale to use for parsing. */
-        private Locale locale = SimpleQueryStringBuilder.DEFAULT_LOCALE;
-        /** Specifies whether parsed terms should be lowercased. */
-        private boolean lowercaseExpandedTerms = SimpleQueryStringBuilder.DEFAULT_LOWERCASE_EXPANDED_TERMS;
-        /** Specifies whether lenient query parsing should be used. */
-        private boolean lenient = SimpleQueryStringBuilder.DEFAULT_LENIENT;
-        /** Specifies whether wildcards should be analyzed. */
-        private boolean analyzeWildcard = SimpleQueryStringBuilder.DEFAULT_ANALYZE_WILDCARD;
+    public static class Settings {
+        private Locale locale = Locale.ROOT;
+        private boolean lowercaseExpandedTerms = true;
+        private boolean lenient = false;
+        private boolean analyzeWildcard = false;
 
-        /**
-         * Generates default {@link Settings} object (uses ROOT locale, does
-         * lowercase terms, no lenient parsing, no wildcard analysis).
-         * */
         public Settings() {
-        }
 
-        public Settings(Locale locale, Boolean lowercaseExpandedTerms, Boolean lenient, Boolean analyzeWildcard) {
-            this.locale = locale;
-            this.lowercaseExpandedTerms = lowercaseExpandedTerms;
-            this.lenient = lenient;
-            this.analyzeWildcard = analyzeWildcard;
         }
 
-        /** Specifies the locale to use for parsing, Locale.ROOT by default. */
         public void locale(Locale locale) {
-            this.locale = (locale != null) ? locale : SimpleQueryStringBuilder.DEFAULT_LOCALE;
+            this.locale = locale;
         }
 
-        /** Returns the locale to use for parsing. */
         public Locale locale() {
             return this.locale;
         }
 
-        /**
-         * Specifies whether to lowercase parse terms, defaults to true if
-         * unset.
-         */
         public void lowercaseExpandedTerms(boolean lowercaseExpandedTerms) {
             this.lowercaseExpandedTerms = lowercaseExpandedTerms;
         }
 
-        /** Returns whether to lowercase parse terms. */
         public boolean lowercaseExpandedTerms() {
             return this.lowercaseExpandedTerms;
         }
 
-        /** Specifies whether to use lenient parsing, defaults to false. */
         public void lenient(boolean lenient) {
             this.lenient = lenient;
         }
 
-        /** Returns whether to use lenient parsing. */
         public boolean lenient() {
             return this.lenient;
         }
 
-        /** Specifies whether to analyze wildcards. Defaults to false if unset. */
         public void analyzeWildcard(boolean analyzeWildcard) {
             this.analyzeWildcard = analyzeWildcard;
         }
 
-        /** Returns whether to analyze wildcards. */
         public boolean analyzeWildcard() {
             return analyzeWildcard;
         }
-
-        @Override
-        public int hashCode() {
-            // checking the return value of toLanguageTag() for locales only.
-            // For further reasoning see
-            // https://issues.apache.org/jira/browse/LUCENE-4021
-            return Objects.hash(locale.toLanguageTag(), lowercaseExpandedTerms, lenient, analyzeWildcard);
-        }
-
-        @Override
-        public boolean equals(Object obj) {
-            if (this == obj) {
-                return true;
-            }
-            if (obj == null || getClass() != obj.getClass()) {
-                return false;
-            }
-            Settings other = (Settings) obj;
-
-            // checking the return value of toLanguageTag() for locales only.
-            // For further reasoning see
-            // https://issues.apache.org/jira/browse/LUCENE-4021
-            return (Objects.equals(locale.toLanguageTag(), other.locale.toLanguageTag())
-                    && Objects.equals(lowercaseExpandedTerms, other.lowercaseExpandedTerms) 
-                    && Objects.equals(lenient, other.lenient)
-                    && Objects.equals(analyzeWildcard, other.analyzeWildcard));
-        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java
index 4f90097..700ad41 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringBuilder.java
@@ -19,393 +19,202 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.regex.Regex;
+import org.elasticsearch.common.xcontent.ToXContent.Params;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.SimpleQueryParser.Settings;
 
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
-import java.util.Objects;
-import java.util.TreeMap;
 
 /**
- * SimpleQuery is a query parser that acts similar to a query_string query, but
- * won't throw exceptions for any weird string syntax.
- *
- * For more detailed explanation of the query string syntax see also the <a
- * href=
- * "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-simple-query-string-query.html"
- * > online documentation</a>.
+ * SimpleQuery is a query parser that acts similar to a query_string
+ * query, but won't throw exceptions for any weird string syntax.
  */
-public class SimpleQueryStringBuilder extends AbstractQueryBuilder<SimpleQueryStringBuilder> {
-    /** Default locale used for parsing.*/
-    public static final Locale DEFAULT_LOCALE = Locale.ROOT;
-    /** Default for lowercasing parsed terms.*/
-    public static final boolean DEFAULT_LOWERCASE_EXPANDED_TERMS = true;
-    /** Default for using lenient query parsing.*/
-    public static final boolean DEFAULT_LENIENT = false;
-    /** Default for wildcard analysis.*/
-    public static final boolean DEFAULT_ANALYZE_WILDCARD = false;
-    /** Default for default operator to use for linking boolean clauses.*/
-    public static final Operator DEFAULT_OPERATOR = Operator.OR;
-    /** Default for search flags to use. */
-    public static final int DEFAULT_FLAGS = SimpleQueryStringFlag.ALL.value;
-    /** Name for (de-)serialization. */
-    public static final String NAME = "simple_query_string";
-
-    static final SimpleQueryStringBuilder PROTOTYPE = new SimpleQueryStringBuilder(null);
-
-    /** Query text to parse. */
-    private final String queryText;
-    /**
-     * Fields to query against. If left empty will query default field,
-     * currently _ALL. Uses a TreeMap to hold the fields so boolean clauses are
-     * always sorted in same order for generated Lucene query for easier
-     * testing.
-     *
-     * Can be changed back to HashMap once https://issues.apache.org/jira/browse/LUCENE-6305 is fixed.
-     */
-    private final Map<String, Float> fieldsAndWeights = new TreeMap<>();
-    /** If specified, analyzer to use to parse the query text, defaults to registered default in toQuery. */
+public class SimpleQueryStringBuilder extends QueryBuilder implements BoostableQueryBuilder<SimpleQueryStringBuilder> {
+    private Map<String, Float> fields = new HashMap<>();
     private String analyzer;
-    /** Default operator to use for linking boolean clauses. Defaults to OR according to docs. */
-    private Operator defaultOperator = DEFAULT_OPERATOR;
-    /** If result is a boolean query, minimumShouldMatch parameter to apply. Ignored otherwise. */
+    private Operator operator;
+    private final String queryText;
+    private String queryName;
     private String minimumShouldMatch;
-    /** Any search flags to be used, ALL by default. */
-    private int flags = DEFAULT_FLAGS;
+    private int flags = -1;
+    private float boost = -1.0f;
+    private Boolean lowercaseExpandedTerms;
+    private Boolean lenient;
+    private Boolean analyzeWildcard;
+    private Locale locale;
 
-    /** Further search settings needed by the ES specific query string parser only. */
-    private Settings settings = new Settings();
+    /**
+     * Operators for the default_operator
+     */
+    public static enum Operator {
+        AND,
+        OR
+    }
 
-    /** Construct a new simple query with this query string. */
-    public SimpleQueryStringBuilder(String queryText) {
-        this.queryText = queryText;
+    /**
+     * Construct a new simple query with the given text
+     */
+    public SimpleQueryStringBuilder(String text) {
+        this.queryText = text;
     }
 
-    /** Returns the text to parse the query from. */
-    public String value() {
-        return this.queryText;
+    /** Set the boost of this query. */
+    @Override
+    public SimpleQueryStringBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+    
+    /** Returns the boost of this query. */
+    public float boost() {
+        return this.boost;
     }
 
-    /** Add a field to run the query against. */
+    /**
+     * Add a field to run the query against
+     */
     public SimpleQueryStringBuilder field(String field) {
-        if (Strings.isEmpty(field)) {
-            throw new IllegalArgumentException("supplied field is null or empty.");
-        }
-        this.fieldsAndWeights.put(field, AbstractQueryBuilder.DEFAULT_BOOST);
+        this.fields.put(field, null);
         return this;
     }
 
-    /** Add a field to run the query against with a specific boost. */
+    /**
+     * Add a field to run the query against with a specific boost
+     */
     public SimpleQueryStringBuilder field(String field, float boost) {
-        if (Strings.isEmpty(field)) {
-            throw new IllegalArgumentException("supplied field is null or empty.");
-        }
-        this.fieldsAndWeights.put(field, boost);
+        this.fields.put(field, boost);
         return this;
     }
 
-    /** Add several fields to run the query against with a specific boost. */
-    public SimpleQueryStringBuilder fields(Map<String, Float> fields) {
-        this.fieldsAndWeights.putAll(fields);
+    /**
+     * Specify a name for the query
+     */
+    public SimpleQueryStringBuilder queryName(String name) {
+        this.queryName = name;
         return this;
     }
 
-    /** Returns the fields including their respective boosts to run the query against. */
-    public Map<String, Float> fields() {
-        return this.fieldsAndWeights;
-    }
-
-    /** Specify an analyzer to use for the query. */
+    /**
+     * Specify an analyzer to use for the query
+     */
     public SimpleQueryStringBuilder analyzer(String analyzer) {
         this.analyzer = analyzer;
         return this;
     }
 
-    /** Returns the analyzer to use for the query. */
-    public String analyzer() {
-        return this.analyzer;
-    }
-
     /**
      * Specify the default operator for the query. Defaults to "OR" if no
-     * operator is specified.
+     * operator is specified
      */
     public SimpleQueryStringBuilder defaultOperator(Operator defaultOperator) {
-        this.defaultOperator = (defaultOperator != null) ? defaultOperator : DEFAULT_OPERATOR;
+        this.operator = defaultOperator;
         return this;
     }
 
-    /** Returns the default operator for the query. */
-    public Operator defaultOperator() {
-        return this.defaultOperator;
-    }
-
     /**
-     * Specify the enabled features of the SimpleQueryString. Defaults to ALL if
-     * none are specified.
+     * Specify the enabled features of the SimpleQueryString.
      */
     public SimpleQueryStringBuilder flags(SimpleQueryStringFlag... flags) {
-        if (flags != null && flags.length > 0) {
-            int value = 0;
+        int value = 0;
+        if (flags.length == 0) {
+            value = SimpleQueryStringFlag.ALL.value;
+        } else {
             for (SimpleQueryStringFlag flag : flags) {
                 value |= flag.value;
             }
-            this.flags = value;
-        } else {
-            this.flags = DEFAULT_FLAGS;
         }
-
+        this.flags = value;
         return this;
     }
 
-    /** For testing and serialisation only. */
-    SimpleQueryStringBuilder flags(int flags) {
-        this.flags = flags;
-        return this;
-    }
-
-    /** For testing only: Return the flags set for this query. */
-    int flags() {
-        return this.flags;
-    }
-
-    /**
-     * Specifies whether parsed terms for this query should be lower-cased.
-     * Defaults to true if not set.
-     */
     public SimpleQueryStringBuilder lowercaseExpandedTerms(boolean lowercaseExpandedTerms) {
-        this.settings.lowercaseExpandedTerms(lowercaseExpandedTerms);
+        this.lowercaseExpandedTerms = lowercaseExpandedTerms;
         return this;
     }
 
-    /** Returns whether parsed terms should be lower cased for this query. */
-    public boolean lowercaseExpandedTerms() {
-        return this.settings.lowercaseExpandedTerms();
-    }
-
-    /** Specifies the locale for parsing terms. Defaults to ROOT if none is set. */
     public SimpleQueryStringBuilder locale(Locale locale) {
-        this.settings.locale(locale);
+        this.locale = locale;
         return this;
     }
 
-    /** Returns the locale for parsing terms for this query. */
-    public Locale locale() {
-        return this.settings.locale();
-    }
-
-    /** Specifies whether query parsing should be lenient. Defaults to false. */
     public SimpleQueryStringBuilder lenient(boolean lenient) {
-        this.settings.lenient(lenient);
+        this.lenient = lenient;
         return this;
     }
 
-    /** Returns whether query parsing should be lenient. */
-    public boolean lenient() {
-        return this.settings.lenient();
-    }
-
-    /** Specifies whether wildcards should be analyzed. Defaults to false. */
     public SimpleQueryStringBuilder analyzeWildcard(boolean analyzeWildcard) {
-        this.settings.analyzeWildcard(analyzeWildcard);
+        this.analyzeWildcard = analyzeWildcard;
         return this;
     }
 
-    /** Returns whether wildcards should by analyzed. */
-    public boolean analyzeWildcard() {
-        return this.settings.analyzeWildcard();
-    }
-
-    /**
-     * Specifies the minimumShouldMatch to apply to the resulting query should
-     * that be a Boolean query.
-     */
     public SimpleQueryStringBuilder minimumShouldMatch(String minimumShouldMatch) {
         this.minimumShouldMatch = minimumShouldMatch;
         return this;
     }
 
-    /**
-     * Returns the minimumShouldMatch to apply to the resulting query should
-     * that be a Boolean query.
-     */
-    public String minimumShouldMatch() {
-        return minimumShouldMatch;
-    }
-
-    /**
-     * {@inheritDoc}
-     *
-     * Checks that mandatory queryText is neither null nor empty.
-     * */
     @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        // Query text is required
-        if (queryText == null) {
-            validationException = addValidationError("query text missing", validationException);
-        }
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(SimpleQueryStringParser.NAME);
 
-        return validationException;
-    }
+        builder.field("query", queryText);
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        // field names in builder can have wildcards etc, need to resolve them here
-        Map<String, Float> resolvedFieldsAndWeights = new TreeMap<>();
-        // Use the default field if no fields specified
-        if (fieldsAndWeights.isEmpty()) {
-            resolvedFieldsAndWeights.put(resolveIndexName(context.defaultField(), context), AbstractQueryBuilder.DEFAULT_BOOST);
-        } else {
-            for (Map.Entry<String, Float> fieldEntry : fieldsAndWeights.entrySet()) {
-                if (Regex.isSimpleMatchPattern(fieldEntry.getKey())) {
-                    for (String fieldName : context.mapperService().simpleMatchToIndexNames(fieldEntry.getKey())) {
-                        resolvedFieldsAndWeights.put(fieldName, fieldEntry.getValue());
-                    }
+        if (fields.size() > 0) {
+            builder.startArray("fields");
+            for (Map.Entry<String, Float> entry : fields.entrySet()) {
+                String field = entry.getKey();
+                Float boost = entry.getValue();
+                if (boost != null) {
+                    builder.value(field + "^" + boost);
                 } else {
-                    resolvedFieldsAndWeights.put(resolveIndexName(fieldEntry.getKey(), context), fieldEntry.getValue());
+                    builder.value(field);
                 }
             }
+            builder.endArray();
         }
 
-        // Use standard analyzer by default if none specified
-        Analyzer luceneAnalyzer;
-        if (analyzer == null) {
-            luceneAnalyzer = context.mapperService().searchAnalyzer();
-        } else {
-            luceneAnalyzer = context.analysisService().analyzer(analyzer);
-            if (luceneAnalyzer == null) {
-                throw new QueryShardException(context, "[" + SimpleQueryStringBuilder.NAME + "] analyzer [" + analyzer
-                        + "] not found");
-            }
-
+        if (flags != -1) {
+            builder.field("flags", flags);
         }
 
-        SimpleQueryParser sqp = new SimpleQueryParser(luceneAnalyzer, resolvedFieldsAndWeights, flags, settings);
-        sqp.setDefaultOperator(defaultOperator.toBooleanClauseOccur());
-
-        Query query = sqp.parse(queryText);
-        if (minimumShouldMatch != null && query instanceof BooleanQuery) {
-            query = Queries.applyMinimumShouldMatch((BooleanQuery) query, minimumShouldMatch);
+        if (analyzer != null) {
+            builder.field("analyzer", analyzer);
         }
-        return query;
-    }
 
-    private static String resolveIndexName(String fieldName, QueryShardContext context) {
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            return fieldType.names().indexName();
+        if (operator != null) {
+            builder.field("default_operator", operator.name().toLowerCase(Locale.ROOT));
         }
-        return fieldName;
-    }
 
-    @Override
-    protected void setFinalBoost(Query query) {
-        query.setBoost(boost * query.getBoost());
-    }
-
-    @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        if (lowercaseExpandedTerms != null) {
+            builder.field("lowercase_expanded_terms", lowercaseExpandedTerms);
+        }
 
-        builder.field("query", queryText);
+        if (lenient != null) {
+            builder.field("lenient", lenient);
+        }
 
-        if (fieldsAndWeights.size() > 0) {
-            builder.startArray("fields");
-            for (Map.Entry<String, Float> entry : fieldsAndWeights.entrySet()) {
-                builder.value(entry.getKey() + "^" + entry.getValue());
-            }
-            builder.endArray();
+        if (analyzeWildcard != null) {
+            builder.field("analyze_wildcard", analyzeWildcard);
         }
 
-        if (analyzer != null) {
-            builder.field("analyzer", analyzer);
+        if (locale != null) {
+            builder.field("locale", locale.toString());
         }
 
-        builder.field("flags", flags);
-        builder.field("default_operator", defaultOperator.name().toLowerCase(Locale.ROOT));
-        builder.field("lowercase_expanded_terms", settings.lowercaseExpandedTerms());
-        builder.field("lenient", settings.lenient());
-        builder.field("analyze_wildcard", settings.analyzeWildcard());
-        builder.field("locale", (settings.locale().toLanguageTag()));
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
 
         if (minimumShouldMatch != null) {
             builder.field("minimum_should_match", minimumShouldMatch);
         }
-
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected SimpleQueryStringBuilder doReadFrom(StreamInput in) throws IOException {
-        SimpleQueryStringBuilder result = new SimpleQueryStringBuilder(in.readString());
-        int size = in.readInt();
-        Map<String, Float> fields = new HashMap<>();
-        for (int i = 0; i < size; i++) {
-            String field = in.readString();
-            Float weight = in.readFloat();
-            fields.put(field, weight);
-        }
-        result.fieldsAndWeights.putAll(fields);
-        result.flags = in.readInt();
-        result.analyzer = in.readOptionalString();
-        result.defaultOperator = Operator.readOperatorFrom(in);
-        result.settings.lowercaseExpandedTerms(in.readBoolean());
-        result.settings.lenient(in.readBoolean());
-        result.settings.analyzeWildcard(in.readBoolean());
-        String localeStr = in.readString();
-        result.settings.locale(Locale.forLanguageTag(localeStr));
-        result.minimumShouldMatch = in.readOptionalString();
-        return result;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(queryText);
-        out.writeInt(fieldsAndWeights.size());
-        for (Map.Entry<String, Float> entry : fieldsAndWeights.entrySet()) {
-            out.writeString(entry.getKey());
-            out.writeFloat(entry.getValue());
+        
+        if (boost != -1.0f) {
+            builder.field("boost", boost);
         }
-        out.writeInt(flags);
-        out.writeOptionalString(analyzer);
-        defaultOperator.writeTo(out);
-        out.writeBoolean(settings.lowercaseExpandedTerms());
-        out.writeBoolean(settings.lenient());
-        out.writeBoolean(settings.analyzeWildcard());
-        out.writeString(settings.locale().toLanguageTag());
-        out.writeOptionalString(minimumShouldMatch);
-    }
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldsAndWeights, analyzer, defaultOperator, queryText, minimumShouldMatch, settings, flags);
+        builder.endObject();
     }
 
-    @Override
-    protected boolean doEquals(SimpleQueryStringBuilder other) {
-        return Objects.equals(fieldsAndWeights, other.fieldsAndWeights) && Objects.equals(analyzer, other.analyzer)
-                && Objects.equals(defaultOperator, other.defaultOperator) && Objects.equals(queryText, other.queryText)
-                && Objects.equals(minimumShouldMatch, other.minimumShouldMatch)
-                && Objects.equals(settings, other.settings) && (flags == other.flags);
-    }
 }
-
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java
index 68d19db..ce0ce88 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringFlag.java
@@ -71,7 +71,7 @@ public enum SimpleQueryStringFlag {
                         magic |= flag.value();
                 }
             } catch (IllegalArgumentException iae) {
-                throw new IllegalArgumentException("Unknown " + SimpleQueryStringBuilder.NAME + " flag [" + s + "]");
+                throw new IllegalArgumentException("Unknown " + SimpleQueryStringParser.NAME + " flag [" + s + "]");
             }
         }
         return magic;
diff --git a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java
index 89f94ed..fa65e51 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SimpleQueryStringParser.java
@@ -19,12 +19,20 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.search.Queries;
+import org.elasticsearch.common.regex.Regex;
+import org.elasticsearch.common.util.LocaleUtils;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
@@ -60,7 +68,9 @@ import java.util.Map;
  * {@code fields} - fields to search, defaults to _all if not set, allows
  * boosting a field with ^n
  */
-public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBuilder> {
+public class SimpleQueryStringParser implements QueryParser {
+
+    public static final String NAME = "simple_query_string";
 
     @Inject
     public SimpleQueryStringParser() {
@@ -69,26 +79,23 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
 
     @Override
     public String[] names() {
-        return new String[]{SimpleQueryStringBuilder.NAME, Strings.toCamelCase(SimpleQueryStringBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SimpleQueryStringBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String currentFieldName = null;
         String queryBody = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f; 
         String queryName = null;
         String minimumShouldMatch = null;
-        Map<String, Float> fieldsAndWeights = new HashMap<>();
-        Operator defaultOperator = null;
-        String analyzerName = null;
-        int flags = SimpleQueryStringFlag.ALL.value();
-        boolean lenient = SimpleQueryStringBuilder.DEFAULT_LENIENT;
-        boolean lowercaseExpandedTerms = SimpleQueryStringBuilder.DEFAULT_LOWERCASE_EXPANDED_TERMS;
-        boolean analyzeWildcard = SimpleQueryStringBuilder.DEFAULT_ANALYZE_WILDCARD;
-        Locale locale = null;
+        Map<String, Float> fieldsAndWeights = null;
+        BooleanClause.Occur defaultOperator = null;
+        Analyzer analyzer = null;
+        int flags = -1;
+        SimpleQueryParser.Settings sqsSettings = new SimpleQueryParser.Settings();
 
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -112,10 +119,26 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
                         if (fField == null) {
                             fField = parser.text();
                         }
-                        fieldsAndWeights.put(fField, fBoost);
+
+                        if (fieldsAndWeights == null) {
+                            fieldsAndWeights = new HashMap<>();
+                        }
+
+                        if (Regex.isSimpleMatchPattern(fField)) {
+                            for (String fieldName : parseContext.mapperService().simpleMatchToIndexNames(fField)) {
+                                fieldsAndWeights.put(fieldName, fBoost);
+                            }
+                        } else {
+                            MappedFieldType fieldType = parseContext.fieldMapper(fField);
+                            if (fieldType != null) {
+                                fieldsAndWeights.put(fieldType.names().indexName(), fBoost);
+                            } else {
+                                fieldsAndWeights.put(fField, fBoost);
+                            }
+                        }
                     }
                 } else {
-                    throw new QueryParsingException(parseContext, "[" + SimpleQueryStringBuilder.NAME + "] query does not support [" + currentFieldName + "]");
+                    throw new QueryParsingException(parseContext, "[" + NAME + "] query does not support [" + currentFieldName + "]");
                 }
             } else if (token.isValue()) {
                 if ("query".equals(currentFieldName)) {
@@ -123,9 +146,19 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else if ("analyzer".equals(currentFieldName)) {
-                    analyzerName = parser.text();
+                    analyzer = parseContext.analysisService().analyzer(parser.text());
+                    if (analyzer == null) {
+                        throw new QueryParsingException(parseContext, "[" + NAME + "] analyzer [" + parser.text() + "] not found");
+                    }
                 } else if ("default_operator".equals(currentFieldName) || "defaultOperator".equals(currentFieldName)) {
-                    defaultOperator = Operator.fromString(parser.text());
+                    String op = parser.text();
+                    if ("or".equalsIgnoreCase(op)) {
+                        defaultOperator = BooleanClause.Occur.SHOULD;
+                    } else if ("and".equalsIgnoreCase(op)) {
+                        defaultOperator = BooleanClause.Occur.MUST;
+                    } else {
+                        throw new QueryParsingException(parseContext, "[" + NAME + "] default operator [" + op + "] is not allowed");
+                    }
                 } else if ("flags".equals(currentFieldName)) {
                     if (parser.currentToken() != XContentParser.Token.VALUE_NUMBER) {
                         // Possible options are:
@@ -139,37 +172,56 @@ public class SimpleQueryStringParser extends BaseQueryParser<SimpleQueryStringBu
                     }
                 } else if ("locale".equals(currentFieldName)) {
                     String localeStr = parser.text();
-                    locale = Locale.forLanguageTag(localeStr);
+                    Locale locale = LocaleUtils.parse(localeStr);
+                    sqsSettings.locale(locale);
                 } else if ("lowercase_expanded_terms".equals(currentFieldName)) {
-                    lowercaseExpandedTerms = parser.booleanValue();
+                    sqsSettings.lowercaseExpandedTerms(parser.booleanValue());
                 } else if ("lenient".equals(currentFieldName)) {
-                    lenient = parser.booleanValue();
+                    sqsSettings.lenient(parser.booleanValue());
                 } else if ("analyze_wildcard".equals(currentFieldName)) {
-                    analyzeWildcard = parser.booleanValue();
+                    sqsSettings.analyzeWildcard(parser.booleanValue());
                 } else if ("_name".equals(currentFieldName)) {
                     queryName = parser.text();
                 } else if ("minimum_should_match".equals(currentFieldName)) {
                     minimumShouldMatch = parser.textOrNull();
                 } else {
-                    throw new QueryParsingException(parseContext, "[" + SimpleQueryStringBuilder.NAME + "] unsupported field [" + parser.currentName() + "]");
+                    throw new QueryParsingException(parseContext, "[" + NAME + "] unsupported field [" + parser.currentName() + "]");
                 }
             }
         }
 
         // Query text is required
         if (queryBody == null) {
-            throw new QueryParsingException(parseContext, "[" + SimpleQueryStringBuilder.NAME + "] query text missing");
+            throw new QueryParsingException(parseContext, "[" + NAME + "] query text missing");
         }
 
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder(queryBody);
-        qb.boost(boost).fields(fieldsAndWeights).analyzer(analyzerName).queryName(queryName).minimumShouldMatch(minimumShouldMatch);
-        qb.flags(flags).defaultOperator(defaultOperator).locale(locale).lowercaseExpandedTerms(lowercaseExpandedTerms);
-        qb.lenient(lenient).analyzeWildcard(analyzeWildcard).boost(boost);
-        return qb;
-    }
+        // Use standard analyzer by default
+        if (analyzer == null) {
+            analyzer = parseContext.mapperService().searchAnalyzer();
+        }
 
-    @Override
-    public SimpleQueryStringBuilder getBuilderPrototype() {
-        return SimpleQueryStringBuilder.PROTOTYPE;
+        if (fieldsAndWeights == null) {
+            fieldsAndWeights = Collections.singletonMap(parseContext.defaultField(), 1.0F);
+        }
+        SimpleQueryParser sqp = new SimpleQueryParser(analyzer, fieldsAndWeights, flags, sqsSettings);
+
+        if (defaultOperator != null) {
+            sqp.setDefaultOperator(defaultOperator);
+        }
+
+        Query query = sqp.parse(queryBody);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+
+        if (minimumShouldMatch != null && query instanceof BooleanQuery) {
+            query = Queries.applyMinimumShouldMatch((BooleanQuery) query, minimumShouldMatch);
+        }
+
+        if (query != null) {
+            query.setBoost(boost * query.getBoost());
+        }
+
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java
index 1d55bbe..0b7a3cd 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryBuilder.java
@@ -19,119 +19,74 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanContainingQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * Builder for {@link org.apache.lucene.search.spans.SpanContainingQuery}.
  */
-public class SpanContainingQueryBuilder extends AbstractQueryBuilder<SpanContainingQueryBuilder> implements SpanQueryBuilder<SpanContainingQueryBuilder> {
+public class SpanContainingQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanContainingQueryBuilder> {
 
-    public static final String NAME = "span_containing";
-    private final SpanQueryBuilder big;
-    private final SpanQueryBuilder little;
-    static final SpanContainingQueryBuilder PROTOTYPE = new SpanContainingQueryBuilder(null, null);
+    private SpanQueryBuilder big;
+    private SpanQueryBuilder little;
+    private float boost = -1;
+    private String queryName;
 
-    /**
-     * @param big the big clause, it must enclose {@code little} for a match.
-     * @param little the little clause, it must be contained within {@code big} for a match.
-     */
-    public SpanContainingQueryBuilder(SpanQueryBuilder big, SpanQueryBuilder little) {
-        this.little = little;
-        this.big = big;
-    }
-
-    /**
-     * @return the big clause, it must enclose {@code little} for a match.
+    /** 
+     * Sets the little clause, it must be contained within {@code big} for a match.
      */
-    public SpanQueryBuilder bigQuery() {
-        return this.big;
+    public SpanContainingQueryBuilder little(SpanQueryBuilder clause) {
+        this.little = clause;
+        return this;
     }
 
-    /**
-     * @return the little clause, it must be contained within {@code big} for a match.
+    /** 
+     * Sets the big clause, it must enclose {@code little} for a match.
      */
-    public SpanQueryBuilder littleQuery() {
-        return this.little;
+    public SpanContainingQueryBuilder big(SpanQueryBuilder clause) {
+        this.big = clause;
+        return this;
     }
 
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("big");
-        big.toXContent(builder, params);
-        builder.field("little");
-        little.toXContent(builder, params);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerBig = big.toQuery(context);
-        assert innerBig instanceof SpanQuery;
-        Query innerLittle = little.toQuery(context);
-        assert innerLittle instanceof SpanQuery;
-        return new SpanContainingQuery((SpanQuery) innerBig, (SpanQuery) innerLittle);
+    public SpanContainingQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected void setFinalBoost(Query query) {
-        if (boost != AbstractQueryBuilder.DEFAULT_BOOST) {
-            //preserve potential inner boost coming from lucene (default is big.boost)
-            query.setBoost(boost);
-        }
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public SpanContainingQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
         if (big == null) {
-            validationException = addValidationError("inner clause [big] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(big, validationException);
+            throw new IllegalArgumentException("Must specify big clause when building a span_containing query");
         }
         if (little == null) {
-            validationException = addValidationError("inner clause [little] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(little, validationException);
+            throw new IllegalArgumentException("Must specify little clause when building a span_containing query");
         }
-        return validationException;
-    }
+        builder.startObject(SpanContainingQueryParser.NAME);
 
-    @Override
-    protected SpanContainingQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder big = (SpanQueryBuilder)in.readQuery();
-        SpanQueryBuilder little = (SpanQueryBuilder)in.readQuery();
-        return new SpanContainingQueryBuilder(big, little);
-    }
+        builder.field("big");
+        big.toXContent(builder, params);
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(big);
-        out.writeQuery(little);
-    }
+        builder.field("little");
+        little.toXContent(builder, params);
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(big, little);
-    }
+        if (boost != -1) {
+            builder.field("boost", boost);
+        }
 
-    @Override
-    protected boolean doEquals(SpanContainingQueryBuilder other) {
-        return Objects.equals(big, other.big) &&
-               Objects.equals(little, other.little);
-    }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java
index affc853..e2dc813 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanContainingQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_containing query
+ * Parser for {@link SpanContainingQuery}
  */
-public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQueryBuilder> {
+public class SpanContainingQueryParser implements QueryParser {
+
+    public static final String NAME = "span_containing";
 
     @Inject
     public SpanContainingQueryParser() {
@@ -36,16 +41,17 @@ public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQue
 
     @Override
     public String[] names() {
-        return new String[]{SpanContainingQueryBuilder.NAME, Strings.toCamelCase(SpanContainingQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanContainingQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+
+        float boost = 1.0f;
         String queryName = null;
-        SpanQueryBuilder<?> big = null;
-        SpanQueryBuilder<?> little = null;
+        SpanQuery big = null;
+        SpanQuery little = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -54,17 +60,17 @@ public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQue
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("big".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder<?>)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "span_containing [big] must be of type span query");
                     }
-                    big = (SpanQueryBuilder<?>) query;
+                    big = (SpanQuery) query;
                 } else if ("little".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder<?>)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "span_containing [little] must be of type span query");
                     }
-                    little = (SpanQueryBuilder<?>) query;
+                    little = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_containing] query does not support [" + currentFieldName + "]");
                 }
@@ -75,15 +81,22 @@ public class SpanContainingQueryParser extends BaseQueryParser<SpanContainingQue
             } else {
                 throw new QueryParsingException(parseContext, "[span_containing] query does not support [" + currentFieldName + "]");
             }
+        }        
+        
+        if (big == null) {
+            throw new QueryParsingException(parseContext, "span_containing must include [big]");
+        }
+        if (little == null) {
+            throw new QueryParsingException(parseContext, "span_containing must include [little]");
         }
 
-        SpanContainingQueryBuilder query = new SpanContainingQueryBuilder(big, little);
-        query.boost(boost).queryName(queryName);
+        Query query = new SpanContainingQuery(big, little);
+        if (boost != 1.0F) {
+            query.setBoost(boost);
+        }
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
         return query;
     }
-
-    @Override
-    public SpanContainingQueryBuilder getBuilderPrototype() {
-        return SpanContainingQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java
index a7c4572..f967a1c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryBuilder.java
@@ -19,109 +19,51 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanFirstQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class SpanFirstQueryBuilder extends AbstractQueryBuilder<SpanFirstQueryBuilder> implements SpanQueryBuilder<SpanFirstQueryBuilder>{
-
-    public static final String NAME = "span_first";
+public class SpanFirstQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanFirstQueryBuilder> {
 
     private final SpanQueryBuilder matchBuilder;
 
     private final int end;
 
-    static final SpanFirstQueryBuilder PROTOTYPE = new SpanFirstQueryBuilder(null, -1);
+    private float boost = -1;
+
+    private String queryName;
 
-    /**
-     * Query that matches spans queries defined in <code>matchBuilder</code>
-     * whose end position is less than or equal to <code>end</code>.
-     * @param matchBuilder inner {@link SpanQueryBuilder}
-     * @param end maximum end position of the match, needs to be positive
-     * @throws IllegalArgumentException for negative <code>end</code> positions
-     */
     public SpanFirstQueryBuilder(SpanQueryBuilder matchBuilder, int end) {
         this.matchBuilder = matchBuilder;
         this.end = end;
     }
 
-    /**
-     * @return the inner {@link SpanQueryBuilder} defined in this query
-     */
-    public SpanQueryBuilder innerQuery() {
-        return this.matchBuilder;
+    @Override
+    public SpanFirstQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
-     * @return maximum end position of the matching inner span query
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public int end() {
-        return this.end;
+    public SpanFirstQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(SpanFirstQueryParser.NAME);
         builder.field("match");
         matchBuilder.toXContent(builder, params);
         builder.field("end", end);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerSpanQuery = matchBuilder.toQuery(context);
-        assert innerSpanQuery instanceof SpanQuery;
-        return new SpanFirstQuery((SpanQuery) innerSpanQuery, end);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (matchBuilder == null) {
-            validationException = addValidationError("inner clause [match] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(matchBuilder, validationException);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        if (end < 0) {
-            validationException = addValidationError("parameter [end] needs to be positive.", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    protected SpanFirstQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder matchBuilder = (SpanQueryBuilder)in.readQuery();
-        int end = in.readInt();
-        return new SpanFirstQueryBuilder(matchBuilder, end);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(matchBuilder);
-        out.writeInt(end);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(matchBuilder, end);
-    }
-
-    @Override
-    protected boolean doEquals(SpanFirstQueryBuilder other) {
-        return Objects.equals(matchBuilder, other.matchBuilder) &&
-               Objects.equals(end, other.end);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java
index 995bb4d..5a302eb 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanFirstQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanFirstQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_first query
+ *
  */
-public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder> {
+public class SpanFirstQueryParser implements QueryParser {
+
+    public static final String NAME = "span_first";
 
     @Inject
     public SpanFirstQueryParser() {
@@ -36,17 +41,17 @@ public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder>
 
     @Override
     public String[] names() {
-        return new String[]{SpanFirstQueryBuilder.NAME, Strings.toCamelCase(SpanFirstQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanFirstQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
-        SpanQueryBuilder match = null;
-        Integer end = null;
+        SpanQuery match = null;
+        int end = -1;
         String queryName = null;
 
         String currentFieldName = null;
@@ -56,11 +61,11 @@ public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder>
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("match".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "spanFirst [match] must be of type span query");
                     }
-                    match = (SpanQueryBuilder) query;
+                    match = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_first] query does not support [" + currentFieldName + "]");
                 }
@@ -79,16 +84,15 @@ public class SpanFirstQueryParser extends BaseQueryParser<SpanFirstQueryBuilder>
         if (match == null) {
             throw new QueryParsingException(parseContext, "spanFirst must have [match] span query clause");
         }
-        if (end == null) {
+        if (end == -1) {
             throw new QueryParsingException(parseContext, "spanFirst must have [end] set for it");
         }
-        SpanFirstQueryBuilder queryBuilder = new SpanFirstQueryBuilder(match, end);
-        queryBuilder.boost(boost).queryName(queryName);
-        return queryBuilder;
-    }
 
-    @Override
-    public SpanFirstQueryBuilder getBuilderPrototype() {
-        return SpanFirstQueryBuilder.PROTOTYPE;
+        SpanFirstQuery query = new SpanFirstQuery(match, end);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java
index a31b17e..11b9897 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilder.java
@@ -18,88 +18,25 @@
  */
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
-/**
- * Query that allows wraping a {@link MultiTermQueryBuilder} (one of wildcard, fuzzy, prefix, term, range or regexp query)
- * as a {@link SpanQueryBuilder} so it can be nested.
- */
-public class SpanMultiTermQueryBuilder extends AbstractQueryBuilder<SpanMultiTermQueryBuilder> implements SpanQueryBuilder<SpanMultiTermQueryBuilder> {
+public class SpanMultiTermQueryBuilder extends SpanQueryBuilder {
 
-    public static final String NAME = "span_multi";
-    private final MultiTermQueryBuilder multiTermQueryBuilder;
-    static final SpanMultiTermQueryBuilder PROTOTYPE = new SpanMultiTermQueryBuilder(null);
+    private MultiTermQueryBuilder multiTermQueryBuilder;
 
     public SpanMultiTermQueryBuilder(MultiTermQueryBuilder multiTermQueryBuilder) {
         this.multiTermQueryBuilder = multiTermQueryBuilder;
     }
 
-    public MultiTermQueryBuilder innerQuery() {
-        return this.multiTermQueryBuilder;
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params)
             throws IOException {
-        builder.startObject(NAME);
+        builder.startObject(SpanMultiTermQueryParser.NAME);
         builder.field(SpanMultiTermQueryParser.MATCH_NAME);
         multiTermQueryBuilder.toXContent(builder, params);
-        printBoostAndQueryName(builder);
         builder.endObject();
     }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query subQuery = multiTermQueryBuilder.toQuery(context);
-        if (subQuery instanceof MultiTermQuery == false) {
-            throw new UnsupportedOperationException("unsupported inner query, should be " + MultiTermQuery.class.getName() +" but was "
-                    + subQuery.getClass().getName());
-        }
-        return new SpanMultiTermQueryWrapper<>((MultiTermQuery) subQuery);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (multiTermQueryBuilder == null) {
-            validationException = addValidationError("inner clause ["+ SpanMultiTermQueryParser.MATCH_NAME +"] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(multiTermQueryBuilder, validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected SpanMultiTermQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        MultiTermQueryBuilder multiTermBuilder = (MultiTermQueryBuilder)in.readQuery();
-        return new SpanMultiTermQueryBuilder(multiTermBuilder);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(multiTermQueryBuilder);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(multiTermQueryBuilder);
-    }
-
-    @Override
-    protected boolean doEquals(SpanMultiTermQueryBuilder other) {
-        return Objects.equals(multiTermQueryBuilder, other.multiTermQueryBuilder);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java
index 77e9def..a44580a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanMultiTermQueryParser.java
@@ -18,17 +18,22 @@
  */
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.MultiTermQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.XContentParser.Token;
 
 import java.io.IOException;
 
 /**
- * Parser for span_multi query
+ *
  */
-public class SpanMultiTermQueryParser extends BaseQueryParser<SpanMultiTermQueryBuilder> {
+public class SpanMultiTermQueryParser implements QueryParser {
 
+    public static final String NAME = "span_multi";
     public static final String MATCH_NAME = "match";
 
     @Inject
@@ -37,50 +42,29 @@ public class SpanMultiTermQueryParser extends BaseQueryParser<SpanMultiTermQuery
 
     @Override
     public String[] names() {
-        return new String[]{SpanMultiTermQueryBuilder.NAME, Strings.toCamelCase(SpanMultiTermQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanMultiTermQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        String currentFieldName = null;
-        MultiTermQueryBuilder subQuery = null;
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        XContentParser.Token token;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                currentFieldName = parser.currentName();
-            } else if (token == XContentParser.Token.START_OBJECT) {
-                if (MATCH_NAME.equals(currentFieldName)) {
-                    QueryBuilder innerQuery = parseContext.parseInnerQueryBuilder();
-                    if (innerQuery instanceof MultiTermQueryBuilder == false) {
-                        throw new QueryParsingException(parseContext, "[span_multi] [" + MATCH_NAME + "] must be of type multi term query");
-                    }
-                    subQuery = (MultiTermQueryBuilder) innerQuery;
-                } else {
-                    throw new QueryParsingException(parseContext, "[span_multi] query does not support [" + currentFieldName + "]");
-                }
-            } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
-                } else {
-                    throw new QueryParsingException(parseContext, "[span_multi] query does not support [" + currentFieldName + "]");
-                }
-            }
+
+        Token token = parser.nextToken();
+        if (!MATCH_NAME.equals(parser.currentName()) || token != XContentParser.Token.FIELD_NAME) {
+            throw new QueryParsingException(parseContext, "spanMultiTerm must have [" + MATCH_NAME + "] multi term query clause");
         }
 
-        if (subQuery == null) {
-            throw new QueryParsingException(parseContext, "[span_multi] must have [" + MATCH_NAME + "] multi term query clause");
+        token = parser.nextToken();
+        if (token != XContentParser.Token.START_OBJECT) {
+            throw new QueryParsingException(parseContext, "spanMultiTerm must have [" + MATCH_NAME + "] multi term query clause");
         }
 
-        return new SpanMultiTermQueryBuilder(subQuery).queryName(queryName).boost(boost);
-    }
+        Query subQuery = parseContext.parseInnerQuery();
+        if (!(subQuery instanceof MultiTermQuery)) {
+            throw new QueryParsingException(parseContext, "spanMultiTerm [" + MATCH_NAME + "] must be of type multi term query");
+        }
 
-    @Override
-    public SpanMultiTermQueryBuilder getBuilderPrototype() {
-        return SpanMultiTermQueryBuilder.PROTOTYPE;
+        parser.nextToken();
+        return new SpanMultiTermQueryWrapper<>((MultiTermQuery) subQuery);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java
index e00cc32..cb05e08 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryBuilder.java
@@ -19,179 +19,86 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNearQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.List;
-import java.util.Objects;
 
-/**
- * Matches spans which are near one another. One can specify slop, the maximum number
- * of intervening unmatched positions, as well as whether matches are required to be in-order.
- * The span near query maps to Lucene {@link SpanNearQuery}.
- */
-public class SpanNearQueryBuilder extends AbstractQueryBuilder<SpanNearQueryBuilder> implements SpanQueryBuilder<SpanNearQueryBuilder> {
-
-    public static final String NAME = "span_near";
-
-    /** Default for flag controlling whether matches are required to be in-order */
-    public static boolean DEFAULT_IN_ORDER = true;
-
-    /** Default for flag controlling whether payloads are collected */
-    public static boolean DEFAULT_COLLECT_PAYLOADS = true;
+public class SpanNearQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanNearQueryBuilder> {
 
-    private final List<SpanQueryBuilder> clauses = new ArrayList<>();
+    private ArrayList<SpanQueryBuilder> clauses = new ArrayList<>();
 
-    private final int slop;
+    private Integer slop = null;
 
-    private boolean inOrder = DEFAULT_IN_ORDER;
+    private Boolean inOrder;
 
-    private boolean collectPayloads = DEFAULT_COLLECT_PAYLOADS;
+    private Boolean collectPayloads;
 
-    static final SpanNearQueryBuilder PROTOTYPE = new SpanNearQueryBuilder(0);
+    private float boost = -1;
 
-    /**
-     * @param slop controls the maximum number of intervening unmatched positions permitted
-     */
-    public SpanNearQueryBuilder(int slop) {
-        this.slop = slop;
-    }
-
-    /**
-     * @return the maximum number of intervening unmatched positions permitted
-     */
-    public int slop() {
-        return this.slop;
-    }
+    private String queryName;
 
     public SpanNearQueryBuilder clause(SpanQueryBuilder clause) {
         clauses.add(clause);
         return this;
     }
 
-    /**
-     * @return the {@link SpanQueryBuilder} clauses that were set for this query
-     */
-    public List<SpanQueryBuilder> clauses() {
-        return this.clauses;
+    public SpanNearQueryBuilder slop(int slop) {
+        this.slop = slop;
+        return this;
     }
 
-    /**
-     * When <code>inOrder</code> is true, the spans from each clause
-     * must be in the same order as in <code>clauses</code> and must be non-overlapping.
-     * Defaults to <code>true</code>
-     */
     public SpanNearQueryBuilder inOrder(boolean inOrder) {
         this.inOrder = inOrder;
         return this;
     }
 
-    /**
-     * @see SpanNearQueryBuilder#inOrder(boolean))
-     */
-    public boolean inOrder() {
-        return this.inOrder;
-    }
-
-    /**
-     * @param collectPayloads flag controlling whether payloads are collected
-     */
     public SpanNearQueryBuilder collectPayloads(boolean collectPayloads) {
         this.collectPayloads = collectPayloads;
         return this;
     }
 
+    @Override
+    public SpanNearQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
     /**
-     * @see SpanNearQueryBuilder#collectPayloads(boolean))
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public boolean collectPayloads() {
-        return this.collectPayloads;
+    public SpanNearQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        if (clauses.isEmpty()) {
+            throw new IllegalArgumentException("Must have at least one clause when building a spanNear query");
+        }
+        if (slop == null) {
+            throw new IllegalArgumentException("Must set the slop when building a spanNear query");
+        }
+        builder.startObject(SpanNearQueryParser.NAME);
         builder.startArray("clauses");
         for (SpanQueryBuilder clause : clauses) {
             clause.toXContent(builder, params);
         }
         builder.endArray();
-        builder.field("slop", slop);
-        builder.field("in_order", inOrder);
-        builder.field("collect_payloads", collectPayloads);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        SpanQuery[] spanQueries = new SpanQuery[clauses.size()];
-        for (int i = 0; i < clauses.size(); i++) {
-            Query query = clauses.get(i).toQuery(context);
-            assert query instanceof SpanQuery;
-            spanQueries[i] = (SpanQuery) query;
+        builder.field("slop", slop.intValue());
+        if (inOrder != null) {
+            builder.field("in_order", inOrder);
         }
-        return new SpanNearQuery(spanQueries, slop, inOrder, collectPayloads);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (clauses.isEmpty()) {
-            validationException =  addValidationError("query must include [clauses]", validationException);
+        if (collectPayloads != null) {
+            builder.field("collect_payloads", collectPayloads);
         }
-        for (SpanQueryBuilder innerClause : clauses) {
-            if (innerClause == null) {
-                validationException =  addValidationError("[clauses] contains null element", validationException);
-            } else {
-                validationException = validateInnerQuery(innerClause, validationException);
-            }
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return validationException;
-    }
-
-    @Override
-    protected SpanNearQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(in.readVInt());
-        List<QueryBuilder> clauses = readQueries(in);
-        for (QueryBuilder subClause : clauses) {
-            queryBuilder.clauses.add((SpanQueryBuilder)subClause);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        queryBuilder.collectPayloads = in.readBoolean();
-        queryBuilder.inOrder = in.readBoolean();
-        return queryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeVInt(slop);
-        writeQueries(out, clauses);
-        out.writeBoolean(collectPayloads);
-        out.writeBoolean(inOrder);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(clauses, slop, collectPayloads, inOrder);
-    }
-
-    @Override
-    protected boolean doEquals(SpanNearQueryBuilder other) {
-        return Objects.equals(clauses, other.clauses) &&
-               Objects.equals(slop, other.slop) &&
-               Objects.equals(collectPayloads, other.collectPayloads) &&
-               Objects.equals(inOrder, other.inOrder);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java
index cc6d8bc..506bce2 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanNearQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -28,9 +31,11 @@ import java.util.ArrayList;
 import java.util.List;
 
 /**
- * Parser for span_near query
+ *
  */
-public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
+public class SpanNearQueryParser implements QueryParser {
+
+    public static final String NAME = "span_near";
 
     @Inject
     public SpanNearQueryParser() {
@@ -38,20 +43,20 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{SpanNearQueryBuilder.NAME, Strings.toCamelCase(SpanNearQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanNearQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         Integer slop = null;
-        boolean inOrder = SpanNearQueryBuilder.DEFAULT_IN_ORDER;
-        boolean collectPayloads = SpanNearQueryBuilder.DEFAULT_COLLECT_PAYLOADS;
+        boolean inOrder = true;
+        boolean collectPayloads = true;
         String queryName = null;
 
-        List<SpanQueryBuilder> clauses = new ArrayList<>();
+        List<SpanQuery> clauses = new ArrayList<>();
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -61,11 +66,11 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
             } else if (token == XContentParser.Token.START_ARRAY) {
                 if ("clauses".equals(currentFieldName)) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                        if (!(query instanceof SpanQueryBuilder)) {
+                        Query query = parseContext.parseInnerQuery();
+                        if (!(query instanceof SpanQuery)) {
                             throw new QueryParsingException(parseContext, "spanNear [clauses] must be of type span query");
                         }
-                        clauses.add((SpanQueryBuilder) query);
+                        clauses.add((SpanQuery) query);
                     }
                 } else {
                     throw new QueryParsingException(parseContext, "[span_near] query does not support [" + currentFieldName + "]");
@@ -76,7 +81,7 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
                 } else if ("collect_payloads".equals(currentFieldName) || "collectPayloads".equals(currentFieldName)) {
                     collectPayloads = parser.booleanValue();
                 } else if ("slop".equals(currentFieldName)) {
-                    slop = parser.intValue();
+                    slop = Integer.valueOf(parser.intValue());
                 } else if ("boost".equals(currentFieldName)) {
                     boost = parser.floatValue();
                 } else if ("_name".equals(currentFieldName)) {
@@ -88,24 +93,18 @@ public class SpanNearQueryParser extends BaseQueryParser<SpanNearQueryBuilder> {
                 throw new QueryParsingException(parseContext, "[span_near] query does not support [" + currentFieldName + "]");
             }
         }
-
+        if (clauses.isEmpty()) {
+            throw new QueryParsingException(parseContext, "span_near must include [clauses]");
+        }
         if (slop == null) {
             throw new QueryParsingException(parseContext, "span_near must include [slop]");
         }
 
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(slop);
-        for (SpanQueryBuilder subQuery : clauses) {
-            queryBuilder.clause(subQuery);
+        SpanNearQuery query = new SpanNearQuery(clauses.toArray(new SpanQuery[clauses.size()]), slop.intValue(), inOrder, collectPayloads);
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
         }
-        queryBuilder.inOrder(inOrder);
-        queryBuilder.collectPayloads(collectPayloads);
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
-
-    @Override
-    public SpanNearQueryBuilder getBuilderPrototype() {
-        return SpanNearQueryBuilder.PROTOTYPE;
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java
index 3af88e3..e37cd80 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryBuilder.java
@@ -19,176 +19,100 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNotQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class SpanNotQueryBuilder extends AbstractQueryBuilder<SpanNotQueryBuilder> implements SpanQueryBuilder<SpanNotQueryBuilder> {
+public class SpanNotQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanNotQueryBuilder> {
 
-    public static final String NAME = "span_not";
+    private SpanQueryBuilder include;
 
-    /** the default pre parameter size */
-    public static final int DEFAULT_PRE = 0;
-    /** the default post parameter size */
-    public static final int DEFAULT_POST = 0;
+    private SpanQueryBuilder exclude;
 
-    private final SpanQueryBuilder include;
+    private Integer dist;
 
-    private final SpanQueryBuilder exclude;
+    private Integer pre;
 
-    private int pre = DEFAULT_PRE;
+    private Integer post;
 
-    private int post = DEFAULT_POST;
+    private Float boost;
 
-    static final SpanNotQueryBuilder PROTOTYPE = new SpanNotQueryBuilder(null, null);
+    private String queryName;
 
-    /**
-     * Construct a span query matching spans from <code>include</code> which
-     * have no overlap with spans from <code>exclude</code>.
-     * @param include the span query whose matches are filtered
-     * @param exclude the span query whose matches must not overlap
-     */
-    public SpanNotQueryBuilder(SpanQueryBuilder include, SpanQueryBuilder exclude) {
+    public SpanNotQueryBuilder include(SpanQueryBuilder include) {
         this.include = include;
-        this.exclude = exclude;
-    }
-
-    /**
-     * @return the span query whose matches are filtered
-     */
-    public SpanQueryBuilder includeQuery() {
-        return this.include;
+        return this;
     }
 
-    /**
-     * @return the span query whose matches must not overlap
-     */
-    public SpanQueryBuilder excludeQuery() {
-        return this.exclude;
+    public SpanNotQueryBuilder exclude(SpanQueryBuilder exclude) {
+        this.exclude = exclude;
+        return this;
     }
 
-    /**
-     * @param dist the amount of tokens from within the include span cant have overlap with the exclude span.
-     * Equivalent to setting both pre and post parameter.
-     */
     public SpanNotQueryBuilder dist(int dist) {
-        pre(dist);
-        post(dist);
+        this.dist = dist;
         return this;
     }
 
-    /**
-     * @param pre the amount of tokens before the include span that cant have overlap with the exclude span. Values
-     * smaller than 0 will be ignored and 0 used instead.
-     */
     public SpanNotQueryBuilder pre(int pre) {
-        this.pre = (pre >= 0) ? pre : 0;
+        this.pre = (pre >=0) ? pre : 0;
         return this;
     }
 
-    /**
-     * @return the amount of tokens before the include span that cant have overlap with the exclude span.
-     * @see SpanNotQueryBuilder#pre(int)
-     */
-    public Integer pre() {
-        return this.pre;
-    }
-
-    /**
-     * @param post the amount of tokens after the include span that cant have overlap with the exclude span.
-     */
     public SpanNotQueryBuilder post(int post) {
         this.post = (post >= 0) ? post : 0;
         return this;
     }
 
-    /**
-     * @return the amount of tokens after the include span that cant have overlap with the exclude span.
-     * @see SpanNotQueryBuilder#post(int)
-     */
-    public Integer post() {
-        return this.post;
-    }
-
     @Override
-    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("include");
-        include.toXContent(builder, params);
-        builder.field("exclude");
-        exclude.toXContent(builder, params);
-        builder.field("pre", pre);
-        builder.field("post", post);
-        printBoostAndQueryName(builder);
-        builder.endObject();
+    public SpanNotQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-
-        Query includeQuery = this.include.toQuery(context);
-        assert includeQuery instanceof SpanQuery;
-        Query excludeQuery = this.exclude.toQuery(context);
-        assert excludeQuery instanceof SpanQuery;
-
-        return new SpanNotQuery((SpanQuery) includeQuery, (SpanQuery) excludeQuery, pre, post);
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     * @param queryName The query name
+     * @return this
+     */
+    public SpanNotQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
+    protected void doXContent(XContentBuilder builder, Params params) throws IOException {
         if (include == null) {
-            validationException = addValidationError("inner clause [include] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(include, validationException);
+            throw new IllegalArgumentException("Must specify include when using spanNot query");
         }
         if (exclude == null) {
-            validationException = addValidationError("inner clause [exclude] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(exclude, validationException);
+            throw new IllegalArgumentException("Must specify exclude when using spanNot query");
         }
-        return validationException;
-    }
-
-    @Override
-    protected SpanNotQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder include = (SpanQueryBuilder)in.readQuery();
-        SpanQueryBuilder exclude = (SpanQueryBuilder)in.readQuery();
-        SpanNotQueryBuilder queryBuilder = new SpanNotQueryBuilder(include, exclude);
-        queryBuilder.pre(in.readVInt());
-        queryBuilder.post(in.readVInt());
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(include);
-        out.writeQuery(exclude);
-        out.writeVInt(pre);
-        out.writeVInt(post);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(include, exclude, pre, post);
-    }
 
-    @Override
-    protected boolean doEquals(SpanNotQueryBuilder other) {
-        return Objects.equals(include, other.include) &&
-               Objects.equals(exclude, other.exclude) &&
-               (pre == other.pre) &&
-               (post == other.post);
-    }
+        if (dist != null && (pre != null || post != null)) {
+             throw new IllegalArgumentException("spanNot can either use [dist] or [pre] & [post] (or none)");
+        }
 
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.startObject(SpanNotQueryParser.NAME);
+        builder.field("include");
+        include.toXContent(builder, params);
+        builder.field("exclude");
+        exclude.toXContent(builder, params);
+        if (dist != null) {
+            builder.field("dist", dist);
+        }
+        if (pre != null) {
+            builder.field("pre", pre);
+        }
+        if (post != null) {
+            builder.field("post", post);
+        }
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java
index bc9ee51..bcb62e7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanNotQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanNotQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_not query
+ *
  */
-public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
+public class SpanNotQueryParser implements QueryParser {
+
+    public static final String NAME = "span_not";
 
     @Inject
     public SpanNotQueryParser() {
@@ -36,17 +41,17 @@ public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{SpanNotQueryBuilder.NAME, Strings.toCamelCase(SpanNotQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanNotQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
 
-        SpanQueryBuilder include = null;
-        SpanQueryBuilder exclude = null;
+        SpanQuery include = null;
+        SpanQuery exclude = null;
 
         Integer dist = null;
         Integer pre  = null;
@@ -61,17 +66,17 @@ public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("include".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "spanNot [include] must be of type span query");
                     }
-                    include = (SpanQueryBuilder) query;
+                    include = (SpanQuery) query;
                 } else if ("exclude".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (!(query instanceof SpanQueryBuilder)) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (!(query instanceof SpanQuery)) {
                         throw new QueryParsingException(parseContext, "spanNot [exclude] must be of type span query");
                     }
-                    exclude = (SpanQueryBuilder) query;
+                    exclude = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_not] query does not support [" + currentFieldName + "]");
                 }
@@ -101,23 +106,26 @@ public class SpanNotQueryParser extends BaseQueryParser<SpanNotQueryBuilder> {
             throw new QueryParsingException(parseContext, "spanNot can either use [dist] or [pre] & [post] (or none)");
         }
 
-        SpanNotQueryBuilder spanNotQuery = new SpanNotQueryBuilder(include, exclude);
-        if (dist != null) {
-            spanNotQuery.dist(dist);
+        // set appropriate defaults
+        if (pre != null && post == null) {
+            post = 0;
+        } else if (pre == null && post != null){
+            pre = 0;
         }
-        if (pre != null) {
-            spanNotQuery.pre(pre);
-        }
-        if (post != null) {
-            spanNotQuery.post(post);
+
+        SpanNotQuery query;
+        if (pre != null && post != null) {
+            query = new SpanNotQuery(include, exclude, pre, post);
+        } else if (dist != null) {
+            query = new SpanNotQuery(include, exclude, dist);
+        } else {
+            query = new SpanNotQuery(include, exclude);
         }
-        spanNotQuery.boost(boost);
-        spanNotQuery.queryName(queryName);
-        return spanNotQuery;
-    }
 
-    @Override
-    public SpanNotQueryBuilder getBuilderPrototype() {
-        return SpanNotQueryBuilder.PROTOTYPE;
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java
index 8e9b7ae..0042aa7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryBuilder.java
@@ -19,108 +19,55 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanOrQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.List;
-import java.util.Objects;
 
-/**
- * Span query that matches the union of its clauses. Maps to {@link SpanOrQuery}.
- */
-public class SpanOrQueryBuilder extends AbstractQueryBuilder<SpanOrQueryBuilder> implements SpanQueryBuilder<SpanOrQueryBuilder> {
+public class SpanOrQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanOrQueryBuilder> {
 
-    public static final String NAME = "span_or";
+    private ArrayList<SpanQueryBuilder> clauses = new ArrayList<>();
 
-    private final List<SpanQueryBuilder> clauses = new ArrayList<>();
+    private float boost = -1;
 
-    static final SpanOrQueryBuilder PROTOTYPE = new SpanOrQueryBuilder();
+    private String queryName;
 
     public SpanOrQueryBuilder clause(SpanQueryBuilder clause) {
         clauses.add(clause);
         return this;
     }
 
+    @Override
+    public SpanOrQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
     /**
-     * @return the {@link SpanQueryBuilder} clauses that were set for this query
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public List<SpanQueryBuilder> clauses() {
-        return this.clauses;
+    public SpanOrQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        if (clauses.isEmpty()) {
+            throw new IllegalArgumentException("Must have at least one clause when building a spanOr query");
+        }
+        builder.startObject(SpanOrQueryParser.NAME);
         builder.startArray("clauses");
         for (SpanQueryBuilder clause : clauses) {
             clause.toXContent(builder, params);
         }
         builder.endArray();
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        SpanQuery[] spanQueries = new SpanQuery[clauses.size()];
-        for (int i = 0; i < clauses.size(); i++) {
-            Query query = clauses.get(i).toQuery(context);
-            assert query instanceof SpanQuery;
-            spanQueries[i] = (SpanQuery) query;
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        return new SpanOrQuery(spanQueries);
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (clauses.isEmpty()) {
-            validationException =  addValidationError("query must include [clauses]", validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        for (SpanQueryBuilder innerClause : clauses) {
-            if (innerClause == null) {
-                validationException =  addValidationError("[clauses] contains null element", validationException);
-            } else {
-                validationException = validateInnerQuery(innerClause, validationException);
-            }
-        }
-        return validationException;
-    }
-
-    @Override
-    protected SpanOrQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        List<QueryBuilder> clauses = readQueries(in);
-        for (QueryBuilder subClause : clauses) {
-            queryBuilder.clauses.add((SpanQueryBuilder)subClause);
-        }
-        return queryBuilder;
-
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        writeQueries(out, clauses);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(clauses);
-    }
-
-    @Override
-    protected boolean doEquals(SpanOrQueryBuilder other) {
-        return Objects.equals(clauses, other.clauses);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java
index c424f66..e28a9cc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java
@@ -19,7 +19,11 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanOrQuery;
+import org.apache.lucene.search.spans.SpanQuery;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
@@ -27,23 +31,29 @@ import java.util.ArrayList;
 import java.util.List;
 
 /**
- * Parser for span_or query
+ *
  */
-public class SpanOrQueryParser extends BaseQueryParser<SpanOrQueryBuilder> {
+public class SpanOrQueryParser implements QueryParser {
+
+    public static final String NAME = "span_or";
+
+    @Inject
+    public SpanOrQueryParser() {
+    }
 
     @Override
     public String[] names() {
-        return new String[]{SpanOrQueryBuilder.NAME, Strings.toCamelCase(SpanOrQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanOrQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String queryName = null;
 
-        List<SpanQueryBuilder> clauses = new ArrayList<>();
+        List<SpanQuery> clauses = new ArrayList<>();
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -53,11 +63,11 @@ public class SpanOrQueryParser extends BaseQueryParser<SpanOrQueryBuilder> {
             } else if (token == XContentParser.Token.START_ARRAY) {
                 if ("clauses".equals(currentFieldName)) {
                     while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                        if (!(query instanceof SpanQueryBuilder)) {
+                        Query query = parseContext.parseInnerQuery();
+                        if (!(query instanceof SpanQuery)) {
                             throw new QueryParsingException(parseContext, "spanOr [clauses] must be of type span query");
                         }
-                        clauses.add((SpanQueryBuilder) query);
+                        clauses.add((SpanQuery) query);
                     }
                 } else {
                     throw new QueryParsingException(parseContext, "[span_or] query does not support [" + currentFieldName + "]");
@@ -76,17 +86,11 @@ public class SpanOrQueryParser extends BaseQueryParser<SpanOrQueryBuilder> {
             throw new QueryParsingException(parseContext, "spanOr must include [clauses]");
         }
 
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        for (SpanQueryBuilder clause : clauses) {
-            queryBuilder.clause(clause);
+        SpanOrQuery query = new SpanOrQuery(clauses.toArray(new SpanQuery[clauses.size()]));
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
         }
-        queryBuilder.boost(boost);
-        queryBuilder.queryName(queryName);
-        return queryBuilder;
-    }
-
-    @Override
-    public SpanOrQueryBuilder getBuilderPrototype() {
-        return SpanOrQueryBuilder.PROTOTYPE;
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java
index d35dcbc..4216f22 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanQueryBuilder.java
@@ -19,9 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-/**
- * Marker interface for a specific type of {@link QueryBuilder} that allows to build span queries
- */
-public interface SpanQueryBuilder<QB extends SpanQueryBuilder> extends QueryBuilder<QB> {
+public abstract class SpanQueryBuilder extends QueryBuilder {
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java
index 24cd816..9d0176e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryBuilder.java
@@ -19,76 +19,75 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.apache.lucene.search.spans.SpanTermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 
-/**
- * A Span Query that matches documents containing a term.
- * @see SpanTermQuery
- */
-public class SpanTermQueryBuilder extends BaseTermQueryBuilder<SpanTermQueryBuilder> implements SpanQueryBuilder<SpanTermQueryBuilder> {
+public class SpanTermQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanTermQueryBuilder> {
+
+    private final String name;
+
+    private final Object value;
+
+    private float boost = -1;
 
-    public static final String NAME = "span_term";
-    static final SpanTermQueryBuilder PROTOTYPE = new SpanTermQueryBuilder(null, null);
+    private String queryName;
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, String) */
     public SpanTermQueryBuilder(String name, String value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, int) */
     public SpanTermQueryBuilder(String name, int value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, long) */
     public SpanTermQueryBuilder(String name, long value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, float) */
     public SpanTermQueryBuilder(String name, float value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, double) */
     public SpanTermQueryBuilder(String name, double value) {
-        super(name, (Object) value);
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, Object) */
-    public SpanTermQueryBuilder(String name, Object value) {
-        super(name, value);
+    private SpanTermQueryBuilder(String name, Object value) {
+        this.name = name;
+        this.value = value;
     }
 
     @Override
-    public SpanQuery doToQuery(QueryShardContext context) throws IOException {
-        BytesRef valueBytes = null;
-        String fieldName = this.fieldName;
-        MappedFieldType mapper = context.fieldMapper(fieldName);
-        if (mapper != null) {
-            fieldName = mapper.names().indexName();
-            valueBytes = mapper.indexedValueForSearch(value);
-        }
-        if (valueBytes == null) {
-            valueBytes = BytesRefs.toBytesRef(this.value);
-        }
-        return new SpanTermQuery(new Term(fieldName, valueBytes));
+    public SpanTermQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected SpanTermQueryBuilder createBuilder(String fieldName, Object value) {
-        return new SpanTermQueryBuilder(fieldName, value);
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public SpanTermQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public String getWriteableName() {
-        return NAME;
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(SpanTermQueryParser.NAME);
+        if (boost == -1 && queryName != null) {
+            builder.field(name, value);
+        } else {
+            builder.startObject(name);
+            builder.field("value", value);
+            if (boost != -1) {
+                builder.field("boost", boost);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
+        }
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java
index 824b474..c4ff2ee 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanTermQueryParser.java
@@ -19,16 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
 
 /**
- * Parser for span_term query
+ *
  */
-public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
+public class SpanTermQueryParser implements QueryParser {
+
+    public static final String NAME = "span_term";
 
     @Inject
     public SpanTermQueryParser() {
@@ -36,24 +43,23 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{SpanTermQueryBuilder.NAME, Strings.toCamelCase(SpanTermQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanTermQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.currentToken();
         if (token == XContentParser.Token.START_OBJECT) {
             token = parser.nextToken();
         }
-
         assert token == XContentParser.Token.FIELD_NAME;
         String fieldName = parser.currentName();
 
 
-        Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        String value = null;
+        float boost = 1.0f;
         String queryName = null;
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
@@ -63,9 +69,9 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
                     currentFieldName = parser.currentName();
                 } else {
                     if ("term".equals(currentFieldName)) {
-                        value = parser.objectBytes();
+                        value = parser.text();
                     } else if ("value".equals(currentFieldName)) {
-                        value = parser.objectBytes();
+                        value = parser.text();
                     } else if ("boost".equals(currentFieldName)) {
                         boost = parser.floatValue();
                     } else if ("_name".equals(currentFieldName)) {
@@ -77,7 +83,7 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
             }
             parser.nextToken();
         } else {
-            value = parser.objectBytes();
+            value = parser.text();
             // move to the next token
             parser.nextToken();
         }
@@ -86,13 +92,21 @@ public class SpanTermQueryParser extends BaseQueryParser<SpanTermQueryBuilder> {
             throw new QueryParsingException(parseContext, "No value specified for term query");
         }
 
-        SpanTermQueryBuilder result = new SpanTermQueryBuilder(fieldName, value);
-        result.boost(boost).queryName(queryName);
-        return result;
-    }
+        BytesRef valueBytes = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            fieldName = fieldType.names().indexName();
+            valueBytes = fieldType.indexedValueForSearch(value);
+        }
+        if (valueBytes == null) {
+            valueBytes = new BytesRef(value);
+        }
 
-    @Override
-    public SpanTermQueryBuilder getBuilderPrototype() {
-        return SpanTermQueryBuilder.PROTOTYPE;
+        SpanTermQuery query = new SpanTermQuery(new Term(fieldName, valueBytes));
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java
index 8751a16..d2b2fdc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryBuilder.java
@@ -19,53 +19,59 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.apache.lucene.search.spans.SpanWithinQuery;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * Builder for {@link org.apache.lucene.search.spans.SpanWithinQuery}.
  */
-public class SpanWithinQueryBuilder extends AbstractQueryBuilder<SpanWithinQueryBuilder> implements SpanQueryBuilder<SpanWithinQueryBuilder> {
+public class SpanWithinQueryBuilder extends SpanQueryBuilder implements BoostableQueryBuilder<SpanWithinQueryBuilder> {
 
-    public static final String NAME = "span_within";
-    private final SpanQueryBuilder big;
-    private final SpanQueryBuilder little;
-    static final SpanWithinQueryBuilder PROTOTYPE = new SpanWithinQueryBuilder(null, null);
+    private SpanQueryBuilder big;
+    private SpanQueryBuilder little;
+    private float boost = -1;
+    private String queryName;
 
-    /**
-     * Query that returns spans from <code>little</code> that are contained in a spans from <code>big</code>.
-     * @param big clause that must enclose {@code little} for a match.
-     * @param little the little clause, it must be contained within {@code big} for a match.
+    /** 
+     * Sets the little clause, it must be contained within {@code big} for a match.
      */
-    public SpanWithinQueryBuilder(SpanQueryBuilder big, SpanQueryBuilder little) {
-        this.little = little;
-        this.big = big;
+    public SpanWithinQueryBuilder little(SpanQueryBuilder clause) {
+        this.little = clause;
+        return this;
     }
 
-    /**
-     * @return the little clause, contained within {@code big} for a match.
+    /** 
+     * Sets the big clause, it must enclose {@code little} for a match.
      */
-    public SpanQueryBuilder littleQuery() {
-        return this.little;
+    public SpanWithinQueryBuilder big(SpanQueryBuilder clause) {
+        this.big = clause;
+        return this;
+    }
+
+    @Override
+    public SpanWithinQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
     /**
-     * @return the big clause that must enclose {@code little} for a match.
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
      */
-    public SpanQueryBuilder bigQuery() {
-        return this.big;
+    public SpanWithinQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
+        if (big == null) {
+            throw new IllegalArgumentException("Must specify big clause when building a span_within query");
+        }
+        if (little == null) {
+            throw new IllegalArgumentException("Must specify little clause when building a span_within query");
+        }
+        builder.startObject(SpanWithinQueryParser.NAME);
 
         builder.field("big");
         big.toXContent(builder, params);
@@ -73,70 +79,14 @@ public class SpanWithinQueryBuilder extends AbstractQueryBuilder<SpanWithinQuery
         builder.field("little");
         little.toXContent(builder, params);
 
-        printBoostAndQueryName(builder);
-
-        builder.endObject();
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query innerBig = big.toQuery(context);
-        assert innerBig instanceof SpanQuery;
-        Query innerLittle = little.toQuery(context);
-        assert innerLittle instanceof SpanQuery;
-        return new SpanWithinQuery((SpanQuery) innerBig, (SpanQuery) innerLittle);
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        if (boost != AbstractQueryBuilder.DEFAULT_BOOST) {
-            //preserve potential inner boost coming from lucene (default is little.boost)
-            query.setBoost(boost);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-    }
 
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (big == null) {
-            validationException = addValidationError("inner clause [big] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(big, validationException);
-        }
-        if (little == null) {
-            validationException = addValidationError("inner clause [little] cannot be null.", validationException);
-        } else {
-            validationException = validateInnerQuery(little, validationException);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        return validationException;
-    }
-
-    @Override
-    protected SpanWithinQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        SpanQueryBuilder big = (SpanQueryBuilder)in.readQuery();
-        SpanQueryBuilder little = (SpanQueryBuilder)in.readQuery();
-        return new SpanWithinQueryBuilder(big, little);
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeQuery(big);
-        out.writeQuery(little);
-    }
 
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(big, little);
-    }
-
-    @Override
-    protected boolean doEquals(SpanWithinQueryBuilder other) {
-        return Objects.equals(big, other.big) &&
-               Objects.equals(little, other.little);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java
index 00ddb0e..c801e0d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java
@@ -19,6 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.spans.SpanQuery;
+import org.apache.lucene.search.spans.SpanWithinQuery;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -26,9 +29,11 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import java.io.IOException;
 
 /**
- * Parser for span_within query
+ * Parser for {@link SpanWithinQuery}
  */
-public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilder> {
+public class SpanWithinQueryParser implements QueryParser {
+
+    public static final String NAME = "span_within";
 
     @Inject
     public SpanWithinQueryParser() {
@@ -36,17 +41,17 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
 
     @Override
     public String[] names() {
-        return new String[]{SpanWithinQueryBuilder.NAME, Strings.toCamelCase(SpanWithinQueryBuilder.NAME)};
+        return new String[]{NAME, Strings.toCamelCase(NAME)};
     }
 
     @Override
-    public SpanWithinQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String queryName = null;
-        SpanQueryBuilder big = null;
-        SpanQueryBuilder little = null;
+        SpanQuery big = null;
+        SpanQuery little = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
@@ -55,17 +60,17 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
                 currentFieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("big".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (query instanceof SpanQueryBuilder == false) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (query instanceof SpanQuery == false) {
                         throw new QueryParsingException(parseContext, "span_within [big] must be of type span query");
                     }
-                    big = (SpanQueryBuilder) query;
+                    big = (SpanQuery) query;
                 } else if ("little".equals(currentFieldName)) {
-                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
-                    if (query instanceof SpanQueryBuilder == false) {
+                    Query query = parseContext.parseInnerQuery();
+                    if (query instanceof SpanQuery == false) {
                         throw new QueryParsingException(parseContext, "span_within [little] must be of type span query");
                     }
-                    little = (SpanQueryBuilder) query;
+                    little = (SpanQuery) query;
                 } else {
                     throw new QueryParsingException(parseContext, "[span_within] query does not support [" + currentFieldName + "]");
                 }
@@ -76,8 +81,8 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
             } else {
                 throw new QueryParsingException(parseContext, "[span_within] query does not support [" + currentFieldName + "]");
             }
-        }
-
+        }        
+        
         if (big == null) {
             throw new QueryParsingException(parseContext, "span_within must include [big]");
         }
@@ -85,13 +90,13 @@ public class SpanWithinQueryParser extends BaseQueryParser<SpanWithinQueryBuilde
             throw new QueryParsingException(parseContext, "span_within must include [little]");
         }
 
-        SpanWithinQueryBuilder query = new SpanWithinQueryBuilder(big, little);
-        query.boost(boost).queryName(queryName);
+        Query query = new SpanWithinQuery(big, little);
+        if (boost != 1.0F) {
+            query.setBoost(boost);
+        }
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
         return query;
     }
-
-    @Override
-    public SpanWithinQueryBuilder getBuilderPrototype() {
-        return SpanWithinQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java
index 5c912de..852977f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryBuilder.java
@@ -18,33 +18,26 @@
  */
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.script.Template;
-import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 import java.util.Map;
-import java.util.Objects;
 
 /**
  * Facilitates creating template query requests.
  * */
-public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuilder> {
-
-    /** Name to reference this type of query. */
-    public static final String NAME = "template";
+public class TemplateQueryBuilder extends QueryBuilder {
 
     /** Template to fill. */
-    private final Template template;
+    private Template template;
+    /** Parameters to fill the template with. */
+    private Map<String, Object> vars;
+    /** Template to fill.*/
+    private String templateString;
 
-    static final TemplateQueryBuilder PROTOTYPE = new TemplateQueryBuilder(null);
+    private ScriptService.ScriptType templateType;
 
     /**
      * @param template
@@ -54,10 +47,6 @@ public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuil
         this.template = template;
     }
 
-    public Template template() {
-        return template;
-    }
-
     /**
      * @param template
      *            the template to use for that query.
@@ -67,7 +56,7 @@ public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuil
      * */
     @Deprecated
     public TemplateQueryBuilder(String template, Map<String, Object> vars) {
-        this(new Template(template, ScriptService.ScriptType.INLINE, null, null, vars));
+        this(template, ScriptService.ScriptType.INLINE, vars);
     }
 
     /**
@@ -81,64 +70,18 @@ public class TemplateQueryBuilder extends AbstractQueryBuilder<TemplateQueryBuil
      * */
     @Deprecated
     public TemplateQueryBuilder(String template, ScriptService.ScriptType templateType, Map<String, Object> vars) {
-        this(new Template(template, templateType, null, null, vars));
+        this.templateString = template;
+        this.vars = vars;
+        this.templateType = templateType;
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params builderParams) throws IOException {
-        builder.field(TemplateQueryBuilder.NAME);
-        template.toXContent(builder, builderParams);
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        BytesReference querySource = context.executeQueryTemplate(template, SearchContext.current());
-        try (XContentParser qSourceParser = XContentFactory.xContent(querySource).createParser(querySource)) {
-            final QueryShardContext contextCopy = new QueryShardContext(context.index(), context.indexQueryParserService());
-            contextCopy.reset(qSourceParser);
-            QueryBuilder result = contextCopy.parseContext().parseInnerQueryBuilder();
-            context.combineNamedQueries(contextCopy);
-            return result.toQuery(context);
-        }
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        //no-op this query doesn't support boost
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.template == null) {
-            validationException = addValidationError("query template cannot be null", validationException);
+        builder.field(TemplateQueryParser.NAME);
+        if (template == null) {
+            new Template(templateString, templateType, null, null, this.vars).toXContent(builder, builderParams);
+        } else {
+            template.toXContent(builder, builderParams);
         }
-        return validationException;
-    }
-
-    @Override
-    protected TemplateQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        TemplateQueryBuilder templateQueryBuilder = new TemplateQueryBuilder(Template.readTemplate(in));
-        return templateQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        template.writeTo(out);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(template);
-    }
-
-    @Override
-    protected boolean doEquals(TemplateQueryBuilder other) {
-        return Objects.equals(template, other.template);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
index b74e276..1b5210d 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
@@ -18,11 +18,18 @@
  */
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseFieldMatcher;
+import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.script.ExecutableScript;
+import org.elasticsearch.script.ScriptContext;
 import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.script.Template;
+import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 import java.util.HashMap;
@@ -32,7 +39,14 @@ import java.util.Map;
  * In the simplest case, parse template string and variables from the request,
  * compile the template and execute the template against the given variables.
  * */
-public class TemplateQueryParser extends BaseQueryParser<TemplateQueryBuilder> {
+public class TemplateQueryParser implements QueryParser {
+
+    /** Name to reference this type of query. */
+    public static final String NAME = "template";
+    /** Name of query parameter containing the template string. */
+    public static final String QUERY = "query";
+
+    private final ScriptService scriptService;
 
     private final static Map<String, ScriptService.ScriptType> parametersToTypes = new HashMap<>();
     static {
@@ -41,9 +55,14 @@ public class TemplateQueryParser extends BaseQueryParser<TemplateQueryBuilder> {
         parametersToTypes.put("id", ScriptService.ScriptType.INDEXED);
     }
 
+    @Inject
+    public TemplateQueryParser(ScriptService scriptService) {
+        this.scriptService = scriptService;
+    }
+
     @Override
     public String[] names() {
-        return new String[] {TemplateQueryBuilder.NAME};
+        return new String[] { NAME };
     }
 
     /**
@@ -51,17 +70,27 @@ public class TemplateQueryParser extends BaseQueryParser<TemplateQueryBuilder> {
      * values. Handles both submitting the template as part of the request as
      * well as referencing only the template name.
      *
-     * @param parseContext parse context containing the templated query.
+     * @param parseContext
+     *            parse context containing the templated query.
      */
     @Override
     @Nullable
-    public TemplateQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException {
         XContentParser parser = parseContext.parser();
         Template template = parse(parser, parseContext.parseFieldMatcher());
-        return new TemplateQueryBuilder(template);
+        ExecutableScript executable = this.scriptService.executable(template, ScriptContext.Standard.SEARCH, SearchContext.current());
+
+        BytesReference querySource = (BytesReference) executable.run();
+
+        try (XContentParser qSourceParser = XContentFactory.xContent(querySource).createParser(querySource)) {
+            final QueryParseContext context = new QueryParseContext(parseContext.index(), parseContext.indexQueryParserService());
+            context.reset(qSourceParser);
+            return context.parseInnerQuery();
+        }
     }
 
     public static Template parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, String... parameters) throws IOException {
+
         Map<String, ScriptService.ScriptType> parameterMap = new HashMap<>(parametersToTypes);
         for (String parameter : parameters) {
             parameterMap.put(parameter, ScriptService.ScriptType.INLINE);
@@ -85,9 +114,4 @@ public class TemplateQueryParser extends BaseQueryParser<TemplateQueryBuilder> {
     public static Template parse(XContentParser parser, Map<String, ScriptService.ScriptType> parameterMap, ParseFieldMatcher parseFieldMatcher) throws IOException {
         return Template.parse(parser, parameterMap, parseFieldMatcher);
     }
-
-    @Override
-    public TemplateQueryBuilder getBuilderPrototype() {
-        return TemplateQueryBuilder.PROTOTYPE;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java
index 5c8bf3f..5bd911a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermQueryBuilder.java
@@ -19,77 +19,128 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 
 /**
  * A Query that matches documents containing a term.
  */
-public class TermQueryBuilder extends BaseTermQueryBuilder<TermQueryBuilder> {
+public class TermQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<TermQueryBuilder> {
 
-    public static final String NAME = "term";
-    static final TermQueryBuilder PROTOTYPE = new TermQueryBuilder(null, null);
+    private final String name;
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, String) */
-    public TermQueryBuilder(String fieldName, String value) {
-        super(fieldName, (Object) value);
+    private final Object value;
+
+    private float boost = -1;
+
+    private String queryName;
+
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, String value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, int) */
-    public TermQueryBuilder(String fieldName, int value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, int value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, long) */
-    public TermQueryBuilder(String fieldName, long value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, long value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, float) */
-    public TermQueryBuilder(String fieldName, float value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, float value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, double) */
-    public TermQueryBuilder(String fieldName, double value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, double value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, boolean) */
-    public TermQueryBuilder(String fieldName, boolean value) {
-        super(fieldName, (Object) value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, boolean value) {
+        this(name, (Object) value);
     }
 
-    /** @see BaseTermQueryBuilder#BaseTermQueryBuilder(String, Object) */
-    public TermQueryBuilder(String fieldName, Object value) {
-        super(fieldName, value);
+    /**
+     * Constructs a new term query.
+     *
+     * @param name  The name of the field
+     * @param value The value of the term
+     */
+    public TermQueryBuilder(String name, Object value) {
+        this.name = name;
+        this.value = value;
     }
 
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    public Query doToQuery(QueryShardContext context) throws IOException {
-        Query query = null;
-        MappedFieldType mapper = context.fieldMapper(this.fieldName);
-        if (mapper != null) {
-            query = mapper.termQuery(this.value, context);
-        }
-        if (query == null) {
-            query = new TermQuery(new Term(this.fieldName, BytesRefs.toBytesRef(this.value)));
-        }
-        return query;
+    public TermQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    protected TermQueryBuilder createBuilder(String fieldName, Object value) {
-        return new TermQueryBuilder(fieldName, value);
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public TermQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    public String getWriteableName() {
-        return NAME;
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(TermQueryParser.NAME);
+        if (boost == -1 && queryName == null) {
+            builder.field(name, value);
+        } else {
+            builder.startObject(name);
+            builder.field("value", value);
+            if (boost != -1) {
+                builder.field("boost", boost);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
+        }
+        builder.endObject();
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java
index 43d4d95..1c3876f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermQueryParser.java
@@ -19,16 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
 
 import java.io.IOException;
 
 /**
- * Parser for the term query
+ *
  */
-public class TermQueryParser extends BaseQueryParser<TermQueryBuilder> {
+public class TermQueryParser implements QueryParser {
+
+    public static final String NAME = "term";
 
     private static final ParseField NAME_FIELD = new ParseField("_name").withAllDeprecated("query name is not supported in short version of term query");
     private static final ParseField BOOST_FIELD = new ParseField("boost").withAllDeprecated("boost is not supported in short version of term query");
@@ -39,17 +46,17 @@ public class TermQueryParser extends BaseQueryParser<TermQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{TermQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public TermQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         String queryName = null;
         String fieldName = null;
         Object value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String currentFieldName = null;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -97,16 +104,22 @@ public class TermQueryParser extends BaseQueryParser<TermQueryBuilder> {
             }
         }
 
-        TermQueryBuilder termQuery = new TermQueryBuilder(fieldName, value);
-        termQuery.boost(boost);
-        if (queryName != null) {
-            termQuery.queryName(queryName);
+        if (value == null) {
+            throw new QueryParsingException(parseContext, "No value specified for term query");
         }
-        return termQuery;
-    }
 
-    @Override
-    public TermQueryBuilder getBuilderPrototype() {
-        return TermQueryBuilder.PROTOTYPE;
+        Query query = null;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            query = fieldType.termQuery(value, parseContext);
+        }
+        if (query == null) {
+            query = new TermQuery(new Term(fieldName, BytesRefs.toBytesRef(value)));
+        }
+        query.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java
index a074e2a..4bdd0da 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermsLookupQueryBuilder.java
@@ -19,20 +19,93 @@
 
 package org.elasticsearch.index.query;
 
+import org.elasticsearch.common.xcontent.XContentBuilder;
+
+import java.io.IOException;
 
 /**
- * A filter for a field based on several terms matching on any of them.
- * @deprecated use {@link TermsQueryBuilder} instead.
+ * A filer for a field based on several terms matching on any of them.
  */
-@Deprecated
-public class TermsLookupQueryBuilder extends TermsQueryBuilder {
+public class TermsLookupQueryBuilder extends QueryBuilder {
+
+    private final String name;
+    private String lookupIndex;
+    private String lookupType;
+    private String lookupId;
+    private String lookupRouting;
+    private String lookupPath;
+
+    private String queryName;
 
     public TermsLookupQueryBuilder(String name) {
-        super(name, (Object[]) null);
+        this.name = name;
+    }
+
+    /**
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public TermsLookupQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
+    }
+
+    /**
+     * Sets the index name to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupIndex(String lookupIndex) {
+        this.lookupIndex = lookupIndex;
+        return this;
+    }
+
+    /**
+     * Sets the index type to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupType(String lookupType) {
+        this.lookupType = lookupType;
+        return this;
+    }
+
+    /**
+     * Sets the doc id to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupId(String lookupId) {
+        this.lookupId = lookupId;
+        return this;
+    }
+
+    /**
+     * Sets the path within the document to lookup the terms from.
+     */
+    public TermsLookupQueryBuilder lookupPath(String lookupPath) {
+        this.lookupPath = lookupPath;
+        return this;
+    }
+
+    public TermsLookupQueryBuilder lookupRouting(String lookupRouting) {
+        this.lookupRouting = lookupRouting;
+        return this;
     }
 
     @Override
-    public String getWriteableName() {
-        return TermsQueryBuilder.NAME;
-   }
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(TermsQueryParser.NAME);
+
+        builder.startObject(name);
+        if (lookupIndex != null) {
+            builder.field("index", lookupIndex);
+        }
+        builder.field("type", lookupType);
+        builder.field("id", lookupId);
+        if (lookupRouting != null) {
+            builder.field("routing", lookupRouting);
+        }
+        builder.field("path", lookupPath);
+        builder.endObject();
+
+        if (queryName != null) {
+            builder.field("_name", queryName);
+        }
+
+        builder.endObject();
+    }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java
index 3f0ce91..ca54eb3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermsQueryBuilder.java
@@ -19,137 +19,101 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.primitives.Doubles;
-import com.google.common.primitives.Floats;
-import com.google.common.primitives.Ints;
-import com.google.common.primitives.Longs;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-import java.util.Objects;
 
 /**
- * A filter for a field based on several terms matching on any of them.
+ * A filer for a field based on several terms matching on any of them.
  */
-public class TermsQueryBuilder extends AbstractQueryBuilder<TermsQueryBuilder> {
+public class TermsQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<TermsQueryBuilder> {
 
-    public static final String NAME = "terms";
+    private final String name;
 
-    static final TermsQueryBuilder PROTOTYPE = new TermsQueryBuilder(null);
+    private final Object values;
 
-    public static final boolean DEFAULT_DISABLE_COORD = false;
-
-    private final String fieldName;
-    private List<Object> values;
     private String minimumShouldMatch;
-    private boolean disableCoord = DEFAULT_DISABLE_COORD;
-    private TermsLookup termsLookup;
+
+    private Boolean disableCoord;
+
+    private String queryName;
+
+    private float boost = -1;
 
     /**
-     * A filter for a field based on several terms matching on any of them.
-     *
-     * @param fieldName The field name
-     * @param values The terms
-     */
-    public TermsQueryBuilder(String fieldName, String... values) {
-        this(fieldName, values != null ? Arrays.asList(values) : (Iterable<?>) null);
-    }
-    
-    /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, int... values) {
-        this(fieldName, values != null ? Ints.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, String... values) {
+        this(name, (Object[]) values);
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, long... values) {
-        this(fieldName, values != null ? Longs.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, int... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, float... values) {
-        this(fieldName, values != null ? Floats.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, long... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, double... values) {
-        this(fieldName, values != null ? Doubles.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, float... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, Object... values) {
-        this(fieldName, values != null ? Arrays.asList(values) : (Iterable<?>) null);
+    public TermsQueryBuilder(String name, double... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * Constructor used for terms query lookup.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
+     * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName) {
-        this.fieldName = fieldName;
+    public TermsQueryBuilder(String name, Object... values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
-     * A filter for a field based on several terms matching on any of them.
+     * A filer for a field based on several terms matching on any of them.
      *
-     * @param fieldName The field name
+     * @param name   The field name
      * @param values The terms
      */
-    public TermsQueryBuilder(String fieldName, Iterable<?> values) {
-        if (values == null) {
-            throw new IllegalArgumentException("No value specified for terms query");
-        }
-        this.fieldName = fieldName;
-        this.values = convertToBytesRefListIfStringList(values);
-    }
-
-    public String fieldName() {
-        return this.fieldName;
-    }
-
-    public List<Object> values() {
-        return convertToStringListIfBytesRefList(this.values);
+    public TermsQueryBuilder(String name, Iterable values) {
+        this.name = name;
+        this.values = values;
     }
 
     /**
@@ -162,10 +126,6 @@ public class TermsQueryBuilder extends AbstractQueryBuilder<TermsQueryBuilder> {
         return this;
     }
 
-    public String minimumShouldMatch() {
-        return this.minimumShouldMatch;
-    }
-
     /**
      * Disables <tt>Similarity#coord(int,int)</tt> in scoring. Defaults to <tt>false</tt>.
      * @deprecated use [bool] query instead
@@ -176,254 +136,41 @@ public class TermsQueryBuilder extends AbstractQueryBuilder<TermsQueryBuilder> {
         return this;
     }
 
-    public boolean disableCoord() {
-        return this.disableCoord;
-    }
-
-    private boolean isTermsLookupQuery() {
-        return this.termsLookup != null;
-    }
-
-    public TermsQueryBuilder termsLookup(TermsLookup termsLookup) {
-        this.termsLookup = termsLookup;
-        return this;
-    }
-
-    public TermsLookup termsLookup() {
-        return this.termsLookup;
-    }
-
-    /**
-     * Sets the index name to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupIndex(String lookupIndex) {
-        if (lookupIndex == null) {
-            throw new IllegalArgumentException("Lookup index cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.index(lookupIndex);
-        return this;
-    }
-
-    /**
-     * Sets the type name to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupType(String lookupType) {
-        if (lookupType == null) {
-            throw new IllegalArgumentException("Lookup type cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.type(lookupType);
-        return this;
-    }
-
-    /**
-     * Sets the document id to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupId(String lookupId) {
-        if (lookupId == null) {
-            throw new IllegalArgumentException("Lookup id cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.id(lookupId);
-        return this;
-    }
-
     /**
-     * Sets the path name to lookup the terms from.
+     * Sets the filter name for the filter that can be used when searching for matched_filters per hit.
      */
-    public TermsQueryBuilder lookupPath(String lookupPath) {
-        if (lookupPath == null) {
-            throw new IllegalArgumentException("Lookup path cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.path(lookupPath);
+    public TermsQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
         return this;
     }
 
-    /**
-     * Sets the routing to lookup the terms from.
-     */
-    public TermsQueryBuilder lookupRouting(String lookupRouting) {
-        if (lookupRouting == null) {
-            throw new IllegalArgumentException("Lookup routing cannot be set to null");
-        }
-        if (this.termsLookup == null) {
-            this.termsLookup = new TermsLookup();
-        }
-        this.termsLookup.routing(lookupRouting);
+    @Override
+    public TermsQueryBuilder boost(float boost) {
+        this.boost = boost;
         return this;
     }
 
-    /**
-     * Same as {@link #convertToBytesRefIfString} but on Iterable.
-     * @param objs the Iterable of input object
-     * @return the same input or a list of {@link BytesRef} representation if input was a list of type string
-     */
-    private static List<Object> convertToBytesRefListIfStringList(Iterable<?> objs) {
-        if (objs == null) {
-            return null;
-        }
-        List<Object> newObjs = new ArrayList<>();
-        for (Object obj : objs) {
-            newObjs.add(convertToBytesRefIfString(obj));
-        }
-        return newObjs;
-    }
-
-    /**
-     * Same as {@link #convertToStringIfBytesRef} but on Iterable.
-     * @param objs the Iterable of input object
-     * @return the same input or a list of utf8 string if input was a list of type {@link BytesRef}
-     */
-    private static List<Object> convertToStringListIfBytesRefList(Iterable<?> objs) {
-        if (objs == null) {
-            return null;
-        }
-        List<Object> newObjs = new ArrayList<>();
-        for (Object obj : objs) {
-            newObjs.add(convertToStringIfBytesRef(obj));
-        }
-        return newObjs;
-    }
-
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        if (isTermsLookupQuery()) {
-            builder.startObject(fieldName);
-            termsLookup.toXContent(builder, params);
-            builder.endObject();
-        } else {
-            builder.field(fieldName, convertToStringListIfBytesRefList(values));
-        }
+        builder.startObject(TermsQueryParser.NAME);
+        builder.field(name, values);
+
         if (minimumShouldMatch != null) {
             builder.field("minimum_should_match", minimumShouldMatch);
         }
-        builder.field("disable_coord", disableCoord);
-        printBoostAndQueryName(builder);
-        builder.endObject();
-    }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        List<Object> terms;
-        if (isTermsLookupQuery()) {
-            if (termsLookup.index() == null) {
-                termsLookup.index(context.index().name());
-            }
-            terms = context.handleTermsLookup(termsLookup);
-        } else {
-            terms = values;
-        }
-        if (terms == null || terms.isEmpty()) {
-            return Queries.newMatchNoDocsQuery();
-        }
-        return handleTermsQuery(terms, fieldName, context, minimumShouldMatch, disableCoord);
-    }
-
-    private static Query handleTermsQuery(List<Object> terms, String fieldName, QueryShardContext context, String minimumShouldMatch, boolean disableCoord) {
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        String indexFieldName;
-        if (fieldType != null) {
-            indexFieldName = fieldType.names().indexName();
-        } else {
-            indexFieldName = fieldName;
-        }
-
-        Query query;
-        if (context.isFilter()) {
-            if (fieldType != null) {
-                query = fieldType.termsQuery(terms, context);
-            } else {
-                BytesRef[] filterValues = new BytesRef[terms.size()];
-                for (int i = 0; i < filterValues.length; i++) {
-                    filterValues[i] = BytesRefs.toBytesRef(terms.get(i));
-                }
-                query = new TermsQuery(indexFieldName, filterValues);
-            }
-        } else {
-            BooleanQuery.Builder bq = new BooleanQuery.Builder();
-            bq.setDisableCoord(disableCoord);
-            for (Object term : terms) {
-                if (fieldType != null) {
-                    bq.add(fieldType.termQuery(term, context), BooleanClause.Occur.SHOULD);
-                } else {
-                    bq.add(new TermQuery(new Term(indexFieldName, BytesRefs.toBytesRef(term))), BooleanClause.Occur.SHOULD);
-                }
-            }
-            query = Queries.applyMinimumShouldMatch(bq.build(), minimumShouldMatch);
-        }
-        return query;
-    }
 
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.fieldName == null) {
-            validationException = addValidationError("field name cannot be null.", validationException);
+        if (disableCoord != null) {
+            builder.field("disable_coord", disableCoord);
         }
-        if (isTermsLookupQuery() && this.values != null) {
-            validationException = addValidationError("can't have both a terms query and a lookup query.", validationException);
-        }
-        if (isTermsLookupQuery()) {
-            QueryValidationException exception = termsLookup.validate();
-            if (exception != null) {
-                validationException = QueryValidationException.addValidationErrors(exception.validationErrors(), validationException);
-            }
-        }
-        return validationException;
-    }
 
-    @SuppressWarnings("unchecked")
-    @Override
-    protected TermsQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        TermsQueryBuilder termsQueryBuilder = new TermsQueryBuilder(in.readString());
-        if (in.readBoolean()) {
-            termsQueryBuilder.termsLookup = TermsLookup.readTermsLookupFrom(in);
+        if (boost != -1) {
+            builder.field("boost", boost);
         }
-        termsQueryBuilder.values = ((List<Object>) in.readGenericValue());
-        termsQueryBuilder.minimumShouldMatch = in.readOptionalString();
-        termsQueryBuilder.disableCoord = in.readBoolean();
-        return termsQueryBuilder;
-    }
 
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeBoolean(isTermsLookupQuery());
-        if (isTermsLookupQuery()) {
-            termsLookup.writeTo(out);
+        if (queryName != null) {
+            builder.field("_name", queryName);
         }
-        out.writeGenericValue(values);
-        out.writeOptionalString(minimumShouldMatch);
-        out.writeBoolean(disableCoord);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, values, minimumShouldMatch, disableCoord, termsLookup);
-    }
 
-    @Override
-    protected boolean doEquals(TermsQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(values, other.values) &&
-                Objects.equals(minimumShouldMatch, other.minimumShouldMatch) &&
-                Objects.equals(disableCoord, other.disableCoord) &&
-                Objects.equals(termsLookup, other.termsLookup);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java
index 350672a..b5fbce4 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TermsQueryParser.java
@@ -19,29 +19,40 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.queries.TermsQuery;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.util.BytesRef;
+import org.elasticsearch.action.get.GetRequest;
+import org.elasticsearch.action.get.GetResponse;
+import org.elasticsearch.client.Client;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lucene.BytesRefs;
+import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.support.XContentMapValues;
+import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.indices.cache.query.terms.TermsLookup;
+import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 
 /**
- * Parser for terms query and terms lookup.
  *
- * Filters documents that have fields that match any of the provided terms (not analyzed)
- *
- * It also supports a terms lookup mechanism which can be used to fetch the term values from
- * a document in an index.
  */
-public class TermsQueryParser extends BaseQueryParser {
+public class TermsQueryParser implements QueryParser {
 
-    private static final ParseField MIN_SHOULD_MATCH_FIELD = new ParseField("min_match", "min_should_match", "minimum_should_match")
-            .withAllDeprecated("Use [bool] query instead");
+    public static final String NAME = "terms";
+    private static final ParseField MIN_SHOULD_MATCH_FIELD = new ParseField("min_match", "min_should_match").withAllDeprecated("Use [bool] query instead");
     private static final ParseField DISABLE_COORD_FIELD = new ParseField("disable_coord").withAllDeprecated("Use [bool] query instead");
     private static final ParseField EXECUTION_FIELD = new ParseField("execution").withAllDeprecated("execution is deprecated and has no effect");
+    private Client client;
 
     @Inject
     public TermsQueryParser() {
@@ -49,24 +60,34 @@ public class TermsQueryParser extends BaseQueryParser {
 
     @Override
     public String[] names() {
-        return new String[]{TermsQueryBuilder.NAME, "in"};
+        return new String[]{NAME, "in"};
+    }
+
+    @Inject(optional = true)
+    public void setClient(Client client) {
+        this.client = client;
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
-        String fieldName = null;
-        List<Object> values = null;
+        String queryName = null;
+        String currentFieldName = null;
+
+        String lookupIndex = parseContext.index().name();
+        String lookupType = null;
+        String lookupId = null;
+        String lookupPath = null;
+        String lookupRouting = null;
         String minShouldMatch = null;
-        boolean disableCoord = TermsQueryBuilder.DEFAULT_DISABLE_COORD;
-        TermsLookup termsLookup = null;
 
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        boolean disableCoord = false;
 
         XContentParser.Token token;
-        String currentFieldName = null;
+        List<Object> terms = new ArrayList<>();
+        String fieldName = null;
+        float boost = 1f;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
@@ -77,16 +98,51 @@ public class TermsQueryParser extends BaseQueryParser {
                     throw new QueryParsingException(parseContext, "[terms] query does not support multiple fields");
                 }
                 fieldName = currentFieldName;
-                values = parseValues(parseContext, parser);
+
+                while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
+                    Object value = parser.objectBytes();
+                    if (value == null) {
+                        throw new QueryParsingException(parseContext, "No value specified for terms query");
+                    }
+                    terms.add(value);
+                }
             } else if (token == XContentParser.Token.START_OBJECT) {
                 fieldName = currentFieldName;
-                termsLookup = parseTermsLookup(parseContext, parser);
+                while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
+                    if (token == XContentParser.Token.FIELD_NAME) {
+                        currentFieldName = parser.currentName();
+                    } else if (token.isValue()) {
+                        if ("index".equals(currentFieldName)) {
+                            lookupIndex = parser.text();
+                        } else if ("type".equals(currentFieldName)) {
+                            lookupType = parser.text();
+                        } else if ("id".equals(currentFieldName)) {
+                            lookupId = parser.text();
+                        } else if ("path".equals(currentFieldName)) {
+                            lookupPath = parser.text();
+                        } else if ("routing".equals(currentFieldName)) {
+                            lookupRouting = parser.textOrNull();
+                        } else {
+                            throw new QueryParsingException(parseContext, "[terms] query does not support [" + currentFieldName
+                                    + "] within lookup element");
+                        }
+                    }
+                }
+                if (lookupType == null) {
+                    throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the type");
+                }
+                if (lookupId == null) {
+                    throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the id");
+                }
+                if (lookupPath == null) {
+                    throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the path");
+                }
             } else if (token.isValue()) {
                 if (parseContext.parseFieldMatcher().match(currentFieldName, EXECUTION_FIELD)) {
                     // ignore
                 } else if (parseContext.parseFieldMatcher().match(currentFieldName, MIN_SHOULD_MATCH_FIELD)) {
                     if (minShouldMatch != null) {
-                        throw new IllegalArgumentException("[" + currentFieldName + "] is not allowed in a filter context for the [" + TermsQueryBuilder.NAME + "] query");
+                        throw new IllegalArgumentException("[" + currentFieldName + "] is not allowed in a filter context for the [" + NAME + "] query");
                     }
                     minShouldMatch = parser.textOrNull();
                 } else if ("boost".equals(currentFieldName)) {
@@ -102,73 +158,57 @@ public class TermsQueryParser extends BaseQueryParser {
         }
 
         if (fieldName == null) {
-            throw new QueryParsingException(parseContext, "terms query requires a field name, followed by array of terms or a document lookup specification");
+            throw new QueryParsingException(parseContext, "terms query requires a field name, followed by array of terms");
         }
-        TermsQueryBuilder termsQueryBuilder;
-        if (values == null) {
-            termsQueryBuilder = new TermsQueryBuilder(fieldName);
-        } else {
-            termsQueryBuilder = new TermsQueryBuilder(fieldName, values);
+
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            fieldName = fieldType.names().indexName();
         }
-        return termsQueryBuilder
-                .disableCoord(disableCoord)
-                .minimumShouldMatch(minShouldMatch)
-                .termsLookup(termsLookup)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    private static List<Object> parseValues(QueryParseContext parseContext, XContentParser parser) throws IOException {
-        List<Object> values = new ArrayList<>();
-        XContentParser.Token token;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-            Object value = parser.objectBytes();
-            if (value == null) {
-                throw new QueryParsingException(parseContext, "No value specified for terms query");
+        if (lookupId != null) {
+            final TermsLookup lookup = new TermsLookup(lookupIndex, lookupType, lookupId, lookupRouting, lookupPath, parseContext);
+            GetRequest getRequest = new GetRequest(lookup.getIndex(), lookup.getType(), lookup.getId()).preference("_local").routing(lookup.getRouting());
+            getRequest.copyContextAndHeadersFrom(SearchContext.current());
+            final GetResponse getResponse = client.get(getRequest).actionGet();
+            if (getResponse.isExists()) {
+                List<Object> values = XContentMapValues.extractRawValues(lookup.getPath(), getResponse.getSourceAsMap());
+                terms.addAll(values);
             }
-            values.add(value);
         }
-        return values;
-    }
 
-    private static TermsLookup parseTermsLookup(QueryParseContext parseContext, XContentParser parser) throws IOException {
-        TermsLookup termsLookup = new TermsLookup();
-        XContentParser.Token token;
-        String currentFieldName = null;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                currentFieldName = parser.currentName();
-            } else if (token.isValue()) {
-                if ("index".equals(currentFieldName)) {
-                    termsLookup.index(parser.textOrNull());
-                } else if ("type".equals(currentFieldName)) {
-                    termsLookup.type(parser.text());
-                } else if ("id".equals(currentFieldName)) {
-                    termsLookup.id(parser.text());
-                } else if ("routing".equals(currentFieldName)) {
-                    termsLookup.routing(parser.textOrNull());
-                } else if ("path".equals(currentFieldName)) {
-                    termsLookup.path(parser.text());
+        if (terms.isEmpty()) {
+            return Queries.newMatchNoDocsQuery();
+        }
+
+        Query query;
+        if (parseContext.isFilter()) {
+            if (fieldType != null) {
+                query = fieldType.termsQuery(terms, parseContext);
+            } else {
+                BytesRef[] filterValues = new BytesRef[terms.size()];
+                for (int i = 0; i < filterValues.length; i++) {
+                    filterValues[i] = BytesRefs.toBytesRef(terms.get(i));
+                }
+                query = new TermsQuery(fieldName, filterValues);
+            }
+        } else {
+            BooleanQuery.Builder bq = new BooleanQuery.Builder();
+            bq.setDisableCoord(disableCoord);
+            for (Object term : terms) {
+                if (fieldType != null) {
+                    bq.add(fieldType.termQuery(term, parseContext), Occur.SHOULD);
                 } else {
-                    throw new QueryParsingException(parseContext, "[terms] query does not support [" + currentFieldName
-                            + "] within lookup element");
+                    bq.add(new TermQuery(new Term(fieldName, BytesRefs.toBytesRef(term))), Occur.SHOULD);
                 }
             }
+            query = Queries.applyMinimumShouldMatch(bq.build(), minShouldMatch);
         }
-        if (termsLookup.type() == null) {
-            throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the type");
-        }
-        if (termsLookup.id() == null) {
-            throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the id");
-        }
-        if (termsLookup.path() == null) {
-            throw new QueryParsingException(parseContext, "[terms] query lookup element requires specifying the path");
-        }
-        return termsLookup;
-    }
+        query.setBoost(boost);
 
-    @Override
-    public TermsQueryBuilder getBuilderPrototype() {
-        return TermsQueryBuilder.PROTOTYPE;
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, query);
+        }
+        return query;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java
index 9f89a94..2a9a6c5 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TypeQueryBuilder.java
@@ -19,92 +19,22 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 
 import java.io.IOException;
-import java.util.Objects;
 
-public class TypeQueryBuilder extends AbstractQueryBuilder<TypeQueryBuilder> {
+public class TypeQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "type";
-
-    private final BytesRef type;
-
-    static final TypeQueryBuilder PROTOTYPE = new TypeQueryBuilder((BytesRef) null);
+    private final String type;
 
     public TypeQueryBuilder(String type) {
-        this.type = BytesRefs.toBytesRef(type);
-    }
-
-    TypeQueryBuilder(BytesRef type) {
         this.type = type;
     }
 
-    public String type() {
-        return BytesRefs.toString(this.type);
-    }
-
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("value", type.utf8ToString());
-        printBoostAndQueryName(builder);
+        builder.startObject(TypeQueryParser.NAME);
+        builder.field("value", type);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        Query filter;
-        //LUCENE 4 UPGRADE document mapper should use bytesref as well?
-        DocumentMapper documentMapper = context.mapperService().documentMapper(type.utf8ToString());
-        if (documentMapper == null) {
-            filter = new TermQuery(new Term(TypeFieldMapper.NAME, type));
-        } else {
-            filter = documentMapper.typeFilter();
-        }
-        return filter;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (type == null) {
-            validationException = addValidationError("[type] cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected TypeQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new TypeQueryBuilder(in.readBytesRef());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeBytesRef(type);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(type);
-    }
-
-    @Override
-    protected boolean doEquals(TypeQueryBuilder other) {
-        return Objects.equals(type, other.type);
-    }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java
index ee5e772..e4b7889 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TypeQueryParser.java
@@ -19,16 +19,20 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.DocumentMapper;
+import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 
 import java.io.IOException;
 
-/**
- * Parser for type query
- */
-public class TypeQueryParser extends BaseQueryParser<TypeQueryBuilder> {
+public class TypeQueryParser implements QueryParser {
+
+    public static final String NAME = "type";
 
     @Inject
     public TypeQueryParser() {
@@ -36,45 +40,37 @@ public class TypeQueryParser extends BaseQueryParser<TypeQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{TypeQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public TypeQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
-        BytesRef type = null;
 
-        String queryName = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-
-        String currentFieldName = null;
-        XContentParser.Token token;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                currentFieldName = parser.currentName();
-            } else if (token.isValue()) {
-                if ("_name".equals(currentFieldName)) {
-                    queryName = parser.text();
-                } else if ("boost".equals(currentFieldName)) {
-                    boost = parser.floatValue();
-                } else if ("value".equals(currentFieldName)) {
-                    type = parser.utf8Bytes();
-                }
-            } else {
-                throw new QueryParsingException(parseContext, "[type] filter doesn't support [" + currentFieldName + "]");
-            }
+        XContentParser.Token token = parser.nextToken();
+        if (token != XContentParser.Token.FIELD_NAME) {
+            throw new QueryParsingException(parseContext, "[type] filter should have a value field, and the type name");
         }
-
-        if (type == null) {
-            throw new QueryParsingException(parseContext, "[type] filter needs to be provided with a value for the type");
+        String fieldName = parser.currentName();
+        if (!fieldName.equals("value")) {
+            throw new QueryParsingException(parseContext, "[type] filter should have a value field, and the type name");
         }
-        return new TypeQueryBuilder(type)
-                .boost(boost)
-                .queryName(queryName);
-    }
+        token = parser.nextToken();
+        if (token != XContentParser.Token.VALUE_STRING) {
+            throw new QueryParsingException(parseContext, "[type] filter should have a value field, and the type name");
+        }
+        BytesRef type = parser.utf8Bytes();
+        // move to the next token
+        parser.nextToken();
 
-    @Override
-    public TypeQueryBuilder getBuilderPrototype() {
-        return TypeQueryBuilder.PROTOTYPE;
+        Query filter;
+        //LUCENE 4 UPGRADE document mapper should use bytesref as well? 
+        DocumentMapper documentMapper = parseContext.mapperService().documentMapper(type.utf8ToString());
+        if (documentMapper == null) {
+            filter = new TermQuery(new Term(TypeFieldMapper.NAME, type));
+        } else {
+            filter = documentMapper.typeFilter();
+        }
+        return filter;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java
index 89b753e..654f14e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryBuilder.java
@@ -19,20 +19,9 @@
 
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.WildcardQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
-import java.util.Objects;
 
 /**
  * Implements the wildcard search query. Supported wildcards are <tt>*</tt>, which
@@ -42,17 +31,17 @@ import java.util.Objects;
  * a Wildcard term should not start with one of the wildcards <tt>*</tt> or
  * <tt>?</tt>.
  */
-public class WildcardQueryBuilder extends AbstractQueryBuilder<WildcardQueryBuilder> implements MultiTermQueryBuilder<WildcardQueryBuilder> {
+public class WildcardQueryBuilder extends MultiTermQueryBuilder implements BoostableQueryBuilder<WildcardQueryBuilder> {
 
-    public static final String NAME = "wildcard";
+    private final String name;
 
-    private final String fieldName;
+    private final String wildcard;
 
-    private final String value;
+    private float boost = -1;
 
     private String rewrite;
 
-    static final WildcardQueryBuilder PROTOTYPE = new WildcardQueryBuilder(null, null);
+    private String queryName;
 
     /**
      * Implements the wildcard search query. Supported wildcards are <tt>*</tt>, which
@@ -62,20 +51,12 @@ public class WildcardQueryBuilder extends AbstractQueryBuilder<WildcardQueryBuil
      * a Wildcard term should not start with one of the wildcards <tt>*</tt> or
      * <tt>?</tt>.
      *
-     * @param fieldName The field name
-     * @param value The wildcard query string
+     * @param name     The field name
+     * @param wildcard The wildcard query string
      */
-    public WildcardQueryBuilder(String fieldName, String value) {
-        this.fieldName = fieldName;
-        this.value = value;
-    }
-
-    public String fieldName() {
-        return fieldName;
-    }
-
-    public String value() {
-        return value;
+    public WildcardQueryBuilder(String name, String wildcard) {
+        this.name = name;
+        this.wildcard = wildcard;
     }
 
     public WildcardQueryBuilder rewrite(String rewrite) {
@@ -83,83 +64,43 @@ public class WildcardQueryBuilder extends AbstractQueryBuilder<WildcardQueryBuil
         return this;
     }
 
-    public String rewrite() {
-        return this.rewrite;
-    }
-
+    /**
+     * Sets the boost for this query.  Documents matching this query will (in addition to the normal
+     * weightings) have their score multiplied by the boost provided.
+     */
     @Override
-    public String getWriteableName() {
-        return NAME;
+    public WildcardQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
     }
 
-    @Override
-    public void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.startObject(fieldName);
-        builder.field("wildcard", value);
-        if (rewrite != null) {
-            builder.field("rewrite", rewrite);
-        }
-        printBoostAndQueryName(builder);
-        builder.endObject();
-        builder.endObject();
+    /**
+     * Sets the query name for the filter that can be used when searching for matched_filters per hit.
+     */
+    public WildcardQueryBuilder queryName(String queryName) {
+        this.queryName = queryName;
+        return this;
     }
 
     @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        String indexFieldName;
-        BytesRef valueBytes;
-
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType != null) {
-            indexFieldName = fieldType.names().indexName();
-            valueBytes = fieldType.indexedValueForSearch(value);
+    public void doXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(WildcardQueryParser.NAME);
+        if (boost == -1 && rewrite == null && queryName == null) {
+            builder.field(name, wildcard);
         } else {
-            indexFieldName = fieldName;
-            valueBytes = new BytesRef(value);
+            builder.startObject(name);
+            builder.field("wildcard", wildcard);
+            if (boost != -1) {
+                builder.field("boost", boost);
+            }
+            if (rewrite != null) {
+                builder.field("rewrite", rewrite);
+            }
+            if (queryName != null) {
+                builder.field("_name", queryName);
+            }
+            builder.endObject();
         }
-
-        WildcardQuery query = new WildcardQuery(new Term(indexFieldName, valueBytes));
-        MultiTermQuery.RewriteMethod rewriteMethod = QueryParsers.parseRewriteMethod(context.parseFieldMatcher(), rewrite, null);
-        QueryParsers.setRewriteMethod(query, rewriteMethod);
-        return query;
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (Strings.isEmpty(this.fieldName)) {
-            validationException = addValidationError("field name cannot be null or empty.", validationException);
-        }
-        if (this.value == null) {
-            validationException = addValidationError("wildcard cannot be null", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected WildcardQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        WildcardQueryBuilder wildcardQueryBuilder = new WildcardQueryBuilder(in.readString(), in.readString());
-        wildcardQueryBuilder.rewrite = in.readOptionalString();
-        return wildcardQueryBuilder;
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeString(fieldName);
-        out.writeString(value);
-        out.writeOptionalString(rewrite);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Objects.hash(fieldName, value, rewrite);
-    }
-
-    @Override
-    protected boolean doEquals(WildcardQueryBuilder other) {
-        return Objects.equals(fieldName, other.fieldName) &&
-                Objects.equals(value, other.value) &&
-                Objects.equals(rewrite, other.rewrite);
+        builder.endObject();
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java
index d3b3e26..da92db4 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WildcardQueryParser.java
@@ -19,15 +19,23 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.WildcardQuery;
+import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
 
 /**
- * Parser for wildcard query
+ *
  */
-public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
+public class WildcardQueryParser implements QueryParser {
+
+    public static final String NAME = "wildcard";
 
     @Inject
     public WildcardQueryParser() {
@@ -35,11 +43,11 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
 
     @Override
     public String[] names() {
-        return new String[]{WildcardQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public WildcardQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.nextToken();
@@ -47,10 +55,10 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
             throw new QueryParsingException(parseContext, "[wildcard] query malformed, no field");
         }
         String fieldName = parser.currentName();
-        String rewrite = null;
+        String rewriteMethod = null;
 
         String value = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
+        float boost = 1.0f;
         String queryName = null;
         token = parser.nextToken();
         if (token == XContentParser.Token.START_OBJECT) {
@@ -66,7 +74,7 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
                     } else if ("boost".equals(currentFieldName)) {
                         boost = parser.floatValue();
                     } else if ("rewrite".equals(currentFieldName)) {
-                        rewrite = parser.textOrNull();
+                        rewriteMethod = parser.textOrNull();
                     } else if ("_name".equals(currentFieldName)) {
                         queryName = parser.text();
                     } else {
@@ -83,14 +91,22 @@ public class WildcardQueryParser extends BaseQueryParser<WildcardQueryBuilder> {
         if (value == null) {
             throw new QueryParsingException(parseContext, "No value specified for prefix query");
         }
-        return new WildcardQueryBuilder(fieldName, value)
-                .rewrite(rewrite)
-                .boost(boost)
-                .queryName(queryName);
-    }
 
-    @Override
-    public WildcardQueryBuilder getBuilderPrototype() {
-        return WildcardQueryBuilder.PROTOTYPE;
+        BytesRef valueBytes;
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
+        if (fieldType != null) {
+            fieldName = fieldType.names().indexName();
+            valueBytes = fieldType.indexedValueForSearch(value);
+        } else {
+            valueBytes = new BytesRef(value);
+        }
+
+        WildcardQuery wildcardQuery = new WildcardQuery(new Term(fieldName, valueBytes));
+        QueryParsers.setRewriteMethod(wildcardQuery, parseContext.parseFieldMatcher(), rewriteMethod);
+        wildcardQuery.setBoost(boost);
+        if (queryName != null) {
+            parseContext.addNamedQuery(queryName, wildcardQuery);
+        }
+        return wildcardQuery;
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java
index f4a75c7..6fde3c7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryBuilder.java
@@ -20,16 +20,10 @@
 package org.elasticsearch.index.query;
 
 import com.google.common.base.Charsets;
-import org.apache.lucene.search.Query;
 import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
-import java.util.Arrays;
 
 /**
  * A Query builder which allows building a query given JSON string or binary data provided as input. This is useful when you want
@@ -45,24 +39,28 @@ import java.util.Arrays;
  * }
  * </pre>
  */
-public class WrapperQueryBuilder extends AbstractQueryBuilder<WrapperQueryBuilder> {
+public class WrapperQueryBuilder extends QueryBuilder {
 
-    public static final String NAME = "wrapper";
     private final byte[] source;
-    static final WrapperQueryBuilder PROTOTYPE = new WrapperQueryBuilder((byte[]) null);
+    private final int offset;
+    private final int length;
 
     /**
      * Creates a query builder given a query provided as a string
      */
     public WrapperQueryBuilder(String source) {
         this.source = source.getBytes(Charsets.UTF_8);
+        this.offset = 0;
+        this.length = this.source.length;
     }
 
     /**
      * Creates a query builder given a query provided as a bytes array
      */
-    public WrapperQueryBuilder(byte[] source) {
+    public WrapperQueryBuilder(byte[] source, int offset, int length) {
         this.source = source;
+        this.offset = offset;
+        this.length = length;
     }
 
     /**
@@ -70,71 +68,14 @@ public class WrapperQueryBuilder extends AbstractQueryBuilder<WrapperQueryBuilde
      */
     public WrapperQueryBuilder(BytesReference source) {
         this.source = source.array();
-    }
-
-    public byte[] source() {
-        return this.source;
-    }
-
-    @Override
-    public String getName() {
-        return NAME;
+        this.offset = source.arrayOffset();
+        this.length = source.length();
     }
 
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(NAME);
-        builder.field("query", source);
+        builder.startObject(WrapperQueryParser.NAME);
+        builder.field("query", source, offset, length);
         builder.endObject();
     }
-
-    @Override
-    public String getWriteableName() {
-        return NAME;
-    }
-
-    @Override
-    protected Query doToQuery(QueryShardContext context) throws IOException {
-        try (XContentParser qSourceParser = XContentFactory.xContent(source).createParser(source)) {
-            final QueryShardContext contextCopy = new QueryShardContext(context.index(), context.indexQueryParserService());
-            contextCopy.reset(qSourceParser);
-            QueryBuilder result = contextCopy.parseContext().parseInnerQueryBuilder();
-            context.combineNamedQueries(contextCopy);
-            return result.toQuery(context);
-        }
-    }
-
-    @Override
-    protected void setFinalBoost(Query query) {
-        //no-op this query doesn't support boost
-    }
-
-    @Override
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (this.source == null || this.source.length == 0) {
-            validationException = addValidationError("query source text cannot be null or empty", validationException);
-        }
-        return validationException;
-    }
-
-    @Override
-    protected WrapperQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        return new WrapperQueryBuilder(in.readByteArray());
-    }
-
-    @Override
-    protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeByteArray(this.source);
-    }
-
-    @Override
-    protected int doHashCode() {
-        return Arrays.hashCode(source);
-    }
-
-    @Override
-    protected boolean doEquals(WrapperQueryBuilder other) {
-        return Arrays.equals(source, other.source);   // otherwise we compare pointers
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java
index cd9eb83..331ba78 100644
--- a/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/WrapperQueryParser.java
@@ -19,7 +19,9 @@
 
 package org.elasticsearch.index.query;
 
+import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
@@ -27,7 +29,9 @@ import java.io.IOException;
 /**
  * Query parser for JSON Queries.
  */
-public class WrapperQueryParser extends BaseQueryParser {
+public class WrapperQueryParser implements QueryParser {
+
+    public static final String NAME = "wrapper";
 
     @Inject
     public WrapperQueryParser() {
@@ -35,11 +39,11 @@ public class WrapperQueryParser extends BaseQueryParser {
 
     @Override
     public String[] names() {
-        return new String[]{WrapperQueryBuilder.NAME};
+        return new String[]{NAME};
     }
 
     @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         XContentParser.Token token = parser.nextToken();
@@ -52,18 +56,14 @@ public class WrapperQueryParser extends BaseQueryParser {
         }
         parser.nextToken();
 
-        byte[] source = parser.binaryValue();
-
-        parser.nextToken();
-
-        if (source == null) {
-            throw new QueryParsingException(parseContext, "wrapper query has no [query] specified");
+        byte[] querySource = parser.binaryValue();
+        try (XContentParser qSourceParser = XContentFactory.xContent(querySource).createParser(querySource)) {
+            final QueryParseContext context = new QueryParseContext(parseContext.index(), parseContext.indexQueryParserService());
+            context.reset(qSourceParser);
+            Query result = context.parseInnerQuery();
+            parser.nextToken();
+            parseContext.combineNamedQueries(context);
+            return result;
         }
-        return new WrapperQueryBuilder(source);
-    }
-
-    @Override
-    public WrapperQueryBuilder getBuilderPrototype() {
-        return WrapperQueryBuilder.PROTOTYPE;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
index 7580c84..3dc2427 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.core.DateFieldMapper;
 import org.elasticsearch.index.mapper.core.NumberFieldMapper;
 import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionBuilder;
 import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionParser;
@@ -119,7 +119,7 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
      *
      * */
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
         String currentFieldName;
         XContentParser.Token token;
         AbstractDistanceScoreFunction scoreFunction;
@@ -132,7 +132,7 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
             if (token == XContentParser.Token.START_OBJECT) {
                 variableContent.copyCurrentStructure(parser);
                 fieldName = currentFieldName;
-            } else if (context.parseFieldMatcher().match(currentFieldName, MULTI_VALUE_MODE)) {
+            } else if (parseContext.parseFieldMatcher().match(currentFieldName, MULTI_VALUE_MODE)) {
                 multiValueMode = parser.text();
             } else {
                 throw new ElasticsearchParseException("malformed score function score parameters.");
@@ -142,34 +142,34 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
             throw new ElasticsearchParseException("malformed score function score parameters.");
         }
         XContentParser variableParser = XContentFactory.xContent(variableContent.string()).createParser(variableContent.string());
-        scoreFunction = parseVariable(fieldName, variableParser, context, MultiValueMode.fromString(multiValueMode.toUpperCase(Locale.ROOT)));
+        scoreFunction = parseVariable(fieldName, variableParser, parseContext, MultiValueMode.fromString(multiValueMode.toUpperCase(Locale.ROOT)));
         return scoreFunction;
     }
 
     // parses origin and scale parameter for field "fieldName"
-    private AbstractDistanceScoreFunction parseVariable(String fieldName, XContentParser parser, QueryShardContext context, MultiValueMode mode) throws IOException {
+    private AbstractDistanceScoreFunction parseVariable(String fieldName, XContentParser parser, QueryParseContext parseContext, MultiValueMode mode) throws IOException {
 
         // now, the field must exist, else we cannot read the value for
         // the doc later
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType == null) {
-            throw new QueryParsingException(context.parseContext(), "unknown field [{}]", fieldName);
+            throw new QueryParsingException(parseContext, "unknown field [{}]", fieldName);
         }
 
         // dates and time need special handling
         parser.nextToken();
         if (fieldType instanceof DateFieldMapper.DateFieldType) {
-            return parseDateVariable(fieldName, parser, context, (DateFieldMapper.DateFieldType) fieldType, mode);
+            return parseDateVariable(fieldName, parser, parseContext, (DateFieldMapper.DateFieldType) fieldType, mode);
         } else if (fieldType instanceof GeoPointFieldMapper.GeoPointFieldType) {
-            return parseGeoVariable(fieldName, parser, context, (GeoPointFieldMapper.GeoPointFieldType) fieldType, mode);
+            return parseGeoVariable(fieldName, parser, parseContext, (GeoPointFieldMapper.GeoPointFieldType) fieldType, mode);
         } else if (fieldType instanceof NumberFieldMapper.NumberFieldType) {
-            return parseNumberVariable(fieldName, parser, context, (NumberFieldMapper.NumberFieldType) fieldType, mode);
+            return parseNumberVariable(fieldName, parser, parseContext, (NumberFieldMapper.NumberFieldType) fieldType, mode);
         } else {
-            throw new QueryParsingException(context.parseContext(), "field [{}] is of type [{}], but only numeric types are supported.", fieldName, fieldType);
+            throw new QueryParsingException(parseContext, "field [{}] is of type [{}], but only numeric types are supported.", fieldName, fieldType);
         }
     }
 
-    private AbstractDistanceScoreFunction parseNumberVariable(String fieldName, XContentParser parser, QueryShardContext context,
+    private AbstractDistanceScoreFunction parseNumberVariable(String fieldName, XContentParser parser, QueryParseContext parseContext,
             NumberFieldMapper.NumberFieldType fieldType, MultiValueMode mode) throws IOException {
         XContentParser.Token token;
         String parameterName = null;
@@ -199,11 +199,11 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
         if (!scaleFound || !refFound) {
             throw new ElasticsearchParseException("both [{}] and [{}] must be set for numeric fields.", DecayFunctionBuilder.SCALE, DecayFunctionBuilder.ORIGIN);
         }
-        IndexNumericFieldData numericFieldData = context.getForField(fieldType);
+        IndexNumericFieldData numericFieldData = parseContext.getForField(fieldType);
         return new NumericFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), numericFieldData, mode);
     }
 
-    private AbstractDistanceScoreFunction parseGeoVariable(String fieldName, XContentParser parser, QueryShardContext context,
+    private AbstractDistanceScoreFunction parseGeoVariable(String fieldName, XContentParser parser, QueryParseContext parseContext,
             GeoPointFieldMapper.GeoPointFieldType fieldType, MultiValueMode mode) throws IOException {
         XContentParser.Token token;
         String parameterName = null;
@@ -231,12 +231,12 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
         }
         double scale = DistanceUnit.DEFAULT.parse(scaleString, DistanceUnit.DEFAULT);
         double offset = DistanceUnit.DEFAULT.parse(offsetString, DistanceUnit.DEFAULT);
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+        IndexGeoPointFieldData indexFieldData = parseContext.getForField(fieldType);
         return new GeoFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), indexFieldData, mode);
 
     }
 
-    private AbstractDistanceScoreFunction parseDateVariable(String fieldName, XContentParser parser, QueryShardContext context,
+    private AbstractDistanceScoreFunction parseDateVariable(String fieldName, XContentParser parser, QueryParseContext parseContext,
             DateFieldMapper.DateFieldType dateFieldType, MultiValueMode mode) throws IOException {
         XContentParser.Token token;
         String parameterName = null;
@@ -271,7 +271,7 @@ public abstract class DecayFunctionParser implements ScoreFunctionParser {
         double scale = val.getMillis();
         val = TimeValue.parseTimeValue(offsetString, TimeValue.timeValueHours(24), getClass().getSimpleName() + ".offset");
         double offset = val.getMillis();
-        IndexNumericFieldData numericFieldData = context.getForField(dateFieldType);
+        IndexNumericFieldData numericFieldData = parseContext.getForField(dateFieldType);
         return new NumericFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), numericFieldData, mode);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
index 3880592..dc7571a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
@@ -21,7 +21,7 @@ package org.elasticsearch.index.query.functionscore;
 
 import org.elasticsearch.common.lucene.search.function.CombineFunction;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.AbstractQueryBuilder;
+import org.elasticsearch.index.query.BoostableQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
 
 import java.io.IOException;
@@ -31,12 +31,14 @@ import java.util.ArrayList;
  * A query that uses a filters with a script associated with them to compute the
  * score.
  */
-public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScoreQueryBuilder> {
+public class FunctionScoreQueryBuilder extends QueryBuilder implements BoostableQueryBuilder<FunctionScoreQueryBuilder> {
 
     private final QueryBuilder queryBuilder;
 
     private final QueryBuilder filterBuilder;
 
+    private Float boost;
+
     private Float maxBoost;
 
     private String scoreMode;
@@ -47,8 +49,6 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
     private ArrayList<ScoreFunctionBuilder> scoreFunctions = new ArrayList<>();
     private Float minScore = null;
 
-    static final FunctionScoreQueryBuilder PROTOTYPE = new FunctionScoreQueryBuilder();
-
     /**
      * Creates a function_score query that executes on documents that match query a query.
      * Query and filter will be wrapped into a filtered_query.
@@ -143,6 +143,17 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
         return this;
     }
 
+    /**
+     * Sets the boost for this query. Documents matching this query will (in
+     * addition to the normal weightings) have their score multiplied by the
+     * boost provided.
+     */
+    @Override
+    public FunctionScoreQueryBuilder boost(float boost) {
+        this.boost = boost;
+        return this;
+    }
+
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject(FunctionScoreQueryParser.NAME);
@@ -175,10 +186,13 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
         if (maxBoost != null) {
             builder.field("max_boost", maxBoost);
         }
+        if (boost != null) {
+            builder.field("boost", boost);
+        }
         if (minScore != null) {
             builder.field("min_score", minScore);
         }
-        printBoostAndQueryName(builder);
+
         builder.endObject();
     }
 
@@ -186,9 +200,4 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
         this.minScore = minScore;
         return this;
     }
-
-    @Override
-    public String getWriteableName() {
-        return FunctionScoreQueryParser.NAME;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
index c59be16..c2c6494 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
@@ -37,7 +37,9 @@ import org.elasticsearch.common.lucene.search.function.FunctionScoreQuery;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.lucene.search.function.WeightFactorFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParser;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.factor.FactorParser;
 
 import java.io.IOException;
@@ -45,7 +47,7 @@ import java.util.ArrayList;
 import java.util.Arrays;
 
 /**
- * Parser for function_score query
+ *
  */
 public class FunctionScoreQueryParser implements QueryParser {
 
@@ -82,14 +84,12 @@ public class FunctionScoreQueryParser implements QueryParser {
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
         XContentParser parser = parseContext.parser();
 
         Query query = null;
         Query filter = null;
-        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
-        String queryName = null;
+        float boost = 1.0f;
 
         FiltersFunctionScoreQuery.ScoreMode scoreMode = FiltersFunctionScoreQuery.ScoreMode.Multiply;
         ArrayList<FiltersFunctionScoreQuery.FilterFunction> filterFunctions = new ArrayList<>();
@@ -119,8 +119,6 @@ public class FunctionScoreQueryParser implements QueryParser {
                 maxBoost = parser.floatValue();
             } else if ("boost".equals(currentFieldName)) {
                 boost = parser.floatValue();
-            } else if ("_name".equals(currentFieldName)) {
-                queryName = parser.text();
             } else if ("min_score".equals(currentFieldName) || "minScore".equals(currentFieldName)) {
                 minScore = parser.floatValue();
             } else if ("functions".equals(currentFieldName)) {
@@ -128,7 +126,7 @@ public class FunctionScoreQueryParser implements QueryParser {
                     String errorString = "already found [" + singleFunctionName + "], now encountering [functions].";
                     handleMisplacedFunctionsDeclaration(errorString, singleFunctionName);
                 }
-                currentFieldName = parseFiltersAndFunctions(context, parser, filterFunctions, currentFieldName);
+                currentFieldName = parseFiltersAndFunctions(parseContext, parser, filterFunctions, currentFieldName);
                 functionArrayFound = true;
             } else {
                 ScoreFunction scoreFunction;
@@ -139,7 +137,7 @@ public class FunctionScoreQueryParser implements QueryParser {
                     // we try to parse a score function. If there is no score
                     // function for the current field name,
                     // functionParserMapper.get() will throw an Exception.
-                    scoreFunction = functionParserMapper.get(parseContext, currentFieldName).parse(context, parser);
+                    scoreFunction = functionParserMapper.get(parseContext, currentFieldName).parse(parseContext, parser);
                 }
                 if (functionArrayFound) {
                     String errorString = "already found [functions] array, now encountering [" + currentFieldName + "].";
@@ -170,7 +168,6 @@ public class FunctionScoreQueryParser implements QueryParser {
         if (maxBoost == null) {
             maxBoost = Float.MAX_VALUE;
         }
-        Query result;
         // handle cases where only one score function and no filter was
         // provided. In this case we create a FunctionScoreQuery.
         if (filterFunctions.size() == 0 || filterFunctions.size() == 1 && (filterFunctions.get(0).filter == null || Queries.isConstantMatchAllQuery(filterFunctions.get(0).filter))) {
@@ -179,8 +176,9 @@ public class FunctionScoreQueryParser implements QueryParser {
             if (combineFunction != null) {
                 theQuery.setCombineFunction(combineFunction);
             }
+            theQuery.setBoost(boost);
             theQuery.setMaxBoost(maxBoost);
-            result = theQuery;
+            return theQuery;
             // in all other cases we create a FiltersFunctionScoreQuery.
         } else {
             FiltersFunctionScoreQuery functionScoreQuery = new FiltersFunctionScoreQuery(query, scoreMode,
@@ -188,13 +186,9 @@ public class FunctionScoreQueryParser implements QueryParser {
             if (combineFunction != null) {
                 functionScoreQuery.setCombineFunction(combineFunction);
             }
-            result = functionScoreQuery;
-        }
-        result.setBoost(boost);
-        if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+            functionScoreQuery.setBoost(boost);
+            return functionScoreQuery;
         }
-        return result;
     }
 
     private void handleMisplacedFunctionsDeclaration(String errorString, String functionName) {
@@ -205,9 +199,8 @@ public class FunctionScoreQueryParser implements QueryParser {
         throw new ElasticsearchParseException("failed to parse [{}] query. [{}]", NAME, errorString);
     }
 
-    private String parseFiltersAndFunctions(QueryShardContext context, XContentParser parser,
+    private String parseFiltersAndFunctions(QueryParseContext parseContext, XContentParser parser,
                                             ArrayList<FiltersFunctionScoreQuery.FilterFunction> filterFunctions, String currentFieldName) throws IOException {
-        QueryParseContext parseContext = context.parseContext();
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
             Query filter = null;
@@ -229,7 +222,7 @@ public class FunctionScoreQueryParser implements QueryParser {
                             // functionParserMapper throws exception if parser
                             // non-existent
                             ScoreFunctionParser functionParser = functionParserMapper.get(parseContext, currentFieldName);
-                            scoreFunction = functionParser.parse(context, parser);
+                            scoreFunction = functionParser.parse(parseContext, parser);
                         }
                     }
                 }
@@ -276,16 +269,4 @@ public class FunctionScoreQueryParser implements QueryParser {
         }
         return cf;
     }
-
-    //norelease to be removed once all queries are moved over to extend BaseQueryParser
-    @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-        Query query = parse(parseContext.shardContext());
-        return new QueryWrappingQueryBuilder(query);
-    }
-
-    @Override
-    public FunctionScoreQueryBuilder getBuilderPrototype() {
-        return FunctionScoreQueryBuilder.PROTOTYPE;
-    }
-}
+}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
index 4065f08..74c3d08 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
@@ -21,14 +21,14 @@ package org.elasticsearch.index.query.functionscore;
 
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 
 import java.io.IOException;
 
 public interface ScoreFunctionParser {
 
-    ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException;
+    ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException;
 
     /**
      * Returns the name of the function, for example "linear", "gauss" etc. This
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorParser.java
index 2635c2b..a1c8d20 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/factor/FactorParser.java
@@ -19,13 +19,14 @@
 
 package org.elasticsearch.index.query.functionscore.factor;
 
+import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
+
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.function.BoostScoreFunction;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
 
 import java.io.IOException;
 
@@ -42,7 +43,7 @@ public class FactorParser implements ScoreFunctionParser {
     }
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
         float boostFactor = parser.floatValue();
         return new BoostScoreFunction(boostFactor);
     }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
index 140f541..6f68db5 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
@@ -19,13 +19,15 @@
 
 package org.elasticsearch.index.query.functionscore.fieldvaluefactor;
 
+import org.apache.lucene.document.FieldType;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.lucene.search.function.FieldValueFactorFunction;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.fielddata.IndexNumericFieldData;
+import org.elasticsearch.index.fielddata.plain.DoubleArrayIndexFieldData;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
@@ -52,8 +54,7 @@ public class FieldValueFactorFunctionParser implements ScoreFunctionParser {
     public static String[] NAMES = { "field_value_factor", "fieldValueFactor" };
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
 
         String currentFieldName = null;
         String field = null;
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
index 20c2f55..124336c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
@@ -27,8 +27,8 @@ import org.elasticsearch.common.lucene.search.function.RandomScoreFunction;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.fielddata.IndexFieldData;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
@@ -51,8 +51,8 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
     }
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
+
         int seed = -1;
 
         String currentFieldName = null;
@@ -90,7 +90,7 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
         }
 
         if (seed == -1) {
-            seed = Longs.hashCode(context.nowInMillis());
+            seed = Longs.hashCode(parseContext.nowInMillis());
         }
         final ShardId shardId = SearchContext.current().indexShard().shardId();
         final int salt = (shardId.index().name().hashCode() << 10) | shardId.id();
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
index 38a29f3..2cf066f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
@@ -21,11 +21,11 @@
 
 package org.elasticsearch.index.query.functionscore.script;
 
+import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.lucene.search.function.ScriptScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
@@ -58,8 +58,7 @@ public class ScriptScoreFunctionParser implements ScoreFunctionParser {
     }
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, QueryParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public ScoreFunction parse(QueryParseContext parseContext, XContentParser parser) throws IOException, QueryParsingException {
         ScriptParameterParser scriptParameterParser = new ScriptParameterParser();
         Script script = null;
         Map<String, Object> vars = null;
@@ -101,7 +100,7 @@ public class ScriptScoreFunctionParser implements ScoreFunctionParser {
 
         SearchScript searchScript;
         try {
-            searchScript = context.scriptService().search(context.lookup(), script, ScriptContext.Standard.SEARCH);
+            searchScript = parseContext.scriptService().search(parseContext.lookup(), script, ScriptContext.Standard.SEARCH);
             return new ScriptScoreFunction(script, searchScript);
         } catch (Exception e) {
             throw new QueryParsingException(parseContext, NAMES[0] + " the script could not be loaded", e);
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/BaseInnerHitBuilder.java b/core/src/main/java/org/elasticsearch/index/query/support/BaseInnerHitBuilder.java
new file mode 100644
index 0000000..48a2f59
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/query/support/BaseInnerHitBuilder.java
@@ -0,0 +1,376 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query.support;
+
+import org.elasticsearch.common.Nullable;
+import org.elasticsearch.common.xcontent.ToXContent;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.index.query.QueryBuilder;
+import org.elasticsearch.script.Script;
+import org.elasticsearch.search.builder.SearchSourceBuilder;
+import org.elasticsearch.search.highlight.HighlightBuilder;
+import org.elasticsearch.search.sort.SortBuilder;
+import org.elasticsearch.search.sort.SortOrder;
+
+import java.io.IOException;
+import java.util.Map;
+
+/**
+ */
+@SuppressWarnings("unchecked")
+public abstract class BaseInnerHitBuilder<T extends BaseInnerHitBuilder> implements ToXContent {
+
+    protected SearchSourceBuilder sourceBuilder;
+
+    /**
+     * The index to start to return hits from. Defaults to <tt>0</tt>.
+     */
+    public T setFrom(int from) {
+        sourceBuilder().from(from);
+        return (T) this;
+    }
+
+
+    /**
+     * The number of search hits to return. Defaults to <tt>10</tt>.
+     */
+    public T setSize(int size) {
+        sourceBuilder().size(size);
+        return (T) this;
+    }
+
+    /**
+     * Applies when sorting, and controls if scores will be tracked as well. Defaults to
+     * <tt>false</tt>.
+     */
+    public T setTrackScores(boolean trackScores) {
+        sourceBuilder().trackScores(trackScores);
+        return (T) this;
+    }
+
+    /**
+     * Should each {@link org.elasticsearch.search.SearchHit} be returned with an
+     * explanation of the hit (ranking).
+     */
+    public T setExplain(boolean explain) {
+        sourceBuilder().explain(explain);
+        return (T) this;
+    }
+
+    /**
+     * Should each {@link org.elasticsearch.search.SearchHit} be returned with its
+     * version.
+     */
+    public T setVersion(boolean version) {
+        sourceBuilder().version(version);
+        return (T) this;
+    }
+
+    /**
+     * Add a stored field to be loaded and returned with the inner hit.
+     */
+    public T field(String name) {
+        sourceBuilder().field(name);
+        return (T) this;
+    }
+
+    /**
+     * Sets no fields to be loaded, resulting in only id and type to be returned per field.
+     */
+    public T setNoFields() {
+        sourceBuilder().noFields();
+        return (T) this;
+    }
+
+    /**
+     * Indicates whether the response should contain the stored _source for every hit
+     */
+    public T setFetchSource(boolean fetch) {
+        sourceBuilder().fetchSource(fetch);
+        return (T) this;
+    }
+
+    /**
+     * Indicate that _source should be returned with every hit, with an "include" and/or "exclude" set which can include simple wildcard
+     * elements.
+     *
+     * @param include An optional include (optionally wildcarded) pattern to filter the returned _source
+     * @param exclude An optional exclude (optionally wildcarded) pattern to filter the returned _source
+     */
+    public T setFetchSource(@Nullable String include, @Nullable String exclude) {
+        sourceBuilder().fetchSource(include, exclude);
+        return (T) this;
+    }
+
+    /**
+     * Indicate that _source should be returned with every hit, with an "include" and/or "exclude" set which can include simple wildcard
+     * elements.
+     *
+     * @param includes An optional list of include (optionally wildcarded) pattern to filter the returned _source
+     * @param excludes An optional list of exclude (optionally wildcarded) pattern to filter the returned _source
+     */
+    public T setFetchSource(@Nullable String[] includes, @Nullable String[] excludes) {
+        sourceBuilder().fetchSource(includes, excludes);
+        return (T) this;
+    }
+
+    /**
+     * Adds a field data based field to load and return. The field does not have to be stored,
+     * but its recommended to use non analyzed or numeric fields.
+     *
+     * @param name The field to get from the field data cache
+     */
+    public T addFieldDataField(String name) {
+        sourceBuilder().fieldDataField(name);
+        return (T) this;
+    }
+
+    /**
+     * Adds a script based field to load and return. The field does not have to be stored,
+     * but its recommended to use non analyzed or numeric fields.
+     *
+     * @param name   The name that will represent this value in the return hit
+     * @param script The script to use
+     */
+    public T addScriptField(String name, Script script) {
+        sourceBuilder().scriptField(name, script);
+        return (T) this;
+    }
+
+    /**
+     * Adds a sort against the given field name and the sort ordering.
+     *
+     * @param field The name of the field
+     * @param order The sort ordering
+     */
+    public T addSort(String field, SortOrder order) {
+        sourceBuilder().sort(field, order);
+        return (T) this;
+    }
+
+    /**
+     * Adds a generic sort builder.
+     *
+     * @see org.elasticsearch.search.sort.SortBuilders
+     */
+    public T addSort(SortBuilder sort) {
+        sourceBuilder().sort(sort);
+        return (T) this;
+    }
+
+    public HighlightBuilder highlightBuilder() {
+        return sourceBuilder().highlighter();
+    }
+
+    /**
+     * Adds a field to be highlighted with default fragment size of 100 characters, and
+     * default number of fragments of 5.
+     *
+     * @param name The field to highlight
+     */
+    public T addHighlightedField(String name) {
+        highlightBuilder().field(name);
+        return (T) this;
+    }
+
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters), and
+     * default number of fragments of 5.
+     *
+     * @param name         The field to highlight
+     * @param fragmentSize The size of a fragment in characters
+     */
+    public T addHighlightedField(String name, int fragmentSize) {
+        highlightBuilder().field(name, fragmentSize);
+        return (T) this;
+    }
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters), and
+     * a provided (maximum) number of fragments.
+     *
+     * @param name              The field to highlight
+     * @param fragmentSize      The size of a fragment in characters
+     * @param numberOfFragments The (maximum) number of fragments
+     */
+    public T addHighlightedField(String name, int fragmentSize, int numberOfFragments) {
+        highlightBuilder().field(name, fragmentSize, numberOfFragments);
+        return (T) this;
+    }
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters),
+     * a provided (maximum) number of fragments and an offset for the highlight.
+     *
+     * @param name              The field to highlight
+     * @param fragmentSize      The size of a fragment in characters
+     * @param numberOfFragments The (maximum) number of fragments
+     */
+    public T addHighlightedField(String name, int fragmentSize, int numberOfFragments,
+                                        int fragmentOffset) {
+        highlightBuilder().field(name, fragmentSize, numberOfFragments, fragmentOffset);
+        return (T) this;
+    }
+
+    /**
+     * Adds a highlighted field.
+     */
+    public T addHighlightedField(HighlightBuilder.Field field) {
+        highlightBuilder().field(field);
+        return (T) this;
+    }
+
+    /**
+     * Set a tag scheme that encapsulates a built in pre and post tags. The allows schemes
+     * are <tt>styled</tt> and <tt>default</tt>.
+     *
+     * @param schemaName The tag scheme name
+     */
+    public T setHighlighterTagsSchema(String schemaName) {
+        highlightBuilder().tagsSchema(schemaName);
+        return (T) this;
+    }
+
+    public T setHighlighterFragmentSize(Integer fragmentSize) {
+        highlightBuilder().fragmentSize(fragmentSize);
+        return (T) this;
+    }
+
+    public T setHighlighterNumOfFragments(Integer numOfFragments) {
+        highlightBuilder().numOfFragments(numOfFragments);
+        return (T) this;
+    }
+
+    public T setHighlighterFilter(Boolean highlightFilter) {
+        highlightBuilder().highlightFilter(highlightFilter);
+        return (T) this;
+    }
+
+    /**
+     * The encoder to set for highlighting
+     */
+    public T setHighlighterEncoder(String encoder) {
+        highlightBuilder().encoder(encoder);
+        return (T) this;
+    }
+
+    /**
+     * Explicitly set the pre tags that will be used for highlighting.
+     */
+    public T setHighlighterPreTags(String... preTags) {
+        highlightBuilder().preTags(preTags);
+        return (T) this;
+    }
+
+    /**
+     * Explicitly set the post tags that will be used for highlighting.
+     */
+    public T setHighlighterPostTags(String... postTags) {
+        highlightBuilder().postTags(postTags);
+        return (T) this;
+    }
+
+    /**
+     * The order of fragments per field. By default, ordered by the order in the
+     * highlighted text. Can be <tt>score</tt>, which then it will be ordered
+     * by score of the fragments.
+     */
+    public T setHighlighterOrder(String order) {
+        highlightBuilder().order(order);
+        return (T) this;
+    }
+
+    public T setHighlighterRequireFieldMatch(boolean requireFieldMatch) {
+        highlightBuilder().requireFieldMatch(requireFieldMatch);
+        return (T) this;
+    }
+
+    public T setHighlighterBoundaryMaxScan(Integer boundaryMaxScan) {
+        highlightBuilder().boundaryMaxScan(boundaryMaxScan);
+        return (T) this;
+    }
+
+    public T setHighlighterBoundaryChars(char[] boundaryChars) {
+        highlightBuilder().boundaryChars(boundaryChars);
+        return (T) this;
+    }
+
+    /**
+     * The highlighter type to use.
+     */
+    public T setHighlighterType(String type) {
+        highlightBuilder().highlighterType(type);
+        return (T) this;
+    }
+
+    public T setHighlighterFragmenter(String fragmenter) {
+        highlightBuilder().fragmenter(fragmenter);
+        return (T) this;
+    }
+
+    /**
+     * Sets a query to be used for highlighting all fields instead of the search query.
+     */
+    public T setHighlighterQuery(QueryBuilder highlightQuery) {
+        highlightBuilder().highlightQuery(highlightQuery);
+        return (T) this;
+    }
+
+    /**
+     * Sets the size of the fragment to return from the beginning of the field if there are no matches to
+     * highlight and the field doesn't also define noMatchSize.
+     * @param noMatchSize integer to set or null to leave out of request.  default is null.
+     * @return this builder for chaining
+     */
+    public T setHighlighterNoMatchSize(Integer noMatchSize) {
+        highlightBuilder().noMatchSize(noMatchSize);
+        return (T) this;
+    }
+
+    /**
+     * Sets the maximum number of phrases the fvh will consider if the field doesn't also define phraseLimit.
+     */
+    public T setHighlighterPhraseLimit(Integer phraseLimit) {
+        highlightBuilder().phraseLimit(phraseLimit);
+        return (T) this;
+    }
+
+    public T setHighlighterOptions(Map<String, Object> options) {
+        highlightBuilder().options(options);
+        return (T) this;
+    }
+
+    protected SearchSourceBuilder sourceBuilder() {
+        if (sourceBuilder == null) {
+            sourceBuilder = new SearchSourceBuilder();
+        }
+        return sourceBuilder;
+    }
+
+    @Override
+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
+        if (sourceBuilder != null) {
+            sourceBuilder.innerToXContent(builder, params);
+        }
+        return builder;
+    }
+
+}
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java b/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java
index bb581a8..b4d3e63 100644
--- a/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java
+++ b/core/src/main/java/org/elasticsearch/index/query/support/InnerHitsQueryParserHelper.java
@@ -21,8 +21,6 @@ package org.elasticsearch.index.query.support;
 
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
-import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.fetch.fielddata.FieldDataFieldsParseElement;
@@ -53,12 +51,13 @@ public class InnerHitsQueryParserHelper {
         this.fieldDataFieldsParseElement = fieldDataFieldsParseElement;
     }
 
-    public InnerHitsSubSearchContext parse(XContentParser parser) throws IOException {
+    public InnerHitsSubSearchContext parse(QueryParseContext parserContext) throws IOException, QueryParsingException {
         String fieldName = null;
         XContentParser.Token token;
         String innerHitName = null;
         SubSearchContext subSearchContext = new SubSearchContext(SearchContext.current());
         try {
+            XContentParser parser = parserContext.parser();
             while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                 if (token == XContentParser.Token.FIELD_NAME) {
                     fieldName = parser.currentName();
@@ -73,7 +72,7 @@ public class InnerHitsQueryParserHelper {
                 }
             }
         } catch (Exception e) {
-            throw new IOException("Failed to parse [_inner_hits]");
+            throw new QueryParsingException(parserContext, "Failed to parse [_inner_hits]", e);
         }
         return new InnerHitsSubSearchContext(innerHitName, subSearchContext);
     }
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java b/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java
index 717fe3f..49610a7 100644
--- a/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java
+++ b/core/src/main/java/org/elasticsearch/index/query/support/NestedInnerQueryParseSupport.java
@@ -28,9 +28,8 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
-import org.elasticsearch.index.query.QueryShardContext;
-import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
@@ -42,7 +41,6 @@ import java.io.IOException;
  */
 public class NestedInnerQueryParseSupport {
 
-    protected final QueryShardContext shardContext;
     protected final QueryParseContext parseContext;
 
     private BytesReference source;
@@ -62,15 +60,12 @@ public class NestedInnerQueryParseSupport {
     private ObjectMapper parentObjectMapper;
 
     public NestedInnerQueryParseSupport(XContentParser parser, SearchContext searchContext) {
-        parseContext = searchContext.queryParserService().getShardContext().parseContext();
-        shardContext = searchContext.queryParserService().getShardContext();
-        shardContext.reset(parser);
-
+        parseContext = searchContext.queryParserService().getParseContext();
+        parseContext.reset(parser);
     }
 
-    public NestedInnerQueryParseSupport(QueryShardContext context) {
-        this.parseContext = context.parseContext();
-        this.shardContext = context;
+    public NestedInnerQueryParseSupport(QueryParseContext parseContext) {
+        this.parseContext = parseContext;
     }
 
     public void query() throws IOException {
@@ -108,10 +103,10 @@ public class NestedInnerQueryParseSupport {
             return innerQuery;
         } else {
             if (path == null) {
-                throw new QueryShardException(shardContext, "[nested] requires 'path' field");
+                throw new QueryParsingException(parseContext, "[nested] requires 'path' field");
             }
             if (!queryFound) {
-                throw new QueryShardException(shardContext, "[nested] requires either 'query' or 'filter' field");
+                throw new QueryParsingException(parseContext, "[nested] requires either 'query' or 'filter' field");
             }
 
             XContentParser old = parseContext.parser();
@@ -137,10 +132,10 @@ public class NestedInnerQueryParseSupport {
             return innerFilter;
         } else {
             if (path == null) {
-                throw new QueryShardException(shardContext, "[nested] requires 'path' field");
+                throw new QueryParsingException(parseContext, "[nested] requires 'path' field");
             }
             if (!filterFound) {
-                throw new QueryShardException(shardContext, "[nested] requires either 'query' or 'filter' field");
+                throw new QueryParsingException(parseContext, "[nested] requires either 'query' or 'filter' field");
             }
 
             setPathLevel();
@@ -160,12 +155,12 @@ public class NestedInnerQueryParseSupport {
 
     public void setPath(String path) {
         this.path = path;
-        nestedObjectMapper = shardContext.getObjectMapper(path);
+        nestedObjectMapper = parseContext.getObjectMapper(path);
         if (nestedObjectMapper == null) {
-            throw new QueryShardException(shardContext, "[nested] failed to find nested object under path [" + path + "]");
+            throw new QueryParsingException(parseContext, "[nested] failed to find nested object under path [" + path + "]");
         }
         if (!nestedObjectMapper.nested().isNested()) {
-            throw new QueryShardException(shardContext, "[nested] nested object under path [" + path + "] is not of nested type");
+            throw new QueryParsingException(parseContext, "[nested] nested object under path [" + path + "] is not of nested type");
         }
     }
 
@@ -190,18 +185,18 @@ public class NestedInnerQueryParseSupport {
     }
 
     private void setPathLevel() {
-        ObjectMapper objectMapper = shardContext.nestedScope().getObjectMapper();
+        ObjectMapper objectMapper = parseContext.nestedScope().getObjectMapper();
         if (objectMapper == null) {
-            parentFilter = shardContext.bitsetFilter(Queries.newNonNestedFilter());
+            parentFilter = parseContext.bitsetFilter(Queries.newNonNestedFilter());
         } else {
-            parentFilter = shardContext.bitsetFilter(objectMapper.nestedTypeFilter());
+            parentFilter = parseContext.bitsetFilter(objectMapper.nestedTypeFilter());
         }
         childFilter = nestedObjectMapper.nestedTypeFilter();
-        parentObjectMapper = shardContext.nestedScope().nextLevel(nestedObjectMapper);
+        parentObjectMapper = parseContext.nestedScope().nextLevel(nestedObjectMapper);
     }
 
     private void resetPathLevel() {
-        shardContext.nestedScope().previousLevel();
+        parseContext.nestedScope().previousLevel();
     }
 
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHitBuilder.java b/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHitBuilder.java
new file mode 100644
index 0000000..71229ab
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHitBuilder.java
@@ -0,0 +1,51 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query.support;
+
+import org.elasticsearch.common.xcontent.XContentBuilder;
+
+import java.io.IOException;
+
+/**
+ */
+public class QueryInnerHitBuilder extends BaseInnerHitBuilder<QueryInnerHitBuilder> {
+
+    private String name;
+
+    /**
+     * Set the key name to be used in the response.
+     *
+     * Defaults to the path if used in nested query, child type if used in has_child query and parent type if used in has_parent.
+     */
+    public QueryInnerHitBuilder setName(String name) {
+        this.name = name;
+        return this;
+    }
+
+    @Override
+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
+        super.toXContent(builder, params);
+        if (name != null) {
+            builder.field("name", name);
+        }
+        return builder;
+    }
+
+}
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHits.java b/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHits.java
deleted file mode 100644
index fc9b154..0000000
--- a/core/src/main/java/org/elasticsearch/index/query/support/QueryInnerHits.java
+++ /dev/null
@@ -1,110 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.query.support;
-
-import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.action.support.ToXContentToBytes;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
-import org.elasticsearch.common.xcontent.*;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-
-import java.io.IOException;
-
-/**
- */
-public class QueryInnerHits extends ToXContentToBytes implements Writeable<QueryInnerHits> {
-    private final BytesReference queryInnerHitsSearchSource;
-
-    public QueryInnerHits(StreamInput input) throws IOException {
-        queryInnerHitsSearchSource = input.readBytesReference();
-    }
-
-    public QueryInnerHits(XContentParser parser) throws IOException {
-        BytesStreamOutput out = new BytesStreamOutput();
-        try (XContentBuilder builder = XContentFactory.cborBuilder(out)) {
-            builder.copyCurrentStructure(parser);
-            queryInnerHitsSearchSource = builder.bytes();
-        }
-    }
-
-    public QueryInnerHits() {
-        this(null, null);
-    }
-
-    public QueryInnerHits(String name, InnerHitsBuilder.InnerHit innerHit) {
-        BytesStreamOutput out = new BytesStreamOutput();
-        try (XContentBuilder builder = XContentFactory.cborBuilder(out)) {
-            builder.startObject();
-            if (name != null) {
-                builder.field("name", name);
-            }
-            if (innerHit != null) {
-                innerHit.toXContent(builder, ToXContent.EMPTY_PARAMS);
-            }
-            builder.endObject();
-            this.queryInnerHitsSearchSource = builder.bytes();
-        } catch (IOException e) {
-            throw new ElasticsearchException("failed to build xcontent", e);
-        }
-    }
-
-    @Override
-    public QueryInnerHits readFrom(StreamInput in) throws IOException {
-        return new QueryInnerHits(in);
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.field("inner_hits");
-        try (XContentParser parser = XContentType.CBOR.xContent().createParser(queryInnerHitsSearchSource)) {
-            builder.copyCurrentStructure(parser);
-        }
-        return builder;
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeBytesReference(queryInnerHitsSearchSource);
-    }
-
-    public XContentParser getXcontentParser() throws IOException {
-        return XContentType.CBOR.xContent().createParser(queryInnerHitsSearchSource);
-    }
-
-    @Override
-    public boolean equals(Object o) {
-        if (this == o) return true;
-        if (o == null || getClass() != o.getClass()) return false;
-
-        QueryInnerHits that = (QueryInnerHits) o;
-
-        return queryInnerHitsSearchSource.equals(that.queryInnerHitsSearchSource);
-
-    }
-
-    @Override
-    public int hashCode() {
-        return queryInnerHitsSearchSource.hashCode();
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java b/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java
index a500393..1a12c74 100644
--- a/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java
+++ b/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java
@@ -29,12 +29,12 @@ import org.elasticsearch.common.ParseFieldMatcher;
  */
 public final class QueryParsers {
 
-    public static final ParseField CONSTANT_SCORE = new ParseField("constant_score", "constant_score_auto", "constant_score_filter");
-    public static final ParseField SCORING_BOOLEAN = new ParseField("scoring_boolean");
-    public static final ParseField CONSTANT_SCORE_BOOLEAN = new ParseField("constant_score_boolean");
-    public static final ParseField TOP_TERMS = new ParseField("top_terms_");
-    public static final ParseField TOP_TERMS_BOOST = new ParseField("top_terms_boost_");
-    public static final ParseField TOP_TERMS_BLENDED_FREQS = new ParseField("top_terms_blended_freqs_");
+    private static final ParseField CONSTANT_SCORE = new ParseField("constant_score", "constant_score_auto", "constant_score_filter");
+    private static final ParseField SCORING_BOOLEAN = new ParseField("scoring_boolean");
+    private static final ParseField CONSTANT_SCORE_BOOLEAN = new ParseField("constant_score_boolean");
+    private static final ParseField TOP_TERMS = new ParseField("top_terms_");
+    private static final ParseField TOP_TERMS_BOOST = new ParseField("top_terms_boost_");
+    private static final ParseField TOP_TERMS_BLENDED_FREQS = new ParseField("top_terms_blended_freqs_");
 
     private QueryParsers() {
 
diff --git a/core/src/main/java/org/elasticsearch/index/query/support/XContentStructure.java b/core/src/main/java/org/elasticsearch/index/query/support/XContentStructure.java
index 0d4a4d9..37716d1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/support/XContentStructure.java
+++ b/core/src/main/java/org/elasticsearch/index/query/support/XContentStructure.java
@@ -25,7 +25,6 @@ import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
@@ -38,7 +37,6 @@ import java.io.IOException;
  * immediately, however, the extra overhead means that the type not be
  * extracted prior to query parsing (in the case of unordered JSON).
  */
-//norelease we should be able to delete this class once all queries are refactored
 public abstract class XContentStructure {
 
     private final QueryParseContext parseContext;
@@ -86,14 +84,14 @@ public abstract class XContentStructure {
         BytesReference br = this.bytes();
         assert br != null : "innerBytes must be set with .bytes(bytes) or .freeze() before parsing";
         XContentParser innerParser = XContentHelper.createParser(br);
-        String[] origTypes = QueryShardContext.setTypesWithPrevious(types);
+        String[] origTypes = QueryParseContext.setTypesWithPrevious(types);
         XContentParser old = parseContext.parser();
         parseContext.parser(innerParser);
         try {
             return parseContext.parseInnerQuery();
         } finally {
             parseContext.parser(old);
-            QueryShardContext.setTypes(origTypes);
+            QueryParseContext.setTypes(origTypes);
         }
     }
 
@@ -102,20 +100,18 @@ public abstract class XContentStructure {
      * parses the query in a streaming manner if the types are available at
      * construction time.
      */
-    //norelease we should be able to delete this class once all queries are refactored
-    @Deprecated
     public static class InnerQuery extends XContentStructure {
         private Query query = null;
         private boolean queryParsed = false;
         public InnerQuery(QueryParseContext parseContext1, @Nullable String... types) throws IOException {
             super(parseContext1);
             if (types != null) {
-                String[] origTypes = QueryShardContext.setTypesWithPrevious(types);
+                String[] origTypes = QueryParseContext.setTypesWithPrevious(types);
                 try {
                     query = parseContext1.parseInnerQuery();
                     queryParsed = true;
                 } finally {
-                    QueryShardContext.setTypes(origTypes);
+                    QueryParseContext.setTypes(origTypes);
                 }
             } else {
                 BytesReference innerBytes = XContentFactory.smileBuilder().copyCurrentStructure(parseContext1.parser()).bytes();
diff --git a/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java b/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java
index 0b5dae6..fb5fff8 100644
--- a/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/search/MatchQuery.java
@@ -30,7 +30,7 @@ import org.elasticsearch.common.lucene.search.MultiPhrasePrefixQuery;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.support.QueryParsers;
 
 import java.io.IOException;
@@ -49,7 +49,7 @@ public class MatchQuery {
         ALL
     }
 
-    protected final QueryShardContext context;
+    protected final QueryParseContext parseContext;
 
     protected String analyzer;
 
@@ -60,9 +60,9 @@ public class MatchQuery {
     protected int phraseSlop = 0;
 
     protected Fuzziness fuzziness = null;
-
+    
     protected int fuzzyPrefixLength = FuzzyQuery.defaultPrefixLength;
-
+    
     protected int maxExpansions = FuzzyQuery.defaultMaxExpansions;
 
     protected boolean transpositions = FuzzyQuery.defaultTranspositions;
@@ -72,11 +72,11 @@ public class MatchQuery {
     protected boolean lenient;
 
     protected ZeroTermsQuery zeroTermsQuery = ZeroTermsQuery.NONE;
-
+    
     protected Float commonTermsCutoff = null;
-
-    public MatchQuery(QueryShardContext context) {
-        this.context = context;
+    
+    public MatchQuery(QueryParseContext parseContext) {
+        this.parseContext = parseContext;
     }
 
     public void setAnalyzer(String analyzer) {
@@ -86,7 +86,7 @@ public class MatchQuery {
     public void setOccur(BooleanClause.Occur occur) {
         this.occur = occur;
     }
-
+    
     public void setCommonTermsCutoff(float cutoff) {
         this.commonTermsCutoff = Float.valueOf(cutoff);
     }
@@ -134,11 +134,11 @@ public class MatchQuery {
     protected Analyzer getAnalyzer(MappedFieldType fieldType) {
         if (this.analyzer == null) {
             if (fieldType != null) {
-                return context.getSearchAnalyzer(fieldType);
+                return parseContext.getSearchAnalyzer(fieldType);
             }
-            return context.mapperService().searchAnalyzer();
+            return parseContext.mapperService().searchAnalyzer();
         } else {
-            Analyzer analyzer = context.mapperService().analysisService().analyzer(this.analyzer);
+            Analyzer analyzer = parseContext.mapperService().analysisService().analyzer(this.analyzer);
             if (analyzer == null) {
                 throw new IllegalArgumentException("No analyzer found for [" + this.analyzer + "]");
             }
@@ -148,7 +148,7 @@ public class MatchQuery {
 
     public Query parse(Type type, String fieldName, Object value) throws IOException {
         final String field;
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        MappedFieldType fieldType = parseContext.fieldMapper(fieldName);
         if (fieldType != null) {
             field = fieldType.names().indexName();
         } else {
@@ -157,14 +157,14 @@ public class MatchQuery {
 
         if (fieldType != null && fieldType.useTermQueryWithQueryString() && !forceAnalyzeQueryString()) {
             try {
-                return fieldType.termQuery(value, context);
+                return fieldType.termQuery(value, parseContext);
             } catch (RuntimeException e) {
                 if (lenient) {
                     return null;
                 }
                 throw e;
             }
-
+            
         }
         Analyzer analyzer = getAnalyzer(fieldType);
         assert analyzer != null;
diff --git a/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java b/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java
index 5fb2db0..08cc55f 100644
--- a/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/search/MultiMatchQuery.java
@@ -31,7 +31,7 @@ import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.query.MultiMatchQueryBuilder;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -47,10 +47,10 @@ public class MultiMatchQuery extends MatchQuery {
         this.groupTieBreaker = tieBreaker;
     }
 
-    public MultiMatchQuery(QueryShardContext context) {
-        super(context);
+    public MultiMatchQuery(QueryParseContext parseContext) {
+        super(parseContext);
     }
-
+    
     private Query parseAndApply(Type type, String fieldName, Object value, String minimumShouldMatch, Float boostValue) throws IOException {
         Query query = parse(type, fieldName, value);
         if (query instanceof BooleanQuery) {
@@ -162,7 +162,7 @@ public class MultiMatchQuery extends MatchQuery {
             List<Tuple<String, Float>> missing = new ArrayList<>();
             for (Map.Entry<String, Float> entry : fieldNames.entrySet()) {
                 String name = entry.getKey();
-                MappedFieldType fieldType = context.fieldMapper(name);
+                MappedFieldType fieldType = parseContext.fieldMapper(name);
                 if (fieldType != null) {
                     Analyzer actualAnalyzer = getAnalyzer(fieldType);
                     name = fieldType.names().indexName();
diff --git a/core/src/main/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQuery.java b/core/src/main/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQuery.java
deleted file mode 100644
index 81c33ab..0000000
--- a/core/src/main/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQuery.java
+++ /dev/null
@@ -1,304 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.search.child;
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.CollectionTerminatedException;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.search.XFilteredDocIdSetIterator;
-import org.apache.lucene.search.join.BitSetProducer;
-import org.apache.lucene.util.LongBitSet;
-import org.elasticsearch.common.lucene.IndexCacheableQuery;
-import org.elasticsearch.common.lucene.Lucene;
-import org.elasticsearch.common.lucene.search.NoopCollector;
-import org.elasticsearch.index.fielddata.AtomicParentChildFieldData;
-import org.elasticsearch.index.fielddata.IndexParentChildFieldData;
-import org.elasticsearch.search.internal.SearchContext;
-
-import java.io.IOException;
-import java.util.List;
-import java.util.Set;
-
-/**
- *
- */
-// TODO: Remove me and move the logic to ChildrenQuery when needsScore=false
-public class ChildrenConstantScoreQuery extends IndexCacheableQuery {
-
-    private final IndexParentChildFieldData parentChildIndexFieldData;
-    private final Query childQuery;
-    private final String parentType;
-    private final String childType;
-    private final Filter parentFilter;
-    private final int shortCircuitParentDocSet;
-    private final BitSetProducer nonNestedDocsFilter;
-
-    public ChildrenConstantScoreQuery(IndexParentChildFieldData parentChildIndexFieldData, Query childQuery, String parentType, String childType, Filter parentFilter, int shortCircuitParentDocSet, BitSetProducer nonNestedDocsFilter) {
-        this.parentChildIndexFieldData = parentChildIndexFieldData;
-        this.parentFilter = parentFilter;
-        this.parentType = parentType;
-        this.childType = childType;
-        this.childQuery = childQuery;
-        this.shortCircuitParentDocSet = shortCircuitParentDocSet;
-        this.nonNestedDocsFilter = nonNestedDocsFilter;
-    }
-
-    @Override
-    public Query rewrite(IndexReader reader) throws IOException {
-        final Query childRewritten = childQuery.rewrite(reader);
-        if (childRewritten != childQuery) {
-            ChildrenConstantScoreQuery rewritten = new ChildrenConstantScoreQuery(parentChildIndexFieldData, childRewritten, parentType, childType, parentFilter, shortCircuitParentDocSet, nonNestedDocsFilter);
-            rewritten.setBoost(getBoost());
-            return rewritten;
-        }
-        return super.rewrite(reader);
-    }
-
-    @Override
-    public Weight doCreateWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-        SearchContext sc = SearchContext.current();
-        IndexParentChildFieldData globalIfd = parentChildIndexFieldData.loadGlobal(searcher.getIndexReader());
-
-        final long valueCount;
-        List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();
-        if (globalIfd == null || leaves.isEmpty()) {
-            return new BooleanQuery.Builder().build().createWeight(searcher, needsScores);
-        } else {
-            AtomicParentChildFieldData afd = globalIfd.load(leaves.get(0));
-            SortedDocValues globalValues = afd.getOrdinalsValues(parentType);
-            valueCount = globalValues.getValueCount();
-        }
-
-        if (valueCount == 0) {
-            return new BooleanQuery.Builder().build().createWeight(searcher, needsScores);
-        }
-
-        ParentOrdCollector collector = new ParentOrdCollector(globalIfd, valueCount, parentType);
-        searcher.search(childQuery, collector);
-
-        final long remaining = collector.foundParents();
-        if (remaining == 0) {
-            return new BooleanQuery.Builder().build().createWeight(searcher, needsScores);
-        }
-
-        Filter shortCircuitFilter = null;
-        if (remaining <= shortCircuitParentDocSet) {
-            shortCircuitFilter = ParentIdsFilter.createShortCircuitFilter(
-                    nonNestedDocsFilter, sc, parentType, collector.values, collector.parentOrds, remaining
-            );
-        }
-        return new ParentWeight(this, parentFilter, globalIfd, shortCircuitFilter, collector, remaining);
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (super.equals(obj) == false) {
-            return false;
-        }
-
-        ChildrenConstantScoreQuery that = (ChildrenConstantScoreQuery) obj;
-        if (!childQuery.equals(that.childQuery)) {
-            return false;
-        }
-        if (!childType.equals(that.childType)) {
-            return false;
-        }
-        if (shortCircuitParentDocSet != that.shortCircuitParentDocSet) {
-            return false;
-        }
-        return true;
-    }
-
-    @Override
-    public int hashCode() {
-        int result = super.hashCode();
-        result = 31 * result + childQuery.hashCode();
-        result = 31 * result + childType.hashCode();
-        result = 31 * result + shortCircuitParentDocSet;
-        return result;
-    }
-
-    @Override
-    public String toString(String field) {
-        return "child_filter[" + childType + "/" + parentType + "](" + childQuery + ')';
-    }
-
-    private final class ParentWeight extends Weight  {
-
-        private final Filter parentFilter;
-        private final Filter shortCircuitFilter;
-        private final ParentOrdCollector collector;
-        private final IndexParentChildFieldData globalIfd;
-
-        private long remaining;
-        private float queryNorm;
-        private float queryWeight;
-
-        public ParentWeight(Query query, Filter parentFilter, IndexParentChildFieldData globalIfd, Filter shortCircuitFilter, ParentOrdCollector collector, long remaining) {
-            super(query);
-            this.parentFilter = parentFilter;
-            this.globalIfd = globalIfd;
-            this.shortCircuitFilter = shortCircuitFilter;
-            this.collector = collector;
-            this.remaining = remaining;
-        }
-
-        @Override
-        public void extractTerms(Set<Term> terms) {
-        }
-
-        @Override
-        public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-            return Explanation.match(getBoost(), "not implemented yet...");
-        }
-
-        @Override
-        public float getValueForNormalization() throws IOException {
-            queryWeight = getBoost();
-            return queryWeight * queryWeight;
-        }
-
-        @Override
-        public void normalize(float norm, float topLevelBoost) {
-            this.queryNorm = norm * topLevelBoost;
-            queryWeight *= this.queryNorm;
-        }
-
-        @Override
-        public Scorer scorer(LeafReaderContext context) throws IOException {
-            if (remaining == 0) {
-                return null;
-            }
-
-            if (shortCircuitFilter != null) {
-                DocIdSet docIdSet = shortCircuitFilter.getDocIdSet(context, null);
-                if (!Lucene.isEmpty(docIdSet)) {
-                    DocIdSetIterator iterator = docIdSet.iterator();
-                    if (iterator != null) {
-                        return ConstantScorer.create(iterator, this, queryWeight);
-                    }
-                }
-                return null;
-            }
-
-            DocIdSet parentDocIdSet = this.parentFilter.getDocIdSet(context, null);
-            if (!Lucene.isEmpty(parentDocIdSet)) {
-                // We can't be sure of the fact that liveDocs have been applied, so we apply it here. The "remaining"
-                // count down (short circuit) logic will then work as expected.
-                parentDocIdSet = BitsFilteredDocIdSet.wrap(parentDocIdSet, context.reader().getLiveDocs());
-                DocIdSetIterator innerIterator = parentDocIdSet.iterator();
-                if (innerIterator != null) {
-                    LongBitSet parentOrds = collector.parentOrds;
-                    SortedDocValues globalValues = globalIfd.load(context).getOrdinalsValues(parentType);
-                    if (globalValues != null) {
-                        DocIdSetIterator parentIdIterator = new ParentOrdIterator(innerIterator, parentOrds, globalValues, this);
-                        return ConstantScorer.create(parentIdIterator, this, queryWeight);
-                    }
-                }
-            }
-            return null;
-        }
-
-    }
-
-    private final static class ParentOrdCollector extends NoopCollector {
-
-        private final LongBitSet parentOrds;
-        private final IndexParentChildFieldData indexFieldData;
-        private final String parentType;
-
-        private SortedDocValues values;
-
-        private ParentOrdCollector(IndexParentChildFieldData indexFieldData, long maxOrd, String parentType) {
-            // TODO: look into reusing LongBitSet#bits array
-            this.parentOrds = new LongBitSet(maxOrd + 1);
-            this.indexFieldData = indexFieldData;
-            this.parentType = parentType;
-        }
-
-        @Override
-        public void collect(int doc) throws IOException {
-            if (values != null) {
-                int globalOrdinal = values.getOrd(doc);
-                // TODO: oversize the long bitset and remove the branch
-                if (globalOrdinal >= 0) {
-                    parentOrds.set(globalOrdinal);
-                }
-            }
-        }
-
-        @Override
-        protected void doSetNextReader(LeafReaderContext context) throws IOException {
-            values = indexFieldData.load(context).getOrdinalsValues(parentType);
-        }
-
-        long foundParents() {
-            return parentOrds.cardinality();
-        }
-
-    }
-
-    private final static class ParentOrdIterator extends XFilteredDocIdSetIterator {
-
-        private final LongBitSet parentOrds;
-        private final SortedDocValues ordinals;
-        private final ParentWeight parentWeight;
-
-        private ParentOrdIterator(DocIdSetIterator innerIterator, LongBitSet parentOrds, SortedDocValues ordinals, ParentWeight parentWeight) {
-            super(innerIterator);
-            this.parentOrds = parentOrds;
-            this.ordinals = ordinals;
-            this.parentWeight = parentWeight;
-        }
-
-        @Override
-        protected boolean match(int doc) {
-            if (parentWeight.remaining == 0) {
-                throw new CollectionTerminatedException();
-            }
-
-            long parentOrd = ordinals.getOrd(doc);
-            if (parentOrd >= 0) {
-                boolean match = parentOrds.get(parentOrd);
-                if (match) {
-                    parentWeight.remaining--;
-                }
-                return match;
-            }
-            return false;
-        }
-    }
-
-}
diff --git a/core/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java b/core/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java
deleted file mode 100644
index fd297d8..0000000
--- a/core/src/main/java/org/elasticsearch/index/search/child/ChildrenQuery.java
+++ /dev/null
@@ -1,740 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.CollectionTerminatedException;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.search.XFilteredDocIdSetIterator;
-import org.apache.lucene.search.join.BitSetProducer;
-import org.apache.lucene.util.ToStringUtils;
-import org.elasticsearch.common.lease.Releasable;
-import org.elasticsearch.common.lease.Releasables;
-import org.elasticsearch.common.lucene.IndexCacheableQuery;
-import org.elasticsearch.common.lucene.Lucene;
-import org.elasticsearch.common.lucene.search.NoopCollector;
-import org.elasticsearch.common.util.BigArrays;
-import org.elasticsearch.common.util.FloatArray;
-import org.elasticsearch.common.util.IntArray;
-import org.elasticsearch.common.util.LongHash;
-import org.elasticsearch.index.fielddata.IndexParentChildFieldData;
-import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.internal.SearchContext.Lifetime;
-
-import java.io.IOException;
-import java.util.Set;
-
-/**
- * A query implementation that executes the wrapped child query and connects all the matching child docs to the related
- * parent documents using {@link ParentChildIndexFieldData}.
- * <p/>
- * This query is executed in two rounds. The first round resolves all the matching child documents and groups these
- * documents by parent uid value. Also the child scores are aggregated per parent uid value. During the second round
- * all parent documents having the same uid value that is collected in the first phase are emitted as hit including
- * a score based on the aggregated child scores and score type.
- */
-public final class ChildrenQuery extends IndexCacheableQuery {
-
-    protected final ParentChildIndexFieldData ifd;
-    protected final String parentType;
-    protected final String childType;
-    protected final Filter parentFilter;
-    protected final ScoreType scoreType;
-    protected Query childQuery;
-    protected final int minChildren;
-    protected final int maxChildren;
-    protected final int shortCircuitParentDocSet;
-    protected final BitSetProducer nonNestedDocsFilter;
-
-    public ChildrenQuery(ParentChildIndexFieldData ifd, String parentType, String childType, Filter parentFilter, Query childQuery, ScoreType scoreType, int minChildren, int maxChildren, int shortCircuitParentDocSet, BitSetProducer nonNestedDocsFilter) {
-        this.ifd = ifd;
-        this.parentType = parentType;
-        this.childType = childType;
-        this.parentFilter = parentFilter;
-        this.childQuery = childQuery;
-        this.scoreType = scoreType;
-        this.shortCircuitParentDocSet = shortCircuitParentDocSet;
-        this.nonNestedDocsFilter = nonNestedDocsFilter;
-        assert maxChildren == 0 || minChildren <= maxChildren;
-        this.minChildren = minChildren > 1 ? minChildren : 0;
-        this.maxChildren = maxChildren;
-    }
-
-    @Override
-    public Query rewrite(IndexReader reader) throws IOException {
-        final Query childRewritten = childQuery.rewrite(reader);
-        if (childRewritten != childQuery) {
-            Query rewritten = new ChildrenQuery(ifd, parentType, childType, parentFilter, childRewritten, scoreType, minChildren, maxChildren, shortCircuitParentDocSet, nonNestedDocsFilter);
-            rewritten.setBoost(getBoost());
-            return rewritten;
-        }
-        return super.rewrite(reader);
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (super.equals(obj) == false) {
-            return false;
-        }
-
-        ChildrenQuery that = (ChildrenQuery) obj;
-        if (!childQuery.equals(that.childQuery)) {
-            return false;
-        }
-        if (!childType.equals(that.childType)) {
-            return false;
-        }
-        if (minChildren != that.minChildren) {
-            return false;
-        }
-        if (maxChildren != that.maxChildren) {
-            return false;
-        }
-        return true;
-    }
-
-    @Override
-    public int hashCode() {
-        int result = super.hashCode();
-        result = 31 * result + childQuery.hashCode();
-        result = 31 * result + childType.hashCode();
-        result = 31 * result + minChildren;
-        result = 31 * result + maxChildren;
-        return result;
-    }
-
-    @Override
-    public String toString(String field) {
-        int max = maxChildren == 0 ? Integer.MAX_VALUE : maxChildren;
-        return "ChildrenQuery[min(" + Integer.toString(minChildren) + ") max(" + Integer.toString(max) + ")of " + childType + "/"
-                + parentType + "](" + childQuery.toString(field) + ')' + ToStringUtils.boost(getBoost());
-    }
-
-    @Override
-    public Weight doCreateWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-        SearchContext sc = SearchContext.current();
-
-        IndexParentChildFieldData globalIfd = ifd.loadGlobal(searcher.getIndexReader());
-        if (globalIfd == null) {
-            // No docs of the specified type exist on this shard
-            return new BooleanQuery.Builder().build().createWeight(searcher, needsScores);
-        }
-
-        boolean abort = true;
-        long numFoundParents;
-        ParentCollector collector = null;
-        try {
-            if (minChildren == 0 && maxChildren == 0 && scoreType != ScoreType.NONE) {
-                switch (scoreType) {
-                case MIN:
-                    collector = new MinCollector(globalIfd, sc, parentType);
-                    break;
-                case MAX:
-                    collector = new MaxCollector(globalIfd, sc, parentType);
-                    break;
-                case SUM:
-                    collector = new SumCollector(globalIfd, sc, parentType);
-                    break;
-                }
-            }
-            if (collector == null) {
-                switch (scoreType) {
-                case MIN:
-                    collector = new MinCountCollector(globalIfd, sc, parentType);
-                    break;
-                case MAX:
-                    collector = new MaxCountCollector(globalIfd, sc, parentType);
-                    break;
-                case SUM:
-                case AVG:
-                    collector = new SumCountAndAvgCollector(globalIfd, sc, parentType);
-                    break;
-                case NONE:
-                    collector = new CountCollector(globalIfd, sc, parentType);
-                    break;
-                default:
-                    throw new RuntimeException("Are we missing a score type here? -- " + scoreType);
-                }
-            }
-
-            searcher.search(childQuery, collector);
-            numFoundParents = collector.foundParents();
-            if (numFoundParents == 0) {
-                return new BooleanQuery.Builder().build().createWeight(searcher, needsScores);
-            }
-            abort = false;
-        } finally {
-            if (abort) {
-                Releasables.close(collector);
-            }
-        }
-        sc.addReleasable(collector, Lifetime.COLLECTION);
-        final Filter parentFilter;
-        if (numFoundParents <= shortCircuitParentDocSet) {
-            parentFilter = ParentIdsFilter.createShortCircuitFilter(nonNestedDocsFilter, sc, parentType, collector.values,
-                    collector.parentIdxs, numFoundParents);
-        } else {
-            parentFilter = this.parentFilter;
-        }
-        return new ParentWeight(this, childQuery.createWeight(searcher, needsScores), parentFilter, numFoundParents, collector, minChildren,
-                maxChildren);
-    }
-
-    protected class ParentWeight extends Weight {
-
-        protected final Weight childWeight;
-        protected final Filter parentFilter;
-        protected final ParentCollector collector;
-        protected final int minChildren;
-        protected final int maxChildren;
-
-        protected long remaining;
-        protected float queryNorm;
-        protected float queryWeight;
-
-        protected ParentWeight(Query query, Weight childWeight, Filter parentFilter, long remaining, ParentCollector collector, int minChildren, int maxChildren) {
-            super(query);
-            this.childWeight = childWeight;
-            this.parentFilter = parentFilter;
-            this.remaining = remaining;
-            this.collector = collector;
-            this.minChildren = minChildren;
-            this.maxChildren = maxChildren;
-        }
-
-        @Override
-        public void extractTerms(Set<Term> terms) {
-        }
-
-        @Override
-        public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-            return Explanation.match(getBoost(), "not implemented yet...");
-        }
-
-        @Override
-        public void normalize(float norm, float topLevelBoost) {
-            this.queryNorm = norm * topLevelBoost;
-            queryWeight *= this.queryNorm;
-        }
-
-        @Override
-        public float getValueForNormalization() throws IOException {
-            queryWeight = getBoost();
-            if (scoreType == ScoreType.NONE) {
-                return queryWeight * queryWeight;
-            }
-            float sum = childWeight.getValueForNormalization();
-            sum *= queryWeight * queryWeight;
-            return sum;
-        }
-
-        @Override
-        public Scorer scorer(LeafReaderContext context) throws IOException {
-            DocIdSet parentsSet = parentFilter.getDocIdSet(context, null);
-            if (Lucene.isEmpty(parentsSet) || remaining == 0) {
-                return null;
-            }
-
-            // We can't be sure of the fact that liveDocs have been applied, so we apply it here. The "remaining"
-            // count down (short circuit) logic will then work as expected.
-            DocIdSetIterator parents = BitsFilteredDocIdSet.wrap(parentsSet, context.reader().getLiveDocs()).iterator();
-
-            if (parents != null) {
-                SortedDocValues bytesValues = collector.globalIfd.load(context).getOrdinalsValues(parentType);
-                if (bytesValues == null) {
-                    return null;
-                }
-
-                if (minChildren > 0 || maxChildren != 0 || scoreType == ScoreType.NONE) {
-                    switch (scoreType) {
-                    case NONE:
-                        DocIdSetIterator parentIdIterator = new CountParentOrdIterator(this, parents, collector, bytesValues,
-                                minChildren, maxChildren);
-                        return ConstantScorer.create(parentIdIterator, this, queryWeight);
-                    case AVG:
-                        return new AvgParentCountScorer(this, parents, collector, bytesValues, minChildren, maxChildren);
-                    default:
-                        return new ParentCountScorer(this, parents, collector, bytesValues, minChildren, maxChildren);
-                    }
-                }
-                switch (scoreType) {
-                case AVG:
-                    return new AvgParentScorer(this, parents, collector, bytesValues);
-                default:
-                    return new ParentScorer(this, parents, collector, bytesValues);
-                }
-            }
-            return null;
-        }
-    }
-
-    protected abstract static class ParentCollector extends NoopCollector implements Releasable {
-
-        protected final IndexParentChildFieldData globalIfd;
-        protected final LongHash parentIdxs;
-        protected final BigArrays bigArrays;
-        protected final SearchContext searchContext;
-        protected final String parentType;
-
-        protected SortedDocValues values;
-        protected Scorer scorer;
-
-        protected ParentCollector(IndexParentChildFieldData globalIfd, SearchContext searchContext, String parentType) {
-            this.globalIfd = globalIfd;
-            this.searchContext = searchContext;
-            this.bigArrays = searchContext.bigArrays();
-            this.parentIdxs = new LongHash(512, bigArrays);
-            this.parentType = parentType;
-        }
-
-        @Override
-        public final void collect(int doc) throws IOException {
-            if (values != null) {
-                final long globalOrdinal = values.getOrd(doc);
-                if (globalOrdinal >= 0) {
-                    long parentIdx = parentIdxs.add(globalOrdinal);
-                    if (parentIdx >= 0) {
-                        newParent(parentIdx);
-                    } else {
-                        parentIdx = -1 - parentIdx;
-                        existingParent(parentIdx);
-                    }
-                }
-            }
-        }
-
-        protected void newParent(long parentIdx) throws IOException {
-        }
-
-        protected void existingParent(long parentIdx) throws IOException {
-        }
-
-        public long foundParents() {
-            return parentIdxs.size();
-        }
-
-        @Override
-        protected void doSetNextReader(LeafReaderContext context) throws IOException {
-            values = globalIfd.load(context).getOrdinalsValues(parentType);
-        }
-
-        @Override
-        public void setScorer(Scorer scorer) throws IOException {
-            this.scorer = scorer;
-        }
-
-        @Override
-        public void close() {
-            Releasables.close(parentIdxs);
-        }
-    }
-
-    protected abstract static class ParentScoreCollector extends ParentCollector implements Releasable {
-
-        protected FloatArray scores;
-
-        protected ParentScoreCollector(IndexParentChildFieldData globalIfd, SearchContext searchContext, String parentType) {
-            super(globalIfd, searchContext, parentType);
-            this.scores = this.bigArrays.newFloatArray(512, false);
-        }
-
-        @Override
-        public boolean needsScores() {
-            return true;
-        }
-
-        @Override
-        protected void newParent(long parentIdx) throws IOException {
-            scores = bigArrays.grow(scores, parentIdx + 1);
-            scores.set(parentIdx, scorer.score());
-        }
-
-        @Override
-        public void close() {
-            Releasables.close(parentIdxs, scores);
-        }
-    }
-
-    protected abstract static class ParentScoreCountCollector extends ParentScoreCollector implements Releasable {
-
-        protected IntArray occurrences;
-
-        protected ParentScoreCountCollector(IndexParentChildFieldData globalIfd, SearchContext searchContext, String parentType) {
-            super(globalIfd, searchContext, parentType);
-            this.occurrences = bigArrays.newIntArray(512, false);
-        }
-
-        @Override
-        protected void newParent(long parentIdx) throws IOException {
-            scores = bigArrays.grow(scores, parentIdx + 1);
-            scores.set(parentIdx, scorer.score());
-            occurrences = bigArrays.grow(occurrences, parentIdx + 1);
-            occurrences.set(parentIdx, 1);
-        }
-
-        @Override
-        public void close() {
-            Releasables.close(parentIdxs, scores, occurrences);
-        }
-    }
-
-    private final static class CountCollector extends ParentCollector implements Releasable {
-
-        protected IntArray occurrences;
-
-        protected CountCollector(IndexParentChildFieldData globalIfd, SearchContext searchContext, String parentType) {
-            super(globalIfd, searchContext, parentType);
-            this.occurrences = bigArrays.newIntArray(512, false);
-        }
-
-        @Override
-        protected void newParent(long parentIdx) throws IOException {
-            occurrences = bigArrays.grow(occurrences, parentIdx + 1);
-            occurrences.set(parentIdx, 1);
-        }
-
-        @Override
-        protected void existingParent(long parentIdx) throws IOException {
-            occurrences.increment(parentIdx, 1);
-        }
-
-        @Override
-        public void close() {
-            Releasables.close(parentIdxs, occurrences);
-        }
-    }
-
-    private final static class SumCollector extends ParentScoreCollector {
-
-        private SumCollector(IndexParentChildFieldData globalIfd, SearchContext searchContext, String parentType) {
-            super(globalIfd, searchContext, parentType);
-        }
-
-        @Override
-        protected void existingParent(long parentIdx) throws IOException {
-            scores.increment(parentIdx, scorer.score());
-        }
-    }
-
-    private final static class MaxCollector extends ParentScoreCollector {
-
-        private MaxCollector(IndexParentChildFieldData globalIfd, SearchContext searchContext, String parentType) {
-            super(globalIfd, searchContext, parentType);
-        }
-
-        @Override
-        protected void existingParent(long parentIdx) throws IOException {
-            float currentScore = scorer.score();
-            if (currentScore > scores.get(parentIdx)) {
-                scores.set(parentIdx, currentScore);
-            }
-        }
-    }
-
-    private final static class MinCollector extends ParentScoreCollector {
-
-        private MinCollector(IndexParentChildFieldData globalIfd, SearchContext searchContext, String parentType) {
-            super(globalIfd, searchContext, parentType);
-        }
-
-        @Override
-        protected void existingParent(long parentIdx) throws IOException {
-            float currentScore = scorer.score();
-            if (currentScore < scores.get(parentIdx)) {
-                scores.set(parentIdx, currentScore);
-            }
-        }
-    }
-
-    private final static class MaxCountCollector extends ParentScoreCountCollector {
-
-        private MaxCountCollector(IndexParentChildFieldData globalIfd, SearchContext searchContext, String parentType) {
-            super(globalIfd, searchContext, parentType);
-        }
-
-        @Override
-        protected void existingParent(long parentIdx) throws IOException {
-            float currentScore = scorer.score();
-            if (currentScore > scores.get(parentIdx)) {
-                scores.set(parentIdx, currentScore);
-            }
-            occurrences.increment(parentIdx, 1);
-        }
-    }
-
-    private final static class MinCountCollector extends ParentScoreCountCollector {
-
-        private MinCountCollector(IndexParentChildFieldData globalIfd, SearchContext searchContext, String parentType) {
-            super(globalIfd, searchContext, parentType);
-        }
-
-        @Override
-        protected void existingParent(long parentIdx) throws IOException {
-            float currentScore = scorer.score();
-            if (currentScore < scores.get(parentIdx)) {
-                scores.set(parentIdx, currentScore);
-            }
-            occurrences.increment(parentIdx, 1);
-        }
-    }
-
-    private final static class SumCountAndAvgCollector extends ParentScoreCountCollector {
-
-        SumCountAndAvgCollector(IndexParentChildFieldData globalIfd, SearchContext searchContext, String parentType) {
-            super(globalIfd, searchContext, parentType);
-        }
-
-        @Override
-        protected void existingParent(long parentIdx) throws IOException {
-            scores.increment(parentIdx, scorer.score());
-            occurrences.increment(parentIdx, 1);
-        }
-    }
-
-    private static class ParentScorer extends Scorer {
-
-        final ParentWeight parentWeight;
-        final LongHash parentIds;
-        final FloatArray scores;
-
-        final SortedDocValues globalOrdinals;
-        final DocIdSetIterator parentsIterator;
-
-        int currentDocId = -1;
-        float currentScore;
-
-        ParentScorer(ParentWeight parentWeight, DocIdSetIterator parentsIterator, ParentCollector collector, SortedDocValues globalOrdinals) {
-            super(parentWeight);
-            this.parentWeight = parentWeight;
-            this.globalOrdinals = globalOrdinals;
-            this.parentsIterator = parentsIterator;
-            this.parentIds = collector.parentIdxs;
-            this.scores = ((ParentScoreCollector) collector).scores;
-        }
-
-        @Override
-        public float score() throws IOException {
-            return currentScore;
-        }
-
-        protected boolean acceptAndScore(long parentIdx) {
-            currentScore = scores.get(parentIdx);
-            return true;
-        }
-
-        @Override
-        public int freq() throws IOException {
-            // We don't have the original child query hit info here...
-            // But the freq of the children could be collector and returned here, but makes this Scorer more expensive.
-            return 1;
-        }
-
-        @Override
-        public int docID() {
-            return currentDocId;
-        }
-
-        @Override
-        public int nextDoc() throws IOException {
-            if (parentWeight.remaining == 0) {
-                return currentDocId = NO_MORE_DOCS;
-            }
-
-            while (true) {
-                currentDocId = parentsIterator.nextDoc();
-                if (currentDocId == DocIdSetIterator.NO_MORE_DOCS) {
-                    return currentDocId;
-                }
-
-                final int globalOrdinal = globalOrdinals.getOrd(currentDocId);
-                if (globalOrdinal < 0) {
-                    continue;
-                }
-
-                final long parentIdx = parentIds.find(globalOrdinal);
-                if (parentIdx != -1) {
-                    parentWeight.remaining--;
-                    if (acceptAndScore(parentIdx)) {
-                        return currentDocId;
-                    }
-                }
-            }
-        }
-
-        @Override
-        public int advance(int target) throws IOException {
-            if (parentWeight.remaining == 0) {
-                return currentDocId = NO_MORE_DOCS;
-            }
-
-            currentDocId = parentsIterator.advance(target);
-            if (currentDocId == DocIdSetIterator.NO_MORE_DOCS) {
-                return currentDocId;
-            }
-
-            final long globalOrdinal = globalOrdinals.getOrd(currentDocId);
-            if (globalOrdinal < 0) {
-                return nextDoc();
-            }
-
-            final long parentIdx = parentIds.find(globalOrdinal);
-            if (parentIdx != -1) {
-                parentWeight.remaining--;
-                if (acceptAndScore(parentIdx)) {
-                    return currentDocId;
-                }
-            }
-            return nextDoc();
-        }
-
-        @Override
-        public long cost() {
-            return parentsIterator.cost();
-        }
-    }
-
-    private static class ParentCountScorer extends ParentScorer {
-
-        protected final IntArray occurrences;
-        protected final int minChildren;
-        protected final int maxChildren;
-
-        ParentCountScorer(ParentWeight parentWeight, DocIdSetIterator parentsIterator, ParentCollector collector, SortedDocValues globalOrdinals, int minChildren, int maxChildren) {
-            super(parentWeight, parentsIterator, (ParentScoreCollector) collector, globalOrdinals);
-            this.minChildren = minChildren;
-            this.maxChildren = maxChildren == 0 ? Integer.MAX_VALUE : maxChildren;
-            this.occurrences = ((ParentScoreCountCollector) collector).occurrences;
-        }
-
-        @Override
-        protected boolean acceptAndScore(long parentIdx) {
-            int count = occurrences.get(parentIdx);
-            if (count < minChildren || count > maxChildren) {
-                return false;
-            }
-            return super.acceptAndScore(parentIdx);
-        }
-    }
-
-    private static final class AvgParentScorer extends ParentCountScorer {
-
-        AvgParentScorer(ParentWeight weight, DocIdSetIterator parentsIterator, ParentCollector collector, SortedDocValues globalOrdinals) {
-            super(weight, parentsIterator, collector, globalOrdinals, 0, 0);
-        }
-
-        @Override
-        protected boolean acceptAndScore(long parentIdx) {
-            currentScore = scores.get(parentIdx);
-            currentScore /= occurrences.get(parentIdx);
-            return true;
-        }
-
-    }
-
-    private static final class AvgParentCountScorer extends ParentCountScorer {
-
-        AvgParentCountScorer(ParentWeight weight, DocIdSetIterator parentsIterator, ParentCollector collector, SortedDocValues globalOrdinals, int minChildren, int maxChildren) {
-            super(weight, parentsIterator, collector, globalOrdinals, minChildren, maxChildren);
-        }
-
-        @Override
-        protected boolean acceptAndScore(long parentIdx) {
-            int count = occurrences.get(parentIdx);
-            if (count < minChildren || count > maxChildren) {
-                return false;
-            }
-            currentScore = scores.get(parentIdx);
-            currentScore /= occurrences.get(parentIdx);
-            return true;
-        }
-    }
-
-    private final static class CountParentOrdIterator extends XFilteredDocIdSetIterator {
-
-        private final LongHash parentIds;
-        protected final IntArray occurrences;
-        private final int minChildren;
-        private final int maxChildren;
-        private final SortedDocValues ordinals;
-        private final ParentWeight parentWeight;
-
-        private CountParentOrdIterator(ParentWeight parentWeight, DocIdSetIterator innerIterator, ParentCollector collector, SortedDocValues ordinals, int minChildren, int maxChildren) {
-            super(innerIterator);
-            this.parentIds = ((CountCollector) collector).parentIdxs;
-            this.occurrences = ((CountCollector) collector).occurrences;
-            this.ordinals = ordinals;
-            this.parentWeight = parentWeight;
-            this.minChildren = minChildren;
-            this.maxChildren = maxChildren == 0 ? Integer.MAX_VALUE : maxChildren;
-        }
-
-        @Override
-        protected boolean match(int doc) {
-            if (parentWeight.remaining == 0) {
-                throw new CollectionTerminatedException();
-            }
-
-            final long parentOrd = ordinals.getOrd(doc);
-            if (parentOrd >= 0) {
-                final long parentIdx = parentIds.find(parentOrd);
-                if (parentIdx != -1) {
-                    parentWeight.remaining--;
-                    int count = occurrences.get(parentIdx);
-                    if (count >= minChildren && count <= maxChildren) {
-                        return true;
-                    }
-                }
-            }
-            return false;
-        }
-    }
-
-    public int getMinChildren() {
-        return minChildren;
-    }
-
-    public int getShortCircuitParentDocSet() {
-        return shortCircuitParentDocSet;
-    }
-
-    public int getMaxChildren() {
-        return maxChildren;
-    }
-
-    public ScoreType getScoreType() {
-        return scoreType;
-    }
-
-}
diff --git a/core/src/main/java/org/elasticsearch/index/search/child/ConstantScorer.java b/core/src/main/java/org/elasticsearch/index/search/child/ConstantScorer.java
deleted file mode 100644
index b5789cf..0000000
--- a/core/src/main/java/org/elasticsearch/index/search/child/ConstantScorer.java
+++ /dev/null
@@ -1,77 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.util.BytesRef;
-
-import java.io.IOException;
-
-/**
- * A scorer that wraps a {@link DocIdSetIterator} and emits a constant score.
- */
-// Borrowed from ConstantScoreQuery
-public class ConstantScorer extends Scorer {
-
-    public static ConstantScorer create(DocIdSetIterator iterator, Weight weight, float constantScore) throws IOException {
-        return new ConstantScorer(iterator, weight, constantScore);
-    }
-
-    private final DocIdSetIterator docIdSetIterator;
-    private final float constantScore;
-
-    private ConstantScorer(DocIdSetIterator docIdSetIterator, Weight w, float constantScore) {
-        super(w);
-        this.constantScore = constantScore;
-        this.docIdSetIterator = docIdSetIterator;
-    }
-
-    @Override
-    public int nextDoc() throws IOException {
-        return docIdSetIterator.nextDoc();
-    }
-
-    @Override
-    public int docID() {
-        return docIdSetIterator.docID();
-    }
-
-    @Override
-    public float score() throws IOException {
-        assert docIdSetIterator.docID() != NO_MORE_DOCS;
-        return constantScore;
-    }
-
-    @Override
-    public int freq() throws IOException {
-        return 1;
-    }
-
-    @Override
-    public int advance(int target) throws IOException {
-        return docIdSetIterator.advance(target);
-    }
-
-    @Override
-    public long cost() {
-        return docIdSetIterator.cost();
-    }
-}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/search/child/ParentConstantScoreQuery.java b/core/src/main/java/org/elasticsearch/index/search/child/ParentConstantScoreQuery.java
deleted file mode 100644
index 0f81afb..0000000
--- a/core/src/main/java/org/elasticsearch/index/search/child/ParentConstantScoreQuery.java
+++ /dev/null
@@ -1,257 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.FilteredDocIdSetIterator;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.LongBitSet;
-import org.elasticsearch.common.lucene.IndexCacheableQuery;
-import org.elasticsearch.common.lucene.Lucene;
-import org.elasticsearch.common.lucene.search.NoopCollector;
-import org.elasticsearch.index.fielddata.AtomicParentChildFieldData;
-import org.elasticsearch.index.fielddata.IndexParentChildFieldData;
-import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
-
-import java.io.IOException;
-import java.util.List;
-import java.util.Set;
-
-/**
- * A query that only return child documents that are linked to the parent documents that matched with the inner query.
- */
-public class ParentConstantScoreQuery extends IndexCacheableQuery {
-
-    private final ParentChildIndexFieldData parentChildIndexFieldData;
-    private Query parentQuery;
-    private final String parentType;
-    private final Filter childrenFilter;
-
-    public ParentConstantScoreQuery(ParentChildIndexFieldData parentChildIndexFieldData, Query parentQuery, String parentType, Filter childrenFilter) {
-        this.parentChildIndexFieldData = parentChildIndexFieldData;
-        this.parentQuery = parentQuery;
-        this.parentType = parentType;
-        this.childrenFilter = childrenFilter;
-    }
-
-    @Override
-    public Query rewrite(IndexReader reader) throws IOException {
-        Query parentRewritten = parentQuery.rewrite(reader);
-        if (parentRewritten != parentQuery) {
-            Query rewritten = new ParentConstantScoreQuery(parentChildIndexFieldData, parentRewritten, parentType, childrenFilter);
-            rewritten.setBoost(getBoost());
-            return rewritten;
-        }
-        return super.rewrite(reader);
-    }
-
-    @Override
-    public Weight doCreateWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-        IndexParentChildFieldData globalIfd = parentChildIndexFieldData.loadGlobal(searcher.getIndexReader());
-
-        final long maxOrd;
-        List<LeafReaderContext> leaves = searcher.getIndexReader().leaves();
-        if (globalIfd == null || leaves.isEmpty()) {
-            return new BooleanQuery.Builder().build().createWeight(searcher, needsScores);
-        } else {
-            AtomicParentChildFieldData afd = globalIfd.load(leaves.get(0));
-            SortedDocValues globalValues = afd.getOrdinalsValues(parentType);
-            maxOrd = globalValues.getValueCount();
-        }
-
-        if (maxOrd == 0) {
-            return new BooleanQuery.Builder().build().createWeight(searcher, needsScores);
-        }
-
-        ParentOrdsCollector collector = new ParentOrdsCollector(globalIfd, maxOrd, parentType);
-        searcher.search(parentQuery, collector);
-
-        if (collector.parentCount() == 0) {
-            return new BooleanQuery.Builder().build().createWeight(searcher, needsScores);
-        }
-
-        return new ChildrenWeight(this, childrenFilter, collector, globalIfd);
-    }
-
-    @Override
-    public int hashCode() {
-        int result = super.hashCode();
-        result = 31 * result + parentQuery.hashCode();
-        result = 31 * result + parentType.hashCode();
-        return result;
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (super.equals(obj) == false) {
-            return false;
-        }
-
-        ParentConstantScoreQuery that = (ParentConstantScoreQuery) obj;
-        if (!parentQuery.equals(that.parentQuery)) {
-            return false;
-        }
-        if (!parentType.equals(that.parentType)) {
-            return false;
-        }
-        return true;
-    }
-
-    @Override
-    public String toString(String field) {
-        return "parent_filter[" + parentType + "](" + parentQuery + ')';
-    }
-
-    private final class ChildrenWeight extends Weight {
-
-        private final IndexParentChildFieldData globalIfd;
-        private final Filter childrenFilter;
-        private final LongBitSet parentOrds;
-
-        private float queryNorm;
-        private float queryWeight;
-
-        private ChildrenWeight(Query query, Filter childrenFilter, ParentOrdsCollector collector, IndexParentChildFieldData globalIfd) {
-            super(query);
-            this.globalIfd = globalIfd;
-            this.childrenFilter = childrenFilter;
-            this.parentOrds = collector.parentOrds;
-        }
-
-        @Override
-        public void extractTerms(Set<Term> terms) {
-        }
-
-        @Override
-        public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-            return Explanation.match(getBoost(), "not implemented yet...");
-        }
-
-        @Override
-        public float getValueForNormalization() throws IOException {
-            queryWeight = getBoost();
-            return queryWeight * queryWeight;
-        }
-
-        @Override
-        public void normalize(float norm, float topLevelBoost) {
-            this.queryNorm = norm * topLevelBoost;
-            queryWeight *= this.queryNorm;
-        }
-
-        @Override
-        public Scorer scorer(LeafReaderContext context) throws IOException {
-            DocIdSet childrenDocIdSet = childrenFilter.getDocIdSet(context, null);
-            if (Lucene.isEmpty(childrenDocIdSet)) {
-                return null;
-            }
-
-            SortedDocValues globalValues = globalIfd.load(context).getOrdinalsValues(parentType);
-            if (globalValues != null) {
-                // we forcefully apply live docs here so that deleted children don't give matching parents
-                childrenDocIdSet = BitsFilteredDocIdSet.wrap(childrenDocIdSet, context.reader().getLiveDocs());
-                DocIdSetIterator innerIterator = childrenDocIdSet.iterator();
-                if (innerIterator != null) {
-                    ChildrenDocIdIterator childrenDocIdIterator = new ChildrenDocIdIterator(
-                            innerIterator, parentOrds, globalValues
-                    );
-                    return ConstantScorer.create(childrenDocIdIterator, this, queryWeight);
-                }
-            }
-            return null;
-        }
-
-    }
-
-    private final class ChildrenDocIdIterator extends FilteredDocIdSetIterator {
-
-        private final LongBitSet parentOrds;
-        private final SortedDocValues globalOrdinals;
-
-        ChildrenDocIdIterator(DocIdSetIterator innerIterator, LongBitSet parentOrds, SortedDocValues globalOrdinals) {
-            super(innerIterator);
-            this.parentOrds = parentOrds;
-            this.globalOrdinals = globalOrdinals;
-        }
-
-        @Override
-        protected boolean match(int docId) {
-            int globalOrd = globalOrdinals.getOrd(docId);
-            if (globalOrd >= 0) {
-                return parentOrds.get(globalOrd);
-            } else {
-                return false;
-            }
-        }
-
-    }
-
-    private final static class ParentOrdsCollector extends NoopCollector {
-
-        private final LongBitSet parentOrds;
-        private final IndexParentChildFieldData globalIfd;
-        private final String parentType;
-
-        private SortedDocValues globalOrdinals;
-
-        ParentOrdsCollector(IndexParentChildFieldData globalIfd, long maxOrd, String parentType) {
-            this.parentOrds = new LongBitSet(maxOrd);
-            this.globalIfd = globalIfd;
-            this.parentType = parentType;
-        }
-
-        @Override
-        public void collect(int doc) throws IOException {
-            // It can happen that for particular segment no document exist for an specific type. This prevents NPE
-            if (globalOrdinals != null) {
-                long globalOrd = globalOrdinals.getOrd(doc);
-                if (globalOrd >= 0) {
-                    parentOrds.set(globalOrd);
-                }
-            }
-        }
-
-        @Override
-        public void doSetNextReader(LeafReaderContext readerContext) throws IOException {
-            globalOrdinals = globalIfd.load(readerContext).getOrdinalsValues(parentType);
-        }
-
-        public long parentCount() {
-            return parentOrds.cardinality();
-        }
-    }
-
-}
-
diff --git a/core/src/main/java/org/elasticsearch/index/search/child/ParentIdsFilter.java b/core/src/main/java/org/elasticsearch/index/search/child/ParentIdsFilter.java
deleted file mode 100644
index 10ead15..0000000
--- a/core/src/main/java/org/elasticsearch/index/search/child/ParentIdsFilter.java
+++ /dev/null
@@ -1,187 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.join.BitSetProducer;
-import org.apache.lucene.util.BitDocIdSet;
-import org.apache.lucene.util.BitSet;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util.LongBitSet;
-import org.apache.lucene.util.SparseFixedBitSet;
-import org.elasticsearch.common.lease.Releasables;
-import org.elasticsearch.common.util.BytesRefHash;
-import org.elasticsearch.common.util.LongHash;
-import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.mapper.internal.UidFieldMapper;
-import org.elasticsearch.search.internal.SearchContext;
-
-import java.io.IOException;
-
-/**
- * Advantages over using this filter over Lucene's TermsFilter in the parent child context:
- * 1) Don't need to copy all values over to a list from the id cache and then
- * copy all the ids values over to one continuous byte array. Should save a lot of of object creations and gcs..
- * 2) We filter docs by one field only.
- */
-final class ParentIdsFilter extends Filter {
-
-    static Filter createShortCircuitFilter(BitSetProducer nonNestedDocsFilter, SearchContext searchContext,
-                                           String parentType, SortedDocValues globalValues,
-                                           LongBitSet parentOrds, long numFoundParents) {
-        BytesRefHash parentIds= null;
-        boolean constructed = false;
-        try {
-            parentIds = new BytesRefHash(numFoundParents, searchContext.bigArrays());
-            for (long parentOrd = parentOrds.nextSetBit(0); parentOrd != -1; parentOrd = parentOrds.nextSetBit(parentOrd + 1)) {
-                parentIds.add(globalValues.lookupOrd((int) parentOrd));
-            }
-            constructed = true;
-        } finally {
-            if (!constructed) {
-                Releasables.close(parentIds);
-            }
-        }
-        searchContext.addReleasable(parentIds, SearchContext.Lifetime.COLLECTION);
-        return new ParentIdsFilter(parentType, nonNestedDocsFilter, parentIds);
-    }
-
-    static Filter createShortCircuitFilter(BitSetProducer nonNestedDocsFilter, SearchContext searchContext,
-                                           String parentType, SortedDocValues globalValues,
-                                           LongHash parentIdxs, long numFoundParents) {
-        BytesRefHash parentIds = null;
-        boolean constructed = false;
-        try {
-            parentIds = new BytesRefHash(numFoundParents, searchContext.bigArrays());
-            for (int id = 0; id < parentIdxs.size(); id++) {
-                parentIds.add(globalValues.lookupOrd((int) parentIdxs.get(id)));
-            }
-            constructed = true;
-        } finally {
-            if (!constructed) {
-                Releasables.close(parentIds);
-            }
-        }
-        searchContext.addReleasable(parentIds, SearchContext.Lifetime.COLLECTION);
-        return new ParentIdsFilter(parentType, nonNestedDocsFilter, parentIds);
-    }
-
-    private final BytesRef parentTypeBr;
-    private final BitSetProducer nonNestedDocsFilter;
-    private final BytesRefHash parentIds;
-
-    private ParentIdsFilter(String parentType, BitSetProducer nonNestedDocsFilter, BytesRefHash parentIds) {
-        this.nonNestedDocsFilter = nonNestedDocsFilter;
-        this.parentTypeBr = new BytesRef(parentType);
-        this.parentIds = parentIds;
-    }
-
-    @Override
-    public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
-        Terms terms = context.reader().terms(UidFieldMapper.NAME);
-        if (terms == null) {
-            return null;
-        }
-
-        TermsEnum termsEnum = terms.iterator();
-        BytesRefBuilder uidSpare = new BytesRefBuilder();
-        BytesRef idSpare = new BytesRef();
-
-        if (acceptDocs == null) {
-            acceptDocs = context.reader().getLiveDocs();
-        }
-
-        BitSet nonNestedDocs = null;
-        if (nonNestedDocsFilter != null) {
-            nonNestedDocs = nonNestedDocsFilter.getBitSet(context);
-        }
-
-        PostingsEnum docsEnum = null;
-        BitSet result = null;
-        int size = (int) parentIds.size();
-        for (int i = 0; i < size; i++) {
-            parentIds.get(i, idSpare);
-            BytesRef uid = Uid.createUidAsBytes(parentTypeBr, idSpare, uidSpare);
-            if (termsEnum.seekExact(uid)) {
-                docsEnum = termsEnum.postings(docsEnum, PostingsEnum.NONE);
-                int docId;
-                for (docId = docsEnum.nextDoc(); docId != DocIdSetIterator.NO_MORE_DOCS; docId = docsEnum.nextDoc()) {
-                    if (acceptDocs == null || acceptDocs.get(docId)) {
-                        break;
-                    }
-                }
-                if (docId == DocIdSetIterator.NO_MORE_DOCS) {
-                    continue;
-                }
-                if (result == null) {
-                    // very rough heuristic that tries to get an idea of the number of documents
-                    // in the set based on the number of parent ids that we didn't find in this segment
-                    final int expectedCardinality = size / (i + 1);
-                    // similar heuristic to BitDocIdSet.Builder
-                    if (expectedCardinality >= (context.reader().maxDoc() >>> 10)) {
-                        result = new FixedBitSet(context.reader().maxDoc());
-                    } else {
-                        result = new SparseFixedBitSet(context.reader().maxDoc());
-                    }
-                }
-                if (nonNestedDocs != null) {
-                    docId = nonNestedDocs.nextSetBit(docId);
-                }
-                result.set(docId);
-                assert docsEnum.advance(docId + 1) == DocIdSetIterator.NO_MORE_DOCS : "DocId " + docId + " should have been the last one but docId " + docsEnum.docID() + " exists.";
-            }
-        }
-        return result == null ? null : new BitDocIdSet(result);
-    }
-
-    @Override
-    public String toString(String field) {
-        return "parentsFilter(type=" + parentTypeBr.utf8ToString() + ")";
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (super.equals(obj) == false) {
-            return false;
-        }
-        ParentIdsFilter other = (ParentIdsFilter) obj;
-        return parentTypeBr.equals(other.parentTypeBr)
-                && parentIds.equals(other.parentIds)
-                && nonNestedDocsFilter.equals(nonNestedDocsFilter);
-    }
-
-    @Override
-    public int hashCode() {
-        int h = super.hashCode();
-        h = 31 * h + parentTypeBr.hashCode();
-        h = 31 * h + parentIds.hashCode();
-        h = 31 * h + nonNestedDocsFilter.hashCode();
-        return h;
-    }
-}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/search/child/ParentQuery.java b/core/src/main/java/org/elasticsearch/index/search/child/ParentQuery.java
deleted file mode 100644
index 141d4f1..0000000
--- a/core/src/main/java/org/elasticsearch/index/search/child/ParentQuery.java
+++ /dev/null
@@ -1,350 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.SortedSetDocValues;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Collector;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.LeafCollector;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.ToStringUtils;
-import org.elasticsearch.common.lease.Releasable;
-import org.elasticsearch.common.lease.Releasables;
-import org.elasticsearch.common.lucene.IndexCacheableQuery;
-import org.elasticsearch.common.lucene.Lucene;
-import org.elasticsearch.common.lucene.search.NoopCollector;
-import org.elasticsearch.common.util.BigArrays;
-import org.elasticsearch.common.util.FloatArray;
-import org.elasticsearch.common.util.LongHash;
-import org.elasticsearch.index.fielddata.IndexParentChildFieldData;
-import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.internal.SearchContext.Lifetime;
-
-import java.io.IOException;
-import java.util.Set;
-
-/**
- * A query implementation that executes the wrapped parent query and
- * connects the matching parent docs to the related child documents
- * using the {@link ParentChildIndexFieldData}.
- */
-public class ParentQuery extends IndexCacheableQuery {
-
-    private final ParentChildIndexFieldData parentChildIndexFieldData;
-    private Query parentQuery;
-    private final String parentType;
-    private final Filter childrenFilter;
-
-    public ParentQuery(ParentChildIndexFieldData parentChildIndexFieldData, Query parentQuery, String parentType, Filter childrenFilter) {
-        this.parentChildIndexFieldData = parentChildIndexFieldData;
-        this.parentQuery = parentQuery;
-        this.parentType = parentType;
-        this.childrenFilter = childrenFilter;
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (super.equals(obj) == false) {
-            return false;
-        }
-
-        ParentQuery that = (ParentQuery) obj;
-        if (!parentQuery.equals(that.parentQuery)) {
-            return false;
-        }
-        if (!parentType.equals(that.parentType)) {
-            return false;
-        }
-        return true;
-    }
-
-    @Override
-    public int hashCode() {
-        int result = super.hashCode();
-        result = 31 * result + parentQuery.hashCode();
-        result = 31 * result + parentType.hashCode();
-        result = 31 * result + Float.floatToIntBits(getBoost());
-        return result;
-    }
-
-    @Override
-    public String toString(String field) {
-        return "ParentQuery[" + parentType + "](" + parentQuery.toString(field) + ')' + ToStringUtils.boost(getBoost());
-    }
-
-    @Override
-    public Query rewrite(IndexReader reader) throws IOException {
-        Query parentRewritten = parentQuery.rewrite(reader);
-        if (parentRewritten != parentQuery) {
-            Query rewritten = new ParentQuery(parentChildIndexFieldData, parentRewritten, parentType, childrenFilter);
-            rewritten.setBoost(getBoost());
-            return rewritten;
-        }
-        return super.rewrite(reader);
-    }
-
-    @Override
-    public Weight doCreateWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-        SearchContext sc = SearchContext.current();
-        ChildWeight childWeight;
-        boolean releaseCollectorResource = true;
-        ParentOrdAndScoreCollector collector = null;
-        IndexParentChildFieldData globalIfd = parentChildIndexFieldData.loadGlobal(searcher.getIndexReader());
-        if (globalIfd == null) {
-            // No docs of the specified type don't exist on this shard
-            return new BooleanQuery.Builder().build().createWeight(searcher, needsScores);
-        }
-
-        try {
-            collector = new ParentOrdAndScoreCollector(sc, globalIfd, parentType);
-            searcher.search(parentQuery, collector);
-            if (collector.parentCount() == 0) {
-                return new BooleanQuery.Builder().build().createWeight(searcher, needsScores);
-            }
-            childWeight = new ChildWeight(this, parentQuery.createWeight(searcher, needsScores), childrenFilter, collector, globalIfd);
-            releaseCollectorResource = false;
-        } finally {
-            if (releaseCollectorResource) {
-                // either if we run into an exception or if we return early
-                Releasables.close(collector);
-            }
-        }
-        sc.addReleasable(collector, Lifetime.COLLECTION);
-        return childWeight;
-    }
-
-    private static class ParentOrdAndScoreCollector implements Collector, Releasable {
-
-        private final LongHash parentIdxs;
-        private FloatArray scores;
-        private final IndexParentChildFieldData globalIfd;
-        private final BigArrays bigArrays;
-        private final String parentType;
-
-        ParentOrdAndScoreCollector(SearchContext searchContext, IndexParentChildFieldData globalIfd, String parentType) {
-            this.bigArrays = searchContext.bigArrays();
-            this.parentIdxs = new LongHash(512, bigArrays);
-            this.scores = bigArrays.newFloatArray(512, false);
-            this.globalIfd = globalIfd;
-            this.parentType = parentType;
-        }
-
-        @Override
-        public boolean needsScores() {
-            return true;
-        }
-
-        @Override
-        public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {
-            final SortedDocValues values = globalIfd.load(context).getOrdinalsValues(parentType);
-            if (values == null) {
-                return NoopCollector.NOOP_COLLECTOR;
-            }
-            return new LeafCollector() {
-                Scorer scorer;
-                @Override
-                public void setScorer(Scorer scorer) throws IOException {
-                    this.scorer = scorer;
-                }
-                @Override
-                public void collect(int doc) throws IOException {
-                    long globalOrdinal = values.getOrd(doc);
-                    if (globalOrdinal != SortedSetDocValues.NO_MORE_ORDS) {
-                        long parentIdx = parentIdxs.add(globalOrdinal);
-                        if (parentIdx >= 0) {
-                            scores = bigArrays.grow(scores, parentIdx + 1);
-                            scores.set(parentIdx, scorer.score());
-                        } else {
-                            assert false : "parent id should only match once, since there can only be one parent doc";
-                        }
-                    }
-                }
-            };
-        }
-
-        @Override
-        public void close() {
-            Releasables.close(parentIdxs, scores);
-        }
-
-        public long parentCount() {
-            return parentIdxs.size();
-        }
-
-    }
-
-    private class ChildWeight extends Weight {
-
-        private final Weight parentWeight;
-        private final Filter childrenFilter;
-        private final LongHash parentIdxs;
-        private final FloatArray scores;
-        private final IndexParentChildFieldData globalIfd;
-
-        private ChildWeight(Query query, Weight parentWeight, Filter childrenFilter, ParentOrdAndScoreCollector collector, IndexParentChildFieldData globalIfd) {
-            super(query);
-            this.parentWeight = parentWeight;
-            this.childrenFilter = childrenFilter;
-            this.parentIdxs = collector.parentIdxs;
-            this.scores = collector.scores;
-            this.globalIfd = globalIfd;
-        }
-
-        @Override
-        public void extractTerms(Set<Term> terms) {
-        }
-
-        @Override
-        public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-            return Explanation.match(getBoost(), "not implemented yet...");
-        }
-
-        @Override
-        public float getValueForNormalization() throws IOException {
-            float sum = parentWeight.getValueForNormalization();
-            sum *= getBoost() * getBoost();
-            return sum;
-        }
-
-        @Override
-        public void normalize(float norm, float topLevelBoost) {
-        }
-
-        @Override
-        public Scorer scorer(LeafReaderContext context) throws IOException {
-            DocIdSet childrenDocSet = childrenFilter.getDocIdSet(context, null);
-            // we forcefully apply live docs here so that deleted children don't give matching parents
-            childrenDocSet = BitsFilteredDocIdSet.wrap(childrenDocSet, context.reader().getLiveDocs());
-            if (Lucene.isEmpty(childrenDocSet)) {
-                return null;
-            }
-            final DocIdSetIterator childIterator = childrenDocSet.iterator();
-            if (childIterator == null) {
-                return null;
-            }
-            SortedDocValues bytesValues = globalIfd.load(context).getOrdinalsValues(parentType);
-            if (bytesValues == null) {
-                return null;
-            }
-
-            return new ChildScorer(this, parentIdxs, scores, childIterator, bytesValues);
-        }
-
-    }
-
-    private static class ChildScorer extends Scorer {
-
-        private final LongHash parentIdxs;
-        private final FloatArray scores;
-        private final DocIdSetIterator childrenIterator;
-        private final SortedDocValues ordinals;
-
-        private int currentChildDoc = -1;
-        private float currentScore;
-
-        ChildScorer(Weight weight, LongHash parentIdxs, FloatArray scores, DocIdSetIterator childrenIterator, SortedDocValues ordinals) {
-            super(weight);
-            this.parentIdxs = parentIdxs;
-            this.scores = scores;
-            this.childrenIterator = childrenIterator;
-            this.ordinals = ordinals;
-        }
-
-        @Override
-        public float score() throws IOException {
-            return currentScore;
-        }
-
-        @Override
-        public int freq() throws IOException {
-            // We don't have the original child query hit info here...
-            // But the freq of the children could be collector and returned here, but makes this Scorer more expensive.
-            return 1;
-        }
-
-        @Override
-        public int docID() {
-            return currentChildDoc;
-        }
-
-        @Override
-        public int nextDoc() throws IOException {
-            while (true) {
-                currentChildDoc = childrenIterator.nextDoc();
-                if (currentChildDoc == DocIdSetIterator.NO_MORE_DOCS) {
-                    return currentChildDoc;
-                }
-
-                int globalOrdinal = (int) ordinals.getOrd(currentChildDoc);
-                if (globalOrdinal < 0) {
-                    continue;
-                }
-
-                final long parentIdx = parentIdxs.find(globalOrdinal);
-                if (parentIdx != -1) {
-                    currentScore = scores.get(parentIdx);
-                    return currentChildDoc;
-                }
-            }
-        }
-
-        @Override
-        public int advance(int target) throws IOException {
-            currentChildDoc = childrenIterator.advance(target);
-            if (currentChildDoc == DocIdSetIterator.NO_MORE_DOCS) {
-                return currentChildDoc;
-            }
-
-            int globalOrdinal = (int) ordinals.getOrd(currentChildDoc);
-            if (globalOrdinal < 0) {
-                return nextDoc();
-            }
-
-            final long parentIdx = parentIdxs.find(globalOrdinal);
-            if (parentIdx != -1) {
-                currentScore = scores.get(parentIdx);
-                return currentChildDoc;
-            } else {
-                return nextDoc();
-            }
-        }
-
-        @Override
-        public long cost() {
-            return childrenIterator.cost();
-        }
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/search/child/ScoreType.java b/core/src/main/java/org/elasticsearch/index/search/child/ScoreType.java
deleted file mode 100644
index b9ea628..0000000
--- a/core/src/main/java/org/elasticsearch/index/search/child/ScoreType.java
+++ /dev/null
@@ -1,71 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-
-/**
- * Defines how scores from child documents are mapped into the parent document.
- */
-public enum ScoreType {
-    /**
-     * Only the lowest score of all matching child documents is mapped into the
-     * parent.
-     */
-    MIN,
-    /**
-     * Only the highest score of all matching child documents is mapped into the
-     * parent.
-     */
-    MAX,
-
-    /**
-     * The average score based on all matching child documents are mapped into
-     * the parent.
-     */
-    AVG,
-
-    /**
-     * The matching children scores is summed up and mapped into the parent.
-     */
-    SUM,
-
-    /**
-     * Scores are not taken into account
-     */
-    NONE;
-
-
-    public static ScoreType fromString(String type) {
-        if ("none".equals(type)) {
-            return NONE;
-        } else if ("min".equals(type)) {
-            return MIN;
-        } else if ("max".equals(type)) {
-            return MAX;
-        } else if ("avg".equals(type)) {
-            return AVG;
-        } else if ("sum".equals(type)) {
-            return SUM;
-        } else if ("total".equals(type)) { // This name is consistent with: ScoreMode.Total
-            return SUM;
-        }
-        throw new IllegalArgumentException("No score type for child query [" + type + "] found");
-    }
-
-}
diff --git a/core/src/main/java/org/elasticsearch/index/search/morelikethis/MoreLikeThisFetchService.java b/core/src/main/java/org/elasticsearch/index/search/morelikethis/MoreLikeThisFetchService.java
index 1c64d2b..49643aa 100644
--- a/core/src/main/java/org/elasticsearch/index/search/morelikethis/MoreLikeThisFetchService.java
+++ b/core/src/main/java/org/elasticsearch/index/search/morelikethis/MoreLikeThisFetchService.java
@@ -20,12 +20,17 @@
 package org.elasticsearch.index.search.morelikethis;
 
 import org.apache.lucene.index.Fields;
-import org.elasticsearch.action.termvectors.*;
+import org.elasticsearch.action.termvectors.MultiTermVectorsItemResponse;
+import org.elasticsearch.action.termvectors.MultiTermVectorsRequest;
+import org.elasticsearch.action.termvectors.MultiTermVectorsResponse;
+import org.elasticsearch.action.termvectors.TermVectorsResponse;
 import org.elasticsearch.client.Client;
+import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.query.MoreLikeThisQueryBuilder.Item;
+import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -46,24 +51,35 @@ public class MoreLikeThisFetchService extends AbstractComponent {
         this.client = client;
     }
 
-    public Fields[] fetch(MultiTermVectorsRequest requests) throws IOException {
-        return getFields(fetchResponse(requests), requests);
+    public Fields[] fetch(List<Item> items) throws IOException {
+        return getFieldsFor(fetchResponse(items, null, SearchContext.current()), items);
     }
 
-    public MultiTermVectorsResponse fetchResponse(MultiTermVectorsRequest requests) throws IOException {
-        return client.multiTermVectors(requests).actionGet();
+    public MultiTermVectorsResponse fetchResponse(List<Item> likeItems, @Nullable List<Item> unlikeItems,
+                                                  SearchContext searchContext) throws IOException {
+        MultiTermVectorsRequest request = new MultiTermVectorsRequest();
+        for (Item item : likeItems) {
+            request.add(item.toTermVectorsRequest());
+        }
+        if (unlikeItems != null) {
+            for (Item item : unlikeItems) {
+                request.add(item.toTermVectorsRequest());
+            }
+        }
+        request.copyContextAndHeadersFrom(searchContext);
+        return client.multiTermVectors(request).actionGet();
     }
 
-    public static Fields[] getFields(MultiTermVectorsResponse responses, MultiTermVectorsRequest requests) throws IOException {
+    public static Fields[] getFieldsFor(MultiTermVectorsResponse responses, List<Item> items) throws IOException {
         List<Fields> likeFields = new ArrayList<>();
 
-        Set<Item> items = new HashSet<>();
-        for (TermVectorsRequest request : requests) {
-            items.add(new Item(request.index(), request.type(), request.id()));
+        Set<Item> selectedItems = new HashSet<>();
+        for (Item request : items) {
+            selectedItems.add(new Item(request.index(), request.type(), request.id()));
         }
 
         for (MultiTermVectorsItemResponse response : responses) {
-            if (!hasResponseFromRequest(response, items)) {
+            if (!hasResponseFromRequest(response, selectedItems)) {
                 continue;
             }
             if (response.isFailed()) {
@@ -78,7 +94,7 @@ public class MoreLikeThisFetchService extends AbstractComponent {
         return likeFields.toArray(Fields.EMPTY_ARRAY);
     }
 
-    private static boolean hasResponseFromRequest(MultiTermVectorsItemResponse response, Set<Item> items) {
-        return items.contains(new Item(response.getIndex(), response.getType(), response.getId()));
+    private static boolean hasResponseFromRequest(MultiTermVectorsItemResponse response, Set<Item> selectedItems) {
+        return selectedItems.contains(new Item(response.getIndex(), response.getType(), response.getId()));
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/search/termslookup/TermsLookupFetchService.java b/core/src/main/java/org/elasticsearch/index/search/termslookup/TermsLookupFetchService.java
deleted file mode 100644
index b787344..0000000
--- a/core/src/main/java/org/elasticsearch/index/search/termslookup/TermsLookupFetchService.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.search.termslookup;
-
-import org.elasticsearch.action.get.GetRequest;
-import org.elasticsearch.action.get.GetResponse;
-import org.elasticsearch.client.Client;
-import org.elasticsearch.common.component.AbstractComponent;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.support.XContentMapValues;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
-import org.elasticsearch.search.internal.SearchContext;
-
-import java.util.ArrayList;
-import java.util.List;
-
-/**
- * Service which retrieves terms from a {@link TermsLookup} specification
- */
-public class TermsLookupFetchService extends AbstractComponent {
-
-    private final Client client;
-
-    @Inject
-    public TermsLookupFetchService(Client client, Settings settings) {
-        super(settings);
-        this.client = client;
-    }
-
-    public List<Object> fetch(TermsLookup termsLookup) {
-        List<Object> terms = new ArrayList<>();
-        GetRequest getRequest = new GetRequest(termsLookup.index(), termsLookup.type(), termsLookup.id())
-                .preference("_local").routing(termsLookup.routing());
-        getRequest.copyContextAndHeadersFrom(SearchContext.current());
-        final GetResponse getResponse = client.get(getRequest).actionGet();
-        if (getResponse.isExists()) {
-            List<Object> extractedValues = XContentMapValues.extractRawValues(termsLookup.path(), getResponse.getSourceAsMap());
-            terms.addAll(extractedValues);
-        }
-        return terms;
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
index e537607..2bc4ae1 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
@@ -66,7 +66,6 @@ import org.elasticsearch.index.deletionpolicy.SnapshotDeletionPolicy;
 import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.engine.*;
 import org.elasticsearch.index.fielddata.FieldDataStats;
-import org.elasticsearch.index.fielddata.IndexFieldDataCache;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
 import org.elasticsearch.index.fielddata.ShardFieldData;
 import org.elasticsearch.index.flush.FlushStats;
@@ -698,7 +697,7 @@ public class IndexShard extends AbstractIndexShardComponent {
 
     }
 
-    public void optimize(OptimizeRequest optimize) {
+    public void optimize(OptimizeRequest optimize) throws IOException {
         verifyStarted();
         if (logger.isTraceEnabled()) {
             logger.trace("optimize with {}", optimize);
@@ -709,7 +708,7 @@ public class IndexShard extends AbstractIndexShardComponent {
     /**
      * Upgrades the shard to the current version of Lucene and returns the minimum segment version
      */
-    public org.apache.lucene.util.Version upgrade(UpgradeRequest upgrade) {
+    public org.apache.lucene.util.Version upgrade(UpgradeRequest upgrade) throws IOException {
         verifyStarted();
         if (logger.isTraceEnabled()) {
             logger.trace("upgrade with {}", upgrade);
diff --git a/core/src/main/java/org/elasticsearch/indices/IndicesModule.java b/core/src/main/java/org/elasticsearch/indices/IndicesModule.java
index e3be629..24e5a32 100644
--- a/core/src/main/java/org/elasticsearch/indices/IndicesModule.java
+++ b/core/src/main/java/org/elasticsearch/indices/IndicesModule.java
@@ -28,6 +28,7 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.util.ExtensionPoint;
 import org.elasticsearch.index.query.*;
 import org.elasticsearch.index.query.functionscore.FunctionScoreQueryParser;
+import org.elasticsearch.index.query.MoreLikeThisQueryParser;
 import org.elasticsearch.indices.analysis.HunspellService;
 import org.elasticsearch.indices.analysis.IndicesAnalysisService;
 import org.elasticsearch.indices.cache.query.IndicesQueryCache;
@@ -114,7 +115,6 @@ public class IndicesModule extends AbstractModule {
         registerQueryParser(NotQueryParser.class);
         registerQueryParser(ExistsQueryParser.class);
         registerQueryParser(MissingQueryParser.class);
-        registerQueryParser(MatchNoneQueryParser.class);
 
         if (ShapesAvailability.JTS_AVAILABLE) {
             registerQueryParser(GeoShapeQueryParser.class);
diff --git a/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java b/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java
index 8da06ea..28ab04b 100644
--- a/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java
+++ b/core/src/main/java/org/elasticsearch/indices/cache/query/terms/TermsLookup.java
@@ -19,162 +19,58 @@
 
 package org.elasticsearch.indices.cache.query.terms;
 
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.QueryValidationException;
-
-import java.io.IOException;
-import java.util.Objects;
+import org.elasticsearch.common.Nullable;
+import org.elasticsearch.index.query.QueryParseContext;
 
 /**
- * Encapsulates the parameters needed to fetch terms.
  */
-public class TermsLookup implements Writeable<TermsLookup>, ToXContent {
-    static final TermsLookup PROTOTYPE = new TermsLookup();
+public class TermsLookup {
 
-    private String index;
-    private String type;
-    private String id;
-    private String path;
-    private String routing;
+    private final String index;
+    private final String type;
+    private final String id;
+    private final String routing;
+    private final String path;
 
-    public TermsLookup() {
-    }
+    @Nullable
+    private final QueryParseContext queryParseContext;
 
-    public TermsLookup(String index, String type, String id, String path) {
+    public TermsLookup(String index, String type, String id, String routing, String path, @Nullable QueryParseContext queryParseContext) {
         this.index = index;
         this.type = type;
         this.id = id;
+        this.routing = routing;
         this.path = path;
+        this.queryParseContext = queryParseContext;
     }
 
-    public String index() {
+    public String getIndex() {
         return index;
     }
 
-    public TermsLookup index(String index) {
-        this.index = index;
-        return this;
-    }
-
-    public String type() {
+    public String getType() {
         return type;
     }
 
-    public TermsLookup type(String type) {
-        this.type = type;
-        return this;
-    }
-
-    public String id() {
+    public String getId() {
         return id;
     }
 
-    public TermsLookup id(String id) {
-        this.id = id;
-        return this;
+    public String getRouting() {
+        return this.routing;
     }
 
-    public String path() {
+    public String getPath() {
         return path;
     }
 
-    public TermsLookup path(String path) {
-        this.path = path;
-        return this;
-    }
-
-    public String routing() {
-        return routing;
-    }
-
-    public TermsLookup routing(String routing) {
-        this.routing = routing;
-        return this;
+    @Nullable
+    public QueryParseContext getQueryParseContext() {
+        return queryParseContext;
     }
 
     @Override
     public String toString() {
         return index + "/" + type + "/" + id + "/" + path;
     }
-
-    @Override
-    public TermsLookup readFrom(StreamInput in) throws IOException {
-        TermsLookup termsLookup = new TermsLookup();
-        termsLookup.index = in.readOptionalString();
-        termsLookup.type = in.readString();
-        termsLookup.id = in.readString();
-        termsLookup.path = in.readString();
-        termsLookup.routing = in.readOptionalString();
-        return termsLookup;
-    }
-
-    public static TermsLookup readTermsLookupFrom(StreamInput in) throws IOException {
-        return PROTOTYPE.readFrom(in);
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeOptionalString(index);
-        out.writeString(type);
-        out.writeString(id);
-        out.writeString(path);
-        out.writeOptionalString(routing);
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        if (index != null) {
-            builder.field("index", index);
-        }
-        builder.field("type", type);
-        builder.field("id", id);
-        builder.field("path", path);
-        if (routing != null) {
-            builder.field("routing", routing);
-        }
-        return builder;
-    }
-
-    @Override
-    public int hashCode() {
-        return Objects.hash(index, type, id, path, routing);
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (this == obj) {
-            return true;
-        }
-        if (obj == null || getClass() != obj.getClass()) {
-            return false;
-        }
-        TermsLookup other = (TermsLookup) obj;
-        return Objects.equals(index, other.index) &&
-                Objects.equals(type, other.type) &&
-                Objects.equals(id, other.id) &&
-                Objects.equals(path, other.path) &&
-                Objects.equals(routing, other.routing);
-    }
-
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (id == null) {
-            validationException = addValidationError("[terms] query lookup element requires specifying the id.", validationException);
-        }
-        if (type == null) {
-            validationException = addValidationError("[terms] query lookup element requires specifying the type.", validationException);
-        }
-        if (path == null) {
-            validationException = addValidationError("[terms] query lookup element requires specifying the path.", validationException);
-        }
-        return validationException;
-    }
-
-    private static QueryValidationException addValidationError(String validationError, QueryValidationException validationException) {
-        return QueryValidationException.addValidationError("terms_lookup", validationError, validationException);
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java b/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
index 2a5d815..7d13fe0 100644
--- a/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
+++ b/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
@@ -21,12 +21,10 @@ package org.elasticsearch.indices.query;
 
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.Maps;
+
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.query.EmptyQueryBuilder;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryParser;
 
 import java.util.Map;
@@ -34,28 +32,24 @@ import java.util.Set;
 
 public class IndicesQueriesRegistry extends AbstractComponent {
 
-    private ImmutableMap<String, QueryParser<?>> queryParsers;
+    private ImmutableMap<String, QueryParser> queryParsers;
 
     @Inject
-    public IndicesQueriesRegistry(Settings settings, Set<QueryParser> injectedQueryParsers, NamedWriteableRegistry namedWriteableRegistry) {
+    public IndicesQueriesRegistry(Settings settings, Set<QueryParser> injectedQueryParsers) {
         super(settings);
-        Map<String, QueryParser<?>> queryParsers = Maps.newHashMap();
-        for (QueryParser<?> queryParser : injectedQueryParsers) {
+        Map<String, QueryParser> queryParsers = Maps.newHashMap();
+        for (QueryParser queryParser : injectedQueryParsers) {
             for (String name : queryParser.names()) {
                 queryParsers.put(name, queryParser);
             }
-            namedWriteableRegistry.registerPrototype(QueryBuilder.class, queryParser.getBuilderPrototype());
         }
-        // EmptyQueryBuilder is not registered as query parser but used internally.
-        // We need to register it with the NamedWriteableRegistry in order to serialize it
-        namedWriteableRegistry.registerPrototype(QueryBuilder.class, EmptyQueryBuilder.PROTOTYPE);
         this.queryParsers = ImmutableMap.copyOf(queryParsers);
     }
 
     /**
      * Returns all the registered query parsers
      */
-    public ImmutableMap<String, QueryParser<?>> queryParsers() {
+    public ImmutableMap<String, QueryParser> queryParsers() {
         return queryParsers;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/node/Node.java b/core/src/main/java/org/elasticsearch/node/Node.java
index 437d6b5..e0532ed 100644
--- a/core/src/main/java/org/elasticsearch/node/Node.java
+++ b/core/src/main/java/org/elasticsearch/node/Node.java
@@ -124,30 +124,28 @@ public class Node implements Releasable {
      * Constructs a node with the given settings.
      *
      * @param preparedSettings Base settings to configure the node with
-     * @param loadConfigSettings true if settings should also be loaded and merged from configuration files
      */
-    public Node(Settings preparedSettings, boolean loadConfigSettings) {
-        this(preparedSettings, loadConfigSettings, Version.CURRENT, Collections.<Class<? extends Plugin>>emptyList());
+    public Node(Settings preparedSettings) {
+        this(preparedSettings, Version.CURRENT, Collections.<Class<? extends Plugin>>emptyList());
     }
 
-    Node(Settings preparedSettings, boolean loadConfigSettings, Version version, Collection<Class<? extends Plugin>> classpathPlugins) {
+    Node(Settings preparedSettings, Version version, Collection<Class<? extends Plugin>> classpathPlugins) {
         final Settings pSettings = settingsBuilder().put(preparedSettings)
                 .put(Client.CLIENT_TYPE_SETTING, CLIENT_TYPE).build();
-        Tuple<Settings, Environment> tuple = InternalSettingsPreparer.prepareSettings(pSettings, loadConfigSettings);
-        tuple = new Tuple<>(TribeService.processSettings(tuple.v1()), tuple.v2());
+        Environment tmpEnv = InternalSettingsPreparer.prepareEnvironment(pSettings, null);
+        Settings tmpSettings = TribeService.processSettings(tmpEnv.settings());
 
-        ESLogger logger = Loggers.getLogger(Node.class, tuple.v1().get("name"));
+        ESLogger logger = Loggers.getLogger(Node.class, tmpSettings.get("name"));
         logger.info("version[{}], pid[{}], build[{}/{}]", version, JvmInfo.jvmInfo().pid(), Build.CURRENT.hashShort(), Build.CURRENT.timestamp());
 
         logger.info("initializing ...");
 
         if (logger.isDebugEnabled()) {
-            Environment env = tuple.v2();
             logger.debug("using config [{}], data [{}], logs [{}], plugins [{}]",
-                    env.configFile(), Arrays.toString(env.dataFiles()), env.logsFile(), env.pluginsFile());
+                tmpEnv.configFile(), Arrays.toString(tmpEnv.dataFiles()), tmpEnv.logsFile(), tmpEnv.pluginsFile());
         }
 
-        this.pluginsService = new PluginsService(tuple.v1(), tuple.v2(), classpathPlugins);
+        this.pluginsService = new PluginsService(tmpSettings, tmpEnv.pluginsFile(), classpathPlugins);
         this.settings = pluginsService.updatedSettings();
         // create the environment based on the finalized (processed) view of the settings
         this.environment = new Environment(this.settings());
@@ -171,17 +169,17 @@ public class Node implements Releasable {
                 modules.add(pluginModule);
             }
             modules.add(new PluginsModule(pluginsService));
-            modules.add(new SettingsModule(settings));
+            modules.add(new SettingsModule(this.settings));
             modules.add(new NodeModule(this));
             modules.add(new NetworkModule());
-            modules.add(new ScriptModule(settings));
+            modules.add(new ScriptModule(this.settings));
             modules.add(new EnvironmentModule(environment));
             modules.add(new NodeEnvironmentModule(nodeEnvironment));
-            modules.add(new ClusterNameModule(settings));
+            modules.add(new ClusterNameModule(this.settings));
             modules.add(new ThreadPoolModule(threadPool));
-            modules.add(new DiscoveryModule(settings));
-            modules.add(new ClusterModule(settings));
-            modules.add(new RestModule(settings));
+            modules.add(new DiscoveryModule(this.settings));
+            modules.add(new ClusterModule(this.settings));
+            modules.add(new RestModule(this.settings));
             modules.add(new TransportModule(settings));
             if (settings.getAsBoolean(HTTP_ENABLED, true)) {
                 modules.add(new HttpServerModule(settings));
@@ -190,7 +188,7 @@ public class Node implements Releasable {
             modules.add(new SearchModule(settings));
             modules.add(new ActionModule(false));
             modules.add(new MonitorModule(settings));
-            modules.add(new GatewayModule());
+            modules.add(new GatewayModule(settings));
             modules.add(new NodeClientModule());
             modules.add(new ShapeModule());
             modules.add(new PercolatorModule());
diff --git a/core/src/main/java/org/elasticsearch/node/NodeBuilder.java b/core/src/main/java/org/elasticsearch/node/NodeBuilder.java
index 9107cf0..257d380 100644
--- a/core/src/main/java/org/elasticsearch/node/NodeBuilder.java
+++ b/core/src/main/java/org/elasticsearch/node/NodeBuilder.java
@@ -26,8 +26,7 @@ import org.elasticsearch.common.settings.Settings;
  * <p/>
  * <p>Settings will be loaded relative to the ES home (with or without <tt>config/</tt> prefix) and if not found,
  * within the classpath (with or without <tt>config/<tt> prefix). The settings file loaded can either be named
- * <tt>elasticsearch.yml</tt> or <tt>elasticsearch.json</tt>). Loading settings can be disabled by calling
- * {@link #loadConfigSettings(boolean)} with <tt>false<tt>.
+ * <tt>elasticsearch.yml</tt> or <tt>elasticsearch.json</tt>).
  * <p/>
  * <p>Explicit settings can be passed by using the {@link #settings(org.elasticsearch.common.settings.Settings)} method.
  * <p/>
@@ -57,8 +56,6 @@ public class NodeBuilder {
 
     private final Settings.Builder settings = Settings.settingsBuilder();
 
-    private boolean loadConfigSettings = true;
-
     /**
      * A convenient factory method to create a {@link NodeBuilder}.
      */
@@ -96,15 +93,6 @@ public class NodeBuilder {
     }
 
     /**
-     * Should the node builder automatically try and load config settings from the file system / classpath. Defaults
-     * to <tt>true</tt>.
-     */
-    public NodeBuilder loadConfigSettings(boolean loadConfigSettings) {
-        this.loadConfigSettings = loadConfigSettings;
-        return this;
-    }
-
-    /**
      * Is the node going to be a client node which means it will hold no data (<tt>node.data</tt> is
      * set to <tt>false</tt>) and other optimizations by different modules.
      *
@@ -154,7 +142,7 @@ public class NodeBuilder {
      * Builds the node without starting it.
      */
     public Node build() {
-        return new Node(settings.build(), loadConfigSettings);
+        return new Node(settings.build());
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java b/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java
index 350ced2..1515617 100644
--- a/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java
+++ b/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java
@@ -21,7 +21,6 @@ package org.elasticsearch.node.internal;
 
 import com.google.common.base.Charsets;
 import com.google.common.collect.Sets;
-import com.google.common.collect.UnmodifiableIterator;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.common.Booleans;
 import org.elasticsearch.common.Strings;
@@ -38,7 +37,6 @@ import java.io.InputStreamReader;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.util.ArrayList;
-import java.util.Arrays;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -52,22 +50,22 @@ import static org.elasticsearch.common.settings.Settings.settingsBuilder;
  */
 public class InternalSettingsPreparer {
 
-    static final List<String> ALLOWED_SUFFIXES = Arrays.asList(".yml", ".yaml", ".json", ".properties");
+    private static final String[] ALLOWED_SUFFIXES = {".yml", ".yaml", ".json", ".properties"};
+    static final String[] PROPERTY_PREFIXES = {"es.", "elasticsearch."};
+    static final String[] PROPERTY_DEFAULTS_PREFIXES = {"es.default.", "elasticsearch.default."};
 
     public static final String SECRET_PROMPT_VALUE = "${prompt.secret}";
     public static final String TEXT_PROMPT_VALUE = "${prompt.text}";
     public static final String IGNORE_SYSTEM_PROPERTIES_SETTING = "config.ignore_system_properties";
 
     /**
-     * Prepares the settings by gathering all elasticsearch system properties, optionally loading the configuration settings,
-     * and then replacing all property placeholders. This method will not work with settings that have <code>${prompt.text}</code>
-     * or <code>${prompt.secret}</code> as their value unless they have been resolved previously.
-     * @param pSettings The initial settings to use
-     * @param loadConfigSettings flag to indicate whether to load settings from the configuration directory/file
-     * @return the {@link Settings} and {@link Environment} as a {@link Tuple}
+     * Prepares the settings by gathering all elasticsearch system properties and setting defaults.
      */
-    public static Tuple<Settings, Environment> prepareSettings(Settings pSettings, boolean loadConfigSettings) {
-        return prepareSettings(pSettings, loadConfigSettings, null);
+    public static Settings prepareSettings(Settings input) {
+        Settings.Builder output = settingsBuilder();
+        initializeSettings(output, input, true);
+        finalizeSettings(output, null, null);
+        return output.build();
     }
 
     /**
@@ -75,126 +73,143 @@ public class InternalSettingsPreparer {
      * and then replacing all property placeholders. If a {@link Terminal} is provided and configuration settings are loaded,
      * settings with a value of <code>${prompt.text}</code> or <code>${prompt.secret}</code> will result in a prompt for
      * the setting to the user.
-     * @param pSettings The initial settings to use
-     * @param loadConfigSettings flag to indicate whether to load settings from the configuration directory/file
+     * @param input The initial settings to use
      * @param terminal the Terminal to use for input/output
      * @return the {@link Settings} and {@link Environment} as a {@link Tuple}
      */
-    public static Tuple<Settings, Environment> prepareSettings(Settings pSettings, boolean loadConfigSettings, Terminal terminal) {
-        // ignore this prefixes when getting properties from es. and elasticsearch.
-        String[] ignorePrefixes = new String[]{"es.default.", "elasticsearch.default."};
-        boolean useSystemProperties = !pSettings.getAsBoolean(IGNORE_SYSTEM_PROPERTIES_SETTING, false);
-        // just create enough settings to build the environment
-        Settings.Builder settingsBuilder = settingsBuilder().put(pSettings);
-        if (useSystemProperties) {
-            settingsBuilder.putProperties("elasticsearch.default.", System.getProperties())
-                    .putProperties("es.default.", System.getProperties())
-                    .putProperties("elasticsearch.", System.getProperties(), ignorePrefixes)
-                    .putProperties("es.", System.getProperties(), ignorePrefixes);
-        }
-        settingsBuilder.replacePropertyPlaceholders();
+    public static Environment prepareEnvironment(Settings input, Terminal terminal) {
+        // just create enough settings to build the environment, to get the config dir
+        Settings.Builder output = settingsBuilder();
+        initializeSettings(output, input, true);
+        Environment environment = new Environment(output.build());
 
-        Environment environment = new Environment(settingsBuilder.build());
-
-        if (loadConfigSettings) {
-            boolean loadFromEnv = true;
-            if (useSystemProperties) {
-                // if its default, then load it, but also load form env
-                if (Strings.hasText(System.getProperty("es.default.config"))) {
-                    loadFromEnv = true;
-                    settingsBuilder.loadFromPath(environment.configFile().resolve(System.getProperty("es.default.config")));
-                }
-                // if explicit, just load it and don't load from env
-                if (Strings.hasText(System.getProperty("es.config"))) {
-                    loadFromEnv = false;
-                    settingsBuilder.loadFromPath(environment.configFile().resolve(System.getProperty("es.config")));
-                }
-                if (Strings.hasText(System.getProperty("elasticsearch.config"))) {
-                    loadFromEnv = false;
-                    settingsBuilder.loadFromPath(environment.configFile().resolve(System.getProperty("elasticsearch.config")));
-                }
+        // TODO: can we simplify all of this and have a single filename, which is looked up in the config dir?
+        boolean loadFromEnv = true;
+        if (useSystemProperties(input)) {
+            // if its default, then load it, but also load form env
+            if (Strings.hasText(System.getProperty("es.default.config"))) {
+                // TODO: we don't allow multiple config files, but having loadFromEnv true here allows just that
+                loadFromEnv = true;
+                output.loadFromPath(environment.configFile().resolve(System.getProperty("es.default.config")));
+            }
+            // TODO: these should be elseifs so that multiple files cannot be loaded
+            // if explicit, just load it and don't load from env
+            if (Strings.hasText(System.getProperty("es.config"))) {
+                loadFromEnv = false;
+                output.loadFromPath(environment.configFile().resolve(System.getProperty("es.config")));
+            }
+            if (Strings.hasText(System.getProperty("elasticsearch.config"))) {
+                loadFromEnv = false;
+                output.loadFromPath(environment.configFile().resolve(System.getProperty("elasticsearch.config")));
             }
-            if (loadFromEnv) {
-                boolean settingsFileFound = false;
-                Set<String> foundSuffixes = Sets.newHashSet();
-                for (String allowedSuffix : ALLOWED_SUFFIXES) {
-                    Path path = environment.configFile().resolve("elasticsearch" + allowedSuffix);
-                    if (Files.exists(path)) {
-                        if (!settingsFileFound) {
-                            settingsBuilder.loadFromPath(path);
-                        }
-                        settingsFileFound = true;
-                        foundSuffixes.add(allowedSuffix);
+        }
+        if (loadFromEnv) {
+            boolean settingsFileFound = false;
+            Set<String> foundSuffixes = Sets.newHashSet();
+            for (String allowedSuffix : ALLOWED_SUFFIXES) {
+                Path path = environment.configFile().resolve("elasticsearch" + allowedSuffix);
+                if (Files.exists(path)) {
+                    if (!settingsFileFound) {
+                        output.loadFromPath(path);
                     }
-                }
-                if (foundSuffixes.size() > 1) {
-                    throw new SettingsException("multiple settings files found with suffixes: " + Strings.collectionToDelimitedString(foundSuffixes, ","));
+                    settingsFileFound = true;
+                    foundSuffixes.add(allowedSuffix);
                 }
             }
+            if (foundSuffixes.size() > 1) {
+                throw new SettingsException("multiple settings files found with suffixes: " + Strings.collectionToDelimitedString(foundSuffixes, ","));
+            }
         }
 
-        settingsBuilder.put(pSettings);
-        if (useSystemProperties) {
-            settingsBuilder.putProperties("elasticsearch.", System.getProperties(), ignorePrefixes)
-                    .putProperties("es.", System.getProperties(), ignorePrefixes);
+        // re-initialize settings now that the config file has been loaded
+        // TODO: only re-initialize if a config file was actually loaded
+        initializeSettings(output, input, false);
+        finalizeSettings(output, terminal, environment.configFile());
+
+        environment = new Environment(output.build());
+
+        // we put back the path.logs so we can use it in the logging configuration file
+        output.put("path.logs", cleanPath(environment.logsFile().toAbsolutePath().toString()));
+
+        return new Environment(output.build());
+    }
+
+    private static boolean useSystemProperties(Settings input) {
+        return !input.getAsBoolean(IGNORE_SYSTEM_PROPERTIES_SETTING, false);
+    }
+
+    /**
+     * Initializes the builder with the given input settings, and loads system properties settings if allowed.
+     * If loadDefaults is true, system property default settings are loaded.
+     */
+    private static void initializeSettings(Settings.Builder output, Settings input, boolean loadDefaults) {
+        output.put(input);
+        if (useSystemProperties(input)) {
+            if (loadDefaults) {
+                for (String prefix : PROPERTY_DEFAULTS_PREFIXES) {
+                    output.putProperties(prefix, System.getProperties());
+                }
+            }
+            for (String prefix : PROPERTY_PREFIXES) {
+                output.putProperties(prefix, System.getProperties(), PROPERTY_DEFAULTS_PREFIXES);
+            }
         }
-        settingsBuilder.replacePropertyPlaceholders();
+        output.replacePropertyPlaceholders();
+    }
 
+    /**
+     * Finish preparing settings by replacing forced settings, prompts, and any defaults that need to be added.
+     * The provided terminal is used to prompt for settings needing to be replaced.
+     * The provided configDir is optional and will be used to lookup names.txt if the node name is not set, if provided.
+     */
+    private static void finalizeSettings(Settings.Builder output, Terminal terminal, Path configDir) {
         // allow to force set properties based on configuration of the settings provided
-        for (Map.Entry<String, String> entry : pSettings.getAsMap().entrySet()) {
-            String setting = entry.getKey();
+        List<String> forcedSettings = new ArrayList<>();
+        for (String setting : output.internalMap().keySet()) {
             if (setting.startsWith("force.")) {
-                settingsBuilder.remove(setting);
-                settingsBuilder.put(setting.substring("force.".length()), entry.getValue());
+                forcedSettings.add(setting);
             }
         }
-        settingsBuilder.replacePropertyPlaceholders();
+        for (String forcedSetting : forcedSettings) {
+            String value = output.remove(forcedSetting);
+            output.put(forcedSetting.substring("force.".length()), value);
+        }
+        output.replacePropertyPlaceholders();
 
         // check if name is set in settings, if not look for system property and set it
-        if (settingsBuilder.get("name") == null) {
+        if (output.get("name") == null) {
             String name = System.getProperty("name");
             if (name != null) {
-                settingsBuilder.put("name", name);
+                output.put("name", name);
             }
         }
 
         // put the cluster name
-        if (settingsBuilder.get(ClusterName.SETTING) == null) {
-            settingsBuilder.put(ClusterName.SETTING, ClusterName.DEFAULT.value());
+        if (output.get(ClusterName.SETTING) == null) {
+            output.put(ClusterName.SETTING, ClusterName.DEFAULT.value());
         }
 
-        String v = settingsBuilder.get(Settings.SETTINGS_REQUIRE_UNITS);
+        String v = output.get(Settings.SETTINGS_REQUIRE_UNITS);
         if (v != null) {
             Settings.setSettingsRequireUnits(Booleans.parseBoolean(v, true));
         }
 
-        Settings settings = replacePromptPlaceholders(settingsBuilder.build(), terminal);
+        replacePromptPlaceholders(output, terminal);
         // all settings placeholders have been resolved. resolve the value for the name setting by checking for name,
         // then looking for node.name, and finally generate one if needed
-        if (settings.get("name") == null) {
-            String name = settings.get("node.name");
+        if (output.get("name") == null) {
+            String name = output.get("node.name");
             if (name == null || name.isEmpty()) {
-                name = randomNodeName(environment);
+                name = randomNodeName(configDir);
             }
-            settings = settingsBuilder().put(settings).put("name", name).build();
+            output.put("name", name);
         }
-
-        environment = new Environment(settings);
-
-        // put back the env settings
-        settingsBuilder = settingsBuilder().put(settings);
-        // we put back the path.logs so we can use it in the logging configuration file
-        settingsBuilder.put("path.logs", cleanPath(environment.logsFile().toAbsolutePath().toString()));
-
-        settings = settingsBuilder.build();
-
-        return new Tuple<>(settings, environment);
     }
 
-    static String randomNodeName(Environment environment) {
+    private static String randomNodeName(Path configDir) {
         InputStream input;
-        Path namesPath = environment.configFile().resolve("names.txt");
-        if (Files.exists(namesPath)) {
+        if (configDir != null && Files.exists(configDir.resolve("names.txt"))) {
+            Path namesPath = configDir.resolve("names.txt");
             try {
                 input = Files.newInputStream(namesPath);
             } catch (IOException e) {
@@ -220,37 +235,40 @@ public class InternalSettingsPreparer {
         }
     }
 
-    static Settings replacePromptPlaceholders(Settings settings, Terminal terminal) {
-        UnmodifiableIterator<Map.Entry<String, String>> iter = settings.getAsMap().entrySet().iterator();
-        Settings.Builder builder = Settings.builder();
-
-        while (iter.hasNext()) {
-            Map.Entry<String, String> entry = iter.next();
-            String value = entry.getValue();
-            String key = entry.getKey();
-            switch (value) {
+    private static void replacePromptPlaceholders(Settings.Builder settings, Terminal terminal) {
+        List<String> secretToPrompt = new ArrayList<>();
+        List<String> textToPrompt = new ArrayList<>();
+        for (Map.Entry<String, String> entry : settings.internalMap().entrySet()) {
+            switch (entry.getValue()) {
                 case SECRET_PROMPT_VALUE:
-                    String secretValue = promptForValue(key, terminal, true);
-                    if (Strings.hasLength(secretValue)) {
-                        builder.put(key, secretValue);
-                    }
+                    secretToPrompt.add(entry.getKey());
                     break;
                 case TEXT_PROMPT_VALUE:
-                    String textValue = promptForValue(key, terminal, false);
-                    if (Strings.hasLength(textValue)) {
-                        builder.put(key, textValue);
-                    }
-                    break;
-                default:
-                    builder.put(key, value);
+                    textToPrompt.add(entry.getKey());
                     break;
             }
         }
-
-        return builder.build();
+        for (String setting : secretToPrompt) {
+            String secretValue = promptForValue(setting, terminal, true);
+            if (Strings.hasLength(secretValue)) {
+                settings.put(setting, secretValue);
+            } else {
+                // TODO: why do we remove settings if prompt returns empty??
+                settings.remove(setting);
+            }
+        }
+        for (String setting : textToPrompt) {
+            String textValue = promptForValue(setting, terminal, false);
+            if (Strings.hasLength(textValue)) {
+                settings.put(setting, textValue);
+            } else {
+                // TODO: why do we remove settings if prompt returns empty??
+                settings.remove(setting);
+            }
+        }
     }
 
-    static String promptForValue(String key, Terminal terminal, boolean secret) {
+    private static String promptForValue(String key, Terminal terminal, boolean secret) {
         if (terminal == null) {
             throw new UnsupportedOperationException("found property [" + key + "] with value [" + (secret ? SECRET_PROMPT_VALUE : TEXT_PROMPT_VALUE) +"]. prompting for property values is only supported when running elasticsearch in the foreground");
         }
diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java
index d4afa22..ee9e6b3 100644
--- a/core/src/main/java/org/elasticsearch/plugins/PluginManager.java
+++ b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java
@@ -321,7 +321,7 @@ public class PluginManager {
         }
 
         // read existing bundles. this does some checks on the installation too.
-        List<Bundle> bundles = PluginsService.getPluginBundles(environment);
+        List<Bundle> bundles = PluginsService.getPluginBundles(environment.pluginsFile());
 
         // if we aren't isolated, we need to jarhellcheck against any other non-isolated plugins
         // thats always the first bundle
diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java b/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java
index 0e17cae..c24b823 100644
--- a/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java
+++ b/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java
@@ -50,8 +50,8 @@ public class PluginManagerCliParser extends CliTool {
             .build();
 
     public static void main(String[] args) {
-        Tuple<Settings, Environment> initialSettings = InternalSettingsPreparer.prepareSettings(EMPTY, true, Terminal.DEFAULT);
-        LogConfigurator.configure(initialSettings.v1());
+        Environment env = InternalSettingsPreparer.prepareEnvironment(EMPTY, Terminal.DEFAULT);
+        LogConfigurator.configure(env.settings());
         int status = new PluginManagerCliParser().execute(args).status();
         System.exit(status);
     }
diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
index 6172122..c70349f 100644
--- a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
+++ b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.plugins;
 
-import com.google.common.collect.ImmutableMap;
-
 import org.apache.lucene.analysis.util.CharFilterFactory;
 import org.apache.lucene.analysis.util.TokenFilterFactory;
 import org.apache.lucene.analysis.util.TokenizerFactory;
@@ -31,7 +29,6 @@ import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.admin.cluster.node.info.PluginsInfo;
 import org.elasticsearch.bootstrap.JarHell;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.component.LifecycleComponent;
@@ -40,7 +37,6 @@ import org.elasticsearch.common.io.FileSystemUtils;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.env.Environment;
 
 import java.io.Closeable;
 import java.io.IOException;
@@ -87,10 +83,10 @@ public class PluginsService extends AbstractComponent {
     /**
      * Constructs a new PluginService
      * @param settings The settings of the system
-     * @param environment The environment of the system
+     * @param pluginsDirectory The directory plugins exist in, or null if plugins should not be loaded from the filesystem
      * @param classpathPlugins Plugins that exist in the classpath which should be loaded
      */
-    public PluginsService(Settings settings, Environment environment, Collection<Class<? extends Plugin>> classpathPlugins) {
+    public PluginsService(Settings settings, Path pluginsDirectory, Collection<Class<? extends Plugin>> classpathPlugins) {
         super(settings);
 
         List<Tuple<PluginInfo, Plugin>> tupleBuilder = new ArrayList<>();
@@ -106,11 +102,13 @@ public class PluginsService extends AbstractComponent {
         }
 
         // now, find all the ones that are in plugins/
-        try {
-          List<Bundle> bundles = getPluginBundles(environment);
-          tupleBuilder.addAll(loadBundles(bundles));
-        } catch (IOException ex) {
-          throw new IllegalStateException("Unable to initialize plugins", ex);
+        if (pluginsDirectory != null) {
+            try {
+                List<Bundle> bundles = getPluginBundles(pluginsDirectory);
+                tupleBuilder.addAll(loadBundles(bundles));
+            } catch (IOException ex) {
+                throw new IllegalStateException("Unable to initialize plugins", ex);
+            }
         }
 
         plugins = Collections.unmodifiableList(tupleBuilder);
@@ -281,10 +279,9 @@ public class PluginsService extends AbstractComponent {
         List<URL> urls = new ArrayList<>();
     }
 
-    static List<Bundle> getPluginBundles(Environment environment) throws IOException {
+    static List<Bundle> getPluginBundles(Path pluginsDirectory) throws IOException {
         ESLogger logger = Loggers.getLogger(PluginsService.class);
 
-        Path pluginsDirectory = environment.pluginsFile();
         // TODO: remove this leniency, but tests bogusly rely on it
         if (!isAccessibleDirectory(pluginsDirectory, logger)) {
             return Collections.emptyList();
diff --git a/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java b/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java
index 7c01fdd..ce306c6 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/explain/RestExplainAction.java
@@ -30,7 +30,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentBuilderString;
 import org.elasticsearch.index.get.GetResult;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.QueryStringQueryBuilder;
 import org.elasticsearch.rest.*;
@@ -75,7 +74,13 @@ public class RestExplainAction extends BaseRestHandler {
             queryStringBuilder.lenient(request.paramAsBoolean("lenient", null));
             String defaultOperator = request.param("default_operator");
             if (defaultOperator != null) {
-                queryStringBuilder.defaultOperator(Operator.fromString(defaultOperator));
+                if ("OR".equals(defaultOperator)) {
+                    queryStringBuilder.defaultOperator(QueryStringQueryBuilder.Operator.OR);
+                } else if ("AND".equals(defaultOperator)) {
+                    queryStringBuilder.defaultOperator(QueryStringQueryBuilder.Operator.AND);
+                } else {
+                    throw new IllegalArgumentException("Unsupported defaultOperator [" + defaultOperator + "], can either be [OR] or [AND]");
+                }
             }
 
             QuerySourceBuilder querySourceBuilder = new QuerySourceBuilder();
diff --git a/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java b/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
index 674aa69..bd17c1d 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
@@ -27,7 +27,6 @@ import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.lucene.uid.Versions;
 import org.elasticsearch.common.xcontent.*;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.QueryStringQueryBuilder;
 import org.elasticsearch.rest.RestRequest;
@@ -98,7 +97,13 @@ public class RestActions {
         queryBuilder.lenient(request.paramAsBoolean("lenient", null));
         String defaultOperator = request.param("default_operator");
         if (defaultOperator != null) {
-            queryBuilder.defaultOperator(Operator.fromString(defaultOperator));
+            if ("OR".equals(defaultOperator)) {
+                queryBuilder.defaultOperator(QueryStringQueryBuilder.Operator.OR);
+            } else if ("AND".equals(defaultOperator)) {
+                queryBuilder.defaultOperator(QueryStringQueryBuilder.Operator.AND);
+            } else {
+                throw new IllegalArgumentException("Unsupported defaultOperator [" + defaultOperator + "], can either be [OR] or [AND]");
+            }
         }
         return new QuerySourceBuilder().setQuery(queryBuilder);
     }
diff --git a/core/src/main/java/org/elasticsearch/search/SearchService.java b/core/src/main/java/org/elasticsearch/search/SearchService.java
index ea1eb71..59ec671 100644
--- a/core/src/main/java/org/elasticsearch/search/SearchService.java
+++ b/core/src/main/java/org/elasticsearch/search/SearchService.java
@@ -62,6 +62,7 @@ import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.MappedFieldType.Loading;
 import org.elasticsearch.index.mapper.MapperService;
+import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
 import org.elasticsearch.index.query.TemplateQueryParser;
 import org.elasticsearch.index.search.stats.ShardSearchStats;
 import org.elasticsearch.index.search.stats.StatsGroupsParseElement;
@@ -910,7 +911,22 @@ public class SearchService extends AbstractLifecycleComponent<SearchService> {
             final Map<String, MappedFieldType> warmUp = new HashMap<>();
             for (DocumentMapper docMapper : mapperService.docMappers(false)) {
                 for (FieldMapper fieldMapper : docMapper.mappers()) {
-                    final FieldDataType fieldDataType = fieldMapper.fieldType().fieldDataType();
+                    final FieldDataType fieldDataType;
+                    final String indexName;
+                    if (fieldMapper instanceof ParentFieldMapper) {
+                        MappedFieldType joinFieldType = ((ParentFieldMapper) fieldMapper).getChildJoinFieldType();
+                        if (joinFieldType == null) {
+                            continue;
+                        }
+                        fieldDataType = joinFieldType.fieldDataType();
+                        // TODO: this can be removed in 3.0 when the old parent/child impl is removed:
+                        // related to: https://github.com/elastic/elasticsearch/pull/12418
+                        indexName = fieldMapper.fieldType().names().indexName();
+                    } else {
+                        fieldDataType = fieldMapper.fieldType().fieldDataType();
+                        indexName = fieldMapper.fieldType().names().indexName();
+                    }
+
                     if (fieldDataType == null) {
                         continue;
                     }
@@ -918,7 +934,6 @@ public class SearchService extends AbstractLifecycleComponent<SearchService> {
                         continue;
                     }
 
-                    final String indexName = fieldMapper.fieldType().names().indexName();
                     if (warmUp.containsKey(indexName)) {
                         continue;
                     }
@@ -964,14 +979,27 @@ public class SearchService extends AbstractLifecycleComponent<SearchService> {
             final Map<String, MappedFieldType> warmUpGlobalOrdinals = new HashMap<>();
             for (DocumentMapper docMapper : mapperService.docMappers(false)) {
                 for (FieldMapper fieldMapper : docMapper.mappers()) {
-                    final FieldDataType fieldDataType = fieldMapper.fieldType().fieldDataType();
+                    final FieldDataType fieldDataType;
+                    final String indexName;
+                    if (fieldMapper instanceof ParentFieldMapper) {
+                        MappedFieldType joinFieldType = ((ParentFieldMapper) fieldMapper).getChildJoinFieldType();
+                        if (joinFieldType == null) {
+                            continue;
+                        }
+                        fieldDataType = joinFieldType.fieldDataType();
+                        // TODO: this can be removed in 3.0 when the old parent/child impl is removed:
+                        // related to: https://github.com/elastic/elasticsearch/pull/12418
+                        indexName = fieldMapper.fieldType().names().indexName();
+                    } else {
+                        fieldDataType = fieldMapper.fieldType().fieldDataType();
+                        indexName = fieldMapper.fieldType().names().indexName();
+                    }
                     if (fieldDataType == null) {
                         continue;
                     }
                     if (fieldDataType.getLoading() != Loading.EAGER_GLOBAL_ORDINALS) {
                         continue;
                     }
-                    final String indexName = fieldMapper.fieldType().names().indexName();
                     if (warmUpGlobalOrdinals.containsKey(indexName)) {
                         continue;
                     }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/children/ParentToChildrenAggregator.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/children/ParentToChildrenAggregator.java
index ba776e3..dc98416 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/children/ParentToChildrenAggregator.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/children/ParentToChildrenAggregator.java
@@ -20,16 +20,12 @@ package org.elasticsearch.search.aggregations.bucket.children;
 
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.*;
 import org.apache.lucene.util.Bits;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.util.LongArray;
 import org.elasticsearch.common.util.LongObjectPagedHashMap;
-import org.elasticsearch.index.search.child.ConstantScorer;
 import org.elasticsearch.search.aggregations.Aggregator;
 import org.elasticsearch.search.aggregations.AggregatorFactories;
 import org.elasticsearch.search.aggregations.InternalAggregation;
@@ -155,7 +151,7 @@ public class ParentToChildrenAggregator extends SingleBucketAggregator {
             final SortedDocValues globalOrdinals = valuesSource.globalOrdinalsValues(parentType, ctx);
 
             // Set the scorer, since we now replay only the child docIds
-            sub.setScorer(ConstantScorer.create(childDocsIter, null, 1f));
+            sub.setScorer(new ConstantScoreScorer(null, 1f,childDocsIter));
 
             final Bits liveDocs = ctx.reader().getLiveDocs();
             for (int docId = childDocsIter.nextDoc(); docId != DocIdSetIterator.NO_MORE_DOCS; docId = childDocsIter.nextDoc()) {
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java
index 99ee7c7..00d12a8 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/GND.java
@@ -28,7 +28,7 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
@@ -117,7 +117,7 @@ public class GND extends NXYSignificanceHeuristic {
 
         @Override
         public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                throws IOException, QueryShardException {
+                throws IOException, QueryParsingException {
             String givenName = parser.currentName();
             boolean backgroundIsSuperset = true;
             XContentParser.Token token = parser.nextToken();
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java
index 97264e7..d5bfc5c 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/JLHScore.java
@@ -27,7 +27,7 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
@@ -110,7 +110,7 @@ public class JLHScore extends SignificanceHeuristic {
 
         @Override
         public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                throws IOException, QueryShardException {
+                throws IOException, QueryParsingException {
             // move to the closing bracket
             if (!parser.nextToken().equals(XContentParser.Token.END_OBJECT)) {
                 throw new ElasticsearchParseException("failed to parse [jhl] significance heuristic. expected an empty object, but found [{}] instead", parser.currentToken());
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java
index c6a6924..4d86661 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/NXYSignificanceHeuristic.java
@@ -27,7 +27,7 @@ import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
@@ -140,7 +140,7 @@ public abstract class NXYSignificanceHeuristic extends SignificanceHeuristic {
 
         @Override
         public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                throws IOException, QueryShardException {
+                throws IOException, QueryParsingException {
             String givenName = parser.currentName();
             boolean includeNegatives = false;
             boolean backgroundIsSuperset = true;
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java
index aceae8c..d613ef2 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/PercentageScore.java
@@ -27,7 +27,7 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
@@ -79,7 +79,7 @@ public class PercentageScore extends SignificanceHeuristic {
 
         @Override
         public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                throws IOException, QueryShardException {
+                throws IOException, QueryParsingException {
             // move to the closing bracket
             if (!parser.nextToken().equals(XContentParser.Token.END_OBJECT)) {
                 throw new ElasticsearchParseException("failed to parse [percentage] significance heuristic. expected an empty object, but got [{}] instead", parser.currentToken());
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
index d117969..c20399e 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/heuristics/ScriptHeuristic.java
@@ -29,10 +29,14 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.logging.ESLoggerFactory;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardException;
-import org.elasticsearch.script.*;
+import org.elasticsearch.index.query.QueryParsingException;
+import org.elasticsearch.script.ExecutableScript;
+import org.elasticsearch.script.Script;
 import org.elasticsearch.script.Script.ScriptField;
+import org.elasticsearch.script.ScriptContext;
+import org.elasticsearch.script.ScriptParameterParser;
 import org.elasticsearch.script.ScriptParameterParser.ScriptParameterValue;
+import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.search.aggregations.InternalAggregation;
 import org.elasticsearch.search.internal.SearchContext;
 
@@ -131,7 +135,7 @@ public class ScriptHeuristic extends SignificanceHeuristic {
 
         @Override
         public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                throws IOException, QueryShardException {
+                throws IOException, QueryParsingException {
             String heuristicName = parser.currentName();
             Script script = null;
             XContentParser.Token token;
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java
index a14fdfe..125f635 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java
@@ -19,15 +19,10 @@
 
 package org.elasticsearch.search.fetch.innerhits;
 
-import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
-import org.elasticsearch.search.highlight.HighlightBuilder;
-import org.elasticsearch.search.sort.SortBuilder;
-import org.elasticsearch.search.sort.SortOrder;
+import org.elasticsearch.index.query.support.BaseInnerHitBuilder;
 
 import java.io.IOException;
 import java.util.HashMap;
@@ -37,12 +32,12 @@ import java.util.Map;
  */
 public class InnerHitsBuilder implements ToXContent {
 
-    private final Map<String, InnerHitsHolder> innerHits = new HashMap<>();
+    private Map<String, InnerHit> innerHits = new HashMap<>();
 
     @Override
     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject("inner_hits");
-        for (Map.Entry<String, InnerHitsHolder> entry : innerHits.entrySet()) {
+        for (Map.Entry<String, InnerHit> entry : innerHits.entrySet()) {
             builder.startObject(entry.getKey());
             entry.getValue().toXContent(builder, params);
             builder.endObject();
@@ -50,425 +45,36 @@ public class InnerHitsBuilder implements ToXContent {
         return builder.endObject();
     }
 
-    /**
-     * For nested inner hits the path to collect child nested docs for.
-     * @param name the name / key of the inner hits in the response
-     * @param path the path into the nested to collect inner hits for
-     * @param innerHit the inner hits definition
-     */
-    public void addNestedInnerHits(String name, String path, InnerHit innerHit) {
-        if (innerHits.containsKey(name)) {
-            throw new IllegalArgumentException("inner hits for name: [" + name +"] is already registered");
-        }
-        innerHits.put(name, new NestedInnerHitsHolder(path, innerHit));
-    }
-
-    /**
-     * For parent/child inner hits the type to collect inner hits for.
-     * @param name the name / key of the inner hits in the response
-     * @param type the document type to collect inner hits for
-     * @param innerHit the inner hits definition
-     */
-    public void addParentChildInnerHits(String name, String type, InnerHit innerHit) {
-        innerHits.put(name, new ParentChildInnerHitsHolder(type, innerHit));
-    }
-
-    private static class InnerHitsHolder implements ToXContent{
-        private final InnerHit hits;
-
-        private InnerHitsHolder(InnerHit hits) {
-            this.hits = hits;
-        }
-
-        @Override
-        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-            return hits.toXContent(builder, params);
-        }
-    }
-
-    private static class ParentChildInnerHitsHolder extends InnerHitsHolder {
-
-        private final String type;
-
-        private ParentChildInnerHitsHolder(String type, InnerHit hits) {
-            super(hits);
-            this.type = type;
-        }
-
-        @Override
-        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-            builder.startObject("type").startObject(type);
-            super.toXContent(builder, params);
-            return builder.endObject().endObject();
-        }
-    }
-
-    private static class NestedInnerHitsHolder extends InnerHitsHolder {
-
-        private final String path;
-
-        private NestedInnerHitsHolder(String path, InnerHit hits) {
-            super(hits);
-            this.path = path;
-        }
-
-        @Override
-        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-            builder.startObject("path").startObject(path);
-            super.toXContent(builder, params);
-            return builder.endObject().endObject();
-        }
+    public void addInnerHit(String name, InnerHit innerHit) {
+        innerHits.put(name, innerHit);
     }
 
-    public static class InnerHit implements ToXContent {
+    public static class InnerHit extends BaseInnerHitBuilder<InnerHit> {
 
-        private SearchSourceBuilder sourceBuilder;
         private String path;
         private String type;
 
         /**
-         * The index to start to return hits from. Defaults to <tt>0</tt>.
-         */
-        public InnerHit setFrom(int from) {
-            sourceBuilder().from(from);
-            return this;
-        }
-
-        /**
-         * The number of search hits to return. Defaults to <tt>10</tt>.
-         */
-        public InnerHit setSize(int size) {
-            sourceBuilder().size(size);
-            return this;
-        }
-
-        /**
-         * Applies when sorting, and controls if scores will be tracked as well. Defaults to
-         * <tt>false</tt>.
-         */
-        public InnerHit setTrackScores(boolean trackScores) {
-            sourceBuilder().trackScores(trackScores);
-            return this;
-        }
-
-        /**
-         * Should each {@link org.elasticsearch.search.SearchHit} be returned with an
-         * explanation of the hit (ranking).
-         */
-        public InnerHit setExplain(boolean explain) {
-            sourceBuilder().explain(explain);
-            return this;
-        }
-
-        /**
-         * Should each {@link org.elasticsearch.search.SearchHit} be returned with its
-         * version.
-         */
-        public InnerHit setVersion(boolean version) {
-            sourceBuilder().version(version);
-            return this;
-        }
-
-        /**
-         * Add a stored field to be loaded and returned with the inner hit.
-         */
-        public InnerHit field(String name) {
-            sourceBuilder().field(name);
-            return this;
-        }
-
-        /**
-         * Sets no fields to be loaded, resulting in only id and type to be returned per field.
-         */
-        public InnerHit setNoFields() {
-            sourceBuilder().noFields();
-            return this;
-        }
-
-        /**
-         * Indicates whether the response should contain the stored _source for every hit
-         */
-        public InnerHit setFetchSource(boolean fetch) {
-            sourceBuilder().fetchSource(fetch);
-            return this;
-        }
-
-        /**
-         * Indicate that _source should be returned with every hit, with an "include" and/or "exclude" set which can include simple wildcard
-         * elements.
-         *
-         * @param include An optional include (optionally wildcarded) pattern to filter the returned _source
-         * @param exclude An optional exclude (optionally wildcarded) pattern to filter the returned _source
-         */
-        public InnerHit setFetchSource(@Nullable String include, @Nullable String exclude) {
-            sourceBuilder().fetchSource(include, exclude);
-            return this;
-        }
-
-        /**
-         * Indicate that _source should be returned with every hit, with an "include" and/or "exclude" set which can include simple wildcard
-         * elements.
-         *
-         * @param includes An optional list of include (optionally wildcarded) pattern to filter the returned _source
-         * @param excludes An optional list of exclude (optionally wildcarded) pattern to filter the returned _source
-         */
-        public InnerHit setFetchSource(@Nullable String[] includes, @Nullable String[] excludes) {
-            sourceBuilder().fetchSource(includes, excludes);
-            return this;
-        }
-
-        /**
-         * Adds a field data based field to load and return. The field does not have to be stored,
-         * but its recommended to use non analyzed or numeric fields.
-         *
-         * @param name The field to get from the field data cache
-         */
-        public InnerHit addFieldDataField(String name) {
-            sourceBuilder().fieldDataField(name);
-            return this;
-        }
-
-        /**
-         * Adds a script based field to load and return. The field does not have to be stored,
-         * but its recommended to use non analyzed or numeric fields.
-         *
-         * @param name   The name that will represent this value in the return hit
-         * @param script The script to use
-         */
-        public InnerHit addScriptField(String name, Script script) {
-            sourceBuilder().scriptField(name, script);
-            return this;
-        }
-
-        /**
-         * Adds a sort against the given field name and the sort ordering.
-         *
-         * @param field The name of the field
-         * @param order The sort ordering
-         */
-        public InnerHit addSort(String field, SortOrder order) {
-            sourceBuilder().sort(field, order);
-            return this;
-        }
-
-        /**
-         * Adds a generic sort builder.
-         *
-         * @see org.elasticsearch.search.sort.SortBuilders
-         */
-        public InnerHit addSort(SortBuilder sort) {
-            sourceBuilder().sort(sort);
-            return this;
-        }
-
-        public HighlightBuilder highlightBuilder() {
-            return sourceBuilder().highlighter();
-        }
-
-        /**
-         * Adds a field to be highlighted with default fragment size of 100 characters, and
-         * default number of fragments of 5.
-         *
-         * @param name The field to highlight
-         */
-        public InnerHit addHighlightedField(String name) {
-            highlightBuilder().field(name);
-            return this;
-        }
-
-
-        /**
-         * Adds a field to be highlighted with a provided fragment size (in characters), and
-         * default number of fragments of 5.
-         *
-         * @param name         The field to highlight
-         * @param fragmentSize The size of a fragment in characters
-         */
-        public InnerHit addHighlightedField(String name, int fragmentSize) {
-            highlightBuilder().field(name, fragmentSize);
-            return this;
-        }
-
-        /**
-         * Adds a field to be highlighted with a provided fragment size (in characters), and
-         * a provided (maximum) number of fragments.
-         *
-         * @param name              The field to highlight
-         * @param fragmentSize      The size of a fragment in characters
-         * @param numberOfFragments The (maximum) number of fragments
-         */
-        public InnerHit addHighlightedField(String name, int fragmentSize, int numberOfFragments) {
-            highlightBuilder().field(name, fragmentSize, numberOfFragments);
-            return this;
-        }
-
-        /**
-         * Adds a field to be highlighted with a provided fragment size (in characters),
-         * a provided (maximum) number of fragments and an offset for the highlight.
-         *
-         * @param name              The field to highlight
-         * @param fragmentSize      The size of a fragment in characters
-         * @param numberOfFragments The (maximum) number of fragments
-         */
-        public InnerHit addHighlightedField(String name, int fragmentSize, int numberOfFragments,
-                                            int fragmentOffset) {
-            highlightBuilder().field(name, fragmentSize, numberOfFragments, fragmentOffset);
-            return this;
-        }
-
-        /**
-         * Adds a highlighted field.
-         */
-        public InnerHit addHighlightedField(HighlightBuilder.Field field) {
-            highlightBuilder().field(field);
-            return this;
-        }
-
-        /**
-         * Set a tag scheme that encapsulates a built in pre and post tags. The allows schemes
-         * are <tt>styled</tt> and <tt>default</tt>.
-         *
-         * @param schemaName The tag scheme name
-         */
-        public InnerHit setHighlighterTagsSchema(String schemaName) {
-            highlightBuilder().tagsSchema(schemaName);
-            return this;
-        }
-
-        public InnerHit setHighlighterFragmentSize(Integer fragmentSize) {
-            highlightBuilder().fragmentSize(fragmentSize);
-            return this;
-        }
-
-        public InnerHit setHighlighterNumOfFragments(Integer numOfFragments) {
-            highlightBuilder().numOfFragments(numOfFragments);
-            return this;
-        }
-
-        public InnerHit setHighlighterFilter(Boolean highlightFilter) {
-            highlightBuilder().highlightFilter(highlightFilter);
-            return this;
-        }
-
-        /**
-         * The encoder to set for highlighting
-         */
-        public InnerHit setHighlighterEncoder(String encoder) {
-            highlightBuilder().encoder(encoder);
-            return this;
-        }
-
-        /**
-         * Explicitly set the pre tags that will be used for highlighting.
-         */
-        public InnerHit setHighlighterPreTags(String... preTags) {
-            highlightBuilder().preTags(preTags);
-            return this;
-        }
-
-        /**
-         * Explicitly set the post tags that will be used for highlighting.
-         */
-        public InnerHit setHighlighterPostTags(String... postTags) {
-            highlightBuilder().postTags(postTags);
-            return this;
-        }
-
-        /**
-         * The order of fragments per field. By default, ordered by the order in the
-         * highlighted text. Can be <tt>score</tt>, which then it will be ordered
-         * by score of the fragments.
-         */
-        public InnerHit setHighlighterOrder(String order) {
-            highlightBuilder().order(order);
-            return this;
-        }
-
-        public InnerHit setHighlighterRequireFieldMatch(boolean requireFieldMatch) {
-            highlightBuilder().requireFieldMatch(requireFieldMatch);
-            return this;
-        }
-
-        public InnerHit setHighlighterBoundaryMaxScan(Integer boundaryMaxScan) {
-            highlightBuilder().boundaryMaxScan(boundaryMaxScan);
-            return this;
-        }
-
-        public InnerHit setHighlighterBoundaryChars(char[] boundaryChars) {
-            highlightBuilder().boundaryChars(boundaryChars);
-            return this;
-        }
-
-        /**
-         * The highlighter type to use.
-         */
-        public InnerHit setHighlighterType(String type) {
-            highlightBuilder().highlighterType(type);
-            return this;
-        }
-
-        public InnerHit setHighlighterFragmenter(String fragmenter) {
-            highlightBuilder().fragmenter(fragmenter);
-            return this;
-        }
-
-        /**
-         * Sets a query to be used for highlighting all fields instead of the search query.
-         */
-        public InnerHit setHighlighterQuery(QueryBuilder highlightQuery) {
-            highlightBuilder().highlightQuery(highlightQuery);
-            return this;
-        }
-
-        /**
-         * Sets the size of the fragment to return from the beginning of the field if there are no matches to
-         * highlight and the field doesn't also define noMatchSize.
-         *
-         * @param noMatchSize integer to set or null to leave out of request.  default is null.
-         * @return this builder for chaining
+         * Sets the query to run for collecting the inner hits.
          */
-        public InnerHit setHighlighterNoMatchSize(Integer noMatchSize) {
-            highlightBuilder().noMatchSize(noMatchSize);
+        public InnerHit setQuery(QueryBuilder query) {
+            sourceBuilder().query(query);
             return this;
         }
 
         /**
-         * Sets the maximum number of phrases the fvh will consider if the field doesn't also define phraseLimit.
+         * For parent/child inner hits the type to collect inner hits for.
          */
-        public InnerHit setHighlighterPhraseLimit(Integer phraseLimit) {
-            highlightBuilder().phraseLimit(phraseLimit);
-            return this;
-        }
-
-        public InnerHit setHighlighterOptions(Map<String, Object> options) {
-            highlightBuilder().options(options);
-            return this;
-        }
-
-        protected SearchSourceBuilder sourceBuilder() {
-            if (sourceBuilder == null) {
-                sourceBuilder = new SearchSourceBuilder();
-            }
-            return sourceBuilder;
-        }
-
-        /**
-         * Sets the query to run for collecting the inner hits.
-         */
-        public InnerHit setQuery(QueryBuilder query) {
-            sourceBuilder().query(query);
+        public InnerHit setPath(String path) {
+            this.path = path;
             return this;
         }
 
-
-
-
         /**
-         * Adds a nested inner hit definition that collects inner hits for hits
-         * on this inner hit level.
+         * For nested inner hits the path to collect child nested docs for.
          */
-        public InnerHit addNestedInnerHits(String name, String path, InnerHit innerHit) {
-            sourceBuilder().innerHitsBuilder().addNestedInnerHits(name, path, innerHit);
+        public InnerHit setType(String type) {
+            this.type = type;
             return this;
         }
 
@@ -476,17 +82,21 @@ public class InnerHitsBuilder implements ToXContent {
          * Adds a nested inner hit definition that collects inner hits for hits
          * on this inner hit level.
          */
-        public InnerHit addParentChildInnerHits(String name, String type, InnerHit innerHit) {
-            sourceBuilder().innerHitsBuilder().addParentChildInnerHits(name, type, innerHit);
+        public InnerHit addInnerHit(String name, InnerHit innerHit) {
+            sourceBuilder().innerHitsBuilder().addInnerHit(name, innerHit);
             return this;
         }
 
         @Override
         public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-            if (sourceBuilder != null) {
-                sourceBuilder.innerToXContent(builder, params);
+            if (path != null) {
+                builder.startObject("path").startObject(path);
+            } else {
+                builder.startObject("type").startObject(type);
             }
-            return builder;
+            super.toXContent(builder, params);
+            return builder.endObject().endObject();
         }
     }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsContext.java b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsContext.java
index a0df638..2887a83 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsContext.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsContext.java
@@ -123,7 +123,7 @@ public final class InnerHitsContext {
             if (size() == 0) {
                 return new TopDocs(context.searcher().count(q), Lucene.EMPTY_SCORE_DOCS, 0);
             } else {
-                int topN = from() + size();
+                int topN = Math.min(from() + size(), context.searcher().getIndexReader().maxDoc());
                 TopDocsCollector topDocsCollector;
                 if (sort() != null) {
                     try {
@@ -303,7 +303,7 @@ public final class InnerHitsContext {
                 final int count = context.searcher().count(q);
                 return new TopDocs(count, Lucene.EMPTY_SCORE_DOCS, 0);
             } else {
-                int topN = from() + size();
+                int topN = Math.min(from() + size(), context.searcher().getIndexReader().maxDoc());
                 TopDocsCollector topDocsCollector;
                 if (sort() != null) {
                     topDocsCollector = TopFieldCollector.create(sort(), topN, true, trackScores(), trackScores());
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java
index ac6dc18..c02e2c6 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsParseElement.java
@@ -24,7 +24,7 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.mapper.DocumentMapper;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
 import org.elasticsearch.index.query.ParsedQuery;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.search.SearchParseElement;
 import org.elasticsearch.search.fetch.fielddata.FieldDataFieldsParseElement;
 import org.elasticsearch.search.fetch.script.ScriptFieldsParseElement;
@@ -59,15 +59,15 @@ public class InnerHitsParseElement implements SearchParseElement {
 
     @Override
     public void parse(XContentParser parser, SearchContext searchContext) throws Exception {
-        QueryShardContext context = searchContext.queryParserService().getShardContext();
-        context.reset(parser);
-        Map<String, InnerHitsContext.BaseInnerHits> innerHitsMap = parseInnerHits(parser, context, searchContext);
+        QueryParseContext parseContext = searchContext.queryParserService().getParseContext();
+        parseContext.reset(parser);
+        Map<String, InnerHitsContext.BaseInnerHits> innerHitsMap = parseInnerHits(parser, parseContext, searchContext);
         if (innerHitsMap != null) {
             searchContext.innerHits(new InnerHitsContext(innerHitsMap));
         }
     }
 
-    private Map<String, InnerHitsContext.BaseInnerHits> parseInnerHits(XContentParser parser, QueryShardContext context, SearchContext searchContext) throws Exception {
+    private Map<String, InnerHitsContext.BaseInnerHits> parseInnerHits(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext) throws Exception {
         XContentParser.Token token;
         Map<String, InnerHitsContext.BaseInnerHits> innerHitsMap = null;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -79,7 +79,7 @@ public class InnerHitsParseElement implements SearchParseElement {
             if (token != XContentParser.Token.START_OBJECT) {
                 throw new IllegalArgumentException("Inner hit definition for [" + innerHitName + " starts with a [" + token + "], expected a [" + XContentParser.Token.START_OBJECT + "].");
             }
-            InnerHitsContext.BaseInnerHits innerHits = parseInnerHit(parser, context, searchContext, innerHitName);
+            InnerHitsContext.BaseInnerHits innerHits = parseInnerHit(parser, parseContext, searchContext, innerHitName);
             if (innerHitsMap == null) {
                 innerHitsMap = new HashMap<>();
             }
@@ -88,7 +88,7 @@ public class InnerHitsParseElement implements SearchParseElement {
         return innerHitsMap;
     }
 
-    private InnerHitsContext.BaseInnerHits parseInnerHit(XContentParser parser, QueryShardContext context, SearchContext searchContext, String innerHitName) throws Exception {
+    private InnerHitsContext.BaseInnerHits parseInnerHit(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext, String innerHitName) throws Exception {
         XContentParser.Token token = parser.nextToken();
         if (token != XContentParser.Token.FIELD_NAME) {
             throw new IllegalArgumentException("Unexpected token " + token + " inside inner hit definition. Either specify [path] or [type] object");
@@ -123,9 +123,9 @@ public class InnerHitsParseElement implements SearchParseElement {
 
         final InnerHitsContext.BaseInnerHits innerHits;
         if (nestedPath != null) {
-            innerHits = parseNested(parser, context, searchContext, fieldName);
+            innerHits = parseNested(parser, parseContext, searchContext, fieldName);
         } else if (type != null) {
-            innerHits = parseParentChild(parser, context, searchContext, fieldName);
+            innerHits = parseParentChild(parser, parseContext, searchContext, fieldName);
         } else {
             throw new IllegalArgumentException("Either [path] or [type] must be defined");
         }
@@ -143,16 +143,16 @@ public class InnerHitsParseElement implements SearchParseElement {
         return innerHits;
     }
 
-    private InnerHitsContext.ParentChildInnerHits parseParentChild(XContentParser parser, QueryShardContext context, SearchContext searchContext, String type) throws Exception {
-        ParseResult parseResult = parseSubSearchContext(searchContext, context, parser);
+    private InnerHitsContext.ParentChildInnerHits parseParentChild(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext, String type) throws Exception {
+        ParseResult parseResult = parseSubSearchContext(searchContext, parseContext, parser);
         DocumentMapper documentMapper = searchContext.mapperService().documentMapper(type);
         if (documentMapper == null) {
             throw new IllegalArgumentException("type [" + type + "] doesn't exist");
         }
-        return new InnerHitsContext.ParentChildInnerHits(parseResult.context(), parseResult.query(), parseResult.childInnerHits(), context.mapperService(), documentMapper);
+        return new InnerHitsContext.ParentChildInnerHits(parseResult.context(), parseResult.query(), parseResult.childInnerHits(), parseContext.mapperService(), documentMapper);
     }
 
-    private InnerHitsContext.NestedInnerHits parseNested(XContentParser parser, QueryShardContext context, SearchContext searchContext, String nestedPath) throws Exception {
+    private InnerHitsContext.NestedInnerHits parseNested(XContentParser parser, QueryParseContext parseContext, SearchContext searchContext, String nestedPath) throws Exception {
         ObjectMapper objectMapper = searchContext.getObjectMapper(nestedPath);
         if (objectMapper == null) {
             throw new IllegalArgumentException("path [" + nestedPath +"] doesn't exist");
@@ -160,14 +160,14 @@ public class InnerHitsParseElement implements SearchParseElement {
         if (objectMapper.nested().isNested() == false) {
             throw new IllegalArgumentException("path [" + nestedPath +"] isn't nested");
         }
-        ObjectMapper parentObjectMapper = context.nestedScope().nextLevel(objectMapper);
-        ParseResult parseResult = parseSubSearchContext(searchContext, context, parser);
-        context.nestedScope().previousLevel();
+        ObjectMapper parentObjectMapper = parseContext.nestedScope().nextLevel(objectMapper);
+        ParseResult parseResult = parseSubSearchContext(searchContext, parseContext, parser);
+        parseContext.nestedScope().previousLevel();
 
         return new InnerHitsContext.NestedInnerHits(parseResult.context(), parseResult.query(), parseResult.childInnerHits(), parentObjectMapper, objectMapper);
     }
 
-    private ParseResult parseSubSearchContext(SearchContext searchContext, QueryShardContext context, XContentParser parser) throws Exception {
+    private ParseResult parseSubSearchContext(SearchContext searchContext, QueryParseContext parseContext, XContentParser parser) throws Exception {
         ParsedQuery query = null;
         Map<String, InnerHitsContext.BaseInnerHits> childInnerHits = null;
         SubSearchContext subSearchContext = new SubSearchContext(searchContext);
@@ -178,10 +178,10 @@ public class InnerHitsParseElement implements SearchParseElement {
                 fieldName = parser.currentName();
             } else if (token == XContentParser.Token.START_OBJECT) {
                 if ("query".equals(fieldName)) {
-                    Query q = searchContext.queryParserService().parseInnerQuery(context);
-                    query = new ParsedQuery(q, context.copyNamedQueries());
+                    Query q = searchContext.queryParserService().parseInnerQuery(parseContext);
+                    query = new ParsedQuery(q, parseContext.copyNamedQueries());
                 } else if ("inner_hits".equals(fieldName)) {
-                    childInnerHits = parseInnerHits(parser, context, searchContext);
+                    childInnerHits = parseInnerHits(parser, parseContext, searchContext);
                 } else {
                     parseCommonInnerHitOptions(parser, token, fieldName, subSearchContext, sortParseElement, sourceParseElement, highlighterParseElement, scriptFieldsParseElement, fieldDataFieldsParseElement);
                 }
diff --git a/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java b/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
index d73e3a7..234a841 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.query.ParsedQuery;
-import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.similarity.SimilarityService;
 import org.elasticsearch.script.ScriptService;
@@ -75,12 +75,12 @@ public abstract class SearchContext extends DelegatingHasContextAndHeaders imple
 
     public static void setCurrent(SearchContext value) {
         current.set(value);
-        QueryShardContext.setTypes(value.types());
+        QueryParseContext.setTypes(value.types());
     }
 
     public static void removeCurrent() {
         current.remove();
-        QueryShardContext.removeTypes();
+        QueryParseContext.removeTypes();
     }
 
     public static SearchContext current() {
diff --git a/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java b/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java
index e1405f8..0916128 100644
--- a/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java
+++ b/core/src/main/java/org/elasticsearch/search/sort/GeoDistanceSortParser.java
@@ -173,7 +173,7 @@ public class GeoDistanceSortParser implements SortParser {
             ObjectMapper objectMapper = context.mapperService().resolveClosestNestedObjectMapper(fieldName);
             if (objectMapper != null && objectMapper.nested().isNested()) {
                 if (nestedHelper == null) {
-                    nestedHelper = new NestedInnerQueryParseSupport(context.queryParserService().getShardContext());
+                    nestedHelper = new NestedInnerQueryParseSupport(context.queryParserService().getParseContext());
                 }
                 nestedHelper.setPath(objectMapper.fullPath());
             }
@@ -181,6 +181,7 @@ public class GeoDistanceSortParser implements SortParser {
 
         final Nested nested;
         if (nestedHelper != null && nestedHelper.getPath() != null) {
+            
             BitSetProducer rootDocumentsFilter = context.bitsetFilterCache().getBitSetProducer(Queries.newNonNestedFilter());
             Filter innerDocumentsFilter;
             if (nestedHelper.filterFound()) {
diff --git a/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java b/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java
index 2a98054..c7a3192 100644
--- a/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java
+++ b/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java
@@ -244,7 +244,7 @@ public class SortParseElement implements SearchParseElement {
                     ObjectMapper objectMapper = context.mapperService().resolveClosestNestedObjectMapper(fieldName);
                     if (objectMapper != null && objectMapper.nested().isNested()) {
                         if (nestedHelper == null) {
-                            nestedHelper = new NestedInnerQueryParseSupport(context.queryParserService().getShardContext());
+                            nestedHelper = new NestedInnerQueryParseSupport(context.queryParserService().getParseContext());
                         }
                         nestedHelper.setPath(objectMapper.fullPath());
                     }
diff --git a/core/src/main/java/org/elasticsearch/tribe/TribeService.java b/core/src/main/java/org/elasticsearch/tribe/TribeService.java
index 3cc7b77..854c5c6 100644
--- a/core/src/main/java/org/elasticsearch/tribe/TribeService.java
+++ b/core/src/main/java/org/elasticsearch/tribe/TribeService.java
@@ -137,7 +137,7 @@ public class TribeService extends AbstractLifecycleComponent<TribeService> {
             if (sb.get("http.enabled") == null) {
                 sb.put("http.enabled", false);
             }
-            nodes.add(NodeBuilder.nodeBuilder().settings(sb).client(true).loadConfigSettings(false).build());
+            nodes.add(NodeBuilder.nodeBuilder().settings(sb).client(true).build());
         }
 
         String[] blockIndicesWrite = Strings.EMPTY_ARRAY;
diff --git a/core/src/main/resources/org/elasticsearch/index/mapper/default-mapping.json b/core/src/main/resources/org/elasticsearch/index/mapper/default-mapping.json
new file mode 100644
index 0000000..7b035a3
--- /dev/null
+++ b/core/src/main/resources/org/elasticsearch/index/mapper/default-mapping.json
@@ -0,0 +1,4 @@
+{
+    "_default_":{
+    }
+}
\ No newline at end of file
diff --git a/core/src/main/resources/org/elasticsearch/index/mapper/script-mapping.json b/core/src/main/resources/org/elasticsearch/index/mapper/script-mapping.json
new file mode 100644
index 0000000..799039c
--- /dev/null
+++ b/core/src/main/resources/org/elasticsearch/index/mapper/script-mapping.json
@@ -0,0 +1,9 @@
+{
+     "_default_": {
+
+       "properties": {
+         "script": { "enabled": false },
+         "template": { "enabled": false }
+       }
+     }
+}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/ESExceptionTests.java b/core/src/test/java/org/elasticsearch/ESExceptionTests.java
index eb3d870..dea127a 100644
--- a/core/src/test/java/org/elasticsearch/ESExceptionTests.java
+++ b/core/src/test/java/org/elasticsearch/ESExceptionTests.java
@@ -35,7 +35,8 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentLocation;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.IndexNotFoundException;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.QueryParsingException;
+import org.elasticsearch.index.query.TestQueryParsingException;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.search.SearchParseException;
 import org.elasticsearch.search.SearchShardTarget;
@@ -51,6 +52,7 @@ import java.io.EOFException;
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.nio.file.NoSuchFileException;
+import java.util.Collections;
 
 import static org.hamcrest.Matchers.equalTo;
 
@@ -307,7 +309,7 @@ public class ESExceptionTests extends ESTestCase {
                 new OutOfMemoryError("no memory left"),
                 new AlreadyClosedException("closed!!", new NullPointerException()),
                 new LockObtainFailedException("can't lock directory", new NullPointerException()),
-                new Throwable("this exception is unknown", new QueryShardException(new Index("foo"), "foobar", null) ), // somethin unknown
+                new Throwable("this exception is unknown", new QueryParsingException(new Index("foo"), 1, 2, "foobar", null) ), // somethin unknown
         };
         for (Throwable t : causes) {
             BytesStreamOutput out = new BytesStreamOutput();
diff --git a/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java b/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
index eaa5ad0..dc0dd76 100644
--- a/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
+++ b/core/src/test/java/org/elasticsearch/ExceptionSerializationTests.java
@@ -35,17 +35,11 @@ import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.*;
 import org.elasticsearch.common.breaker.CircuitBreakingException;
 import org.elasticsearch.common.io.PathUtils;
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.NotSerializableExceptionWrapper;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.io.stream.*;
 import org.elasticsearch.common.transport.LocalTransportAddress;
 import org.elasticsearch.common.unit.ByteSizeValue;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentLocation;
 import org.elasticsearch.common.util.CancellableThreadsTests;
+import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.discovery.DiscoverySettings;
 import org.elasticsearch.index.AlreadyExpiredException;
 import org.elasticsearch.index.Index;
@@ -54,11 +48,7 @@ import org.elasticsearch.index.engine.IndexFailedEngineException;
 import org.elasticsearch.index.engine.RecoveryEngineException;
 import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.query.QueryParsingException;
-import org.elasticsearch.index.query.QueryShardException;
-import org.elasticsearch.index.shard.IllegalIndexShardStateException;
-import org.elasticsearch.index.shard.IndexShardState;
-import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.shard.TranslogRecoveryPerformer;
+import org.elasticsearch.index.shard.*;
 import org.elasticsearch.indices.IndexTemplateAlreadyExistsException;
 import org.elasticsearch.indices.IndexTemplateMissingException;
 import org.elasticsearch.indices.InvalidIndexTemplateException;
@@ -233,16 +223,6 @@ public class ExceptionSerializationTests extends ESTestCase {
         assertEquals(ex.getColumnNumber(), 2);
     }
 
-    public void testQueryShardException() throws IOException {
-        QueryShardException ex = serialize(new QueryShardException(new Index("foo"), "fobar", null));
-        assertEquals(ex.getIndex(), "foo");
-        assertEquals(ex.getMessage(), "fobar");
-
-        ex = serialize(new QueryShardException((Index)null, null, null));
-        assertNull(ex.getIndex());
-        assertNull(ex.getMessage());
-    }
-
     public void testSearchException() throws IOException {
         SearchShardTarget target = new SearchShardTarget("foo", "bar", 1);
         SearchException ex = serialize(new SearchException(target, "hello world"));
diff --git a/core/src/test/java/org/elasticsearch/action/bulk/bulk-log.json b/core/src/test/java/org/elasticsearch/action/bulk/bulk-log.json
deleted file mode 100644
index 9c3663c..0000000
--- a/core/src/test/java/org/elasticsearch/action/bulk/bulk-log.json
+++ /dev/null
@@ -1,24 +0,0 @@
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug2/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug2/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug2/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
-{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
-{"message":"in24.inetnebr.com--[01/Aug2/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
diff --git a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk.json b/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk.json
deleted file mode 100644
index cf76477..0000000
--- a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{ "index":{"_index":"test","_type":"type1","_id":"1"} }
-{ "field1" : "value1" }
-{ "delete" : { "_index" : "test", "_type" : "type1", "_id" : "2" } }
-{ "create" : { "_index" : "test", "_type" : "type1", "_id" : "3" } }
-{ "field1" : "value3" }
diff --git a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk10.json b/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk10.json
deleted file mode 100644
index 3556dc2..0000000
--- a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk10.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{ "index"  : {"_index":null, "_type":"type1", "_id":"0"} }
-{ "field1" : "value1" }
-{ "index"  : {"_index":"test", "_type":null, "_id":"0"} }
-{ "field1" : "value1" }
-{ "index"  : {"_index":"test", "_type":"type1", "_id":null} }
-{ "field1" : "value1" }
-{ "delete"  : {"_index":null, "_type":"type1", "_id":"0"} }
-{ "delete"  : {"_index":"test", "_type":null, "_id":"0"} }
-{ "delete"  : {"_index":"test", "_type":"type1", "_id":null} }
-{ "create"  : {"_index":null, "_type":"type1", "_id":"0"} }
-{ "field1" : "value1" }
-{ "create"  : {"_index":"test", "_type":null, "_id":"0"} }
-{ "field1" : "value1" }
-{ "create"  : {"_index":"test", "_type":"type1", "_id":null} }
-{ "field1" : "value1" }
diff --git a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk2.json b/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk2.json
deleted file mode 100644
index 7cd4f99..0000000
--- a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk2.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{ "index":{ } }
-{ "field1" : "value1" }
-{ "delete" : { "_id" : "2" } }
-{ "create" : { "_id" : "3" } }
-{ "field1" : "value3" }
diff --git a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk3.json b/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk3.json
deleted file mode 100644
index 7cd4f99..0000000
--- a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk3.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{ "index":{ } }
-{ "field1" : "value1" }
-{ "delete" : { "_id" : "2" } }
-{ "create" : { "_id" : "3" } }
-{ "field1" : "value3" }
diff --git a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk4.json b/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk4.json
deleted file mode 100644
index 8b916b8..0000000
--- a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk4.json
+++ /dev/null
@@ -1,7 +0,0 @@
-{ "update" : {"_id" : "1", "_retry_on_conflict" : 2} }
-{ "doc" : {"field" : "value"} }
-{ "update" : { "_id" : "0", "_type" : "type1", "_index" : "index1" } }
-{ "script" : "counter += param1", "lang" : "js", "params" : {"param1" : 1}, "upsert" : {"counter" : 1}}
-{ "delete" : { "_id" : "2" } }
-{ "create" : { "_id" : "3" } }
-{ "field1" : "value3" }
diff --git a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk5.json b/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk5.json
deleted file mode 100644
index 6ad5ff3..0000000
--- a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk5.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{ "index": {"_type": "type1","_id": "1"} }
-{ "field1" : "value1" }
-{ "delete" : { "_type" : "type1", "_id" : "2" } }
-{ "create" : { "_type" : "type1", "_id" : "3" } }
-{ "field1" : "value3" }
diff --git a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk6.json b/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk6.json
deleted file mode 100644
index e9c9796..0000000
--- a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk6.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{"index": {"_index": "test", "_type": "doc", "_source": {"hello": "world"}, "_id": 0}}
-{"field1": "value0"}
-{"index": {"_index": "test", "_type": "doc", "_id": 1}}
-{"field1": "value1"}
-{"index": {"_index": "test", "_type": "doc", "_id": 2}}
-{"field1": "value2"}
diff --git a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk7.json b/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk7.json
deleted file mode 100644
index a642d9c..0000000
--- a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk7.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{"index": {"_index": "test", "_type": "doc", "_id": 0}}
-{"field1": "value0"}
-{"index": {"_index": "test", "_type": "doc", "_id": 1}}
-{"field1": "value1"}
-{"index": {"_index": "test", "_type": "doc", "_id": 2, "_unkown": ["foo", "bar"]}}
-{"field1": "value2"}
diff --git a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk8.json b/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk8.json
deleted file mode 100644
index c1a94b1..0000000
--- a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk8.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{"index": {"_index": "test", "_type": "doc", "_id": 0}}
-{"field1": "value0"}
-{"index": {"_index": "test", "_type": "doc", "_id": 1, "_foo": "bar"}}
-{"field1": "value1"}
-{"index": {"_index": "test", "_type": "doc", "_id": 2}}
-{"field1": "value2"}
diff --git a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk9.json b/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk9.json
deleted file mode 100644
index ebdbf75..0000000
--- a/core/src/test/java/org/elasticsearch/action/bulk/simple-bulk9.json
+++ /dev/null
@@ -1,4 +0,0 @@
-{"index": {}}
-{"field1": "value0"}
-{"index": ["bar"] }
-{"field1": "value1"}
diff --git a/core/src/test/java/org/elasticsearch/action/percolate/mpercolate1.json b/core/src/test/java/org/elasticsearch/action/percolate/mpercolate1.json
deleted file mode 100644
index 4407939..0000000
--- a/core/src/test/java/org/elasticsearch/action/percolate/mpercolate1.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{"percolate" : {"index" : "my-index1", "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local", "ignore_unavailable" : false}}
-{"doc" : {"field1" : "value1"}}
-{"percolate" : {"indices" : ["my-index2", "my-index3"], "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local", "ignore_unavailable" : true}}
-{"doc" : {"field1" : "value2"}}
-{"count" : {"indices" : ["my-index4", "my-index5"], "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local", "expand_wildcards" : "open,closed"}}
-{"doc" : {"field1" : "value3"}}
-{"percolate" : {"id" : "1", "index" : "my-index6", "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local", "expand_wildcards" : ["open", "closed"]}}
-{}
-{"count" : {"id" : "2", "index" : "my-index7", "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local"}}
-{}
-{"percolate" : {"index" : "my-index8", "type" : "my-type1", "routing" : "my-routing-1", "preference" : "primary"}}
-{"doc" : {"field1" : "value4"}}
-{"percolate" : {"id" : "3", "index" : "my-index9", "type" : "my-type1", "percolate_index": "percolate-index1", "percolate_type": "other-type", "percolate_preference": "_local", "percolate_routing": "percolate-routing-1"}}
-{}
-{"percolate" : {"id" : "4", "index" : "my-index10", "type" : "my-type1", "allow_no_indices": false, "expand_wildcards" : ["open"]}}
-{}
diff --git a/core/src/test/java/org/elasticsearch/action/percolate/mpercolate2.json b/core/src/test/java/org/elasticsearch/action/percolate/mpercolate2.json
deleted file mode 100644
index fa676cf..0000000
--- a/core/src/test/java/org/elasticsearch/action/percolate/mpercolate2.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{"percolate" : {"routing" : "my-routing-1", "preference" : "_local"}}
-{"doc" : {"field1" : "value1"}}
-{"percolate" : {"index" : "my-index1", "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local", "ignore_unavailable" : true}}
-{"doc" : {"field1" : "value2"}}
-{"percolate" : {}}
-{"doc" : {"field1" : "value3"}}
diff --git a/core/src/test/java/org/elasticsearch/action/termvectors/multiRequest1.json b/core/src/test/java/org/elasticsearch/action/termvectors/multiRequest1.json
deleted file mode 100644
index fcb5e3a..0000000
--- a/core/src/test/java/org/elasticsearch/action/termvectors/multiRequest1.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-    "ids": ["1","2"],
-    "parameters": {
-        "field_statistics": false,
-        "term_statistics": true,
-        "payloads":false,
-        "offsets":false,
-        "positions":false,
-        "fields":["a","b","c"],
-        "_index": "testidx",
-        "_type":"test"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/action/termvectors/multiRequest2.json b/core/src/test/java/org/elasticsearch/action/termvectors/multiRequest2.json
deleted file mode 100644
index a0709ef..0000000
--- a/core/src/test/java/org/elasticsearch/action/termvectors/multiRequest2.json
+++ /dev/null
@@ -1,26 +0,0 @@
-{
-   "docs": [
-      {
-         "_id": "1",
-         "field_statistics": false,
-         "term_statistics": true,
-         "payloads": false,
-         "offsets": false,
-         "positions": false,
-         "fields":["a","b","c"],
-         "_index": "testidx",
-         "_type": "test"
-      },
-      {
-         "_id": "2",
-         "field_statistics": false,
-         "term_statistics": true,
-         "payloads": false,
-         "offsets": false,
-         "positions": false,
-         "fields":["a","b","c"],
-         "_index": "testidx",
-         "_type": "test"
-      }
-   ]
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/action/termvectors/multiRequest3.json b/core/src/test/java/org/elasticsearch/action/termvectors/multiRequest3.json
deleted file mode 100644
index 457f43c..0000000
--- a/core/src/test/java/org/elasticsearch/action/termvectors/multiRequest3.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-   "ids": ["1","2"],
-   "parameters": {
-      "_index": "testidx",
-      "_type": "test",
-      "filter": {
-         "max_num_terms": 20,
-         "min_term_freq": 1,
-         "max_term_freq": 20,
-         "min_doc_freq": 1,
-         "max_doc_freq": 20,
-         "min_word_length": 1,
-         "max_word_length": 20
-      }
-   }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java b/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java
index 80f4c45..4956853 100644
--- a/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java
+++ b/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java
@@ -151,7 +151,7 @@ public class IndexAliasesIT extends ESIntegTestCase {
         logger.info("--> making sure that filter was stored with alias [alias1] and filter [user:kimchy]");
         ClusterState clusterState = admin().cluster().prepareState().get().getState();
         IndexMetaData indexMd = clusterState.metaData().index("test");
-        assertThat(indexMd.aliases().get("alias1").filter().string(), equalTo("{\"term\":{\"user\":{\"value\":\"kimchy\",\"boost\":1.0}}}"));
+        assertThat(indexMd.aliases().get("alias1").filter().string(), equalTo("{\"term\":{\"user\":\"kimchy\"}}"));
 
     }
 
@@ -413,8 +413,8 @@ public class IndexAliasesIT extends ESIntegTestCase {
         assertThat(client().prepareCount("bars").setQuery(QueryBuilders.matchAllQuery()).get().getCount(), equalTo(1L));
     }
 
-
-
+    
+    
     @Test
     public void testDeleteAliases() throws Exception {
         logger.info("--> creating index [test1] and [test2]");
@@ -434,17 +434,17 @@ public class IndexAliasesIT extends ESIntegTestCase {
                 .addAlias("test2", "aliasToTests")
                 .addAlias("test2", "foos", termQuery("name", "foo"))
                 .addAlias("test2", "tests", termQuery("name", "test")));
-
-        String[] indices = {"test1", "test2"};
+        
+        String[] indices = {"test1", "test2"}; 
         String[] aliases = {"aliasToTest1", "foos", "bars", "tests", "aliasToTest2", "aliasToTests"};
-
+        
         admin().indices().prepareAliases().removeAlias(indices, aliases).get();
-
+        
         AliasesExistResponse response = admin().indices().prepareAliasesExist(aliases).get();
         assertThat(response.exists(), equalTo(false));
     }
 
-
+    
     @Test
     public void testWaitForAliasCreationMultipleShards() throws Exception {
         logger.info("--> creating index [test]");
@@ -532,16 +532,16 @@ public class IndexAliasesIT extends ESIntegTestCase {
 
         logger.info("--> verify that filter was updated");
         AliasMetaData aliasMetaData = ((AliasOrIndex.Alias) internalCluster().clusterService().state().metaData().getAliasAndIndexLookup().get("alias1")).getFirstAliasMetaData();
-        assertThat(aliasMetaData.getFilter().toString(), equalTo("{\"term\":{\"name\":{\"value\":\"bar\",\"boost\":1.0}}}"));
+        assertThat(aliasMetaData.getFilter().toString(), equalTo("{\"term\":{\"name\":\"bar\"}}"));
 
         logger.info("--> deleting alias1");
         stopWatch.start();
         assertAcked((admin().indices().prepareAliases().removeAlias("test", "alias1").setTimeout(timeout)));
         assertThat(stopWatch.stop().lastTaskTime().millis(), lessThan(timeout.millis()));
 
-
+        
     }
-
+    
     @Test(expected = AliasesNotFoundException.class)
     public void testIndicesRemoveNonExistingAliasResponds404() throws Exception {
         logger.info("--> creating index [test]");
@@ -980,30 +980,6 @@ public class IndexAliasesIT extends ESIntegTestCase {
     }
 
     @Test
-    public void testAliasesFilterWithHasChildQueryPre2Dot0() throws Exception {
-        assertAcked(prepareCreate("my-index")
-                        .setSettings(Settings.builder()
-                                .put(indexSettings())
-                                .put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_6_0)
-                        )
-                        .addMapping("parent")
-                        .addMapping("child", "_parent", "type=parent")
-        );
-        client().prepareIndex("my-index", "parent", "1").setSource("{}").get();
-        client().prepareIndex("my-index", "child", "2").setSource("{}").setParent("1").get();
-        refresh();
-
-        assertAcked(admin().indices().prepareAliases().addAlias("my-index", "filter1", hasChildQuery("child", matchAllQuery())));
-        assertAcked(admin().indices().prepareAliases().addAlias("my-index", "filter2", hasParentQuery("parent", matchAllQuery())));
-        SearchResponse response = client().prepareSearch("filter1").get();
-        assertHitCount(response, 1);
-        assertThat(response.getHits().getAt(0).id(), equalTo("1"));
-        response = client().prepareSearch("filter2").get();
-        assertHitCount(response, 1);
-        assertThat(response.getHits().getAt(0).id(), equalTo("2"));
-    }
-
-    @Test
     public void testAliasesWithBlocks() {
         createIndex("test");
         ensureGreen();
diff --git a/core/src/test/java/org/elasticsearch/benchmark/recovery/ReplicaRecoveryBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/recovery/ReplicaRecoveryBenchmark.java
index e7ef325..555a332 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/recovery/ReplicaRecoveryBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/recovery/ReplicaRecoveryBenchmark.java
@@ -60,7 +60,6 @@ public class ReplicaRecoveryBenchmark {
         BootstrapForTesting.ensureInitialized();
 
         Settings settings = settingsBuilder()
-                .put("gateway.type", "local")
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_DISK_THRESHOLD_ENABLED, "false")
                 .put(SETTING_NUMBER_OF_SHARDS, 1)
                 .put(SETTING_NUMBER_OF_REPLICAS, 0)
diff --git a/core/src/test/java/org/elasticsearch/benchmark/scripts/expression/ScriptComparisonBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/scripts/expression/ScriptComparisonBenchmark.java
index 6581cd2..ce4cbf1 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/scripts/expression/ScriptComparisonBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/scripts/expression/ScriptComparisonBenchmark.java
@@ -111,7 +111,7 @@ public class ScriptComparisonBenchmark {
         Settings settings = settingsBuilder().put("name", "node1")
                                              .put("cluster.name", clusterName).build();
         Collection<Class<? extends Plugin>> plugins = Collections.<Class<? extends Plugin>>singletonList(NativeScriptPlugin.class);
-        Node node1 = new MockNode(settings, true, Version.CURRENT, plugins);
+        Node node1 = new MockNode(settings, Version.CURRENT, plugins);
         node1.start();
         Client client = node1.client();
         client.admin().cluster().prepareHealth(indexName).setWaitForGreenStatus().setTimeout("10s").execute().actionGet();
diff --git a/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsConstantScoreBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsConstantScoreBenchmark.java
index 7ad1837..53baf78 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsConstantScoreBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsConstantScoreBenchmark.java
@@ -56,7 +56,7 @@ public class ScriptsConstantScoreBenchmark extends BasicScriptBenchmark {
         Settings settings = settingsBuilder().put("name", "node1")
                                              .put("cluster.name", clusterName).build();
         Collection<Class<? extends Plugin>> plugins = Collections.<Class<? extends Plugin>>singletonList(NativeScriptExamplesPlugin.class);
-        Node node1 = new MockNode(settings, true, Version.CURRENT, plugins);
+        Node node1 = new MockNode(settings, Version.CURRENT, plugins);
         node1.start();
         Client client = node1.client();
         client.admin().cluster().prepareHealth("test").setWaitForGreenStatus().setTimeout("10s").execute().actionGet();
diff --git a/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsScoreBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsScoreBenchmark.java
index 712b613..53c34a2 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsScoreBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsScoreBenchmark.java
@@ -55,7 +55,7 @@ public class ScriptsScoreBenchmark extends BasicScriptBenchmark {
         Settings settings = settingsBuilder().put("name", "node1")
             .put("cluster.name", clusterName).build();
         Collection<Class<? extends Plugin>> plugins = Collections.<Class<? extends Plugin>>singletonList(NativeScriptExamplesPlugin.class);
-        Node node1 = new MockNode(settings, true, Version.CURRENT, plugins);
+        Node node1 = new MockNode(settings, Version.CURRENT, plugins);
         node1.start();
         Client client = node1.client();
         client.admin().cluster().prepareHealth("test").setWaitForGreenStatus().setTimeout("10s").execute().actionGet();
diff --git a/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsScorePayloadSumBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsScorePayloadSumBenchmark.java
index 556c224..b809192 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsScorePayloadSumBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/scripts/score/ScriptsScorePayloadSumBenchmark.java
@@ -55,7 +55,7 @@ public class ScriptsScorePayloadSumBenchmark extends BasicScriptBenchmark {
         Settings settings = settingsBuilder().put("name", "node1")
             .put("cluster.name", clusterName).build();
         Collection<Class<? extends Plugin>> plugins = Collections.<Class<? extends Plugin>>singletonList(NativeScriptExamplesPlugin.class);
-        Node node1 = new MockNode(settings, true, Version.CURRENT, plugins);
+        Node node1 = new MockNode(settings, Version.CURRENT, plugins);
         node1.start();
         Client client = node1.client();
         client.admin().cluster().prepareHealth("test").setWaitForGreenStatus().setTimeout("10s").execute().actionGet();
diff --git a/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchBenchmark.java
index 8902a31..19e5c2f 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchBenchmark.java
@@ -26,7 +26,6 @@ import org.elasticsearch.client.Client;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.SizeValue;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.search.child.ScoreType;
 import org.elasticsearch.indices.IndexAlreadyExistsException;
 import org.elasticsearch.node.Node;
 import org.elasticsearch.search.aggregations.AggregationBuilders;
@@ -286,12 +285,12 @@ public class ChildSearchBenchmark {
         System.out.println("--> Running has_child query with score type");
         // run parent child score query
         for (int j = 0; j < QUERY_WARMUP; j++) {
-            client.prepareSearch(indexName).setQuery(hasChildQuery("child", termQuery("field2", parentChildIndexGenerator.getQueryValue())).scoreType(ScoreType.MAX)).execute().actionGet();
+            client.prepareSearch(indexName).setQuery(hasChildQuery("child", termQuery("field2", parentChildIndexGenerator.getQueryValue())).scoreType("max")).execute().actionGet();
         }
 
         totalQueryTime = 0;
         for (int j = 0; j < QUERY_COUNT; j++) {
-            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasChildQuery("child", termQuery("field2", parentChildIndexGenerator.getQueryValue())).scoreType(ScoreType.MAX)).execute().actionGet();
+            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasChildQuery("child", termQuery("field2", parentChildIndexGenerator.getQueryValue())).scoreType("max")).execute().actionGet();
             if (j % 10 == 0) {
                 System.out.println("--> hits [" + j + "], got [" + searchResponse.getHits().totalHits() + "]");
             }
@@ -301,7 +300,7 @@ public class ChildSearchBenchmark {
         
         totalQueryTime = 0;
         for (int j = 0; j < QUERY_COUNT; j++) {
-            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasChildQuery("child", matchAllQuery()).scoreType(ScoreType.MAX)).execute().actionGet();
+            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasChildQuery("child", matchAllQuery()).scoreType("max")).execute().actionGet();
             if (j % 10 == 0) {
                 System.out.println("--> hits [" + j + "], got [" + searchResponse.getHits().totalHits() + "]");
             }
@@ -312,12 +311,12 @@ public class ChildSearchBenchmark {
         System.out.println("--> Running has_parent query with score type");
         // run parent child score query
         for (int j = 0; j < QUERY_WARMUP; j++) {
-            client.prepareSearch(indexName).setQuery(hasParentQuery("parent", termQuery("field1", parentChildIndexGenerator.getQueryValue())).score(true)).execute().actionGet();
+            client.prepareSearch(indexName).setQuery(hasParentQuery("parent", termQuery("field1", parentChildIndexGenerator.getQueryValue())).scoreType("score")).execute().actionGet();
         }
 
         totalQueryTime = 0;
         for (int j = 1; j < QUERY_COUNT; j++) {
-            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasParentQuery("parent", termQuery("field1", parentChildIndexGenerator.getQueryValue())).score(true)).execute().actionGet();
+            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasParentQuery("parent", termQuery("field1", parentChildIndexGenerator.getQueryValue())).scoreType("score")).execute().actionGet();
             if (j % 10 == 0) {
                 System.out.println("--> hits [" + j + "], got [" + searchResponse.getHits().totalHits() + "]");
             }
@@ -327,7 +326,7 @@ public class ChildSearchBenchmark {
 
         totalQueryTime = 0;
         for (int j = 1; j < QUERY_COUNT; j++) {
-            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasParentQuery("parent", matchAllQuery()).score(true)).execute().actionGet();
+            SearchResponse searchResponse = client.prepareSearch(indexName).setQuery(hasParentQuery("parent", matchAllQuery()).scoreType("score")).execute().actionGet();
             if (j % 10 == 0) {
                 System.out.println("--> hits [" + j + "], got [" + searchResponse.getHits().totalHits() + "]");
             }
diff --git a/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchShortCircuitBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchShortCircuitBenchmark.java
index aac750f..966ca4f 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchShortCircuitBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/search/child/ChildSearchShortCircuitBenchmark.java
@@ -30,7 +30,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.SizeValue;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.search.child.ScoreType;
 import org.elasticsearch.node.Node;
 
 import java.io.IOException;
@@ -179,7 +178,7 @@ public class ChildSearchShortCircuitBenchmark {
         for (int i = 1; i < PARENT_COUNT; i *= 2) {
             for (int j = 0; j < QUERY_COUNT; j++) {
                 SearchResponse searchResponse = client.prepareSearch(indexName)
-                        .setQuery(hasChildQuery("child", matchQuery("field2", i)).scoreType(ScoreType.MAX))
+                        .setQuery(hasChildQuery("child", matchQuery("field2", i)).scoreType("max"))
                         .execute().actionGet();
                 if (searchResponse.getHits().totalHits() != i) {
                     System.err.println("--> mismatch on hits");
diff --git a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java
index a7b9043..58f4406 100644
--- a/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java
+++ b/core/src/test/java/org/elasticsearch/bootstrap/BootstrapForTesting.java
@@ -80,7 +80,7 @@ public class BootstrapForTesting {
         }
 
         // install security manager if requested
-        if (systemPropertyAsBoolean("tests.security.manager", false)) {
+        if (systemPropertyAsBoolean("tests.security.manager", true)) {
             try {
                 Security.setCodebaseProperties();
                 // initialize paths the same exact way as bootstrap.
diff --git a/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java b/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java
index 964a47c..0cf16b4 100644
--- a/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java
+++ b/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java
@@ -19,8 +19,8 @@
 
 package org.elasticsearch.client;
 
-import com.google.common.base.Throwables;
 import com.google.common.collect.ImmutableMap;
+import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.GenericAction;
 import org.elasticsearch.action.admin.cluster.reroute.ClusterRerouteAction;
@@ -59,7 +59,9 @@ import org.junit.Test;
 import java.util.HashMap;
 import java.util.Map;
 
-import static org.hamcrest.Matchers.*;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.is;
+import static org.hamcrest.Matchers.notNullValue;
 
 /**
  *
@@ -228,7 +230,7 @@ public abstract class AbstractClientHeadersTestCase extends ESTestCase {
                 }
                 if (counter++ > 10) {
                     // dear god, if we got more than 10 levels down, WTF? just bail
-                    fail("Exception cause unwrapping ran for 10 levels: " + Throwables.getStackTraceAsString(t));
+                    fail("Exception cause unwrapping ran for 10 levels: " + ExceptionsHelper.stackTrace(t));
                     return null;
                 }
                 result = result.getCause();
diff --git a/core/src/test/java/org/elasticsearch/cluster/allocation/ClusterRerouteIT.java b/core/src/test/java/org/elasticsearch/cluster/allocation/ClusterRerouteIT.java
index c623552..0eecc58 100644
--- a/core/src/test/java/org/elasticsearch/cluster/allocation/ClusterRerouteIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/allocation/ClusterRerouteIT.java
@@ -166,7 +166,6 @@ public class ClusterRerouteIT extends ESIntegTestCase {
     @Test
     public void testDelayWithALargeAmountOfShards() throws Exception {
         Settings commonSettings = settingsBuilder()
-                .put("gateway.type", "local")
                 .put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_CONCURRENT_RECOVERIES, 1)
                 .build();
         logger.info("--> starting 4 nodes");
diff --git a/core/src/test/java/org/elasticsearch/cluster/node/DiscoveryNodeFiltersTests.java b/core/src/test/java/org/elasticsearch/cluster/node/DiscoveryNodeFiltersTests.java
index 141d983..b37495e 100644
--- a/core/src/test/java/org/elasticsearch/cluster/node/DiscoveryNodeFiltersTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/node/DiscoveryNodeFiltersTests.java
@@ -23,18 +23,38 @@ import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.DummyTransportAddress;
+import org.elasticsearch.common.transport.InetSocketTransportAddress;
 import org.elasticsearch.test.ESTestCase;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
 import org.junit.Test;
 
+import java.net.InetAddress;
+import java.net.UnknownHostException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
 import static org.elasticsearch.cluster.node.DiscoveryNodeFilters.OpType.AND;
 import static org.elasticsearch.cluster.node.DiscoveryNodeFilters.OpType.OR;
-import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.equalTo;
 
 /**
  */
 public class DiscoveryNodeFiltersTests extends ESTestCase {
 
+    private static InetSocketTransportAddress localAddress;
+
+    @BeforeClass
+    public static void createLocalAddress() throws UnknownHostException {
+        localAddress = new InetSocketTransportAddress(InetAddress.getByName("192.1.1.54"), 9999);
+    }
+
+    @AfterClass
+    public static void releaseLocalAddress() {
+        localAddress = null;
+    }
+
     @Test
     public void nameMatch() {
         Settings settings = Settings.settingsBuilder()
@@ -65,10 +85,10 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
 
     @Test
     public void idOrNameMatch() {
-        Settings settings = Settings.settingsBuilder()
+        Settings settings = shuffleSettings(Settings.settingsBuilder()
                 .put("xxx._id", "id1,blah")
                 .put("xxx.name", "blah,name2")
-                .build();
+                .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
 
         DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
@@ -83,22 +103,22 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
 
     @Test
     public void tagAndGroupMatch() {
-        Settings settings = Settings.settingsBuilder()
+        Settings settings = shuffleSettings(Settings.settingsBuilder()
                 .put("xxx.tag", "A")
                 .put("xxx.group", "B")
-                .build();
+                .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
 
         DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE,
-                ImmutableMap.<String, String>of("tag", "A", "group", "B"), Version.CURRENT);
+                ImmutableMap.of("tag", "A", "group", "B"), Version.CURRENT);
         assertThat(filters.match(node), equalTo(true));
 
         node = new DiscoveryNode("name2", "id2", DummyTransportAddress.INSTANCE,
-                ImmutableMap.<String, String>of("tag", "A", "group", "B", "name", "X"), Version.CURRENT);
+                ImmutableMap.of("tag", "A", "group", "B", "name", "X"), Version.CURRENT);
         assertThat(filters.match(node), equalTo(true));
 
         node = new DiscoveryNode("name3", "id3", DummyTransportAddress.INSTANCE,
-                ImmutableMap.<String, String>of("tag", "A", "group", "F", "name", "X"), Version.CURRENT);
+                ImmutableMap.of("tag", "A", "group", "F", "name", "X"), Version.CURRENT);
         assertThat(filters.match(node), equalTo(false));
 
         node = new DiscoveryNode("name4", "id4", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
@@ -115,4 +135,124 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
         DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
         assertThat(filters.match(node), equalTo(true));
     }
+
+    @Test
+    public void ipBindFilteringMatchingAnd() {
+        Settings settings = shuffleSettings(Settings.settingsBuilder()
+                .put("xxx.tag", "A")
+                .put("xxx." + randomFrom("_ip", "_host_ip", "_publish_ip"), "192.1.1.54")
+                .build());
+        DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
+
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
+        assertThat(filters.match(node), equalTo(true));
+    }
+
+    @Test
+    public void ipBindFilteringNotMatching() {
+        Settings settings = shuffleSettings(Settings.settingsBuilder()
+                .put("xxx.tag", "B")
+                .put("xxx." + randomFrom("_ip", "_host_ip", "_publish_ip"), "192.1.1.54")
+                .build());
+        DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
+
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
+        assertThat(filters.match(node), equalTo(false));
+    }
+
+    @Test
+    public void ipBindFilteringNotMatchingAnd() {
+        Settings settings = shuffleSettings(Settings.settingsBuilder()
+                .put("xxx.tag", "A")
+                .put("xxx." + randomFrom("_ip", "_host_ip", "_publish_ip"), "8.8.8.8")
+                .build());
+        DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
+
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
+        assertThat(filters.match(node), equalTo(false));
+    }
+
+    @Test
+    public void ipBindFilteringMatchingOr() {
+        Settings settings = shuffleSettings(Settings.settingsBuilder()
+                .put("xxx." + randomFrom("_ip", "_host_ip", "_publish_ip"), "192.1.1.54")
+                .put("xxx.tag", "A")
+                .build());
+        DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
+
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
+        assertThat(filters.match(node), equalTo(true));
+    }
+
+    @Test
+    public void ipBindFilteringNotMatchingOr() {
+        Settings settings = shuffleSettings(Settings.settingsBuilder()
+                .put("xxx.tag", "A")
+                .put("xxx." + randomFrom("_ip", "_host_ip", "_publish_ip"), "8.8.8.8")
+                .build());
+        DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
+
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
+        assertThat(filters.match(node), equalTo(true));
+    }
+
+    @Test
+    public void ipPublishFilteringMatchingAnd() {
+        Settings settings = shuffleSettings(Settings.settingsBuilder()
+                .put("xxx.tag", "A")
+                .put("xxx._publish_ip", "192.1.1.54")
+                .build());
+        DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
+
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
+        assertThat(filters.match(node), equalTo(true));
+    }
+
+    @Test
+    public void ipPublishFilteringNotMatchingAnd() {
+        Settings settings = shuffleSettings(Settings.settingsBuilder()
+                .put("xxx.tag", "A")
+                .put("xxx._publish_ip", "8.8.8.8")
+                .build());
+        DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
+
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
+        assertThat(filters.match(node), equalTo(false));
+    }
+
+    @Test
+    public void ipPublishFilteringMatchingOr() {
+        Settings settings = shuffleSettings(Settings.settingsBuilder()
+                .put("xxx._publish_ip", "192.1.1.54")
+                .put("xxx.tag", "A")
+                .build());
+        DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
+
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
+        assertThat(filters.match(node), equalTo(true));
+    }
+
+    @Test
+    public void ipPublishFilteringNotMatchingOr() {
+        Settings settings = shuffleSettings(Settings.settingsBuilder()
+                .put("xxx.tag", "A")
+                .put("xxx._publish_ip", "8.8.8.8")
+                .build());
+        DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
+
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
+        assertThat(filters.match(node), equalTo(true));
+    }
+
+    private Settings shuffleSettings(Settings source) {
+        Settings.Builder settings = Settings.settingsBuilder();
+        List<String> keys = new ArrayList(source.getAsMap().keySet());
+        Collections.shuffle(keys, getRandom());
+        for (String o : keys) {
+            settings.put(o, source.getAsMap().get(o));
+        }
+        return settings.build();
+    }
+
+
 }
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/RoutingBackwardCompatibilityTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/RoutingBackwardCompatibilityTests.java
index 7a79497..a2dbf78 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/RoutingBackwardCompatibilityTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/RoutingBackwardCompatibilityTests.java
@@ -39,7 +39,7 @@ public class RoutingBackwardCompatibilityTests extends ESTestCase {
 
     public void testBackwardCompatibility() throws Exception {
         Path baseDir = createTempDir();
-        Node node = new Node(Settings.builder().put("path.home", baseDir.toString()).build(), false);
+        Node node = new Node(Settings.builder().put("path.home", baseDir.toString()).build());
         try {
             try (BufferedReader reader = new BufferedReader(new InputStreamReader(RoutingBackwardCompatibilityTests.class.getResourceAsStream("/org/elasticsearch/cluster/routing/shard_routes.txt"), "UTF-8"))) {
                 for (String line = reader.readLine(); line != null; line = reader.readLine()) {
diff --git a/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java b/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java
index 84a6610..3d4eaf9 100644
--- a/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java
+++ b/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java
@@ -18,12 +18,7 @@
  */
 package org.elasticsearch.common.inject;
 
-import org.elasticsearch.common.inject.spi.Element;
-import org.elasticsearch.common.inject.spi.Elements;
-import org.elasticsearch.common.inject.spi.InstanceBinding;
-import org.elasticsearch.common.inject.spi.LinkedKeyBinding;
-import org.elasticsearch.common.inject.spi.ProviderInstanceBinding;
-import org.elasticsearch.common.inject.spi.ProviderLookup;
+import org.elasticsearch.common.inject.spi.*;
 import org.elasticsearch.test.ESTestCase;
 
 import java.lang.annotation.Annotation;
@@ -45,11 +40,17 @@ public abstract class ModuleTestCase extends ESTestCase {
         List<Element> elements = Elements.getElements(module);
         for (Element element : elements) {
             if (element instanceof LinkedKeyBinding) {
-                LinkedKeyBinding binding = (LinkedKeyBinding)element;
+                LinkedKeyBinding binding = (LinkedKeyBinding) element;
                 if (to.equals(binding.getKey().getTypeLiteral().getType())) {
                     assertSame(clazz, binding.getLinkedKey().getTypeLiteral().getType());
                     return;
                 }
+            } else if (element instanceof UntargettedBinding) {
+                UntargettedBinding binding = (UntargettedBinding) element;
+                if (to.equals(binding.getKey().getTypeLiteral().getType())) {
+                    assertSame(clazz, to);
+                    return;
+                }
             }
         }
         StringBuilder s = new StringBuilder();
@@ -88,12 +89,12 @@ public abstract class ModuleTestCase extends ESTestCase {
         boolean providerFound = false;
         for (Element element : elements) {
             if (element instanceof LinkedKeyBinding) {
-                LinkedKeyBinding binding = (LinkedKeyBinding)element;
+                LinkedKeyBinding binding = (LinkedKeyBinding) element;
                 if (to.equals(binding.getKey().getTypeLiteral().getType())) {
                     bindings.add(binding.getLinkedKey().getTypeLiteral().getType());
                 }
             } else if (element instanceof ProviderInstanceBinding) {
-                ProviderInstanceBinding binding = (ProviderInstanceBinding)element;
+                ProviderInstanceBinding binding = (ProviderInstanceBinding) element;
                 String setType = binding.getKey().getTypeLiteral().getType().toString();
                 if (setType.equals("java.util.Map<java.lang.String, " + to.getName() + ">")) {
                     providerFound = true;
@@ -108,7 +109,6 @@ public abstract class ModuleTestCase extends ESTestCase {
     }
 
 
-
     /**
      * Configures the module and checks a Set of the "to" class
      * is bound to "classes". There may be more classes bound
@@ -120,12 +120,12 @@ public abstract class ModuleTestCase extends ESTestCase {
         boolean providerFound = false;
         for (Element element : elements) {
             if (element instanceof LinkedKeyBinding) {
-                LinkedKeyBinding binding = (LinkedKeyBinding)element;
+                LinkedKeyBinding binding = (LinkedKeyBinding) element;
                 if (to.equals(binding.getKey().getTypeLiteral().getType())) {
                     bindings.add(binding.getLinkedKey().getTypeLiteral().getType());
                 }
             } else if (element instanceof ProviderInstanceBinding) {
-                ProviderInstanceBinding binding = (ProviderInstanceBinding)element;
+                ProviderInstanceBinding binding = (ProviderInstanceBinding) element;
                 String setType = binding.getKey().getTypeLiteral().getType().toString();
                 if (setType.equals("java.util.Set<" + to.getName() + ">")) {
                     providerFound = true;
@@ -178,23 +178,23 @@ public abstract class ModuleTestCase extends ESTestCase {
      * and that all of the "expected" values are bound.
      */
     @SuppressWarnings("unchecked")
-    public <K,V> void assertMapInstanceBinding(Module module, Class<K> keyType, Class<V> valueType, Map<K,V> expected) throws Exception {
+    public <K, V> void assertMapInstanceBinding(Module module, Class<K> keyType, Class<V> valueType, Map<K, V> expected) throws Exception {
         // this method is insane because java type erasure makes it incredibly difficult...
-        Map<K,Key> keys = new HashMap<>();
-        Map<Key,V> values = new HashMap<>();
+        Map<K, Key> keys = new HashMap<>();
+        Map<Key, V> values = new HashMap<>();
         List<Element> elements = Elements.getElements(module);
         for (Element element : elements) {
             if (element instanceof InstanceBinding) {
                 InstanceBinding binding = (InstanceBinding) element;
                 if (binding.getKey().getRawType().equals(valueType)) {
-                    values.put(binding.getKey(), (V)binding.getInstance());
+                    values.put(binding.getKey(), (V) binding.getInstance());
                 } else if (binding.getInstance() instanceof Map.Entry) {
-                    Map.Entry entry = (Map.Entry)binding.getInstance();
+                    Map.Entry entry = (Map.Entry) binding.getInstance();
                     Object key = entry.getKey();
                     Object providerValue = entry.getValue();
                     if (key.getClass().equals(keyType) && providerValue instanceof ProviderLookup.ProviderImpl) {
-                        ProviderLookup.ProviderImpl provider = (ProviderLookup.ProviderImpl)providerValue;
-                        keys.put((K)key, provider.getKey());
+                        ProviderLookup.ProviderImpl provider = (ProviderLookup.ProviderImpl) providerValue;
+                        keys.put((K) key, provider.getKey());
                     }
                 }
             }
diff --git a/core/src/test/java/org/elasticsearch/common/io/rootdir.properties b/core/src/test/java/org/elasticsearch/common/io/rootdir.properties
deleted file mode 100644
index d816feb..0000000
--- a/core/src/test/java/org/elasticsearch/common/io/rootdir.properties
+++ /dev/null
@@ -1 +0,0 @@
-copyappend.root.dir=${basedir}/src/test/resources/org/elasticsearch/common/io/copyappend
diff --git a/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java b/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java
index afc17ce..d313dd7 100644
--- a/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java
+++ b/core/src/test/java/org/elasticsearch/common/io/stream/BytesStreamsTests.java
@@ -26,7 +26,6 @@ import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
 import java.io.IOException;
-
 import java.util.Objects;
 
 import static org.hamcrest.Matchers.closeTo;
diff --git a/core/src/test/java/org/elasticsearch/common/settings/loader/indentation-settings.yml b/core/src/test/java/org/elasticsearch/common/settings/loader/indentation-settings.yml
deleted file mode 100644
index cd14c5f..0000000
--- a/core/src/test/java/org/elasticsearch/common/settings/loader/indentation-settings.yml
+++ /dev/null
@@ -1,10 +0,0 @@
- test1:
-   value1: value1
-   test2:
-     value2: value2
-     value3: 2
-   test3:
-     - test3-1
-     - test3-2
-test4:
-  value4: value4
diff --git a/core/src/test/java/org/elasticsearch/common/settings/loader/indentation-with-explicit-document-start-settings.yml b/core/src/test/java/org/elasticsearch/common/settings/loader/indentation-with-explicit-document-start-settings.yml
deleted file mode 100644
index e02a357..0000000
--- a/core/src/test/java/org/elasticsearch/common/settings/loader/indentation-with-explicit-document-start-settings.yml
+++ /dev/null
@@ -1,11 +0,0 @@
- test1:
-   value1: value1
-   test2:
-     value2: value2
-     value3: 2
-   test3:
-     - test3-1
-     - test3-2
----
-test4:
-  value4: value4
diff --git a/core/src/test/java/org/elasticsearch/common/settings/loader/test-settings.json b/core/src/test/java/org/elasticsearch/common/settings/loader/test-settings.json
deleted file mode 100644
index 7190648..0000000
--- a/core/src/test/java/org/elasticsearch/common/settings/loader/test-settings.json
+++ /dev/null
@@ -1,10 +0,0 @@
-{
-    test1:{
-        value1:"value1",
-        test2:{
-            value2:"value2",
-            value3:2
-        },
-        test3:["test3-1", "test3-2"]
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/common/settings/loader/test-settings.yml b/core/src/test/java/org/elasticsearch/common/settings/loader/test-settings.yml
deleted file mode 100644
index b533ae0..0000000
--- a/core/src/test/java/org/elasticsearch/common/settings/loader/test-settings.yml
+++ /dev/null
@@ -1,8 +0,0 @@
-test1:
-  value1: value1
-  test2:
-    value2: value2
-    value3: 2
-  test3:
-    - test3-1
-    - test3-2
diff --git a/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java b/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java
index 807b4a7..234e341 100644
--- a/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java
+++ b/core/src/test/java/org/elasticsearch/common/unit/FuzzinessTests.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.common.unit;
 
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.xcontent.XContent;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentType;
@@ -164,29 +162,4 @@ public class FuzzinessTests extends ESTestCase {
         }
     }
 
-    @Test
-    public void testSerialization() throws IOException {
-        Fuzziness fuzziness = Fuzziness.AUTO;
-        Fuzziness deserializedFuzziness = doSerializeRoundtrip(fuzziness);
-        assertEquals(fuzziness, deserializedFuzziness);
-
-        fuzziness = Fuzziness.fromEdits(randomIntBetween(0, 2));
-        deserializedFuzziness = doSerializeRoundtrip(fuzziness);
-        assertEquals(fuzziness, deserializedFuzziness);
-    }
-
-    @Test
-    public void testSerializationAuto() throws IOException {
-        Fuzziness fuzziness = Fuzziness.AUTO;
-        Fuzziness deserializedFuzziness = doSerializeRoundtrip(fuzziness);
-        assertEquals(fuzziness, deserializedFuzziness);
-        assertEquals(fuzziness.asInt(), deserializedFuzziness.asInt());
-    }
-
-    private static Fuzziness doSerializeRoundtrip(Fuzziness in) throws IOException {
-        BytesStreamOutput output = new BytesStreamOutput();
-        in.writeTo(output);
-        StreamInput streamInput = StreamInput.wrap(output.bytes());
-        return Fuzziness.readFuzzinessFrom(streamInput);
-    }
 }
diff --git a/core/src/test/java/org/elasticsearch/gateway/GatewayModuleTests.java b/core/src/test/java/org/elasticsearch/gateway/GatewayModuleTests.java
new file mode 100644
index 0000000..ffd5454
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/gateway/GatewayModuleTests.java
@@ -0,0 +1,48 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.gateway;
+
+import org.elasticsearch.cluster.ClusterName;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.inject.ModuleTestCase;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.env.NodeEnvironment;
+
+public class GatewayModuleTests extends ModuleTestCase {
+
+    public void testCustomGateway() {
+        GatewayModule gatewayModule = new GatewayModule(Settings.builder().put(GatewayModule.GATEWAY_TYPE_KEY, "mock").build());
+        gatewayModule.registerGatewayType("mock", MockGateway.class);
+        assertBinding(gatewayModule, Gateway.class, MockGateway.class);
+    }
+
+    public void testDefaultGateway() {
+        GatewayModule gatewayModule = new GatewayModule(Settings.EMPTY);
+        assertBinding(gatewayModule, Gateway.class, Gateway.class);
+    }
+
+    public static class MockGateway extends Gateway {
+
+        @Inject
+        public MockGateway(Settings settings, ClusterService clusterService, NodeEnvironment nodeEnv, GatewayMetaState metaState, TransportNodesListGatewayMetaState listGatewayMetaState, ClusterName clusterName) {
+            super(settings, clusterService, nodeEnv, metaState, listGatewayMetaState, clusterName);
+        }
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/gateway/GatewayTests.java b/core/src/test/java/org/elasticsearch/gateway/GatewayTests.java
new file mode 100644
index 0000000..8d29698
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/gateway/GatewayTests.java
@@ -0,0 +1,67 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.gateway;
+
+import org.elasticsearch.cluster.ClusterName;
+import org.elasticsearch.cluster.ClusterService;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.test.ESTestCase;
+import org.elasticsearch.test.cluster.TestClusterService;
+
+import java.util.HashMap;
+import java.util.Map;
+
+import static org.hamcrest.Matchers.equalTo;
+
+
+public class GatewayTests extends ESTestCase {
+
+    public void testCalcRequiredAllocations() {
+        MockGateway gateway = new MockGateway(Settings.EMPTY, new TestClusterService());
+        int nodeCount = randomIntBetween(1, 6);
+        Map<String, Integer> expectedResult = new HashMap<>();
+        expectedResult.put("quorum", nodeCount > 2 ? nodeCount / 2 + 1 : 1);
+        expectedResult.put("quorum-1", nodeCount > 2 ? (nodeCount + 1) / 2 : 1);
+        expectedResult.put("half", expectedResult.get("quorum-1"));
+        expectedResult.put("one", 1);
+        expectedResult.put("full", nodeCount);
+        expectedResult.put("all", nodeCount);
+        expectedResult.put("full-1", Math.max(1, nodeCount - 1));
+        expectedResult.put("all-1", Math.max(1, nodeCount - 1));
+        int i = randomIntBetween(1, 20);
+        expectedResult.put("" + i, i);
+        expectedResult.put(randomUnicodeOfCodepointLength(10), 1);
+        for (String setting : expectedResult.keySet()) {
+            assertThat("unexpected result for setting [" + setting + "]", gateway.calcRequiredAllocations(setting, nodeCount), equalTo(expectedResult.get(setting).intValue()));
+        }
+
+    }
+
+    static class MockGateway extends Gateway {
+
+        MockGateway(Settings settings, ClusterService clusterService) {
+            super(settings, clusterService, null, null, null, ClusterName.DEFAULT);
+        }
+
+        @Override
+        public int calcRequiredAllocations(String setting, int nodeCount) {
+            return super.calcRequiredAllocations(setting, nodeCount);
+        }
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/cjk_analysis.json b/core/src/test/java/org/elasticsearch/index/analysis/cjk_analysis.json
deleted file mode 100644
index 89a1281..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/cjk_analysis.json
+++ /dev/null
@@ -1,37 +0,0 @@
-{
-   "index":{
-      "analysis":{
-         "filter":{
-            "cjk_all_flags":{
-               "type":"cjk_bigram",
-               "output_unigrams":true,
-               "ignored_scripts":[
-                  "han",
-                  "hiragana",
-                  "katakana",
-                  "hangul",
-                  "foobar"
-               ]
-            },
-            "cjk_han_only":{
-               "type":"cjk_bigram",
-               "output_unigrams":false,
-               "ignored_scripts":[
-                  "hiragana"
-               ]
-            },
-            "cjk_han_unigram_only":{
-               "type":"cjk_bigram",
-               "output_unigrams":true,
-               "ignored_scripts":[
-                  "hiragana"
-               ]
-            },
-            "cjk_no_flags":{
-               "type":"cjk_bigram",
-               "output_unigrams":false
-            }
-         }
-      }
-   }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/commongrams/common_words.txt b/core/src/test/java/org/elasticsearch/index/analysis/commongrams/common_words.txt
deleted file mode 100644
index f97b799..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/commongrams/common_words.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-brown
-fox
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/commongrams/commongrams.json b/core/src/test/java/org/elasticsearch/index/analysis/commongrams/commongrams.json
deleted file mode 100644
index 377b403..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/commongrams/commongrams.json
+++ /dev/null
@@ -1,29 +0,0 @@
-{
-    "index":{
-        "analysis":{
-            "analyzer":{
-                "commongramsAnalyzer":{
-                    "tokenizer":"whitespace",
-                    "filter":[ "common_grams" ]
-                },
-                "commongramsAnalyzer_file":{
-                    "tokenizer":"whitespace",
-                    "filter":[ "common_grams_file" ]
-                }
-            },
-            "filter":{
-                "common_grams":{
-                    "type":"common_grams",
-                    "common_words":[
-                        "brown",
-                        "fox"
-                    ]
-                },
-                "common_grams_file":{
-                    "type":"common_grams",
-                    "common_words_path":"common_words.txt"
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/commongrams/commongrams_query_mode.json b/core/src/test/java/org/elasticsearch/index/analysis/commongrams/commongrams_query_mode.json
deleted file mode 100644
index 4151c46..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/commongrams/commongrams_query_mode.json
+++ /dev/null
@@ -1,31 +0,0 @@
-{
-    "index":{
-        "analysis":{
-            "analyzer":{
-                "commongramsAnalyzer":{
-                    "tokenizer":"whitespace",
-                    "filter":[ "common_grams" ]
-                },
-                "commongramsAnalyzer_file":{
-                    "tokenizer":"whitespace",
-                    "filter":[ "common_grams_file" ]
-                }
-            },
-            "filter":{
-                "common_grams":{
-                    "type":"common_grams",
-                    "query_mode" : true,
-                    "common_words":[
-                        "brown",
-                        "fox"
-                    ]
-                },
-                "common_grams_file":{
-                    "type":"common_grams",
-                    "query_mode" : true,
-                    "common_words_path":"common_words.txt"
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/keep_analysis.json b/core/src/test/java/org/elasticsearch/index/analysis/keep_analysis.json
deleted file mode 100644
index 233d6f3..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/keep_analysis.json
+++ /dev/null
@@ -1,19 +0,0 @@
-{
-    "index":{
-        "analysis":{
-            "filter":{
-                "my_keep_filter":{
-                    "type":"keep",
-                    "keep_words" : ["Hello", "worlD"],
-                    "keep_words_case" : true
-                },
-                "my_case_sensitive_keep_filter":{
-                    "type":"keep",
-                    "keep_words" : ["Hello", "worlD"],
-                    "enable_position_increments" : false,
-                    "version" : "4.2"
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/pattern_capture.json b/core/src/test/java/org/elasticsearch/index/analysis/pattern_capture.json
deleted file mode 100644
index d82fb98..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/pattern_capture.json
+++ /dev/null
@@ -1,46 +0,0 @@
-{
-   "index": {
-      "number_of_shards": 1,
-      "number_of_replicas": 0,
-      "analysis": {
-         "filter": {
-            "single": {
-               "type": "pattern_capture",
-               "patterns": "((...)...)"
-            },
-            "multi": {
-               "type": "pattern_capture",
-               "patterns": [
-                  "(\\d+)",
-                  "([a-z]+)"
-               ]
-            },
-            "preserve": {
-               "type": "pattern_capture",
-               "preserve_original": false,
-               "patterns": "((...)...)"
-            }
-         },
-         "analyzer": {
-            "single": {
-               "tokenizer": "keyword",
-               "filter": [
-                  "single"
-               ]
-            },
-            "multi": {
-               "tokenizer": "keyword",
-               "filter": [
-                  "multi"
-               ]
-            },
-            "preserve": {
-               "tokenizer": "keyword",
-               "filter": [
-                  "preserve"
-               ]
-            }
-         }
-      }
-   }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/shingle_analysis.json b/core/src/test/java/org/elasticsearch/index/analysis/shingle_analysis.json
deleted file mode 100644
index 33c09fe..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/shingle_analysis.json
+++ /dev/null
@@ -1,23 +0,0 @@
-{
-    "index":{
-        "analysis":{
-            "filter":{
-                "shingle_inverse":{
-                    "type":"shingle",
-                    "max_shingle_size" : 3,
-                    "min_shingle_size" : 3,
-                    "output_unigrams" : false,
-                    "output_unigrams_if_no_shingles" : true,
-                    "token_separator" : "_"
-                },
-                "shingle_filler":{
-                    "type":"shingle",
-                    "max_shingle_size" : 3,
-                    "min_shingle_size" : 2,
-                    "output_unigrams" : false,
-                    "filler_token" : "FILLER"
-                }
-            }            
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/stop.json b/core/src/test/java/org/elasticsearch/index/analysis/stop.json
deleted file mode 100644
index 717c9fd..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/stop.json
+++ /dev/null
@@ -1,18 +0,0 @@
-{
-    "index":{
-        "number_of_shards":1,
-        "number_of_replicas":0,
-        "analysis":{
-            "analyzer":{
-                "analyzer1":{
-                    "type":"stop",
-                    "stopwords":["_english_"]
-                },
-                "analyzer2":{
-                    "type":"stop",
-                    "stopwords":"_english_"
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/synonyms/synonyms.json b/core/src/test/java/org/elasticsearch/index/analysis/synonyms/synonyms.json
deleted file mode 100644
index fe5f4d4..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/synonyms/synonyms.json
+++ /dev/null
@@ -1,72 +0,0 @@
-{
-    "index":{
-        "analysis":{
-            "analyzer":{
-                "synonymAnalyzer":{
-                    "tokenizer":"standard",
-                    "filter":[ "synonym" ]
-                },
-                "synonymAnalyzer_file":{
-                    "tokenizer":"standard",
-                    "filter":[ "synonym_file" ]
-                },
-                "synonymAnalyzerWordnet":{
-                    "tokenizer":"standard",
-                    "filter":[ "synonymWordnet" ]
-                },
-                "synonymAnalyzerWordnet_file":{
-                    "tokenizer":"standard",
-                    "filter":[ "synonymWordnet_file" ]
-                },
-                "synonymAnalyzerWithsettings":{
-                    "tokenizer":"trigram",
-                    "filter":["synonymWithTokenizerSettings"]
-                }
-            },
-            "tokenizer":{
-                "trigram" : {
-                    "type" : "ngram",
-                    "min_gram" : 3,
-                    "max_gram" : 3
-                }
-            },
-            "filter":{
-                "synonym":{
-                    "type":"synonym",
-                    "synonyms":[
-                        "kimchy => shay",
-                        "dude => elasticsearch",
-                        "abides => man!"
-                    ]
-                },
-                "synonym_file":{
-                    "type":"synonym",
-                    "synonyms_path":"synonyms.txt"
-                },
-                "synonymWordnet":{
-                    "type":"synonym",
-                    "format":"wordnet",
-                    "synonyms":[
-                        "s(100000001,1,'abstain',v,1,0).",
-                        "s(100000001,2,'refrain',v,1,0).",
-                        "s(100000001,3,'desist',v,1,0)."
-                    ]
-                },
-                "synonymWordnet_file":{
-                    "type":"synonym",
-                    "format":"wordnet",
-                    "synonyms_path":"synonyms_wordnet.txt"
-                },
-                "synonymWithTokenizerSettings":{
-                    "type":"synonym",
-                    "synonyms":[
-                        "kimchy => shay"
-                    ],
-                    "tokenizer" : "trigram",
-                    "min_gram" : 3,
-                    "max_gram" : 3
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/synonyms/synonyms.txt b/core/src/test/java/org/elasticsearch/index/analysis/synonyms/synonyms.txt
deleted file mode 100644
index ef4b225..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/synonyms/synonyms.txt
+++ /dev/null
@@ -1,3 +0,0 @@
-kimchy => shay
-dude => elasticsearch
-abides => man!
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/synonyms/synonyms_wordnet.txt b/core/src/test/java/org/elasticsearch/index/analysis/synonyms/synonyms_wordnet.txt
deleted file mode 100644
index f7b68e3..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/synonyms/synonyms_wordnet.txt
+++ /dev/null
@@ -1,3 +0,0 @@
-s(100000001,1,'abstain',v,1,0).
-s(100000001,2,'refrain',v,1,0).
-s(100000001,3,'desist',v,1,0).
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/test1.json b/core/src/test/java/org/elasticsearch/index/analysis/test1.json
deleted file mode 100644
index 2434963..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/test1.json
+++ /dev/null
@@ -1,84 +0,0 @@
-{
-    "index":{
-        "analysis":{
-            "tokenizer":{
-                "standard":{
-                    "type":"standard"
-                }
-            },
-            "char_filter":{
-                "my_html":{
-                    "type":"html_strip",
-                    "escaped_tags":["xxx", "yyy"],
-                    "read_ahead":1024
-                },
-                "my_pattern":{
-                    "type":"pattern_replace",
-                    "pattern":"sample(.*)",
-                    "replacement":"replacedSample $1"
-                },
-                "my_mapping":{
-                    "type":"mapping",
-                    "mappings":["ph=>f", "qu=>q"]
-                }
-            },
-            "filter":{
-                "stop":{
-                    "type":"stop",
-                    "stopwords":["test-stop"]
-                },
-                "stop2":{
-                    "type":"stop",
-                    "stopwords":["stop2-1", "stop2-2"]
-                },
-                "my":{
-                    "type":"myfilter"
-                },
-                "dict_dec":{
-                    "type":"dictionary_decompounder",
-                    "word_list":["donau", "dampf", "schiff", "spargel", "creme", "suppe"]
-                }
-            },
-            "analyzer":{
-                "standard":{
-                    "alias":"alias1,alias2",
-                    "type":"standard",
-                    "stopwords":["test1", "test2", "test3"]
-                },
-                "custom1":{
-                    "alias":["alias4", "alias5"],
-                    "tokenizer":"standard",
-                    "filter":["stop", "stop2"]
-                },
-                "custom2":{
-                    "tokenizer":"standard",
-                    "char_filter":["html_strip", "my_html"]
-                },
-                "custom3":{
-                    "tokenizer":"standard",
-                    "char_filter":["my_pattern"]
-                },
-                "custom4":{
-                    "tokenizer":"standard",
-                    "filter":["my"]
-                },
-                "custom5":{
-                    "tokenizer":"standard",
-                    "char_filter":["my_mapping"]
-                },
-                "custom6":{
-                    "tokenizer":"standard",
-                    "position_increment_gap": 256
-                },
-                "czechAnalyzerWithStemmer":{
-                    "tokenizer":"standard",
-                    "filter":["standard", "lowercase", "stop", "czech_stem"]
-                },
-                "decompoundingAnalyzer":{
-                    "tokenizer":"standard",
-                    "filter":["dict_dec"]
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/analysis/test1.yml b/core/src/test/java/org/elasticsearch/index/analysis/test1.yml
deleted file mode 100644
index 196e4ef..0000000
--- a/core/src/test/java/org/elasticsearch/index/analysis/test1.yml
+++ /dev/null
@@ -1,62 +0,0 @@
-index :
-  analysis :
-    tokenizer :
-      standard :
-        type : standard
-    char_filter :
-      my_html :
-        type : html_strip
-        escaped_tags : [xxx, yyy]
-        read_ahead : 1024
-      my_pattern :
-        type: pattern_replace
-        pattern: sample(.*)
-        replacement: replacedSample $1
-      my_mapping :
-        type : mapping
-        mappings : [ph=>f, qu=>q]
-    filter :
-      stop :
-        type : stop
-        stopwords : [test-stop]
-      stop2 :
-        type : stop
-        stopwords : [stop2-1, stop2-2]
-      my :
-        type : myfilter
-      dict_dec :
-        type : dictionary_decompounder
-        word_list : [donau, dampf, schiff, spargel, creme, suppe]
-    analyzer :
-      standard :
-        alias: alias1,alias2
-        type : standard
-        stopwords : [test1, test2, test3]
-      custom1 :
-        alias : [alias4, alias5]
-        tokenizer : standard
-        filter : [stop, stop2]
-      custom2 :
-        tokenizer : standard
-        char_filter : [html_strip, my_html]
-      custom3 :
-        tokenizer : standard
-        char_filter : [my_pattern]
-      custom4 :
-        tokenizer : standard
-        filter : [my]
-      custom5 :
-        tokenizer : standard
-        char_filter : [my_mapping]
-      custom6 :
-        tokenizer : standard
-        position_increment_gap: 256
-      custom7 :
-        type : standard
-        version: 3.6
-      czechAnalyzerWithStemmer :
-        tokenizer : standard
-        filter : [standard, lowercase, stop, czech_stem]
-      decompoundingAnalyzer :
-        tokenizer : standard
-        filter : [dict_dec]
diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
index deebc45..5a1efd1 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
@@ -41,6 +41,7 @@ import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.TestUtil;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.Version;
+import org.elasticsearch.action.support.TransportActions;
 import org.elasticsearch.bwcompat.OldIndexBackwardsCompatibilityIT;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.Base64;
@@ -92,8 +93,12 @@ import java.nio.file.DirectoryStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.util.*;
+import java.util.concurrent.BrokenBarrierException;
 import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.CyclicBarrier;
+import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicReference;
 import java.util.regex.Pattern;
 
 import static org.elasticsearch.common.settings.Settings.Builder.EMPTY_SETTINGS;
@@ -520,6 +525,45 @@ public class InternalEngineTests extends ESTestCase {
     }
 
     @Test
+    /* */
+    public void testConcurrentGetAndFlush() throws Exception {
+        ParsedDocument doc = testParsedDocument("1", "1", "test", null, -1, -1, testDocumentWithTextField(), B_1, null);
+        engine.create(new Engine.Create(newUid("1"), doc));
+
+        final AtomicReference<Engine.GetResult> latestGetResult = new AtomicReference<>();
+        latestGetResult.set(engine.get(new Engine.Get(true, newUid("1"))));
+        final AtomicBoolean flushFinished = new AtomicBoolean(false);
+        final CyclicBarrier barrier = new CyclicBarrier(2);
+        Thread getThread = new Thread() {
+            @Override
+            public void run() {
+                try {
+                    barrier.await();
+                } catch (InterruptedException | BrokenBarrierException e) {
+                    throw new RuntimeException(e);
+                }
+                while (flushFinished.get() == false) {
+                    Engine.GetResult previousGetResult = latestGetResult.get();
+                    if (previousGetResult != null) {
+                        previousGetResult.release();
+                    }
+                    latestGetResult.set(engine.get(new Engine.Get(true, newUid("1"))));
+                    if (latestGetResult.get().exists() == false) {
+                        break;
+                    }
+                }
+            }
+        };
+        getThread.start();
+        barrier.await();
+        engine.flush();
+        flushFinished.set(true);
+        getThread.join();
+        assertTrue(latestGetResult.get().exists());
+        latestGetResult.get().release();
+    }
+
+    @Test
     public void testSimpleOperations() throws Exception {
         Engine.Searcher searchResult = engine.acquireSearcher("test");
         MatcherAssert.assertThat(searchResult, EngineSearcherTotalHitsMatcher.engineSearcherTotalHits(0));
@@ -1000,8 +1044,7 @@ public class InternalEngineTests extends ESTestCase {
                                 indexed.countDown();
                                 try {
                                     engine.forceMerge(randomBoolean(), 1, false, randomBoolean(), randomBoolean());
-                                } catch (ForceMergeFailedEngineException ex) {
-                                    // ok
+                                } catch (IOException e) {
                                     return;
                                 }
                             }
@@ -2019,4 +2062,42 @@ public class InternalEngineTests extends ESTestCase {
             assertThat(topDocs.totalHits, equalTo(numDocs));
         }
     }
+
+    public void testShardNotAvailableExceptionWhenEngineClosedConcurrently() throws IOException, InterruptedException {
+        AtomicReference<Throwable> throwable = new AtomicReference<>();
+        String operation = randomFrom("optimize", "refresh", "flush");
+        Thread mergeThread = new Thread() {
+            @Override
+            public void run() {
+                boolean stop = false;
+                logger.info("try with {}", operation);
+                while (stop == false) {
+                    try {
+                        switch (operation) {
+                            case "optimize": {
+                                engine.forceMerge(true, 1, false, false, false);
+                                break;
+                            }
+                            case "refresh": {
+                                engine.refresh("test refresh");
+                                break;
+                            }
+                            case "flush": {
+                                engine.flush(true, false);
+                                break;
+                            }
+                        }
+                    } catch (Throwable t) {
+                        throwable.set(t);
+                        stop = true;
+                    }
+                }
+            }
+        };
+        mergeThread.start();
+        engine.close();
+        mergeThread.join();
+        logger.info("exception caught: ", throwable.get());
+        assertTrue("expected an Exception that signals shard is not available", TransportActions.isShardNotAvailableException(throwable.get()));
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/index/fielddata/AbstractFieldDataTestCase.java b/core/src/test/java/org/elasticsearch/index/fielddata/AbstractFieldDataTestCase.java
index d42c86c..5980688 100644
--- a/core/src/test/java/org/elasticsearch/index/fielddata/AbstractFieldDataTestCase.java
+++ b/core/src/test/java/org/elasticsearch/index/fielddata/AbstractFieldDataTestCase.java
@@ -88,7 +88,7 @@ public abstract class AbstractFieldDataTestCase extends ESSingleNodeTestCase {
         } else if (type.getType().equals("geo_point")) {
             fieldType = MapperBuilders.geoPointField(fieldName).docValues(docValues).fieldDataSettings(type.getSettings()).build(context).fieldType();
         } else if (type.getType().equals("_parent")) {
-            fieldType = new ParentFieldMapper.Builder().type(fieldName).build(context).fieldType();
+            fieldType = new ParentFieldMapper.Builder("_type").type(fieldName).build(context).fieldType();
         } else if (type.getType().equals("binary")) {
             fieldType = MapperBuilders.binaryField(fieldName).docValues(docValues).fieldDataSettings(type.getSettings()).build(context).fieldType();
         } else {
diff --git a/core/src/test/java/org/elasticsearch/index/fielddata/plain/ParentChildFilteredTermsEnumTests.java b/core/src/test/java/org/elasticsearch/index/fielddata/plain/ParentChildFilteredTermsEnumTests.java
deleted file mode 100644
index 488aca2..0000000
--- a/core/src/test/java/org/elasticsearch/index/fielddata/plain/ParentChildFilteredTermsEnumTests.java
+++ /dev/null
@@ -1,120 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.fielddata.plain;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.*;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.test.ESTestCase;
-import org.junit.Test;
-
-import java.util.Locale;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.core.IsNull.notNullValue;
-
-/**
- */
-public class ParentChildFilteredTermsEnumTests extends ESTestCase {
-
-    @Test
-    public void testSimple_twoFieldEachUniqueValue() throws Exception {
-        Directory directory = newDirectory();
-        RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory);
-        for (int i = 1; i <= 10000; i++) {
-            Document document = new Document();
-            String fieldName = i % 2 == 0 ? "field1" : "field2";
-            document.add(new StringField(fieldName, format(i), Field.Store.NO));
-            indexWriter.addDocument(document);
-        }
-
-        IndexReader indexReader = DirectoryReader.open(indexWriter.w, false);
-        TermsEnum[] compoundTermsEnums = new TermsEnum[]{
-                new ParentChildIntersectTermsEnum(SlowCompositeReaderWrapper.wrap(indexReader), "field1", "field2")
-        };
-        for (TermsEnum termsEnum : compoundTermsEnums) {
-            int expected = 0;
-            for (BytesRef term = termsEnum.next(); term != null; term = termsEnum.next()) {
-                ++expected;
-                assertThat(term.utf8ToString(), equalTo(format(expected)));
-                PostingsEnum docsEnum = termsEnum.postings(null);
-                assertThat(docsEnum, notNullValue());
-                int docId = docsEnum.nextDoc();
-                assertThat(docId, not(equalTo(-1)));
-                assertThat(docId, not(equalTo(DocIdSetIterator.NO_MORE_DOCS)));
-                assertThat(docsEnum.nextDoc(), equalTo(DocIdSetIterator.NO_MORE_DOCS));
-            }
-        }
-
-        indexWriter.close();
-        indexReader.close();
-        directory.close();
-    }
-
-    @Test
-    public void testDocument_twoFieldsEachSharingValues() throws Exception {
-        Directory directory = newDirectory();
-        RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory);
-        for (int i = 1; i <= 1000; i++) {
-            Document document = new Document();
-            document.add(new StringField("field1", format(i), Field.Store.NO));
-            indexWriter.addDocument(document);
-
-            for (int j = 0; j < 10; j++) {
-                document = new Document();
-                document.add(new StringField("field2", format(i), Field.Store.NO));
-                indexWriter.addDocument(document);
-            }
-        }
-
-        IndexReader indexReader = DirectoryReader.open(indexWriter.w, false);
-        TermsEnum[] compoundTermsEnums = new TermsEnum[]{
-                new ParentChildIntersectTermsEnum(SlowCompositeReaderWrapper.wrap(indexReader), "field1", "field2")
-        };
-        for (TermsEnum termsEnum : compoundTermsEnums) {
-            int expected = 0;
-            for (BytesRef term = termsEnum.next(); term != null; term = termsEnum.next()) {
-                ++expected;
-                assertThat(term.utf8ToString(), equalTo(format(expected)));
-                PostingsEnum docsEnum = termsEnum.postings(null);
-                assertThat(docsEnum, notNullValue());
-                int numDocs = 0;
-                for (int docId = docsEnum.nextDoc(); docId != DocIdSetIterator.NO_MORE_DOCS; docId = docsEnum.nextDoc()) {
-                    numDocs++;
-                }
-                assertThat(numDocs, equalTo(11));
-            }
-        }
-
-
-        indexWriter.close();
-        indexReader.close();
-        directory.close();
-    }
-
-    static String format(int i) {
-        return String.format(Locale.ROOT, "%06d", i);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/all/mapping.json
deleted file mode 100644
index f956b84..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/mapping.json
+++ /dev/null
@@ -1,56 +0,0 @@
-{
-    "person":{
-        "_all":{
-            "enabled":true,
-            "omit_norms":true
-        },
-        "properties":{
-            "name":{
-                "type":"object",
-                "dynamic":false,
-                "properties":{
-                    "first":{
-                        "type":"string",
-                        "store":"yes",
-                        "include_in_all":false
-                    },
-                    "last":{
-                        "type":"string",
-                        "index":"not_analyzed",
-                        "boost":2.0
-                    }
-                }
-            },
-            "address":{
-                "type":"object",
-                "include_in_all":false,
-                "properties":{
-                    "first":{
-                        "properties":{
-                            "location":{
-                                "type":"string",
-                                "store":"yes"
-                            }
-                        }
-                    },
-                    "last":{
-                        "properties":{
-                            "location":{
-                                "type":"string",
-                                "include_in_all":true
-                            }
-                        }
-                    }
-                }
-            },
-            "simple1":{
-                "type":"long",
-                "include_in_all":true
-            },
-            "simple2":{
-                "type":"long",
-                "include_in_all":false
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/mapping_boost_omit_positions_on_all.json b/core/src/test/java/org/elasticsearch/index/mapper/all/mapping_boost_omit_positions_on_all.json
deleted file mode 100644
index 452ef9f..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/mapping_boost_omit_positions_on_all.json
+++ /dev/null
@@ -1,56 +0,0 @@
-{
-    "person":{
-        "_all":{
-            "enabled": true ,
-            "index_options" : "freqs"
-        },
-        "properties":{
-            "name":{
-                "type":"object",
-                "dynamic":false,
-                "properties":{
-                    "first":{
-                        "type":"string",
-                        "store":"yes",
-                        "include_in_all":false
-                    },
-                    "last":{
-                        "type":"string",
-                        "index":"not_analyzed",
-			"boost": 2.0
-                    }
-                }
-            },
-            "address":{
-                "type":"object",
-                "include_in_all":false,
-                "properties":{
-                    "first":{
-                        "properties":{
-                            "location":{
-                                "type":"string",
-                                "store":"yes"
-                            }
-                        }
-                    },
-                    "last":{
-                        "properties":{
-                            "location":{
-                                "type":"string",
-                                "include_in_all":true
-                            }
-                        }
-                    }
-                }
-            },
-            "simple1":{
-                "type":"long",
-                "include_in_all":true
-            },
-            "simple2":{
-                "type":"long",
-                "include_in_all":false
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/mapping_offsets_on_all.json b/core/src/test/java/org/elasticsearch/index/mapper/all/mapping_offsets_on_all.json
deleted file mode 100644
index f6b0699..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/mapping_offsets_on_all.json
+++ /dev/null
@@ -1,56 +0,0 @@
-{
-    "person":{
-        "_all":{
-            "enabled": true ,
-            "index_options" : "offsets"
-        },
-        "properties":{
-            "name":{
-                "type":"object",
-                "dynamic":false,
-                "properties":{
-                    "first":{
-                        "type":"string",
-                        "store":"yes",
-                        "include_in_all":false
-                    },
-                    "last":{
-                        "type":"string",
-                        "index":"not_analyzed",
-			"boost": 2.0
-                    }
-                }
-            },
-            "address":{
-                "type":"object",
-                "include_in_all":false,
-                "properties":{
-                    "first":{
-                        "properties":{
-                            "location":{
-                                "type":"string",
-                                "store":"yes"
-                            }
-                        }
-                    },
-                    "last":{
-                        "properties":{
-                            "location":{
-                                "type":"string",
-                                "include_in_all":true
-                            }
-                        }
-                    }
-                }
-            },
-            "simple1":{
-                "type":"long",
-                "include_in_all":true
-            },
-            "simple2":{
-                "type":"long",
-                "include_in_all":false
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/mapping_omit_positions_on_all.json b/core/src/test/java/org/elasticsearch/index/mapper/all/mapping_omit_positions_on_all.json
deleted file mode 100644
index f8e418c..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/mapping_omit_positions_on_all.json
+++ /dev/null
@@ -1,55 +0,0 @@
-{
-    "person":{
-        "_all":{
-            "enabled": true ,
-            "index_options" : "freqs"
-        },
-        "properties":{
-            "name":{
-                "type":"object",
-                "dynamic":false,
-                "properties":{
-                    "first":{
-                        "type":"string",
-                        "store":"yes",
-                        "include_in_all":false
-                    },
-                    "last":{
-                        "type":"string",
-                        "index":"not_analyzed"
-                    }
-                }
-            },
-            "address":{
-                "type":"object",
-                "include_in_all":false,
-                "properties":{
-                    "first":{
-                        "properties":{
-                            "location":{
-                                "type":"string",
-                                "store":"yes"
-                            }
-                        }
-                    },
-                    "last":{
-                        "properties":{
-                            "location":{
-                                "type":"string",
-                                "include_in_all":true
-                            }
-                        }
-                    }
-                }
-            },
-            "simple1":{
-                "type":"long",
-                "include_in_all":true
-            },
-            "simple2":{
-                "type":"long",
-                "include_in_all":false
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/misplaced_mapping_key_in_root.json b/core/src/test/java/org/elasticsearch/index/mapper/all/misplaced_mapping_key_in_root.json
deleted file mode 100644
index f08757a..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/misplaced_mapping_key_in_root.json
+++ /dev/null
@@ -1,11 +0,0 @@
-{
-    "mapping": {
-        "test": {
-            "properties": {
-                "foo": {
-                    "type": "string"
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/misplaced_type_in_root.json b/core/src/test/java/org/elasticsearch/index/mapper/all/misplaced_type_in_root.json
deleted file mode 100644
index f4b325c..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/misplaced_type_in_root.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "type": "string",
-    "properties": {
-        "foo": {
-            "type": "string"
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/mistyped_type_in_root.json b/core/src/test/java/org/elasticsearch/index/mapper/all/mistyped_type_in_root.json
deleted file mode 100644
index 19edf59..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/mistyped_type_in_root.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-    "testX": {
-        "properties": {
-            "foo": {
-                "type": "string"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/multifield-mapping_default.json b/core/src/test/java/org/elasticsearch/index/mapper/all/multifield-mapping_default.json
deleted file mode 100644
index 6a5f044..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/multifield-mapping_default.json
+++ /dev/null
@@ -1,21 +0,0 @@
-{
-    "test": {
-        "properties": {
-            "foo": {
-                "type": "nested",
-                "properties": {
-                    "bar": {
-                        "type": "string",
-                        "index": "not_analyzed",
-                        "fields": {
-                            "lower": {
-                                "analyzer": "standard",
-                                "type": "string"
-                            }
-                        }
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/multifield-mapping_include_in_all_set_to_false.json b/core/src/test/java/org/elasticsearch/index/mapper/all/multifield-mapping_include_in_all_set_to_false.json
deleted file mode 100644
index 5a0ad92..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/multifield-mapping_include_in_all_set_to_false.json
+++ /dev/null
@@ -1,23 +0,0 @@
-{
-    "test": {
-        "properties": {
-            "foo": {
-                "type": "nested",
-                "include_in_all": false,
-                "properties": {
-                    "bar": {
-                        "type": "string",
-                        "index": "not_analyzed",
-                        "include_in_all": false,
-                        "fields": {
-                            "lower": {
-                                "analyzer": "standard",
-                                "type": "string"
-                            }
-                        }
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/noboost-mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/all/noboost-mapping.json
deleted file mode 100644
index 799a3ab..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/noboost-mapping.json
+++ /dev/null
@@ -1,54 +0,0 @@
-{
-    "person":{
-        "_all":{
-            "enabled":true
-        },
-        "properties":{
-            "name":{
-                "type":"object",
-                "dynamic":false,
-                "properties":{
-                    "first":{
-                        "type":"string",
-                        "store":"yes",
-                        "include_in_all":false
-                    },
-                    "last":{
-                        "type":"string",
-                        "index":"not_analyzed"
-                    }
-                }
-            },
-            "address":{
-                "type":"object",
-                "include_in_all":false,
-                "properties":{
-                    "first":{
-                        "properties":{
-                            "location":{
-                                "type":"string",
-                                "store":"yes"
-                            }
-                        }
-                    },
-                    "last":{
-                        "properties":{
-                            "location":{
-                                "type":"string",
-                                "include_in_all":true
-                            }
-                        }
-                    }
-                }
-            },
-            "simple1":{
-                "type":"long",
-                "include_in_all":true
-            },
-            "simple2":{
-                "type":"long",
-                "include_in_all":false
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/store-mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/all/store-mapping.json
deleted file mode 100644
index 8f653a3..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/store-mapping.json
+++ /dev/null
@@ -1,55 +0,0 @@
-{
-    "person":{
-        "_all":{
-            "enabled":true,
-            "store":"yes"
-        },
-        "properties":{
-            "name":{
-                "type":"object",
-                "dynamic":false,
-                "properties":{
-                    "first":{
-                        "type":"string",
-                        "store":"yes",
-                        "include_in_all":false
-                    },
-                    "last":{
-                        "type":"string",
-                        "index":"not_analyzed",
-                        "boost":2.0
-                    }
-                }
-            },
-            "address":{
-                "type":"object",
-                "include_in_all":false,
-                "properties":{
-                    "first":{
-                        "properties":{
-                            "location":{
-                                "type":"string",
-                                "store":"yes"
-                            }
-                        }
-                    },
-                    "last":{
-                        "properties":{
-                            "location":{
-                                "type":"string"
-                            }
-                        }
-                    }
-                }
-            },
-            "simple1":{
-                "type":"long",
-                "include_in_all":true
-            },
-            "simple2":{
-                "type":"long",
-                "include_in_all":false
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/test1.json b/core/src/test/java/org/elasticsearch/index/mapper/all/test1.json
deleted file mode 100644
index 4437d3f..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/test1.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-    "name":{
-        "first":"shay",
-        "last":"banon"
-    },
-    "address":{
-        "first":{
-            "location":"first location"
-        },
-        "last":{
-            "location":"last location"
-        }
-    },
-    "simple1":1,
-    "simple2":2
-}
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/type_date_detection_mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/all/type_date_detection_mapping.json
deleted file mode 100644
index c2db712..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/type_date_detection_mapping.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "date_detection" : false,
-    "properties": {
-        "foo": {
-            "type": "string"
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/type_dynamic_date_formats_mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/all/type_dynamic_date_formats_mapping.json
deleted file mode 100644
index 7e6afd3..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/type_dynamic_date_formats_mapping.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "dynamic_date_formats" : ["yyyy-MM-dd", "dd-MM-yyyy"],
-    "properties": {
-        "foo": {
-            "type": "string"
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/type_dynamic_template_mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/all/type_dynamic_template_mapping.json
deleted file mode 100644
index b155fb7..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/type_dynamic_template_mapping.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-    "dynamic_templates" : [
-        {
-            "dynamic_template_name" : {
-                "match" : "*",
-                "mapping" : {
-                    "store" : true
-                }
-            }
-        }
-    ],
-    "properties": {
-        "foo": {
-            "type": "string"
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/type_numeric_detection_mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/all/type_numeric_detection_mapping.json
deleted file mode 100644
index 4729354..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/type_numeric_detection_mapping.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "numeric_detection" : false,
-    "properties": {
-        "foo": {
-            "type": "string"
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-data.json b/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-data.json
deleted file mode 100644
index b7439dc..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-data.json
+++ /dev/null
@@ -1,4 +0,0 @@
-{
-    "name":"some name",
-    "age":1
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-mapping.json
deleted file mode 100644
index d99067c..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-mapping.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    "person":{
-        "dynamic_templates":[
-            {
-                "template_1":{
-                    "match":"*",
-                    "mapping":{
-                        "store":"yes"
-                    }
-                }
-            }
-        ]
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-data.json b/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-data.json
deleted file mode 100644
index 2e6ec99..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-data.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    "name":"top_level",
-    "obj1":{
-        "name":"obj1_level",
-        "obj2":{
-            "name":"obj2_level"
-        }
-    },
-    "obj3":{
-        "obj4":{
-            "prop1":"prop1_value"
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-mapping.json
deleted file mode 100644
index dce33da..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-mapping.json
+++ /dev/null
@@ -1,30 +0,0 @@
-{
-    "person":{
-        "dynamic_templates":[
-            {
-                "template_1":{
-                    "path_match":"obj1.obj2.*",
-                    "mapping":{
-                        "store":"no"
-                    }
-                }
-            },
-            {
-                "template_2":{
-                    "path_match":"obj1.*",
-                    "mapping":{
-                        "store":"yes"
-                    }
-                }
-            },
-            {
-                "template_3":{
-                    "path_match":"*.obj4.*",
-                    "mapping":{
-                        "type":"string"
-                    }
-                }
-            }
-        ]
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/simple/test-data.json b/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/simple/test-data.json
deleted file mode 100644
index 1ed3c50..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/simple/test-data.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{
-    "name":"some name",
-    "age":1,
-    "multi1":"multi 1",
-    "multi2":"multi 2"
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/simple/test-mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/simple/test-mapping.json
deleted file mode 100644
index 9c8f8d8..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/dynamictemplate/simple/test-mapping.json
+++ /dev/null
@@ -1,33 +0,0 @@
-{
-    "person":{
-        "dynamic_templates":[
-            {
-                "tempalte_1":{
-                    "match":"multi*",
-                    "mapping":{
-                        "type":"{dynamic_type}",
-                        "index":"analyzed",
-                        "store":"yes",
-                        "fields":{
-                            "org":{
-                                "type":"{dynamic_type}",
-                                "index":"not_analyzed",
-                                "store":"yes"
-                            }
-                        }
-                    }
-                }
-            },
-            {
-                "template_2":{
-                    "match":"*",
-                    "match_mapping_type":"string",
-                    "mapping":{
-                        "type":"string",
-                        "index":"not_analyzed"
-                    }
-                }
-            }
-        ]
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapperTests.java b/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapperTests.java
index b7161c3..2fe5978 100644
--- a/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapperTests.java
+++ b/core/src/test/java/org/elasticsearch/index/mapper/geo/GeoShapeFieldMapperTests.java
@@ -168,6 +168,7 @@ public class GeoShapeFieldMapperTests extends ESSingleNodeTestCase {
                     .field("tree", "quadtree")
                     .field("tree_levels", "6")
                     .field("distance_error_pct", "0.5")
+                    .field("points_only", true)
                 .endObject().endObject()
                 .endObject().endObject().string();
 
@@ -181,6 +182,7 @@ public class GeoShapeFieldMapperTests extends ESSingleNodeTestCase {
         assertThat(strategy.getDistErrPct(), equalTo(0.5));
         assertThat(strategy.getGrid(), instanceOf(QuadPrefixTree.class));
         assertThat(strategy.getGrid().getMaxLevels(), equalTo(6));
+        assertThat(strategy.isPointsOnly(), equalTo(true));
     }
     
     @Test
@@ -308,7 +310,28 @@ public class GeoShapeFieldMapperTests extends ESSingleNodeTestCase {
             assertThat(strategy.getGrid().getMaxLevels(), equalTo(GeoUtils.quadTreeLevelsForPrecision(70d)+1)); 
         }
     }
-    
+
+    @Test
+    public void testPointsOnlyOption() throws IOException {
+        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type1")
+                .startObject("properties").startObject("location")
+                .field("type", "geo_shape")
+                .field("tree", "geohash")
+                .field("points_only", true)
+                .endObject().endObject()
+                .endObject().endObject().string();
+
+        DocumentMapper defaultMapper = createIndex("test").mapperService().documentMapperParser().parse(mapping);
+        FieldMapper fieldMapper = defaultMapper.mappers().getMapper("location");
+        assertThat(fieldMapper, instanceOf(GeoShapeFieldMapper.class));
+
+        GeoShapeFieldMapper geoShapeFieldMapper = (GeoShapeFieldMapper) fieldMapper;
+        PrefixTreeStrategy strategy = geoShapeFieldMapper.fieldType().defaultStrategy();
+
+        assertThat(strategy.getGrid(), instanceOf(GeohashPrefixTree.class));
+        assertThat(strategy.isPointsOnly(), equalTo(true));
+    }
+
     @Test
     public void testLevelDefaults() throws IOException {
         DocumentMapperParser parser = createIndex("test").mapperService().documentMapperParser();
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/internal/ParentFieldMapperTests.java b/core/src/test/java/org/elasticsearch/index/mapper/internal/ParentFieldMapperTests.java
new file mode 100644
index 0000000..b094c1f
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/mapper/internal/ParentFieldMapperTests.java
@@ -0,0 +1,158 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.index.mapper.internal;
+
+import org.apache.lucene.index.DocValuesType;
+import org.elasticsearch.Version;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.index.fielddata.FieldDataType;
+import org.elasticsearch.index.mapper.ContentPath;
+import org.elasticsearch.index.mapper.MappedFieldType.Loading;
+import org.elasticsearch.index.mapper.Mapper;
+import org.elasticsearch.test.ESTestCase;
+
+import static org.elasticsearch.common.settings.Settings.settingsBuilder;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.is;
+import static org.hamcrest.Matchers.nullValue;
+
+public class ParentFieldMapperTests extends ESTestCase {
+
+    public void testPost2Dot0LazyLoading() {
+        ParentFieldMapper.Builder builder = new ParentFieldMapper.Builder("child");
+        builder.type("parent");
+        builder.fieldDataSettings(createFDSettings(Loading.LAZY));
+
+        ParentFieldMapper parentFieldMapper = builder.build(new Mapper.BuilderContext(post2Dot0IndexSettings(), new ContentPath(0)));
+
+        assertThat(parentFieldMapper.getParentJoinFieldType().names().indexName(), equalTo("_parent#child"));
+        assertThat(parentFieldMapper.getParentJoinFieldType().fieldDataType(), nullValue());
+        assertThat(parentFieldMapper.getParentJoinFieldType().hasDocValues(), is(true));
+        assertThat(parentFieldMapper.getParentJoinFieldType().docValuesType(), equalTo(DocValuesType.SORTED));
+
+        assertThat(parentFieldMapper.getChildJoinFieldType().names().indexName(), equalTo("_parent#parent"));
+        assertThat(parentFieldMapper.getChildJoinFieldType().fieldDataType().getLoading(), equalTo(Loading.LAZY));
+        assertThat(parentFieldMapper.getChildJoinFieldType().hasDocValues(), is(true));
+        assertThat(parentFieldMapper.getChildJoinFieldType().docValuesType(), equalTo(DocValuesType.SORTED));
+    }
+
+    public void testPost2Dot0EagerLoading() {
+        ParentFieldMapper.Builder builder = new ParentFieldMapper.Builder("child");
+        builder.type("parent");
+        builder.fieldDataSettings(createFDSettings(Loading.EAGER));
+
+        ParentFieldMapper parentFieldMapper = builder.build(new Mapper.BuilderContext(post2Dot0IndexSettings(), new ContentPath(0)));
+
+        assertThat(parentFieldMapper.getParentJoinFieldType().names().indexName(), equalTo("_parent#child"));
+        assertThat(parentFieldMapper.getParentJoinFieldType().fieldDataType(), nullValue());
+        assertThat(parentFieldMapper.getParentJoinFieldType().hasDocValues(), is(true));
+        assertThat(parentFieldMapper.getParentJoinFieldType().docValuesType(), equalTo(DocValuesType.SORTED));
+
+        assertThat(parentFieldMapper.getChildJoinFieldType().names().indexName(), equalTo("_parent#parent"));
+        assertThat(parentFieldMapper.getChildJoinFieldType().fieldDataType().getLoading(), equalTo(Loading.EAGER));
+        assertThat(parentFieldMapper.getChildJoinFieldType().hasDocValues(), is(true));
+        assertThat(parentFieldMapper.getChildJoinFieldType().docValuesType(), equalTo(DocValuesType.SORTED));
+    }
+
+    public void testPost2Dot0EagerGlobalOrdinalsLoading() {
+        ParentFieldMapper.Builder builder = new ParentFieldMapper.Builder("child");
+        builder.type("parent");
+        builder.fieldDataSettings(createFDSettings(Loading.EAGER_GLOBAL_ORDINALS));
+
+        ParentFieldMapper parentFieldMapper = builder.build(new Mapper.BuilderContext(post2Dot0IndexSettings(), new ContentPath(0)));
+
+        assertThat(parentFieldMapper.getParentJoinFieldType().names().indexName(), equalTo("_parent#child"));
+        assertThat(parentFieldMapper.getParentJoinFieldType().fieldDataType(), nullValue());
+        assertThat(parentFieldMapper.getParentJoinFieldType().hasDocValues(), is(true));
+        assertThat(parentFieldMapper.getParentJoinFieldType().docValuesType(), equalTo(DocValuesType.SORTED));
+
+        assertThat(parentFieldMapper.getChildJoinFieldType().names().indexName(), equalTo("_parent#parent"));
+        assertThat(parentFieldMapper.getChildJoinFieldType().fieldDataType().getLoading(), equalTo(Loading.EAGER_GLOBAL_ORDINALS));
+        assertThat(parentFieldMapper.getChildJoinFieldType().hasDocValues(), is(true));
+        assertThat(parentFieldMapper.getChildJoinFieldType().docValuesType(), equalTo(DocValuesType.SORTED));
+    }
+
+    public void testPre2Dot0LazyLoading() {
+        ParentFieldMapper.Builder builder = new ParentFieldMapper.Builder("child");
+        builder.type("parent");
+        builder.fieldDataSettings(createFDSettings(Loading.LAZY));
+
+        ParentFieldMapper parentFieldMapper = builder.build(new Mapper.BuilderContext(pre2Dot0IndexSettings(), new ContentPath(0)));
+
+        assertThat(parentFieldMapper.getParentJoinFieldType().names().indexName(), equalTo("_parent#child"));
+        assertThat(parentFieldMapper.getParentJoinFieldType().fieldDataType(), nullValue());
+        assertThat(parentFieldMapper.getParentJoinFieldType().hasDocValues(), is(false));
+        assertThat(parentFieldMapper.getParentJoinFieldType().docValuesType(), equalTo(DocValuesType.NONE));
+
+        assertThat(parentFieldMapper.getChildJoinFieldType().names().indexName(), equalTo("_parent#parent"));
+        assertThat(parentFieldMapper.getChildJoinFieldType().fieldDataType().getLoading(), equalTo(Loading.LAZY));
+        assertThat(parentFieldMapper.getChildJoinFieldType().hasDocValues(), is(false));
+        assertThat(parentFieldMapper.getChildJoinFieldType().docValuesType(), equalTo(DocValuesType.NONE));
+    }
+
+    public void testPre2Dot0EagerLoading() {
+        ParentFieldMapper.Builder builder = new ParentFieldMapper.Builder("child");
+        builder.type("parent");
+        builder.fieldDataSettings(createFDSettings(Loading.EAGER));
+
+        ParentFieldMapper parentFieldMapper = builder.build(new Mapper.BuilderContext(pre2Dot0IndexSettings(), new ContentPath(0)));
+
+        assertThat(parentFieldMapper.getParentJoinFieldType().names().indexName(), equalTo("_parent#child"));
+        assertThat(parentFieldMapper.getParentJoinFieldType().fieldDataType(), nullValue());
+        assertThat(parentFieldMapper.getParentJoinFieldType().hasDocValues(), is(false));
+        assertThat(parentFieldMapper.getParentJoinFieldType().docValuesType(), equalTo(DocValuesType.NONE));
+
+        assertThat(parentFieldMapper.getChildJoinFieldType().names().indexName(), equalTo("_parent#parent"));
+        assertThat(parentFieldMapper.getChildJoinFieldType().fieldDataType().getLoading(), equalTo(Loading.EAGER));
+        assertThat(parentFieldMapper.getChildJoinFieldType().hasDocValues(), is(false));
+        assertThat(parentFieldMapper.getChildJoinFieldType().docValuesType(), equalTo(DocValuesType.NONE));
+    }
+
+    public void testPre2Dot0EagerGlobalOrdinalsLoading() {
+        ParentFieldMapper.Builder builder = new ParentFieldMapper.Builder("child");
+        builder.type("parent");
+        builder.fieldDataSettings(createFDSettings(Loading.EAGER_GLOBAL_ORDINALS));
+
+        ParentFieldMapper parentFieldMapper = builder.build(new Mapper.BuilderContext(pre2Dot0IndexSettings(), new ContentPath(0)));
+
+        assertThat(parentFieldMapper.getParentJoinFieldType().names().indexName(), equalTo("_parent#child"));
+        assertThat(parentFieldMapper.getParentJoinFieldType().fieldDataType(), nullValue());
+        assertThat(parentFieldMapper.getParentJoinFieldType().hasDocValues(), is(false));
+        assertThat(parentFieldMapper.getParentJoinFieldType().docValuesType(), equalTo(DocValuesType.NONE));
+
+        assertThat(parentFieldMapper.getChildJoinFieldType().names().indexName(), equalTo("_parent#parent"));
+        assertThat(parentFieldMapper.getChildJoinFieldType().fieldDataType().getLoading(), equalTo(Loading.EAGER_GLOBAL_ORDINALS));
+        assertThat(parentFieldMapper.getChildJoinFieldType().hasDocValues(), is(false));
+        assertThat(parentFieldMapper.getChildJoinFieldType().docValuesType(), equalTo(DocValuesType.NONE));
+    }
+
+    private static Settings pre2Dot0IndexSettings() {
+        return Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_6_3).build();
+    }
+
+    private static Settings post2Dot0IndexSettings() {
+        return Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_2_1_0).build();
+    }
+
+    private static Settings createFDSettings(Loading loading) {
+        return new FieldDataType("child", settingsBuilder().put(Loading.KEY, loading)).getSettings();
+    }
+
+}
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-data.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-data.json
deleted file mode 100644
index c539fcc..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-data.json
+++ /dev/null
@@ -1,4 +0,0 @@
-{
-    _id:1,
-    name:"some name"
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping1.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping1.json
deleted file mode 100644
index 61f08af..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping1.json
+++ /dev/null
@@ -1,11 +0,0 @@
-{
-    person:{
-        properties:{
-            "name":{
-                type:"string",
-                index:"analyzed",
-                store:"yes"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping2.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping2.json
deleted file mode 100644
index 02ce895..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping2.json
+++ /dev/null
@@ -1,27 +0,0 @@
-{
-    "person" :{
-        "properties" :{
-            "name":{
-                "type" :"string",
-                "index" :"analyzed",
-                "store" :"yes",
-                "fields":{
-                    "name":{
-                        "type" :"string",
-                        "index" :"analyzed",
-                        "store" :"yes"
-                    },
-                    "indexed":{
-                        "type" :"string",
-                        "index" :"analyzed"
-                    },
-                    "not_indexed":{
-                        "type" :"string",
-                        "index" :"no",
-                        "store" :"yes"
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping3.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping3.json
deleted file mode 100644
index ea07675..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping3.json
+++ /dev/null
@@ -1,32 +0,0 @@
-{
-    "person" : {
-        "properties" :{
-            "name" : {
-                "type" : "string",
-                "index" : "analyzed",
-                "store" : "yes",
-                "fields": {
-                    "name" : {
-                        "type" : "string",
-                        "index" : "analyzed",
-                        "store" : "yes"
-                    },
-                    "indexed":{
-                        type:"string",
-                        index:"analyzed"
-                    },
-                    "not_indexed":{
-                        type:"string",
-                        index:"no",
-                        store:"yes"
-                    },
-                    "not_indexed2":{
-                        type:"string",
-                        index:"no",
-                        store:"yes"
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping4.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping4.json
deleted file mode 100644
index 384c263..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/test-mapping4.json
+++ /dev/null
@@ -1,18 +0,0 @@
-{
-    person:{
-        properties:{
-            "name":{
-                type:"string",
-                index:"analyzed",
-                store:"yes",
-                "fields":{
-                    "not_indexed3":{
-                        type:"string",
-                        index:"no",
-                        store:"yes"
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/upgrade1.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/upgrade1.json
deleted file mode 100644
index 6206592..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/upgrade1.json
+++ /dev/null
@@ -1,25 +0,0 @@
-{
-    person:{
-        properties:{
-            "name":{
-                type:"multi_field",
-                "fields":{
-                    "name":{
-                        type:"string",
-                        index:"analyzed",
-                        store:"yes"
-                    },
-                    "indexed":{
-                        type:"string",
-                        index:"analyzed"
-                    },
-                    "not_indexed":{
-                        type:"string",
-                        index:"no",
-                        store:"yes"
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/upgrade2.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/upgrade2.json
deleted file mode 100644
index 4a8fbf6..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/upgrade2.json
+++ /dev/null
@@ -1,30 +0,0 @@
-{
-    person:{
-        properties:{
-            "name":{
-                type:"multi_field",
-                "fields":{
-                    "name":{
-                        type:"string",
-                        index:"analyzed",
-                        store:"yes"
-                    },
-                    "indexed":{
-                        type:"string",
-                        index:"analyzed"
-                    },
-                    "not_indexed":{
-                        type:"string",
-                        index:"no",
-                        store:"yes"
-                    },
-                    "not_indexed2":{
-                        type:"string",
-                        index:"no",
-                        store:"yes"
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/upgrade3.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/upgrade3.json
deleted file mode 100644
index 9b30978..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/merge/upgrade3.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-    person:{
-        properties:{
-            "name":{
-                type:"multi_field",
-                "fields":{
-                    "not_indexed3":{
-                        type:"string",
-                        index:"no",
-                        store:"yes"
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-data.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-data.json
deleted file mode 100644
index 2e8ab25..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-data.json
+++ /dev/null
@@ -1,7 +0,0 @@
-{
-    "age":28,
-    "name":"some name",
-    "object1":{
-        "multi1":"2010-01-01"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type-completion.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type-completion.json
deleted file mode 100644
index d36e9d2..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type-completion.json
+++ /dev/null
@@ -1,30 +0,0 @@
-{
-  "type":{
-    "properties":{
-      "a":{
-        "type":"multi_field",
-        "fields":{
-          "a":{
-            "type":"string",
-            "index":"not_analyzed"
-          },
-          "b":{
-            "type":"completion"
-          }
-        }
-      },
-      "b":{
-        "type":"multi_field",
-        "fields":{
-          "a":{
-            "type":"string",
-            "index":"not_analyzed"
-          },
-          "b":{
-            "type":"completion"
-          }
-        }
-      }
-    }
-  }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type-geo_point.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type-geo_point.json
deleted file mode 100644
index c7d11be..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type-geo_point.json
+++ /dev/null
@@ -1,30 +0,0 @@
-{
-  "type":{
-    "properties":{
-      "a":{
-        "type":"multi_field",
-        "fields":{
-          "a":{
-            "type":"string",
-            "index":"not_analyzed"
-          },
-          "b":{
-            "type":"geo_point"
-          }
-        }
-      },
-      "b":{
-        "type":"multi_field",
-        "fields":{
-          "a":{
-            "type":"string",
-            "index":"not_analyzed"
-          },
-          "b":{
-            "type":"geo_point"
-          }
-        }
-      }
-    }
-  }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type-no-default-field.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type-no-default-field.json
deleted file mode 100644
index 99b74c0..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type-no-default-field.json
+++ /dev/null
@@ -1,32 +0,0 @@
-{
-  "person": {
-    "properties": {
-      "name": {
-        "type": "multi_field",
-        "fields": {
-          "indexed": {
-            "type": "string",
-            "index": "analyzed"
-          },
-          "not_indexed": {
-            "type": "string",
-            "index": "no",
-            "store": "yes"
-          }
-        }
-      },
-      "age": {
-        "type": "multi_field",
-        "fields": {
-          "not_stored": {
-            "type": "long"
-          },
-          "stored": {
-            "type": "long",
-            "store": "yes"
-          }
-        }
-      }
-    }
-  }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type.json
deleted file mode 100644
index b099b9a..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-field-type.json
+++ /dev/null
@@ -1,55 +0,0 @@
-{
-    "person":{
-        "properties":{
-            "name":{
-                "type":"multi_field",
-                "fields":{
-                    "name":{
-                        "type":"string",
-                        "index":"analyzed",
-                        "store":"yes"
-                    },
-                    "indexed":{
-                        "type":"string",
-                        "index":"analyzed"
-                    },
-                    "not_indexed":{
-                        "type":"string",
-                        "index":"no",
-                        "store":"yes"
-                    },
-                    "test1" : {
-                        "type":"string",
-                        "index":"analyzed",
-                        "store" : "yes",
-                        "fielddata" : {
-                            "loading" : "eager"
-                        }
-                    },
-                    "test2" : {
-                        "type" : "token_count",
-                        "store" : "yes",
-                        "index" : "not_analyzed",
-                        "analyzer" : "simple"
-                    }
-                }
-            },
-            "object1":{
-                "properties":{
-                    "multi1":{
-                        "type":"multi_field",
-                        "fields":{
-                            "multi1":{
-                                "type":"date"
-                            },
-                            "string":{
-                                "type":"string",
-                                "index":"not_analyzed"
-                            }
-                        }
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-fields.json b/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-fields.json
deleted file mode 100644
index b116665..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/multifield/test-multi-fields.json
+++ /dev/null
@@ -1,50 +0,0 @@
-{
-  "person": {
-    "properties": {
-      "name": {
-        "type": "string",
-        "index": "analyzed",
-        "store": "yes",
-        "fields": {
-          "indexed": {
-            "type": "string",
-            "index": "analyzed",
-            "store": "no"
-          },
-          "not_indexed": {
-            "type": "string",
-            "index": "no",
-            "store": "yes"
-          },
-          "test1": {
-            "type": "string",
-            "index": "analyzed",
-            "store": "yes",
-            "fielddata": {
-              "loading": "eager"
-            }
-          },
-          "test2": {
-            "type": "token_count",
-            "index": "not_analyzed",
-            "store": "yes",
-            "analyzer": "simple"
-          }
-        }
-      },
-      "object1": {
-        "properties": {
-          "multi1": {
-            "type": "date",
-            "fields": {
-              "string": {
-                "type": "string",
-                "index": "not_analyzed"
-              }
-            }
-          }
-        }
-      }
-    }
-  }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/path/test-mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/path/test-mapping.json
deleted file mode 100644
index 8af451a..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/path/test-mapping.json
+++ /dev/null
@@ -1,28 +0,0 @@
-{
-    "person":{
-        "properties":{
-            "name1":{
-                "type":"object",
-                "properties":{
-                    "first1":{
-                        "type":"string"
-                    },
-                    "last1":{
-                        "type":"string"
-                    }
-                }
-            },
-            "name2":{
-                "type":"object",
-                "properties":{
-                    "first2":{
-                        "type":"string"
-                    },
-                    "last2":{
-                        "type":"string"
-                    }
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/simple/test-mapping.json b/core/src/test/java/org/elasticsearch/index/mapper/simple/test-mapping.json
deleted file mode 100644
index e001673..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/simple/test-mapping.json
+++ /dev/null
@@ -1,84 +0,0 @@
-{
-    person:{
-        "_meta":{
-            "param1":"value1"
-        },
-        date_formats:["yyyy-MM-dd", "dd-MM-yyyy"],
-        dynamic:false,
-        enabled:true,
-        _source:{
-        },
-        properties:{
-            name:{
-                type:"object",
-                dynamic:false,
-                properties:{
-                    first:{
-                        type:"string",
-                        store:"yes"
-                    },
-                    last:{
-                        type:"string",
-                        index:"not_analyzed"
-                    }
-                }
-            },
-            address:{
-                type:"object",
-                properties:{
-                    first:{
-                        properties:{
-                            location:{
-                                type:"string",
-                                store:"yes"
-                            }
-                        }
-                    },
-                    last:{
-                        properties:{
-                            location:{
-                                type:"string"
-                            }
-                        }
-                    }
-                }
-            },
-            age:{
-                type:"integer",
-                null_value:0
-            },
-            birthdate:{
-                type:"date",
-                format:"yyyy-MM-dd"
-            },
-            nerd:{
-                type:"boolean"
-            },
-            dogs:{
-                type:"string"
-            },
-            complex:{
-                type:"object",
-                properties:{
-                    value1:{
-                        type:"string"
-                    },
-                    value2:{
-                        type:"string"
-                    }
-                }
-            },
-            complex2:{
-                type:"object",
-                properties:{
-                    value1:{
-                        type:"string"
-                    },
-                    value2:{
-                        type:"string"
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/simple/test1-notype-noid.json b/core/src/test/java/org/elasticsearch/index/mapper/simple/test1-notype-noid.json
deleted file mode 100644
index eb71b7a..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/simple/test1-notype-noid.json
+++ /dev/null
@@ -1,39 +0,0 @@
-{
-    name:{
-        first:"shay",
-        last:"banon"
-    },
-    address:{
-        first:{
-            location:"first location"
-        },
-        last:{
-            location:"last location"
-        }
-    },
-    age:32,
-    birthDate:"1977-11-15",
-    nerd:true,
-    dogs:["buck", "mia"],
-    complex:[
-        {
-            value1:"value1"
-        },
-        {
-            value2:"value2"
-        }
-    ],
-    complex2:[
-        [
-            {
-                value1:"value1"
-            }
-        ],
-        [
-            {
-                value2:"value2"
-            }
-        ]
-    ],
-    nullValue:null
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/simple/test1-notype.json b/core/src/test/java/org/elasticsearch/index/mapper/simple/test1-notype.json
deleted file mode 100644
index e91f2f5..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/simple/test1-notype.json
+++ /dev/null
@@ -1,40 +0,0 @@
-{
-    _id:"1",
-    name:{
-        first:"shay",
-        last:"banon"
-    },
-    address:{
-        first:{
-            location:"first location"
-        },
-        last:{
-            location:"last location"
-        }
-    },
-    age:32,
-    birthDate:"1977-11-15",
-    nerd:true,
-    dogs:["buck", "mia"],
-    complex:[
-        {
-            value1:"value1"
-        },
-        {
-            value2:"value2"
-        }
-    ],
-    complex2:[
-        [
-            {
-                value1:"value1"
-            }
-        ],
-        [
-            {
-                value2:"value2"
-            }
-        ]
-    ],
-    nullValue:null
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/simple/test1-withtype.json b/core/src/test/java/org/elasticsearch/index/mapper/simple/test1-withtype.json
deleted file mode 100644
index 5711d58..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/simple/test1-withtype.json
+++ /dev/null
@@ -1,42 +0,0 @@
-{
-    person:{
-        _id:"1",
-        name:{
-            first:"shay",
-            last:"banon"
-        },
-        address:{
-            first:{
-                location:"first location"
-            },
-            last:{
-                location:"last location"
-            }
-        },
-        age:32,
-        birthDate:"1977-11-15",
-        nerd:true,
-        dogs:["buck", "mia"],
-        complex:[
-            {
-                value1:"value1"
-            },
-            {
-                value2:"value2"
-            }
-        ],
-        complex2:[
-            [
-                {
-                    value1:"value1"
-                }
-            ],
-            [
-                {
-                    value2:"value2"
-                }
-            ]
-        ],
-        nullValue:null
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/simple/test1.json b/core/src/test/java/org/elasticsearch/index/mapper/simple/test1.json
deleted file mode 100644
index a4e64e9..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/simple/test1.json
+++ /dev/null
@@ -1,39 +0,0 @@
-{
-    name:{
-        first:"shay",
-        last:"banon"
-    },
-    address:{
-        first:{
-            location:"first location"
-        },
-        last:{
-            location:"last location"
-        }
-    },
-    age:32,
-    birthDate:"1977-11-15",
-    nerd:true,
-    dogs:["buck", "mia"],
-    complex:[
-        {
-            value1:"value1"
-        },
-        {
-            value2:"value2"
-        }
-    ],
-    complex2:[
-        [
-            {
-                value1:"value1"
-            }
-        ],
-        [
-            {
-                value2:"value2"
-            }
-        ]
-    ],
-    nullValue:null
-}
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/update/all_mapping_create_index.json b/core/src/test/java/org/elasticsearch/index/mapper/update/all_mapping_create_index.json
deleted file mode 100644
index e9604ae..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/update/all_mapping_create_index.json
+++ /dev/null
@@ -1,31 +0,0 @@
-{
-  "mappings": {
-    "type": {
-      "_all": {
-        "store": true,
-        "store_term_vectors": true,
-        "store_term_vector_offsets": true,
-        "store_term_vector_positions": true,
-        "store_term_vector_payloads": true,
-        "omit_norms": true,
-        "analyzer": "standard",
-        "search_analyzer": "whitespace",
-        "similarity": "my_similarity",
-        "fielddata": {
-           "format": "paged_bytes"
-        }
-      }
-    }
-  },
-  "settings": {
-    "similarity": {
-      "my_similarity": {
-        "type": "DFR",
-        "basic_model": "g",
-        "after_effect": "l",
-        "normalization": "h2",
-        "normalization.h2.c": "3.0"
-      }
-    }
-  }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/update/all_mapping_update_with_conflicts.json b/core/src/test/java/org/elasticsearch/index/mapper/update/all_mapping_update_with_conflicts.json
deleted file mode 100644
index 252aafe..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/update/all_mapping_update_with_conflicts.json
+++ /dev/null
@@ -1,19 +0,0 @@
-{
-  "type": {
-    "_all": {
-      "store": false,
-      "enabled": false,
-      "store_term_vectors": false,
-      "store_term_vector_offsets": false,
-      "store_term_vector_positions": false,
-      "store_term_vector_payloads": false,
-      "omit_norms": false,
-      "analyzer": "whitespace",
-      "search_analyzer": "standard",
-      "similarity": "bm25",
-      "fielddata": {
-          "format": "paged_bytes"
-      }
-    }
-  }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/update/default_mapping_with_disabled_root_types.json b/core/src/test/java/org/elasticsearch/index/mapper/update/default_mapping_with_disabled_root_types.json
deleted file mode 100644
index 5f49a6f..0000000
--- a/core/src/test/java/org/elasticsearch/index/mapper/update/default_mapping_with_disabled_root_types.json
+++ /dev/null
@@ -1 +0,0 @@
-{"type":{"_timestamp":{"enabled":false}}}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/AndQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/AndQueryBuilderTests.java
deleted file mode 100644
index e18495b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/AndQueryBuilderTests.java
+++ /dev/null
@@ -1,124 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.*;
-
-import static org.hamcrest.CoreMatchers.*;
-
-@SuppressWarnings("deprecation")
-public class AndQueryBuilderTests extends BaseQueryTestCase<AndQueryBuilder> {
-
-    /**
-     * @return a AndQueryBuilder with random limit between 0 and 20
-     */
-    @Override
-    protected AndQueryBuilder doCreateTestQueryBuilder() {
-        AndQueryBuilder query = new AndQueryBuilder();
-        int subQueries = randomIntBetween(1, 5);
-        for (int i = 0; i < subQueries; i++ ) {
-            query.add(RandomQueryBuilder.createQuery(random()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(AndQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.innerQueries().isEmpty()) {
-            assertThat(query, nullValue());
-        } else {
-            List<Query> clauses = new ArrayList<>();
-            for (QueryBuilder innerFilter : queryBuilder.innerQueries()) {
-                Query clause = innerFilter.toQuery(context);
-                if (clause != null) {
-                    clauses.add(clause);
-                }
-            }
-            if (clauses.isEmpty()) {
-                assertThat(query, nullValue());
-            } else {
-                assertThat(query, instanceOf(BooleanQuery.class));
-                BooleanQuery booleanQuery = (BooleanQuery) query;
-                assertThat(booleanQuery.clauses().size(), equalTo(clauses.size()));
-                Iterator<Query> queryIterator = clauses.iterator();
-                for (BooleanClause booleanClause : booleanQuery) {
-                    assertThat(booleanClause.getOccur(), equalTo(BooleanClause.Occur.MUST));
-                    assertThat(booleanClause.getQuery(), equalTo(queryIterator.next()));
-                }
-            }
-        }
-    }
-
-    /**
-     * test corner case where no inner queries exist
-     */
-    @Test
-    public void testNoInnerQueries() throws QueryShardException, IOException {
-        AndQueryBuilder andQuery = new AndQueryBuilder();
-        assertNull(andQuery.toQuery(createShardContext()));
-    }
-
-    @Test(expected=QueryParsingException.class)
-    public void testMissingFiltersSection() throws IOException {
-        parseQuery("{ \"and\" : {}");
-    }
-
-    @Test
-    public void testValidate() {
-        AndQueryBuilder andQuery = new AndQueryBuilder();
-        int iters = randomIntBetween(0, 5);
-        int totalExpectedErrors = 0;
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    andQuery.add(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    andQuery.add(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                andQuery.add(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        assertValidate(andQuery, totalExpectedErrors);
-    }
-
-    @Override
-    protected Map<String, AndQueryBuilder> getAlternateVersions() {
-        Map<String, AndQueryBuilder> alternateVersions = new HashMap<>();
-        QueryBuilder innerQuery = createTestQueryBuilder().innerQueries().get(0);
-        AndQueryBuilder expectedQuery = new AndQueryBuilder(innerQuery);
-        String contentString =  "{ \"and\" : [ " + innerQuery + "] }";
-        alternateVersions.put(contentString, expectedQuery);
-        return alternateVersions;
-    }
-
-    @Test(expected=QueryParsingException.class)
-    public void testParsingExceptionNonFiltersElementArray() throws IOException {
-        String queryString = "{ \"and\" : { \"whatever_filters\" : [ { \"match_all\" : {} } ] } }";
-        parseQuery(queryString);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java
deleted file mode 100644
index 1af92e4..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/BaseQueryTestCase.java
+++ /dev/null
@@ -1,570 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.carrotsearch.randomizedtesting.generators.CodepointSetGenerator;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.Version;
-import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.collect.Tuple;
-import org.elasticsearch.common.compress.CompressedXContent;
-import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.inject.Injector;
-import org.elasticsearch.common.inject.ModulesBuilder;
-import org.elasticsearch.common.inject.multibindings.Multibinder;
-import org.elasticsearch.common.inject.util.Providers;
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.NamedWriteableAwareStreamInput;
-import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.settings.SettingsModule;
-import org.elasticsearch.common.unit.Fuzziness;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.env.Environment;
-import org.elasticsearch.env.EnvironmentModule;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.index.IndexNameModule;
-import org.elasticsearch.index.analysis.AnalysisModule;
-import org.elasticsearch.index.cache.IndexCacheModule;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
-import org.elasticsearch.index.query.support.QueryParsers;
-import org.elasticsearch.index.settings.IndexSettingsModule;
-import org.elasticsearch.index.similarity.SimilarityModule;
-import org.elasticsearch.indices.IndicesModule;
-import org.elasticsearch.indices.analysis.IndicesAnalysisService;
-import org.elasticsearch.indices.breaker.CircuitBreakerService;
-import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
-import org.elasticsearch.script.ScriptModule;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.test.ESTestCase;
-import org.elasticsearch.test.TestSearchContext;
-import org.elasticsearch.test.VersionUtils;
-import org.elasticsearch.test.cluster.TestClusterService;
-import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.threadpool.ThreadPoolModule;
-import org.joda.time.DateTime;
-import org.joda.time.DateTimeZone;
-import org.junit.After;
-import org.junit.AfterClass;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Collections;
-import java.util.Map;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
-
-public abstract class BaseQueryTestCase<QB extends AbstractQueryBuilder<QB>> extends ESTestCase { // TODO rename this AbstractQueryTestCase
-
-    private static final GeohashGenerator geohashGenerator = new GeohashGenerator();
-    protected static final String STRING_FIELD_NAME = "mapped_string";
-    protected static final String INT_FIELD_NAME = "mapped_int";
-    protected static final String DOUBLE_FIELD_NAME = "mapped_double";
-    protected static final String BOOLEAN_FIELD_NAME = "mapped_boolean";
-    protected static final String DATE_FIELD_NAME = "mapped_date";
-    protected static final String OBJECT_FIELD_NAME = "mapped_object";
-    protected static final String GEO_FIELD_NAME = "mapped_geo";
-    protected static final String[] MAPPED_FIELD_NAMES = new String[] { STRING_FIELD_NAME, INT_FIELD_NAME,
-            DOUBLE_FIELD_NAME, BOOLEAN_FIELD_NAME, DATE_FIELD_NAME, OBJECT_FIELD_NAME, GEO_FIELD_NAME };
-    protected static final String[] MAPPED_LEAF_FIELD_NAMES = new String[] { STRING_FIELD_NAME, INT_FIELD_NAME,
-            DOUBLE_FIELD_NAME, BOOLEAN_FIELD_NAME, DATE_FIELD_NAME, GEO_FIELD_NAME };
-
-    private static Injector injector;
-    private static IndexQueryParserService queryParserService;
-
-    protected static IndexQueryParserService queryParserService() {
-        return queryParserService;
-    }
-
-    private static Index index;
-
-    protected static Index getIndex() {
-        return index;
-    }
-
-    private static String[] currentTypes;
-
-    protected static String[] getCurrentTypes() {
-        return currentTypes;
-    }
-
-    private static NamedWriteableRegistry namedWriteableRegistry;
-
-    /**
-     * Setup for the whole base test class.
-     * @throws IOException
-     */
-    @BeforeClass
-    public static void init() throws IOException {
-        // we have to prefer CURRENT since with the range of versions we support it's rather unlikely to get the current actually.
-        Version version = randomBoolean() ? Version.CURRENT : VersionUtils.randomVersionBetween(random(), Version.V_1_0_0, Version.CURRENT);
-        Settings settings = Settings.settingsBuilder()
-                .put("name", BaseQueryTestCase.class.toString())
-                .put("path.home", createTempDir())
-                .build();
-        Settings indexSettings = Settings.settingsBuilder()
-                .put(IndexMetaData.SETTING_VERSION_CREATED, version).build();
-        index = new Index(randomAsciiOfLengthBetween(1, 10));
-        final TestClusterService clusterService = new TestClusterService();
-        clusterService.setState(new ClusterState.Builder(clusterService.state()).metaData(new MetaData.Builder().put(
-                new IndexMetaData.Builder(index.name()).settings(indexSettings).numberOfShards(1).numberOfReplicas(0))));
-        injector = new ModulesBuilder().add(
-                new EnvironmentModule(new Environment(settings)),
-                new SettingsModule(settings),
-                new ThreadPoolModule(new ThreadPool(settings)),
-                new IndicesModule(settings) {
-                    @Override
-                    public void configure() {
-                        // skip services
-                        bindQueryParsersExtension();
-                    }
-                },
-                new ScriptModule(settings),
-                new IndexSettingsModule(index, indexSettings),
-                new IndexCacheModule(indexSettings),
-                new AnalysisModule(indexSettings, new IndicesAnalysisService(indexSettings)),
-                new SimilarityModule(indexSettings),
-                new IndexNameModule(index),
-        new AbstractModule() {
-                    @Override
-                    protected void configure() {
-                        Multibinder.newSetBinder(binder(), ScoreFunctionParser.class);
-                        bind(ClusterService.class).toProvider(Providers.of(clusterService));
-                        bind(CircuitBreakerService.class).to(NoneCircuitBreakerService.class);
-                        bind(NamedWriteableRegistry.class).asEagerSingleton();
-                    }
-                }
-        ).createInjector();
-        queryParserService = injector.getInstance(IndexQueryParserService.class);
-        MapperService mapperService = queryParserService.mapperService;
-        //create some random type with some default field, those types will stick around for all of the subclasses
-        currentTypes = new String[randomIntBetween(0, 5)];
-        for (int i = 0; i < currentTypes.length; i++) {
-            String type = randomAsciiOfLengthBetween(1, 10);
-            mapperService.merge(type, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(type,
-                    STRING_FIELD_NAME, "type=string",
-                    INT_FIELD_NAME, "type=integer",
-                    DOUBLE_FIELD_NAME, "type=double",
-                    BOOLEAN_FIELD_NAME, "type=boolean",
-                    DATE_FIELD_NAME, "type=date",
-                    OBJECT_FIELD_NAME, "type=object",
-                    GEO_FIELD_NAME, "type=geo_point,lat_lon=true,geohash=true,geohash_prefix=true"
-            ).string()), false, false);
-            // also add mappings for two inner field in the object field
-            mapperService.merge(type, new CompressedXContent("{\"properties\":{\""+OBJECT_FIELD_NAME+"\":{\"type\":\"object\","
-                    + "\"properties\":{\""+DATE_FIELD_NAME+"\":{\"type\":\"date\"},\""+INT_FIELD_NAME+"\":{\"type\":\"integer\"}}}}}"), false, false);
-            currentTypes[i] = type;
-        }
-        namedWriteableRegistry = injector.getInstance(NamedWriteableRegistry.class);
-    }
-
-    @AfterClass
-    public static void afterClass() throws Exception {
-        terminate(injector.getInstance(ThreadPool.class));
-        injector = null;
-        index = null;
-        queryParserService = null;
-        currentTypes = null;
-        namedWriteableRegistry = null;
-    }
-
-    @Before
-    public void beforeTest() {
-        //set some random types to be queried as part the search request, before each test
-        String[] types = getRandomTypes();
-        //some query (e.g. range query) have a different behaviour depending on whether the current search context is set or not
-        //which is why we randomly set the search context, which will internally also do QueryParseContext.setTypes(types)
-        if (randomBoolean()) {
-            QueryShardContext.setTypes(types);
-        } else {
-           setSearchContext(types); // TODO should this be set after we parsed and before we build the query? it makes more sense?
-        }
-    }
-
-    protected void setSearchContext(String[] types) {
-        TestSearchContext testSearchContext = new TestSearchContext();
-        testSearchContext.setTypes(types);
-        SearchContext.setCurrent(testSearchContext);
-    }
-
-    @After
-    public void afterTest() {
-        QueryShardContext.removeTypes();
-        SearchContext.removeCurrent();
-    }
-
-    protected final QB createTestQueryBuilder() {
-        QB query = doCreateTestQueryBuilder();
-        //we should not set boost and query name for queries that don't parse it
-        if (supportsBoostAndQueryName()) {
-            if (randomBoolean()) {
-                query.boost(2.0f / randomIntBetween(1, 20));
-            }
-            if (randomBoolean()) {
-                query.queryName(randomAsciiOfLengthBetween(1, 10));
-            }
-        }
-        return query;
-    }
-
-    /**
-     * Create the query that is being tested
-     */
-    protected abstract QB doCreateTestQueryBuilder();
-
-    /**
-     * Generic test that creates new query from the test query and checks both for equality
-     * and asserts equality on the two queries.
-     */
-    @Test
-    public void testFromXContent() throws IOException {
-        QB testQuery = createTestQueryBuilder();
-        assertParsedQuery(testQuery.toString(), testQuery);
-        for (Map.Entry<String, QB> alternateVersion : getAlternateVersions().entrySet()) {
-            assertParsedQuery(alternateVersion.getKey(), alternateVersion.getValue());
-        }
-    }
-
-    /**
-     * Returns alternate string representation of the query that need to be tested as they are never used as output
-     * of {@link QueryBuilder#toXContent(XContentBuilder, ToXContent.Params)}. By default there are no alternate versions.
-     */
-    protected Map<String, QB> getAlternateVersions() {
-        return Collections.emptyMap();
-    }
-
-    /**
-     * Parses the query provided as string argument and compares it with the expected result provided as argument as a {@link QueryBuilder}
-     */
-    protected void assertParsedQuery(String queryAsString, QueryBuilder<?> expectedQuery) throws IOException {
-        QueryBuilder<?> newQuery = parseQuery(queryAsString);
-        assertNotSame(newQuery, expectedQuery);
-        assertEquals(expectedQuery, newQuery);
-        assertEquals(expectedQuery.hashCode(), newQuery.hashCode());
-    }
-
-    protected QueryBuilder<?> parseQuery(String queryAsString) throws IOException {
-        XContentParser parser = XContentFactory.xContent(queryAsString).createParser(queryAsString);
-        QueryParseContext context = createParseContext();
-        context.reset(parser);
-        // TODO this should set context.parseFieldMatcher(ParseFieldMatcher.STRICT);
-        // all our builders should only create non-deprecated XContent.
-        return context.parseInnerQueryBuilder();
-    }
-
-    /**
-     * Test creates the {@link Query} from the {@link QueryBuilder} under test and delegates the
-     * assertions being made on the result to the implementing subclass.
-     */
-    @Test
-    public void testToQuery() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-
-        QB firstQuery = createTestQueryBuilder();
-        Query firstLuceneQuery = firstQuery.toQuery(context);
-        assertLuceneQuery(firstQuery, firstLuceneQuery, context);
-
-        QB secondQuery = copyQuery(firstQuery);
-        //query _name never should affect the result of toQuery, we randomly set it to make sure
-        if (randomBoolean()) {
-            secondQuery.queryName(secondQuery.queryName() == null ? randomAsciiOfLengthBetween(1, 30) : secondQuery.queryName() + randomAsciiOfLengthBetween(1, 10));
-        }
-        Query secondLuceneQuery = secondQuery.toQuery(context);
-        assertLuceneQuery(secondQuery, secondLuceneQuery, context);
-        assertThat("two equivalent query builders lead to different lucene queries", secondLuceneQuery, equalTo(firstLuceneQuery));
-
-        //if the initial lucene query is null, changing its boost won't have any effect, we shouldn't test that
-        if (firstLuceneQuery != null && supportsBoostAndQueryName()) {
-            secondQuery.boost(firstQuery.boost() + 1f + randomFloat());
-            Query thirdLuceneQuery = secondQuery.toQuery(context);
-            assertThat("modifying the boost doesn't affect the corresponding lucene query", firstLuceneQuery, not(equalTo(thirdLuceneQuery)));
-        }
-    }
-
-    /**
-     * Few queries allow you to set the boost and queryName on the java api, although the corresponding parser doesn't parse them as they are not supported.
-     * This method allows to disable boost and queryName related tests for those queries. Those queries are easy to identify: their parsers
-     * don't parse `boost` and `_name` as they don't apply to the specific query: filter query, wrapper query and match_none
-     */
-    protected boolean supportsBoostAndQueryName() {
-        return true;
-    }
-
-    /**
-     * Checks the result of {@link QueryBuilder#toQuery(QueryShardContext)} given the original {@link QueryBuilder} and {@link QueryShardContext}.
-     * Verifies that named queries and boost are properly handled and delegates to {@link #doAssertLuceneQuery(AbstractQueryBuilder, Query, QueryShardContext)}
-     * for query specific checks.
-     */
-    protected final void assertLuceneQuery(QB queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.queryName() != null) {
-            Query namedQuery = context.copyNamedQueries().get(queryBuilder.queryName());
-            assertThat(namedQuery, equalTo(query));
-        }
-        if (query != null) {
-            assertBoost(queryBuilder, query);
-        }
-        doAssertLuceneQuery(queryBuilder, query, context);
-    }
-
-    /**
-     * Allows to override boost assertions for queries that don't have the default behaviour
-     */
-    protected void assertBoost(QB queryBuilder, Query query) throws IOException {
-        assertThat(query.getBoost(), equalTo(queryBuilder.boost()));
-    }
-
-    /**
-     * Checks the result of {@link QueryBuilder#toQuery(QueryShardContext)} given the original {@link QueryBuilder} and {@link QueryShardContext}.
-     * Contains the query specific checks to be implemented by subclasses.
-     */
-    protected abstract void doAssertLuceneQuery(QB queryBuilder, Query query, QueryShardContext context) throws IOException;
-
-    /**
-     * Test serialization and deserialization of the test query.
-     */
-    @Test
-    public void testSerialization() throws IOException {
-        QB testQuery = createTestQueryBuilder();
-        try (BytesStreamOutput output = new BytesStreamOutput()) {
-            testQuery.writeTo(output);
-            try (StreamInput in = new NamedWriteableAwareStreamInput(StreamInput.wrap(output.bytes()), namedWriteableRegistry)) {
-                QueryBuilder<?> prototype = queryParser(testQuery.getName()).getBuilderPrototype();
-                QueryBuilder deserializedQuery = prototype.readFrom(in);
-                assertEquals(deserializedQuery, testQuery);
-                assertEquals(deserializedQuery.hashCode(), testQuery.hashCode());
-                assertNotSame(deserializedQuery, testQuery);
-            }
-        }
-    }
-
-    @Test
-    public void testEqualsAndHashcode() throws IOException {
-        QB firstQuery = createTestQueryBuilder();
-        assertFalse("query is equal to null", firstQuery.equals(null));
-        assertFalse("query is equal to incompatible type", firstQuery.equals(""));
-        assertTrue("query is not equal to self", firstQuery.equals(firstQuery));
-        assertThat("same query's hashcode returns different values if called multiple times", firstQuery.hashCode(), equalTo(firstQuery.hashCode()));
-
-        QB secondQuery = copyQuery(firstQuery);
-        assertTrue("query is not equal to self", secondQuery.equals(secondQuery));
-        assertTrue("query is not equal to its copy", firstQuery.equals(secondQuery));
-        assertTrue("equals is not symmetric", secondQuery.equals(firstQuery));
-        assertThat("query copy's hashcode is different from original hashcode", secondQuery.hashCode(), equalTo(firstQuery.hashCode()));
-
-        QB thirdQuery = copyQuery(secondQuery);
-        assertTrue("query is not equal to self", thirdQuery.equals(thirdQuery));
-        assertTrue("query is not equal to its copy", secondQuery.equals(thirdQuery));
-        assertThat("query copy's hashcode is different from original hashcode", secondQuery.hashCode(), equalTo(thirdQuery.hashCode()));
-        assertTrue("equals is not transitive", firstQuery.equals(thirdQuery));
-        assertThat("query copy's hashcode is different from original hashcode", firstQuery.hashCode(), equalTo(thirdQuery.hashCode()));
-        assertTrue("equals is not symmetric", thirdQuery.equals(secondQuery));
-        assertTrue("equals is not symmetric", thirdQuery.equals(firstQuery));
-
-        if (randomBoolean()) {
-            secondQuery.queryName(secondQuery.queryName() == null ? randomAsciiOfLengthBetween(1, 30) : secondQuery.queryName() + randomAsciiOfLengthBetween(1, 10));
-        } else {
-            secondQuery.boost(firstQuery.boost() + 1f + randomFloat());
-        }
-        assertThat("different queries should not be equal", secondQuery, not(equalTo(firstQuery)));
-        assertThat("different queries should have different hashcode", secondQuery.hashCode(), not(equalTo(firstQuery.hashCode())));
-    }
-
-    private QueryParser<?> queryParser(String queryId) {
-        return queryParserService.indicesQueriesRegistry().queryParsers().get(queryId);
-    }
-
-    //we use the streaming infra to create a copy of the query provided as argument
-    protected QB copyQuery(QB query) throws IOException {
-        try (BytesStreamOutput output = new BytesStreamOutput()) {
-            query.writeTo(output);
-            try (StreamInput in = new NamedWriteableAwareStreamInput(StreamInput.wrap(output.bytes()), namedWriteableRegistry)) {
-                QueryBuilder<?> prototype = queryParser(query.getName()).getBuilderPrototype();
-                @SuppressWarnings("unchecked")
-                QB secondQuery = (QB)prototype.readFrom(in);
-                return secondQuery;
-            }
-        }
-    }
-
-    /**
-     * @return a new {@link QueryShardContext} based on the base test index and queryParserService
-     */
-    protected static QueryShardContext createShardContext() {
-        QueryShardContext queryCreationContext = new QueryShardContext(index, queryParserService);
-        queryCreationContext.parseFieldMatcher(ParseFieldMatcher.EMPTY);
-        return queryCreationContext;
-    }
-
-    /**
-     * @return a new {@link QueryParseContext} based on the base test index and queryParserService
-     */
-    protected static QueryParseContext createParseContext() {
-        return createShardContext().parseContext();
-    }
-
-    protected static void assertValidate(QueryBuilder queryBuilder, int totalExpectedErrors) {
-        QueryValidationException queryValidationException = queryBuilder.validate();
-        if (totalExpectedErrors > 0) {
-            assertThat(queryValidationException, notNullValue());
-            assertThat(queryValidationException.validationErrors().size(), equalTo(totalExpectedErrors));
-        } else {
-            assertThat(queryValidationException, nullValue());
-        }
-    }
-
-    /**
-     * create a random value for either {@link BaseQueryTestCase#BOOLEAN_FIELD_NAME}, {@link BaseQueryTestCase#INT_FIELD_NAME},
-     * {@link BaseQueryTestCase#DOUBLE_FIELD_NAME}, {@link BaseQueryTestCase#STRING_FIELD_NAME} or
-     * {@link BaseQueryTestCase#DATE_FIELD_NAME}, or a String value by default
-     */
-    protected static Object getRandomValueForFieldName(String fieldName) {
-        Object value;
-        switch (fieldName) {
-            case STRING_FIELD_NAME:
-                value = rarely() ? randomUnicodeOfLength(10) : randomAsciiOfLengthBetween(1, 10); // unicode in 10% cases
-                break;
-            case INT_FIELD_NAME:
-                value = randomIntBetween(0, 10);
-                break;
-            case DOUBLE_FIELD_NAME:
-                value = randomDouble() * 10;
-                break;
-            case BOOLEAN_FIELD_NAME:
-                value = randomBoolean();
-                break;
-            case DATE_FIELD_NAME:
-                value = new DateTime(System.currentTimeMillis(), DateTimeZone.UTC).toString();
-                break;
-            default:
-                value = randomAsciiOfLengthBetween(1, 10);
-        }
-        return value;
-    }
-
-    /**
-     * Helper method to return a mapped or a random field
-     */
-    protected String getRandomFieldName() {
-        // if no type is set then return a random field name
-        if (currentTypes == null || currentTypes.length == 0 || randomBoolean()) {
-            return randomAsciiOfLengthBetween(1, 10);
-        }
-        return randomFrom(MAPPED_LEAF_FIELD_NAMES);
-    }
-
-    /**
-     * Helper method to return a random field (mapped or unmapped) and a value
-     */
-    protected Tuple<String, Object> getRandomFieldNameAndValue() {
-        String fieldName = getRandomFieldName();
-        return new Tuple<>(fieldName, getRandomValueForFieldName(fieldName));
-    }
-
-    /**
-     * Helper method to return a random rewrite method
-     */
-    protected static String getRandomRewriteMethod() {
-        String rewrite;
-        if (randomBoolean()) {
-            rewrite = randomFrom(QueryParsers.CONSTANT_SCORE,
-                    QueryParsers.SCORING_BOOLEAN,
-                    QueryParsers.CONSTANT_SCORE_BOOLEAN).getPreferredName();
-        } else {
-            rewrite = randomFrom(QueryParsers.TOP_TERMS,
-                    QueryParsers.TOP_TERMS_BOOST,
-                    QueryParsers.TOP_TERMS_BLENDED_FREQS).getPreferredName() + "1";
-        }
-        return rewrite;
-    }
-
-    protected String[] getRandomTypes() {
-        String[] types;
-        if (currentTypes.length > 0 && randomBoolean()) {
-            int numberOfQueryTypes = randomIntBetween(1, currentTypes.length);
-            types = new String[numberOfQueryTypes];
-            for (int i = 0; i < numberOfQueryTypes; i++) {
-                types[i] = randomFrom(currentTypes);
-            }
-        } else {
-            if (randomBoolean()) {
-                types = new String[] { MetaData.ALL };
-            } else {
-                types = new String[0];
-            }
-        }
-        return types;
-    }
-
-    protected String getRandomType() {
-        return (currentTypes.length == 0) ? MetaData.ALL : randomFrom(currentTypes);
-    }
-
-    public static String randomGeohash(int minPrecision, int maxPrecision) {
-        return geohashGenerator.ofStringLength(getRandom(), minPrecision, maxPrecision);
-    }
-
-    public static class GeohashGenerator extends CodepointSetGenerator {
-        private final static char[] ASCII_SET = "0123456789bcdefghjkmnpqrstuvwxyz".toCharArray();
-
-        public GeohashGenerator() {
-            super(ASCII_SET);
-        }
-    }
-
-    protected static Fuzziness randomFuzziness(String fieldName) {
-        Fuzziness fuzziness = Fuzziness.AUTO;
-        switch (fieldName) {
-            case INT_FIELD_NAME:
-                fuzziness = Fuzziness.build(randomIntBetween(3, 100));
-                break;
-            case DOUBLE_FIELD_NAME:
-                fuzziness = Fuzziness.build(1 + randomFloat() * 10);
-                break;
-            case DATE_FIELD_NAME:
-                fuzziness = Fuzziness.build(randomTimeValue());
-                break;
-        }
-        if (randomBoolean()) {
-            fuzziness = Fuzziness.fromEdits(randomIntBetween(0, 2));
-        }
-        return fuzziness;
-    }
-
-    protected static boolean isNumericFieldName(String fieldName) {
-        return INT_FIELD_NAME.equals(fieldName) || DOUBLE_FIELD_NAME.equals(fieldName);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/BaseTermQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/BaseTermQueryTestCase.java
deleted file mode 100644
index c83a3f5..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/BaseTermQueryTestCase.java
+++ /dev/null
@@ -1,110 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.junit.Test;
-
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.Matchers.is;
-
-public abstract class BaseTermQueryTestCase<QB extends BaseTermQueryBuilder<QB>> extends BaseQueryTestCase<QB> {
-
-    @Override
-    protected final QB doCreateTestQueryBuilder() {
-        String fieldName = null;
-        Object value;
-        switch (randomIntBetween(0, 3)) {
-            case 0:
-                if (randomBoolean()) {
-                    fieldName = BOOLEAN_FIELD_NAME;
-                }
-                value = randomBoolean();
-                break;
-            case 1:
-                if (randomBoolean()) {
-                    fieldName = STRING_FIELD_NAME;
-                }
-                if (frequently()) {
-                    value = randomAsciiOfLengthBetween(1, 10);
-                } else {
-                    // generate unicode string in 10% of cases
-                    value = randomUnicodeOfLength(10);
-                }
-                break;
-            case 2:
-                if (randomBoolean()) {
-                    fieldName = INT_FIELD_NAME;
-                }
-                value = randomInt(10000);
-                break;
-            case 3:
-                if (randomBoolean()) {
-                    fieldName = DOUBLE_FIELD_NAME;
-                }
-                value = randomDouble();
-                break;
-            default:
-                throw new UnsupportedOperationException();
-        }
-
-        if (fieldName == null) {
-            fieldName = randomAsciiOfLengthBetween(1, 10);
-        }
-        return createQueryBuilder(fieldName, value);
-    }
-
-    protected abstract QB createQueryBuilder(String fieldName, Object value);
-
-    @Test
-    public void testValidate() throws QueryShardException {
-        QB queryBuilder = createQueryBuilder(randomAsciiOfLengthBetween(1, 30), randomAsciiOfLengthBetween(1, 30));
-        assertNull(queryBuilder.validate());
-
-        queryBuilder = createQueryBuilder(null, randomAsciiOfLengthBetween(1, 30));
-        assertNotNull(queryBuilder.validate());
-        assertThat(queryBuilder.validate().validationErrors().size(), is(1));
-
-        queryBuilder = createQueryBuilder("", randomAsciiOfLengthBetween(1, 30));
-        assertNotNull(queryBuilder.validate());
-        assertThat(queryBuilder.validate().validationErrors().size(), is(1));
-
-        queryBuilder = createQueryBuilder("", null);
-        assertNotNull(queryBuilder.validate());
-        assertThat(queryBuilder.validate().validationErrors().size(), is(2));
-    }
-
-    @Override
-    protected Map<String, QB> getAlternateVersions() {
-        HashMap<String, QB> alternateVersions = new HashMap<>();
-        QB tempQuery = createTestQueryBuilder();
-        QB testQuery = createQueryBuilder(tempQuery.fieldName(), tempQuery.value());
-        boolean isString = testQuery.value() instanceof String;
-        String value = (isString ? "\"" : "") + testQuery.value() + (isString ? "\"" : "");
-        String contentString = "{\n" +
-                "    \"" + testQuery.getName() + "\" : {\n" +
-                "        \"" + testQuery.fieldName() + "\" : " + value + "\n" +
-                "    }\n" +
-                "}";
-        alternateVersions.put(contentString, testQuery);
-        return alternateVersions;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/BoolQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/BoolQueryBuilderTests.java
deleted file mode 100644
index cec4a7e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/BoolQueryBuilderTests.java
+++ /dev/null
@@ -1,206 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.*;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class BoolQueryBuilderTests extends BaseQueryTestCase<BoolQueryBuilder> {
-
-    @Override
-    protected BoolQueryBuilder doCreateTestQueryBuilder() {
-        BoolQueryBuilder query = new BoolQueryBuilder();
-        if (randomBoolean()) {
-            query.adjustPureNegative(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.disableCoord(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.minimumNumberShouldMatch(randomIntBetween(1, 10));
-        }
-        int mustClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < mustClauses; i++) {
-            query.must(RandomQueryBuilder.createQuery(random()));
-        }
-        int mustNotClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < mustNotClauses; i++) {
-            query.mustNot(RandomQueryBuilder.createQuery(random()));
-        }
-        int shouldClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < shouldClauses; i++) {
-            query.should(RandomQueryBuilder.createQuery(random()));
-        }
-        int filterClauses = randomIntBetween(0, 3);
-        for (int i = 0; i < filterClauses; i++) {
-            query.filter(RandomQueryBuilder.createQuery(random()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(BoolQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (!queryBuilder.hasClauses()) {
-            assertThat(query, instanceOf(MatchAllDocsQuery.class));
-        } else {
-            List<BooleanClause> clauses = new ArrayList<>();
-            clauses.addAll(getBooleanClauses(queryBuilder.must(), BooleanClause.Occur.MUST, context));
-            clauses.addAll(getBooleanClauses(queryBuilder.mustNot(), BooleanClause.Occur.MUST_NOT, context));
-            clauses.addAll(getBooleanClauses(queryBuilder.should(), BooleanClause.Occur.SHOULD, context));
-            clauses.addAll(getBooleanClauses(queryBuilder.filter(), BooleanClause.Occur.FILTER, context));
-
-            if (clauses.isEmpty()) {
-                assertThat(query, instanceOf(MatchAllDocsQuery.class));
-            } else {
-                assertThat(query, instanceOf(BooleanQuery.class));
-                BooleanQuery booleanQuery = (BooleanQuery) query;
-                if (queryBuilder.adjustPureNegative()) {
-                    boolean isNegative = true;
-                    for (BooleanClause clause : clauses) {
-                        if (clause.isProhibited() == false) {
-                            isNegative = false;
-                            break;
-                        }
-                    }
-                    if (isNegative) {
-                        clauses.add(new BooleanClause(new MatchAllDocsQuery(), BooleanClause.Occur.MUST));
-                    }
-                }
-                assertThat(booleanQuery.clauses().size(), equalTo(clauses.size()));
-                Iterator<BooleanClause> clauseIterator = clauses.iterator();
-                for (BooleanClause booleanClause : booleanQuery.getClauses()) {
-                    assertThat(booleanClause, equalTo(clauseIterator.next()));
-                }
-            }
-        }
-    }
-
-    private static List<BooleanClause> getBooleanClauses(List<QueryBuilder> queryBuilders, BooleanClause.Occur occur, QueryShardContext context) throws IOException {
-        List<BooleanClause> clauses = new ArrayList<>();
-        for (QueryBuilder query : queryBuilders) {
-            Query innerQuery = query.toQuery(context);
-            if (innerQuery != null) {
-                clauses.add(new BooleanClause(innerQuery, occur));
-            }
-        }
-        return clauses;
-    }
-
-    @Override
-    protected Map<String, BoolQueryBuilder> getAlternateVersions() {
-        Map<String, BoolQueryBuilder> alternateVersions = new HashMap<>();
-        BoolQueryBuilder tempQueryBuilder = createTestQueryBuilder();
-        BoolQueryBuilder expectedQuery = new BoolQueryBuilder();
-        String contentString = "{\n" +
-                "    \"bool\" : {\n";
-        if (tempQueryBuilder.must().size() > 0) {
-            QueryBuilder must = tempQueryBuilder.must().get(0);
-            contentString += "must: " + must.toString() + ",";
-            expectedQuery.must(must);
-        }
-        if (tempQueryBuilder.mustNot().size() > 0) {
-            QueryBuilder mustNot = tempQueryBuilder.mustNot().get(0);
-            contentString += (randomBoolean() ? "must_not: " : "mustNot: ") + mustNot.toString() + ",";
-            expectedQuery.mustNot(mustNot);
-        }
-        if (tempQueryBuilder.should().size() > 0) {
-            QueryBuilder should = tempQueryBuilder.should().get(0);
-            contentString += "should: " + should.toString() + ",";
-            expectedQuery.should(should);
-        }
-        if (tempQueryBuilder.filter().size() > 0) {
-            QueryBuilder filter = tempQueryBuilder.filter().get(0);
-            contentString += "filter: " + filter.toString() + ",";
-            expectedQuery.filter(filter);
-        }
-        contentString = contentString.substring(0, contentString.length() - 1);
-        contentString += "    }    \n" + "}";
-        alternateVersions.put(contentString, expectedQuery);
-        return alternateVersions;
-    }
-
-    @Test
-    public void testValidate() {
-        BoolQueryBuilder booleanQuery = new BoolQueryBuilder();
-        int iters = randomIntBetween(0, 3);
-        int totalExpectedErrors = 0;
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.must(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.must(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.must(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        iters = randomIntBetween(0, 3);
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.should(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.should(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.should(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        iters = randomIntBetween(0, 3);
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.mustNot(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.mustNot(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.mustNot(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        iters = randomIntBetween(0, 3);
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    booleanQuery.filter(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    booleanQuery.filter(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                booleanQuery.filter(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        assertValidate(booleanQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/BoostingQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/BoostingQueryBuilderTests.java
deleted file mode 100644
index fdff0c3..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/BoostingQueryBuilderTests.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.queries.BoostingQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-import static org.hamcrest.CoreMatchers.nullValue;
-
-public class BoostingQueryBuilderTests extends BaseQueryTestCase<BoostingQueryBuilder> {
-
-    @Override
-    protected BoostingQueryBuilder doCreateTestQueryBuilder() {
-        BoostingQueryBuilder query = new BoostingQueryBuilder(RandomQueryBuilder.createQuery(random()), RandomQueryBuilder.createQuery(random()));
-        query.negativeBoost(2.0f / randomIntBetween(1, 20));
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(BoostingQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query positive = queryBuilder.positiveQuery().toQuery(context);
-        Query negative = queryBuilder.negativeQuery().toQuery(context);
-        if (positive == null || negative == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(BoostingQuery.class));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        QueryBuilder positive = null;
-        QueryBuilder negative = null;
-        if (frequently()) {
-            if (randomBoolean()) {
-                negative = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            negative = RandomQueryBuilder.createQuery(random());
-        }
-        if (frequently()) {
-            if (randomBoolean()) {
-                positive = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            positive = RandomQueryBuilder.createQuery(random());
-        }
-        BoostingQueryBuilder boostingQuery = new BoostingQueryBuilder(positive, negative);
-        if (frequently()) {
-            boostingQuery.negativeBoost(0.5f);
-        } else {
-            boostingQuery.negativeBoost(-0.5f);
-            totalExpectedErrors++;
-        }
-        assertValidate(boostingQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/CommonTermsQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/CommonTermsQueryBuilderTests.java
deleted file mode 100644
index 1d093ad..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/CommonTermsQueryBuilderTests.java
+++ /dev/null
@@ -1,105 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.queries.ExtendedCommonTermsQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class CommonTermsQueryBuilderTests extends BaseQueryTestCase<CommonTermsQueryBuilder> {
-
-    @Override
-    protected CommonTermsQueryBuilder doCreateTestQueryBuilder() {
-        CommonTermsQueryBuilder query;
-
-        // mapped or unmapped field
-        String text = randomAsciiOfLengthBetween(1, 10);
-        if (randomBoolean()) {
-            query = new CommonTermsQueryBuilder(STRING_FIELD_NAME, text);
-        } else {
-            query = new CommonTermsQueryBuilder(randomAsciiOfLengthBetween(1, 10), text);
-        }
-
-        if (randomBoolean()) {
-            query.cutoffFrequency((float) randomIntBetween(1, 10));
-        }
-
-        if (randomBoolean()) {
-            query.lowFreqOperator(randomFrom(Operator.values()));
-        }
-
-        // number of low frequency terms that must match
-        if (randomBoolean()) {
-            query.lowFreqMinimumShouldMatch("" + randomIntBetween(1, 5));
-        }
-
-        if (randomBoolean()) {
-            query.highFreqOperator(randomFrom(Operator.values()));
-        }
-
-        // number of high frequency terms that must match
-        if (randomBoolean()) {
-            query.highFreqMinimumShouldMatch("" + randomIntBetween(1, 5));
-        }
-
-        if (randomBoolean()) {
-            query.analyzer(randomFrom("simple", "keyword", "whitespace"));
-        }
-
-        if (randomBoolean()) {
-            query.disableCoord(randomBoolean());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(CommonTermsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(ExtendedCommonTermsQuery.class));
-        ExtendedCommonTermsQuery extendedCommonTermsQuery = (ExtendedCommonTermsQuery) query;
-        assertThat(extendedCommonTermsQuery.getHighFreqMinimumNumberShouldMatchSpec(), equalTo(queryBuilder.highFreqMinimumShouldMatch()));
-        assertThat(extendedCommonTermsQuery.getLowFreqMinimumNumberShouldMatchSpec(), equalTo(queryBuilder.lowFreqMinimumShouldMatch()));
-    }
-
-    @Test
-    public void testValidate() {
-        CommonTermsQueryBuilder commonTermsQueryBuilder = new CommonTermsQueryBuilder("", "text");
-        assertThat(commonTermsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        commonTermsQueryBuilder = new CommonTermsQueryBuilder("field", null);
-        assertThat(commonTermsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        commonTermsQueryBuilder = new CommonTermsQueryBuilder("field", "text");
-        assertNull(commonTermsQueryBuilder.validate());
-    }
-
-    @Test
-    public void testNoTermsFromQueryString() throws IOException {
-        CommonTermsQueryBuilder builder = new CommonTermsQueryBuilder(STRING_FIELD_NAME, "");
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-        assertNull(builder.toQuery(context));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ConstantScoreQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/ConstantScoreQueryBuilderTests.java
deleted file mode 100644
index 7e3e48e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/ConstantScoreQueryBuilderTests.java
+++ /dev/null
@@ -1,76 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.*;
-
-public class ConstantScoreQueryBuilderTests extends BaseQueryTestCase<ConstantScoreQueryBuilder> {
-
-    /**
-     * @return a {@link ConstantScoreQueryBuilder} with random boost between 0.1f and 2.0f
-     */
-    @Override
-    protected ConstantScoreQueryBuilder doCreateTestQueryBuilder() {
-        return new ConstantScoreQueryBuilder(RandomQueryBuilder.createQuery(random()));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(ConstantScoreQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query innerQuery = queryBuilder.innerQuery().toQuery(context);
-        if (innerQuery == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(ConstantScoreQuery.class));
-            ConstantScoreQuery constantScoreQuery = (ConstantScoreQuery) query;
-            assertThat(constantScoreQuery.getQuery(), equalTo(innerQuery));
-        }
-    }
-
-    /**
-     * test that missing "filter" element causes {@link QueryParsingException}
-     */
-    @Test(expected=QueryParsingException.class)
-    public void testFilterElement() throws IOException {
-        String queryString = "{ \"" + ConstantScoreQueryBuilder.NAME + "\" : {}";
-        parseQuery(queryString);
-    }
-
-    @Test
-    public void testValidate() {
-        QueryBuilder innerQuery = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        ConstantScoreQueryBuilder constantScoreQuery = new ConstantScoreQueryBuilder(innerQuery);
-        assertValidate(constantScoreQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/DisMaxQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/DisMaxQueryBuilderTests.java
deleted file mode 100644
index 4999814..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/DisMaxQueryBuilderTests.java
+++ /dev/null
@@ -1,128 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.DisjunctionMaxQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.Map;
-
-import static org.hamcrest.CoreMatchers.*;
-
-public class DisMaxQueryBuilderTests extends BaseQueryTestCase<DisMaxQueryBuilder> {
-
-    /**
-     * @return a {@link DisMaxQueryBuilder} with random inner queries
-     */
-    @Override
-    protected DisMaxQueryBuilder doCreateTestQueryBuilder() {
-        DisMaxQueryBuilder dismax = new DisMaxQueryBuilder();
-        int clauses = randomIntBetween(1, 5);
-        for (int i = 0; i < clauses; i++) {
-            dismax.add(RandomQueryBuilder.createQuery(random()));
-        }
-        if (randomBoolean()) {
-            dismax.tieBreaker(2.0f / randomIntBetween(1, 20));
-        }
-        return dismax;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(DisMaxQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Collection<Query> queries = AbstractQueryBuilder.toQueries(queryBuilder.innerQueries(), context);
-        if (queries.isEmpty()) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(DisjunctionMaxQuery.class));
-            DisjunctionMaxQuery disjunctionMaxQuery = (DisjunctionMaxQuery) query;
-            assertThat(disjunctionMaxQuery.getTieBreakerMultiplier(), equalTo(queryBuilder.tieBreaker()));
-            assertThat(disjunctionMaxQuery.getDisjuncts().size(), equalTo(queries.size()));
-            Iterator<Query> queryIterator = queries.iterator();
-            for (int i = 0; i < disjunctionMaxQuery.getDisjuncts().size(); i++) {
-                assertThat(disjunctionMaxQuery.getDisjuncts().get(i), equalTo(queryIterator.next()));
-            }
-        }
-    }
-
-    @Override
-    protected Map<String, DisMaxQueryBuilder> getAlternateVersions() {
-        Map<String, DisMaxQueryBuilder> alternateVersions = new HashMap<>();
-        QueryBuilder innerQuery = createTestQueryBuilder().innerQueries().get(0);
-        DisMaxQueryBuilder expectedQuery = new DisMaxQueryBuilder();
-        expectedQuery.add(innerQuery);
-        String contentString = "{\n" +
-                "    \"dis_max\" : {\n" +
-                "        \"queries\" : " + innerQuery.toString() +
-                "    }\n" +
-                "}";
-        alternateVersions.put(contentString, expectedQuery);
-        return alternateVersions;
-    }
-
-    /**
-     * test `null`return value for missing inner queries
-     * @throws IOException
-     * @throws QueryParsingException
-     */
-    @Test
-    public void testNoInnerQueries() throws QueryParsingException, IOException {
-        DisMaxQueryBuilder disMaxBuilder = new DisMaxQueryBuilder();
-        assertNull(disMaxBuilder.toQuery(createShardContext()));
-        assertNull(disMaxBuilder.validate());
-    }
-
-    /**
-     * Test inner query parsing to null. Current DSL allows inner filter element to parse to <tt>null</tt>.
-     * Those should be ignored upstream. To test this, we use inner {@link ConstantScoreQueryBuilder}
-     * with empty inner filter.
-     */
-    @Test
-    public void testInnerQueryReturnsNull() throws IOException {
-        String queryString = "{ \"" + ConstantScoreQueryBuilder.NAME + "\" : { \"filter\" : { } } }";
-        QueryBuilder<?> innerQueryBuilder = parseQuery(queryString);
-        DisMaxQueryBuilder disMaxBuilder = new DisMaxQueryBuilder().add(innerQueryBuilder);
-        assertNull(disMaxBuilder.toQuery(createShardContext()));
-    }
-
-    @Test
-    public void testValidate() {
-        DisMaxQueryBuilder disMaxQuery = new DisMaxQueryBuilder();
-        int iters = randomIntBetween(0, 5);
-        int totalExpectedErrors = 0;
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    disMaxQuery.add(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    disMaxQuery.add(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                disMaxQuery.add(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        assertValidate(disMaxQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ExistsQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/ExistsQueryBuilderTests.java
deleted file mode 100644
index 6b6615d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/ExistsQueryBuilderTests.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.index.mapper.object.ObjectMapper;
-
-import java.io.IOException;
-import java.util.Collection;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class ExistsQueryBuilderTests extends BaseQueryTestCase<ExistsQueryBuilder> {
-
-    @Override
-    protected ExistsQueryBuilder doCreateTestQueryBuilder() {
-        String fieldPattern;
-        if (randomBoolean()) {
-            fieldPattern = randomFrom(MAPPED_FIELD_NAMES);
-        } else {
-            fieldPattern = randomAsciiOfLengthBetween(1, 10);
-        }
-        // also sometimes test wildcard patterns
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                fieldPattern = fieldPattern + "*";
-            } else {
-                fieldPattern = MetaData.ALL;
-            }
-        }
-        return new ExistsQueryBuilder(fieldPattern);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(ExistsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        String fieldPattern = queryBuilder.fieldName();
-        ObjectMapper objectMapper = context.getObjectMapper(fieldPattern);
-        if (objectMapper != null) {
-            // automatic make the object mapper pattern
-            fieldPattern = fieldPattern + ".*";
-        }
-        Collection<String> fields = context.simpleMatchToIndexNames(fieldPattern);
-        if (getCurrentTypes().length == 0 || fields.size() == 0) {
-            assertThat(query, instanceOf(BooleanQuery.class));
-            BooleanQuery booleanQuery = (BooleanQuery) query;
-            assertThat(booleanQuery.clauses().size(), equalTo(0));
-        } else {
-            assertThat(query, instanceOf(ConstantScoreQuery.class));
-            ConstantScoreQuery constantScoreQuery = (ConstantScoreQuery) query;
-            assertThat(constantScoreQuery.getQuery(), instanceOf(BooleanQuery.class));
-            BooleanQuery booleanQuery = (BooleanQuery) constantScoreQuery.getQuery();
-            assertThat(booleanQuery.clauses().size(), equalTo(fields.size()));
-            for (int i = 0; i < fields.size(); i++) {
-                BooleanClause booleanClause = booleanQuery.clauses().get(i);
-                assertThat(booleanClause.getOccur(), equalTo(BooleanClause.Occur.SHOULD));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/FQueryFilterBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/FQueryFilterBuilderTests.java
deleted file mode 100644
index 4092565..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/FQueryFilterBuilderTests.java
+++ /dev/null
@@ -1,91 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.*;
-
-@SuppressWarnings("deprecation")
-public class FQueryFilterBuilderTests extends BaseQueryTestCase<FQueryFilterBuilder> {
-
-    /**
-     * @return a FQueryFilterBuilder with random inner query
-     */
-    @Override
-    protected FQueryFilterBuilder doCreateTestQueryBuilder() {
-        QueryBuilder innerQuery = RandomQueryBuilder.createQuery(random());
-        return new FQueryFilterBuilder(innerQuery);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(FQueryFilterBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query innerQuery = queryBuilder.innerQuery().toQuery(context);
-        if (innerQuery == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(ConstantScoreQuery.class));
-            ConstantScoreQuery constantScoreQuery = (ConstantScoreQuery) query;
-            assertThat(constantScoreQuery.getQuery(), equalTo(innerQuery));
-        }
-    }
-
-    /**
-     * test corner case where no inner query exist
-     */
-    @Test
-    public void testNoInnerQuery() throws QueryParsingException, IOException {
-        FQueryFilterBuilder queryFilterQuery = new FQueryFilterBuilder(EmptyQueryBuilder.PROTOTYPE);
-        assertNull(queryFilterQuery.toQuery(createShardContext()));
-    }
-
-    /**
-     * test wrapping an inner filter that returns null also returns <tt>null</null> to pass on upwards
-     */
-    @Test
-    public void testInnerQueryReturnsNull() throws IOException {
-        // create inner filter
-        String queryString = "{ \"constant_score\" : { \"filter\" : {} } }";
-        QueryBuilder innerQuery = parseQuery(queryString);
-        // check that when wrapping this filter, toQuery() returns null
-        FQueryFilterBuilder queryFilterQuery = new FQueryFilterBuilder(innerQuery);
-        assertNull(queryFilterQuery.toQuery(createShardContext()));
-    }
-
-    @Test
-    public void testValidate() {
-        QueryBuilder innerQuery = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        FQueryFilterBuilder fQueryFilter = new FQueryFilterBuilder(innerQuery);
-        assertValidate(fQueryFilter, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilderTests.java
deleted file mode 100644
index fc0a2ac..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/FieldMaskingSpanQueryBuilderTests.java
+++ /dev/null
@@ -1,83 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class FieldMaskingSpanQueryBuilderTests extends BaseQueryTestCase<FieldMaskingSpanQueryBuilder> {
-
-    @Override
-    protected FieldMaskingSpanQueryBuilder doCreateTestQueryBuilder() {
-        String fieldName;
-        if (randomBoolean()) {
-            fieldName = randomFrom(MAPPED_FIELD_NAMES);
-        } else {
-            fieldName = randomAsciiOfLengthBetween(1, 10);
-        }
-        SpanTermQueryBuilder innerQuery = new SpanTermQueryBuilderTests().createTestQueryBuilder();
-        return new FieldMaskingSpanQueryBuilder(innerQuery, fieldName);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(FieldMaskingSpanQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        String fieldInQuery = queryBuilder.fieldName();
-        MappedFieldType fieldType = context.fieldMapper(fieldInQuery);
-        if (fieldType != null) {
-            fieldInQuery = fieldType.names().indexName();
-        }
-        assertThat(query, instanceOf(FieldMaskingSpanQuery.class));
-        FieldMaskingSpanQuery fieldMaskingSpanQuery = (FieldMaskingSpanQuery) query;
-        assertThat(fieldMaskingSpanQuery.getField(), equalTo(fieldInQuery));
-        assertThat(fieldMaskingSpanQuery.getMaskedQuery(), equalTo(queryBuilder.innerQuery().toQuery(context)));
-    }
-
-    @Test
-    public void testValidate() {
-        String fieldName = null;
-        SpanQueryBuilder spanQueryBuilder = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            fieldName = "fieldName";
-        } else {
-            if (randomBoolean()) {
-                fieldName = "";
-            }
-            totalExpectedErrors++;
-        }
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                spanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            }
-            totalExpectedErrors++;
-        } else {
-            spanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        FieldMaskingSpanQueryBuilder queryBuilder = new FieldMaskingSpanQueryBuilder(spanQueryBuilder, fieldName);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/FilteredQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/FilteredQueryBuilderTests.java
deleted file mode 100644
index 4d6036d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/FilteredQueryBuilderTests.java
+++ /dev/null
@@ -1,108 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-import static org.hamcrest.CoreMatchers.nullValue;
-
-@SuppressWarnings("deprecation")
-public class FilteredQueryBuilderTests extends BaseQueryTestCase<FilteredQueryBuilder> {
-
-    @Override
-    protected FilteredQueryBuilder doCreateTestQueryBuilder() {
-        QueryBuilder queryBuilder = RandomQueryBuilder.createQuery(random());
-        QueryBuilder filterBuilder = RandomQueryBuilder.createQuery(random());
-        return new FilteredQueryBuilder(queryBuilder, filterBuilder);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(FilteredQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query innerQuery = queryBuilder.innerQuery().toQuery(context);
-        if (innerQuery == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(BooleanQuery.class));
-            BooleanQuery booleanQuery = (BooleanQuery) query;
-            Query innerFilter = queryBuilder.innerFilter().toQuery(context);
-            if (innerFilter == null) {
-                assertThat(booleanQuery.clauses().size(), equalTo(1));
-                assertThat(booleanQuery.clauses().get(0).getOccur(), equalTo(BooleanClause.Occur.MUST));
-                assertThat(booleanQuery.clauses().get(0).getQuery(), equalTo(innerQuery));
-            } else {
-                assertThat(booleanQuery.clauses().get(0).getOccur(), equalTo(BooleanClause.Occur.MUST));
-                assertThat(booleanQuery.clauses().get(0).getQuery(), equalTo(innerQuery));
-                assertThat(booleanQuery.clauses().get(1).getOccur(), equalTo(BooleanClause.Occur.FILTER));
-                assertThat(booleanQuery.clauses().get(1).getQuery(), equalTo(innerFilter));
-            }
-        }
-    }
-
-    @Test
-    public void testValidation() {
-        QueryBuilder valid = RandomQueryBuilder.createQuery(random());
-        QueryBuilder invalid = RandomQueryBuilder.createInvalidQuery(random());
-
-        // invalid cases
-        FilteredQueryBuilder qb = new FilteredQueryBuilder(invalid);
-        QueryValidationException result = qb.validate();
-        assertNotNull(result);
-        assertEquals(1, result.validationErrors().size());
-
-        qb = new FilteredQueryBuilder(valid, invalid);
-        result = qb.validate();
-        assertNotNull(result);
-        assertEquals(1, result.validationErrors().size());
-
-        qb = new FilteredQueryBuilder(invalid, valid);
-        result = qb.validate();
-        assertNotNull(result);
-        assertEquals(1, result.validationErrors().size());
-
-        qb = new FilteredQueryBuilder(invalid, invalid);
-        result = qb.validate();
-        assertNotNull(result);
-        assertEquals(2, result.validationErrors().size());
-
-        // valid cases
-        qb = new FilteredQueryBuilder(valid);
-        assertNull(qb.validate());
-
-        qb = new FilteredQueryBuilder(null);
-        assertNull(qb.validate());
-
-        qb = new FilteredQueryBuilder(null, valid);
-        assertNull(qb.validate());
-
-        qb = new FilteredQueryBuilder(valid, null);
-        assertNull(qb.validate());
-
-        qb = new FilteredQueryBuilder(valid, valid);
-        assertNull(qb.validate());
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/FuzzyQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/FuzzyQueryBuilderTests.java
deleted file mode 100644
index d74b442..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/FuzzyQueryBuilderTests.java
+++ /dev/null
@@ -1,98 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.collect.Tuple;
-import org.elasticsearch.common.unit.Fuzziness;
-import org.hamcrest.Matchers;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class FuzzyQueryBuilderTests extends BaseQueryTestCase<FuzzyQueryBuilder> {
-
-    @Override
-    protected FuzzyQueryBuilder doCreateTestQueryBuilder() {
-        Tuple<String, Object> fieldAndValue = getRandomFieldNameAndValue();
-        FuzzyQueryBuilder query = new FuzzyQueryBuilder(fieldAndValue.v1(), fieldAndValue.v2());
-        if (randomBoolean()) {
-            query.fuzziness(randomFuzziness(query.fieldName()));
-        }
-        if (randomBoolean()) {
-            query.prefixLength(randomIntBetween(0, 10));
-        }
-        if (randomBoolean()) {
-            query.maxExpansions(randomIntBetween(1, 10));
-        }
-        if (randomBoolean()) {
-            query.transpositions(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.rewrite(getRandomRewriteMethod());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(FuzzyQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (isNumericFieldName(queryBuilder.fieldName()) || queryBuilder.fieldName().equals(DATE_FIELD_NAME)) {
-            assertThat(query, instanceOf(NumericRangeQuery.class));
-        } else {
-            assertThat(query, instanceOf(FuzzyQuery.class));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        FuzzyQueryBuilder fuzzyQueryBuilder = new FuzzyQueryBuilder("", "text");
-        assertThat(fuzzyQueryBuilder.validate().validationErrors().size(), is(1));
-
-        fuzzyQueryBuilder = new FuzzyQueryBuilder("field", null);
-        assertThat(fuzzyQueryBuilder.validate().validationErrors().size(), is(1));
-
-        fuzzyQueryBuilder = new FuzzyQueryBuilder("field", "text");
-        assertNull(fuzzyQueryBuilder.validate());
-
-        fuzzyQueryBuilder = new FuzzyQueryBuilder(null, null);
-        assertThat(fuzzyQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-    
-    @Test
-    public void testUnsupportedFuzzinessForStringType() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-        
-        FuzzyQueryBuilder fuzzyQueryBuilder = new FuzzyQueryBuilder(STRING_FIELD_NAME, "text");
-        fuzzyQueryBuilder.fuzziness(Fuzziness.build(randomFrom("a string which is not auto", "3h", "200s")));
-
-        try {
-            fuzzyQueryBuilder.toQuery(context);
-            fail("should have failed with NumberFormatException");
-        } catch (NumberFormatException e) {
-            assertThat(e.getMessage(), Matchers.containsString("For input string"));
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java b/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java
deleted file mode 100644
index cba0ab7..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/GeoDistanceRangeQueryTests.java
+++ /dev/null
@@ -1,246 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.geo.GeoDistance;
-import org.elasticsearch.common.geo.GeoPoint;
-import org.elasticsearch.common.unit.DistanceUnit;
-import org.elasticsearch.index.search.geo.GeoDistanceRangeQuery;
-import org.joda.time.DateTime;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.closeTo;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.notNullValue;
-
-public class GeoDistanceRangeQueryTests extends BaseQueryTestCase<GeoDistanceRangeQueryBuilder> {
-
-    @Override
-    protected GeoDistanceRangeQueryBuilder doCreateTestQueryBuilder() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_FIELD_NAME);
-        if (randomBoolean()) {
-            builder.geohash(randomGeohash(1, 12));
-        } else {
-            double lat = randomDouble() * 180 - 90;
-            double lon = randomDouble() * 360 - 180;
-            if (randomBoolean()) {
-                builder.point(lat, lon);
-            } else {
-                builder.point(new GeoPoint(lat, lon));
-            }
-        }
-        int fromValue = randomInt(1000000);
-        int toValue = randomIntBetween(fromValue, 1000000);
-        String fromToUnits = randomFrom(DistanceUnit.values()).toString();
-        if (randomBoolean()) {
-            int branch = randomInt(2);
-            switch (branch) {
-            case 0:
-                builder.from(fromValue);
-                break;
-            case 1:
-                builder.to(toValue);
-                break;
-            case 2:
-                builder.from(fromValue);
-                builder.to(toValue);
-                break;
-            }
-        } else {
-            int branch = randomInt(2);
-            switch (branch) {
-            case 0:
-                builder.from(fromValue + fromToUnits);
-                break;
-            case 1:
-                builder.to(toValue + fromToUnits);
-                break;
-            case 2:
-                builder.from(fromValue + fromToUnits);
-                builder.to(toValue + fromToUnits);
-                break;
-            }
-        }
-        if (randomBoolean()) {
-            builder.includeLower(randomBoolean());
-        }
-        if (randomBoolean()) {
-            builder.includeUpper(randomBoolean());
-        }
-        if (randomBoolean()) {
-            builder.geoDistance(randomFrom(GeoDistance.values()));
-        }
-        if (randomBoolean()) {
-            builder.unit(randomFrom(DistanceUnit.values()));
-        }
-        if (randomBoolean()) {
-            builder.optimizeBbox(randomFrom("none", "memory", "indexed"));
-        }
-        if (randomBoolean()) {
-            builder.coerce(randomBoolean());
-        }
-        if (randomBoolean()) {
-            builder.ignoreMalformed(randomBoolean());
-        }
-        return builder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(GeoDistanceRangeQueryBuilder queryBuilder, Query query, QueryShardContext context)
-            throws IOException {
-        assertThat(query, instanceOf(GeoDistanceRangeQuery.class));
-        GeoDistanceRangeQuery geoQuery = (GeoDistanceRangeQuery) query;
-        assertThat(geoQuery.fieldName(), equalTo(queryBuilder.fieldName()));
-        if (queryBuilder.point() != null) {
-            assertThat(geoQuery.lat(), equalTo(queryBuilder.point().lat()));
-            assertThat(geoQuery.lon(), equalTo(queryBuilder.point().lon()));
-        }
-        assertThat(geoQuery.geoDistance(), equalTo(queryBuilder.geoDistance()));
-        if (queryBuilder.from() != null && queryBuilder.from() instanceof Number) {
-            double fromValue = ((Number) queryBuilder.from()).doubleValue();
-            if (queryBuilder.unit() != null) {
-                fromValue = queryBuilder.unit().toMeters(fromValue);
-            }
-            if (queryBuilder.geoDistance() != null) {
-                fromValue = queryBuilder.geoDistance().normalize(fromValue, DistanceUnit.DEFAULT);
-            }
-            assertThat(geoQuery.minInclusiveDistance(), closeTo(fromValue, Math.abs(fromValue) / 1000));
-        }
-        if (queryBuilder.to() != null && queryBuilder.to() instanceof Number) {
-            double toValue = ((Number) queryBuilder.to()).doubleValue();
-            if (queryBuilder.unit() != null) {
-                toValue = queryBuilder.unit().toMeters(toValue);
-            }
-            if (queryBuilder.geoDistance() != null) {
-                toValue = queryBuilder.geoDistance().normalize(toValue, DistanceUnit.DEFAULT);
-            }
-            assertThat(geoQuery.maxInclusiveDistance(), closeTo(toValue, Math.abs(toValue) / 1000));
-        }
-    }
-
-    /**
-     * Overridden here to ensure the test is only run if at least one type is
-     * present in the mappings. Geo queries do not execute if the field is not
-     * explicitly mapped
-     */
-    @Override
-    public void testToQuery() throws IOException {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        super.testToQuery();
-    }
-
-    @Test
-    public void testNullFieldName() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(null);
-        builder.geohash(randomGeohash(1, 20));
-        builder.from(10);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME + "] fieldName must not be null"));
-    }
-
-    @Test
-    public void testNoPoint() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_FIELD_NAME);
-        builder.from(10);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME + "] point must not be null"));
-    }
-
-    @Test
-    public void testNoFromOrTo() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_FIELD_NAME);
-        String geohash = randomGeohash(1, 20);
-        builder.geohash(geohash);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME
-                + "] Must define at least one parameter from [from, to]"));
-    }
-
-    @Test
-    public void testInvalidFrom() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_FIELD_NAME);
-        String geohash = randomGeohash(1, 20);
-        builder.geohash(geohash);
-        builder.from(new DateTime());
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME
-                + "] from must either be a number or a string. Found [" + DateTime.class.getName() + "]"));
-    }
-
-    @Test
-    public void testInvalidTo() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_FIELD_NAME);
-        String geohash = randomGeohash(1, 20);
-        builder.geohash(geohash);
-        builder.to(new DateTime());
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME
-                + "] to must either be a number or a string. Found [" + DateTime.class.getName() + "]"));
-    }
-
-    @Test
-    public void testInvalidOptimizeBBox() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_FIELD_NAME);
-        String geohash = randomGeohash(1, 20);
-        builder.geohash(geohash);
-        builder.from(10);
-        builder.optimizeBbox("foo");
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeoDistanceRangeQueryBuilder.NAME
-                + "] optimizeBbox must be one of [none, memory, indexed]"));
-    }
-
-    @Test
-    public void testMultipleValidationErrors() {
-        GeoDistanceRangeQueryBuilder builder = new GeoDistanceRangeQueryBuilder(GEO_FIELD_NAME);
-        double lat = randomDouble() * 360 - 180;
-        double lon = randomDouble() * 360 - 180;
-        builder.point(lat, lon);
-        builder.from(new DateTime());
-        builder.to(new DateTime());
-        builder.optimizeBbox("foo");
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(3));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/GeohashCellQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/GeohashCellQueryBuilderTests.java
deleted file mode 100644
index 5a40863..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/GeohashCellQueryBuilderTests.java
+++ /dev/null
@@ -1,119 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.common.unit.DistanceUnit;
-import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
-import org.elasticsearch.index.query.GeohashCellQuery.Builder;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.notNullValue;
-
-public class GeohashCellQueryBuilderTests extends BaseQueryTestCase<GeohashCellQuery.Builder> {
-
-    @Override
-    protected Builder doCreateTestQueryBuilder() {
-        GeohashCellQuery.Builder builder = new Builder(GEO_FIELD_NAME);
-        builder.geohash(randomGeohash(1, 12));
-        if (randomBoolean()) {
-            builder.neighbors(randomBoolean());
-        }
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                builder.precision(randomIntBetween(1, 12));
-            } else {
-                builder.precision(randomIntBetween(1, 1000000) + randomFrom(DistanceUnit.values()).toString());
-            }
-        }
-        return builder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(Builder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.neighbors()) {
-            assertThat(query, instanceOf(TermsQuery.class));
-        } else {
-            assertThat(query, instanceOf(TermQuery.class));
-            TermQuery termQuery = (TermQuery) query;
-            Term term = termQuery.getTerm();
-            assertThat(term.field(), equalTo(queryBuilder.fieldName() + GeoPointFieldMapper.Names.GEOHASH_SUFFIX));
-            String geohash = queryBuilder.geohash();
-            if (queryBuilder.precision() != null) {
-                int len = Math.min(queryBuilder.precision(), geohash.length());
-                geohash = geohash.substring(0, len);
-            }
-            assertThat(term.text(), equalTo(geohash));
-        }
-    }
-
-    /**
-     * Overridden here to ensure the test is only run if at least one type is
-     * present in the mappings. Geo queries do not execute if the field is not
-     * explicitly mapped
-     */
-    @Override
-    public void testToQuery() throws IOException {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        super.testToQuery();
-    }
-
-    @Test
-    public void testNullField() {
-        GeohashCellQuery.Builder builder = new Builder(null);
-        builder.geohash(randomGeohash(1, 12));
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeohashCellQuery.NAME + "] fieldName must not be null"));
-    }
-
-    @Test
-    public void testNullGeohash() {
-        GeohashCellQuery.Builder builder = new Builder(GEO_FIELD_NAME);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeohashCellQuery.NAME + "] geohash or point must be defined"));
-    }
-
-    @Test
-    public void testInvalidPrecision() {
-        GeohashCellQuery.Builder builder = new Builder(GEO_FIELD_NAME);
-        builder.geohash(randomGeohash(1, 12));
-        builder.precision(-1);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-        assertThat(exception.validationErrors(), notNullValue());
-        assertThat(exception.validationErrors().size(), equalTo(1));
-        assertThat(exception.validationErrors().get(0), equalTo("[" + GeohashCellQuery.NAME + "] precision must be greater than 0. Found ["
-                + -1 + "]"));
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java
deleted file mode 100644
index e9bdb55..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java
+++ /dev/null
@@ -1,221 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.Version;
-import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;
-import org.elasticsearch.common.compress.CompressedXContent;
-import org.elasticsearch.common.xcontent.*;
-import org.elasticsearch.index.fielddata.IndexFieldDataService;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.index.search.child.ChildrenQuery;
-import org.elasticsearch.index.search.child.ScoreType;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.sort.SortOrder;
-import org.elasticsearch.test.TestSearchContext;
-
-import java.io.IOException;
-
-import static org.elasticsearch.test.StreamsUtils.copyToStringFromClasspath;
-import static org.hamcrest.CoreMatchers.*;
-
-public class HasChildQueryBuilderTests extends BaseQueryTestCase<HasChildQueryBuilder> {
-    protected static final String PARENT_TYPE = "parent";
-    protected static final String CHILD_TYPE = "child";
-
-    public void setUp() throws Exception {
-        super.setUp();
-        MapperService mapperService = queryParserService().mapperService;
-        mapperService.merge(PARENT_TYPE, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(PARENT_TYPE,
-                STRING_FIELD_NAME, "type=string",
-                INT_FIELD_NAME, "type=integer",
-                DOUBLE_FIELD_NAME, "type=double",
-                BOOLEAN_FIELD_NAME, "type=boolean",
-                DATE_FIELD_NAME, "type=date",
-                OBJECT_FIELD_NAME, "type=object"
-        ).string()), false, false);
-        mapperService.merge(CHILD_TYPE, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(CHILD_TYPE,
-                "_parent", "type=" + PARENT_TYPE,
-                STRING_FIELD_NAME, "type=string",
-                INT_FIELD_NAME, "type=integer",
-                DOUBLE_FIELD_NAME, "type=double",
-                BOOLEAN_FIELD_NAME, "type=boolean",
-                DATE_FIELD_NAME, "type=date",
-                OBJECT_FIELD_NAME, "type=object"
-        ).string()), false, false);
-    }
-
-    protected void setSearchContext(String[] types) {
-        final MapperService mapperService = queryParserService().mapperService;
-        final IndexFieldDataService fieldData = queryParserService().fieldDataService;
-        TestSearchContext testSearchContext = new TestSearchContext() {
-            private InnerHitsContext context;
-
-
-            @Override
-            public void innerHits(InnerHitsContext innerHitsContext) {
-                context = innerHitsContext;
-            }
-
-            @Override
-            public InnerHitsContext innerHits() {
-                return context;
-            }
-
-            @Override
-            public MapperService mapperService() {
-                return mapperService; // need to build / parse inner hits sort fields
-            }
-
-            @Override
-            public IndexFieldDataService fieldData() {
-                return fieldData; // need to build / parse inner hits sort fields
-            }
-        };
-        testSearchContext.setTypes(types);
-        SearchContext.setCurrent(testSearchContext);
-    }
-
-    /**
-     * @return a {@link HasChildQueryBuilder} with random values all over the place
-     */
-    @Override
-    protected HasChildQueryBuilder doCreateTestQueryBuilder() {
-        int min = randomIntBetween(0, Integer.MAX_VALUE / 2);
-        int max = randomIntBetween(min, Integer.MAX_VALUE);
-        InnerHitsBuilder.InnerHit innerHit = new InnerHitsBuilder.InnerHit().setSize(100).addSort(STRING_FIELD_NAME, SortOrder.ASC);
-        return new HasChildQueryBuilder(CHILD_TYPE,
-                RandomQueryBuilder.createQuery(random()), max, min, randomIntBetween(0, Integer.MAX_VALUE),
-                RandomPicks.randomFrom(random(), ScoreType.values()),
-                SearchContext.current() == null ? null : new QueryInnerHits("inner_hits_name", innerHit));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(HasChildQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        QueryBuilder innerQueryBuilder = queryBuilder.query();
-        if (innerQueryBuilder instanceof EmptyQueryBuilder) {
-            assertNull(query);
-        } else if (context.indexVersionCreated().onOrAfter(Version.V_2_0_0_beta1)) {
-            assertThat(query, instanceOf(HasChildQueryBuilder.LateParsingQuery.class));
-            HasChildQueryBuilder.LateParsingQuery lpq = (HasChildQueryBuilder.LateParsingQuery) query;
-            assertEquals(queryBuilder.minChildren(), lpq.getMinChildren());
-            assertEquals(queryBuilder.maxChildren(), lpq.getMaxChildren());
-            assertEquals(HasChildQueryBuilder.scoreTypeToScoreMode(queryBuilder.scoreType()), lpq.getScoreMode()); // WTF is this why do we have two?
-        } else {
-            assertThat(query, instanceOf(ChildrenQuery.class));
-            ChildrenQuery lpq = (ChildrenQuery) query;
-            assertEquals(queryBuilder.minChildren(), lpq.getMinChildren());
-            assertEquals(queryBuilder.maxChildren(), lpq.getMaxChildren());
-            assertEquals(queryBuilder.scoreType(), lpq.getScoreType());
-            assertEquals(queryBuilder.shortCircuitCutoff(), lpq.getShortCircuitParentDocSet());
-        }
-        if (queryBuilder.innerHit() != null) {
-            assertNotNull(SearchContext.current());
-            if (query != null) {
-                assertNotNull(SearchContext.current().innerHits());
-                assertEquals(1, SearchContext.current().innerHits().getInnerHits().size());
-                assertTrue(SearchContext.current().innerHits().getInnerHits().containsKey("inner_hits_name"));
-                InnerHitsContext.BaseInnerHits innerHits = SearchContext.current().innerHits().getInnerHits().get("inner_hits_name");
-                assertEquals(innerHits.size(), 100);
-                assertEquals(innerHits.sort().getSort().length, 1);
-                assertEquals(innerHits.sort().getSort()[0].getField(), STRING_FIELD_NAME);
-            } else {
-                assertNull(SearchContext.current().innerHits());
-            }
-        }
-    }
-
-    public void testIllegalValues() {
-        QueryBuilder query = RandomQueryBuilder.createQuery(random());
-        try {
-            new HasChildQueryBuilder(null, query);
-            fail("must not be null");
-        } catch (IllegalArgumentException ex) {
-
-        }
-
-        try {
-            new HasChildQueryBuilder("foo", null);
-            fail("must not be null");
-        } catch (IllegalArgumentException ex) {
-
-        }
-        HasChildQueryBuilder foo = new HasChildQueryBuilder("foo", query);// all good
-        try {
-            foo.scoreType(null);
-            fail("must not be null");
-        } catch (IllegalArgumentException ex) {
-
-        }
-        final int positiveValue = randomIntBetween(0, Integer.MAX_VALUE);
-        try {
-            foo.shortCircuitCutoff(randomIntBetween(Integer.MIN_VALUE, -1));
-            fail("must not be negative");
-        } catch (IllegalArgumentException ex) {
-
-        }
-
-        foo.shortCircuitCutoff(positiveValue);
-        assertEquals(positiveValue, foo.shortCircuitCutoff());
-
-        try {
-            foo.minChildren(randomIntBetween(Integer.MIN_VALUE, -1));
-            fail("must not be negative");
-        } catch (IllegalArgumentException ex) {
-
-        }
-        foo.minChildren(positiveValue);
-        assertEquals(positiveValue, foo.minChildren());
-        try {
-            foo.maxChildren(randomIntBetween(Integer.MIN_VALUE, -1));
-            fail("must not be negative");
-        } catch (IllegalArgumentException ex) {
-
-        }
-
-        foo.maxChildren(positiveValue);
-        assertEquals(positiveValue, foo.maxChildren());
-    }
-
-    public void testParseFromJSON() throws IOException {
-        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/has-child-with-inner-hits.json").trim();
-        HasChildQueryBuilder queryBuilder = (HasChildQueryBuilder) parseQuery(query);
-        assertEquals(query, queryBuilder.maxChildren(), 1217235442);
-        assertEquals(query, queryBuilder.minChildren(), 883170873);
-        assertEquals(query, queryBuilder.shortCircuitCutoff(), 340606183);
-        assertEquals(query, queryBuilder.boost(), 2.0f, 0.0f);
-        assertEquals(query, queryBuilder.queryName(), "WNzYMJKRwePuRBh");
-        assertEquals(query, queryBuilder.childType(), "child");
-        assertEquals(query, queryBuilder.scoreType(), ScoreType.AVG);
-        assertNotNull(query, queryBuilder.innerHit());
-        assertEquals(query, queryBuilder.innerHit(), new QueryInnerHits("inner_hits_name", new InnerHitsBuilder.InnerHit().setSize(100).addSort("mapped_string", SortOrder.ASC)));
-        // now assert that we actually generate the same JSON
-        XContentBuilder builder = XContentFactory.jsonBuilder().prettyPrint();
-        queryBuilder.toXContent(builder, ToXContent.EMPTY_PARAMS);
-        assertEquals(query, builder.string());
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/HasParentQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/HasParentQueryBuilderTests.java
deleted file mode 100644
index 9bdff9c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/HasParentQueryBuilderTests.java
+++ /dev/null
@@ -1,212 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.join.ScoreMode;
-import org.elasticsearch.Version;
-import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.compress.CompressedXContent;
-import org.elasticsearch.common.xcontent.*;
-import org.elasticsearch.index.fielddata.IndexFieldDataService;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.index.search.child.ChildrenQuery;
-import org.elasticsearch.index.search.child.ParentConstantScoreQuery;
-import org.elasticsearch.index.search.child.ParentQuery;
-import org.elasticsearch.index.search.child.ScoreType;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsContext;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.sort.SortOrder;
-import org.elasticsearch.test.TestSearchContext;
-
-import java.io.IOException;
-import java.util.Arrays;
-
-import static org.elasticsearch.test.StreamsUtils.copyToStringFromClasspath;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class HasParentQueryBuilderTests extends BaseQueryTestCase<HasParentQueryBuilder> {
-    protected static final String PARENT_TYPE = "parent";
-    protected static final String CHILD_TYPE = "child";
-
-    public void setUp() throws Exception {
-        super.setUp();
-        MapperService mapperService = queryParserService().mapperService;
-        mapperService.merge(PARENT_TYPE, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(PARENT_TYPE,
-                STRING_FIELD_NAME, "type=string",
-                INT_FIELD_NAME, "type=integer",
-                DOUBLE_FIELD_NAME, "type=double",
-                BOOLEAN_FIELD_NAME, "type=boolean",
-                DATE_FIELD_NAME, "type=date",
-                OBJECT_FIELD_NAME, "type=object"
-        ).string()), false, false);
-        mapperService.merge(CHILD_TYPE, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(CHILD_TYPE,
-                "_parent", "type=" + PARENT_TYPE,
-                STRING_FIELD_NAME, "type=string",
-                INT_FIELD_NAME, "type=integer",
-                DOUBLE_FIELD_NAME, "type=double",
-                BOOLEAN_FIELD_NAME, "type=boolean",
-                DATE_FIELD_NAME, "type=date",
-                OBJECT_FIELD_NAME, "type=object"
-        ).string()), false, false);
-    }
-
-    protected void setSearchContext(String[] types) {
-        final MapperService mapperService = queryParserService().mapperService;
-        final IndexFieldDataService fieldData = queryParserService().fieldDataService;
-        TestSearchContext testSearchContext = new TestSearchContext() {
-            private InnerHitsContext context;
-
-
-            @Override
-            public void innerHits(InnerHitsContext innerHitsContext) {
-                context = innerHitsContext;
-            }
-
-            @Override
-            public InnerHitsContext innerHits() {
-                return context;
-            }
-
-            @Override
-            public MapperService mapperService() {
-                return mapperService; // need to build / parse inner hits sort fields
-            }
-
-            @Override
-            public IndexFieldDataService fieldData() {
-                return fieldData; // need to build / parse inner hits sort fields
-            }
-        };
-        testSearchContext.setTypes(types);
-        SearchContext.setCurrent(testSearchContext);
-    }
-
-    /**
-     * @return a {@link HasChildQueryBuilder} with random values all over the place
-     */
-    @Override
-    protected HasParentQueryBuilder doCreateTestQueryBuilder() {
-        InnerHitsBuilder.InnerHit innerHit = new InnerHitsBuilder.InnerHit().setSize(100).addSort(STRING_FIELD_NAME, SortOrder.ASC);
-        return new HasParentQueryBuilder(PARENT_TYPE,
-                RandomQueryBuilder.createQuery(random()),randomBoolean(),
-                SearchContext.current() == null ? null : new QueryInnerHits("inner_hits_name", innerHit));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(HasParentQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        QueryBuilder innerQueryBuilder = queryBuilder.query();
-        if (innerQueryBuilder instanceof EmptyQueryBuilder) {
-            assertNull(query);
-        } else if (context.indexVersionCreated().onOrAfter(Version.V_2_0_0_beta1)) {
-            assertThat(query, instanceOf(HasChildQueryBuilder.LateParsingQuery.class));
-            HasChildQueryBuilder.LateParsingQuery lpq = (HasChildQueryBuilder.LateParsingQuery) query;
-            assertEquals(queryBuilder.score() ? ScoreMode.Max : ScoreMode.None, lpq.getScoreMode());
-        } else {
-            if (queryBuilder.score()) {
-                assertThat(query, instanceOf(ParentQuery.class));
-                ParentQuery pq = (ParentQuery) query;
-                assertEquals(queryBuilder.boost(), pq.getBoost(), 0f);
-            } else {
-                assertThat(query, instanceOf(ParentConstantScoreQuery.class));
-                ParentConstantScoreQuery csq = (ParentConstantScoreQuery) query;
-                assertEquals(queryBuilder.boost(), csq.getBoost(), 0f);
-            }
-        }
-        if (queryBuilder.innerHit() != null) {
-            assertNotNull(SearchContext.current());
-            if (query != null) {
-                assertNotNull(SearchContext.current().innerHits());
-                assertEquals(1, SearchContext.current().innerHits().getInnerHits().size());
-                assertTrue(SearchContext.current().innerHits().getInnerHits().containsKey("inner_hits_name"));
-                InnerHitsContext.BaseInnerHits innerHits = SearchContext.current().innerHits().getInnerHits().get("inner_hits_name");
-                assertEquals(innerHits.size(), 100);
-                assertEquals(innerHits.sort().getSort().length, 1);
-                assertEquals(innerHits.sort().getSort()[0].getField(), STRING_FIELD_NAME);
-            } else {
-                assertNull(SearchContext.current().innerHits());
-            }
-        }
-    }
-
-    public void testIllegalValues() {
-        QueryBuilder query = RandomQueryBuilder.createQuery(random());
-        try {
-            new HasParentQueryBuilder(null, query);
-            fail("must not be null");
-        } catch (IllegalArgumentException ex) {
-
-        }
-
-        try {
-            new HasParentQueryBuilder("foo", null);
-            fail("must not be null");
-        } catch (IllegalArgumentException ex) {
-
-        }
-    }
-
-    public void testDeprecatedXContent() throws IOException {
-        XContentBuilder builder = XContentFactory.jsonBuilder().prettyPrint();
-        builder.startObject();
-        builder.startObject("has_parent");
-        builder.field("query");
-        EmptyQueryBuilder.PROTOTYPE.toXContent(builder, ToXContent.EMPTY_PARAMS);
-        builder.field("type", "foo"); // deprecated
-        builder.endObject();
-        builder.endObject();
-        String queryAsString = builder.string();
-        QueryShardContext shardContext = createShardContext();
-        QueryParseContext context = shardContext.parseContext();
-        XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(queryAsString);
-        context.reset(parser);
-        context.parseFieldMatcher(ParseFieldMatcher.STRICT);
-        try {
-            context.parseInnerQueryBuilder();
-            fail("type is deprecated");
-        } catch (IllegalArgumentException ex) {
-            assertEquals("Deprecated field [type] used, expected [parent_type] instead", ex.getMessage());
-        }
-
-        String key = RandomPicks.randomFrom(random(), Arrays.asList("score_mode", "scoreMode", "score_type", "scoreType"));
-        builder = XContentFactory.jsonBuilder().prettyPrint();
-        builder.startObject();
-        builder.startObject("has_parent");
-        builder.field("query");
-        EmptyQueryBuilder.PROTOTYPE.toXContent(builder, ToXContent.EMPTY_PARAMS);
-        builder.field(key, "score");
-        builder.endObject();
-        builder.endObject();
-        queryAsString = builder.string();
-        parser = XContentFactory.xContent(XContentType.JSON).createParser(queryAsString);
-        context.reset(parser);
-        context.parseFieldMatcher(ParseFieldMatcher.STRICT);
-        try {
-            context.parseInnerQueryBuilder();
-            fail(key + " is deprecated");
-        } catch (IllegalArgumentException ex) {
-            assertEquals("Deprecated field [" + key + "] used, replaced by [score]", ex.getMessage());
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTests.java
deleted file mode 100644
index 52d7c67..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTests.java
+++ /dev/null
@@ -1,124 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-
-import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class IdsQueryBuilderTests extends BaseQueryTestCase<IdsQueryBuilder> {
-
-    /**
-     * check that parser throws exception on missing values field
-     * @throws IOException
-     */
-    @Test(expected=QueryParsingException.class)
-    public void testIdsNotProvided() throws IOException {
-        String noIdsFieldQuery = "{\"ids\" : { \"type\" : \"my_type\"  }";
-        parseQuery(noIdsFieldQuery);
-    }
-
-    @Override
-    protected IdsQueryBuilder doCreateTestQueryBuilder() {
-        String[] types;
-        if (getCurrentTypes().length > 0 && randomBoolean()) {
-            int numberOfTypes = randomIntBetween(1, getCurrentTypes().length);
-            types = new String[numberOfTypes];
-            for (int i = 0; i < numberOfTypes; i++) {
-                if (frequently()) {
-                    types[i] = randomFrom(getCurrentTypes());
-                } else {
-                    types[i] = randomAsciiOfLengthBetween(1, 10);
-                }
-            }
-        } else {
-            if (randomBoolean()) {
-                types = new String[]{MetaData.ALL};
-            } else {
-                types = new String[0];
-            }
-        }
-        int numberOfIds = randomIntBetween(0, 10);
-        String[] ids = new String[numberOfIds];
-        for (int i = 0; i < numberOfIds; i++) {
-            ids[i] = randomAsciiOfLengthBetween(1, 10);
-        }
-        IdsQueryBuilder query;
-        if (types.length > 0 || randomBoolean()) {
-            query = new IdsQueryBuilder(types);
-            query.addIds(ids);
-        } else {
-            query = new IdsQueryBuilder();
-            query.addIds(ids);
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(IdsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.ids().size() == 0) {
-            assertThat(query, instanceOf(BooleanQuery.class));
-            assertThat(((BooleanQuery)query).clauses().size(), equalTo(0));
-        } else {
-            assertThat(query, instanceOf(TermsQuery.class));
-        }
-    }
-
-    @Override
-    protected Map<String, IdsQueryBuilder> getAlternateVersions() {
-        Map<String, IdsQueryBuilder> alternateVersions = new HashMap<>();
-
-        IdsQueryBuilder tempQuery = createTestQueryBuilder();
-        if (tempQuery.types() != null && tempQuery.types().length > 0) {
-            String type = tempQuery.types()[0];
-            IdsQueryBuilder testQuery = new IdsQueryBuilder(type);
-
-            //single value type can also be called _type
-            String contentString1 = "{\n" +
-                        "    \"ids\" : {\n" +
-                        "        \"_type\" : \"" + type + "\",\n" +
-                        "        \"values\" : []\n" +
-                        "    }\n" +
-                        "}";
-            alternateVersions.put(contentString1, testQuery);
-
-            //array of types can also be called type rather than types
-            String contentString2 = "{\n" +
-                        "    \"ids\" : {\n" +
-                        "        \"type\" : [\"" + type + "\"],\n" +
-                        "        \"values\" : []\n" +
-                        "    }\n" +
-                        "}";
-            alternateVersions.put(contentString2, testQuery);
-        }
-
-        return alternateVersions;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java b/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java
index 6222f3b..d581aa6 100644
--- a/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/IndexQueryParserFilterDateRangeTimezoneTests.java
@@ -83,7 +83,7 @@ public class IndexQueryParserFilterDateRangeTimezoneTests extends ESSingleNodeTe
             SearchContext.setCurrent(new TestSearchContext());
             queryParser.parse(query).query();
             fail("A Range Filter on a numeric field with a TimeZone should raise a QueryParsingException");
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             // We expect it
         } finally {
             SearchContext.removeCurrent();
@@ -120,7 +120,7 @@ public class IndexQueryParserFilterDateRangeTimezoneTests extends ESSingleNodeTe
             SearchContext.setCurrent(new TestSearchContext());
             queryParser.parse(query).query();
             fail("A Range Query on a numeric field with a TimeZone should raise a QueryParsingException");
-        } catch (QueryShardException e) {
+        } catch (QueryParsingException e) {
             // We expect it
         } finally {
             SearchContext.removeCurrent();
diff --git a/core/src/test/java/org/elasticsearch/index/query/IndicesQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/IndicesQueryBuilderTests.java
deleted file mode 100644
index 9abdfca..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/IndicesQueryBuilderTests.java
+++ /dev/null
@@ -1,103 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-public class IndicesQueryBuilderTests extends BaseQueryTestCase<IndicesQueryBuilder> {
-
-    @Override
-    protected IndicesQueryBuilder doCreateTestQueryBuilder() {
-        String[] indices;
-        if (randomBoolean()) {
-            indices = new String[]{getIndex().getName()};
-        } else {
-            indices = generateRandomStringArray(5, 10, false, false);
-        }
-        IndicesQueryBuilder query = new IndicesQueryBuilder(RandomQueryBuilder.createQuery(random()), indices);
-
-        switch (randomInt(2)) {
-            case 0:
-                query.noMatchQuery(RandomQueryBuilder.createQuery(random()));
-                break;
-            case 1:
-                query.noMatchQuery(randomFrom(QueryBuilders.matchAllQuery(), new MatchNoneQueryBuilder()));
-                break;
-            default:
-                // do not set noMatchQuery
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(IndicesQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query expected;
-        if (queryBuilder.indices().length == 1 && getIndex().getName().equals(queryBuilder.indices()[0])) {
-            expected = queryBuilder.innerQuery().toQuery(context);
-        } else {
-            expected = queryBuilder.noMatchQuery().toQuery(context);
-        }
-        if (expected != null && queryBuilder.boost() != AbstractQueryBuilder.DEFAULT_BOOST) {
-            expected.setBoost(queryBuilder.boost());
-        }
-        assertEquals(query, expected);
-    }
-
-    @Override
-    protected void assertBoost(IndicesQueryBuilder queryBuilder, Query query) throws IOException {
-        //nothing to do here, boost check is already included in equality check done as part of doAssertLuceneQuery above
-    }
-
-    @Test
-    public void testValidate() {
-        int expectedErrors = 0;
-
-        // inner query
-        QueryBuilder innerQuery;
-        if (randomBoolean()) {
-            // setting innerQuery to null would be caught in the builder already and make validation fail
-            innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            expectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        // indices
-        String[] indices;
-        if (randomBoolean()) {
-            indices = randomBoolean() ? null : new String[0];
-            expectedErrors++;
-        } else {
-            indices = new String[]{"index"};
-        }
-        // no match query
-        QueryBuilder noMatchQuery;
-        if (randomBoolean()) {
-            noMatchQuery = RandomQueryBuilder.createInvalidQuery(random());
-            expectedErrors++;
-        } else {
-            noMatchQuery = RandomQueryBuilder.createQuery(random());
-        }
-
-        assertValidate(new IndicesQueryBuilder(innerQuery, indices).noMatchQuery(noMatchQuery), expectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/LimitQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/LimitQueryBuilderTests.java
deleted file mode 100644
index dfb4716..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/LimitQueryBuilderTests.java
+++ /dev/null
@@ -1,43 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class LimitQueryBuilderTests extends BaseQueryTestCase<LimitQueryBuilder> {
-
-    /**
-     * @return a LimitQueryBuilder with random limit between 0 and 20
-     */
-    @Override
-    protected LimitQueryBuilder doCreateTestQueryBuilder() {
-        return new LimitQueryBuilder(randomIntBetween(0, 20));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(LimitQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(MatchAllDocsQuery.class));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTests.java
deleted file mode 100644
index 5603997..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/MatchAllQueryBuilderTests.java
+++ /dev/null
@@ -1,40 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class MatchAllQueryBuilderTests extends BaseQueryTestCase<MatchAllQueryBuilder> {
-
-    @Override
-    protected MatchAllQueryBuilder doCreateTestQueryBuilder() {
-        return new MatchAllQueryBuilder();
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(MatchAllQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(MatchAllDocsQuery.class));
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/MatchNoneQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MatchNoneQueryBuilderTests.java
deleted file mode 100644
index 1511243..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/MatchNoneQueryBuilderTests.java
+++ /dev/null
@@ -1,48 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class MatchNoneQueryBuilderTests extends BaseQueryTestCase {
-
-    @Override
-    protected boolean supportsBoostAndQueryName() {
-        return false;
-    }
-
-    @Override
-    protected AbstractQueryBuilder doCreateTestQueryBuilder() {
-        return new MatchNoneQueryBuilder();
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(AbstractQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(BooleanQuery.class));
-        BooleanQuery booleanQuery = (BooleanQuery) query;
-        assertThat(booleanQuery.clauses().size(), equalTo(0));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/MissingQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MissingQueryBuilderTests.java
deleted file mode 100644
index d5fe75c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/MissingQueryBuilderTests.java
+++ /dev/null
@@ -1,73 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.is;
-
-public class MissingQueryBuilderTests extends BaseQueryTestCase<MissingQueryBuilder> {
-
-    @Override
-    protected MissingQueryBuilder doCreateTestQueryBuilder() {
-        MissingQueryBuilder query  = new MissingQueryBuilder(randomBoolean() ? randomFrom(MAPPED_FIELD_NAMES) : randomAsciiOfLengthBetween(1, 10));
-        if (randomBoolean()) {
-            query.nullValue(randomBoolean());
-        }
-        if (randomBoolean()) {
-            query.existence(randomBoolean());
-        }
-        // cannot set both to false
-        if ((query.nullValue() == false) && (query.existence() == false)) {
-            query.existence(!query.existence());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(MissingQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        //too many mapping dependent cases to test, we don't want to end up duplication the toQuery method
-    }
-
-    @Test
-    public void testValidate() {
-        MissingQueryBuilder missingQueryBuilder = new MissingQueryBuilder("");
-        assertThat(missingQueryBuilder.validate().validationErrors().size(), is(1));
-
-        missingQueryBuilder = new MissingQueryBuilder(null);
-        assertThat(missingQueryBuilder.validate().validationErrors().size(), is(1));
-
-        missingQueryBuilder = new MissingQueryBuilder("field").existence(false).nullValue(false);
-        assertThat(missingQueryBuilder.validate().validationErrors().size(), is(1));
-
-        missingQueryBuilder = new MissingQueryBuilder("field");
-        assertNull(missingQueryBuilder.validate());
-    }
-
-    @Test(expected = QueryShardException.class)
-    public void testBothNullValueAndExistenceFalse() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-        MissingQueryBuilder.newFilter(context, "field", false, false);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/NotQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/NotQueryBuilderTests.java
deleted file mode 100644
index 5cd870c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/NotQueryBuilderTests.java
+++ /dev/null
@@ -1,108 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.CoreMatchers.*;
-
-public class NotQueryBuilderTests extends BaseQueryTestCase<NotQueryBuilder> {
-
-    /**
-     * @return a NotQueryBuilder with random limit between 0 and 20
-     */
-    @Override
-    protected NotQueryBuilder doCreateTestQueryBuilder() {
-        return new NotQueryBuilder(RandomQueryBuilder.createQuery(random()));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(NotQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query filter = queryBuilder.innerQuery().toQuery(context);
-        if (filter == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(BooleanQuery.class));
-            BooleanQuery booleanQuery = (BooleanQuery) query;
-            assertThat(booleanQuery.clauses().size(), equalTo(2));
-            assertThat(booleanQuery.clauses().get(0).getOccur(), equalTo(BooleanClause.Occur.MUST));
-            assertThat(booleanQuery.clauses().get(0).getQuery(), instanceOf(MatchAllDocsQuery.class));
-            assertThat(booleanQuery.clauses().get(1).getOccur(), equalTo(BooleanClause.Occur.MUST_NOT));
-            assertThat(booleanQuery.clauses().get(1).getQuery(), equalTo(filter));
-        }
-    }
-
-    /**
-     * @throws IOException
-     */
-    @Test(expected=QueryParsingException.class)
-    public void testMissingFilterSection() throws IOException {
-        String queryString = "{ \"not\" : {}";
-        parseQuery(queryString);
-    }
-
-    @Override
-    protected Map<String, NotQueryBuilder> getAlternateVersions() {
-        Map<String, NotQueryBuilder> alternateVersions = new HashMap<>();
-
-        NotQueryBuilder testQuery1 = new NotQueryBuilder(createTestQueryBuilder().innerQuery());
-        String contentString1 = "{\n" +
-                "    \"not\" : {\n" +
-                "        \"filter\" : " + testQuery1.innerQuery().toString() + "\n" +
-                "    }\n" +
-                "}";
-        alternateVersions.put(contentString1, testQuery1);
-
-        QueryBuilder innerQuery = createTestQueryBuilder().innerQuery();
-        //not doesn't support empty query when query/filter element is not specified
-        if (innerQuery != EmptyQueryBuilder.PROTOTYPE) {
-            NotQueryBuilder testQuery2 = new NotQueryBuilder(innerQuery);
-            String contentString2 = "{\n" +
-                    "    \"not\" : " + testQuery2.innerQuery().toString() +  "\n}";
-            alternateVersions.put(contentString2, testQuery2);
-        }
-
-        return alternateVersions;
-    }
-
-    @Test
-    public void testValidate() {
-        QueryBuilder innerQuery = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        NotQueryBuilder notQuery = new NotQueryBuilder(innerQuery);
-        assertValidate(notQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/OrQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/OrQueryBuilderTests.java
deleted file mode 100644
index e190431..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/OrQueryBuilderTests.java
+++ /dev/null
@@ -1,120 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.*;
-
-import static org.hamcrest.CoreMatchers.*;
-
-@SuppressWarnings("deprecation")
-public class OrQueryBuilderTests extends BaseQueryTestCase<OrQueryBuilder> {
-
-    /**
-     * @return an OrQueryBuilder with random limit between 0 and 20
-     */
-    @Override
-    protected OrQueryBuilder doCreateTestQueryBuilder() {
-        OrQueryBuilder query = new OrQueryBuilder();
-        int subQueries = randomIntBetween(1, 5);
-        for (int i = 0; i < subQueries; i++ ) {
-            query.add(RandomQueryBuilder.createQuery(random()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(OrQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (queryBuilder.innerQueries().isEmpty()) {
-            assertThat(query, nullValue());
-        } else {
-            List<Query> innerQueries = new ArrayList<>();
-            for (QueryBuilder subQuery : queryBuilder.innerQueries()) {
-                Query innerQuery = subQuery.toQuery(context);
-                // ignore queries that are null
-                if (innerQuery != null) {
-                    innerQueries.add(innerQuery);
-                }
-            }
-            if (innerQueries.isEmpty()) {
-                assertThat(query, nullValue());
-            } else {
-                assertThat(query, instanceOf(BooleanQuery.class));
-                BooleanQuery booleanQuery = (BooleanQuery) query;
-                assertThat(booleanQuery.clauses().size(), equalTo(innerQueries.size()));
-                Iterator<Query> queryIterator = innerQueries.iterator();
-                for (BooleanClause booleanClause : booleanQuery) {
-                    assertThat(booleanClause.getOccur(), equalTo(BooleanClause.Occur.SHOULD));
-                    assertThat(booleanClause.getQuery(), equalTo(queryIterator.next()));
-                }
-            }
-        }
-    }
-
-    /**
-     * test corner case where no inner queries exist
-     */
-    @Test
-    public void testNoInnerQueries() throws QueryShardException, IOException {
-        OrQueryBuilder orQuery = new OrQueryBuilder();
-        assertNull(orQuery.toQuery(createShardContext()));
-    }
-
-    @Override
-    protected Map<String, OrQueryBuilder> getAlternateVersions() {
-        Map<String, OrQueryBuilder> alternateVersions = new HashMap<>();
-        QueryBuilder innerQuery = createTestQueryBuilder().innerQueries().get(0);
-        OrQueryBuilder expectedQuery = new OrQueryBuilder(innerQuery);
-        String contentString =  "{ \"or\" : [ " + innerQuery + "] }";
-        alternateVersions.put(contentString, expectedQuery);
-        return alternateVersions;
-    }
-
-    @Test(expected=QueryParsingException.class)
-    public void testMissingFiltersSection() throws IOException {
-        String queryString = "{ \"or\" : {}";
-        parseQuery(queryString);
-    }
-
-    @Test
-    public void testValidate() {
-        OrQueryBuilder orQuery = new OrQueryBuilder();
-        int iters = randomIntBetween(0, 5);
-        int totalExpectedErrors = 0;
-        for (int i = 0; i < iters; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    orQuery.add(RandomQueryBuilder.createInvalidQuery(random()));
-                } else {
-                    orQuery.add(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                orQuery.add(RandomQueryBuilder.createQuery(random()));
-            }
-        }
-        assertValidate(orQuery, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/PrefixQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/PrefixQueryBuilderTests.java
deleted file mode 100644
index b5ebe4b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/PrefixQueryBuilderTests.java
+++ /dev/null
@@ -1,67 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class PrefixQueryBuilderTests extends BaseQueryTestCase<PrefixQueryBuilder> {
-
-    @Override
-    protected PrefixQueryBuilder doCreateTestQueryBuilder() {
-        String fieldName = randomBoolean() ? STRING_FIELD_NAME : randomAsciiOfLengthBetween(1, 10);
-        String value = randomAsciiOfLengthBetween(1, 10);
-        PrefixQueryBuilder query = new PrefixQueryBuilder(fieldName, value);
-
-        if (randomBoolean()) {
-            query.rewrite(getRandomRewriteMethod());
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(PrefixQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(PrefixQuery.class));
-        PrefixQuery prefixQuery = (PrefixQuery) query;
-        assertThat(prefixQuery.getPrefix().field(), equalTo(queryBuilder.fieldName()));
-    }
-
-    @Test
-    public void testValidate() {
-        PrefixQueryBuilder prefixQueryBuilder = new PrefixQueryBuilder("", "prefix");
-        assertThat(prefixQueryBuilder.validate().validationErrors().size(), is(1));
-
-        prefixQueryBuilder = new PrefixQueryBuilder("field", null);
-        assertThat(prefixQueryBuilder.validate().validationErrors().size(), is(1));
-
-        prefixQueryBuilder = new PrefixQueryBuilder("field", "prefix");
-        assertNull(prefixQueryBuilder.validate());
-
-        prefixQueryBuilder = new PrefixQueryBuilder(null, null);
-        assertThat(prefixQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/QueryFilterBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/QueryFilterBuilderTests.java
deleted file mode 100644
index 6530e65..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/QueryFilterBuilderTests.java
+++ /dev/null
@@ -1,84 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.*;
-
-@SuppressWarnings("deprecation")
-public class QueryFilterBuilderTests extends BaseQueryTestCase<QueryFilterBuilder> {
-
-    @Override
-    protected QueryFilterBuilder doCreateTestQueryBuilder() {
-        QueryBuilder innerQuery = RandomQueryBuilder.createQuery(random());
-        return new QueryFilterBuilder(innerQuery);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(QueryFilterBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        Query innerQuery = queryBuilder.innerQuery().toQuery(context);
-        if (innerQuery == null) {
-            assertThat(query, nullValue());
-        } else {
-            assertThat(query, instanceOf(ConstantScoreQuery.class));
-            ConstantScoreQuery constantScoreQuery = (ConstantScoreQuery) query;
-            assertThat(constantScoreQuery.getQuery(), equalTo(innerQuery));
-        }
-    }
-
-    @Override
-    protected boolean supportsBoostAndQueryName() {
-        return false;
-    }
-
-    /**
-     * test wrapping an inner filter that returns null also returns <tt>null</null> to pass on upwards
-     */
-    @Test
-    public void testInnerQueryReturnsNull() throws IOException {
-        // create inner filter
-        String queryString = "{ \"constant_score\" : { \"filter\" : {} } }";
-        QueryBuilder<?> innerQuery = parseQuery(queryString);
-        // check that when wrapping this filter, toQuery() returns null
-        QueryFilterBuilder queryFilterQuery = new QueryFilterBuilder(innerQuery);
-        assertNull(queryFilterQuery.toQuery(createShardContext()));
-    }
-
-    @Test
-    public void testValidate() {
-        QueryBuilder innerQuery = null;
-        int totalExpectedErrors = 0;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerQuery = RandomQueryBuilder.createInvalidQuery(random());
-            }
-            totalExpectedErrors++;
-        } else {
-            innerQuery = RandomQueryBuilder.createQuery(random());
-        }
-        QueryFilterBuilder fQueryFilter = new QueryFilterBuilder(innerQuery);
-        assertValidate(fQueryFilter, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/RandomQueryBuilder.java b/core/src/test/java/org/elasticsearch/index/query/RandomQueryBuilder.java
deleted file mode 100644
index f7157f2..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/RandomQueryBuilder.java
+++ /dev/null
@@ -1,91 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import com.carrotsearch.randomizedtesting.generators.RandomInts;
-import com.carrotsearch.randomizedtesting.generators.RandomStrings;
-
-import java.util.Random;
-
-/**
- * Utility class for creating random QueryBuilders.
- * So far only leaf queries like {@link MatchAllQueryBuilder}, {@link TermQueryBuilder} or
- * {@link IdsQueryBuilder} are returned.
- */
-public class RandomQueryBuilder {
-
-    /**
-     * Create a new query of a random type
-     * @param r random seed
-     * @return a random {@link QueryBuilder}
-     */
-    public static QueryBuilder createQuery(Random r) {
-        switch (RandomInts.randomIntBetween(r, 0, 4)) {
-            case 0:
-                return new MatchAllQueryBuilderTests().createTestQueryBuilder();
-            case 1:
-                return new TermQueryBuilderTests().createTestQueryBuilder();
-            case 2:
-                return new IdsQueryBuilderTests().createTestQueryBuilder();
-            case 3:
-                return createMultiTermQuery(r);
-            case 4:
-                return EmptyQueryBuilder.PROTOTYPE;
-            default:
-                throw new UnsupportedOperationException();
-        }
-    }
-
-    /**
-     * Create a new multi term query of a random type
-     * @param r random seed
-     * @return a random {@link MultiTermQueryBuilder}
-     */
-    public static MultiTermQueryBuilder createMultiTermQuery(Random r) {
-        // for now, only use String Rangequeries for MultiTerm test, numeric and date makes little sense
-        // see issue #12123 for discussion
-        // Prefix / Fuzzy / RegEx / Wildcard can go here later once refactored and they have random query generators
-        RangeQueryBuilder query = new RangeQueryBuilder(BaseQueryTestCase.STRING_FIELD_NAME);
-        query.from("a" + RandomStrings.randomAsciiOfLengthBetween(r, 1, 10));
-        query.to("z" + RandomStrings.randomAsciiOfLengthBetween(r, 1, 10));
-        return query;
-    }
-
-    /**
-     * Create a new invalid query of a random type
-     * @param r random seed
-     * @return a random {@link QueryBuilder} that is invalid, meaning that calling validate against it
-     * will return an error. We can rely on the fact that a single error will be returned per query.
-     */
-    public static QueryBuilder createInvalidQuery(Random r) {
-        switch (RandomInts.randomIntBetween(r, 0, 3)) {
-            case 0:
-                return new TermQueryBuilder("", "test");
-            case 1:
-                return new BoostingQueryBuilder(new MatchAllQueryBuilder(), new MatchAllQueryBuilder()).negativeBoost(-1f);
-            case 2:
-                return new CommonTermsQueryBuilder("", "text");
-            case 3:
-                return new SimpleQueryStringBuilder(null);
-            default:
-                throw new UnsupportedOperationException();
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTests.java
deleted file mode 100644
index fa0726e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/RangeQueryBuilderTests.java
+++ /dev/null
@@ -1,144 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermRangeQuery;
-import org.joda.time.DateTime;
-import org.joda.time.DateTimeZone;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class RangeQueryBuilderTests extends BaseQueryTestCase<RangeQueryBuilder> {
-
-    private static final List<String> TIMEZONE_IDS = new ArrayList<>(DateTimeZone.getAvailableIDs());
-
-    @Override
-    protected RangeQueryBuilder doCreateTestQueryBuilder() {
-        RangeQueryBuilder query;
-        // switch between numeric and date ranges
-        switch (randomIntBetween(0, 2)) {
-            case 0:
-                if (randomBoolean()) {
-                    // use mapped integer field for numeric range queries
-                    query = new RangeQueryBuilder(INT_FIELD_NAME);
-                    query.from(randomIntBetween(1, 100));
-                    query.to(randomIntBetween(101, 200));
-                } else {
-                    // use unmapped field for numeric range queries
-                    query = new RangeQueryBuilder(randomAsciiOfLengthBetween(1, 10));
-                    query.from(0.0 - randomDouble());
-                    query.to(randomDouble());
-                }
-                break;
-            case 1:
-                // use mapped date field, using date string representation
-                query = new RangeQueryBuilder(DATE_FIELD_NAME);
-                query.from(new DateTime(System.currentTimeMillis() - randomIntBetween(0, 1000000), DateTimeZone.UTC).toString());
-                query.to(new DateTime(System.currentTimeMillis() + randomIntBetween(0, 1000000), DateTimeZone.UTC).toString());
-                // Create timestamp option only then we have a date mapper,
-                // otherwise we could trigger exception.
-                if (createShardContext().mapperService().smartNameFieldType(DATE_FIELD_NAME) != null) {
-                    if (randomBoolean()) {
-                        query.timeZone(TIMEZONE_IDS.get(randomIntBetween(0, TIMEZONE_IDS.size() - 1)));
-                    }
-                    if (randomBoolean()) {
-                        query.format("yyyy-MM-dd'T'HH:mm:ss.SSSZZ");
-                    }
-                }
-                break;
-            case 2:
-            default:
-                query = new RangeQueryBuilder(STRING_FIELD_NAME);
-                query.from("a" + randomAsciiOfLengthBetween(1, 10));
-                query.to("z" + randomAsciiOfLengthBetween(1, 10));
-                break;
-        }
-        query.includeLower(randomBoolean()).includeUpper(randomBoolean());
-        if (randomBoolean()) {
-            query.from(null);
-        }
-        if (randomBoolean()) {
-            query.to(null);
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(RangeQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (getCurrentTypes().length == 0 || (queryBuilder.fieldName().equals(DATE_FIELD_NAME) == false && queryBuilder.fieldName().equals(INT_FIELD_NAME) == false)) {
-            assertThat(query, instanceOf(TermRangeQuery.class));
-        } else if (queryBuilder.fieldName().equals(DATE_FIELD_NAME)) {
-            //we can't properly test unmapped dates because LateParsingQuery is package private
-        } else if (queryBuilder.fieldName().equals(INT_FIELD_NAME)) {
-            assertThat(query, instanceOf(NumericRangeQuery.class));
-        } else {
-            throw new UnsupportedOperationException();
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        RangeQueryBuilder rangeQueryBuilder = new RangeQueryBuilder("");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(1));
-
-        rangeQueryBuilder = new RangeQueryBuilder("okay").timeZone("UTC");
-        assertNull(rangeQueryBuilder.validate());
-
-        rangeQueryBuilder.timeZone("blab");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(1));
-
-        rangeQueryBuilder.timeZone("UTC").format("basicDate");
-        assertNull(rangeQueryBuilder.validate());
-
-        rangeQueryBuilder.timeZone("UTC").format("broken_xx");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(1));
-
-        rangeQueryBuilder.timeZone("xXx").format("broken_xx");
-        assertThat(rangeQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-
-    /**
-     * Specifying a timezone together with a numeric range query should throw an exception.
-     */
-    @Test(expected=QueryShardException.class)
-    public void testToQueryNonDateWithTimezone() throws QueryShardException, IOException {
-        RangeQueryBuilder query = new RangeQueryBuilder(INT_FIELD_NAME);
-        query.from(1).to(10).timeZone("UTC");
-        query.toQuery(createShardContext());
-    }
-
-    /**
-     * Specifying a timezone together with an unmapped field should throw an exception.
-     */
-    @Test(expected=QueryShardException.class)
-    public void testToQueryUnmappedWithTimezone() throws QueryShardException, IOException {
-        RangeQueryBuilder query = new RangeQueryBuilder("bogus_field");
-        query.from(1).to(10).timeZone("UTC");
-        query.toQuery(createShardContext());
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/RegexpQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/RegexpQueryBuilderTests.java
deleted file mode 100644
index ee4ef0f..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/RegexpQueryBuilderTests.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.RegexpQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class RegexpQueryBuilderTests extends BaseQueryTestCase<RegexpQueryBuilder> {
-
-    @Override
-    protected RegexpQueryBuilder doCreateTestQueryBuilder() {
-        // mapped or unmapped fields
-        String fieldName = randomBoolean() ? STRING_FIELD_NAME : randomAsciiOfLengthBetween(1, 10);
-        String value = randomAsciiOfLengthBetween(1, 10);
-        RegexpQueryBuilder query = new RegexpQueryBuilder(fieldName, value);
-
-        if (randomBoolean()) {
-            List<RegexpFlag> flags = new ArrayList<>();
-            int iter = randomInt(5);
-            for (int i = 0; i < iter; i++) {
-                flags.add(randomFrom(RegexpFlag.values()));
-            }
-            query.flags(flags.toArray(new RegexpFlag[flags.size()]));
-        }
-        if (randomBoolean()) {
-            query.maxDeterminizedStates(randomInt(50000));
-        }
-        if (randomBoolean()) {
-            query.rewrite(randomFrom(getRandomRewriteMethod()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(RegexpQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(RegexpQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        RegexpQueryBuilder regexQueryBuilder = new RegexpQueryBuilder("", "regex");
-        assertThat(regexQueryBuilder.validate().validationErrors().size(), is(1));
-
-        regexQueryBuilder = new RegexpQueryBuilder("field", null);
-        assertThat(regexQueryBuilder.validate().validationErrors().size(), is(1));
-
-        regexQueryBuilder = new RegexpQueryBuilder("field", "regex");
-        assertNull(regexQueryBuilder.validate());
-
-        regexQueryBuilder = new RegexpQueryBuilder(null, null);
-        assertThat(regexQueryBuilder.validate().validationErrors().size(), is(2));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ScoreTypeTests.java b/core/src/test/java/org/elasticsearch/index/query/ScoreTypeTests.java
new file mode 100644
index 0000000..efbcc10
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/query/ScoreTypeTests.java
@@ -0,0 +1,74 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.index.query;
+
+import org.elasticsearch.index.query.ScoreType;
+import org.elasticsearch.test.ESTestCase;
+import org.junit.Test;
+
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.hamcrest.Matchers.equalTo;
+
+/**
+ * Tests {@link ScoreType} to ensure backward compatibility of any changes.
+ */
+public class ScoreTypeTests extends ESTestCase {
+    @Test
+    public void minFromString() {
+        assertThat("fromString(min) != MIN", ScoreType.MIN, equalTo(ScoreType.fromString("min")));
+    }
+
+    @Test
+    public void maxFromString() {
+        assertThat("fromString(max) != MAX", ScoreType.MAX, equalTo(ScoreType.fromString("max")));
+    }
+
+    @Test
+    public void avgFromString() {
+        assertThat("fromString(avg) != AVG", ScoreType.AVG, equalTo(ScoreType.fromString("avg")));
+    }
+
+    @Test
+    public void sumFromString() {
+        assertThat("fromString(sum) != SUM", ScoreType.SUM, equalTo(ScoreType.fromString("sum")));
+        // allowed for consistency with ScoreMode.Total:
+        assertThat("fromString(total) != SUM", ScoreType.SUM, equalTo(ScoreType.fromString("total")));
+    }
+
+    @Test
+    public void noneFromString() {
+        assertThat("fromString(none) != NONE", ScoreType.NONE, equalTo(ScoreType.fromString("none")));
+    }
+
+    /**
+     * Should throw {@link IllegalArgumentException} instead of NPE.
+     */
+    @Test(expected = IllegalArgumentException.class)
+    public void nullFromString_throwsException() {
+        ScoreType.fromString(null);
+    }
+
+    /**
+     * Failure should not change (and the value should never match anything...).
+     */
+    @Test(expected = IllegalArgumentException.class)
+    public void unrecognizedFromString_throwsException() {
+        ScoreType.fromString("unrecognized value");
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTests.java
deleted file mode 100644
index b216418..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTests.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.script.ScriptService.ScriptType;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class ScriptQueryBuilderTests extends BaseQueryTestCase<ScriptQueryBuilder> {
-
-    @Override
-    protected ScriptQueryBuilder doCreateTestQueryBuilder() {
-        String script;
-        Map<String, Object> params = null;
-        if (randomBoolean()) {
-            script = "5 * 2 > param";
-            params = new HashMap<>();
-            params.put("param", 1);
-        } else {
-            script = "5 * 2 > 2";
-        }
-        return new ScriptQueryBuilder(new Script(script, ScriptType.INLINE, "expression", params));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(ScriptQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(ScriptQueryBuilder.ScriptQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        ScriptQueryBuilder scriptQueryBuilder = new ScriptQueryBuilder(null);
-        assertThat(scriptQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java b/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
index 19f8585..e8b39a5 100644
--- a/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
@@ -21,41 +21,15 @@ package org.elasticsearch.index.query;
 
 import com.google.common.collect.Sets;
 import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
-import org.apache.lucene.index.Fields;
-import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.index.*;
 import org.apache.lucene.index.memory.MemoryIndex;
 import org.apache.lucene.queries.BoostingQuery;
 import org.apache.lucene.queries.ExtendedCommonTermsQuery;
 import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.*;
 import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.DisjunctionMaxQuery;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.RegexpQuery;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.TermRangeQuery;
-import org.apache.lucene.search.WildcardQuery;
 import org.apache.lucene.search.join.ToParentBlockJoinQuery;
-import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
-import org.apache.lucene.search.spans.SpanContainingQuery;
-import org.apache.lucene.search.spans.SpanFirstQuery;
-import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
-import org.apache.lucene.search.spans.SpanNearQuery;
-import org.apache.lucene.search.spans.SpanNotQuery;
-import org.apache.lucene.search.spans.SpanOrQuery;
-import org.apache.lucene.search.spans.SpanTermQuery;
-import org.apache.lucene.search.spans.SpanWithinQuery;
+import org.apache.lucene.search.spans.*;
 import org.apache.lucene.spatial.prefix.IntersectsPrefixTreeFilter;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -63,11 +37,10 @@ import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.NumericUtils;
 import org.apache.lucene.util.automaton.TooComplexToDeterminizeException;
 import org.elasticsearch.action.termvectors.MultiTermVectorsItemResponse;
-import org.elasticsearch.action.termvectors.MultiTermVectorsRequest;
 import org.elasticsearch.action.termvectors.MultiTermVectorsResponse;
 import org.elasticsearch.action.termvectors.TermVectorsRequest;
 import org.elasticsearch.action.termvectors.TermVectorsResponse;
-import org.elasticsearch.common.Strings;
+import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.compress.CompressedXContent;
 import org.elasticsearch.common.lucene.search.MoreLikeThisQuery;
@@ -86,6 +59,7 @@ import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.ParsedDocument;
 import org.elasticsearch.index.mapper.core.NumberFieldMapper;
+import org.elasticsearch.index.query.MoreLikeThisQueryBuilder.Item;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
 import org.elasticsearch.index.search.geo.GeoDistanceRangeQuery;
 import org.elasticsearch.index.search.geo.GeoPolygonQuery;
@@ -98,9 +72,7 @@ import org.junit.Before;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.Arrays;
-import java.util.EnumSet;
-import java.util.List;
+import java.util.*;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.*;
@@ -1003,7 +975,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testBoostingQueryBuilder() throws IOException {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(boostingQuery(termQuery("field1", "value1"), termQuery("field1", "value2")).negativeBoost(0.2f)).query();
+        Query parsedQuery = queryParser.parse(boostingQuery().positive(termQuery("field1", "value1")).negative(termQuery("field1", "value2")).negativeBoost(0.2f)).query();
         assertThat(parsedQuery, instanceOf(BoostingQuery.class));
     }
 
@@ -1385,7 +1357,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testSpanNotQueryBuilder() throws IOException {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(spanNotQuery(spanTermQuery("age", 34), spanTermQuery("age", 35))).query();
+        Query parsedQuery = queryParser.parse(spanNotQuery().include(spanTermQuery("age", 34)).exclude(spanTermQuery("age", 35))).query();
         assertThat(parsedQuery, instanceOf(SpanNotQuery.class));
         SpanNotQuery spanNotQuery = (SpanNotQuery) parsedQuery;
         // since age is automatically registered in data, we encode it as numeric
@@ -1414,7 +1386,9 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         little.setBoost(3);
         Query expectedQuery = new SpanWithinQuery(big, little);
 
-        SpanWithinQueryBuilder spanWithinQueryBuilder = spanWithinQuery(spanTermQuery("age", 34).boost(2), spanTermQuery("age", 35).boost(3));
+        SpanWithinQueryBuilder spanWithinQueryBuilder = spanWithinQuery()
+                .big(spanTermQuery("age", 34).boost(2))
+                .little(spanTermQuery("age", 35).boost(3));
         Query actualQuery = queryParser.parse(spanWithinQueryBuilder).query();
         assertEquals(expectedQuery, actualQuery);
 
@@ -1444,7 +1418,9 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         little.setBoost(3);
         Query expectedQuery = new SpanContainingQuery(big, little);
 
-        SpanContainingQueryBuilder spanContainingQueryBuilder = spanContainingQuery(spanTermQuery("age", 34).boost(2), spanTermQuery("age", 35).boost(3));
+        SpanContainingQueryBuilder spanContainingQueryBuilder = spanContainingQuery()
+                .big(spanTermQuery("age", 34).boost(2))
+                .little(spanTermQuery("age", 35).boost(3));
         Query actualQuery = queryParser.parse(spanContainingQueryBuilder).query();
         assertEquals(expectedQuery, actualQuery);
 
@@ -1491,7 +1467,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testSpanNearQueryBuilder() throws IOException {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(spanNearQuery(12).clause(spanTermQuery("age", 34)).clause(spanTermQuery("age", 35)).clause(spanTermQuery("age", 36)).inOrder(false).collectPayloads(false)).query();
+        Query parsedQuery = queryParser.parse(spanNearQuery().clause(spanTermQuery("age", 34)).clause(spanTermQuery("age", 35)).clause(spanTermQuery("age", 36)).slop(12).inOrder(false).collectPayloads(false)).query();
         assertThat(parsedQuery, instanceOf(SpanNearQuery.class));
         SpanNearQuery spanNearQuery = (SpanNearQuery) parsedQuery;
         assertThat(spanNearQuery.getClauses().length, equalTo(3));
@@ -1699,7 +1675,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
 
     @Test
     public void testMoreLikeThisIds() throws Exception {
-        MoreLikeThisQueryParser parser = (MoreLikeThisQueryParser) queryParser.indicesQueriesRegistry().queryParsers().get("more_like_this");
+        MoreLikeThisQueryParser parser = (MoreLikeThisQueryParser) queryParser.queryParser("more_like_this");
         parser.setFetchService(new MockMoreLikeThisFetchService());
 
         IndexQueryParserService queryParser = queryParser();
@@ -1725,7 +1701,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testMLTMinimumShouldMatch() throws Exception {
         // setup for mocking fetching items
-        MoreLikeThisQueryParser parser = (MoreLikeThisQueryParser) queryParser.indicesQueriesRegistry().queryParsers().get("more_like_this");
+        MoreLikeThisQueryParser parser = (MoreLikeThisQueryParser) queryParser.queryParser("more_like_this");
         parser.setFetchService(new MockMoreLikeThisFetchService());
 
         // parsing the ES query
@@ -1766,15 +1742,15 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         }
 
         @Override
-        public MultiTermVectorsResponse fetchResponse(MultiTermVectorsRequest items) throws IOException {
+        public MultiTermVectorsResponse fetchResponse(List<Item> items, List<Item> unlikeItems, SearchContext searchContext) throws IOException {
             MultiTermVectorsItemResponse[] responses = new MultiTermVectorsItemResponse[items.size()];
             int i = 0;
-            for (TermVectorsRequest item : items) {
+            for (Item item : items) {
                 TermVectorsResponse response = new TermVectorsResponse(item.index(), item.type(), item.id());
                 response.setExists(true);
-                Fields generatedFields = generateFields(item.selectedFields().toArray(Strings.EMPTY_ARRAY), item.id());
+                Fields generatedFields = generateFields(item.fields(), item.id());
                 EnumSet<TermVectorsRequest.Flag> flags = EnumSet.of(TermVectorsRequest.Flag.Positions, TermVectorsRequest.Flag.Offsets);
-                response.setFields(generatedFields, item.selectedFields(), flags, generatedFields);
+                response.setFields(generatedFields, new HashSet<String>(Arrays.asList(item.fields())), flags, generatedFields);
                 responses[i++] = new MultiTermVectorsItemResponse(response, null);
             }
             return new MultiTermVectorsResponse(responses);
@@ -2546,6 +2522,31 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     }
 
     @Test
+    public void testSimpleQueryString() throws Exception {
+        IndexQueryParserService queryParser = queryParser();
+        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/simple-query-string.json");
+        Query parsedQuery = queryParser.parse(query).query();
+        assertThat(parsedQuery, instanceOf(BooleanQuery.class));
+    }
+
+    @Test
+    public void testSimpleQueryStringBoost() throws Exception {
+        IndexQueryParserService queryParser = queryParser();
+        SimpleQueryStringBuilder simpleQueryStringBuilder = new SimpleQueryStringBuilder("test");
+        simpleQueryStringBuilder.field("body", 5);
+        Query parsedQuery = queryParser.parse(simpleQueryStringBuilder.toString()).query();
+        assertThat(parsedQuery, instanceOf(TermQuery.class));
+        assertThat(parsedQuery.getBoost(), equalTo(5f));
+
+        simpleQueryStringBuilder = new SimpleQueryStringBuilder("test");
+        simpleQueryStringBuilder.field("body", 5);
+        simpleQueryStringBuilder.boost(2);
+        parsedQuery = queryParser.parse(simpleQueryStringBuilder.toString()).query();
+        assertThat(parsedQuery, instanceOf(TermQuery.class));
+        assertThat(parsedQuery.getBoost(), equalTo(10f));
+    }
+
+    @Test
     public void testMatchWithFuzzyTranspositions() throws Exception {
         IndexQueryParserService queryParser = queryParser();
         String query = copyToStringFromClasspath("/org/elasticsearch/index/query/match-with-fuzzy-transpositions.json");
@@ -2683,8 +2684,8 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         assertThat(toParentBlockJoinQuery.toString(), equalTo("ToParentBlockJoinQuery (+*:* #QueryWrapperFilter(_type:__nested))"));
         SearchContext.removeCurrent();
     }
-
-    /**
+    
+    /** 
      * helper to extract term from TermQuery. */
     private Term getTerm(Query query) {
         while (query instanceof QueryWrapperFilter) {
@@ -2736,4 +2737,19 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
             assertThat(prefixQuery.getRewriteMethod(), instanceOf(MultiTermQuery.TopTermsBlendedFreqScoringRewrite.class));
         }
     }
+
+    @Test
+    public void testSimpleQueryStringNoFields() throws Exception {
+        IndexQueryParserService queryParser = queryParser();
+        String queryText = randomAsciiOfLengthBetween(1, 10).toLowerCase(Locale.ROOT);
+        String query = "{\n" +
+                "    \"simple_query_string\" : {\n" +
+                "        \"query\" : \"" + queryText + "\"\n" +
+                "    }\n" +
+                "}";
+        Query parsedQuery = queryParser.parse(query).query();
+        assertThat(parsedQuery, instanceOf(TermQuery.class));
+        TermQuery termQuery = (TermQuery) parsedQuery;
+        assertThat(termQuery.getTerm(), equalTo(new Term(MetaData.ALL, queryText)));
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTests.java
deleted file mode 100644
index 129de58..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTests.java
+++ /dev/null
@@ -1,348 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.*;
-import org.elasticsearch.Version;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.*;
-
-import static org.hamcrest.Matchers.*;
-
-public class SimpleQueryStringBuilderTests extends BaseQueryTestCase<SimpleQueryStringBuilder> {
-
-    private static final String[] MINIMUM_SHOULD_MATCH = new String[] { "1", "-1", "75%", "-25%", "2<75%", "2<-25%" };
-
-    @Override
-    protected SimpleQueryStringBuilder doCreateTestQueryBuilder() {
-        SimpleQueryStringBuilder result = new SimpleQueryStringBuilder(randomAsciiOfLengthBetween(1, 10));
-        if (randomBoolean()) {
-            result.analyzeWildcard(randomBoolean());
-        }
-        if (randomBoolean()) {
-            result.lenient(randomBoolean());
-        }
-        if (randomBoolean()) {
-            result.lowercaseExpandedTerms(randomBoolean());
-        }
-        if (randomBoolean()) {
-            result.locale(randomLocale(getRandom()));
-        }
-        if (randomBoolean()) {
-            result.minimumShouldMatch(randomFrom(MINIMUM_SHOULD_MATCH));
-        }
-        if (randomBoolean()) {
-            result.analyzer("simple");
-        }
-        if (randomBoolean()) {
-            result.defaultOperator(randomFrom(Operator.AND, Operator.OR));
-        }
-        if (randomBoolean()) {
-            Set<SimpleQueryStringFlag> flagSet = new HashSet<>();
-            int size = randomIntBetween(0, SimpleQueryStringFlag.values().length);
-            for (int i = 0; i < size; i++) {
-                flagSet.add(randomFrom(SimpleQueryStringFlag.values()));
-            }
-            if (flagSet.size() > 0) {
-                result.flags(flagSet.toArray(new SimpleQueryStringFlag[flagSet.size()]));
-            }
-        }
-
-        int fieldCount = randomIntBetween(0, 10);
-        Map<String, Float> fields = new TreeMap<>();
-        for (int i = 0; i < fieldCount; i++) {
-            if (randomBoolean()) {
-                fields.put(randomAsciiOfLengthBetween(1, 10), AbstractQueryBuilder.DEFAULT_BOOST);
-            } else {
-                fields.put(randomAsciiOfLengthBetween(1, 10), 2.0f / randomIntBetween(1, 20));
-            }
-        }
-        result.fields(fields);
-
-        return result;
-    }
-
-    @Test
-    public void testDefaults() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-
-        assertEquals("Wrong default default boost.", AbstractQueryBuilder.DEFAULT_BOOST, qb.boost(), 0.001);
-        assertEquals("Wrong default default boost field.", AbstractQueryBuilder.DEFAULT_BOOST, SimpleQueryStringBuilder.DEFAULT_BOOST,
-                0.001);
-
-        assertEquals("Wrong default flags.", SimpleQueryStringFlag.ALL.value, qb.flags());
-        assertEquals("Wrong default flags field.", SimpleQueryStringFlag.ALL.value(), SimpleQueryStringBuilder.DEFAULT_FLAGS);
-
-        assertEquals("Wrong default default operator.", Operator.OR, qb.defaultOperator());
-        assertEquals("Wrong default default operator field.", Operator.OR, SimpleQueryStringBuilder.DEFAULT_OPERATOR);
-
-        assertEquals("Wrong default default locale.", Locale.ROOT, qb.locale());
-        assertEquals("Wrong default default locale field.", Locale.ROOT, SimpleQueryStringBuilder.DEFAULT_LOCALE);
-
-        assertEquals("Wrong default default analyze_wildcard.", false, qb.analyzeWildcard());
-        assertEquals("Wrong default default analyze_wildcard field.", false, SimpleQueryStringBuilder.DEFAULT_ANALYZE_WILDCARD);
-
-        assertEquals("Wrong default default lowercase_expanded_terms.", true, qb.lowercaseExpandedTerms());
-        assertEquals("Wrong default default lowercase_expanded_terms field.", true,
-                SimpleQueryStringBuilder.DEFAULT_LOWERCASE_EXPANDED_TERMS);
-
-        assertEquals("Wrong default default lenient.", false, qb.lenient());
-        assertEquals("Wrong default default lenient field.", false, SimpleQueryStringBuilder.DEFAULT_LENIENT);
-
-        assertEquals("Wrong default default locale.", Locale.ROOT, qb.locale());
-        assertEquals("Wrong default default locale field.", Locale.ROOT, SimpleQueryStringBuilder.DEFAULT_LOCALE);
-    }
-
-    @Test
-    public void testDefaultNullLocale() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.locale(null);
-        assertEquals("Setting locale to null should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_LOCALE,
-                qb.locale());
-    }
-
-    @Test
-    public void testDefaultNullComplainFlags() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.flags((SimpleQueryStringFlag[]) null);
-        assertEquals("Setting flags to null should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_FLAGS,
-                qb.flags());
-    }
-
-    @Test
-    public void testDefaultEmptyComplainFlags() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.flags(new SimpleQueryStringFlag[]{});
-        assertEquals("Setting flags to empty should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_FLAGS,
-                qb.flags());
-    }
-
-    @Test
-    public void testDefaultNullComplainOp() {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.");
-        qb.defaultOperator(null);
-        assertEquals("Setting operator to null should result in returning to default value.", SimpleQueryStringBuilder.DEFAULT_OPERATOR,
-                qb.defaultOperator());
-    }
-
-    // Check operator handling, and default field handling.
-    @Test
-    public void testDefaultOperatorHandling() throws IOException {
-        SimpleQueryStringBuilder qb = new SimpleQueryStringBuilder("The quick brown fox.").field(STRING_FIELD_NAME);
-        QueryShardContext shardContext = createShardContext();
-        shardContext.setAllowUnmappedFields(true); // to avoid occasional cases
-                                                   // in setup where we didn't
-                                                   // add types but strict field
-                                                   // resolution
-        BooleanQuery boolQuery = (BooleanQuery) qb.toQuery(shardContext);
-        assertThat(shouldClauses(boolQuery), is(4));
-
-        qb.defaultOperator(Operator.AND);
-        boolQuery = (BooleanQuery) qb.toQuery(shardContext);
-        assertThat(shouldClauses(boolQuery), is(0));
-
-        qb.defaultOperator(Operator.OR);
-        boolQuery = (BooleanQuery) qb.toQuery(shardContext);
-        assertThat(shouldClauses(boolQuery), is(4));
-    }
-
-    @Test
-    public void testValidation() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        assertNull(qb.validate());
-    }
-
-    @Test
-    public void testNullQueryTextGeneratesException() {
-        SimpleQueryStringBuilder builder = new SimpleQueryStringBuilder(null);
-        QueryValidationException exception = builder.validate();
-        assertThat(exception, notNullValue());
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeNull() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field(null);
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeNullAndWeighted() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field(null, AbstractQueryBuilder.DEFAULT_BOOST);
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeEmpty() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field("");
-    }
-
-    @Test(expected = IllegalArgumentException.class)
-    public void testFieldCannotBeEmptyAndWeighted() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.field("", AbstractQueryBuilder.DEFAULT_BOOST);
-    }
-
-    /**
-     * The following should fail fast - never silently set the map containing
-     * fields and weights to null but refuse to accept null instead.
-     * */
-    @Test(expected = NullPointerException.class)
-    public void testFieldsCannotBeSetToNull() {
-        SimpleQueryStringBuilder qb = createTestQueryBuilder();
-        qb.fields(null);
-    }
-
-    @Test
-    public void testDefaultFieldParsing() throws IOException {
-        QueryParseContext context = createParseContext();
-        String query = randomAsciiOfLengthBetween(1, 10).toLowerCase(Locale.ROOT);
-        String contentString = "{\n" +
-                "    \"simple_query_string\" : {\n" +
-                "      \"query\" : \"" + query + "\"" +
-                "    }\n" +
-                "}";
-        XContentParser parser = XContentFactory.xContent(contentString).createParser(contentString);
-        context.reset(parser);
-        SimpleQueryStringBuilder queryBuilder = new SimpleQueryStringParser().fromXContent(context);
-        assertThat(queryBuilder.value(), equalTo(query));
-        assertThat(queryBuilder.fields(), notNullValue());
-        assertThat(queryBuilder.fields().size(), equalTo(0));
-        QueryShardContext shardContext = createShardContext();
-
-        // the remaining tests requires either a mapping that we register with types in base test setup
-        // no strict field resolution (version before V_1_4_0_Beta1)
-        if (getCurrentTypes().length > 0 || shardContext.indexQueryParserService().getIndexCreatedVersion().before(Version.V_1_4_0_Beta1)) {
-            Query luceneQuery = queryBuilder.toQuery(shardContext);
-            assertThat(luceneQuery, instanceOf(TermQuery.class));
-            TermQuery termQuery = (TermQuery) luceneQuery;
-            assertThat(termQuery.getTerm(), equalTo(new Term(MetaData.ALL, query)));
-        }
-    }
-
-    /*
-     * This assumes that Lucene query parsing is being checked already, adding
-     * checks only for our parsing extensions.
-     * 
-     * Also this relies on {@link SimpleQueryStringTests} to test most of the
-     * actual functionality of query parsing.
-     */
-    @Override
-    protected void doAssertLuceneQuery(SimpleQueryStringBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, notNullValue());
-
-        if ("".equals(queryBuilder.value())) {
-            assertTrue("Query should have been MatchNoDocsQuery but was " + query.getClass().getName(), query instanceof MatchNoDocsQuery);
-        } else if (queryBuilder.fields().size() > 1) {
-            assertTrue("Query should have been BooleanQuery but was " + query.getClass().getName(), query instanceof BooleanQuery);
-
-            BooleanQuery boolQuery = (BooleanQuery) query;
-            if (queryBuilder.lowercaseExpandedTerms()) {
-                for (BooleanClause clause : boolQuery.clauses()) {
-                    if (clause.getQuery() instanceof TermQuery) {
-                        TermQuery inner = (TermQuery) clause.getQuery();
-                        assertThat(inner.getTerm().bytes().toString(), is(inner.getTerm().bytes().toString().toLowerCase(Locale.ROOT)));
-                    }
-                }
-            }
-
-            assertThat(boolQuery.clauses().size(), equalTo(queryBuilder.fields().size()));
-            Iterator<String> fields = queryBuilder.fields().keySet().iterator();
-            for (BooleanClause booleanClause : boolQuery) {
-                assertThat(booleanClause.getQuery(), instanceOf(TermQuery.class));
-                TermQuery termQuery = (TermQuery) booleanClause.getQuery();
-                assertThat(termQuery.getTerm(), equalTo(new Term(fields.next(), queryBuilder.value().toLowerCase(Locale.ROOT))));
-            }
-
-            if (queryBuilder.minimumShouldMatch() != null) {
-                Collection<String> minMatchAlways = Arrays.asList("1", "-1", "75%", "-25%");
-                Collection<String> minMatchLarger = Arrays.asList("2<75%", "2<-25%");
-
-                if (minMatchAlways.contains(queryBuilder.minimumShouldMatch())) {
-                    assertThat(boolQuery.getMinimumNumberShouldMatch(), greaterThan(0));
-                } else if (minMatchLarger.contains(queryBuilder.minimumShouldMatch())) {
-                    if (shouldClauses(boolQuery) > 2) {
-                        assertThat(boolQuery.getMinimumNumberShouldMatch(), greaterThan(0));
-                    }
-                } else {
-                    assertEquals(0, boolQuery.getMinimumNumberShouldMatch());
-                }
-            }
-        } else if (queryBuilder.fields().size() <= 1) {
-            assertTrue("Query should have been TermQuery but was " + query.getClass().getName(), query instanceof TermQuery);
-
-            TermQuery termQuery = (TermQuery) query;
-            String field;
-            if (queryBuilder.fields().size() == 0) {
-                field = MetaData.ALL;
-            } else {
-                field = queryBuilder.fields().keySet().iterator().next();
-            }
-            assertThat(termQuery.getTerm(), equalTo(new Term(field, queryBuilder.value().toLowerCase(Locale.ROOT))));
-
-            if (queryBuilder.lowercaseExpandedTerms()) {
-                assertThat(termQuery.getTerm().bytes().toString(), is(termQuery.getTerm().bytes().toString().toLowerCase(Locale.ROOT)));
-            }
-        } else {
-            fail("Encountered lucene query type we do not have a validation implementation for in our " + SimpleQueryStringBuilderTests.class.getSimpleName());
-        }
-    }
-
-    @Override
-    protected void assertBoost(SimpleQueryStringBuilder queryBuilder, Query query) throws IOException {
-        //boost may get parsed from the random query, we then combine the main boost with that one coming from lucene
-        //instead of trying to reparse the query and guess what the boost should be, we delegate boost checks to specific boost tests below
-    }
-
-
-    private int shouldClauses(BooleanQuery query) {
-        int result = 0;
-        for (BooleanClause c : query.clauses()) {
-            if (c.getOccur() == BooleanClause.Occur.SHOULD) {
-                result++;
-            }
-        }
-        return result;
-    }
-
-    @Test
-    public void testToQueryBoost() throws IOException {
-        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
-        QueryShardContext shardContext = createShardContext();
-        SimpleQueryStringBuilder simpleQueryStringBuilder = new SimpleQueryStringBuilder("test");
-        simpleQueryStringBuilder.field(STRING_FIELD_NAME, 5);
-        Query query = simpleQueryStringBuilder.toQuery(shardContext);
-        assertThat(query, instanceOf(TermQuery.class));
-        assertThat(query.getBoost(), equalTo(5f));
-
-        simpleQueryStringBuilder = new SimpleQueryStringBuilder("test");
-        simpleQueryStringBuilder.field(STRING_FIELD_NAME, 5);
-        simpleQueryStringBuilder.boost(2);
-        query = simpleQueryStringBuilder.toQuery(shardContext);
-        assertThat(query, instanceOf(TermQuery.class));
-        assertThat(query.getBoost(), equalTo(10f));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTests.java
deleted file mode 100644
index 5938c31..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanContainingQueryBuilderTests.java
+++ /dev/null
@@ -1,82 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanContainingQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanContainingQueryBuilderTests extends BaseQueryTestCase<SpanContainingQueryBuilder> {
-
-    @Override
-    protected SpanContainingQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(2);
-        return new SpanContainingQueryBuilder(spanTermQueries[0], spanTermQueries[1]);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanContainingQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanContainingQuery.class));
-    }
-
-    @Override
-    protected void assertBoost(SpanContainingQueryBuilder queryBuilder, Query query) throws IOException {
-        if (queryBuilder.boost() == AbstractQueryBuilder.DEFAULT_BOOST) {
-            //lucene default behaviour
-            assertThat(query.getBoost(), equalTo(queryBuilder.bigQuery().boost()));
-        } else {
-            assertThat(query.getBoost(), equalTo(queryBuilder.boost()));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder bigSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                bigSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                bigSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            bigSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanQueryBuilder littleSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                littleSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                littleSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            littleSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanContainingQueryBuilder queryBuilder = new SpanContainingQueryBuilder(bigSpanQueryBuilder, littleSpanQueryBuilder);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanFirstQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanFirstQueryBuilderTests.java
deleted file mode 100644
index 343c203..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanFirstQueryBuilderTests.java
+++ /dev/null
@@ -1,108 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanFirstQuery;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.elasticsearch.index.query.QueryBuilders.spanTermQuery;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanFirstQueryBuilderTests extends BaseQueryTestCase<SpanFirstQueryBuilder> {
-
-    @Override
-    protected SpanFirstQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(1);
-        return new SpanFirstQueryBuilder(spanTermQueries[0], randomIntBetween(0, 1000));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanFirstQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanFirstQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder innerSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                innerSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                innerSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            innerSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        int end = randomIntBetween(0, 10);
-        if (randomBoolean()) {
-            end = randomIntBetween(-10, -1);
-            totalExpectedErrors++;
-        }
-        SpanFirstQueryBuilder queryBuilder = new SpanFirstQueryBuilder(innerSpanQueryBuilder, end);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-
-    /**
-     * test exception on missing `end` and `match` parameter in parser
-     */
-    @Test
-    public void testParseEnd() throws IOException {
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanFirstQueryBuilder.NAME);
-            builder.field("match");
-            spanTermQuery("description", "jumped").toXContent(builder, null);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string());
-                fail("missing [end] parameter should raise exception");
-            } catch (QueryParsingException e) {
-                assertTrue(e.getMessage().contains("spanFirst must have [end] set"));
-            }
-        }
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanFirstQueryBuilder.NAME);
-            builder.field("end", 10);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string());
-                fail("missing [match] parameter should raise exception");
-            } catch (QueryParsingException e) {
-                assertTrue(e.getMessage().contains("spanFirst must have [match] span query clause"));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTests.java
deleted file mode 100644
index 79c98fd..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanMultiTermQueryBuilderTests.java
+++ /dev/null
@@ -1,87 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanMultiTermQueryBuilderTests extends BaseQueryTestCase<SpanMultiTermQueryBuilder> {
-
-    @Override
-    protected SpanMultiTermQueryBuilder doCreateTestQueryBuilder() {
-        MultiTermQueryBuilder multiTermQueryBuilder = RandomQueryBuilder.createMultiTermQuery(random());
-        return new SpanMultiTermQueryBuilder(multiTermQueryBuilder);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanMultiTermQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanMultiTermQueryWrapper.class));
-        SpanMultiTermQueryWrapper spanMultiTermQueryWrapper = (SpanMultiTermQueryWrapper) query;
-        Query multiTermQuery = queryBuilder.innerQuery().toQuery(context);
-        assertThat(multiTermQuery, instanceOf(MultiTermQuery.class));
-        assertThat(spanMultiTermQueryWrapper.getWrappedQuery(), equalTo(new SpanMultiTermQueryWrapper<>((MultiTermQuery)multiTermQuery).getWrappedQuery()));
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        MultiTermQueryBuilder multiTermQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                multiTermQueryBuilder = new RangeQueryBuilder("");
-            } else {
-                multiTermQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            multiTermQueryBuilder = new RangeQueryBuilder("field");
-        }
-        SpanMultiTermQueryBuilder queryBuilder = new SpanMultiTermQueryBuilder(multiTermQueryBuilder);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-
-    /**
-     * test checks that we throw an {@link UnsupportedOperationException} if the query wrapped
-     * by {@link SpanMultiTermQueryBuilder} does not generate a lucene {@link MultiTermQuery}.
-     * This is currently the case for {@link RangeQueryBuilder} when the target field is mapped
-     * to a date.
-     */
-    @Test
-    public void testUnsupportedInnerQueryType() throws IOException {
-        QueryShardContext context = createShardContext();
-        // test makes only sense if we have at least one type registered with date field mapping
-        if (getCurrentTypes().length > 0 && context.fieldMapper(DATE_FIELD_NAME) != null) {
-            try {
-                RangeQueryBuilder query = new RangeQueryBuilder(DATE_FIELD_NAME);
-                new SpanMultiTermQueryBuilder(query).toQuery(createShardContext());
-                fail("Exception expected, range query on date fields should not generate a lucene " + MultiTermQuery.class.getName());
-            } catch (UnsupportedOperationException e) {
-                assert(e.getMessage().contains("unsupported inner query, should be " + MultiTermQuery.class.getName()));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanNearQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanNearQueryBuilderTests.java
deleted file mode 100644
index e8ce6c5..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanNearQueryBuilderTests.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNearQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Iterator;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanNearQueryBuilderTests extends BaseQueryTestCase<SpanNearQueryBuilder> {
-
-    @Override
-    protected SpanNearQueryBuilder doCreateTestQueryBuilder() {
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(randomIntBetween(-10, 10));
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(randomIntBetween(1, 6));
-        for (SpanTermQueryBuilder clause : spanTermQueries) {
-            queryBuilder.clause(clause);
-        }
-        queryBuilder.inOrder(randomBoolean());
-        queryBuilder.collectPayloads(randomBoolean());
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanNearQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanNearQuery.class));
-        SpanNearQuery spanNearQuery = (SpanNearQuery) query;
-        assertThat(spanNearQuery.getSlop(), equalTo(queryBuilder.slop()));
-        assertThat(spanNearQuery.isInOrder(), equalTo(queryBuilder.inOrder()));
-        assertThat(spanNearQuery.getClauses().length, equalTo(queryBuilder.clauses().size()));
-        Iterator<SpanQueryBuilder> spanQueryBuilderIterator = queryBuilder.clauses().iterator();
-        for (SpanQuery spanQuery : spanNearQuery.getClauses()) {
-            assertThat(spanQuery, equalTo(spanQueryBuilderIterator.next().toQuery(context)));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(1);
-        assertValidate(queryBuilder, 1); // empty clause list
-
-        int totalExpectedErrors = 0;
-        int clauses = randomIntBetween(1, 10);
-        for (int i = 0; i < clauses; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    queryBuilder.clause(new SpanTermQueryBuilder("", "test"));
-                } else {
-                    queryBuilder.clause(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                queryBuilder.clause(new SpanTermQueryBuilder("name", "value"));
-            }
-        }
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanNotQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanNotQueryBuilderTests.java
deleted file mode 100644
index 7d5f450..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanNotQueryBuilderTests.java
+++ /dev/null
@@ -1,205 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanNotQuery;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.elasticsearch.index.query.QueryBuilders.spanNearQuery;
-import static org.elasticsearch.index.query.QueryBuilders.spanTermQuery;
-import static org.hamcrest.Matchers.*;
-
-public class SpanNotQueryBuilderTests extends BaseQueryTestCase<SpanNotQueryBuilder> {
-
-    @Override
-    protected SpanNotQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(2);
-        SpanNotQueryBuilder queryBuilder = new SpanNotQueryBuilder(spanTermQueries[0], spanTermQueries[1]);
-        if (randomBoolean()) {
-            // also test negative values, they should implicitly be changed to 0
-            queryBuilder.dist(randomIntBetween(-2, 10));
-        } else {
-            if (randomBoolean()) {
-                queryBuilder.pre(randomIntBetween(-2, 10));
-            }
-            if (randomBoolean()) {
-                queryBuilder.post(randomIntBetween(-2, 10));
-            }
-        }
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanNotQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanNotQuery.class));
-        SpanNotQuery spanNotQuery = (SpanNotQuery) query;
-        assertThat(spanNotQuery.getExclude(), equalTo(queryBuilder.excludeQuery().toQuery(context)));
-        assertThat(spanNotQuery.getInclude(), equalTo(queryBuilder.includeQuery().toQuery(context)));
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder include;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                include = new SpanTermQueryBuilder("", "test");
-            } else {
-                include = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            include = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanQueryBuilder exclude;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                exclude = new SpanTermQueryBuilder("", "test");
-            } else {
-                exclude = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            exclude = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanNotQueryBuilder queryBuilder = new SpanNotQueryBuilder(include, exclude);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-
-    @Test
-    public void testDist() {
-        SpanNotQueryBuilder builder = new SpanNotQueryBuilder(new SpanTermQueryBuilder("name1", "value1"), new SpanTermQueryBuilder("name2", "value2"));
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.dist(-4);
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.dist(4);
-        assertThat(builder.pre(), equalTo(4));
-        assertThat(builder.post(), equalTo(4));
-    }
-
-    @Test
-    public void testPrePost() {
-        SpanNotQueryBuilder builder = new SpanNotQueryBuilder(new SpanTermQueryBuilder("name1", "value1"), new SpanTermQueryBuilder("name2", "value2"));
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.pre(-4).post(-4);
-        assertThat(builder.pre(), equalTo(0));
-        assertThat(builder.post(), equalTo(0));
-        builder.pre(1).post(2);
-        assertThat(builder.pre(), equalTo(1));
-        assertThat(builder.post(), equalTo(2));
-    }
-
-    /**
-     * test correct parsing of `dist` parameter, this should create builder with pre/post set to same value
-     */
-    @Test
-    public void testParseDist() throws IOException {
-        XContentBuilder builder = XContentFactory.jsonBuilder();
-        builder.startObject();
-        builder.startObject(SpanNotQueryBuilder.NAME);
-        builder.field("exclude");
-        spanTermQuery("description", "jumped").toXContent(builder, null);
-        builder.field("include");
-        spanNearQuery(1).clause(QueryBuilders.spanTermQuery("description", "quick"))
-                .clause(QueryBuilders.spanTermQuery("description", "fox")).toXContent(builder, null);
-        builder.field("dist", 3);
-        builder.endObject();
-        builder.endObject();
-        SpanNotQueryBuilder query = (SpanNotQueryBuilder)parseQuery(builder.string());
-        assertThat(query.pre(), equalTo(3));
-        assertThat(query.post(), equalTo(3));
-        assertNotNull(query.includeQuery());
-        assertNotNull(query.excludeQuery());
-    }
-
-    /**
-     * test exceptions for three types of broken json, missing include / exclude and both dist and pre/post specified
-     */
-    @Test
-    public void testParserExceptions() throws IOException {
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanNotQueryBuilder.NAME);
-            builder.field("exclude");
-            spanTermQuery("description", "jumped").toXContent(builder, null);
-            builder.field("dist", 2);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string());
-                fail("QueryParsingException should have been caught");
-            } catch (QueryParsingException e) {
-                assertThat("QueryParsingException should have been caught", e.getDetailedMessage(), containsString("spanNot must have [include]"));
-            }
-        }
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanNotQueryBuilder.NAME);
-            builder.field("include");
-            spanNearQuery(1).clause(QueryBuilders.spanTermQuery("description", "quick"))
-                    .clause(QueryBuilders.spanTermQuery("description", "fox")).toXContent(builder, null);
-            builder.field("dist", 2);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string());
-                fail("QueryParsingException should have been caught");
-            } catch (QueryParsingException e) {
-                assertThat("QueryParsingException should have been caught", e.getDetailedMessage(), containsString("spanNot must have [exclude]"));
-            }
-        }
-
-        {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            builder.startObject(SpanNotQueryBuilder.NAME);
-            builder.field("include");
-            spanNearQuery(1).clause(QueryBuilders.spanTermQuery("description", "quick"))
-                    .clause(QueryBuilders.spanTermQuery("description", "fox")).toXContent(builder, null);
-            builder.field("exclude");
-            spanTermQuery("description", "jumped").toXContent(builder, null);
-            builder.field("dist", 2);
-            builder.field("pre", 2);
-            builder.endObject();
-            builder.endObject();
-
-            try {
-                parseQuery(builder.string());
-                fail("QueryParsingException should have been caught");
-            } catch (QueryParsingException e) {
-                assertThat("QueryParsingException should have been caught", e.getDetailedMessage(), containsString("spanNot can either use [dist] or [pre] & [post] (or none)"));
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanOrQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanOrQueryBuilderTests.java
deleted file mode 100644
index a83610b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanOrQueryBuilderTests.java
+++ /dev/null
@@ -1,77 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanOrQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Iterator;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanOrQueryBuilderTests extends BaseQueryTestCase<SpanOrQueryBuilder> {
-
-    @Override
-    protected SpanOrQueryBuilder doCreateTestQueryBuilder() {
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(randomIntBetween(1, 6));
-        for (SpanTermQueryBuilder clause : spanTermQueries) {
-            queryBuilder.clause(clause);
-        }
-        return queryBuilder;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanOrQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanOrQuery.class));
-        SpanOrQuery spanOrQuery = (SpanOrQuery) query;
-        assertThat(spanOrQuery.getClauses().length, equalTo(queryBuilder.clauses().size()));
-        Iterator<SpanQueryBuilder> spanQueryBuilderIterator = queryBuilder.clauses().iterator();
-        for (SpanQuery spanQuery : spanOrQuery.getClauses()) {
-            assertThat(spanQuery, equalTo(spanQueryBuilderIterator.next().toQuery(context)));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
-        assertValidate(queryBuilder, 1); // empty clause list
-
-        int totalExpectedErrors = 0;
-        int clauses = randomIntBetween(1, 10);
-        for (int i = 0; i < clauses; i++) {
-            if (randomBoolean()) {
-                if (randomBoolean()) {
-                    queryBuilder.clause(new SpanTermQueryBuilder("", "test"));
-                } else {
-                    queryBuilder.clause(null);
-                }
-                totalExpectedErrors++;
-            } else {
-                queryBuilder.clause(new SpanTermQueryBuilder("name", "value"));
-            }
-        }
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanTermQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanTermQueryBuilderTests.java
deleted file mode 100644
index 41631df..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanTermQueryBuilderTests.java
+++ /dev/null
@@ -1,75 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanTermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanTermQueryBuilderTests extends BaseTermQueryTestCase<SpanTermQueryBuilder> {
-
-    @Override
-    protected SpanTermQueryBuilder createQueryBuilder(String fieldName, Object value) {
-        return new SpanTermQueryBuilder(fieldName, value);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanTermQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanTermQuery.class));
-        SpanTermQuery spanTermQuery = (SpanTermQuery) query;
-        assertThat(spanTermQuery.getTerm().field(), equalTo(queryBuilder.fieldName()));
-        MappedFieldType mapper = context.fieldMapper(queryBuilder.fieldName());
-        if (mapper != null) {
-            BytesRef bytesRef = mapper.indexedValueForSearch(queryBuilder.value());
-            assertThat(spanTermQuery.getTerm().bytes(), equalTo(bytesRef));
-        } else {
-            assertThat(spanTermQuery.getTerm().bytes(), equalTo(BytesRefs.toBytesRef(queryBuilder.value())));
-        }
-    }
-
-    /**
-     * @param amount the number of clauses that will be returned
-     * @return an array of random {@link SpanTermQueryBuilder} with same field name
-     */
-    public SpanTermQueryBuilder[] createSpanTermQueryBuilders(int amount) {
-        SpanTermQueryBuilder[] clauses = new SpanTermQueryBuilder[amount];
-        SpanTermQueryBuilder first = createTestQueryBuilder();
-        clauses[0] = first;
-        for (int i = 1; i < amount; i++) {
-            // we need same field name in all clauses, so we only randomize value
-            SpanTermQueryBuilder spanTermQuery = new SpanTermQueryBuilder(first.fieldName(), getRandomValueForFieldName(first.fieldName()));
-            if (randomBoolean()) {
-                spanTermQuery.boost(2.0f / randomIntBetween(1, 20));
-            }
-            if (randomBoolean()) {
-                spanTermQuery.queryName(randomAsciiOfLengthBetween(1, 10));
-            }
-            clauses[i] = spanTermQuery;
-        }
-        return clauses;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/SpanWithinQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/SpanWithinQueryBuilderTests.java
deleted file mode 100644
index 0e22f26..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/SpanWithinQueryBuilderTests.java
+++ /dev/null
@@ -1,82 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.spans.SpanWithinQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class SpanWithinQueryBuilderTests extends BaseQueryTestCase<SpanWithinQueryBuilder> {
-
-    @Override
-    protected SpanWithinQueryBuilder doCreateTestQueryBuilder() {
-        SpanTermQueryBuilder[] spanTermQueries = new SpanTermQueryBuilderTests().createSpanTermQueryBuilders(2);
-        return new SpanWithinQueryBuilder(spanTermQueries[0], spanTermQueries[1]);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(SpanWithinQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(SpanWithinQuery.class));
-    }
-
-    @Override
-    protected void assertBoost(SpanWithinQueryBuilder queryBuilder, Query query) throws IOException {
-        if (queryBuilder.boost() == AbstractQueryBuilder.DEFAULT_BOOST) {
-            //lucene default behaviour
-            assertThat(query.getBoost(), equalTo(queryBuilder.littleQuery().boost()));
-        } else {
-            assertThat(query.getBoost(), equalTo(queryBuilder.boost()));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        int totalExpectedErrors = 0;
-        SpanQueryBuilder bigSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                bigSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                bigSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            bigSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanQueryBuilder littleSpanQueryBuilder;
-        if (randomBoolean()) {
-            if (randomBoolean()) {
-                littleSpanQueryBuilder = new SpanTermQueryBuilder("", "test");
-            } else {
-                littleSpanQueryBuilder = null;
-            }
-            totalExpectedErrors++;
-        } else {
-            littleSpanQueryBuilder = new SpanTermQueryBuilder("name", "value");
-        }
-        SpanWithinQueryBuilder queryBuilder = new SpanWithinQueryBuilder(bigSpanQueryBuilder, littleSpanQueryBuilder);
-        assertValidate(queryBuilder, totalExpectedErrors);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java
index e18a0f8..647ac44 100644
--- a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryBuilderTests.java
@@ -16,60 +16,23 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-
 package org.elasticsearch.index.query;
 
-import org.apache.lucene.search.Query;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.script.ScriptService.ScriptType;
 import org.elasticsearch.script.Template;
-import org.junit.BeforeClass;
+import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
 
-import static org.hamcrest.Matchers.is;
-
-public class TemplateQueryBuilderTests extends BaseQueryTestCase<TemplateQueryBuilder> {
-
-    /**
-     * The query type all template tests will be based on.
-     */
-    private static QueryBuilder<?> templateBase;
-
-    @BeforeClass
-    public static void setupClass() {
-        templateBase = RandomQueryBuilder.createQuery(getRandom());
-    }
-
-    @Override
-    protected boolean supportsBoostAndQueryName() {
-        return false;
-    }
-
-    @Override
-    protected TemplateQueryBuilder doCreateTestQueryBuilder() {
-        return new TemplateQueryBuilder(new Template(templateBase.toString()));
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(TemplateQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertEquals(templateBase.toQuery(createShardContext()), query);
-    }
-
-    @Test
-    public void testValidate() {
-        TemplateQueryBuilder templateQueryBuilder = new TemplateQueryBuilder(null);
-        assertThat(templateQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-
-    @Override
-    protected void assertBoost(TemplateQueryBuilder queryBuilder, Query query) throws IOException {
-        //no-op boost is checked already above as part of doAssertLuceneQuery as we rely on lucene equals impl
-    }
+/**
+ * Test building and serialising a template search request.
+ * */
+public class TemplateQueryBuilderTests extends ESTestCase {
 
     @Test
     public void testJSONGeneration() throws IOException {
diff --git a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTests.java b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTests.java
index 5190c40..df65adc 100644
--- a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryParserTests.java
@@ -62,7 +62,7 @@ import java.io.IOException;
 public class TemplateQueryParserTests extends ESTestCase {
 
     private Injector injector;
-    private QueryShardContext context;
+    private QueryParseContext context;
 
     @Before
     public void setup() throws IOException {
@@ -102,7 +102,7 @@ public class TemplateQueryParserTests extends ESTestCase {
         ).createInjector();
 
         IndexQueryParserService queryParserService = injector.getInstance(IndexQueryParserService.class);
-        context = new QueryShardContext(index, queryParserService);
+        context = new QueryParseContext(index, queryParserService);
     }
 
     @Override
diff --git a/core/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTests.java
deleted file mode 100644
index 5c8146d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/TermQueryBuilderTests.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.lucene.BytesRefs;
-import org.elasticsearch.index.mapper.MappedFieldType;
-
-import java.io.IOException;
-
-import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.CoreMatchers.instanceOf;
-
-public class TermQueryBuilderTests extends BaseTermQueryTestCase<TermQueryBuilder> {
-
-    /**
-     * @return a TermQuery with random field name and value, optional random boost and queryname
-     */
-    @Override
-    protected TermQueryBuilder createQueryBuilder(String fieldName, Object value) {
-        return new TermQueryBuilder(fieldName, value);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(TermQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(TermQuery.class));
-        TermQuery termQuery = (TermQuery) query;
-        assertThat(termQuery.getTerm().field(), equalTo(queryBuilder.fieldName()));
-        MappedFieldType mapper = context.fieldMapper(queryBuilder.fieldName());
-        if (mapper != null) {
-            BytesRef bytesRef = mapper.indexedValueForSearch(queryBuilder.value());
-            assertThat(termQuery.getTerm().bytes(), equalTo(bytesRef));
-        } else {
-            assertThat(termQuery.getTerm().bytes(), equalTo(BytesRefs.toBytesRef(queryBuilder.value())));
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTests.java
deleted file mode 100644
index cd8d8b1..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/TermsQueryBuilderTests.java
+++ /dev/null
@@ -1,228 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.search.termslookup.TermsLookupFetchService;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
-import org.hamcrest.Matchers;
-import org.junit.Before;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Iterator;
-import java.util.List;
-
-import static org.hamcrest.Matchers.*;
-
-public class TermsQueryBuilderTests extends BaseQueryTestCase<TermsQueryBuilder> {
-
-    private MockTermsLookupFetchService termsLookupFetchService;
-
-    @Before
-    public void mockTermsLookupFetchService() {
-        termsLookupFetchService = new MockTermsLookupFetchService();
-        queryParserService().setTermsLookupFetchService(termsLookupFetchService);
-    }
-
-    @Override
-    protected TermsQueryBuilder doCreateTestQueryBuilder() {
-        TermsQueryBuilder query;
-        // terms query or lookup query
-        if (randomBoolean()) {
-            // make between 0 and 5 different values of the same type
-            String fieldName = getRandomFieldName();
-            Object[] values = new Object[randomInt(5)];
-            for (int i = 0; i < values.length; i++) {
-                values[i] = getRandomValueForFieldName(fieldName);
-            }
-            query = new TermsQueryBuilder(fieldName, values);
-        } else {
-            // right now the mock service returns us a list of strings
-            query = new TermsQueryBuilder(randomBoolean() ? randomAsciiOfLengthBetween(1,10) : STRING_FIELD_NAME);
-            query.termsLookup(randomTermsLookup());
-        }
-        if (randomBoolean()) {
-            query.minimumShouldMatch(randomInt(100) + "%");
-        }
-        if (randomBoolean()) {
-            query.disableCoord(randomBoolean());
-        }
-        return query;
-    }
-
-    private TermsLookup randomTermsLookup() {
-        return new TermsLookup(
-                randomBoolean() ? randomAsciiOfLength(10) : null,
-                randomAsciiOfLength(10),
-                randomAsciiOfLength(10),
-                randomAsciiOfLength(10)
-        ).routing(randomBoolean() ? randomAsciiOfLength(10) : null);
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(TermsQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(BooleanQuery.class));
-        BooleanQuery booleanQuery = (BooleanQuery) query;
-
-        // we only do the check below for string fields (otherwise we'd have to decode the values)
-        if (queryBuilder.fieldName().equals(INT_FIELD_NAME) || queryBuilder.fieldName().equals(DOUBLE_FIELD_NAME)
-                || queryBuilder.fieldName().equals(BOOLEAN_FIELD_NAME) || queryBuilder.fieldName().equals(DATE_FIELD_NAME)) {
-            return;
-        }
-
-        // expected returned terms depending on whether we have a terms query or a terms lookup query
-        List<Object> terms;
-        if (queryBuilder.termsLookup() != null) {
-            terms = termsLookupFetchService.getRandomTerms();
-        } else {
-            terms = queryBuilder.values();
-        }
-
-        // compare whether we have the expected list of terms returned
-        Iterator<Object> iter = terms.iterator();
-        for (BooleanClause booleanClause : booleanQuery) {
-            assertThat(booleanClause.getQuery(), instanceOf(TermQuery.class));
-            Term term = ((TermQuery) booleanClause.getQuery()).getTerm();
-            Object next = iter.next();
-            if (next == null) {
-                continue;
-            }
-            assertThat(term, equalTo(new Term(queryBuilder.fieldName(), next.toString())));
-        }
-    }
-
-    @Test
-    public void testValidate() {
-        TermsQueryBuilder termsQueryBuilder = new TermsQueryBuilder(null, "term");
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        termsQueryBuilder = new TermsQueryBuilder("field", "term").termsLookup(randomTermsLookup());
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(1));
-
-        termsQueryBuilder = new TermsQueryBuilder(null, "term").termsLookup(randomTermsLookup());
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(2));
-
-        termsQueryBuilder = new TermsQueryBuilder("field", "term");
-        assertNull(termsQueryBuilder.validate());
-    }
-
-    @Test
-    public void testValidateLookupQuery() {
-        TermsQueryBuilder termsQuery = new TermsQueryBuilder("field").termsLookup(new TermsLookup());
-        int totalExpectedErrors = 3;
-        if (randomBoolean()) {
-            termsQuery.lookupId("id");
-            totalExpectedErrors--;
-        }
-        if (randomBoolean()) {
-            termsQuery.lookupType("type");
-            totalExpectedErrors--;
-        }
-        if (randomBoolean()) {
-            termsQuery.lookupPath("path");
-            totalExpectedErrors--;
-        }
-        assertValidate(termsQuery, totalExpectedErrors);
-    }
-
-    @Test
-    public void testNullValues() {
-        try {
-            switch (randomInt(6)) {
-                case 0:
-                    new TermsQueryBuilder("field", (String[]) null);
-                    break;
-                case 1:
-                    new TermsQueryBuilder("field", (int[]) null);
-                    break;
-                case 2:
-                    new TermsQueryBuilder("field", (long[]) null);
-                    break;
-                case 3:
-                    new TermsQueryBuilder("field", (float[]) null);
-                    break;
-                case 4:
-                    new TermsQueryBuilder("field", (double[]) null);
-                    break;
-                case 5:
-                    new TermsQueryBuilder("field", (Object[]) null);
-                    break;
-                default:
-                    new TermsQueryBuilder("field", (Iterable<?>) null);
-                    break;
-            }
-            fail("should have failed with IllegalArgumentException");
-        } catch (IllegalArgumentException e) {
-            assertThat(e.getMessage(), Matchers.containsString("No value specified for terms query"));
-        }
-    }
-
-    @Test
-    public void testBothValuesAndLookupSet() throws IOException {
-        String query = "{\n" +
-                "  \"terms\": {\n" +
-                "    \"field\": [\n" +
-                "      \"blue\",\n" +
-                "      \"pill\"\n" +
-                "    ],\n" +
-                "    \"field_lookup\": {\n" +
-                "      \"index\": \"pills\",\n" +
-                "      \"type\": \"red\",\n" +
-                "      \"id\": \"3\",\n" +
-                "      \"path\": \"white rabbit\"\n" +
-                "    }\n" +
-                "  }\n" +
-                "}";
-        QueryBuilder termsQueryBuilder = parseQuery(query);
-        assertThat(termsQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-
-    private static class MockTermsLookupFetchService extends TermsLookupFetchService {
-
-        private List<Object> randomTerms = new ArrayList<>();
-
-        MockTermsLookupFetchService() {
-            super(null, Settings.Builder.EMPTY_SETTINGS);
-            String[] strings = generateRandomStringArray(10, 10, false, true);
-            for (String string : strings) {
-                randomTerms.add(string);
-                if (rarely()) {
-                    randomTerms.add(null);
-                }
-            }
-        }
-
-        @Override
-        public List<Object> fetch(TermsLookup termsLookup) {
-            return randomTerms;
-        }
-
-        List<Object> getRandomTerms() {
-            return randomTerms;
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTests.java
deleted file mode 100644
index 0ed327a..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/TypeQueryBuilderTests.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.TermQuery;
-import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.*;
-
-public class TypeQueryBuilderTests extends BaseQueryTestCase<TypeQueryBuilder> {
-
-    @Override
-    protected TypeQueryBuilder doCreateTestQueryBuilder() {
-        return new TypeQueryBuilder(getRandomType());
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(TypeQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, either(instanceOf(TermQuery.class)).or(instanceOf(ConstantScoreQuery.class)));
-        if (query instanceof ConstantScoreQuery) {
-            query = ((ConstantScoreQuery) query).getQuery();
-            assertThat(query, instanceOf(TermQuery.class));
-        }
-        TermQuery termQuery = (TermQuery) query;
-        assertThat(termQuery.getTerm().field(), equalTo(TypeFieldMapper.NAME));
-        assertThat(termQuery.getTerm().text(), equalTo(queryBuilder.type()));
-    }
-
-    @Test
-    public void testValidate() {
-        TypeQueryBuilder typeQueryBuilder = new TypeQueryBuilder((String) null);
-        assertThat(typeQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/WildcardQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/WildcardQueryBuilderTests.java
deleted file mode 100644
index 39f7187..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/WildcardQueryBuilderTests.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.WildcardQuery;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-
-public class WildcardQueryBuilderTests extends BaseQueryTestCase<WildcardQueryBuilder> {
-
-    @Override
-    protected WildcardQueryBuilder doCreateTestQueryBuilder() {
-        WildcardQueryBuilder query;
-
-        // mapped or unmapped field
-        String text = randomAsciiOfLengthBetween(1, 10);
-        if (randomBoolean()) {
-            query = new WildcardQueryBuilder(STRING_FIELD_NAME, text);
-        } else {
-            query = new WildcardQueryBuilder(randomAsciiOfLengthBetween(1, 10), text);
-        }
-        if (randomBoolean()) {
-            query.rewrite(randomFrom(getRandomRewriteMethod()));
-        }
-        return query;
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(WildcardQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        assertThat(query, instanceOf(WildcardQuery.class));
-    }
-
-    @Test
-    public void testValidate() {
-        WildcardQueryBuilder wildcardQueryBuilder = new WildcardQueryBuilder("", "text");
-        assertThat(wildcardQueryBuilder.validate().validationErrors().size(), is(1));
-
-        wildcardQueryBuilder = new WildcardQueryBuilder("field", null);
-        assertThat(wildcardQueryBuilder.validate().validationErrors().size(), is(1));
-
-        wildcardQueryBuilder = new WildcardQueryBuilder(null, null);
-        assertThat(wildcardQueryBuilder.validate().validationErrors().size(), is(2));
-
-        wildcardQueryBuilder = new WildcardQueryBuilder("field", "text");
-        assertNull(wildcardQueryBuilder.validate());
-    }
-
-    @Test
-    public void testEmptyValue() throws IOException {
-        QueryShardContext context = createShardContext();
-        context.setAllowUnmappedFields(true);
-
-        WildcardQueryBuilder wildcardQueryBuilder = new WildcardQueryBuilder(getRandomType(), "");
-        assertEquals(wildcardQueryBuilder.toQuery(context).getClass(), WildcardQuery.class);
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTests.java
deleted file mode 100644
index 3e9317d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/WrapperQueryBuilderTests.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.query;
-
-import org.apache.lucene.search.Query;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.is;
-
-public class WrapperQueryBuilderTests extends BaseQueryTestCase<WrapperQueryBuilder> {
-
-    @Override
-    protected boolean supportsBoostAndQueryName() {
-        return false;
-    }
-
-    @Override
-    protected WrapperQueryBuilder doCreateTestQueryBuilder() {
-        QueryBuilder wrappedQuery = RandomQueryBuilder.createQuery(random());
-        switch (randomInt(2)) {
-            case 0:
-                return new WrapperQueryBuilder(wrappedQuery.toString());
-            case 1:
-                return new WrapperQueryBuilder(wrappedQuery.buildAsBytes().toBytes());
-            case 2:
-                return new WrapperQueryBuilder(wrappedQuery.buildAsBytes());
-            default:
-                throw new UnsupportedOperationException();
-        }
-    }
-
-    @Override
-    protected void doAssertLuceneQuery(WrapperQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        try (XContentParser qSourceParser = XContentFactory.xContent(queryBuilder.source()).createParser(queryBuilder.source())) {
-            final QueryShardContext contextCopy = new QueryShardContext(context.index(), context.indexQueryParserService());
-            contextCopy.reset(qSourceParser);
-            QueryBuilder<?> innerQuery = contextCopy.parseContext().parseInnerQueryBuilder();
-            Query expected = innerQuery.toQuery(context);
-            assertThat(query, equalTo(expected));
-        }
-    }
-
-    @Override
-    protected void assertBoost(WrapperQueryBuilder queryBuilder, Query query) throws IOException {
-        //no-op boost is checked already above as part of doAssertLuceneQuery as we rely on lucene equals impl
-    }
-
-    @Test
-    public void testValidate() {
-        WrapperQueryBuilder wrapperQueryBuilder = new WrapperQueryBuilder((byte[]) null);
-        assertThat(wrapperQueryBuilder.validate().validationErrors().size(), is(1));
-
-        wrapperQueryBuilder = new WrapperQueryBuilder("");
-        assertThat(wrapperQueryBuilder.validate().validationErrors().size(), is(1));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/and-filter-cache.json b/core/src/test/java/org/elasticsearch/index/query/and-filter-cache.json
deleted file mode 100644
index 41cc482..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/and-filter-cache.json
+++ /dev/null
@@ -1,21 +0,0 @@
-{
-    "filtered":{
-      "filter":{
-            "and":{
-                "filters":[
-                    {
-                        "term":{
-                            "name.first":"shay1"
-                        }
-                    },
-                    {
-                        "term":{
-                            "name.first":"shay4"
-                        }
-                    }
-                ],
-                "_cache" : true
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/and-filter-named.json b/core/src/test/java/org/elasticsearch/index/query/and-filter-named.json
deleted file mode 100644
index 605a193..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/and-filter-named.json
+++ /dev/null
@@ -1,26 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "and":{
-                "filters":[
-                    {
-                        "term":{
-                            "name.first":"shay1"
-                        }
-                    },
-                    {
-                        "term":{
-                            "name.first":"shay4"
-                        }
-                    }
-                ],
-                "_name":"test"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/and-filter.json b/core/src/test/java/org/elasticsearch/index/query/and-filter.json
deleted file mode 100644
index 752add1..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/and-filter.json
+++ /dev/null
@@ -1,25 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "and":{
-                "filters":[
-                    {
-                        "term":{
-                            "name.first":"shay1"
-                        }
-                    },
-                    {
-                        "term":{
-                            "name.first":"shay4"
-                        }
-                    }
-                ]
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/and-filter2.json b/core/src/test/java/org/elasticsearch/index/query/and-filter2.json
deleted file mode 100644
index 580b8e9..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/and-filter2.json
+++ /dev/null
@@ -1,23 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "and":[
-                {
-                    "term":{
-                        "name.first":"shay1"
-                    }
-                },
-                {
-                    "term":{
-                        "name.first":"shay4"
-                    }
-                }
-            ]
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/bool-filter.json b/core/src/test/java/org/elasticsearch/index/query/bool-filter.json
deleted file mode 100644
index 484e517..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/bool-filter.json
+++ /dev/null
@@ -1,35 +0,0 @@
-{
-    filtered:{
-        query:{
-            term:{
-                "name.first":"shay"
-            }
-        },
-        filter:{
-            bool:{
-                must:[
-                    {
-                        term:{
-                            "name.first":"shay1"
-                        }
-                    },
-                    {
-                        term:{
-                            "name.first":"shay4"
-                        }
-                    }
-                ],
-                must_not:{
-                    term:{
-                        "name.first":"shay2"
-                    }
-                },
-                should:{
-                    term:{
-                        "name.first":"shay3"
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/bool-query-with-empty-clauses-for-parsing.json b/core/src/test/java/org/elasticsearch/index/query/bool-query-with-empty-clauses-for-parsing.json
deleted file mode 100644
index 5864359..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/bool-query-with-empty-clauses-for-parsing.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-  "filtered": {
-    "filter": {
-      "nested": {
-        "path": "nested",
-        "query": {
-          "bool": {
-            "must": [],
-            "must_not": [],
-            "should": []
-          }
-        }
-      },
-      "query": []
-    }
-  }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/bool.json b/core/src/test/java/org/elasticsearch/index/query/bool.json
deleted file mode 100644
index 1619fcf..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/bool.json
+++ /dev/null
@@ -1,30 +0,0 @@
-{
-    bool:{
-        must:[
-            {
-                query_string:{
-                    default_field:"content",
-                    query:"test1"
-                }
-            },
-            {
-                query_string:{
-                    default_field:"content",
-                    query:"test4"
-                }
-            }
-        ],
-        must_not:{
-            query_string:{
-                default_field:"content",
-                query:"test2"
-            }
-        },
-        should:{
-            query_string:{
-                default_field:"content",
-                query:"test3"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/boosting-query.json b/core/src/test/java/org/elasticsearch/index/query/boosting-query.json
deleted file mode 100644
index 87b6e6d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/boosting-query.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "boosting":{
-        "positive":{
-            "term":{
-                "field1":"value1"
-            }
-        },
-        "negative":{
-            "term":{
-                "field2":"value2"
-            }
-        },
-        "negative_boost":0.2
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/child-mapping.json b/core/src/test/java/org/elasticsearch/index/query/child-mapping.json
deleted file mode 100644
index 6f3b6e5..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/child-mapping.json
+++ /dev/null
@@ -1,12 +0,0 @@
-{
-    "child":{
-        "properties":{
-            "field":{
-                "type":"string"
-            }
-        },
-        "_parent" : {
-          "type" : "person"
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/commonTerms-query1.json b/core/src/test/java/org/elasticsearch/index/query/commonTerms-query1.json
deleted file mode 100644
index b2728da..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/commonTerms-query1.json
+++ /dev/null
@@ -1,11 +0,0 @@
-{
-    "common" : {
-        "dogs" : {
-            "query" : "buck mia tom",
-            "cutoff_frequency" : 1,
-            "minimum_should_match" : {
-                "low_freq" : 2
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/commonTerms-query2.json b/core/src/test/java/org/elasticsearch/index/query/commonTerms-query2.json
deleted file mode 100644
index aeb281b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/commonTerms-query2.json
+++ /dev/null
@@ -1,11 +0,0 @@
-{
-    "common" : {
-        "dogs" : {
-            "query" : "buck mia tom",
-            "minimum_should_match" : {
-                "high_freq" : "50%",
-                "low_freq" : "5<20%"
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/commonTerms-query3.json b/core/src/test/java/org/elasticsearch/index/query/commonTerms-query3.json
deleted file mode 100644
index f276209..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/commonTerms-query3.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-    "common" : {
-        "dogs" : {
-            "query" : "buck mia tom",
-            "cutoff_frequency" : 1,
-            "minimum_should_match" : 2
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/constantScore-query.json b/core/src/test/java/org/elasticsearch/index/query/constantScore-query.json
deleted file mode 100644
index bf59bc5..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/constantScore-query.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-    constant_score:{
-        filter:{
-            term:{
-                "name.last":"banon"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/data.json b/core/src/test/java/org/elasticsearch/index/query/data.json
deleted file mode 100644
index 79f139f..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/data.json
+++ /dev/null
@@ -1,43 +0,0 @@
-{
-    name:{
-        first:"shay",
-        last:"banon"
-    },
-    address:{
-        first:{
-            location:"first location"
-        },
-        last:{
-            location:"last location"
-        }
-    },
-    age:32,
-    birthDate:"1977-11-15",
-    nerd:true,
-    dogs:["buck", "mia"],
-    complex:[
-        {
-            value1:"value1"
-        },
-        {
-            value2:"value2"
-        }
-    ],
-    complex2:[
-        [
-            {
-                value1:"value1"
-            }
-        ],
-        [
-            {
-                value2:"value2"
-            }
-        ]
-    ],
-    nullValue:null,
-    "location":{
-        "lat":1.1,
-        "lon":1.2
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/date_range_filter_format.json b/core/src/test/java/org/elasticsearch/index/query/date_range_filter_format.json
deleted file mode 100644
index 9459678..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/date_range_filter_format.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-    "constant_score": {
-        "filter": {
-            "range" : {
-                "born" : {
-                    "gte": "01/01/2012",
-                    "lt": "2030",
-                    "format": "dd/MM/yyyy||yyyy"
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/date_range_filter_format_invalid.json b/core/src/test/java/org/elasticsearch/index/query/date_range_filter_format_invalid.json
deleted file mode 100644
index 7b5c272..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/date_range_filter_format_invalid.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-    "constant_score": {
-        "filter": {
-            "range" : {
-                "born" : {
-                    "gte": "01/01/2012",
-                    "lt": "2030",
-                    "format": "yyyy"
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/date_range_filter_timezone.json b/core/src/test/java/org/elasticsearch/index/query/date_range_filter_timezone.json
deleted file mode 100644
index 158550a..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/date_range_filter_timezone.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-    "constant_score": {
-        "filter": {
-            "range" : {
-                "born" : {
-                    "gte": "2012-01-01",
-                    "lte": "now",
-                    "time_zone": "+01:00"
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/date_range_filter_timezone_numeric_field.json b/core/src/test/java/org/elasticsearch/index/query/date_range_filter_timezone_numeric_field.json
deleted file mode 100644
index 6e07194..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/date_range_filter_timezone_numeric_field.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-    "constant_score": {
-        "filter": {
-            "range" : {
-                "age" : {
-                    "gte": "0",
-                    "lte": "100",
-                    "time_zone": "-01:00"
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/date_range_query_boundaries_exclusive.json b/core/src/test/java/org/elasticsearch/index/query/date_range_query_boundaries_exclusive.json
deleted file mode 100644
index 30fe50a..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/date_range_query_boundaries_exclusive.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "range" : {
-        "born" : {
-            "gt": "2014-11-05||/M",
-            "lt": "2014-12-08||/d"
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/date_range_query_boundaries_inclusive.json b/core/src/test/java/org/elasticsearch/index/query/date_range_query_boundaries_inclusive.json
deleted file mode 100644
index 3f3aab0..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/date_range_query_boundaries_inclusive.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "range" : {
-        "born" : {
-            "gte": "2014-11-05||/M",
-            "lte": "2014-12-08||/d"
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/date_range_query_format.json b/core/src/test/java/org/elasticsearch/index/query/date_range_query_format.json
deleted file mode 100644
index f679dc9..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/date_range_query_format.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-    "range" : {
-        "born" : {
-            "gte": "01/01/2012",
-            "lt": "2030",
-            "format": "dd/MM/yyyy||yyyy"
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/date_range_query_format_invalid.json b/core/src/test/java/org/elasticsearch/index/query/date_range_query_format_invalid.json
deleted file mode 100644
index 307e977..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/date_range_query_format_invalid.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-    "range" : {
-        "born" : {
-            "gte": "01/01/2012",
-            "lt": "2030",
-            "format": "yyyy"
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/date_range_query_timezone.json b/core/src/test/java/org/elasticsearch/index/query/date_range_query_timezone.json
deleted file mode 100644
index 0cabb15..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/date_range_query_timezone.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-    "range" : {
-        "born" : {
-            "gte": "2012-01-01",
-            "lte": "now",
-            "time_zone": "+01:00"
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/date_range_query_timezone_numeric_field.json b/core/src/test/java/org/elasticsearch/index/query/date_range_query_timezone_numeric_field.json
deleted file mode 100644
index b7526a2..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/date_range_query_timezone_numeric_field.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-    "range" : {
-        "age" : {
-            "gte": "0",
-            "lte": "100",
-            "time_zone": "-01:00"
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/disMax.json b/core/src/test/java/org/elasticsearch/index/query/disMax.json
deleted file mode 100644
index 99da2df..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/disMax.json
+++ /dev/null
@@ -1,18 +0,0 @@
-{
-    dis_max:{
-        tie_breaker:0.7,
-        boost:1.2,
-        queries:[
-            {
-                term:{
-                    "name.first":"first"
-                }
-            },
-            {
-                term:{
-                    "name.last":"last"
-                }
-            }
-        ]
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/disMax2.json b/core/src/test/java/org/elasticsearch/index/query/disMax2.json
deleted file mode 100644
index ea92d64..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/disMax2.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    "dis_max":{
-        "queries":[
-            {
-                "prefix":{
-                    "name.first":{
-                        "value":"sh",
-                        "boost":1.2
-                    }
-                }
-            }
-        ]
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/faulty-function-score-query.json b/core/src/test/java/org/elasticsearch/index/query/faulty-function-score-query.json
deleted file mode 100644
index 07f906c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/faulty-function-score-query.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "function_score":{
-        "query":{
-            "term":{
-                "name.last":"banon"
-            }
-        },
-        "functions": { 
-            {
-            "boost_factor" : 3
-            }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/field3.json b/core/src/test/java/org/elasticsearch/index/query/field3.json
deleted file mode 100644
index 61e349f..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/field3.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-    field:{
-        age:{
-            query:34,
-            boost:2.0,
-            enable_position_increments:false
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/filtered-query.json b/core/src/test/java/org/elasticsearch/index/query/filtered-query.json
deleted file mode 100644
index 8eea99a..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/filtered-query.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    filtered:{
-        query:{
-            term:{
-                "name.first":"shay"
-            }
-        },
-        filter:{
-            term:{
-                "name.last":"banon"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/filtered-query2.json b/core/src/test/java/org/elasticsearch/index/query/filtered-query2.json
deleted file mode 100644
index b23faf4..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/filtered-query2.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    filtered:{
-        filter:{
-            term:{
-                "name.last":"banon"
-            }
-        },
-        query:{
-            term:{
-                "name.first":"shay"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/filtered-query3.json b/core/src/test/java/org/elasticsearch/index/query/filtered-query3.json
deleted file mode 100644
index 4a9db49..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/filtered-query3.json
+++ /dev/null
@@ -1,19 +0,0 @@
-{
-    filtered:{
-        filter:{
-            range:{
-                age:{
-                    from:"23",
-                    to:"54",
-                    include_lower:true,
-                    include_upper:false
-                }
-            }
-        },
-        query:{
-            term:{
-                "name.first":"shay"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/filtered-query4.json b/core/src/test/java/org/elasticsearch/index/query/filtered-query4.json
deleted file mode 100644
index 8c10013..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/filtered-query4.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-    filtered:{
-        query:{
-            wildcard:{
-                "name.first":{
-                    wildcard:"sh*",
-                    boost:1.1
-                }
-            }
-        },
-        filter:{
-            term:{
-                "name.last":"banon"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/fquery-filter.json b/core/src/test/java/org/elasticsearch/index/query/fquery-filter.json
deleted file mode 100644
index 6015334..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/fquery-filter.json
+++ /dev/null
@@ -1,19 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "fquery":{
-                "query":{
-                    "term":{
-                        "name.last":"banon"
-                    }
-                },
-                "_name":"test"
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/fquery-with-empty-bool-query.json b/core/src/test/java/org/elasticsearch/index/query/fquery-with-empty-bool-query.json
deleted file mode 100644
index 6a6a48c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/fquery-with-empty-bool-query.json
+++ /dev/null
@@ -1,18 +0,0 @@
-{
-  "fquery": {
-    "query": {
-      "filtered": {
-        "query": {
-          "term": {
-            "text": "apache"
-          }
-        },
-        "filter": {
-          "term": {
-            "text": "apache"
-          }
-        }
-      }
-    }
-  }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/function-filter-score-query.json b/core/src/test/java/org/elasticsearch/index/query/function-filter-score-query.json
deleted file mode 100644
index e78c549..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/function-filter-score-query.json
+++ /dev/null
@@ -1,30 +0,0 @@
-
-
-{
-    "function_score":{
-        "query":{
-            "term":{
-                "name.last":"banon"
-            }
-        },
-        "functions":  [
-            {
-                "boost_factor": 3,
-                "filter": {
-                    term:{
-                        "name.last":"banon"
-                    }
-                }
-            },
-            {
-                "boost_factor": 3
-            },
-            {
-                "boost_factor": 3
-            }
-        ],
-        "boost" : 3,
-        "score_mode" : "avg",
-        "max_boost" : 10
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/function-score-query-causing-NPE.json b/core/src/test/java/org/elasticsearch/index/query/function-score-query-causing-NPE.json
deleted file mode 100644
index 283682b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/function-score-query-causing-NPE.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-    "function_score": {
-      "script_score": {
-        "script": "_index['text']['foo'].tf()"
-      },
-      "weight": 2
-    }
-}
-
diff --git a/core/src/test/java/org/elasticsearch/index/query/fuzzy-with-fields.json b/core/src/test/java/org/elasticsearch/index/query/fuzzy-with-fields.json
deleted file mode 100644
index 7636496..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/fuzzy-with-fields.json
+++ /dev/null
@@ -1,10 +0,0 @@
-{
-    "fuzzy":{
-        "name.first":{
-            "value":"sh",
-            "fuzziness": "AUTO",
-            "prefix_length":1,
-            "boost":2.0
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/fuzzy-with-fields2.json b/core/src/test/java/org/elasticsearch/index/query/fuzzy-with-fields2.json
deleted file mode 100644
index 095ecc6..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/fuzzy-with-fields2.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-    "fuzzy":{
-        "age":{
-            "value":12,
-            "fuzziness":5,
-            "boost":2.0
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/fuzzy.json b/core/src/test/java/org/elasticsearch/index/query/fuzzy.json
deleted file mode 100644
index 27d8dee..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/fuzzy.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{
-    "fuzzy":{
-        "name.first":"sh"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/geoShape-filter.json b/core/src/test/java/org/elasticsearch/index/query/geoShape-filter.json
deleted file mode 100644
index a4392ae..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geoShape-filter.json
+++ /dev/null
@@ -1,21 +0,0 @@
-{
-    "filtered" : {
-        "query" : {
-            "match_all" : {}
-        },
-        "filter" : {
-            "geo_shape" : {
-                "country" : {
-                    "shape" : {
-                        "type" : "Envelope",
-                        "coordinates" : [
-                            [-45, 45],
-                            [45, -45]
-                        ]
-                    },
-                    "relation" : "intersects"
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/geoShape-query.json b/core/src/test/java/org/elasticsearch/index/query/geoShape-query.json
deleted file mode 100644
index e0af827..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geoShape-query.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    "geo_shape" : {
-        "country" : {
-            "shape" : {
-                "type" : "Envelope",
-                "coordinates" : [
-                    [-45, 45],
-                    [45, -45]
-                ]
-            },
-            "relation" : "intersects"
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox-named.json b/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox-named.json
deleted file mode 100644
index 6db6d5a..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox-named.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_bounding_box":{
-                "location":{
-                    "top_left":[-70, 40],
-                    "bottom_right":[-80, 30]
-                },
-                "_name":"test"
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox1.json b/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox1.json
deleted file mode 100644
index 8d04915..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox1.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_bounding_box":{
-                "location":{
-                    "top_left":[-70, 40],
-                    "bottom_right":[-80, 30]
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox2.json b/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox2.json
deleted file mode 100644
index 6321654..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox2.json
+++ /dev/null
@@ -1,21 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_bounding_box":{
-                "location":{
-                    "top_left":{
-                        "lat":40,
-                        "lon":-70
-                    },
-                    "bottom_right":{
-                        "lat":30,
-                        "lon":-80
-                    }
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox3.json b/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox3.json
deleted file mode 100644
index 0899960..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox3.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_bounding_box":{
-                "location":{
-                    "top_left":"40, -70",
-                    "bottom_right":"30, -80"
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox4.json b/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox4.json
deleted file mode 100644
index 170a02d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox4.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_bounding_box":{
-                "location":{
-                    "top_left":"drn5x1g8cu2y",
-                    "bottom_right":"30, -80"
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox5.json b/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox5.json
deleted file mode 100644
index 347a463..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox5.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_bounding_box":{
-                "location":{
-                    "top_right":"40, -80",
-                    "bottom_left":"30, -70"
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox6.json b/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox6.json
deleted file mode 100644
index 96ccbd0..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_boundingbox6.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_bounding_box":{
-                "location":{
-                    "right": -80,
-                    "top": 40,
-                    "left": -70,
-                    "bottom": 30
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance-named.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance-named.json
deleted file mode 100644
index a3e0be9..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance-named.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":"12mi",
-                "location":{
-                    "lat":40,
-                    "lon":-70
-                },
-                "_name":"test"
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance1.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance1.json
deleted file mode 100644
index cf3b0ab..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance1.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":"12mi",
-                "location":{
-                    "lat":40,
-                    "lon":-70
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance10.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance10.json
deleted file mode 100644
index 067b39e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance10.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":19.312128,
-                "unit":"km",
-                "location":{
-                    "lat":40,
-                    "lon":-70
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance11.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance11.json
deleted file mode 100644
index 008d5b5..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance11.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":"19.312128km",
-                "location":{
-                    "lat":40,
-                    "lon":-70
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance12.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance12.json
deleted file mode 100644
index 8769223..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance12.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":"12mi",
-                "unit":"km",
-                "location":{
-                    "lat":40,
-                    "lon":-70
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance2.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance2.json
deleted file mode 100644
index 3283867..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance2.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":"12mi",
-                "location":[-70, 40]
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance3.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance3.json
deleted file mode 100644
index 193f234..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance3.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":"12mi",
-                "location":"40, -70"
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance4.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance4.json
deleted file mode 100644
index 56a7409..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance4.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":"12mi",
-                "location":"drn5x1g8cu2y"
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance5.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance5.json
deleted file mode 100644
index bea9a3d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance5.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":12,
-                "unit":"mi",
-                "location":{
-                    "lat":40,
-                    "lon":-70
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance6.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance6.json
deleted file mode 100644
index 4afa128..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance6.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":"12",
-                "unit":"mi",
-                "location":{
-                    "lat":40,
-                    "lon":-70
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance7.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance7.json
deleted file mode 100644
index 7fcf8bd..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance7.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":"19.312128",
-                "location":{
-                    "lat":40,
-                    "lon":-70
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance8.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance8.json
deleted file mode 100644
index 3bafd16..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance8.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":19.312128,
-                "location":{
-                    "lat":40,
-                    "lon":-70
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_distance9.json b/core/src/test/java/org/elasticsearch/index/query/geo_distance9.json
deleted file mode 100644
index e6c8f12..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_distance9.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_distance":{
-                "distance":"19.312128",
-                "unit":"km",
-                "location":{
-                    "lat":40,
-                    "lon":-70
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_polygon-named.json b/core/src/test/java/org/elasticsearch/index/query/geo_polygon-named.json
deleted file mode 100644
index 91256c1..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_polygon-named.json
+++ /dev/null
@@ -1,19 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_polygon":{
-                "location":{
-                    "points":[
-                        [-70, 40],
-                        [-80, 30],
-                        [-90, 20]
-                    ]
-                },
-                "_name":"test"
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_polygon1.json b/core/src/test/java/org/elasticsearch/index/query/geo_polygon1.json
deleted file mode 100644
index 99ac329..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_polygon1.json
+++ /dev/null
@@ -1,18 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_polygon":{
-                "location":{
-                    "points":[
-                        [-70, 40],
-                        [-80, 30],
-                        [-90, 20]
-                    ]
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_polygon2.json b/core/src/test/java/org/elasticsearch/index/query/geo_polygon2.json
deleted file mode 100644
index 588b22f..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_polygon2.json
+++ /dev/null
@@ -1,27 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_polygon":{
-                "location":{
-                    "points":[
-                        {
-                            "lat":40,
-                            "lon":-70
-                        },
-                        {
-                            "lat":30,
-                            "lon":-80
-                        },
-                        {
-                            "lat":20,
-                            "lon":-90
-                        }
-                    ]
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_polygon3.json b/core/src/test/java/org/elasticsearch/index/query/geo_polygon3.json
deleted file mode 100644
index d6d905b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_polygon3.json
+++ /dev/null
@@ -1,18 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_polygon":{
-                "location":{
-                    "points":[
-                        "40, -70",
-                        "30, -80",
-                        "20, -90"
-                    ]
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_polygon4.json b/core/src/test/java/org/elasticsearch/index/query/geo_polygon4.json
deleted file mode 100644
index ae9608d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_polygon4.json
+++ /dev/null
@@ -1,18 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "match_all":{}
-        },
-        "filter":{
-            "geo_polygon":{
-                "location":{
-                    "points":[
-                        "drn5x1g8cu2y",
-                        "30, -80",
-                        "20, -90"
-                    ]
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_1.json b/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_1.json
deleted file mode 100644
index e079d64..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_1.json
+++ /dev/null
@@ -1,20 +0,0 @@
-{
-    "filtered": {
-        "query": {
-            "match_all": {}
-        },
-        "filter": {
-            "geo_polygon": {
-                "location": {
-                    "points": {
-                        "points": [
-                            [-70, 40],
-                            [-80, 30],
-                            [-90, 20]
-                        ]
-                    }
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_2.json b/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_2.json
deleted file mode 100644
index 0955c26..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_2.json
+++ /dev/null
@@ -1,22 +0,0 @@
-{
-    "filtered": {
-        "query": {
-            "match_all": {}
-        },
-        "filter": {
-            "geo_polygon": {
-                "location": {
-                    "points": [
-                        [-70, 40],
-                        [-80, 30],
-                        [-90, 20]
-                    ],
-                    "something_else": {
-
-                    }
-
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_3.json b/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_3.json
deleted file mode 100644
index 0ac2a7b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_3.json
+++ /dev/null
@@ -1,12 +0,0 @@
-{
-    "filtered": {
-        "query": {
-            "match_all": {}
-        },
-        "filter": {
-            "geo_polygon": {
-                "location": ["WRONG"]
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_4.json b/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_4.json
deleted file mode 100644
index 51f6ad0..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_4.json
+++ /dev/null
@@ -1,19 +0,0 @@
-{
-    "filtered": {
-        "query": {
-            "match_all": {}
-        },
-        "filter": {
-            "geo_polygon": {
-                "location": {
-                    "points": [
-                        [-70, 40],
-                        [-80, 30],
-                        [-90, 20]
-                    ]
-                },
-                "bla": true
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_5.json b/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_5.json
deleted file mode 100644
index 6f058f5..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/geo_polygon_exception_5.json
+++ /dev/null
@@ -1,19 +0,0 @@
-{
-    "filtered": {
-        "query": {
-            "match_all": {}
-        },
-        "filter": {
-            "geo_polygon": {
-                "location": {
-                    "points": [
-                        [-70, 40],
-                        [-80, 30],
-                        [-90, 20]
-                    ]
-                },
-                "bla": ["array"]
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/has-child-in-and-filter-cached.json b/core/src/test/java/org/elasticsearch/index/query/has-child-in-and-filter-cached.json
deleted file mode 100644
index 4b055cb..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/has-child-in-and-filter-cached.json
+++ /dev/null
@@ -1,19 +0,0 @@
-{
-  "filtered":{
-    "filter":{
-      "and" : {
-        "filters" : [
-          {
-            "has_child" : {
-              "type" : "child",
-              "query" : {
-                "match_all" : {}
-              }
-            }
-          }
-        ],
-        "_cache" : true
-      }
-    }
-  }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/has-child-with-inner-hits.json b/core/src/test/java/org/elasticsearch/index/query/has-child-with-inner-hits.json
deleted file mode 100644
index 34c9dc4..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/has-child-with-inner-hits.json
+++ /dev/null
@@ -1,31 +0,0 @@
-{
-  "has_child" : {
-    "query" : {
-      "range" : {
-        "mapped_string" : {
-          "from" : "agJhRET",
-          "to" : "zvqIq",
-          "include_lower" : true,
-          "include_upper" : true,
-          "boost" : 1.0
-        }
-      }
-    },
-    "child_type" : "child",
-    "score_type" : "avg",
-    "min_children" : 883170873,
-    "max_children" : 1217235442,
-    "short_circuit_cutoff" : 340606183,
-    "boost" : 2.0,
-    "_name" : "WNzYMJKRwePuRBh",
-    "inner_hits" : {
-      "name" : "inner_hits_name",
-      "size" : 100,
-      "sort" : [ {
-        "mapped_string" : {
-          "order" : "asc"
-        }
-      } ]
-    }
-  }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/has-child.json b/core/src/test/java/org/elasticsearch/index/query/has-child.json
deleted file mode 100644
index c87ac17..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/has-child.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-  "filtered":{
-    "filter":{
-      "has_child" : {
-        "type" : "child",
-        "query" : {
-          "match_all" : {}
-        },
-        "_cache" : true
-      }
-    }
-  }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/mapping.json b/core/src/test/java/org/elasticsearch/index/query/mapping.json
deleted file mode 100644
index 3939249..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/mapping.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "person":{
-        "properties":{
-            "location":{
-                "type":"geo_point"
-            },
-            "country" : {
-                "type" : "geo_shape"
-            },
-            "born":{
-                "type":"date"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/match-query-bad-type.json b/core/src/test/java/org/elasticsearch/index/query/match-query-bad-type.json
deleted file mode 100644
index 47d1227..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/match-query-bad-type.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "match" : {
-        "message" : {
-            "query" : "this is a test",
-            "type" : "doesNotExist"
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/match-with-fuzzy-transpositions.json b/core/src/test/java/org/elasticsearch/index/query/match-with-fuzzy-transpositions.json
deleted file mode 100644
index 5f4fe8b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/match-with-fuzzy-transpositions.json
+++ /dev/null
@@ -1 +0,0 @@
-{ "match": { "body": { "query": "fuzzy", "fuzziness": 1, "fuzzy_transpositions": true }} }
diff --git a/core/src/test/java/org/elasticsearch/index/query/match-without-fuzzy-transpositions.json b/core/src/test/java/org/elasticsearch/index/query/match-without-fuzzy-transpositions.json
deleted file mode 100644
index 06c77aa..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/match-without-fuzzy-transpositions.json
+++ /dev/null
@@ -1 +0,0 @@
-{ "match": { "body": { "query": "fuzzy", "fuzziness": 1, "fuzzy_transpositions": false }} }
diff --git a/core/src/test/java/org/elasticsearch/index/query/matchAll.json b/core/src/test/java/org/elasticsearch/index/query/matchAll.json
deleted file mode 100644
index 3325646..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/matchAll.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{
-    match_all:{
-        boost:1.2
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/match_all_empty1.json b/core/src/test/java/org/elasticsearch/index/query/match_all_empty1.json
deleted file mode 100644
index 6dd141f..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/match_all_empty1.json
+++ /dev/null
@@ -1,3 +0,0 @@
-{
-    "match_all": {}
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/match_all_empty2.json b/core/src/test/java/org/elasticsearch/index/query/match_all_empty2.json
deleted file mode 100644
index a0549df..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/match_all_empty2.json
+++ /dev/null
@@ -1,3 +0,0 @@
-{
-    "match_all": []
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/mlt-items.json b/core/src/test/java/org/elasticsearch/index/query/mlt-items.json
deleted file mode 100644
index d7839ac..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/mlt-items.json
+++ /dev/null
@@ -1,22 +0,0 @@
-{
-    "more_like_this" : {
-        "fields" : ["name.first", "name.last"],
-        "like_text": "Apache Lucene",
-        "like" : [
-        {
-            "_index" : "test",
-            "_type" : "person",
-            "_id" : "1"
-        },
-        {
-            "_index" : "test",
-            "_type" : "person",
-            "_id" : "2"
-        }
-        ],
-        "ids" : ["3", "4"],
-        "include" : true,
-        "min_term_freq" : 1,
-        "max_query_terms" : 12
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/mlt.json b/core/src/test/java/org/elasticsearch/index/query/mlt.json
deleted file mode 100644
index d3d98be..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/mlt.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "more_like_this" : {
-        "fields" : ["name.first", "name.last"],
-        "like_text" : "something",
-        "min_term_freq" : 1,
-        "max_query_terms" : 12
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/multiMatch-query-bad-type.json b/core/src/test/java/org/elasticsearch/index/query/multiMatch-query-bad-type.json
deleted file mode 100644
index 9c3b751..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/multiMatch-query-bad-type.json
+++ /dev/null
@@ -1,7 +0,0 @@
-{
-    "multi_match": {
-        "query": "foo bar",
-        "fields": [ "myField", "otherField" ],
-        "type":"doesNotExist"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/multiMatch-query-fields-as-string.json b/core/src/test/java/org/elasticsearch/index/query/multiMatch-query-fields-as-string.json
deleted file mode 100644
index d29211d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/multiMatch-query-fields-as-string.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{
-    "multi_match": {
-        "query": "foo bar",
-        "fields": "myField"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/multiMatch-query-simple.json b/core/src/test/java/org/elasticsearch/index/query/multiMatch-query-simple.json
deleted file mode 100644
index 904ba0e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/multiMatch-query-simple.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{
-    "multi_match": {
-        "query": "foo bar",
-        "fields": [ "myField", "otherField" ]
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/not-filter.json b/core/src/test/java/org/elasticsearch/index/query/not-filter.json
deleted file mode 100644
index 42c48d8..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/not-filter.json
+++ /dev/null
@@ -1,18 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "not":{
-                "filter":{
-                    "term":{
-                        "name.first":"shay1"
-                    }
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/not-filter2.json b/core/src/test/java/org/elasticsearch/index/query/not-filter2.json
deleted file mode 100644
index 6defaff..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/not-filter2.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "not":{
-                "term":{
-                    "name.first":"shay1"
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/not-filter3.json b/core/src/test/java/org/elasticsearch/index/query/not-filter3.json
deleted file mode 100644
index ab61335..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/not-filter3.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-    "filtered":{
-        "filter":{
-            "not":{
-                "term":{
-                    "name.first":"shay1"
-                }
-            }
-        },
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/or-filter.json b/core/src/test/java/org/elasticsearch/index/query/or-filter.json
deleted file mode 100644
index b1e73fa..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/or-filter.json
+++ /dev/null
@@ -1,25 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "or":{
-                "filters":[
-                    {
-                        "term":{
-                            "name.first":"shay1"
-                        }
-                    },
-                    {
-                        "term":{
-                            "name.first":"shay4"
-                        }
-                    }
-                ]
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/or-filter2.json b/core/src/test/java/org/elasticsearch/index/query/or-filter2.json
deleted file mode 100644
index 2c15e9a..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/or-filter2.json
+++ /dev/null
@@ -1,23 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "or":[
-                {
-                    "term":{
-                        "name.first":"shay1"
-                    }
-                },
-                {
-                    "term":{
-                        "name.first":"shay4"
-                    }
-                }
-            ]
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java b/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java
index 2311f1c..dbbc358 100644
--- a/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java
+++ b/core/src/test/java/org/elasticsearch/index/query/plugin/DummyQueryParserPlugin.java
@@ -25,7 +25,10 @@ import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Weight;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.QueryBuilder;
+import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParser;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.indices.IndicesModule;
 import org.elasticsearch.plugins.Plugin;
 
@@ -47,41 +50,24 @@ public class DummyQueryParserPlugin extends Plugin {
         module.registerQueryParser(DummyQueryParser.class);
     }
 
-    public static class DummyQueryBuilder extends AbstractQueryBuilder<DummyQueryBuilder> {
-        private static final String NAME = "dummy";
-
+    public static class DummyQueryBuilder extends QueryBuilder {
         @Override
         protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-            builder.startObject(NAME).endObject();
-        }
-
-        @Override
-        protected Query doToQuery(QueryShardContext context) throws IOException {
-            return new DummyQuery(context.isFilter());
-        }
-
-        @Override
-        public String getWriteableName() {
-            return NAME;
+            builder.startObject("dummy").endObject();
         }
     }
 
-    public static class DummyQueryParser extends BaseQueryParser {
+    public static class DummyQueryParser implements QueryParser {
         @Override
         public String[] names() {
-            return new String[]{DummyQueryBuilder.NAME};
+            return new String[]{"dummy"};
         }
 
         @Override
-        public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
+        public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
             XContentParser.Token token = parseContext.parser().nextToken();
             assert token == XContentParser.Token.END_OBJECT;
-            return new DummyQueryBuilder();
-        }
-
-        @Override
-        public DummyQueryBuilder getBuilderPrototype() {
-            return new DummyQueryBuilder();
+            return new DummyQuery(parseContext.isFilter());
         }
     }
 
diff --git a/core/src/test/java/org/elasticsearch/index/query/prefix-boost.json b/core/src/test/java/org/elasticsearch/index/query/prefix-boost.json
deleted file mode 100644
index 4da623a..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/prefix-boost.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "prefix":{
-        "name.first":{
-            "value":"sh",
-            "boost":1.2
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/prefix-filter-named.json b/core/src/test/java/org/elasticsearch/index/query/prefix-filter-named.json
deleted file mode 100644
index de01701..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/prefix-filter-named.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "prefix":{
-                "name.first":"sh",
-                "_name":"test"
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/prefix-filter.json b/core/src/test/java/org/elasticsearch/index/query/prefix-filter.json
deleted file mode 100644
index 1f2e42e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/prefix-filter.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "prefix":{
-                "name.first":"sh"
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/prefix-with-boost.json b/core/src/test/java/org/elasticsearch/index/query/prefix-with-boost.json
deleted file mode 100644
index 83e56cb..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/prefix-with-boost.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    prefix:{
-        "name.first":{
-            prefix:"sh",
-            boost:2.0
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/prefix.json b/core/src/test/java/org/elasticsearch/index/query/prefix.json
deleted file mode 100644
index 49f5261..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/prefix.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{
-    prefix:{
-        "name.first":"sh"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/query-fields-match.json b/core/src/test/java/org/elasticsearch/index/query/query-fields-match.json
deleted file mode 100644
index c15cdf3..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/query-fields-match.json
+++ /dev/null
@@ -1,7 +0,0 @@
-{
-    query_string:{
-        fields:["name.*"],
-        use_dis_max:false,
-        query:"test"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/query-fields1.json b/core/src/test/java/org/elasticsearch/index/query/query-fields1.json
deleted file mode 100644
index 84abcaa..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/query-fields1.json
+++ /dev/null
@@ -1,7 +0,0 @@
-{
-    query_string:{
-        fields:["content", "name"],
-        use_dis_max:false,
-        query:"test"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/query-fields2.json b/core/src/test/java/org/elasticsearch/index/query/query-fields2.json
deleted file mode 100644
index ab39c87..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/query-fields2.json
+++ /dev/null
@@ -1,7 +0,0 @@
-{
-    query_string:{
-        fields:["content", "name"],
-        use_dis_max:true,
-        query:"test"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/query-fields3.json b/core/src/test/java/org/elasticsearch/index/query/query-fields3.json
deleted file mode 100644
index 8114c1b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/query-fields3.json
+++ /dev/null
@@ -1,7 +0,0 @@
-{
-    query_string:{
-        fields:["content^2.2", "name"],
-        use_dis_max:true,
-        query:"test"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/query-filter.json b/core/src/test/java/org/elasticsearch/index/query/query-filter.json
deleted file mode 100644
index dee136d..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/query-filter.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-    filtered:{
-        query:{
-            term:{
-                "name.first":"shay"
-            }
-        },
-        filter:{
-            query:{
-                term:{
-                    "name.last":"banon"
-                }
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/query-regexp-max-determinized-states.json b/core/src/test/java/org/elasticsearch/index/query/query-regexp-max-determinized-states.json
deleted file mode 100644
index 023b90e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/query-regexp-max-determinized-states.json
+++ /dev/null
@@ -1,7 +0,0 @@
-{
-    query_string: {
-        default_field: "content",
-        query:"/foo*bar/",
-	max_determinized_states: 5000
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/query-regexp-too-many-determinized-states.json b/core/src/test/java/org/elasticsearch/index/query/query-regexp-too-many-determinized-states.json
deleted file mode 100644
index 0d2d41a..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/query-regexp-too-many-determinized-states.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{
-    query_string: {
-        default_field: "content",
-        query: "/[ac]*a[ac]{50,200}/"
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/query-timezone-incorrect.json b/core/src/test/java/org/elasticsearch/index/query/query-timezone-incorrect.json
deleted file mode 100644
index 3bffb0f..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/query-timezone-incorrect.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{
-    "query_string":{
-        "time_zone":"This timezone does not exist",
-        "query":"date:[2012 TO 2014]"
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/query-timezone.json b/core/src/test/java/org/elasticsearch/index/query/query-timezone.json
deleted file mode 100644
index e2fcc0e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/query-timezone.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{
-    "query_string":{
-        "time_zone":"Europe/Paris",
-        "query":"date:[2012 TO 2014]"
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/query.json b/core/src/test/java/org/elasticsearch/index/query/query.json
deleted file mode 100644
index f07a0d8..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/query.json
+++ /dev/null
@@ -1,7 +0,0 @@
-{
-    query_string:{
-        default_field:"content",
-        phrase_slop:1,
-        query:"test"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/query2.json b/core/src/test/java/org/elasticsearch/index/query/query2.json
deleted file mode 100644
index 410e05c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/query2.json
+++ /dev/null
@@ -1,6 +0,0 @@
-{
-    query_string:{
-        default_field:"age",
-        query:"12~0.2"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/range-filter-named.json b/core/src/test/java/org/elasticsearch/index/query/range-filter-named.json
deleted file mode 100644
index 1b50177..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/range-filter-named.json
+++ /dev/null
@@ -1,20 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "range":{
-                "age":{
-                    "from":"23",
-                    "to":"54",
-                    "include_lower":true,
-                    "include_upper":false
-                },
-                "_name":"test"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/range-filter.json b/core/src/test/java/org/elasticsearch/index/query/range-filter.json
deleted file mode 100644
index 3842e0b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/range-filter.json
+++ /dev/null
@@ -1,19 +0,0 @@
-{
-    filtered:{
-        query:{
-            term:{
-                "name.first":"shay"
-            }
-        },
-        filter:{
-            range:{
-                age:{
-                    from:"23",
-                    to:"54",
-                    include_lower:true,
-                    include_upper:false
-                }
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/range.json b/core/src/test/java/org/elasticsearch/index/query/range.json
deleted file mode 100644
index cc2363f..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/range.json
+++ /dev/null
@@ -1,10 +0,0 @@
-{
-    range:{
-        age:{
-            from:"23",
-            to:"54",
-            include_lower:true,
-            include_upper:false
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/range2.json b/core/src/test/java/org/elasticsearch/index/query/range2.json
deleted file mode 100644
index c116b3c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/range2.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    range:{
-        age:{
-            gte:"23",
-            lt:"54"
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/regexp-boost.json b/core/src/test/java/org/elasticsearch/index/query/regexp-boost.json
deleted file mode 100644
index ed8699b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/regexp-boost.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "regexp":{
-        "name.first":{
-            "value":"sh",
-            "boost":1.2
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/regexp-filter-flags-named-cached.json b/core/src/test/java/org/elasticsearch/index/query/regexp-filter-flags-named-cached.json
deleted file mode 100644
index 112f8fb..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/regexp-filter-flags-named-cached.json
+++ /dev/null
@@ -1,20 +0,0 @@
-{
-    "filtered": {
-        "query": {
-            "term": {
-                "name.first": "shay"
-            }
-        },
-        "filter": {
-            "regexp":{
-                "name.first" : {
-                    "value" : "s.*y",
-                    "flags" : "INTERSECTION|COMPLEMENT|EMPTY"
-                },
-                "_name":"test",
-                "_cache" : true,
-                "_cache_key" : "key"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/regexp-filter-flags.json b/core/src/test/java/org/elasticsearch/index/query/regexp-filter-flags.json
deleted file mode 100644
index a5d7307..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/regexp-filter-flags.json
+++ /dev/null
@@ -1,18 +0,0 @@
-{
-    "filtered": {
-        "query": {
-            "term": {
-                "name.first": "shay"
-            }
-        },
-        "filter": {
-            "regexp":{
-                "name.first" : {
-                    "value" : "s.*y",
-                    "flags" : "INTERSECTION|COMPLEMENT|EMPTY"
-                },
-                "_name":"test"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/regexp-filter-max-determinized-states.json b/core/src/test/java/org/elasticsearch/index/query/regexp-filter-max-determinized-states.json
deleted file mode 100644
index 2672ac6..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/regexp-filter-max-determinized-states.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-    "filtered": {
-        "query": {
-            "term": {
-                "name.first": "shay"
-            }
-        },
-        "filter": {
-            "regexp": {
-                "name.first": {
-		    "value": "s.*y",
-		    "max_determinized_states": 6000
-		}
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/regexp-filter-named.json b/core/src/test/java/org/elasticsearch/index/query/regexp-filter-named.json
deleted file mode 100644
index ac96b3e..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/regexp-filter-named.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "filtered": {
-        "query": {
-            "term": {
-                "name.first": "shay"
-            }
-        },
-        "filter": {
-            "regexp":{
-                "name.first" : "s.*y",
-                "_name" : "test"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/regexp-filter.json b/core/src/test/java/org/elasticsearch/index/query/regexp-filter.json
deleted file mode 100644
index d7c7bfd..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/regexp-filter.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    "filtered": {
-        "query": {
-            "term": {
-                "name.first": "shay"
-            }
-        },
-        "filter": {
-            "regexp":{
-                "name.first" : "s.*y"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/regexp-max-determinized-states.json b/core/src/test/java/org/elasticsearch/index/query/regexp-max-determinized-states.json
deleted file mode 100644
index df2f5cc..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/regexp-max-determinized-states.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "regexp": {
-        "name.first": {
-            "value": "s.*y",
-            "max_determinized_states": 5000
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/regexp.json b/core/src/test/java/org/elasticsearch/index/query/regexp.json
deleted file mode 100644
index 6c3d694..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/regexp.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{
-    "regexp":{
-        "name.first": "s.*y"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-fuzzy-range.json b/core/src/test/java/org/elasticsearch/index/query/span-multi-term-fuzzy-range.json
deleted file mode 100644
index d9ca05b..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-fuzzy-range.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-	"span_multi":{
-		"match":{
-			"fuzzy":{
-        		"age":{
-		            "value":12,
-		            "fuzziness":5,
-		            "boost":2.0
-		        }
-    		}
-    	}
-	}
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-fuzzy-term.json b/core/src/test/java/org/elasticsearch/index/query/span-multi-term-fuzzy-term.json
deleted file mode 100644
index edb58e3..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-fuzzy-term.json
+++ /dev/null
@@ -1,12 +0,0 @@
-{
-	"span_multi":{
-		"match":{
-			"fuzzy" : {
-				"user" : {
-	                "value" : "ki",
-	                "boost" : 1.08
-	            }
-	    	}
-		}
-	}
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-prefix.json b/core/src/test/java/org/elasticsearch/index/query/span-multi-term-prefix.json
deleted file mode 100644
index 62918d6..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-prefix.json
+++ /dev/null
@@ -1,7 +0,0 @@
-{
-	"span_multi":{
-		"match":{
-			"prefix" : { "user" :  { "value" : "ki", "boost" : 1.08 } }
-		}
-	}
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-range-numeric.json b/core/src/test/java/org/elasticsearch/index/query/span-multi-term-range-numeric.json
deleted file mode 100644
index d9db8a4..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-range-numeric.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-	"span_multi":{
-		"match":{
-			"range" : {
-     		   "age" : { 
-            		"from" : 10, 
-            		"to" : 20, 
-            		"include_lower" : true, 
-            		"include_upper": false, 
-            		"boost" : 2.0
-       			}
-    		}
-		}
-	}
-}
-
diff --git a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-range-term.json b/core/src/test/java/org/elasticsearch/index/query/span-multi-term-range-term.json
deleted file mode 100644
index 8c4da31..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-range-term.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-	"span_multi":{
-		"match":{
-			"range" : {
-     		   "user" : { 
-            		"from" : "alice", 
-            		"to" : "bob", 
-            		"include_lower" : true, 
-            		"include_upper": false, 
-            		"boost" : 2.0
-       			}
-    		}
-		}
-	}
-}
-
diff --git a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-wildcard.json b/core/src/test/java/org/elasticsearch/index/query/span-multi-term-wildcard.json
deleted file mode 100644
index a2eaeb7..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/span-multi-term-wildcard.json
+++ /dev/null
@@ -1,7 +0,0 @@
-{
-	"span_multi":{
-		"match":{
-			"wildcard" : { "user" : {"value": "ki*y" , "boost" : 1.08}}
-		}
-	}
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/spanContaining.json b/core/src/test/java/org/elasticsearch/index/query/spanContaining.json
deleted file mode 100644
index 13f91d8..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/spanContaining.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    span_containing:{
-        big:{
-            span_term:{
-                age:34
-            }
-        },
-        little:{
-            span_term:{
-                age:35
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/spanFieldMaskingTerm.json b/core/src/test/java/org/elasticsearch/index/query/spanFieldMaskingTerm.json
deleted file mode 100644
index 9849c10..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/spanFieldMaskingTerm.json
+++ /dev/null
@@ -1,29 +0,0 @@
-{
-   span_near:{
-      clauses:[
-         {
-            span_term:{
-               age:34
-            }
-         },
-         {
-            span_term:{
-               age:35
-            }
-         },
-         {
-           field_masking_span:{
-              query:{
-                 span_term:{
-                    age_1 : 36
-                 }
-              },
-              field:"age"
-           }
-         }
-      ],
-      slop:12,
-      in_order:false,
-      collect_payloads:false
-   }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/spanFirst.json b/core/src/test/java/org/elasticsearch/index/query/spanFirst.json
deleted file mode 100644
index 9972c76..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/spanFirst.json
+++ /dev/null
@@ -1,10 +0,0 @@
-{
-    span_first:{
-        match:{
-            span_term:{
-                age:34
-            }
-        },
-        end:12
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/spanNear.json b/core/src/test/java/org/elasticsearch/index/query/spanNear.json
deleted file mode 100644
index ce17063..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/spanNear.json
+++ /dev/null
@@ -1,24 +0,0 @@
-{
-    span_near:{
-        clauses:[
-            {
-                span_term:{
-                    age:34
-                }
-            },
-            {
-                span_term:{
-                    age:35
-                }
-            },
-            {
-                span_term:{
-                    age:36
-                }
-            }
-        ],
-        slop:12,
-        in_order:false,
-        collect_payloads:false
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/spanNot.json b/core/src/test/java/org/elasticsearch/index/query/spanNot.json
deleted file mode 100644
index c90de33..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/spanNot.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    span_not:{
-        include:{
-            span_term:{
-                age:34
-            }
-        },
-        exclude:{
-            span_term:{
-                age:35
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/spanOr.json b/core/src/test/java/org/elasticsearch/index/query/spanOr.json
deleted file mode 100644
index 06c5262..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/spanOr.json
+++ /dev/null
@@ -1,21 +0,0 @@
-{
-    span_or:{
-        clauses:[
-            {
-                span_term:{
-                    age:34
-                }
-            },
-            {
-                span_term:{
-                    age:35
-                }
-            },
-            {
-                span_term:{
-                    age:36
-                }
-            }
-        ]
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/spanOr2.json b/core/src/test/java/org/elasticsearch/index/query/spanOr2.json
deleted file mode 100644
index b64ce1c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/spanOr2.json
+++ /dev/null
@@ -1,30 +0,0 @@
-{
-    "span_or":{
-        "clauses":[
-            {
-                "span_term":{
-                    "age":{
-                        "value":34,
-                        "boost":1.0
-                    }
-                }
-            },
-            {
-                "span_term":{
-                    "age":{
-                        "value":35,
-                        "boost":1.0
-                    }
-                }
-            },
-            {
-                "span_term":{
-                    "age":{
-                        "value":36,
-                        "boost":1.0
-                    }
-                }
-            }
-        ]
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/spanTerm.json b/core/src/test/java/org/elasticsearch/index/query/spanTerm.json
deleted file mode 100644
index 0186593..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/spanTerm.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{
-    span_term:{
-        age:34
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/spanWithin.json b/core/src/test/java/org/elasticsearch/index/query/spanWithin.json
deleted file mode 100644
index 7cf767c..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/spanWithin.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    span_within:{
-        big:{
-            span_term:{
-                age:34
-            }
-        },
-        little:{
-            span_term:{
-                age:35
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/starColonStar.json b/core/src/test/java/org/elasticsearch/index/query/starColonStar.json
deleted file mode 100644
index c769ca0..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/starColonStar.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{
-    "query_string": {
-        "query": "*:*"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/support/QueryInnerHitsTests.java b/core/src/test/java/org/elasticsearch/index/query/support/QueryInnerHitsTests.java
deleted file mode 100644
index 2c4e317..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/support/QueryInnerHitsTests.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.query.support;
-
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-import org.elasticsearch.test.ESTestCase;
-
-import java.io.IOException;
-
-public class QueryInnerHitsTests extends ESTestCase {
-
-    public void testSerialize() throws IOException {
-        copyAndAssert(new QueryInnerHits());
-        copyAndAssert(new QueryInnerHits("foo", new InnerHitsBuilder.InnerHit()));
-        copyAndAssert(new QueryInnerHits("foo", null));
-        copyAndAssert(new QueryInnerHits("foo", new InnerHitsBuilder.InnerHit().setSize(randomIntBetween(0, 100))));
-    }
-
-    public void testToXContent() throws IOException {
-        assertJson("{\"inner_hits\":{}}", new QueryInnerHits());
-        assertJson("{\"inner_hits\":{\"name\":\"foo\"}}", new QueryInnerHits("foo", new InnerHitsBuilder.InnerHit()));
-        assertJson("{\"inner_hits\":{\"name\":\"bar\"}}", new QueryInnerHits("bar", null));
-        assertJson("{\"inner_hits\":{\"name\":\"foo\",\"size\":42}}", new QueryInnerHits("foo", new InnerHitsBuilder.InnerHit().setSize(42)));
-        assertJson("{\"inner_hits\":{\"name\":\"boom\",\"from\":66,\"size\":666}}", new QueryInnerHits("boom", new InnerHitsBuilder.InnerHit().setFrom(66).setSize(666)));
-    }
-
-    private void assertJson(String expected, QueryInnerHits hits) throws IOException {
-        QueryInnerHits queryInnerHits = copyAndAssert(hits);
-        String actual;
-        if (randomBoolean()) {
-            actual = oneLineJSON(queryInnerHits);
-        } else {
-            actual = oneLineJSON(hits);
-        }
-        assertEquals(expected, actual);
-        XContentParser parser = hits.getXcontentParser();
-        assertEquals(XContentParser.Token.START_OBJECT, parser.nextToken());
-        QueryInnerHits other = copyAndAssert(new QueryInnerHits(parser));
-        assertEquals(expected, oneLineJSON(other));
-    }
-
-    public QueryInnerHits copyAndAssert(QueryInnerHits hits) throws IOException {
-        BytesStreamOutput out = new BytesStreamOutput();
-        hits.writeTo(out);
-        QueryInnerHits copy = randomBoolean() ? hits.readFrom(StreamInput.wrap(out.bytes())) : new QueryInnerHits(StreamInput.wrap(out.bytes()));
-        assertEquals(copy.toString() + " vs. " + hits.toString(), copy, hits);
-        return copy;
-    }
-
-    private String oneLineJSON(QueryInnerHits hits) throws IOException {
-        XContentBuilder builder = XContentFactory.jsonBuilder();
-        builder.startObject();
-        hits.toXContent(builder, ToXContent.EMPTY_PARAMS);
-        builder.endObject();
-        return builder.string().trim();
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/term-array-invalid.json b/core/src/test/java/org/elasticsearch/index/query/term-array-invalid.json
deleted file mode 100644
index a198bc2..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/term-array-invalid.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{
-    "term": {
-        "age": [34, 35]
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/query/term-filter-broken-multi-terms-2.json b/core/src/test/java/org/elasticsearch/index/query/term-filter-broken-multi-terms-2.json
deleted file mode 100644
index b71de53..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/term-filter-broken-multi-terms-2.json
+++ /dev/null
@@ -1,10 +0,0 @@
-{
-  "filtered": {
-    "filter": {
-      "term": {
-        "name.first": { "value": "shay" },
-        "name.last": { "value": "banon" }
-      }
-    }
-  }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/term-filter-broken-multi-terms.json b/core/src/test/java/org/elasticsearch/index/query/term-filter-broken-multi-terms.json
deleted file mode 100644
index aabd6e4..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/term-filter-broken-multi-terms.json
+++ /dev/null
@@ -1,10 +0,0 @@
-{
-  "filtered":{
-    "query":{
-      "term":{
-        "name.first": "shay",
-        "name.last" : "banon"
-      }
-    }
-  }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/term-filter-named.json b/core/src/test/java/org/elasticsearch/index/query/term-filter-named.json
deleted file mode 100644
index c23b7b3..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/term-filter-named.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "term":{
-                "name.last":"banon",
-                "_name":"test"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/term-filter.json b/core/src/test/java/org/elasticsearch/index/query/term-filter.json
deleted file mode 100644
index 11d2bfd..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/term-filter.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "term":{
-                "name.last":"banon"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/term-with-boost.json b/core/src/test/java/org/elasticsearch/index/query/term-with-boost.json
deleted file mode 100644
index 5f33cd5..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/term-with-boost.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    term:{
-        age:{
-            value:34,
-            boost:2.0
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/term.json b/core/src/test/java/org/elasticsearch/index/query/term.json
deleted file mode 100644
index 378cf42..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/term.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{
-    term:{
-        age:34
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/terms-filter-named.json b/core/src/test/java/org/elasticsearch/index/query/terms-filter-named.json
deleted file mode 100644
index 2cb8c7a..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/terms-filter-named.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "terms":{
-                "name.last":["banon", "kimchy"],
-                "_name":"test"
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/terms-filter.json b/core/src/test/java/org/elasticsearch/index/query/terms-filter.json
deleted file mode 100644
index 04a8d26..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/terms-filter.json
+++ /dev/null
@@ -1,14 +0,0 @@
-{
-    "filtered":{
-        "query":{
-            "term":{
-                "name.first":"shay"
-            }
-        },
-        "filter":{
-            "terms":{
-                "name.last":["banon", "kimchy"]
-            }
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/terms-query-options.json b/core/src/test/java/org/elasticsearch/index/query/terms-query-options.json
deleted file mode 100644
index 48263a5..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/terms-query-options.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "terms":{
-        "name.first":["shay", "test", "elasticsearch"],
-        "disable_coord":true,
-        "boost":2.0,
-        "min_should_match":2
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/terms-query.json b/core/src/test/java/org/elasticsearch/index/query/terms-query.json
deleted file mode 100644
index a3e0d08..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/terms-query.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{
-    "terms":{
-        "name.first":["shay", "test"]
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/wildcard-boost.json b/core/src/test/java/org/elasticsearch/index/query/wildcard-boost.json
deleted file mode 100644
index 53c8d82..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/wildcard-boost.json
+++ /dev/null
@@ -1,8 +0,0 @@
-{
-    "wildcard":{
-        "name.first":{
-            "value":"sh*",
-            "boost":1.2
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/query/wildcard.json b/core/src/test/java/org/elasticsearch/index/query/wildcard.json
deleted file mode 100644
index c8ed852..0000000
--- a/core/src/test/java/org/elasticsearch/index/query/wildcard.json
+++ /dev/null
@@ -1,5 +0,0 @@
-{
-    wildcard:{
-        "name.first":"sh*"
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/AbstractChildTestCase.java b/core/src/test/java/org/elasticsearch/index/search/child/AbstractChildTestCase.java
deleted file mode 100644
index a537a4f..0000000
--- a/core/src/test/java/org/elasticsearch/index/search/child/AbstractChildTestCase.java
+++ /dev/null
@@ -1,149 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.search.child;
-
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.search.join.BitSetProducer;
-import org.apache.lucene.util.BitDocIdSet;
-import org.apache.lucene.util.BitSet;
-import org.elasticsearch.Version;
-import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.common.compress.CompressedXContent;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentHelper;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.index.IndexService;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.mapper.internal.UidFieldMapper;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.index.query.QueryShardContext;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.test.ESSingleNodeTestCase;
-import org.hamcrest.Description;
-import org.hamcrest.StringDescription;
-
-import java.io.IOException;
-
-import static org.hamcrest.Matchers.equalTo;
-
-public abstract class AbstractChildTestCase extends ESSingleNodeTestCase {
-
-    /**
-     * The name of the field within the child type that stores a score to use in test queries.
-     * <p />
-     * Its type is {@code double}.
-     */
-    protected static String CHILD_SCORE_NAME = "childScore";
-
-    static SearchContext createSearchContext(String indexName, String parentType, String childType) throws IOException {
-        Settings settings = Settings.builder()
-                .put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_6_0)
-                .build();
-        IndexService indexService = createIndex(indexName, settings);
-        MapperService mapperService = indexService.mapperService();
-        // Parent/child parsers require that the parent and child type to be presented in mapping
-        // Sometimes we want a nested object field in the parent type that triggers nonNestedDocsFilter to be used
-        mapperService.merge(parentType, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(parentType, "nested_field", random().nextBoolean() ? "type=nested" : "type=object").string()), true, false);
-        mapperService.merge(childType, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(childType, "_parent", "type=" + parentType, CHILD_SCORE_NAME, "type=double,doc_values=false").string()), true, false);
-        return createSearchContext(indexService);
-    }
-
-    static void assertBitSet(BitSet actual, BitSet expected, IndexSearcher searcher) throws IOException {
-        assertBitSet(new BitDocIdSet(actual), new BitDocIdSet(expected), searcher);
-    }
-
-    static void assertBitSet(BitDocIdSet actual, BitDocIdSet expected, IndexSearcher searcher) throws IOException {
-        if (!equals(expected, actual)) {
-            Description description = new StringDescription();
-            description.appendText(reason(actual, expected, searcher));
-            description.appendText("\nExpected: ");
-            description.appendValue(expected);
-            description.appendText("\n     got: ");
-            description.appendValue(actual);
-            description.appendText("\n");
-            throw new java.lang.AssertionError(description.toString());
-        }
-    }
-
-    static boolean equals(BitDocIdSet expected, BitDocIdSet actual) {
-        if (actual == null && expected == null) {
-            return true;
-        } else if (actual == null || expected == null) {
-            return false;
-        }
-        BitSet actualBits = actual.bits();
-        BitSet expectedBits = expected.bits();
-        if (actualBits.length() != expectedBits.length()) {
-            return false;
-        }
-        for (int i = 0; i < expectedBits.length(); i++) {
-            if (expectedBits.get(i) != actualBits.get(i)) {
-                return false;
-            }
-        }
-        return true;
-    }
-
-    static String reason(BitDocIdSet actual, BitDocIdSet expected, IndexSearcher indexSearcher) throws IOException {
-        StringBuilder builder = new StringBuilder();
-        builder.append("expected cardinality:").append(expected.bits().cardinality()).append('\n');
-        DocIdSetIterator iterator = expected.iterator();
-        for (int doc = iterator.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = iterator.nextDoc()) {
-            builder.append("Expected doc[").append(doc).append("] with id value ").append(indexSearcher.doc(doc).get(UidFieldMapper.NAME)).append('\n');
-        }
-        builder.append("actual cardinality: ").append(actual.bits().cardinality()).append('\n');
-        iterator = actual.iterator();
-        for (int doc = iterator.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = iterator.nextDoc()) {
-            builder.append("Actual doc[").append(doc).append("] with id value ").append(indexSearcher.doc(doc).get(UidFieldMapper.NAME)).append('\n');
-        }
-        return builder.toString();
-    }
-
-    static void assertTopDocs(TopDocs actual, TopDocs expected) {
-        assertThat("actual.totalHits != expected.totalHits", actual.totalHits, equalTo(expected.totalHits));
-        assertThat("actual.getMaxScore() != expected.getMaxScore()", actual.getMaxScore(), equalTo(expected.getMaxScore()));
-        assertThat("actual.scoreDocs.length != expected.scoreDocs.length", actual.scoreDocs.length, equalTo(actual.scoreDocs.length));
-        for (int i = 0; i < actual.scoreDocs.length; i++) {
-            ScoreDoc actualHit = actual.scoreDocs[i];
-            ScoreDoc expectedHit = expected.scoreDocs[i];
-            assertThat("actualHit.doc != expectedHit.doc", actualHit.doc, equalTo(expectedHit.doc));
-            assertThat("actualHit.score != expectedHit.score", actualHit.score, equalTo(expectedHit.score));
-        }
-    }
-
-    static BitSetProducer wrapWithBitSetFilter(Filter filter) {
-        return SearchContext.current().bitsetFilterCache().getBitSetProducer(filter);
-    }
-
-    static Query parseQuery(QueryBuilder queryBuilder) throws IOException {
-        QueryShardContext context = new QueryShardContext(new Index("test"), SearchContext.current().queryParserService());
-        XContentParser parser = XContentHelper.createParser(queryBuilder.buildAsBytes());
-        context.reset(parser);
-        return context.parseContext().parseInnerQueryBuilder().toQuery(context);
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/BitSetCollector.java b/core/src/test/java/org/elasticsearch/index/search/child/BitSetCollector.java
deleted file mode 100644
index afdc08e..0000000
--- a/core/src/test/java/org/elasticsearch/index/search/child/BitSetCollector.java
+++ /dev/null
@@ -1,50 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.util.FixedBitSet;
-import org.elasticsearch.common.lucene.search.NoopCollector;
-
-import java.io.IOException;
-
-class BitSetCollector extends NoopCollector {
-
-    final FixedBitSet result;
-    int docBase;
-
-    BitSetCollector(int topLevelMaxDoc) {
-        this.result = new FixedBitSet(topLevelMaxDoc);
-    }
-
-    @Override
-    public void collect(int doc) throws IOException {
-        result.set(docBase + doc);
-    }
-
-    @Override
-    protected void doSetNextReader(LeafReaderContext context) throws IOException {
-        docBase = context.docBase;
-    }
-
-    FixedBitSet getResult() {
-        return result;
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java
deleted file mode 100644
index 67f579f..0000000
--- a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java
+++ /dev/null
@@ -1,295 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import com.carrotsearch.hppc.IntHashSet;
-import com.carrotsearch.hppc.ObjectObjectHashMap;
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.*;
-import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util.LuceneTestCase;
-import org.elasticsearch.common.lease.Releasables;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.index.engine.Engine;
-import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
-import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
-import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
-import org.elasticsearch.index.mapper.internal.UidFieldMapper;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.test.TestSearchContext;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.NavigableSet;
-import java.util.Random;
-import java.util.TreeSet;
-
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.filteredQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasChildQuery;
-import static org.elasticsearch.index.query.QueryBuilders.notQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.hamcrest.Matchers.equalTo;
-
-public class ChildrenConstantScoreQueryTests extends AbstractChildTestCase {
-
-    @BeforeClass
-    public static void before() throws IOException {
-        SearchContext.setCurrent(createSearchContext("test", "parent", "child"));
-    }
-
-    @AfterClass
-    public static void after() throws IOException {
-        SearchContext current = SearchContext.current();
-        SearchContext.removeCurrent();
-        Releasables.close(current);
-    }
-
-    @Test
-    public void testBasicQuerySanities() {
-        Query childQuery = new TermQuery(new Term("field", "value"));
-        ParentFieldMapper parentFieldMapper = SearchContext.current().mapperService().documentMapper("child").parentFieldMapper();
-        ParentChildIndexFieldData parentChildIndexFieldData = SearchContext.current().fieldData().getForField(parentFieldMapper.fieldType());
-        Filter parentFilter = new QueryWrapperFilter(new TermQuery(new Term(TypeFieldMapper.NAME, "parent")));
-        Query query = new ChildrenConstantScoreQuery(parentChildIndexFieldData, childQuery, "parent", "child", parentFilter, 12, wrapWithBitSetFilter(Queries.newNonNestedFilter()));
-        QueryUtils.check(query);
-    }
-
-    @Test
-    public void testSimple() throws Exception {
-        Directory directory = newDirectory();
-        RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory);
-
-        for (int parent = 1; parent <= 5; parent++) {
-            Document document = new Document();
-            document.add(new StringField(UidFieldMapper.NAME, Uid.createUid("parent", Integer.toString(parent)), Field.Store.NO));
-            document.add(new StringField(TypeFieldMapper.NAME, "parent", Field.Store.NO));
-            indexWriter.addDocument(document);
-
-            for (int child = 1; child <= 3; child++) {
-                document = new Document();
-                document.add(new StringField(UidFieldMapper.NAME, Uid.createUid("child", Integer.toString(parent * 3 + child)), Field.Store.NO));
-                document.add(new StringField(TypeFieldMapper.NAME, "child", Field.Store.NO));
-                document.add(new StringField(ParentFieldMapper.NAME, Uid.createUid("parent", Integer.toString(parent)), Field.Store.NO));
-                document.add(new StringField("field1", "value" + child, Field.Store.NO));
-                indexWriter.addDocument(document);
-            }
-        }
-
-        IndexReader indexReader = DirectoryReader.open(indexWriter.w, false);
-        IndexSearcher searcher = new IndexSearcher(indexReader);
-        ((TestSearchContext) SearchContext.current()).setSearcher(
-                new Engine.Searcher(ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher)
-        );
-
-        TermQuery childQuery = new TermQuery(new Term("field1", "value" + (1 + random().nextInt(3))));
-        Filter parentFilter = new QueryWrapperFilter(new TermQuery(new Term(TypeFieldMapper.NAME, "parent")));
-        int shortCircuitParentDocSet = random().nextInt(5);
-        ParentFieldMapper parentFieldMapper = SearchContext.current().mapperService().documentMapper("child").parentFieldMapper();
-        ParentChildIndexFieldData parentChildIndexFieldData = SearchContext.current().fieldData().getForField(parentFieldMapper.fieldType());
-        ChildrenConstantScoreQuery query = new ChildrenConstantScoreQuery(parentChildIndexFieldData, childQuery, "parent", "child", parentFilter, shortCircuitParentDocSet, null);
-
-        BitSetCollector collector = new BitSetCollector(indexReader.maxDoc());
-        searcher.search(query, collector);
-        FixedBitSet actualResult = collector.getResult();
-
-        assertThat(actualResult.cardinality(), equalTo(5));
-
-        indexWriter.close();
-        indexReader.close();
-        directory.close();
-    }
-
-    @Test
-    public void testRandom() throws Exception {
-        Directory directory = newDirectory();
-        final Random r = random();
-        final IndexWriterConfig iwc = LuceneTestCase.newIndexWriterConfig(r, new MockAnalyzer(r))
-                .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)
-                .setRAMBufferSizeMB(scaledRandomIntBetween(16, 64)); // we might index a lot - don't go crazy here
-        RandomIndexWriter indexWriter = new RandomIndexWriter(r, directory, iwc);
-        int numUniqueChildValues = scaledRandomIntBetween(100, 2000);
-        String[] childValues = new String[numUniqueChildValues];
-        for (int i = 0; i < numUniqueChildValues; i++) {
-            childValues[i] = Integer.toString(i);
-        }
-
-        IntHashSet filteredOrDeletedDocs = new IntHashSet();
-        int childDocId = 0;
-        int numParentDocs = scaledRandomIntBetween(1, numUniqueChildValues);
-        ObjectObjectHashMap<String, NavigableSet<String>> childValueToParentIds = new ObjectObjectHashMap<>();
-        for (int parentDocId = 0; parentDocId < numParentDocs; parentDocId++) {
-            boolean markParentAsDeleted = rarely();
-            boolean filterMe = rarely();
-            String parent = Integer.toString(parentDocId);
-            Document document = new Document();
-            document.add(new StringField(UidFieldMapper.NAME, Uid.createUid("parent", parent), Field.Store.YES));
-            document.add(new StringField(TypeFieldMapper.NAME, "parent", Field.Store.NO));
-            if (markParentAsDeleted) {
-                filteredOrDeletedDocs.add(parentDocId);
-                document.add(new StringField("delete", "me", Field.Store.NO));
-            }
-            if (filterMe) {
-                filteredOrDeletedDocs.add(parentDocId);
-                document.add(new StringField("filter", "me", Field.Store.NO));
-            }
-            indexWriter.addDocument(document);
-
-            final int numChildDocs = scaledRandomIntBetween(0, 100);
-            for (int i = 0; i < numChildDocs; i++) {
-                boolean markChildAsDeleted = rarely();
-                String childValue = childValues[random().nextInt(childValues.length)];
-
-                document = new Document();
-                document.add(new StringField(UidFieldMapper.NAME, Uid.createUid("child", Integer.toString(childDocId++)), Field.Store.NO));
-                document.add(new StringField(TypeFieldMapper.NAME, "child", Field.Store.NO));
-                document.add(new StringField(ParentFieldMapper.NAME, Uid.createUid("parent", parent), Field.Store.NO));
-                document.add(new StringField("field1", childValue, Field.Store.NO));
-                if (markChildAsDeleted) {
-                    document.add(new StringField("delete", "me", Field.Store.NO));
-                }
-                indexWriter.addDocument(document);
-
-                if (!markChildAsDeleted) {
-                    NavigableSet<String> parentIds;
-                    if (childValueToParentIds.containsKey(childValue)) {
-                        parentIds = childValueToParentIds.get(childValue);
-                    } else {
-                        childValueToParentIds.put(childValue, parentIds = new TreeSet<>());
-                    }
-                    if (!markParentAsDeleted && !filterMe) {
-                        parentIds.add(parent);
-                    }
-                }
-            }
-        }
-
-        // Delete docs that are marked to be deleted.
-        indexWriter.deleteDocuments(new Term("delete", "me"));
-
-        indexWriter.commit();
-        IndexReader indexReader = DirectoryReader.open(directory);
-        IndexSearcher searcher = new IndexSearcher(indexReader);
-        Engine.Searcher engineSearcher = new Engine.Searcher(
-                ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher
-        );
-        ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
-
-        int max = numUniqueChildValues / 4;
-        for (int i = 0; i < max; i++) {
-            // Simulate a parent update
-            if (random().nextBoolean()) {
-                final int numberOfUpdatableParents = numParentDocs - filteredOrDeletedDocs.size();
-                int numberOfUpdates = scaledRandomIntBetween(0, numberOfUpdatableParents);
-                for (int j = 0; j < numberOfUpdates; j++) {
-                    int parentId;
-                    do {
-                        parentId = random().nextInt(numParentDocs);
-                    } while (filteredOrDeletedDocs.contains(parentId));
-
-                    String parentUid = Uid.createUid("parent", Integer.toString(parentId));
-                    indexWriter.deleteDocuments(new Term(UidFieldMapper.NAME, parentUid));
-
-                    Document document = new Document();
-                    document.add(new StringField(UidFieldMapper.NAME, parentUid, Field.Store.YES));
-                    document.add(new StringField(TypeFieldMapper.NAME, "parent", Field.Store.NO));
-                    indexWriter.addDocument(document);
-                }
-
-                indexReader.close();
-                indexReader = DirectoryReader.open(indexWriter.w, true);
-                searcher = new IndexSearcher(indexReader);
-                engineSearcher = new Engine.Searcher(
-                        ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher
-                );
-                ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
-            }
-
-            String childValue = childValues[random().nextInt(numUniqueChildValues)];
-            int shortCircuitParentDocSet = random().nextInt(numParentDocs);
-            QueryBuilder queryBuilder;
-            if (random().nextBoolean()) {
-                queryBuilder = hasChildQuery("child", termQuery("field1", childValue))
-                        .shortCircuitCutoff(shortCircuitParentDocSet);
-            } else {
-                queryBuilder = constantScoreQuery(
-                        hasChildQuery("child", termQuery("field1", childValue))
-                                .shortCircuitCutoff(shortCircuitParentDocSet)
-                );
-            }
-            // Using a FQ, will invoke / test the Scorer#advance(..) and also let the Weight#scorer not get live docs as acceptedDocs
-            queryBuilder = filteredQuery(queryBuilder, notQuery(termQuery("filter", "me")));
-            Query query = parseQuery(queryBuilder);
-
-            BitSetCollector collector = new BitSetCollector(indexReader.maxDoc());
-            searcher.search(query, collector);
-            FixedBitSet actualResult = collector.getResult();
-
-            FixedBitSet expectedResult = new FixedBitSet(indexReader.maxDoc());
-            if (childValueToParentIds.containsKey(childValue)) {
-                LeafReader slowLeafReader = SlowCompositeReaderWrapper.wrap(indexReader);
-                Terms terms = slowLeafReader.terms(UidFieldMapper.NAME);
-                if (terms != null) {
-                    NavigableSet<String> parentIds = childValueToParentIds.get(childValue);
-                    TermsEnum termsEnum = terms.iterator();
-                    PostingsEnum docsEnum = null;
-                    for (String id : parentIds) {
-                        TermsEnum.SeekStatus seekStatus = termsEnum.seekCeil(Uid.createUidAsBytes("parent", id));
-                        if (seekStatus == TermsEnum.SeekStatus.FOUND) {
-                            docsEnum = termsEnum.postings(docsEnum, PostingsEnum.NONE);
-                            final Bits liveDocs = slowLeafReader.getLiveDocs();
-                            for (int doc = docsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = docsEnum.nextDoc()) {
-                                if (liveDocs == null || liveDocs.get(doc)) {
-                                    break;
-                                }
-                            }
-                            expectedResult.set(docsEnum.docID());
-                        } else if (seekStatus == TermsEnum.SeekStatus.END) {
-                            break;
-                        }
-                    }
-                }
-            }
-
-            assertBitSet(actualResult, expectedResult, searcher);
-        }
-
-        indexWriter.close();
-        indexReader.close();
-        directory.close();
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java
deleted file mode 100644
index 971c987..0000000
--- a/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java
+++ /dev/null
@@ -1,397 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import com.carrotsearch.hppc.FloatArrayList;
-import com.carrotsearch.hppc.IntHashSet;
-import com.carrotsearch.hppc.ObjectObjectHashMap;
-import com.carrotsearch.randomizedtesting.generators.RandomInts;
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.DoubleField;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.*;
-import org.apache.lucene.search.*;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util.LuceneTestCase;
-import org.elasticsearch.common.lease.Releasables;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.index.engine.Engine;
-import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
-import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.mapper.internal.IdFieldMapper;
-import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
-import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
-import org.elasticsearch.index.mapper.internal.UidFieldMapper;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.index.query.functionscore.fieldvaluefactor.FieldValueFactorFunctionBuilder;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.test.TestSearchContext;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.*;
-
-import static org.elasticsearch.index.query.QueryBuilders.*;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.lessThanOrEqualTo;
-
-public class ChildrenQueryTests extends AbstractChildTestCase {
-
-    @BeforeClass
-    public static void before() throws IOException {
-        SearchContext.setCurrent(createSearchContext("test", "parent", "child"));
-    }
-
-    @AfterClass
-    public static void after() throws IOException {
-        SearchContext current = SearchContext.current();
-        SearchContext.removeCurrent();
-        Releasables.close(current);
-    }
-
-    @Test
-    public void testBasicQuerySanities() {
-        Query childQuery = new TermQuery(new Term("field", "value"));
-        ScoreType scoreType = ScoreType.values()[random().nextInt(ScoreType.values().length)];
-        ParentFieldMapper parentFieldMapper = SearchContext.current().mapperService().documentMapper("child").parentFieldMapper();
-        ParentChildIndexFieldData parentChildIndexFieldData = SearchContext.current().fieldData().getForField(parentFieldMapper.fieldType());
-        Filter parentFilter = new QueryWrapperFilter(new TermQuery(new Term(TypeFieldMapper.NAME, "parent")));
-        int minChildren = random().nextInt(10);
-        int maxChildren = scaledRandomIntBetween(minChildren, 10);
-        Query query = new ChildrenQuery(parentChildIndexFieldData, "parent", "child", parentFilter, childQuery, scoreType, minChildren,
-                maxChildren, 12, wrapWithBitSetFilter(Queries.newNonNestedFilter()));
-        QueryUtils.check(query);
-    }
-
-    @Test
-    public void testRandom() throws Exception {
-        Directory directory = newDirectory();
-        final Random r = random();
-        final IndexWriterConfig iwc = LuceneTestCase.newIndexWriterConfig(r, new MockAnalyzer(r))
-                .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)
-                .setRAMBufferSizeMB(scaledRandomIntBetween(16, 64)); // we might index a lot - don't go crazy here
-        RandomIndexWriter indexWriter = new RandomIndexWriter(r, directory, iwc);
-        int numUniqueChildValues = scaledRandomIntBetween(100, 2000);
-        String[] childValues = new String[numUniqueChildValues];
-        for (int i = 0; i < numUniqueChildValues; i++) {
-            childValues[i] = Integer.toString(i);
-        }
-
-        IntHashSet filteredOrDeletedDocs = new IntHashSet();
-
-        int childDocId = 0;
-        int numParentDocs = scaledRandomIntBetween(1, numUniqueChildValues);
-        ObjectObjectHashMap<String, NavigableMap<String, FloatArrayList>> childValueToParentIds = new ObjectObjectHashMap<>();
-        for (int parentDocId = 0; parentDocId < numParentDocs; parentDocId++) {
-            boolean markParentAsDeleted = rarely();
-            boolean filterMe = rarely();
-            String parent = Integer.toString(parentDocId);
-            Document document = new Document();
-            document.add(new StringField(UidFieldMapper.NAME, Uid.createUid("parent", parent), Field.Store.YES));
-            document.add(new StringField(TypeFieldMapper.NAME, "parent", Field.Store.NO));
-            if (markParentAsDeleted) {
-                filteredOrDeletedDocs.add(parentDocId);
-                document.add(new StringField("delete", "me", Field.Store.NO));
-            }
-            if (filterMe) {
-                filteredOrDeletedDocs.add(parentDocId);
-                document.add(new StringField("filter", "me", Field.Store.NO));
-            }
-            indexWriter.addDocument(document);
-
-            int numChildDocs = scaledRandomIntBetween(0, 100);
-            for (int i = 0; i < numChildDocs; i++) {
-                boolean markChildAsDeleted = rarely();
-                String childValue = childValues[random().nextInt(childValues.length)];
-
-                document = new Document();
-                document.add(new StringField(UidFieldMapper.NAME, Uid.createUid("child", Integer.toString(childDocId++)), Field.Store.NO));
-                document.add(new StringField(TypeFieldMapper.NAME, "child", Field.Store.NO));
-                document.add(new StringField(ParentFieldMapper.NAME, Uid.createUid("parent", parent), Field.Store.NO));
-                document.add(new StringField("field1", childValue, Field.Store.NO));
-                if (markChildAsDeleted) {
-                    document.add(new StringField("delete", "me", Field.Store.NO));
-                }
-                indexWriter.addDocument(document);
-
-                if (!markChildAsDeleted) {
-                    NavigableMap<String, FloatArrayList> parentIdToChildScores;
-                    if (childValueToParentIds.containsKey(childValue)) {
-                        parentIdToChildScores = childValueToParentIds.get(childValue);
-                    } else {
-                        childValueToParentIds.put(childValue, parentIdToChildScores = new TreeMap<>());
-                    }
-                    if (!markParentAsDeleted && !filterMe) {
-                        FloatArrayList childScores = parentIdToChildScores.get(parent);
-                        if (childScores == null) {
-                            parentIdToChildScores.put(parent, childScores = new FloatArrayList());
-                        }
-                        childScores.add(1f);
-                    }
-                }
-            }
-        }
-
-        // Delete docs that are marked to be deleted.
-        indexWriter.deleteDocuments(new Term("delete", "me"));
-        indexWriter.commit();
-
-        IndexReader indexReader = DirectoryReader.open(directory);
-        IndexSearcher searcher = new IndexSearcher(indexReader);
-        Engine.Searcher engineSearcher = new Engine.Searcher(
-                ChildrenQueryTests.class.getSimpleName(), searcher
-        );
-        ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
-
-        int max = numUniqueChildValues / 4;
-        for (int i = 0; i < max; i++) {
-            // Simulate a parent update
-            if (random().nextBoolean()) {
-                final int numberOfUpdatableParents = numParentDocs - filteredOrDeletedDocs.size();
-                int numberOfUpdates = RandomInts.randomIntBetween(random(), 0, Math.min(numberOfUpdatableParents, TEST_NIGHTLY ? 25 : 5));
-                for (int j = 0; j < numberOfUpdates; j++) {
-                    int parentId;
-                    do {
-                        parentId = random().nextInt(numParentDocs);
-                    } while (filteredOrDeletedDocs.contains(parentId));
-
-                    String parentUid = Uid.createUid("parent", Integer.toString(parentId));
-                    indexWriter.deleteDocuments(new Term(UidFieldMapper.NAME, parentUid));
-
-                    Document document = new Document();
-                    document.add(new StringField(UidFieldMapper.NAME, parentUid, Field.Store.YES));
-                    document.add(new StringField(TypeFieldMapper.NAME, "parent", Field.Store.NO));
-                    indexWriter.addDocument(document);
-                }
-
-                indexReader.close();
-                indexReader = DirectoryReader.open(indexWriter.w, true);
-                searcher = new IndexSearcher(indexReader);
-                engineSearcher = new Engine.Searcher(
-                        ChildrenConstantScoreQueryTests.class.getSimpleName(), searcher
-                );
-                ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
-            }
-
-            String childValue = childValues[random().nextInt(numUniqueChildValues)];
-            int shortCircuitParentDocSet = random().nextInt(numParentDocs);
-            ScoreType scoreType = ScoreType.values()[random().nextInt(ScoreType.values().length)];
-            // leave min/max set to 0 half the time
-            int minChildren = random().nextInt(2) * scaledRandomIntBetween(0, 110);
-            int maxChildren = random().nextInt(2) * scaledRandomIntBetween(minChildren, 110);
-
-            QueryBuilder queryBuilder = hasChildQuery("child", constantScoreQuery(termQuery("field1", childValue)))
-                    .scoreType(scoreType)
-                    .minChildren(minChildren)
-                    .maxChildren(maxChildren)
-                    .shortCircuitCutoff(shortCircuitParentDocSet);
-            // Using a FQ, will invoke / test the Scorer#advance(..) and also let the Weight#scorer not get live docs as acceptedDocs
-            queryBuilder = filteredQuery(queryBuilder, notQuery(termQuery("filter", "me")));
-            Query query = parseQuery(queryBuilder);
-            BitSetCollector collector = new BitSetCollector(indexReader.maxDoc());
-            int numHits = 1 + random().nextInt(25);
-            TopScoreDocCollector actualTopDocsCollector = TopScoreDocCollector.create(numHits);
-            searcher.search(query, MultiCollector.wrap(collector, actualTopDocsCollector));
-            FixedBitSet actualResult = collector.getResult();
-
-            FixedBitSet expectedResult = new FixedBitSet(indexReader.maxDoc());
-            TopScoreDocCollector expectedTopDocsCollector = TopScoreDocCollector.create(numHits);
-            if (childValueToParentIds.containsKey(childValue)) {
-                LeafReader slowLeafReader = SlowCompositeReaderWrapper.wrap(indexReader);
-                final FloatArrayList[] scores = new FloatArrayList[slowLeafReader.maxDoc()];
-                Terms terms = slowLeafReader.terms(UidFieldMapper.NAME);
-                if (terms != null) {
-                    NavigableMap<String, FloatArrayList> parentIdToChildScores = childValueToParentIds.get(childValue);
-                    TermsEnum termsEnum = terms.iterator();
-                    PostingsEnum docsEnum = null;
-                    for (Map.Entry<String, FloatArrayList> entry : parentIdToChildScores.entrySet()) {
-                        int count = entry.getValue().elementsCount;
-                        if (count >= minChildren && (maxChildren == 0 || count <= maxChildren)) {
-                            TermsEnum.SeekStatus seekStatus = termsEnum.seekCeil(Uid.createUidAsBytes("parent", entry.getKey()));
-                            if (seekStatus == TermsEnum.SeekStatus.FOUND) {
-                                docsEnum = termsEnum.postings(docsEnum, PostingsEnum.NONE);
-                                final Bits liveDocs = slowLeafReader.getLiveDocs();
-                                for (int doc = docsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = docsEnum.nextDoc()) {
-                                    if (liveDocs == null || liveDocs.get(doc)) {
-                                        break;
-                                    }
-                                }
-                                expectedResult.set(docsEnum.docID());
-                                scores[docsEnum.docID()] = new FloatArrayList(entry.getValue());
-                            } else if (seekStatus == TermsEnum.SeekStatus.END) {
-                                break;
-                            }
-                        }
-                    }
-                }
-                MockScorer mockScorer = new MockScorer(scoreType);
-                final LeafCollector leafCollector = expectedTopDocsCollector.getLeafCollector(slowLeafReader.getContext());
-                leafCollector.setScorer(mockScorer);
-                for (int doc = expectedResult.nextSetBit(0); doc < slowLeafReader.maxDoc(); doc = doc + 1 >= expectedResult.length() ? DocIdSetIterator.NO_MORE_DOCS : expectedResult.nextSetBit(doc + 1)) {
-                    mockScorer.scores = scores[doc];
-                    leafCollector.collect(doc);
-                }
-            }
-
-            assertBitSet(actualResult, expectedResult, searcher);
-            assertTopDocs(actualTopDocsCollector.topDocs(), expectedTopDocsCollector.topDocs());
-        }
-
-        indexWriter.close();
-        indexReader.close();
-        directory.close();
-    }
-
-    @Test
-    public void testMinScoreMode() throws IOException {
-        assertScoreType(ScoreType.MIN);
-    }
-
-    @Test
-    public void testMaxScoreMode() throws IOException {
-        assertScoreType(ScoreType.MAX);
-    }
-
-    @Test
-    public void testAvgScoreMode() throws IOException {
-        assertScoreType(ScoreType.AVG);
-    }
-
-    @Test
-    public void testSumScoreMode() throws IOException {
-        assertScoreType(ScoreType.SUM);
-    }
-
-    /**
-     * Assert that the {@code scoreType} operates as expected and parents are found in the expected order.
-     * <p />
-     * This will use the test index's parent/child types to create parents with multiple children. Each child will have
-     * a randomly generated scored stored in {@link #CHILD_SCORE_NAME}, which is used to score based on the
-     * {@code scoreType} by using a {@link MockScorer} to determine the expected scores.
-     * @param scoreType The score type to use within the query to score parents relative to their children.
-     * @throws IOException if any unexpected error occurs
-     */
-    private void assertScoreType(ScoreType scoreType) throws IOException {
-        SearchContext context = SearchContext.current();
-        Directory directory = newDirectory();
-        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(new MockAnalyzer(random())));
-
-        // calculates the expected score per parent
-        MockScorer scorer = new MockScorer(scoreType);
-        scorer.scores = new FloatArrayList(10);
-
-        // number of parents to generate
-        int parentDocs = scaledRandomIntBetween(2, 10);
-        // unique child ID
-        int childDocId = 0;
-
-        // Parent ID to expected score
-        Map<String, Float> parentScores = new TreeMap<>();
-
-        // Add a few random parents to ensure that the children's score is appropriately taken into account
-        for (int parentDocId = 0; parentDocId < parentDocs; ++parentDocId) {
-            String parent = Integer.toString(parentDocId);
-
-            // Create the parent
-            Document parentDocument = new Document();
-
-            parentDocument.add(new StringField(UidFieldMapper.NAME, Uid.createUid("parent", parent), Field.Store.YES));
-            parentDocument.add(new StringField(IdFieldMapper.NAME, parent, Field.Store.YES));
-            parentDocument.add(new StringField(TypeFieldMapper.NAME, "parent", Field.Store.NO));
-
-            // add the parent to the index
-            writer.addDocument(parentDocument);
-
-            int numChildDocs = scaledRandomIntBetween(1, 10);
-
-            // forget any parent's previous scores
-            scorer.scores.clear();
-
-            // associate children with the parent
-            for (int i = 0; i < numChildDocs; ++i) {
-                int childScore = random().nextInt(128);
-
-                Document childDocument = new Document();
-
-                childDocument.add(new StringField(UidFieldMapper.NAME, Uid.createUid("child", Integer.toString(childDocId++)), Field.Store.NO));
-                childDocument.add(new StringField(TypeFieldMapper.NAME, "child", Field.Store.NO));
-                // parent association:
-                childDocument.add(new StringField(ParentFieldMapper.NAME, Uid.createUid("parent", parent), Field.Store.NO));
-                childDocument.add(new DoubleField(CHILD_SCORE_NAME, childScore, Field.Store.NO));
-
-                // remember the score to be calculated
-                scorer.scores.add(childScore);
-
-                // add the associated child to the index
-                writer.addDocument(childDocument);
-            }
-
-            // this score that should be returned for this parent
-            parentScores.put(parent, scorer.score());
-        }
-
-        writer.commit();
-
-        IndexReader reader = DirectoryReader.open(writer, true);
-        IndexSearcher searcher = new IndexSearcher(reader);
-
-        // setup to read the parent/child map
-        Engine.Searcher engineSearcher = new Engine.Searcher(ChildrenQueryTests.class.getSimpleName(), searcher);
-        ((TestSearchContext)context).setSearcher(engineSearcher);
-
-        // child query that returns the score as the value of "childScore" for each child document, with the parent's score determined by the score type
-        QueryBuilder childQueryBuilder = functionScoreQuery(typeQuery("child")).add(new FieldValueFactorFunctionBuilder(CHILD_SCORE_NAME));
-        QueryBuilder queryBuilder = hasChildQuery("child", childQueryBuilder)
-                .scoreType(scoreType)
-                .shortCircuitCutoff(parentDocs);
-
-        // Perform the search for the documents using the selected score type
-        Query query = parseQuery(queryBuilder);
-        TopDocs docs = searcher.search(query, parentDocs);
-        assertThat("Expected all parents", docs.totalHits, is(parentDocs));
-
-        // score should be descending (just a sanity check)
-        float topScore = docs.scoreDocs[0].score;
-
-        // ensure each score is returned as expected
-        for (int i = 0; i < parentDocs; ++i) {
-            ScoreDoc scoreDoc = docs.scoreDocs[i];
-            // get the ID from the document to get its expected score; remove it so we cannot double-count it
-            float score = parentScores.remove(reader.document(scoreDoc.doc).get(IdFieldMapper.NAME));
-
-            // expect exact match
-            assertThat("Unexpected score", scoreDoc.score, is(score));
-            assertThat("Not descending", score, lessThanOrEqualTo(topScore));
-
-            // it had better keep descending
-            topScore = score;
-        }
-
-        reader.close();
-        writer.close();
-        directory.close();
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/MockScorer.java b/core/src/test/java/org/elasticsearch/index/search/child/MockScorer.java
deleted file mode 100644
index 2eecbce..0000000
--- a/core/src/test/java/org/elasticsearch/index/search/child/MockScorer.java
+++ /dev/null
@@ -1,102 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import com.carrotsearch.hppc.FloatArrayList;
-
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.util.BytesRef;
-
-import java.io.IOException;
-
-class MockScorer extends Scorer {
-
-    final ScoreType scoreType;
-    FloatArrayList scores;
-
-    MockScorer(ScoreType scoreType) {
-        super(null);
-        this.scoreType = scoreType;
-    }
-
-    @Override
-    public float score() throws IOException {
-        if (scoreType == ScoreType.NONE) {
-            return 1.0f;
-        }
-        float aggregateScore = 0;
-
-        // in the case of a min value, it can't start at 0 (the lowest score); in all cases, it doesn't hurt to use the
-        //  first score, so we can safely use the first value by skipping it in the loop
-        if (scores.elementsCount != 0) {
-            aggregateScore = scores.buffer[0];
-
-            for (int i = 1; i < scores.elementsCount; i++) {
-                float score = scores.buffer[i];
-                switch (scoreType) {
-                    case MIN:
-                        if (aggregateScore > score) {
-                            aggregateScore = score;
-                        }
-                        break;
-                    case MAX:
-                        if (aggregateScore < score) {
-                            aggregateScore = score;
-                        }
-                        break;
-                    case SUM:
-                    case AVG:
-                        aggregateScore += score;
-                        break;
-                }
-            }
-
-            if (scoreType == ScoreType.AVG) {
-                aggregateScore /= scores.elementsCount;
-            }
-        }
-
-        return aggregateScore;
-    }
-
-    @Override
-    public int freq() throws IOException {
-        return 0;
-    }
-
-    @Override
-    public int docID() {
-        return 0;
-    }
-
-    @Override
-    public int nextDoc() throws IOException {
-        return 0;
-    }
-
-    @Override
-    public int advance(int target) throws IOException {
-        return 0;
-    }
-
-    @Override
-    public long cost() {
-        return 0;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java
deleted file mode 100644
index 83488f2..0000000
--- a/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java
+++ /dev/null
@@ -1,236 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import com.carrotsearch.hppc.IntIntHashMap;
-import com.carrotsearch.hppc.ObjectObjectHashMap;
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.*;
-import org.apache.lucene.search.*;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util.LuceneTestCase;
-import org.elasticsearch.common.lease.Releasables;
-import org.elasticsearch.index.engine.Engine;
-import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
-import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
-import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
-import org.elasticsearch.index.mapper.internal.UidFieldMapper;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.test.TestSearchContext;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.NavigableSet;
-import java.util.Random;
-import java.util.TreeSet;
-
-import static org.elasticsearch.index.query.QueryBuilders.*;
-
-/**
- */
-public class ParentConstantScoreQueryTests extends AbstractChildTestCase {
-
-    @BeforeClass
-    public static void before() throws IOException {
-        SearchContext.setCurrent(createSearchContext("test", "parent", "child"));
-    }
-
-    @AfterClass
-    public static void after() throws IOException {
-        SearchContext current = SearchContext.current();
-        SearchContext.removeCurrent();
-        Releasables.close(current);
-    }
-
-    @Test
-    public void testBasicQuerySanities() {
-        Query parentQuery = new TermQuery(new Term("field", "value"));
-        ParentFieldMapper parentFieldMapper = SearchContext.current().mapperService().documentMapper("child").parentFieldMapper();
-        ParentChildIndexFieldData parentChildIndexFieldData = SearchContext.current().fieldData().getForField(parentFieldMapper.fieldType());
-        Filter childrenFilter = new QueryWrapperFilter(new TermQuery(new Term(TypeFieldMapper.NAME, "child")));
-        Query query = new ParentConstantScoreQuery(parentChildIndexFieldData, parentQuery, "parent", childrenFilter);
-        QueryUtils.check(query);
-    }
-
-    @Test
-    public void testRandom() throws Exception {
-        Directory directory = newDirectory();
-        final Random r = random();
-        final IndexWriterConfig iwc = LuceneTestCase.newIndexWriterConfig(r, new MockAnalyzer(r))
-                .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)
-                .setRAMBufferSizeMB(scaledRandomIntBetween(16, 64)); // we might index a lot - don't go crazy here
-        RandomIndexWriter indexWriter = new RandomIndexWriter(r, directory, iwc);
-        int numUniqueParentValues = scaledRandomIntBetween(100, 2000);
-        String[] parentValues = new String[numUniqueParentValues];
-        for (int i = 0; i < numUniqueParentValues; i++) {
-            parentValues[i] = Integer.toString(i);
-        }
-
-        int childDocId = 0;
-        int numParentDocs = scaledRandomIntBetween(1, numUniqueParentValues);
-        ObjectObjectHashMap<String, NavigableSet<String>> parentValueToChildDocIds = new ObjectObjectHashMap<>();
-        IntIntHashMap childIdToParentId = new IntIntHashMap();
-        for (int parentDocId = 0; parentDocId < numParentDocs; parentDocId++) {
-            boolean markParentAsDeleted = rarely();
-            String parentValue = parentValues[random().nextInt(parentValues.length)];
-            String parent = Integer.toString(parentDocId);
-            Document document = new Document();
-            document.add(new StringField(UidFieldMapper.NAME, Uid.createUid("parent", parent), Field.Store.NO));
-            document.add(new StringField(TypeFieldMapper.NAME, "parent", Field.Store.NO));
-            document.add(new StringField("field1", parentValue, Field.Store.NO));
-            if (markParentAsDeleted) {
-                document.add(new StringField("delete", "me", Field.Store.NO));
-            }
-            indexWriter.addDocument(document);
-
-            int numChildDocs = scaledRandomIntBetween(0, 100);
-            if (parentDocId == numParentDocs - 1 && childIdToParentId.isEmpty()) {
-                // ensure there is at least one child in the index
-                numChildDocs = Math.max(1, numChildDocs);
-            }
-            for (int i = 0; i < numChildDocs; i++) {
-                boolean markChildAsDeleted = rarely();
-                boolean filterMe = rarely();
-                String child = Integer.toString(childDocId++);
-
-                document = new Document();
-                document.add(new StringField(UidFieldMapper.NAME, Uid.createUid("child", child), Field.Store.YES));
-                document.add(new StringField(TypeFieldMapper.NAME, "child", Field.Store.NO));
-                document.add(new StringField(ParentFieldMapper.NAME, Uid.createUid("parent", parent), Field.Store.NO));
-                if (markChildAsDeleted) {
-                    document.add(new StringField("delete", "me", Field.Store.NO));
-                }
-                if (filterMe) {
-                    document.add(new StringField("filter", "me", Field.Store.NO));
-                }
-                indexWriter.addDocument(document);
-
-                if (!markParentAsDeleted) {
-                    NavigableSet<String> childIds;
-                    if (parentValueToChildDocIds.containsKey(parentValue)) {
-                        childIds = parentValueToChildDocIds.get(parentValue);
-                    } else {
-                        parentValueToChildDocIds.put(parentValue, childIds = new TreeSet<>());
-                    }
-                    if (!markChildAsDeleted && !filterMe) {
-                        childIdToParentId.put(Integer.valueOf(child), parentDocId);
-                        childIds.add(child);
-                    }
-                }
-            }
-        }
-
-        // Delete docs that are marked to be deleted.
-        indexWriter.deleteDocuments(new Term("delete", "me"));
-        indexWriter.commit();
-
-        IndexReader indexReader = DirectoryReader.open(directory);
-        IndexSearcher searcher = new IndexSearcher(indexReader);
-        Engine.Searcher engineSearcher = new Engine.Searcher(
-                ParentConstantScoreQuery.class.getSimpleName(), searcher
-        );
-        ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
-
-        int max = numUniqueParentValues / 4;
-        for (int i = 0; i < max; i++) {
-            // Simulate a child update
-            if (random().nextBoolean()) {
-                int numberOfUpdates = childIdToParentId.isEmpty() ? 0 : scaledRandomIntBetween(1, 25);
-                int[] childIds = childIdToParentId.keys().toArray();
-                for (int j = 0; j < numberOfUpdates; j++) {
-                    int childId = childIds[random().nextInt(childIds.length)];
-                    String childUid = Uid.createUid("child", Integer.toString(childId));
-                    indexWriter.deleteDocuments(new Term(UidFieldMapper.NAME, childUid));
-
-                    Document document = new Document();
-                    document.add(new StringField(UidFieldMapper.NAME, childUid, Field.Store.YES));
-                    document.add(new StringField(TypeFieldMapper.NAME, "child", Field.Store.NO));
-                    String parentUid = Uid.createUid("parent", Integer.toString(childIdToParentId.get(childId)));
-                    document.add(new StringField(ParentFieldMapper.NAME, parentUid, Field.Store.NO));
-                    indexWriter.addDocument(document);
-                }
-
-                indexReader.close();
-                indexReader = DirectoryReader.open(indexWriter.w, true);
-                searcher = new IndexSearcher(indexReader);
-                engineSearcher = new Engine.Searcher(
-                        ParentConstantScoreQueryTests.class.getSimpleName(), searcher
-                );
-                ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
-            }
-
-            String parentValue = parentValues[random().nextInt(numUniqueParentValues)];
-            QueryBuilder queryBuilder;
-            if (random().nextBoolean()) {
-                queryBuilder = hasParentQuery("parent", termQuery("field1", parentValue));
-            } else {
-                queryBuilder = constantScoreQuery(hasParentQuery("parent", termQuery("field1", parentValue)));
-            }
-            // Using a FQ, will invoke / test the Scorer#advance(..) and also let the Weight#scorer not get live docs as acceptedDocs
-            queryBuilder = filteredQuery(queryBuilder, notQuery(termQuery("filter", "me")));
-            Query query = parseQuery(queryBuilder);
-            BitSetCollector collector = new BitSetCollector(indexReader.maxDoc());
-            searcher.search(query, collector);
-            FixedBitSet actualResult = collector.getResult();
-
-            FixedBitSet expectedResult = new FixedBitSet(indexReader.maxDoc());
-            if (parentValueToChildDocIds.containsKey(parentValue)) {
-                LeafReader slowLeafReader = SlowCompositeReaderWrapper.wrap(indexReader);
-                Terms terms = slowLeafReader.terms(UidFieldMapper.NAME);
-                if (terms != null) {
-                    NavigableSet<String> childIds = parentValueToChildDocIds.get(parentValue);
-                    TermsEnum termsEnum = terms.iterator();
-                    PostingsEnum docsEnum = null;
-                    for (String id : childIds) {
-                        TermsEnum.SeekStatus seekStatus = termsEnum.seekCeil(Uid.createUidAsBytes("child", id));
-                        if (seekStatus == TermsEnum.SeekStatus.FOUND) {
-                            docsEnum = termsEnum.postings(docsEnum, PostingsEnum.NONE);
-                            final Bits liveDocs = slowLeafReader.getLiveDocs();
-                            for (int doc = docsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = docsEnum.nextDoc()) {
-                                if (liveDocs == null || liveDocs.get(doc)) {
-                                    break;
-                                }
-                            }
-                            expectedResult.set(docsEnum.docID());
-                        } else if (seekStatus == TermsEnum.SeekStatus.END) {
-                            break;
-                        }
-                    }
-                }
-            }
-
-            assertBitSet(actualResult, expectedResult, searcher);
-        }
-
-        indexWriter.close();
-        indexReader.close();
-        directory.close();
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java
deleted file mode 100644
index ebc56be..0000000
--- a/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java
+++ /dev/null
@@ -1,249 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import com.carrotsearch.hppc.FloatArrayList;
-import com.carrotsearch.hppc.IntIntHashMap;
-import com.carrotsearch.hppc.ObjectObjectHashMap;
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.*;
-import org.apache.lucene.search.*;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util.LuceneTestCase;
-import org.elasticsearch.common.lease.Releasables;
-import org.elasticsearch.index.engine.Engine;
-import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
-import org.elasticsearch.index.mapper.Uid;
-import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
-import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
-import org.elasticsearch.index.mapper.internal.UidFieldMapper;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.test.TestSearchContext;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Map;
-import java.util.NavigableMap;
-import java.util.Random;
-import java.util.TreeMap;
-
-import static org.elasticsearch.index.query.QueryBuilders.*;
-
-public class ParentQueryTests extends AbstractChildTestCase {
-
-    @BeforeClass
-    public static void before() throws IOException {
-        SearchContext.setCurrent(createSearchContext("test", "parent", "child"));
-    }
-
-    @AfterClass
-    public static void after() throws IOException {
-        SearchContext current = SearchContext.current();
-        SearchContext.removeCurrent();
-        Releasables.close(current);
-    }
-
-    @Test
-    public void testBasicQuerySanities() {
-        Query parentQuery = new TermQuery(new Term("field", "value"));
-        ParentFieldMapper parentFieldMapper = SearchContext.current().mapperService().documentMapper("child").parentFieldMapper();
-        ParentChildIndexFieldData parentChildIndexFieldData = SearchContext.current().fieldData().getForField(parentFieldMapper.fieldType());
-        Filter childrenFilter = new QueryWrapperFilter(new TermQuery(new Term(TypeFieldMapper.NAME, "child")));
-        Query query = new ParentQuery(parentChildIndexFieldData, parentQuery, "parent", childrenFilter);
-        QueryUtils.check(query);
-    }
-
-    @Test
-    public void testRandom() throws Exception {
-        Directory directory = newDirectory();
-        final Random r = random();
-        final IndexWriterConfig iwc = LuceneTestCase.newIndexWriterConfig(r, new MockAnalyzer(r))
-                .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)
-                .setRAMBufferSizeMB(scaledRandomIntBetween(16, 64)); // we might index a lot - don't go crazy here
-        RandomIndexWriter indexWriter = new RandomIndexWriter(r, directory, iwc);
-        int numUniqueParentValues = scaledRandomIntBetween(100, 2000);
-        String[] parentValues = new String[numUniqueParentValues];
-        for (int i = 0; i < numUniqueParentValues; i++) {
-            parentValues[i] = Integer.toString(i);
-        }
-
-        int childDocId = 0;
-        int numParentDocs = scaledRandomIntBetween(1, numUniqueParentValues);
-        ObjectObjectHashMap<String, NavigableMap<String, Float>> parentValueToChildIds = new ObjectObjectHashMap<>();
-        IntIntHashMap childIdToParentId = new IntIntHashMap();
-        for (int parentDocId = 0; parentDocId < numParentDocs; parentDocId++) {
-            boolean markParentAsDeleted = rarely();
-            String parentValue = parentValues[random().nextInt(parentValues.length)];
-            String parent = Integer.toString(parentDocId);
-            Document document = new Document();
-            document.add(new StringField(UidFieldMapper.NAME, Uid.createUid("parent", parent), Field.Store.NO));
-            document.add(new StringField(TypeFieldMapper.NAME, "parent", Field.Store.NO));
-            document.add(new StringField("field1", parentValue, Field.Store.NO));
-            if (markParentAsDeleted) {
-                document.add(new StringField("delete", "me", Field.Store.NO));
-            }
-            indexWriter.addDocument(document);
-
-            int numChildDocs = scaledRandomIntBetween(0, 100);
-            if (parentDocId == numParentDocs - 1 && childIdToParentId.isEmpty()) {
-                // ensure there is at least one child in the index
-                numChildDocs = Math.max(1, numChildDocs);
-            }
-            for (int i = 0; i < numChildDocs; i++) {
-                String child = Integer.toString(childDocId++);
-                boolean markChildAsDeleted = rarely();
-                boolean filterMe = rarely();
-                document = new Document();
-                document.add(new StringField(UidFieldMapper.NAME, Uid.createUid("child", child), Field.Store.YES));
-                document.add(new StringField(TypeFieldMapper.NAME, "child", Field.Store.NO));
-                document.add(new StringField(ParentFieldMapper.NAME, Uid.createUid("parent", parent), Field.Store.NO));
-                if (markChildAsDeleted) {
-                    document.add(new StringField("delete", "me", Field.Store.NO));
-                }
-                if (filterMe) {
-                    document.add(new StringField("filter", "me", Field.Store.NO));
-                }
-                indexWriter.addDocument(document);
-
-                if (!markParentAsDeleted) {
-                    NavigableMap<String, Float> childIdToScore = parentValueToChildIds.getOrDefault(parentValue, null);
-                    if (childIdToScore == null) {
-                        parentValueToChildIds.put(parentValue, childIdToScore = new TreeMap<>());
-                    }
-                    if (!markChildAsDeleted && !filterMe) {
-                        assertFalse("child ["+ child + "] already has a score", childIdToScore.containsKey(child));
-                        childIdToScore.put(child, 1f);
-                        childIdToParentId.put(Integer.valueOf(child), parentDocId);
-                    }
-                }
-            }
-        }
-
-        // Delete docs that are marked to be deleted.
-        indexWriter.deleteDocuments(new Term("delete", "me"));
-        indexWriter.commit();
-
-        IndexReader indexReader = DirectoryReader.open(directory);
-        IndexSearcher searcher = new IndexSearcher(indexReader);
-        Engine.Searcher engineSearcher = new Engine.Searcher(
-                ParentQueryTests.class.getSimpleName(), searcher
-        );
-        ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
-
-        int max = numUniqueParentValues / 4;
-        for (int i = 0; i < max; i++) {
-            // Simulate a child update
-            if (random().nextBoolean()) {
-                int numberOfUpdates = childIdToParentId.isEmpty() ? 0 : scaledRandomIntBetween(1, 5);
-                int[] childIds = childIdToParentId.keys().toArray();
-                for (int j = 0; j < numberOfUpdates; j++) {
-                    int childId = childIds[random().nextInt(childIds.length)];
-                    String childUid = Uid.createUid("child", Integer.toString(childId));
-                    indexWriter.deleteDocuments(new Term(UidFieldMapper.NAME, childUid));
-
-                    Document document = new Document();
-                    document.add(new StringField(UidFieldMapper.NAME, childUid, Field.Store.YES));
-                    document.add(new StringField(TypeFieldMapper.NAME, "child", Field.Store.NO));
-                    String parentUid = Uid.createUid("parent", Integer.toString(childIdToParentId.get(childId)));
-                    document.add(new StringField(ParentFieldMapper.NAME, parentUid, Field.Store.NO));
-                    indexWriter.addDocument(document);
-                }
-
-                indexReader.close();
-                indexReader = DirectoryReader.open(indexWriter.w, true);
-                searcher = new IndexSearcher(indexReader);
-                engineSearcher = new Engine.Searcher(
-                        ParentConstantScoreQueryTests.class.getSimpleName(), searcher
-                );
-                ((TestSearchContext) SearchContext.current()).setSearcher(engineSearcher);
-            }
-
-            String parentValue = parentValues[random().nextInt(numUniqueParentValues)];
-            QueryBuilder queryBuilder = hasParentQuery("parent", constantScoreQuery(termQuery("field1", parentValue)));
-            // Using a FQ, will invoke / test the Scorer#advance(..) and also let the Weight#scorer not get live docs as acceptedDocs
-            queryBuilder = filteredQuery(queryBuilder, notQuery(termQuery("filter", "me")));
-            Query query = parseQuery(queryBuilder);
-
-            BitSetCollector collector = new BitSetCollector(indexReader.maxDoc());
-            int numHits = 1 + random().nextInt(25);
-            TopScoreDocCollector actualTopDocsCollector = TopScoreDocCollector.create(numHits);
-            searcher.search(query, MultiCollector.wrap(collector, actualTopDocsCollector));
-            FixedBitSet actualResult = collector.getResult();
-
-            FixedBitSet expectedResult = new FixedBitSet(indexReader.maxDoc());
-            TopScoreDocCollector expectedTopDocsCollector = TopScoreDocCollector.create(numHits);
-            if (parentValueToChildIds.containsKey(parentValue)) {
-                LeafReader slowLeafReader = SlowCompositeReaderWrapper.wrap(indexReader);
-                final FloatArrayList[] scores = new FloatArrayList[slowLeafReader.maxDoc()];
-                Terms terms = slowLeafReader.terms(UidFieldMapper.NAME);
-                if (terms != null) {
-                    NavigableMap<String, Float> childIdsAndScore = parentValueToChildIds.get(parentValue);
-                    TermsEnum termsEnum = terms.iterator();
-                    PostingsEnum docsEnum = null;
-                    for (Map.Entry<String, Float> entry : childIdsAndScore.entrySet()) {
-                        TermsEnum.SeekStatus seekStatus = termsEnum.seekCeil(Uid.createUidAsBytes("child", entry.getKey()));
-                        if (seekStatus == TermsEnum.SeekStatus.FOUND) {
-                            docsEnum = termsEnum.postings(docsEnum, PostingsEnum.NONE);
-                            final Bits liveDocs = slowLeafReader.getLiveDocs();
-                            for (int doc = docsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = docsEnum.nextDoc()) {
-                                if (liveDocs == null || liveDocs.get(doc)) {
-                                    break;
-                                }
-                            }
-                            expectedResult.set(docsEnum.docID());
-                            FloatArrayList s = scores[docsEnum.docID()];
-                            if (s == null) {
-                                scores[docsEnum.docID()] = s = new FloatArrayList(2);
-                            }
-                            s.add(entry.getValue());
-                        } else if (seekStatus == TermsEnum.SeekStatus.END) {
-                            break;
-                        }
-                    }
-                }
-                MockScorer mockScorer = new MockScorer(ScoreType.MAX);
-                mockScorer.scores = new FloatArrayList();
-                final LeafCollector leafCollector = expectedTopDocsCollector.getLeafCollector(slowLeafReader.getContext());
-                leafCollector.setScorer(mockScorer);
-                for (int doc = expectedResult.nextSetBit(0); doc < slowLeafReader.maxDoc(); doc = doc + 1 >= expectedResult.length() ? DocIdSetIterator.NO_MORE_DOCS : expectedResult.nextSetBit(doc + 1)) {
-                    mockScorer.scores.clear();
-                    mockScorer.scores.addAll(scores[doc]);
-                    leafCollector.collect(doc);
-                }
-            }
-
-            assertBitSet(actualResult, expectedResult, searcher);
-            assertTopDocs(actualTopDocsCollector.topDocs(), expectedTopDocsCollector.topDocs());
-        }
-
-        indexWriter.close();
-        indexReader.close();
-        directory.close();
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/index/search/child/ScoreTypeTests.java b/core/src/test/java/org/elasticsearch/index/search/child/ScoreTypeTests.java
deleted file mode 100644
index de74b53..0000000
--- a/core/src/test/java/org/elasticsearch/index/search/child/ScoreTypeTests.java
+++ /dev/null
@@ -1,73 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.search.child;
-
-import org.elasticsearch.test.ESTestCase;
-import org.junit.Test;
-
-import static org.hamcrest.MatcherAssert.assertThat;
-import static org.hamcrest.Matchers.equalTo;
-
-/**
- * Tests {@link ScoreType} to ensure backward compatibility of any changes.
- */
-public class ScoreTypeTests extends ESTestCase {
-    @Test
-    public void minFromString() {
-        assertThat("fromString(min) != MIN", ScoreType.MIN, equalTo(ScoreType.fromString("min")));
-    }
-
-    @Test
-    public void maxFromString() {
-        assertThat("fromString(max) != MAX", ScoreType.MAX, equalTo(ScoreType.fromString("max")));
-    }
-
-    @Test
-    public void avgFromString() {
-        assertThat("fromString(avg) != AVG", ScoreType.AVG, equalTo(ScoreType.fromString("avg")));
-    }
-
-    @Test
-    public void sumFromString() {
-        assertThat("fromString(sum) != SUM", ScoreType.SUM, equalTo(ScoreType.fromString("sum")));
-        // allowed for consistency with ScoreMode.Total:
-        assertThat("fromString(total) != SUM", ScoreType.SUM, equalTo(ScoreType.fromString("total")));
-    }
-
-    @Test
-    public void noneFromString() {
-        assertThat("fromString(none) != NONE", ScoreType.NONE, equalTo(ScoreType.fromString("none")));
-    }
-
-    /**
-     * Should throw {@link IllegalArgumentException} instead of NPE.
-     */
-    @Test(expected = IllegalArgumentException.class)
-    public void nullFromString_throwsException() {
-        ScoreType.fromString(null);
-    }
-
-    /**
-     * Failure should not change (and the value should never match anything...).
-     */
-    @Test(expected = IllegalArgumentException.class)
-    public void unrecognizedFromString_throwsException() {
-        ScoreType.fromString("unrecognized value");
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
index 81493c5..0bedb81 100644
--- a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
+++ b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
@@ -86,9 +86,10 @@ import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_VERSION_CREATED;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.elasticsearch.common.xcontent.ToXContent.EMPTY_PARAMS;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
 import static org.hamcrest.Matchers.equalTo;
 
 /**
diff --git a/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java b/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java
index fcba11a..7727d8c 100644
--- a/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java
+++ b/core/src/test/java/org/elasticsearch/indices/IndicesModuleTests.java
@@ -23,7 +23,10 @@ import org.apache.lucene.analysis.hunspell.Dictionary;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.common.inject.ModuleTestCase;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.QueryParser;
+import org.elasticsearch.index.query.QueryParsingException;
+import org.elasticsearch.index.query.TermQueryParser;
 
 import java.io.IOException;
 import java.io.InputStream;
@@ -36,19 +39,8 @@ public class IndicesModuleTests extends ModuleTestCase {
         public String[] names() {
             return new String[] {"fake-query-parser"};
         }
-
-        @Override
-        public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
-            return null;
-        }
-
-        @Override
-        public Query parse(QueryShardContext context) throws IOException, QueryParsingException {
-            return null;
-        }
-
         @Override
-        public QueryBuilder getBuilderPrototype() {
+        public Query parse(QueryParseContext parseContext) throws IOException, QueryParsingException {
             return null;
         }
     }
diff --git a/core/src/test/java/org/elasticsearch/indices/template/template0.json b/core/src/test/java/org/elasticsearch/indices/template/template0.json
deleted file mode 100644
index af055fd..0000000
--- a/core/src/test/java/org/elasticsearch/indices/template/template0.json
+++ /dev/null
@@ -1,11 +0,0 @@
-{
-    "template" : "foo*",
-    "order" : 10,
-    "settings" : {
-        "index.number_of_shards": 10,
-        "index.number_of_replicas": 0
-    },
-    "aliases" : {
-        "{index}-alias" : {}
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/indices/template/template1.json b/core/src/test/java/org/elasticsearch/indices/template/template1.json
deleted file mode 100644
index 030fb54..0000000
--- a/core/src/test/java/org/elasticsearch/indices/template/template1.json
+++ /dev/null
@@ -1,11 +0,0 @@
-{
-    "template" : "foo*",
-    "order" : 10,
-    "settings" : {
-        "number_of_shards": 10,
-        "number_of_replicas": 0
-    },
-    "aliases" : {
-        "{index}-alias" : {}
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/indices/template/template2.json b/core/src/test/java/org/elasticsearch/indices/template/template2.json
deleted file mode 100644
index d4a376c..0000000
--- a/core/src/test/java/org/elasticsearch/indices/template/template2.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-    "template" : "foo*",
-    "order" : 10,
-    "settings" : {
-        "index" : {
-            "number_of_shards": 10,
-            "number_of_replicas": 0
-        }
-    },
-    "aliases" : {
-        "{index}-alias" : {}
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/indices/template/template3.json b/core/src/test/java/org/elasticsearch/indices/template/template3.json
deleted file mode 100644
index 7231a6e..0000000
--- a/core/src/test/java/org/elasticsearch/indices/template/template3.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-    "mytemplate" : {
-        "template" : "foo*",
-        "order" : 10,
-        "settings" : {
-            "index.number_of_shards": 10,
-            "index.number_of_replicas": 0
-        },
-        "aliases" : {
-            "{index}-alias" : {}
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/indices/template/template4.json b/core/src/test/java/org/elasticsearch/indices/template/template4.json
deleted file mode 100644
index 52dcaa6..0000000
--- a/core/src/test/java/org/elasticsearch/indices/template/template4.json
+++ /dev/null
@@ -1,13 +0,0 @@
-{
-    "mytemplate" : {
-        "template" : "foo*",
-        "order" : 10,
-        "settings" : {
-            "number_of_shards": 10,
-            "number_of_replicas": 0
-        },
-        "aliases" : {
-            "{index}-alias" : {}
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/indices/template/template5.json b/core/src/test/java/org/elasticsearch/indices/template/template5.json
deleted file mode 100644
index 803bec0..0000000
--- a/core/src/test/java/org/elasticsearch/indices/template/template5.json
+++ /dev/null
@@ -1,15 +0,0 @@
-{
-    "mytemplate" : {
-        "template" : "foo*",
-        "order" : 10,
-        "settings" : {
-            "index" : {
-                "number_of_shards": 10,
-                "number_of_replicas": 0
-            }
-        },
-        "aliases" : {
-            "{index}-alias" : {}
-        }
-    }
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/node/MockNode.java b/core/src/test/java/org/elasticsearch/node/MockNode.java
index 0476264..c5592fe 100644
--- a/core/src/test/java/org/elasticsearch/node/MockNode.java
+++ b/core/src/test/java/org/elasticsearch/node/MockNode.java
@@ -38,8 +38,8 @@ public class MockNode extends Node {
     private Version version;
     private Collection<Class<? extends Plugin>> plugins;
 
-    public MockNode(Settings settings, boolean loadConfigSettings, Version version, Collection<Class<? extends Plugin>> classpathPlugins) {
-        super(settings, loadConfigSettings, version, classpathPlugins);
+    public MockNode(Settings settings, Version version, Collection<Class<? extends Plugin>> classpathPlugins) {
+        super(settings, version, classpathPlugins);
         this.version = version;
         this.plugins = classpathPlugins;
     }
diff --git a/core/src/test/java/org/elasticsearch/node/internal/InternalSettingsPreparerTests.java b/core/src/test/java/org/elasticsearch/node/internal/InternalSettingsPreparerTests.java
index b5bd800..4cd61eb 100644
--- a/core/src/test/java/org/elasticsearch/node/internal/InternalSettingsPreparerTests.java
+++ b/core/src/test/java/org/elasticsearch/node/internal/InternalSettingsPreparerTests.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.node.internal;
 
+import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.common.cli.CliToolTestCase;
 import org.elasticsearch.common.cli.Terminal;
 import org.elasticsearch.common.collect.Tuple;
@@ -28,58 +29,113 @@ import org.elasticsearch.env.Environment;
 import org.elasticsearch.test.ESTestCase;
 import org.junit.After;
 import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.ExpectedException;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.util.ArrayList;
+import java.util.HashMap;
 import java.util.List;
+import java.util.Map;
 import java.util.concurrent.atomic.AtomicInteger;
 
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.hamcrest.Matchers.*;
 
 public class InternalSettingsPreparerTests extends ESTestCase {
-    @Rule
-    public ExpectedException expectedException = ExpectedException.none();
+
+    Map<String, String> savedProperties = new HashMap<>();
+    Settings baseEnvSettings;
 
     @Before
-    public void setupSystemProperties() {
-        System.setProperty("es.node.zone", "foo");
-        System.setProperty("name", "sys-prop-name");
+    public void saveSettingsSystemProperties() {
+        // clear out any properties the settings preparer may look for
+        savedProperties.clear();
+        for (Object propObj : System.getProperties().keySet()) {
+            String property = (String)propObj;
+            // NOTE: these prefixes are prefixes of the defaults, so both are handled here
+            for (String prefix : InternalSettingsPreparer.PROPERTY_PREFIXES) {
+                if (property.startsWith(prefix)) {
+                    savedProperties.put(property, System.getProperty(property));
+                }
+            }
+        }
+        String name = System.getProperty("name");
+        if (name != null) {
+            savedProperties.put("name", name);
+        }
+        for (String property : savedProperties.keySet()) {
+            System.clearProperty(property);
+        }
     }
 
     @After
-    public void cleanupSystemProperties() {
-        System.clearProperty("es.node.zone");
-        System.clearProperty("name");
+    public void restoreSettingsSystemProperties() {
+        for (Map.Entry<String, String> property : savedProperties.entrySet()) {
+            System.setProperty(property.getKey(), property.getValue());
+        }
+    }
+
+    @Before
+    public void createBaseEnvSettings() {
+        baseEnvSettings = settingsBuilder()
+            .put("path.home", createTempDir())
+            .build();
+    }
+
+    @After
+    public void clearBaseEnvSettings() {
+        baseEnvSettings = null;
+    }
+
+    public void testEmptySettings() {
+        Settings settings = InternalSettingsPreparer.prepareSettings(Settings.EMPTY);
+        assertNotNull(settings.get("name")); // a name was set
+        assertNotNull(settings.get(ClusterName.SETTING)); // a cluster name was set
+        assertEquals(settings.toString(), 2, settings.names().size());
+
+        Environment env = InternalSettingsPreparer.prepareEnvironment(baseEnvSettings, null);
+        settings = env.settings();
+        assertNotNull(settings.get("name")); // a name was set
+        assertNotNull(settings.get(ClusterName.SETTING)); // a cluster name was set
+        assertEquals(settings.toString(), 3 /* path.home is in the base settings */, settings.names().size());
+        String home = baseEnvSettings.get("path.home");
+        String configDir = env.configFile().toString();
+        assertTrue(configDir, configDir.startsWith(home));
+    }
+
+    public void testClusterNameDefault() {
+        Settings settings = InternalSettingsPreparer.prepareSettings(Settings.EMPTY);
+        assertEquals(ClusterName.DEFAULT.value(), settings.get(ClusterName.SETTING));
+        settings = InternalSettingsPreparer.prepareEnvironment(baseEnvSettings, null).settings();
+        assertEquals(ClusterName.DEFAULT.value(), settings.get(ClusterName.SETTING));
     }
 
-    @Test
     public void testIgnoreSystemProperties() {
-        Settings settings = settingsBuilder()
+        try {
+            System.setProperty("es.node.zone", "foo");
+            Settings settings = settingsBuilder()
                 .put("node.zone", "bar")
-                .put("path.home", createTempDir().toString())
+                .put(baseEnvSettings)
                 .build();
-        Tuple<Settings, Environment> tuple = InternalSettingsPreparer.prepareSettings(settings, true);
-        // Should use setting from the system property
-        assertThat(tuple.v1().get("node.zone"), equalTo("foo"));
+            Environment env = InternalSettingsPreparer.prepareEnvironment(settings, null);
+            // Should use setting from the system property
+            assertThat(env.settings().get("node.zone"), equalTo("foo"));
 
-        settings = settingsBuilder()
+            settings = settingsBuilder()
                 .put(InternalSettingsPreparer.IGNORE_SYSTEM_PROPERTIES_SETTING, true)
                 .put("node.zone", "bar")
-                .put("path.home", createTempDir().toString())
+                .put(baseEnvSettings)
                 .build();
-        tuple = InternalSettingsPreparer.prepareSettings(settings, true);
-        // Should use setting from the system property
-        assertThat(tuple.v1().get("node.zone"), equalTo("bar"));
+            env = InternalSettingsPreparer.prepareEnvironment(settings, null);
+            // Should use setting from the system property
+            assertThat(env.settings().get("node.zone"), equalTo("bar"));
+        } finally {
+            System.clearProperty("es.node.zone");
+        }
     }
 
-    @Test
     public void testReplacePromptPlaceholders() {
         final List<String> replacedSecretProperties = new ArrayList<>();
         final List<String> replacedTextProperties = new ArrayList<>();
@@ -102,6 +158,7 @@ public class InternalSettingsPreparerTests extends ESTestCase {
         };
 
         Settings.Builder builder = settingsBuilder()
+                .put(baseEnvSettings)
                 .put("password.replace", InternalSettingsPreparer.SECRET_PROMPT_VALUE)
                 .put("dont.replace", "prompt:secret")
                 .put("dont.replace2", "_prompt:secret_")
@@ -109,8 +166,7 @@ public class InternalSettingsPreparerTests extends ESTestCase {
                 .put("dont.replace4", "__prompt:text_")
                 .put("dont.replace5", "prompt:secret__")
                 .put("replace_me", InternalSettingsPreparer.TEXT_PROMPT_VALUE);
-        Settings settings = builder.build();
-        settings = InternalSettingsPreparer.replacePromptPlaceholders(settings, terminal);
+        Settings settings = InternalSettingsPreparer.prepareEnvironment(builder.build(), terminal).settings();
 
         assertThat(replacedSecretProperties.size(), is(1));
         assertThat(replacedTextProperties.size(), is(1));
@@ -125,70 +181,70 @@ public class InternalSettingsPreparerTests extends ESTestCase {
         assertThat(settings.get("dont.replace5"), equalTo("prompt:secret__"));
     }
 
-    @Test
     public void testReplaceSecretPromptPlaceholderWithNullTerminal() {
         Settings.Builder builder = settingsBuilder()
+                .put(baseEnvSettings)
                 .put("replace_me1", InternalSettingsPreparer.SECRET_PROMPT_VALUE);
         try {
-            InternalSettingsPreparer.replacePromptPlaceholders(builder.build(), null);
+            InternalSettingsPreparer.prepareEnvironment(builder.build(), null);
             fail("an exception should have been thrown since no terminal was provided!");
         } catch (UnsupportedOperationException e) {
             assertThat(e.getMessage(), containsString("with value [" + InternalSettingsPreparer.SECRET_PROMPT_VALUE + "]"));
         }
     }
 
-    @Test
     public void testReplaceTextPromptPlaceholderWithNullTerminal() {
         Settings.Builder builder = settingsBuilder()
+                .put(baseEnvSettings)
                 .put("replace_me1", InternalSettingsPreparer.TEXT_PROMPT_VALUE);
         try {
-            InternalSettingsPreparer.replacePromptPlaceholders(builder.build(), null);
+            InternalSettingsPreparer.prepareEnvironment(builder.build(), null);
             fail("an exception should have been thrown since no terminal was provided!");
         } catch (UnsupportedOperationException e) {
             assertThat(e.getMessage(), containsString("with value [" + InternalSettingsPreparer.TEXT_PROMPT_VALUE + "]"));
         }
     }
 
-    @Test
     public void testNameSettingsPreference() {
-        // Test system property overrides node.name
-        Settings settings = settingsBuilder()
+        try {
+            System.setProperty("name", "sys-prop-name");
+            // Test system property overrides node.name
+            Settings settings = settingsBuilder()
                 .put("node.name", "node-name")
-                .put("path.home", createTempDir().toString())
+                .put(baseEnvSettings)
                 .build();
-        Tuple<Settings, Environment> tuple = InternalSettingsPreparer.prepareSettings(settings, true);
-        assertThat(tuple.v1().get("name"), equalTo("sys-prop-name"));
+            Environment env = InternalSettingsPreparer.prepareEnvironment(settings, null);
+            assertThat(env.settings().get("name"), equalTo("sys-prop-name"));
 
-        // test name in settings overrides sys prop and node.name
-        settings = settingsBuilder()
+            // test name in settings overrides sys prop and node.name
+            settings = settingsBuilder()
                 .put("name", "name-in-settings")
                 .put("node.name", "node-name")
-                .put("path.home", createTempDir().toString())
+                .put(baseEnvSettings)
                 .build();
-        tuple = InternalSettingsPreparer.prepareSettings(settings, true);
-        assertThat(tuple.v1().get("name"), equalTo("name-in-settings"));
+            env = InternalSettingsPreparer.prepareEnvironment(settings, null);
+            assertThat(env.settings().get("name"), equalTo("name-in-settings"));
 
-        // test only node.name in settings
-        System.clearProperty("name");
-        settings = settingsBuilder()
+            // test only node.name in settings
+            System.clearProperty("name");
+            settings = settingsBuilder()
                 .put("node.name", "node-name")
-                .put("path.home", createTempDir().toString())
+                .put(baseEnvSettings)
                 .build();
-        tuple = InternalSettingsPreparer.prepareSettings(settings, true);
-        assertThat(tuple.v1().get("name"), equalTo("node-name"));
+            env = InternalSettingsPreparer.prepareEnvironment(settings, null);
+            assertThat(env.settings().get("name"), equalTo("node-name"));
 
-        // test no name at all results in name being set
-        settings = settingsBuilder()
-                .put("path.home", createTempDir().toString())
-                .build();
-        tuple = InternalSettingsPreparer.prepareSettings(settings, true);
-        assertThat(tuple.v1().get("name"), not("name-in-settings"));
-        assertThat(tuple.v1().get("name"), not("sys-prop-name"));
-        assertThat(tuple.v1().get("name"), not("node-name"));
-        assertThat(tuple.v1().get("name"), notNullValue());
+            // test no name at all results in name being set
+            env = InternalSettingsPreparer.prepareEnvironment(baseEnvSettings, null);
+            assertThat(env.settings().get("name"), not("name-in-settings"));
+            assertThat(env.settings().get("name"), not("sys-prop-name"));
+            assertThat(env.settings().get("name"), not("node-name"));
+            assertThat(env.settings().get("name"), notNullValue());
+        } finally {
+            System.clearProperty("name");
+        }
     }
 
-    @Test
     public void testPromptForNodeNameOnlyPromptsOnce() {
         final AtomicInteger counter = new AtomicInteger();
         final Terminal terminal = new CliToolTestCase.MockTerminal() {
@@ -207,27 +263,30 @@ public class InternalSettingsPreparerTests extends ESTestCase {
 
         System.clearProperty("name");
         Settings settings = Settings.builder()
-                .put("path.home", createTempDir())
+                .put(baseEnvSettings)
                 .put("node.name", InternalSettingsPreparer.TEXT_PROMPT_VALUE)
                 .build();
-        Tuple<Settings, Environment> tuple = InternalSettingsPreparer.prepareSettings(settings, false, terminal);
-        settings = tuple.v1();
+        Environment env = InternalSettingsPreparer.prepareEnvironment(settings, terminal);
+        settings = env.settings();
         assertThat(counter.intValue(), is(1));
         assertThat(settings.get("name"), is("prompted name 0"));
         assertThat(settings.get("node.name"), is("prompted name 0"));
     }
 
-    @Test(expected = SettingsException.class)
     public void testGarbageIsNotSwallowed() throws IOException {
-        InputStream garbage = getClass().getResourceAsStream("/config/garbage/garbage.yml");
-        Path home = createTempDir();
-        Path config = home.resolve("config");
-        Files.createDirectory(config);
-        Files.copy(garbage, config.resolve("elasticsearch.yml"));
-        InternalSettingsPreparer.prepareSettings(settingsBuilder()
+        try {
+            InputStream garbage = getClass().getResourceAsStream("/config/garbage/garbage.yml");
+            Path home = createTempDir();
+            Path config = home.resolve("config");
+            Files.createDirectory(config);
+            Files.copy(garbage, config.resolve("elasticsearch.yml"));
+            InternalSettingsPreparer.prepareEnvironment(settingsBuilder()
                 .put("config.ignore_system_properties", true)
-                .put("path.home", home)
-                .build(), true);
+                .put(baseEnvSettings)
+                .build(), null);
+        } catch (SettingsException e) {
+            assertEquals("Failed to load settings from [elasticsearch.yml]", e.getMessage());
+        }
     }
 
     public void testMultipleSettingsFileNotAllowed() throws IOException {
@@ -239,14 +298,15 @@ public class InternalSettingsPreparerTests extends ESTestCase {
         Files.copy(yaml, config.resolve("elasticsearch.yaml"));
         Files.copy(properties, config.resolve("elasticsearch.properties"));
 
-        expectedException.expect(SettingsException.class);
-        expectedException.expectMessage("multiple settings files found with suffixes: ");
-        expectedException.expectMessage("yaml");
-        expectedException.expectMessage("properties");
-
-        InternalSettingsPreparer.prepareSettings(settingsBuilder()
+        try {
+            InternalSettingsPreparer.prepareEnvironment(settingsBuilder()
                 .put("config.ignore_system_properties", true)
-                .put("path.home", home)
-                .build(), true);
+                .put(baseEnvSettings)
+                .build(), null);
+        } catch (SettingsException e) {
+            assertTrue(e.getMessage(), e.getMessage().contains("multiple settings files found with suffixes"));
+            assertTrue(e.getMessage(), e.getMessage().contains(".yaml"));
+            assertTrue(e.getMessage(), e.getMessage().contains(".properties"));
+        }
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java b/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java
index cb64437..77a4b63 100644
--- a/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java
@@ -26,7 +26,6 @@ import org.elasticsearch.client.Requests;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.MatchQueryBuilder;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
@@ -361,7 +360,7 @@ public class MultiPercolatorIT extends ESIntegTestCase {
         ensureGreen("nestedindex");
 
         client().prepareIndex("nestedindex", PercolatorService.TYPE_NAME, "Q").setSource(jsonBuilder().startObject()
-                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(Operator.AND)).scoreMode("avg")).endObject()).get();
+                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(MatchQueryBuilder.Operator.AND)).scoreMode("avg")).endObject()).get();
 
         refresh();
 
diff --git a/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java b/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java
index f250e92..ecee193 100644
--- a/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/PercolatorBackwardsCompatibilityIT.java
@@ -23,8 +23,8 @@ import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.percolate.PercolateResponse;
 import org.elasticsearch.action.percolate.PercolateSourceBuilder;
 import org.elasticsearch.index.percolator.PercolatorException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.test.ESIntegTestCase;
-import org.elasticsearch.index.query.QueryShardException;
 import org.junit.Test;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
@@ -67,7 +67,7 @@ public class PercolatorBackwardsCompatibilityIT extends ESIntegTestCase {
             fail();
         } catch (PercolatorException e) {
             e.printStackTrace();
-            assertThat(e.getRootCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getRootCause(), instanceOf(QueryParsingException.class));
         }
     }
 
diff --git a/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java b/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
index 4c57385..fb37a0d 100644
--- a/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
@@ -41,11 +41,11 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.engine.DocumentMissingException;
 import org.elasticsearch.index.engine.VersionConflictEngineException;
 import org.elasticsearch.index.percolator.PercolatorException;
-import org.elasticsearch.index.query.Operator;
+import org.elasticsearch.index.query.MatchQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.index.query.functionscore.factor.FactorBuilder;
-import org.elasticsearch.index.query.support.QueryInnerHits;
+import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.highlight.HighlightBuilder;
@@ -1764,7 +1764,7 @@ public class PercolatorIT extends ESIntegTestCase {
                     .get();
             fail();
         } catch (PercolatorException e) {
-            assertThat(e.getRootCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getRootCause(), instanceOf(QueryParsingException.class));
         }
 
         try {
@@ -1773,7 +1773,7 @@ public class PercolatorIT extends ESIntegTestCase {
                     .get();
             fail();
         } catch (PercolatorException e) {
-            assertThat(e.getRootCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getRootCause(), instanceOf(QueryParsingException.class));
         }
     }
 
@@ -1812,7 +1812,7 @@ public class PercolatorIT extends ESIntegTestCase {
         ensureGreen("nestedindex");
 
         client().prepareIndex("nestedindex", PercolatorService.TYPE_NAME, "Q").setSource(jsonBuilder().startObject()
-                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(Operator.AND)).scoreMode("avg")).endObject()).get();
+                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(MatchQueryBuilder.Operator.AND)).scoreMode("avg")).endObject()).get();
 
         refresh();
 
@@ -2012,11 +2012,11 @@ public class PercolatorIT extends ESIntegTestCase {
         assertAcked(prepareCreate("index").addMapping("mapping", mapping));
         try {
             client().prepareIndex("index", PercolatorService.TYPE_NAME, "1")
-                    .setSource(jsonBuilder().startObject().field("query", nestedQuery("nested", matchQuery("nested.name", "value")).innerHit(new QueryInnerHits())).endObject())
+                    .setSource(jsonBuilder().startObject().field("query", nestedQuery("nested", matchQuery("nested.name", "value")).innerHit(new QueryInnerHitBuilder())).endObject())
                     .execute().actionGet();
             fail("Expected a parse error, because inner_hits isn't supported in the percolate api");
         } catch (Exception e) {
-            assertThat(e.getCause(), instanceOf(QueryShardException.class));
+            assertThat(e.getCause(), instanceOf(QueryParsingException.class));
             assertThat(e.getCause().getMessage(), containsString("inner_hits unsupported"));
         }
     }
diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java b/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java
index d379822..6a32359 100644
--- a/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java
+++ b/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java
@@ -88,18 +88,18 @@ import static org.jboss.netty.handler.codec.http.HttpVersion.HTTP_1_1;
 // if its in your classpath, then do not use plugins!!!!!!
 public class PluginManagerIT extends ESIntegTestCase {
 
-    private Tuple<Settings, Environment> initialSettings;
+    private Environment environment;
     private CaptureOutputTerminal terminal = new CaptureOutputTerminal();
 
     @Before
     public void setup() throws Exception {
-        initialSettings = buildInitialSettings();
-        System.setProperty("es.default.path.home", initialSettings.v1().get("path.home"));
-        Path binDir = initialSettings.v2().binFile();
+        environment = buildInitialSettings();
+        System.setProperty("es.default.path.home", environment.settings().get("path.home"));
+        Path binDir = environment.binFile();
         if (!Files.exists(binDir)) {
             Files.createDirectories(binDir);
         }
-        Path configDir = initialSettings.v2().configFile();
+        Path configDir = environment.configFile();
         if (!Files.exists(configDir)) {
             Files.createDirectories(configDir);
         }
@@ -206,11 +206,10 @@ public class PluginManagerIT extends ESIntegTestCase {
             "jvm", "true",
             "classname", "FakePlugin");
 
-        Environment env = initialSettings.v2();
-        Path binDir = env.binFile();
+        Path binDir = environment.binFile();
         Path pluginBinDir = binDir.resolve(pluginName);
 
-        Path pluginConfigDir = env.configFile().resolve(pluginName);
+        Path pluginConfigDir = environment.configFile().resolve(pluginName);
         assertStatusOk("install " + pluginUrl + " --verbose");
 
         terminal.getTerminalOutput().clear();
@@ -252,8 +251,7 @@ public class PluginManagerIT extends ESIntegTestCase {
             "jvm", "true",
             "classname", "FakePlugin");
 
-        Environment env = initialSettings.v2();
-        Path pluginConfigDir = env.configFile().resolve(pluginName);
+        Path pluginConfigDir = environment.configFile().resolve(pluginName);
 
         assertStatusOk(String.format(Locale.ROOT, "install %s --verbose", pluginUrl));
 
@@ -355,8 +353,7 @@ public class PluginManagerIT extends ESIntegTestCase {
             "jvm", "true",
             "classname", "FakePlugin");
 
-        Environment env = initialSettings.v2();
-        Path binDir = env.binFile();
+        Path binDir = environment.binFile();
         Path pluginBinDir = binDir.resolve(pluginName);
 
         assertStatusOk(String.format(Locale.ROOT, "install %s --verbose", pluginUrl));
@@ -372,7 +369,7 @@ public class PluginManagerIT extends ESIntegTestCase {
 
     @Test
     public void testListInstalledEmptyWithExistingPluginDirectory() throws IOException {
-        Files.createDirectory(initialSettings.v2().pluginsFile());
+        Files.createDirectory(environment.pluginsFile());
         assertStatusOk("list");
         assertThat(terminal.getTerminalOutput(), hasItem(containsString("No plugin detected")));
     }
@@ -407,7 +404,7 @@ public class PluginManagerIT extends ESIntegTestCase {
         assertStatusOk(String.format(Locale.ROOT, "install %s --verbose", pluginUrl));
         assertThatPluginIsListed(pluginName);
         // We want to check that Plugin Manager moves content to _site
-        assertFileExists(initialSettings.v2().pluginsFile().resolve(pluginName).resolve("_site"));
+        assertFileExists(environment.pluginsFile().resolve(pluginName).resolve("_site"));
     }
 
     @Test
@@ -423,7 +420,7 @@ public class PluginManagerIT extends ESIntegTestCase {
         assertStatus(String.format(Locale.ROOT, "install %s --verbose", pluginUrl),
                 ExitStatus.IO_ERROR);
         assertThatPluginIsNotListed(pluginName);
-        assertFileNotExists(initialSettings.v2().pluginsFile().resolve(pluginName).resolve("_site"));
+        assertFileNotExists(environment.pluginsFile().resolve(pluginName).resolve("_site"));
     }
 
     private void singlePluginInstallAndRemove(String pluginDescriptor, String pluginName, String pluginCoordinates) throws IOException {
@@ -648,11 +645,11 @@ public class PluginManagerIT extends ESIntegTestCase {
 
 
 
-    private Tuple<Settings, Environment> buildInitialSettings() throws IOException {
+    private Environment buildInitialSettings() throws IOException {
         Settings settings = settingsBuilder()
                 .put("http.enabled", true)
                 .put("path.home", createTempDir()).build();
-        return InternalSettingsPreparer.prepareSettings(settings, false);
+        return InternalSettingsPreparer.prepareEnvironment(settings, null);
     }
 
     private void assertStatusOk(String command) {
diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java b/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java
index c497c1a..d4553bd 100644
--- a/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java
+++ b/core/src/test/java/org/elasticsearch/plugins/PluginsServiceTests.java
@@ -57,7 +57,7 @@ public class PluginsServiceTests extends ESTestCase {
     }
 
     static PluginsService newPluginsService(Settings settings, Class<? extends Plugin>... classpathPlugins) {
-        return new PluginsService(settings, new Environment(settings), Arrays.asList(classpathPlugins));
+        return new PluginsService(settings, new Environment(settings).pluginsFile(), Arrays.asList(classpathPlugins));
     }
 
     public void testAdditionalSettings() {
diff --git a/core/src/test/java/org/elasticsearch/plugins/loading/classpath/es-plugin-test.properties b/core/src/test/java/org/elasticsearch/plugins/loading/classpath/es-plugin-test.properties
deleted file mode 100644
index f57bea5..0000000
--- a/core/src/test/java/org/elasticsearch/plugins/loading/classpath/es-plugin-test.properties
+++ /dev/null
@@ -1,19 +0,0 @@
-################################################################
-# Licensed to Elasticsearch under one or more contributor
-# license agreements. See the NOTICE file distributed with
-# this work for additional information regarding copyright
-# ownership. Elasticsearch licenses this file to you under
-# the Apache License, Version 2.0 (the "License"); you may
-# not use this file except in compliance  with the License.
-# You may obtain a copy of the License at
-#
-#    http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing,
-# software distributed under the License is distributed on an
-# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-# KIND, either express or implied.  See the License for the
-# specific language governing permissions and limitations
-# under the License.
-################################################################
-plugin=org.elasticsearch.plugins.loading.classpath.InClassPathPlugin
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java
index 26cb3a9..27bfab0 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java
@@ -29,7 +29,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.QueryShardException;
+import org.elasticsearch.index.query.QueryParsingException;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.ScriptModule;
@@ -237,7 +237,7 @@ public class SignificantTermsSignificanceScoreIT extends ESIntegTestCase {
 
             @Override
             public SignificanceHeuristic parse(XContentParser parser, ParseFieldMatcher parseFieldMatcher, SearchContext context)
-                    throws IOException, QueryShardException {
+                    throws IOException, QueryParsingException {
                 parser.nextToken();
                 return new SimpleHeuristic();
             }
@@ -621,4 +621,4 @@ public class SignificantTermsSignificanceScoreIT extends ESIntegTestCase {
         }
         indexRandom(true, indexRequestBuilderList);
     }
-}
+}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/agg-filter-with-empty-bool.json b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/agg-filter-with-empty-bool.json
deleted file mode 100644
index f730b43..0000000
--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/agg-filter-with-empty-bool.json
+++ /dev/null
@@ -1,33 +0,0 @@
-{
-  "aggs": {
-    "issue7240": {
-      "aggs": {
-        "terms": {
-          "terms": {
-            "field": "field"
-          }
-        }
-      },
-      "filter": {
-        "fquery": {
-          "query": {
-            "filtered": {
-              "query": {
-                "bool": {}
-              },
-              "filter": {
-                "fquery": {
-                  "query": {
-                    "query_string": {
-                      "query": "_type:apache"
-                    }
-                  }
-                }
-              }
-            }
-          }
-        }
-      }
-    }
-  }
-}
diff --git a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchBwcIT.java b/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchBwcIT.java
deleted file mode 100644
index 5d6efa8..0000000
--- a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchBwcIT.java
+++ /dev/null
@@ -1,224 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.search.child;
-
-import org.elasticsearch.Version;
-import org.elasticsearch.action.admin.indices.cache.clear.ClearIndicesCacheResponse;
-import org.elasticsearch.action.admin.indices.stats.IndicesStatsResponse;
-import org.elasticsearch.action.explain.ExplainResponse;
-import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.fielddata.FieldDataType;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.search.child.ScoreType;
-import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
-import org.elasticsearch.test.ESIntegTestCase.Scope;
-import org.junit.Test;
-
-import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasParentQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAllSuccessful;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHits;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.startsWith;
-
-/**
- *
- */
-@ClusterScope(scope = Scope.SUITE)
-public class ChildQuerySearchBwcIT extends ChildQuerySearchIT {
-
-    @Override
-    public Settings indexSettings() {
-        return settings(Version.V_1_6_0).put(super.indexSettings()).build();
-    }
-
-    public void testSelfReferentialIsForbidden() {
-        // we allowed this, but it was actually broken. The has_child/has_parent results were sometimes wrong...
-        assertAcked(prepareCreate("test").addMapping("type", "_parent", "type=type"));
-    }
-
-    @Test
-    public void testAdd_ParentFieldAfterIndexingParentDocButBeforeIndexingChildDoc() throws Exception {
-        assertAcked(prepareCreate("test")
-                .setSettings(Settings.builder()
-                        .put(indexSettings())
-                        .put("index.refresh_interval", -1)));
-        ensureGreen();
-
-        String parentId = "p1";
-        client().prepareIndex("test", "parent", parentId).setSource("p_field", "1").get();
-        refresh();
-        assertAcked(client().admin()
-                .indices()
-                .preparePutMapping("test")
-                .setType("child")
-                .setSource("_parent", "type=parent"));
-        client().prepareIndex("test", "child", "c1").setSource("c_field", "1").setParent(parentId).get();
-        client().admin().indices().prepareRefresh().get();
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(hasChildQuery("child", termQuery("c_field", "1")))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertSearchHits(searchResponse, parentId);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertSearchHits(searchResponse, parentId);
-
-
-        searchResponse = client().prepareSearch("test")
-                .setPostFilter(hasChildQuery("child", termQuery("c_field", "1")))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertSearchHits(searchResponse, parentId);
-
-        searchResponse = client().prepareSearch("test")
-                .setPostFilter(hasParentQuery("parent", termQuery("p_field", "1")))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertSearchHits(searchResponse, "c1");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(hasParentQuery("parent", termQuery("p_field", "1")).score(true))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertSearchHits(searchResponse, "c1");
-    }
-
-    @Test
-    public void testExplainUsage() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping("parent")
-                .addMapping("child", "_parent", "type=parent"));
-        ensureGreen();
-
-        String parentId = "p1";
-        client().prepareIndex("test", "parent", parentId).setSource("p_field", "1").get();
-        client().prepareIndex("test", "child", "c1").setSource("c_field", "1").setParent(parentId).get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setExplain(true)
-                .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).explanation().getDescription(), equalTo("not implemented yet..."));
-
-        searchResponse = client().prepareSearch("test")
-                .setExplain(true)
-                .setQuery(hasParentQuery("parent", termQuery("p_field", "1")).score(true))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).explanation().getDescription(), equalTo("not implemented yet..."));
-
-        ExplainResponse explainResponse = client().prepareExplain("test", "parent", parentId)
-                .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX))
-                .get();
-        assertThat(explainResponse.isExists(), equalTo(true));
-        // TODO: improve test once explanations are actually implemented
-        assertThat(explainResponse.getExplanation().toString(), startsWith("1.0 ="));
-    }
-
-    @Test
-    public void testParentFieldDataCacheBug() throws Exception {
-        assertAcked(prepareCreate("test")
-                .setSettings(Settings.builder().put(indexSettings())
-                        .put("index.refresh_interval", -1)) // Disable automatic refresh, so that the _parent doesn't get warmed
-                .addMapping("parent", jsonBuilder().startObject().startObject("parent")
-                        .startObject("properties")
-                        .startObject("p_field")
-                        .field("type", "string")
-                        .startObject("fielddata")
-                        .field(FieldDataType.FORMAT_KEY, MappedFieldType.Loading.LAZY)
-                        .endObject()
-                        .endObject()
-                        .endObject().endObject().endObject()));
-
-        ensureGreen();
-
-        client().prepareIndex("test", "parent", "p0").setSource("p_field", "p_value0").get();
-        client().prepareIndex("test", "parent", "p1").setSource("p_field", "p_value1").get();
-
-        refresh();
-        // No _parent field yet, there shouldn't be anything in the field data for _parent field
-        IndicesStatsResponse indicesStatsResponse = client().admin().indices()
-                .prepareStats("test").setFieldData(true).get();
-        assertThat(indicesStatsResponse.getTotal().getFieldData().getMemorySizeInBytes(), equalTo(0l));
-
-        // Now add mapping + children
-        client().admin().indices().preparePutMapping("test").setType("child")
-                .setSource(XContentFactory.jsonBuilder().startObject().startObject("child")
-                        .startObject("_parent")
-                        .field("type", "parent")
-                        .endObject()
-                        .startObject("properties")
-                        .startObject("c_field")
-                        .field("type", "string")
-                        .startObject("fielddata")
-                        .field(FieldDataType.FORMAT_KEY, MappedFieldType.Loading.LAZY)
-                        .endObject()
-                        .endObject()
-                        .endObject().endObject().endObject())
-                .get();
-
-        // index simple data
-        client().prepareIndex("test", "child", "c1").setSource("c_field", "red").setParent("p1").get();
-        client().prepareIndex("test", "child", "c2").setSource("c_field", "yellow").setParent("p1").get();
-        client().prepareIndex("test", "parent", "p2").setSource("p_field", "p_value2").get();
-        client().prepareIndex("test", "child", "c3").setSource("c_field", "blue").setParent("p2").get();
-        client().prepareIndex("test", "child", "c4").setSource("c_field", "red").setParent("p2").get();
-
-        refresh();
-
-        indicesStatsResponse = client().admin().indices()
-                .prepareStats("test").setFieldData(true).setFieldDataFields("_parent").get();
-        assertThat(indicesStatsResponse.getTotal().getFieldData().getMemorySizeInBytes(), greaterThan(0l));
-        assertThat(indicesStatsResponse.getTotal().getFieldData().getFields().get("_parent"), greaterThan(0l));
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(hasChildQuery("child", termQuery("c_field", "blue"))))
-                .get();
-        assertNoFailures(searchResponse);
-        assertThat(searchResponse.getHits().totalHits(), equalTo(1l));
-
-        indicesStatsResponse = client().admin().indices()
-                .prepareStats("test").setFieldData(true).setFieldDataFields("_parent").get();
-        assertThat(indicesStatsResponse.getTotal().getFieldData().getMemorySizeInBytes(), greaterThan(0l));
-        assertThat(indicesStatsResponse.getTotal().getFieldData().getFields().get("_parent"), greaterThan(0l));
-
-        ClearIndicesCacheResponse clearCacheResponse = client().admin().indices().prepareClearCache("test").setFieldDataCache(true).get();
-        assertNoFailures(clearCacheResponse);
-        assertAllSuccessful(clearCacheResponse);
-        indicesStatsResponse = client().admin().indices()
-                .prepareStats("test").setFieldData(true).setFieldDataFields("_parent").get();
-        assertThat(indicesStatsResponse.getTotal().getFieldData().getMemorySizeInBytes(), equalTo(0l));
-        assertThat(indicesStatsResponse.getTotal().getFieldData().getFields().get("_parent"), equalTo(0l));
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java b/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
index a7491a1..43cf525 100644
--- a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
@@ -34,7 +34,7 @@ import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.query.HasChildQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.search.child.ScoreType;
+import org.elasticsearch.index.query.ScoreType;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.aggregations.AggregationBuilders;
@@ -286,11 +286,11 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         for (int i = 1; i <= 10; i++) {
             logger.info("Round {}", i);
             SearchResponse searchResponse = client().prepareSearch("test")
-                    .setQuery(constantScoreQuery(hasChildQuery("child", matchAllQuery()).scoreType(ScoreType.MAX)))
+                    .setQuery(constantScoreQuery(hasChildQuery("child", matchAllQuery()).scoreType("max")))
                     .get();
             assertNoFailures(searchResponse);
             searchResponse = client().prepareSearch("test")
-                    .setQuery(constantScoreQuery(hasParentQuery("parent", matchAllQuery()).score(true)))
+                    .setQuery(constantScoreQuery(hasParentQuery("parent", matchAllQuery()).scoreType("score")))
                     .get();
             assertNoFailures(searchResponse);
         }
@@ -548,11 +548,11 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         client().prepareIndex("test", "child", "c1").setSource("c_field", "1").setParent(parentId).get();
         refresh();
 
-        CountResponse countResponse = client().prepareCount("test").setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX))
+        CountResponse countResponse = client().prepareCount("test").setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType("max"))
                 .get();
         assertHitCount(countResponse, 1l);
 
-        countResponse = client().prepareCount("test").setQuery(hasParentQuery("parent", termQuery("p_field", "1")).score(true))
+        countResponse = client().prepareCount("test").setQuery(hasParentQuery("parent", termQuery("p_field", "1")).scoreType("score"))
                 .get();
         assertHitCount(countResponse, 1l);
 
@@ -579,20 +579,20 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
 
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setExplain(true)
-                .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX))
+                .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType("max"))
                 .get();
         assertHitCount(searchResponse, 1l);
         assertThat(searchResponse.getHits().getAt(0).explanation().getDescription(), equalTo("Score based on join value p1"));
 
         searchResponse = client().prepareSearch("test")
                 .setExplain(true)
-                .setQuery(hasParentQuery("parent", termQuery("p_field", "1")).score(true))
+                .setQuery(hasParentQuery("parent", termQuery("p_field", "1")).scoreType("score"))
                 .get();
         assertHitCount(searchResponse, 1l);
         assertThat(searchResponse.getHits().getAt(0).explanation().getDescription(), equalTo("Score based on join value p1"));
 
         ExplainResponse explainResponse = client().prepareExplain("test", "parent", parentId)
-                .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX))
+                .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType("max"))
                 .get();
         assertThat(explainResponse.isExists(), equalTo(true));
         assertThat(explainResponse.getExplanation().getDetails()[0].getDescription(), equalTo("Score based on join value p1"));
@@ -670,7 +670,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "child",
                                 QueryBuilders.functionScoreQuery(matchQuery("c_field2", 0),
                                         scriptFunction(new Script("doc['c_field1'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).scoreType(ScoreType.SUM)).get();
+                                        .boostMode(CombineFunction.REPLACE.getName())).scoreType("sum")).get();
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("1"));
@@ -687,7 +687,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "child",
                                 QueryBuilders.functionScoreQuery(matchQuery("c_field2", 0),
                                         scriptFunction(new Script("doc['c_field1'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).scoreType(ScoreType.MAX)).get();
+                                        .boostMode(CombineFunction.REPLACE.getName())).scoreType("max")).get();
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -704,7 +704,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "child",
                                 QueryBuilders.functionScoreQuery(matchQuery("c_field2", 0),
                                         scriptFunction(new Script("doc['c_field1'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).scoreType(ScoreType.AVG)).get();
+                                        .boostMode(CombineFunction.REPLACE.getName())).scoreType("avg")).get();
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -721,7 +721,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "parent",
                                 QueryBuilders.functionScoreQuery(matchQuery("p_field1", "p_value3"),
                                         scriptFunction(new Script("doc['p_field2'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).score(true))
+                                        .boostMode(CombineFunction.REPLACE.getName())).scoreType("score"))
                 .addSort(SortBuilders.fieldSort("c_field3")).addSort(SortBuilders.scoreSort()).get();
 
         assertThat(response.getHits().totalHits(), equalTo(7l));
@@ -761,7 +761,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertNoFailures(response);
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = client().prepareSearch("test").setQuery(QueryBuilders.hasChildQuery("child", matchQuery("text", "value")).scoreType(ScoreType.MAX))
+        response = client().prepareSearch("test").setQuery(QueryBuilders.hasChildQuery("child", matchQuery("text", "value")).scoreType("max"))
                 .get();
         assertNoFailures(response);
         assertThat(response.getHits().totalHits(), equalTo(0l));
@@ -770,7 +770,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertNoFailures(response);
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = client().prepareSearch("test").setQuery(QueryBuilders.hasParentQuery("child", matchQuery("text", "value")).score(true))
+        response = client().prepareSearch("test").setQuery(QueryBuilders.hasParentQuery("child", matchQuery("text", "value")).scoreType("score"))
                 .get();
         assertNoFailures(response);
         assertThat(response.getHits().totalHits(), equalTo(0l));
@@ -857,7 +857,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         SearchType[] searchTypes = new SearchType[]{SearchType.QUERY_THEN_FETCH, SearchType.DFS_QUERY_THEN_FETCH};
         for (SearchType searchType : searchTypes) {
             SearchResponse searchResponse = client().prepareSearch("test").setSearchType(searchType)
-                    .setQuery(hasChildQuery("child", prefixQuery("c_field", "c")).scoreType(ScoreType.MAX)).addSort("p_field", SortOrder.ASC)
+                    .setQuery(hasChildQuery("child", prefixQuery("c_field", "c")).scoreType("max")).addSort("p_field", SortOrder.ASC)
                     .setSize(5).get();
             assertNoFailures(searchResponse);
             assertThat(searchResponse.getHits().totalHits(), equalTo(10L));
@@ -868,7 +868,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
             assertThat(searchResponse.getHits().hits()[4].id(), equalTo("p004"));
 
             searchResponse = client().prepareSearch("test").setSearchType(searchType)
-                    .setQuery(hasParentQuery("parent", prefixQuery("p_field", "p")).score(true)).addSort("c_field", SortOrder.ASC)
+                    .setQuery(hasParentQuery("parent", prefixQuery("p_field", "p")).scoreType("score")).addSort("c_field", SortOrder.ASC)
                     .setSize(5).get();
             assertNoFailures(searchResponse);
             assertThat(searchResponse.getHits().totalHits(), equalTo(500L));
@@ -900,7 +900,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         refresh();
 
         SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(hasChildQuery("child", termQuery("c_field", "yellow")).scoreType(ScoreType.SUM)).get();
+                .setQuery(hasChildQuery("child", termQuery("c_field", "yellow")).scoreType("sum")).get();
         assertNoFailures(searchResponse);
         assertThat(searchResponse.getHits().totalHits(), equalTo(1l));
         assertThat(searchResponse.getHits().getAt(0).id(), equalTo("p1"));
@@ -910,7 +910,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                 .prepareSearch("test")
                 .setQuery(
                         boolQuery().must(matchQuery("c_field", "x")).must(
-                                hasParentQuery("parent", termQuery("p_field", "p_value2")).score(true))).get();
+                                hasParentQuery("parent", termQuery("p_field", "p_value2")).scoreType("score"))).get();
         assertNoFailures(searchResponse);
         assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
         assertThat(searchResponse.getHits().getAt(0).id(), equalTo("c3"));
@@ -925,7 +925,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
             client().admin().indices().prepareRefresh("test").get();
         }
 
-        searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "yellow")).scoreType(ScoreType.SUM))
+        searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "yellow")).scoreType("sum"))
                 .get();
         assertNoFailures(searchResponse);
         assertThat(searchResponse.getHits().totalHits(), equalTo(1l));
@@ -936,7 +936,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                 .prepareSearch("test")
                 .setQuery(
                         boolQuery().must(matchQuery("c_field", "x")).must(
-                                hasParentQuery("parent", termQuery("p_field", "p_value2")).score(true))).get();
+                                hasParentQuery("parent", termQuery("p_field", "p_value2")).scoreType("score"))).get();
         assertNoFailures(searchResponse);
         assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
         assertThat(searchResponse.getHits().getAt(0).id(), Matchers.anyOf(equalTo("c3"), equalTo("c4")));
@@ -961,7 +961,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         client().prepareIndex("test", "child", "c5").setSource("c_field", "x").setParent("p2").get();
         refresh();
 
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", matchAllQuery()).scoreType(ScoreType.SUM))
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", matchAllQuery()).scoreType("sum"))
                 .setMinScore(3) // Score needs to be 3 or above!
                 .get();
         assertNoFailures(searchResponse);
@@ -1198,7 +1198,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                     .endObject().endObject()).get();
             fail();
         } catch (MergeMappingException e) {
-            assertThat(e.toString(), containsString("Merge failed with failures {[The _parent field's type option can't be changed: [null]->[parent]]}"));
+            assertThat(e.toString(), containsString("Merge failed with failures {[The _parent field's type option can't be changed: [null]->[parent]"));
         }
     }
 
@@ -1230,7 +1230,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         client().prepareIndex("test", "child", "c3").setParent("p2").setSource("c_field", "red").get();
         refresh();
 
-        ScoreType scoreMode = ScoreType.values()[getRandom().nextInt(ScoreType.values().length)];
+        String scoreMode = ScoreType.values()[getRandom().nextInt(ScoreType.values().length)].name().toLowerCase(Locale.ROOT);
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(filteredQuery(QueryBuilders.hasChildQuery("child", termQuery("c_field", "blue")).scoreType(scoreMode), notQuery(termQuery("p_field", "3"))))
                 .get();
@@ -1256,13 +1256,13 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         client().prepareIndex("test", "child", "c1").setSource("c_field", "1").setParent(parentId).get();
         refresh();
 
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX).queryName("test"))
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType("max").queryName("test"))
                 .get();
         assertHitCount(searchResponse, 1l);
         assertThat(searchResponse.getHits().getAt(0).getMatchedQueries().length, equalTo(1));
         assertThat(searchResponse.getHits().getAt(0).getMatchedQueries()[0], equalTo("test"));
 
-        searchResponse = client().prepareSearch("test").setQuery(hasParentQuery("parent", termQuery("p_field", "1")).score(true).queryName("test"))
+        searchResponse = client().prepareSearch("test").setQuery(hasParentQuery("parent", termQuery("p_field", "1")).scoreType("score").queryName("test"))
                 .get();
         assertHitCount(searchResponse, 1l);
         assertThat(searchResponse.getHits().getAt(0).getMatchedQueries().length, equalTo(1));
@@ -1304,7 +1304,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
 
         try {
             client().prepareSearch("test")
-                    .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType(ScoreType.MAX))
+                    .setQuery(hasChildQuery("child", termQuery("c_field", "1")).scoreType("max"))
                     .get();
             fail();
         } catch (SearchPhaseExecutionException e) {
@@ -1322,7 +1322,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
 
         try {
             client().prepareSearch("test")
-                    .setQuery(hasParentQuery("parent", termQuery("p_field", "1")).score(true))
+                    .setQuery(hasParentQuery("parent", termQuery("p_field", "1")).scoreType("score"))
                     .get();
             fail();
         } catch (SearchPhaseExecutionException e) {
@@ -1572,7 +1572,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         return indexBuilders;
     }
 
-    private SearchResponse minMaxQuery(ScoreType scoreType, int minChildren, int maxChildren, int cutoff) throws SearchPhaseExecutionException {
+    private SearchResponse minMaxQuery(String scoreType, int minChildren, int maxChildren) throws SearchPhaseExecutionException {
         return client()
                 .prepareSearch("test")
                 .setQuery(
@@ -1583,16 +1583,16 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                                 .add(QueryBuilders.matchAllQuery(), weightFactorFunction(1))
                                                 .add(QueryBuilders.termQuery("foo", "three"), weightFactorFunction(1))
                                                 .add(QueryBuilders.termQuery("foo", "four"), weightFactorFunction(1))).scoreType(scoreType)
-                                .minChildren(minChildren).maxChildren(maxChildren).shortCircuitCutoff(cutoff))
+                                .minChildren(minChildren).maxChildren(maxChildren))
                 .addSort("_score", SortOrder.DESC).addSort("id", SortOrder.ASC).get();
     }
 
-    private SearchResponse minMaxFilter(int minChildren, int maxChildren, int cutoff) throws SearchPhaseExecutionException {
+    private SearchResponse minMaxFilter(int minChildren, int maxChildren) throws SearchPhaseExecutionException {
         return client()
                 .prepareSearch("test")
                 .setQuery(
                         QueryBuilders.constantScoreQuery(QueryBuilders.hasChildQuery("child", termQuery("foo", "two"))
-                                .minChildren(minChildren).maxChildren(maxChildren).shortCircuitCutoff(cutoff)))
+                                .minChildren(minChildren).maxChildren(maxChildren)))
                 .addSort("id", SortOrder.ASC).setTrackScores(true).get();
     }
 
@@ -1605,10 +1605,9 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
 
         indexRandom(true, createMinMaxDocBuilders().toArray(new IndexRequestBuilder[0]));
         SearchResponse response;
-        int cutoff = getRandom().nextInt(4);
 
         // Score mode = NONE
-        response = minMaxQuery(ScoreType.NONE, 0, 0, cutoff);
+        response = minMaxQuery("none", 0, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1618,7 +1617,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 1, 0, cutoff);
+        response = minMaxQuery("none", 1, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1628,7 +1627,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 2, 0, cutoff);
+        response = minMaxQuery("none", 2, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -1636,17 +1635,17 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("4"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 3, 0, cutoff);
+        response = minMaxQuery("none", 3, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
         assertThat(response.getHits().hits()[0].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 4, 0, cutoff);
+        response = minMaxQuery("none", 4, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = minMaxQuery(ScoreType.NONE, 0, 4, cutoff);
+        response = minMaxQuery("none", 0, 4);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1656,7 +1655,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 0, 3, cutoff);
+        response = minMaxQuery("none", 0, 3);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1666,7 +1665,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 0, 2, cutoff);
+        response = minMaxQuery("none", 0, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1674,21 +1673,21 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("3"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.NONE, 2, 2, cutoff);
+        response = minMaxQuery("none", 2, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
         assertThat(response.getHits().hits()[0].score(), equalTo(1f));
 
         try {
-            response = minMaxQuery(ScoreType.NONE, 3, 2, cutoff);
+            response = minMaxQuery("none", 3, 2);
             fail();
         } catch (SearchPhaseExecutionException e) {
             assertThat(e.toString(), containsString("[has_child] 'max_children' is less than 'min_children'"));
         }
 
         // Score mode = SUM
-        response = minMaxQuery(ScoreType.SUM, 0, 0, cutoff);
+        response = minMaxQuery("sum", 0, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1698,7 +1697,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.SUM, 1, 0, cutoff);
+        response = minMaxQuery("sum", 1, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1708,7 +1707,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.SUM, 2, 0, cutoff);
+        response = minMaxQuery("sum", 2, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1716,17 +1715,17 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("3"));
         assertThat(response.getHits().hits()[1].score(), equalTo(3f));
 
-        response = minMaxQuery(ScoreType.SUM, 3, 0, cutoff);
+        response = minMaxQuery("sum", 3, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
         assertThat(response.getHits().hits()[0].score(), equalTo(6f));
 
-        response = minMaxQuery(ScoreType.SUM, 4, 0, cutoff);
+        response = minMaxQuery("sum", 4, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = minMaxQuery(ScoreType.SUM, 0, 4, cutoff);
+        response = minMaxQuery("sum", 0, 4);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1736,7 +1735,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.SUM, 0, 3, cutoff);
+        response = minMaxQuery("sum", 0, 3);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1746,7 +1745,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.SUM, 0, 2, cutoff);
+        response = minMaxQuery("sum", 0, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -1754,21 +1753,21 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("2"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.SUM, 2, 2, cutoff);
+        response = minMaxQuery("sum", 2, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
         assertThat(response.getHits().hits()[0].score(), equalTo(3f));
 
         try {
-            response = minMaxQuery(ScoreType.SUM, 3, 2, cutoff);
+            response = minMaxQuery("sum", 3, 2);
             fail();
         } catch (SearchPhaseExecutionException e) {
             assertThat(e.toString(), containsString("[has_child] 'max_children' is less than 'min_children'"));
         }
 
         // Score mode = MAX
-        response = minMaxQuery(ScoreType.MAX, 0, 0, cutoff);
+        response = minMaxQuery("max", 0, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1778,7 +1777,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.MAX, 1, 0, cutoff);
+        response = minMaxQuery("max", 1, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1788,7 +1787,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.MAX, 2, 0, cutoff);
+        response = minMaxQuery("max", 2, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1796,17 +1795,17 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("3"));
         assertThat(response.getHits().hits()[1].score(), equalTo(2f));
 
-        response = minMaxQuery(ScoreType.MAX, 3, 0, cutoff);
+        response = minMaxQuery("max", 3, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
         assertThat(response.getHits().hits()[0].score(), equalTo(3f));
 
-        response = minMaxQuery(ScoreType.MAX, 4, 0, cutoff);
+        response = minMaxQuery("max", 4, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = minMaxQuery(ScoreType.MAX, 0, 4, cutoff);
+        response = minMaxQuery("max", 0, 4);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1816,7 +1815,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.MAX, 0, 3, cutoff);
+        response = minMaxQuery("max", 0, 3);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1826,7 +1825,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.MAX, 0, 2, cutoff);
+        response = minMaxQuery("max", 0, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -1834,21 +1833,21 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("2"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.MAX, 2, 2, cutoff);
+        response = minMaxQuery("max", 2, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
         assertThat(response.getHits().hits()[0].score(), equalTo(2f));
 
         try {
-            response = minMaxQuery(ScoreType.MAX, 3, 2, cutoff);
+            response = minMaxQuery("max", 3, 2);
             fail();
         } catch (SearchPhaseExecutionException e) {
             assertThat(e.toString(), containsString("[has_child] 'max_children' is less than 'min_children'"));
         }
 
         // Score mode = AVG
-        response = minMaxQuery(ScoreType.AVG, 0, 0, cutoff);
+        response = minMaxQuery("avg", 0, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1858,7 +1857,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.AVG, 1, 0, cutoff);
+        response = minMaxQuery("avg", 1, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1868,7 +1867,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.AVG, 2, 0, cutoff);
+        response = minMaxQuery("avg", 2, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1876,17 +1875,17 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("3"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1.5f));
 
-        response = minMaxQuery(ScoreType.AVG, 3, 0, cutoff);
+        response = minMaxQuery("avg", 3, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
         assertThat(response.getHits().hits()[0].score(), equalTo(2f));
 
-        response = minMaxQuery(ScoreType.AVG, 4, 0, cutoff);
+        response = minMaxQuery("avg", 4, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = minMaxQuery(ScoreType.AVG, 0, 4, cutoff);
+        response = minMaxQuery("avg", 0, 4);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1896,7 +1895,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.AVG, 0, 3, cutoff);
+        response = minMaxQuery("avg", 0, 3);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
@@ -1906,7 +1905,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("2"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.AVG, 0, 2, cutoff);
+        response = minMaxQuery("avg", 0, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -1914,21 +1913,21 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("2"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxQuery(ScoreType.AVG, 2, 2, cutoff);
+        response = minMaxQuery("avg", 2, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
         assertThat(response.getHits().hits()[0].score(), equalTo(1.5f));
 
         try {
-            response = minMaxQuery(ScoreType.AVG, 3, 2, cutoff);
+            response = minMaxQuery("avg", 3, 2);
             fail();
         } catch (SearchPhaseExecutionException e) {
             assertThat(e.toString(), containsString("[has_child] 'max_children' is less than 'min_children'"));
         }
 
         // HasChildFilter
-        response = minMaxFilter(0, 0, cutoff);
+        response = minMaxFilter(0, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1938,7 +1937,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxFilter(1, 0, cutoff);
+        response = minMaxFilter(1, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1948,7 +1947,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxFilter(2, 0, cutoff);
+        response = minMaxFilter(2, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -1956,17 +1955,17 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("4"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxFilter(3, 0, cutoff);
+        response = minMaxFilter(3, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("4"));
         assertThat(response.getHits().hits()[0].score(), equalTo(1f));
 
-        response = minMaxFilter(4, 0, cutoff);
+        response = minMaxFilter(4, 0);
 
         assertThat(response.getHits().totalHits(), equalTo(0l));
 
-        response = minMaxFilter(0, 4, cutoff);
+        response = minMaxFilter(0, 4);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1976,7 +1975,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxFilter(0, 3, cutoff);
+        response = minMaxFilter(0, 3);
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1986,7 +1985,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[2].id(), equalTo("4"));
         assertThat(response.getHits().hits()[2].score(), equalTo(1f));
 
-        response = minMaxFilter(0, 2, cutoff);
+        response = minMaxFilter(0, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(2l));
         assertThat(response.getHits().hits()[0].id(), equalTo("2"));
@@ -1994,14 +1993,14 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         assertThat(response.getHits().hits()[1].id(), equalTo("3"));
         assertThat(response.getHits().hits()[1].score(), equalTo(1f));
 
-        response = minMaxFilter(2, 2, cutoff);
+        response = minMaxFilter(2, 2);
 
         assertThat(response.getHits().totalHits(), equalTo(1l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
         assertThat(response.getHits().hits()[0].score(), equalTo(1f));
 
         try {
-            response = minMaxFilter(3, 2, cutoff);
+            response = minMaxFilter(3, 2);
             fail();
         } catch (SearchPhaseExecutionException e) {
             assertThat(e.toString(), containsString("[has_child] 'max_children' is less than 'min_children'"));
@@ -2032,7 +2031,6 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
 
     static HasChildQueryBuilder hasChildQuery(String type, QueryBuilder queryBuilder) {
         HasChildQueryBuilder hasChildQueryBuilder = QueryBuilders.hasChildQuery(type, queryBuilder);
-        hasChildQueryBuilder.shortCircuitCutoff(randomInt(10));
         return hasChildQueryBuilder;
     }
 
diff --git a/core/src/test/java/org/elasticsearch/search/child/ParentFieldLoadingBwcIT.java b/core/src/test/java/org/elasticsearch/search/child/ParentFieldLoadingBwcIT.java
deleted file mode 100644
index feb1828..0000000
--- a/core/src/test/java/org/elasticsearch/search/child/ParentFieldLoadingBwcIT.java
+++ /dev/null
@@ -1,252 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.search.child;
-
-import org.elasticsearch.Version;
-import org.elasticsearch.action.admin.cluster.stats.ClusterStatsResponse;
-import org.elasticsearch.action.admin.indices.cache.clear.ClearIndicesCacheResponse;
-import org.elasticsearch.action.admin.indices.mapping.put.PutMappingResponse;
-import org.elasticsearch.action.admin.indices.stats.IndicesStatsResponse;
-import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.IndexService;
-import org.elasticsearch.index.fielddata.FieldDataType;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.shard.IndexShard;
-import org.elasticsearch.index.shard.MergePolicyConfig;
-import org.elasticsearch.indices.IndicesService;
-import org.elasticsearch.test.ESIntegTestCase;
-
-import java.io.IOException;
-
-import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.search.child.ChildQuerySearchIT.hasChildQuery;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-
-public class ParentFieldLoadingBwcIT extends ESIntegTestCase {
-
-    private final Settings indexSettings = Settings.builder()
-            .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)
-            .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0)
-            .put(IndexShard.INDEX_REFRESH_INTERVAL, -1)
-                    // We never want merges in this test to ensure we have two segments for the last validation
-            .put(MergePolicyConfig.INDEX_MERGE_ENABLED, false)
-            .put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_6_0)
-            .build();
-
-    public void testParentFieldDataCacheBug() throws Exception {
-        assertAcked(prepareCreate("test")
-                .setSettings(Settings.builder().put(indexSettings)
-                        .put("index.refresh_interval", -1)) // Disable automatic refresh, so that the _parent doesn't get warmed
-                .addMapping("parent", XContentFactory.jsonBuilder().startObject().startObject("parent")
-                        .startObject("properties")
-                        .startObject("p_field")
-                        .field("type", "string")
-                        .startObject("fielddata")
-                        .field(FieldDataType.FORMAT_KEY, MappedFieldType.Loading.LAZY)
-                        .endObject()
-                        .endObject()
-                        .endObject().endObject().endObject())
-                .addMapping("child", XContentFactory.jsonBuilder().startObject().startObject("child")
-                        .startObject("_parent")
-                        .field("type", "parent")
-                        .endObject()
-                        .startObject("properties")
-                        .startObject("c_field")
-                        .field("type", "string")
-                        .startObject("fielddata")
-                        .field(FieldDataType.FORMAT_KEY, MappedFieldType.Loading.LAZY)
-                        .endObject()
-                        .endObject()
-                        .endObject().endObject().endObject()));
-
-        ensureGreen();
-
-        client().prepareIndex("test", "parent", "p0").setSource("p_field", "p_value0").get();
-        client().prepareIndex("test", "parent", "p1").setSource("p_field", "p_value1").get();
-        client().prepareIndex("test", "child", "c1").setSource("c_field", "red").setParent("p1").get();
-        client().prepareIndex("test", "child", "c2").setSource("c_field", "yellow").setParent("p1").get();
-        client().prepareIndex("test", "parent", "p2").setSource("p_field", "p_value2").get();
-        client().prepareIndex("test", "child", "c3").setSource("c_field", "blue").setParent("p2").get();
-        client().prepareIndex("test", "child", "c4").setSource("c_field", "red").setParent("p2").get();
-        refresh();
-
-        IndicesStatsResponse statsResponse = client().admin().indices()
-                .prepareStats("test").setFieldData(true).setFieldDataFields("_parent").get();
-        assertThat(statsResponse.getTotal().getFieldData().getMemorySizeInBytes(), greaterThan(0l));
-        assertThat(statsResponse.getTotal().getFieldData().getFields().get("_parent"), greaterThan(0l));
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(hasChildQuery("child", termQuery("c_field", "blue"))))
-                .get();
-        assertNoFailures(searchResponse);
-        assertThat(searchResponse.getHits().totalHits(), equalTo(1l));
-
-        statsResponse = client().admin().indices()
-                .prepareStats("test").setFieldData(true).setFieldDataFields("_parent").get();
-        assertThat(statsResponse.getTotal().getFieldData().getMemorySizeInBytes(), greaterThan(0l));
-        assertThat(statsResponse.getTotal().getFieldData().getFields().get("_parent"), greaterThan(0l));
-
-        ClearIndicesCacheResponse clearCacheResponse = client().admin().indices().prepareClearCache("test").setFieldDataCache(true).get();
-        assertNoFailures(clearCacheResponse);
-        assertAllSuccessful(clearCacheResponse);
-        statsResponse = client().admin().indices()
-                .prepareStats("test").setFieldData(true).setFieldDataFields("_parent").get();
-        assertThat(statsResponse.getTotal().getFieldData().getMemorySizeInBytes(), equalTo(0l));
-        assertThat(statsResponse.getTotal().getFieldData().getFields().get("_parent"), equalTo(0l));
-    }
-
-    public void testEagerParentFieldLoading() throws Exception {
-        logger.info("testing lazy loading...");
-        assertAcked(prepareCreate("test")
-                .setSettings(indexSettings)
-                .addMapping("parent")
-                .addMapping("child", childMapping(MappedFieldType.Loading.LAZY))
-                .setUpdateAllTypes(true));
-        ensureGreen();
-
-        client().prepareIndex("test", "parent", "1").setSource("{}").get();
-        client().prepareIndex("test", "child", "1").setParent("1").setSource("{}").get();
-        refresh();
-
-        ClusterStatsResponse response = client().admin().cluster().prepareClusterStats().get();
-        assertThat(response.getIndicesStats().getFieldData().getMemorySizeInBytes(), equalTo(0l));
-
-        logger.info("testing default loading...");
-        assertAcked(client().admin().indices().prepareDelete("test").get());
-        assertAcked(prepareCreate("test")
-                .setSettings(indexSettings)
-                .addMapping("parent")
-                .addMapping("child", "_parent", "type=parent")
-                .setUpdateAllTypes(true));
-        ensureGreen();
-
-        client().prepareIndex("test", "parent", "1").setSource("{}").get();
-        client().prepareIndex("test", "child", "1").setParent("1").setSource("{}").get();
-        refresh();
-
-        response = client().admin().cluster().prepareClusterStats().get();
-        long fielddataSizeDefault = response.getIndicesStats().getFieldData().getMemorySizeInBytes();
-        assertThat(fielddataSizeDefault, greaterThan(0l));
-
-        logger.info("testing eager loading...");
-        assertAcked(client().admin().indices().prepareDelete("test").get());
-        assertAcked(prepareCreate("test")
-                .setSettings(indexSettings)
-                .addMapping("parent")
-                .addMapping("child", childMapping(MappedFieldType.Loading.EAGER))
-                .setUpdateAllTypes(true));
-        ensureGreen();
-
-        client().prepareIndex("test", "parent", "1").setSource("{}").get();
-        client().prepareIndex("test", "child", "1").setParent("1").setSource("{}").get();
-        refresh();
-
-        response = client().admin().cluster().prepareClusterStats().get();
-        assertThat(response.getIndicesStats().getFieldData().getMemorySizeInBytes(), equalTo(fielddataSizeDefault));
-
-        logger.info("testing eager global ordinals loading...");
-        assertAcked(client().admin().indices().prepareDelete("test").get());
-        assertAcked(prepareCreate("test")
-            .setSettings(indexSettings)
-            .addMapping("parent")
-            .addMapping("child", childMapping(MappedFieldType.Loading.EAGER_GLOBAL_ORDINALS))
-            .setUpdateAllTypes(true));
-        ensureGreen();
-
-        // Need to do 2 separate refreshes, otherwise we have 1 segment and then we can't measure if global ordinals
-        // is loaded by the size of the field data cache, because global ordinals on 1 segment shards takes no extra memory.
-        client().prepareIndex("test", "parent", "1").setSource("{}").get();
-        refresh();
-        client().prepareIndex("test", "child", "1").setParent("1").setSource("{}").get();
-        refresh();
-
-        response = client().admin().cluster().prepareClusterStats().get();
-        assertThat(response.getIndicesStats().getFieldData().getMemorySizeInBytes(), greaterThan(fielddataSizeDefault));
-    }
-    
-    public void testChangingEagerParentFieldLoadingAtRuntime() throws Exception {
-        assertAcked(prepareCreate("test")
-                .setSettings(indexSettings)
-                .addMapping("parent")
-                .addMapping("child", "_parent", "type=parent"));
-        ensureGreen();
-
-        client().prepareIndex("test", "parent", "1").setSource("{}").get();
-        client().prepareIndex("test", "child", "1").setParent("1").setSource("{}").get();
-        refresh();
-
-        ClusterStatsResponse response = client().admin().cluster().prepareClusterStats().get();
-        long fielddataSizeDefault = response.getIndicesStats().getFieldData().getMemorySizeInBytes();
-        assertThat(fielddataSizeDefault, greaterThan(0l));
-
-        PutMappingResponse putMappingResponse = client().admin().indices().preparePutMapping("test").setType("child")
-                .setSource(childMapping(MappedFieldType.Loading.EAGER_GLOBAL_ORDINALS))
-                .setUpdateAllTypes(true)
-                .get();
-        assertAcked(putMappingResponse);
-        assertBusy(new Runnable() {
-            @Override
-            public void run() {
-                ClusterState clusterState = internalCluster().clusterService().state();
-                ShardRouting shardRouting = clusterState.routingTable().index("test").shard(0).getShards().get(0);
-                String nodeName = clusterState.getNodes().get(shardRouting.currentNodeId()).getName();
-
-                boolean verified = false;
-                IndicesService indicesService = internalCluster().getInstance(IndicesService.class, nodeName);
-                IndexService indexService = indicesService.indexService("test");
-                if (indexService != null) {
-                    MapperService mapperService = indexService.mapperService();
-                    DocumentMapper documentMapper = mapperService.documentMapper("child");
-                    if (documentMapper != null) {
-                        verified = documentMapper.parentFieldMapper().fieldType().fieldDataType().getLoading() == MappedFieldType.Loading.EAGER_GLOBAL_ORDINALS;
-                    }
-                }
-                assertTrue(verified);
-            }
-        });
-
-        // Need to add a new doc otherwise the refresh doesn't trigger a new searcher
-        // Because it ends up in its own segment, but isn't of type parent or child, this doc doesn't contribute to the size of the fielddata cache
-        client().prepareIndex("test", "dummy", "dummy").setSource("{}").get();
-        refresh();
-        response = client().admin().cluster().prepareClusterStats().get();
-        assertThat(response.getIndicesStats().getFieldData().getMemorySizeInBytes(), greaterThan(fielddataSizeDefault));
-    }
-
-    private XContentBuilder childMapping(MappedFieldType.Loading loading) throws IOException {
-        return jsonBuilder().startObject().startObject("child").startObject("_parent")
-                .field("type", "parent")
-                .startObject("fielddata").field(MappedFieldType.Loading.KEY, loading).endObject()
-                .endObject().endObject().endObject();
-    }
-
-}
diff --git a/core/src/test/java/org/elasticsearch/search/child/ParentFieldLoadingIT.java b/core/src/test/java/org/elasticsearch/search/child/ParentFieldLoadingIT.java
index 8a57e22..729b6ac 100644
--- a/core/src/test/java/org/elasticsearch/search/child/ParentFieldLoadingIT.java
+++ b/core/src/test/java/org/elasticsearch/search/child/ParentFieldLoadingIT.java
@@ -57,8 +57,7 @@ public class ParentFieldLoadingIT extends ESIntegTestCase {
         assertAcked(prepareCreate("test")
                 .setSettings(indexSettings)
                 .addMapping("parent")
-                .addMapping("child", childMapping(MappedFieldType.Loading.LAZY))
-                .setUpdateAllTypes(true));
+                .addMapping("child", childMapping(MappedFieldType.Loading.LAZY)));
         ensureGreen();
 
         client().prepareIndex("test", "parent", "1").setSource("{}").get();
@@ -73,8 +72,7 @@ public class ParentFieldLoadingIT extends ESIntegTestCase {
         assertAcked(prepareCreate("test")
                 .setSettings(indexSettings)
                 .addMapping("parent")
-                .addMapping("child", "_parent", "type=parent")
-                .setUpdateAllTypes(true));
+                .addMapping("child", "_parent", "type=parent"));
         ensureGreen();
 
         client().prepareIndex("test", "parent", "1").setSource("{}").get();
@@ -89,8 +87,7 @@ public class ParentFieldLoadingIT extends ESIntegTestCase {
         assertAcked(prepareCreate("test")
                 .setSettings(indexSettings)
                 .addMapping("parent")
-                .addMapping("child", childMapping(MappedFieldType.Loading.EAGER))
-                .setUpdateAllTypes(true));
+                .addMapping("child", childMapping(MappedFieldType.Loading.EAGER)));
         ensureGreen();
 
         client().prepareIndex("test", "parent", "1").setSource("{}").get();
@@ -105,8 +102,7 @@ public class ParentFieldLoadingIT extends ESIntegTestCase {
         assertAcked(prepareCreate("test")
                 .setSettings(indexSettings)
                 .addMapping("parent")
-                .addMapping("child", childMapping(MappedFieldType.Loading.EAGER_GLOBAL_ORDINALS))
-                .setUpdateAllTypes(true));
+                .addMapping("child", childMapping(MappedFieldType.Loading.EAGER_GLOBAL_ORDINALS)));
         ensureGreen();
 
         // Need to do 2 separate refreshes, otherwise we have 1 segment and then we can't measure if global ordinals
@@ -153,7 +149,7 @@ public class ParentFieldLoadingIT extends ESIntegTestCase {
                     MapperService mapperService = indexService.mapperService();
                     DocumentMapper documentMapper = mapperService.documentMapper("child");
                     if (documentMapper != null) {
-                        verified = documentMapper.parentFieldMapper().fieldType().fieldDataType().getLoading() == MappedFieldType.Loading.EAGER_GLOBAL_ORDINALS;
+                        verified = documentMapper.parentFieldMapper().getChildJoinFieldType().fieldDataType().getLoading() == MappedFieldType.Loading.EAGER_GLOBAL_ORDINALS;
                     }
                 }
                 assertTrue(verified);
diff --git a/core/src/test/java/org/elasticsearch/search/child/bool-query-with-empty-clauses.json b/core/src/test/java/org/elasticsearch/search/child/bool-query-with-empty-clauses.json
deleted file mode 100644
index 844b591..0000000
--- a/core/src/test/java/org/elasticsearch/search/child/bool-query-with-empty-clauses.json
+++ /dev/null
@@ -1,19 +0,0 @@
-{
-"query": {
-  "filtered": {
-    "filter": {
-      "has_parent": {
-        "type": "foo",
-        "query": {
-          "bool": {
-            "must": [],
-            "must_not": [],
-            "should": []
-          }
-        }
-      },
-      "query": []
-    }
-  }
-}
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java b/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java
index 59282e9..054fdfc 100644
--- a/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java
+++ b/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java
@@ -45,15 +45,12 @@ import java.util.Locale;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.filteredQuery;
 import static org.elasticsearch.index.query.QueryBuilders.geoIntersectionQuery;
-import static org.elasticsearch.index.query.QueryBuilders.geoIntersectionQuery;
 import static org.elasticsearch.index.query.QueryBuilders.geoShapeQuery;
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.*;
 
 public class GeoShapeIntegrationIT extends ESIntegTestCase {
 
@@ -479,6 +476,40 @@ public class GeoShapeIntegrationIT extends ESIntegTestCase {
         assertThat(orientation, equalTo(ShapeBuilder.Orientation.CCW));
     }
 
+    @Test
+    public void testPointsOnly() throws Exception {
+        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type1")
+                .startObject("properties").startObject("location")
+                .field("type", "geo_shape")
+                .field("tree", randomBoolean() ? "quadtree" : "geohash")
+                .field("tree_levels", "6")
+                .field("distance_error_pct", "0.01")
+                .field("points_only", true)
+                .endObject().endObject()
+                .endObject().endObject().string();
+
+        assertAcked(prepareCreate("geo_points_only").addMapping("type1", mapping));
+        ensureGreen();
+
+        ShapeBuilder shape = RandomShapeGenerator.createShape(random());
+        try {
+            indexRandom(true, client().prepareIndex("geo_points_only", "type1", "1").setSource(jsonBuilder().startObject()
+                    .field("location", shape).endObject()));
+        } catch (Throwable e) {
+            // RandomShapeGenerator created something other than a POINT type, verify the correct exception is thrown
+            assertThat(e.getMessage(), containsString("MapperParsingException"));
+            assertThat(e.getMessage(), containsString("is configured for points only"));
+            return;
+        }
+
+        // test that point was inserted
+        SearchResponse response = client().prepareSearch()
+                .setQuery(geoIntersectionQuery("location", shape))
+                .execute().actionGet();
+
+        assertEquals(1, response.getHits().getTotalHits());
+    }
+
     private String findNodeName(String index) {
         ClusterState state = client().admin().cluster().prepareState().get().getState();
         IndexShardRoutingTable shard = state.getRoutingTable().index(index).shard(0);
diff --git a/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java b/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
index 61c4dc7..0c569b1 100644
--- a/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
@@ -27,9 +27,10 @@ import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.settings.Settings.Builder;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.BoostableQueryBuilder;
 import org.elasticsearch.index.query.IdsQueryBuilder;
 import org.elasticsearch.index.query.MatchQueryBuilder;
+import org.elasticsearch.index.query.MatchQueryBuilder.Operator;
 import org.elasticsearch.index.query.MatchQueryBuilder.Type;
 import org.elasticsearch.index.query.MultiMatchQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
@@ -70,7 +71,12 @@ import static org.elasticsearch.index.query.QueryBuilders.typeQuery;
 import static org.elasticsearch.index.query.QueryBuilders.wildcardQuery;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.highlight;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.searchSource;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHighlight;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNotHighlighted;
 import static org.elasticsearch.test.hamcrest.RegexMatcher.matches;
 import static org.hamcrest.Matchers.anyOf;
 import static org.hamcrest.Matchers.containsString;
@@ -1391,7 +1397,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
-                .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
+                .query(boostingQuery().positive(termQuery("field2", "brown")).negative(termQuery("field2", "foobar")).negativeBoost(0.5f))
                 .highlight(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source.buildAsBytes()).get();
@@ -1410,7 +1416,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
-                .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
+                .query(boostingQuery().positive(termQuery("field2", "brown")).negative(termQuery("field2", "foobar")).negativeBoost(0.5f))
                 .highlight(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source.buildAsBytes()).get();
@@ -2324,7 +2330,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
-                .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
+                .query(boostingQuery().positive(termQuery("field2", "brown")).negative(termQuery("field2", "foobar")).negativeBoost(0.5f))
                 .highlight(highlight().field("field2").preTags("<x>").postTags("</x>"));
         SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -2613,7 +2619,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
                 queryStringQuery("\"highlight words together\"").field("field1^100").autoGeneratePhraseQueries(true));
     }
 
-    private <P extends AbstractQueryBuilder<P>> void
+    private <P extends QueryBuilder & BoostableQueryBuilder<?>> void
             phraseBoostTestCaseForClauses(String highlighterType, float boost, QueryBuilder terms, P phrase) {
         Matcher<String> highlightedMatcher = Matchers.either(containsString("<em>highlight words together</em>")).or(
                 containsString("<em>highlight</em> <em>words</em> <em>together</em>"));
@@ -2627,10 +2633,10 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         assertHighlight(response, 0, "field1", 0, 1, highlightedMatcher);
         phrase.boost(1);
         // Try with a boosting query
-        response = search.setQuery(boostingQuery(phrase, terms).boost(boost).negativeBoost(1)).get();
+        response = search.setQuery(boostingQuery().positive(phrase).negative(terms).boost(boost).negativeBoost(1)).get();
         assertHighlight(response, 0, "field1", 0, 1, highlightedMatcher);
         // Try with a boosting query using a negative boost
-        response = search.setQuery(boostingQuery(phrase, terms).boost(1).negativeBoost(1/boost)).get();
+        response = search.setQuery(boostingQuery().positive(phrase).negative(terms).boost(1).negativeBoost(1/boost)).get();
         assertHighlight(response, 0, "field1", 0, 1, highlightedMatcher);
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java b/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java
index b182d0f..ba43286 100644
--- a/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.search.innerhits;
 
+import org.apache.lucene.util.ArrayUtil;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;
 import org.elasticsearch.action.index.IndexRequestBuilder;
@@ -27,11 +28,10 @@ import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.query.BoolQueryBuilder;
-import org.elasticsearch.index.query.support.QueryInnerHits;
+import org.elasticsearch.index.query.support.QueryInnerHitBuilder;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHits;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
 import org.elasticsearch.search.sort.SortBuilders;
 import org.elasticsearch.search.sort.SortOrder;
@@ -88,9 +88,9 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         // Inner hits can be defined in two ways: 1) with the query 2) as seperate inner_hit definition
         SearchRequest[] searchRequests = new SearchRequest[]{
-                client().prepareSearch("articles").setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits("comment", null))).request(),
+                client().prepareSearch("articles").setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder().setName("comment"))).request(),
                 client().prepareSearch("articles").setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")))
-                        .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.message", "fox"))).request()
+                        .addInnerHit("comment", new InnerHitsBuilder.InnerHit().setPath("comments").setQuery(matchQuery("comments.message", "fox"))).request()
         };
         for (SearchRequest searchRequest : searchRequests) {
             SearchResponse response = client().search(searchRequest).actionGet();
@@ -112,11 +112,11 @@ public class InnerHitsIT extends ESIntegTestCase {
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")))
-                        .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.message", "elephant"))).request(),
+                        .addInnerHit("comment", new InnerHitsBuilder.InnerHit().setPath("comments").setQuery(matchQuery("comments.message", "elephant"))).request(),
                 client().prepareSearch("articles")
-                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")).innerHit(new QueryInnerHits("comment", null))).request(),
+                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")).innerHit(new QueryInnerHitBuilder().setName("comment"))).request(),
                 client().prepareSearch("articles")
-                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")).innerHit(new QueryInnerHits("comment", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC)))).request()
+                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")).innerHit(new QueryInnerHitBuilder().setName("comment").addSort("_doc", SortOrder.DESC))).request()
         };
         for (SearchRequest searchRequest : searchRequests) {
             SearchResponse response = client().search(searchRequest).actionGet();
@@ -138,24 +138,24 @@ public class InnerHitsIT extends ESIntegTestCase {
             assertThat(innerHits.getAt(2).getNestedIdentity().getField().string(), equalTo("comments"));
             assertThat(innerHits.getAt(2).getNestedIdentity().getOffset(), equalTo(2));
         }
-        InnerHitsBuilder.InnerHit innerHit = new InnerHitsBuilder.InnerHit();
-        innerHit.highlightBuilder().field("comments.message");
-        innerHit.setExplain(true);
-        innerHit.addFieldDataField("comments.message");
-        innerHit.addScriptField("script", new Script("doc['comments.message'].value"));
-        innerHit.setSize(1);
+
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")))
-                        .addNestedInnerHits("comments", "comments", new InnerHitsBuilder.InnerHit()
+                        .addInnerHit("comments", new InnerHitsBuilder.InnerHit().setPath("comments")
                                 .setQuery(matchQuery("comments.message", "fox"))
                                 .addHighlightedField("comments.message")
                                 .setExplain(true)
                                 .addFieldDataField("comments.message")
-                                .addScriptField("script", new Script("doc['comments.message'].value"))
+                                        .addScriptField("script", new Script("doc['comments.message'].value"))
                                 .setSize(1)).request(),
                 client().prepareSearch("articles")
-                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, innerHit))).request()
+                        .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder()
+                                .addHighlightedField("comments.message")
+                                .setExplain(true)
+                                .addFieldDataField("comments.message")
+                                                .addScriptField("script", new Script("doc['comments.message'].value"))
+                                .setSize(1))).request()
         };
 
         for (SearchRequest searchRequest : searchRequests) {
@@ -201,17 +201,17 @@ public class InnerHitsIT extends ESIntegTestCase {
             searchResponse = client().prepareSearch("idx")
                     .setSize(numDocs)
                     .addSort("_uid", SortOrder.ASC)
-                    .addNestedInnerHits("a", "field1", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size)) // Sort order is DESC, because we reverse the inner objects during indexing!
-                    .addNestedInnerHits("b", "field2", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size))
+                    .addInnerHit("a", new InnerHitsBuilder.InnerHit().setPath("field1").addSort("_doc", SortOrder.DESC).setSize(size)) // Sort order is DESC, because we reverse the inner objects during indexing!
+                    .addInnerHit("b", new InnerHitsBuilder.InnerHit().setPath("field2").addSort("_doc", SortOrder.DESC).setSize(size))
                     .get();
         } else {
             BoolQueryBuilder boolQuery = new BoolQueryBuilder();
             if (randomBoolean()) {
-                boolQuery.should(nestedQuery("field1", matchAllQuery()).innerHit(new QueryInnerHits("a", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size))));
-                boolQuery.should(nestedQuery("field2", matchAllQuery()).innerHit(new QueryInnerHits("b", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size))));
+                boolQuery.should(nestedQuery("field1", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("a").addSort("_doc", SortOrder.DESC).setSize(size)));
+                boolQuery.should(nestedQuery("field2", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("b").addSort("_doc", SortOrder.DESC).setSize(size)));
             } else {
-                boolQuery.should(constantScoreQuery(nestedQuery("field1", matchAllQuery()).innerHit(new QueryInnerHits("a", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size)))));
-                boolQuery.should(constantScoreQuery(nestedQuery("field2", matchAllQuery()).innerHit(new QueryInnerHits("b", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size)))));
+                boolQuery.should(constantScoreQuery(nestedQuery("field1", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("a").addSort("_doc", SortOrder.DESC).setSize(size))));
+                boolQuery.should(constantScoreQuery(nestedQuery("field2", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("b").addSort("_doc", SortOrder.DESC).setSize(size))));
             }
             searchResponse = client().prepareSearch("idx")
                     .setQuery(boolQuery)
@@ -267,10 +267,10 @@ public class InnerHitsIT extends ESIntegTestCase {
         SearchRequest[] searchRequests = new SearchRequest[]{
                 client().prepareSearch("articles")
                         .setQuery(hasChildQuery("comment", matchQuery("message", "fox")))
-                        .addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "fox")))
+                        .addInnerHit("comment", new InnerHitsBuilder.InnerHit().setType("comment").setQuery(matchQuery("message", "fox")))
                         .request(),
                 client().prepareSearch("articles")
-                        .setQuery(hasChildQuery("comment", matchQuery("message", "fox")).innerHit(new QueryInnerHits("comment", null)))
+                        .setQuery(hasChildQuery("comment", matchQuery("message", "fox")).innerHit(new QueryInnerHitBuilder().setName("comment")))
                         .request()
         };
         for (SearchRequest searchRequest : searchRequests) {
@@ -293,10 +293,10 @@ public class InnerHitsIT extends ESIntegTestCase {
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(hasChildQuery("comment", matchQuery("message", "elephant")))
-                        .addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "elephant")))
+                        .addInnerHit("comment", new InnerHitsBuilder.InnerHit().setType("comment").setQuery(matchQuery("message", "elephant")))
                         .request(),
                 client().prepareSearch("articles")
-                        .setQuery(hasChildQuery("comment", matchQuery("message", "elephant")).innerHit(new QueryInnerHits()))
+                        .setQuery(hasChildQuery("comment", matchQuery("message", "elephant")).innerHit(new QueryInnerHitBuilder()))
                         .request()
         };
         for (SearchRequest searchRequest : searchRequests) {
@@ -316,16 +316,11 @@ public class InnerHitsIT extends ESIntegTestCase {
             assertThat(innerHits.getAt(2).getId(), equalTo("6"));
             assertThat(innerHits.getAt(2).type(), equalTo("comment"));
         }
-        InnerHitsBuilder.InnerHit innerHit = new InnerHitsBuilder.InnerHit();
-        innerHit.highlightBuilder().field("message");
-        innerHit.setExplain(true);
-        innerHit.addFieldDataField("message");
-        innerHit.addScriptField("script", new Script("doc['message'].value"));
-        innerHit.setSize(1);
+
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(hasChildQuery("comment", matchQuery("message", "fox")))
-                        .addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit()
+                        .addInnerHit("comment", new InnerHitsBuilder.InnerHit().setType("comment")
                                         .setQuery(matchQuery("message", "fox"))
                                         .addHighlightedField("message")
                                         .setExplain(true)
@@ -333,11 +328,12 @@ public class InnerHitsIT extends ESIntegTestCase {
                                         .addScriptField("script", new Script("doc['message'].value"))
                                         .setSize(1)
                         ).request(),
-
                 client().prepareSearch("articles")
                         .setQuery(
                                 hasChildQuery("comment", matchQuery("message", "fox")).innerHit(
-                                        new QueryInnerHits(null, innerHit))).request() };
+                                        new QueryInnerHitBuilder().addHighlightedField("message").setExplain(true)
+                                                .addFieldDataField("message").addScriptField("script", new Script("doc['message'].value"))
+                                                .setSize(1))).request() };
 
         for (SearchRequest searchRequest : searchRequests) {
             SearchResponse response = client().search(searchRequest).actionGet();
@@ -389,17 +385,17 @@ public class InnerHitsIT extends ESIntegTestCase {
                     .setSize(numDocs)
                     .setTypes("parent")
                     .addSort("_uid", SortOrder.ASC)
-                    .addParentChildInnerHits("a", "child1", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size))
-                    .addParentChildInnerHits("b", "child2", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size))
+                    .addInnerHit("a", new InnerHitsBuilder.InnerHit().setType("child1").addSort("_uid", SortOrder.ASC).setSize(size))
+                    .addInnerHit("b", new InnerHitsBuilder.InnerHit().setType("child2").addSort("_uid", SortOrder.ASC).setSize(size))
                     .get();
         } else {
             BoolQueryBuilder boolQuery = new BoolQueryBuilder();
             if (randomBoolean()) {
-                boolQuery.should(hasChildQuery("child1", matchAllQuery()).innerHit(new QueryInnerHits("a", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size))));
-                boolQuery.should(hasChildQuery("child2", matchAllQuery()).innerHit(new QueryInnerHits("b", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size))));
+                boolQuery.should(hasChildQuery("child1", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("a").addSort("_uid", SortOrder.ASC).setSize(size)));
+                boolQuery.should(hasChildQuery("child2", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("b").addSort("_uid", SortOrder.ASC).setSize(size)));
             } else {
-                boolQuery.should(constantScoreQuery(hasChildQuery("child1", matchAllQuery()).innerHit(new QueryInnerHits("a", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size)))));
-                boolQuery.should(constantScoreQuery(hasChildQuery("child2", matchAllQuery()).innerHit(new QueryInnerHits("b", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size)))));
+                boolQuery.should(constantScoreQuery(hasChildQuery("child1", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("a").addSort("_uid", SortOrder.ASC).setSize(size))));
+                boolQuery.should(constantScoreQuery(hasChildQuery("child2", matchAllQuery()).innerHit(new QueryInnerHitBuilder().setName("b").addSort("_uid", SortOrder.ASC).setSize(size))));
             }
             searchResponse = client().prepareSearch("idx")
                     .setSize(numDocs)
@@ -451,7 +447,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         ensureGreen("articles");
         try {
             client().prepareSearch("articles")
-                    .addParentChildInnerHits("comment", null, new InnerHitsBuilder.InnerHit())
+                    .addInnerHit("comment", new InnerHitsBuilder.InnerHit())
                     .get();
         } catch (Exception e) {
             assertThat(e.getMessage(), containsString("Failed to build"));
@@ -478,7 +474,7 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .setQuery(
                         boolQuery()
                                 .must(matchQuery("body", "fail2ban"))
-                                .must(hasParentQuery("question", matchAllQuery()).innerHit(new QueryInnerHits()))
+                                .must(hasParentQuery("question", matchAllQuery()).innerHit(new QueryInnerHitBuilder()))
                 ).get();
         assertNoFailures(response);
         assertHitCount(response, 2);
@@ -517,10 +513,10 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("articles")
                 .setQuery(hasChildQuery("comment", hasChildQuery("remark", matchQuery("message", "good"))))
-                .addParentChildInnerHits("comment", "comment",
-                        new InnerHitsBuilder.InnerHit()
+                .addInnerHit("comment",
+                        new InnerHitsBuilder.InnerHit().setType("comment")
                                 .setQuery(hasChildQuery("remark", matchQuery("message", "good")))
-                                .addParentChildInnerHits("remark", "remark", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "good")))
+                                .addInnerHit("remark", new InnerHitsBuilder.InnerHit().setType("remark").setQuery(matchQuery("message", "good")))
                 )
                 .get();
 
@@ -541,10 +537,10 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         response = client().prepareSearch("articles")
                 .setQuery(hasChildQuery("comment", hasChildQuery("remark", matchQuery("message", "bad"))))
-                .addParentChildInnerHits("comment", "comment",
-                        new InnerHitsBuilder.InnerHit()
+                .addInnerHit("comment",
+                        new InnerHitsBuilder.InnerHit().setType("comment")
                                 .setQuery(hasChildQuery("remark", matchQuery("message", "bad")))
-                                .addParentChildInnerHits("remark", "remark", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "bad")))
+                                .addInnerHit("remark", new InnerHitsBuilder.InnerHit().setType("remark").setQuery(matchQuery("message", "bad")))
                 )
                 .get();
 
@@ -609,9 +605,10 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("articles")
                 .setQuery(nestedQuery("comments", nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "good"))))
-                .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit()
+                .addInnerHit("comment", new InnerHitsBuilder.InnerHit()
+                                .setPath("comments")
                                 .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "good")))
-                                .addNestedInnerHits("remark", "comments.remarks", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.remarks.message", "good")))
+                                .addInnerHit("remark", new InnerHitsBuilder.InnerHit().setPath("comments.remarks").setQuery(matchQuery("comments.remarks.message", "good")))
                 ).get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -634,7 +631,7 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         // Directly refer to the second level:
         response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad")).innerHit(new QueryInnerHits()))
+                .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad")).innerHit(new QueryInnerHitBuilder()))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -651,9 +648,10 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         response = client().prepareSearch("articles")
                 .setQuery(nestedQuery("comments", nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad"))))
-                .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit()
-                        .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad")))
-                        .addNestedInnerHits("remark", "comments.remarks", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.remarks.message", "bad"))))
+                .addInnerHit("comment", new InnerHitsBuilder.InnerHit()
+                                .setPath("comments")
+                                .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad")))
+                                .addInnerHit("remark", new InnerHitsBuilder.InnerHit().setPath("comments.remarks").setQuery(matchQuery("comments.remarks.message", "bad"))))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -688,7 +686,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         indexRandom(true, requests);
 
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits()))
+                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder()))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -726,8 +724,8 @@ public class InnerHitsIT extends ESIntegTestCase {
         indexRandom(true, requests);
 
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, new InnerHitsBuilder.InnerHit().field("comments.message"))))
-                        .get();
+                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder().field("comments.message")))
+                .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
         assertThat(response.getHits().getAt(0).id(), equalTo("1"));
@@ -763,10 +761,9 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .startObject("comments").field("message", "fox eat quick").endObject()
                 .endObject()));
         indexRandom(true, requests);
-        InnerHitsBuilder.InnerHit builder = new InnerHitsBuilder.InnerHit();
-        builder.highlightBuilder().field("comments.message");
+
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, builder)))
+                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder().addHighlightedField("comments.message")))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -785,13 +782,13 @@ public class InnerHitsIT extends ESIntegTestCase {
                         .addMapping("article", jsonBuilder().startObject()
                                         .startObject("_source").field("excludes", new String[]{"comments"}).endObject()
                                         .startObject("properties")
-                                        .startObject("comments")
-                                        .field("type", "nested")
-                                        .startObject("properties")
-                                        .startObject("message").field("type", "string").field("store", "yes").endObject()
-                                        .endObject()
-                                        .endObject()
-                                        .endObject()
+                                            .startObject("comments")
+                                                .field("type", "nested")
+                                                .startObject("properties")
+                                                    .startObject("message").field("type", "string").field("store", "yes").endObject()
+                                                .endObject()
+                                                .endObject()
+                                            .endObject()
                                         .endObject()
                         )
         );
@@ -802,11 +799,9 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .startObject("comments").field("message", "fox eat quick").endObject()
                 .endObject()));
         indexRandom(true, requests);
-        InnerHitsBuilder.InnerHit builder = new InnerHitsBuilder.InnerHit();
-        builder.field("comments.message");
-        builder.setFetchSource(true);
+
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, builder)))
+                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder().field("comments.message").setFetchSource(true)))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -842,11 +837,10 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .startObject("comments").field("message", "fox eat quick").endObject()
                 .endObject()));
         indexRandom(true, requests);
-        InnerHitsBuilder.InnerHit builder = new InnerHitsBuilder.InnerHit();
-        builder.highlightBuilder().field("comments.message");
+
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, builder)))
-                        .get();
+                .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHitBuilder().addHighlightedField("comments.message")))
+                .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
         assertThat(response.getHits().getAt(0).id(), equalTo("1"));
@@ -887,7 +881,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         indexRandom(true, requests);
 
         SearchResponse response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "fox")).innerHit(new QueryInnerHits()))
+                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "fox")).innerHit(new QueryInnerHitBuilder()))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -899,7 +893,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         assertThat(response.getHits().getAt(0).getInnerHits().get("comments.messages").getAt(0).getNestedIdentity().getChild(), nullValue());
 
         response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "bear")).innerHit(new QueryInnerHits()))
+                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "bear")).innerHit(new QueryInnerHitBuilder()))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -918,7 +912,7 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .endObject()));
         indexRandom(true, requests);
         response = client().prepareSearch("articles")
-                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "fox")).innerHit(new QueryInnerHits()))
+                .setQuery(nestedQuery("comments.messages", matchQuery("comments.messages.message", "fox")).innerHit(new QueryInnerHitBuilder()))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -934,11 +928,11 @@ public class InnerHitsIT extends ESIntegTestCase {
     public void testRoyals() throws Exception {
         assertAcked(
                 prepareCreate("royals")
-                        .addMapping("king")
-                        .addMapping("prince", "_parent", "type=king")
-                        .addMapping("duke", "_parent", "type=prince")
-                        .addMapping("earl", "_parent", "type=duke")
-                        .addMapping("baron", "_parent", "type=earl")
+                .addMapping("king")
+                .addMapping("prince", "_parent", "type=king")
+                .addMapping("duke", "_parent", "type=prince")
+                .addMapping("earl", "_parent", "type=duke")
+                .addMapping("baron", "_parent", "type=earl")
         );
 
         List<IndexRequestBuilder> requests = new ArrayList<>();
@@ -957,14 +951,15 @@ public class InnerHitsIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("royals")
                 .setTypes("duke")
-                .addParentChildInnerHits("earls", "earl", new InnerHitsBuilder.InnerHit()
+                .addInnerHit("earls", new InnerHitsBuilder.InnerHit()
+                                .setType("earl")
                                 .addSort(SortBuilders.fieldSort("_uid").order(SortOrder.ASC))
                                 .setSize(4)
-                                .addParentChildInnerHits("barons", "baron", new InnerHitsBuilder.InnerHit())
+                                .addInnerHit("barons", new InnerHitsBuilder.InnerHit().setType("baron"))
                 )
-                .addParentChildInnerHits("princes", "prince",
-                        new InnerHitsBuilder.InnerHit()
-                        .addParentChildInnerHits("kings", "king", new InnerHitsBuilder.InnerHit())
+                .addInnerHit("princes",
+                        new InnerHitsBuilder.InnerHit().setType("prince")
+                        .addInnerHit("kings", new InnerHitsBuilder.InnerHit().setType("king"))
                 )
                 .get();
         assertHitCount(response, 1);
@@ -1072,7 +1067,7 @@ public class InnerHitsIT extends ESIntegTestCase {
                                 .should(termQuery("nested1.n_field1", "n_value1_1").queryName("test1"))
                                 .should(termQuery("nested1.n_field1", "n_value1_3").queryName("test2"))
                                 .should(termQuery("nested1.n_field2", "n_value2_2").queryName("test3"))
-                ).innerHit(new QueryInnerHits(null, new InnerHitsBuilder.InnerHit().addSort("nested1.n_field1", SortOrder.ASC))))
+                ).innerHit(new QueryInnerHitBuilder().addSort("nested1.n_field1", SortOrder.ASC)))
                 .setSize(numDocs)
                 .addSort("field1", SortOrder.ASC)
                 .get();
@@ -1112,7 +1107,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         indexRandom(true, requests);
 
         SearchResponse response = client().prepareSearch("index")
-                .setQuery(hasChildQuery("child", matchQuery("field", "value1").queryName("_name1")).innerHit(new QueryInnerHits()))
+                .setQuery(hasChildQuery("child", matchQuery("field", "value1").queryName("_name1")).innerHit(new QueryInnerHitBuilder()))
                 .addSort("_uid", SortOrder.ASC)
                 .get();
         assertHitCount(response, 2);
@@ -1127,7 +1122,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         assertThat(response.getHits().getAt(1).getInnerHits().get("child").getAt(0).getMatchedQueries()[0], equalTo("_name1"));
 
         response = client().prepareSearch("index")
-                .setQuery(hasChildQuery("child", matchQuery("field", "value2").queryName("_name2")).innerHit(new QueryInnerHits()))
+                .setQuery(hasChildQuery("child", matchQuery("field", "value2").queryName("_name2")).innerHit(new QueryInnerHitBuilder()))
                 .addSort("_id", SortOrder.ASC)
                 .get();
         assertHitCount(response, 1);
@@ -1137,4 +1132,38 @@ public class InnerHitsIT extends ESIntegTestCase {
         assertThat(response.getHits().getAt(0).getInnerHits().get("child").getAt(0).getMatchedQueries()[0], equalTo("_name2"));
     }
 
+    @Test
+    public void testDontExplode() throws Exception {
+        assertAcked(prepareCreate("index1").addMapping("child", "_parent", "type=parent"));
+        List<IndexRequestBuilder> requests = new ArrayList<>();
+        requests.add(client().prepareIndex("index1", "parent", "1").setSource("{}"));
+        requests.add(client().prepareIndex("index1", "child", "1").setParent("1").setSource("field", "value1"));
+        indexRandom(true, requests);
+
+        SearchResponse response = client().prepareSearch("index1")
+                .setQuery(hasChildQuery("child", matchQuery("field", "value1")).innerHit(new QueryInnerHitBuilder().setSize(ArrayUtil.MAX_ARRAY_LENGTH - 1)))
+                .addSort("_uid", SortOrder.ASC)
+                .get();
+        assertNoFailures(response);
+        assertHitCount(response, 1);
+
+        assertAcked(prepareCreate("index2").addMapping("type", "nested", "type=nested"));
+        client().prepareIndex("index2", "type", "1").setSource(jsonBuilder().startObject()
+                .startArray("nested")
+                .startObject()
+                .field("field", "value1")
+                .endObject()
+                .endArray()
+                .endObject())
+        .setRefresh(true)
+        .get();
+
+        response = client().prepareSearch("index2")
+                .setQuery(nestedQuery("nested", matchQuery("nested.field", "value1")).innerHit(new QueryInnerHitBuilder().setSize(ArrayUtil.MAX_ARRAY_LENGTH - 1)))
+                .addSort("_uid", SortOrder.ASC)
+                .get();
+        assertNoFailures(response);
+        assertHitCount(response, 1);
+    }
+
 }
diff --git a/core/src/test/java/org/elasticsearch/search/morelikethis/ItemSerializationTests.java b/core/src/test/java/org/elasticsearch/search/morelikethis/ItemSerializationTests.java
index ab06a3d..5f5f42a 100644
--- a/core/src/test/java/org/elasticsearch/search/morelikethis/ItemSerializationTests.java
+++ b/core/src/test/java/org/elasticsearch/search/morelikethis/ItemSerializationTests.java
@@ -20,71 +20,28 @@
 package org.elasticsearch.search.morelikethis;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-import org.elasticsearch.action.get.MultiGetRequest;
-import org.elasticsearch.common.bytes.BytesArray;
+import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentHelper;
+import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.VersionType;
-import org.elasticsearch.index.query.MoreLikeThisQueryBuilder;
 import org.elasticsearch.index.query.MoreLikeThisQueryBuilder.Item;
-import org.elasticsearch.search.fetch.source.FetchSourceContext;
 import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
-import java.io.IOException;
-import java.util.List;
 import java.util.Random;
 
-import static org.elasticsearch.test.StreamsUtils.copyToStringFromClasspath;
-import static org.hamcrest.Matchers.is;
-
 public class ItemSerializationTests extends ESTestCase {
 
     private Item generateRandomItem(int arraySize, int stringSize) {
         String index = randomAsciiOfLength(stringSize);
         String type = randomAsciiOfLength(stringSize);
         String id = String.valueOf(Math.abs(randomInt()));
-        String routing = randomBoolean() ? randomAsciiOfLength(stringSize) : null;
         String[] fields = generateRandomStringArray(arraySize, stringSize, true);
-
+        String routing = randomBoolean() ? randomAsciiOfLength(stringSize) : null;
         long version = Math.abs(randomLong());
         VersionType versionType = RandomPicks.randomFrom(new Random(), VersionType.values());
-
-        FetchSourceContext fetchSourceContext;
-        switch (randomIntBetween(0, 3)) {
-            case 0 :
-                fetchSourceContext = new FetchSourceContext(randomBoolean());
-                break;
-            case 1 :
-                fetchSourceContext = new FetchSourceContext(generateRandomStringArray(arraySize, stringSize, true));
-                break;
-            case 2 :
-                fetchSourceContext = new FetchSourceContext(generateRandomStringArray(arraySize, stringSize, true),
-                        generateRandomStringArray(arraySize, stringSize, true));
-                break;
-            default:
-                fetchSourceContext = null;
-                break;
-        }
-        return (Item) new Item(index, type, id).routing(routing).fields(fields).version(version).versionType(versionType)
-                .fetchSourceContext(fetchSourceContext);
-    }
-
-    private String ItemToJSON(Item item) throws IOException {
-        XContentBuilder builder = XContentFactory.jsonBuilder();
-        builder.startObject();
-        builder.startArray("docs");
-        item.toXContent(builder, ToXContent.EMPTY_PARAMS);
-        builder.endArray();
-        builder.endObject();
-        return XContentHelper.convertToJson(builder.bytes(), false);
-    }
-
-    private MultiGetRequest.Item JSONtoItem(String json) throws Exception {
-        MultiGetRequest request = new MultiGetRequest().add(null, null, null, null, new BytesArray(json), true);
-        return request.getItems().get(0);
+        return new Item(index, type, id).fields(fields).routing(routing).version(version).versionType(versionType);
     }
 
     @Test
@@ -94,66 +51,10 @@ public class ItemSerializationTests extends ESTestCase {
         int maxStringSize = 8;
         for (int i = 0; i < numOfTrials; i++) {
             Item item1 = generateRandomItem(maxArraySize, maxStringSize);
-            String json = ItemToJSON(item1);
-            MultiGetRequest.Item item2 = JSONtoItem(json);
+            String json = item1.toXContent(XContentFactory.jsonBuilder(), ToXContent.EMPTY_PARAMS).string();
+            XContentParser parser = XContentFactory.xContent(json).createParser(json);
+            Item item2 = Item.parse(parser, ParseFieldMatcher.STRICT, new Item());
             assertEquals(item1, item2);
         }
     }
-
-    private List<MultiGetRequest.Item> testItemsFromJSON(String json) throws Exception {
-        MultiGetRequest request = new MultiGetRequest();
-        request.add(null, null, null, null, new BytesArray(json), true);
-        List<MultiGetRequest.Item> items = request.getItems();
-
-        assertEquals(items.size(), 3);
-        for (MultiGetRequest.Item item : items) {
-            assertThat(item.index(), is("test"));
-            assertThat(item.type(), is("type"));
-            FetchSourceContext fetchSource = item.fetchSourceContext();
-            switch (item.id()) {
-                case "1" :
-                    assertThat(fetchSource.fetchSource(), is(false));
-                    break;
-                case "2" :
-                    assertThat(fetchSource.fetchSource(), is(true));
-                    assertThat(fetchSource.includes(), is(new String[]{"field3", "field4"}));
-                    break;
-                case "3" :
-                    assertThat(fetchSource.fetchSource(), is(true));
-                    assertThat(fetchSource.includes(), is(new String[]{"user"}));
-                    assertThat(fetchSource.excludes(), is(new String[]{"user.location"}));
-                    break;
-                default:
-                    fail("item with id: " + item.id() + " is not 1, 2 or 3");
-                    break;
-            }
-        }
-        return items;
-    }
-
-    @Test
-    public void testSimpleItemSerializationFromFile() throws Exception {
-        // test items from JSON
-        List<MultiGetRequest.Item> itemsFromJSON = testItemsFromJSON(
-                copyToStringFromClasspath("/org/elasticsearch/search/morelikethis/items.json"));
-
-        // create builder from items
-        XContentBuilder builder = XContentFactory.jsonBuilder();
-        builder.startObject();
-        builder.startArray("docs");
-        for (MultiGetRequest.Item item : itemsFromJSON) {
-            MoreLikeThisQueryBuilder.Item itemForBuilder = (MoreLikeThisQueryBuilder.Item) new MoreLikeThisQueryBuilder.Item(
-                    item.index(), item.type(), item.id())
-                    .fetchSourceContext(item.fetchSourceContext())
-                    .fields(item.fields());
-            itemForBuilder.toXContent(builder, ToXContent.EMPTY_PARAMS);
-        }
-        builder.endArray();
-        builder.endObject();
-
-        // verify generated JSON lead to the same items
-        String json = XContentHelper.convertToJson(builder.bytes(), false);
-        testItemsFromJSON(json);
-    }
-
 }
diff --git a/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisIT.java b/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisIT.java
index 52df893..bbc992f 100644
--- a/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisIT.java
+++ b/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisIT.java
@@ -43,8 +43,8 @@ import static org.elasticsearch.client.Requests.*;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
 import static org.elasticsearch.index.query.QueryBuilders.moreLikeThisQuery;
+import static org.elasticsearch.index.query.QueryBuilders.termQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.notNullValue;
@@ -57,11 +57,11 @@ public class MoreLikeThisIT extends ESIntegTestCase {
     @Test
     public void testSimpleMoreLikeThis() throws Exception {
         logger.info("Creating index test");
-        assertAcked(prepareCreate("test").addMapping("type1", 
+        assertAcked(prepareCreate("test").addMapping("type1",
                 jsonBuilder().startObject().startObject("type1").startObject("properties")
-                    .startObject("text").field("type", "string").endObject()
-                    .endObject().endObject().endObject()));
-        
+                        .startObject("text").field("type", "string").endObject()
+                        .endObject().endObject().endObject()));
+
         logger.info("Running Cluster Health");
         assertThat(ensureGreen(), equalTo(ClusterHealthStatus.GREEN));
 
@@ -72,11 +72,10 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         logger.info("Running moreLikeThis");
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 1l);
     }
-    
-    
+
     @Test
     public void testSimpleMoreLikeOnLongField() throws Exception {
         logger.info("Creating index test");
@@ -89,23 +88,21 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         client().index(indexRequest("test").type("type2").id("2").source(jsonBuilder().startObject().field("some_long", 0).endObject())).actionGet();
         client().index(indexRequest("test").type("type1").id("3").source(jsonBuilder().startObject().field("some_long", -666).endObject())).actionGet();
 
-
         client().admin().indices().refresh(refreshRequest()).actionGet();
 
         logger.info("Running moreLikeThis");
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 0l);
     }
 
-
     @Test
     public void testMoreLikeThisWithAliases() throws Exception {
         logger.info("Creating index test");
-        assertAcked(prepareCreate("test").addMapping("type1", 
+        assertAcked(prepareCreate("test").addMapping("type1",
                 jsonBuilder().startObject().startObject("type1").startObject("properties")
-                    .startObject("text").field("type", "string").endObject()
-                    .endObject().endObject().endObject()));
+                        .startObject("text").field("type", "string").endObject()
+                        .endObject().endObject().endObject()));
         logger.info("Creating aliases alias release");
         client().admin().indices().aliases(indexAliasesRequest().addAlias("release", termQuery("text", "release"), "test")).actionGet();
         client().admin().indices().aliases(indexAliasesRequest().addAlias("beta", termQuery("text", "beta"), "test")).actionGet();
@@ -122,27 +119,26 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         logger.info("Running moreLikeThis on index");
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 2l);
 
         logger.info("Running moreLikeThis on beta shard");
         response = client().prepareSearch("beta").setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 1l);
         assertThat(response.getHits().getAt(0).id(), equalTo("3"));
 
         logger.info("Running moreLikeThis on release shard");
         response = client().prepareSearch("release").setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 1l);
         assertThat(response.getHits().getAt(0).id(), equalTo("2"));
 
         logger.info("Running moreLikeThis on alias with node client");
         response = internalCluster().clientNodeClient().prepareSearch("beta").setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 1l);
         assertThat(response.getHits().getAt(0).id(), equalTo("3"));
-
     }
 
     @Test
@@ -160,11 +156,11 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         assertThat(ensureGreen(), equalTo(ClusterHealthStatus.GREEN));
 
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("foo", "bar", "1"))).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("foo", "bar", "1"))).get();
         assertNoFailures(response);
         assertThat(response, notNullValue());
         response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("foo", "bar", "1"))).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("foo", "bar", "1"))).get();
         assertNoFailures(response);
         assertThat(response, notNullValue());
     }
@@ -186,7 +182,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         client().admin().indices().prepareRefresh("foo").execute().actionGet();
 
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().addItem((Item) new Item("foo", "bar", "1").routing("2"))).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("foo", "bar", "1").routing("2"))).get();
         assertNoFailures(response);
         assertThat(response, notNullValue());
     }
@@ -209,7 +205,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
                 .execute().actionGet();
         client().admin().indices().prepareRefresh("foo").execute().actionGet();
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().addItem((Item) new Item("foo", "bar", "1").routing("4000"))).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("foo", "bar", "1").routing("4000"))).get();
         assertNoFailures(response);
         assertThat(response, notNullValue());
     }
@@ -237,12 +233,12 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         // Implicit list of fields -> ignore numeric fields
         SearchResponse searchResponse = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("test", "type", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("test", "type", "1")).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(searchResponse, 1l);
 
         // Explicit list of fields including numeric fields -> fail
         assertThrows(client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder("string_value", "int_value").addItem(new Item("test", "type", "1")).minTermFreq(1).minDocFreq(1)), SearchPhaseExecutionException.class);
+                new MoreLikeThisQueryBuilder("string_value", "int_value").addLikeItem(new Item("test", "type", "1")).minTermFreq(1).minDocFreq(1)), SearchPhaseExecutionException.class);
 
         // mlt query with no field -> OK
         searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery().likeText("index").minTermFreq(1).minDocFreq(1)).execute().actionGet();
@@ -299,16 +295,16 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         logger.info("Running More Like This with include true");
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1).include(true).minimumShouldMatch("0%")).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1).include(true).minimumShouldMatch("0%")).get();
         assertOrderedSearchHits(response, "1", "2");
 
         response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("test", "type1", "2")).minTermFreq(1).minDocFreq(1).include(true).minimumShouldMatch("0%")).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("test", "type1", "2")).minTermFreq(1).minDocFreq(1).include(true).minimumShouldMatch("0%")).get();
         assertOrderedSearchHits(response, "2", "1");
 
         logger.info("Running More Like This with include false");
         response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().addItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1).minimumShouldMatch("0%")).get();
+                new MoreLikeThisQueryBuilder().addLikeItem(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1).minimumShouldMatch("0%")).get();
         assertSearchHits(response, "2");
     }
 
@@ -359,7 +355,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         logger.info("Running MoreLikeThis");
         MoreLikeThisQueryBuilder queryBuilder = QueryBuilders.moreLikeThisQuery("text").include(true).minTermFreq(1).minDocFreq(1)
-                .addItem(new MoreLikeThisQueryBuilder.Item("test", "type0", "0"));
+                .addLikeItem(new Item("test", "type0", "0"));
 
         String[] types = new String[numOfTypes];
         for (int i = 0; i < numOfTypes; i++) {
@@ -389,8 +385,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         indexRandom(true, builders);
 
         int maxIters = randomIntBetween(10, 20);
-        for (int i = 0; i < maxIters; i++)
-        {
+        for (int i = 0; i < maxIters; i++) {
             int max_query_terms = randomIntBetween(1, values.length);
             logger.info("Running More Like This with max_query_terms = %s", max_query_terms);
             MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery("text").ids("0").minTermFreq(1).minDocFreq(1)
@@ -451,14 +446,14 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         logger.info("Indexing a single document ...");
         XContentBuilder doc = jsonBuilder().startObject();
         for (int i = 0; i < numFields; i++) {
-            doc.field("field"+i, generateRandomStringArray(5, 10, false)+"a"); // make sure they are not all empty
+            doc.field("field" + i, generateRandomStringArray(5, 10, false) + "a"); // make sure they are not all empty
         }
         doc.endObject();
         indexRandom(true, client().prepareIndex("test", "type1", "0").setSource(doc));
 
         logger.info("Checking the document matches ...");
         MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery()
-                .like((Item) new Item().doc(doc).index("test").type("type1").routing("0"))  // routing to ensure we hit the shard with the doc
+                .like(new Item("test", "type1", doc).routing("0"))  // routing to ensure we hit the shard with the doc
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .maxQueryTerms(100)
@@ -479,18 +474,18 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         logger.info("Creating an index with a single document ...");
         indexRandom(true, client().prepareIndex("test", "type1", "1").setSource(jsonBuilder()
                 .startObject()
-                    .field("text", "Hello World!")
-                    .field("date", "2009-01-01")
+                .field("text", "Hello World!")
+                .field("date", "2009-01-01")
                 .endObject()));
 
         logger.info("Checking with a malformed field value ...");
         XContentBuilder malformedFieldDoc = jsonBuilder()
                 .startObject()
-                    .field("text", "Hello World!")
-                    .field("date", "this is not a date!")
+                .field("text", "Hello World!")
+                .field("date", "this is not a date!")
                 .endObject();
         MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery()
-                .like((Item) new Item().doc(malformedFieldDoc).index("test").type("type1"))
+                .like(new Item("test", "type1", malformedFieldDoc))
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .minimumShouldMatch("0%");
@@ -502,7 +497,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         logger.info("Checking with an empty document ...");
         XContentBuilder emptyDoc = jsonBuilder().startObject().endObject();
         mltQuery = moreLikeThisQuery()
-                .like((Item) new Item().doc(emptyDoc).index("test").type("type1"))
+                .like(new Item("test", "type1", emptyDoc))
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .minimumShouldMatch("0%");
@@ -514,7 +509,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         logger.info("Checking when document is malformed ...");
         XContentBuilder malformedDoc = jsonBuilder().startObject();
         mltQuery = moreLikeThisQuery()
-                .like((Item) new Item().doc(malformedDoc).index("test").type("type1"))
+                .like(new Item("test", "type1", malformedDoc))
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .minimumShouldMatch("0%");
@@ -526,11 +521,11 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         logger.info("Checking the document matches otherwise ...");
         XContentBuilder normalDoc = jsonBuilder()
                 .startObject()
-                    .field("text", "Hello World!")
-                    .field("date", "1000-01-01") // should be properly parsed but ignored ...
+                .field("text", "Hello World!")
+                .field("date", "1000-01-01") // should be properly parsed but ignored ...
                 .endObject();
         mltQuery = moreLikeThisQuery()
-                .like((Item) new Item().doc(normalDoc).index("test").type("type1"))
+                .like(new Item("test", "type1", normalDoc))
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .minimumShouldMatch("100%");  // strict all terms must match but date is ignored
@@ -541,7 +536,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
     }
 
     @Test
-    public void testMoreLikeThisIgnoreLike() throws ExecutionException, InterruptedException, IOException {
+    public void testMoreLikeThisUnlike() throws ExecutionException, InterruptedException, IOException {
         createIndex("test");
         ensureGreen();
         int numFields = randomIntBetween(5, 10);
@@ -561,8 +556,8 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         indexRandom(true, builders);
 
         logger.info("First check the document matches all indexed docs.");
-        MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery("field0")
-                .like((Item) new Item().doc(doc).index("test").type("type1"))
+        MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery()
+                .like(new Item("test", "type1", doc))
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .maxQueryTerms(100)
@@ -577,11 +572,12 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         for (int i = 0; i < numFields; i++) {
             docs.add(new Item("test", "type1", i+""));
             mltQuery = moreLikeThisQuery()
-                    .like((Item) new Item().doc(doc).index("test").type("type1"))
+                    .like(new Item("test", "type1", doc))
                     .ignoreLike(docs.toArray(Item.EMPTY_ARRAY))
                     .minTermFreq(0)
                     .minDocFreq(0)
                     .maxQueryTerms(100)
+                    .include(true)
                     .minimumShouldMatch("0%");
             response = client().prepareSearch("test").setTypes("type1").setQuery(mltQuery).get();
             assertSearchResponse(response);
@@ -628,5 +624,4 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         assertSearchResponse(response);
         assertHitCount(response, 1);
     }
-
 }
diff --git a/core/src/test/java/org/elasticsearch/search/morelikethis/items.json b/core/src/test/java/org/elasticsearch/search/morelikethis/items.json
deleted file mode 100644
index dc56fc3..0000000
--- a/core/src/test/java/org/elasticsearch/search/morelikethis/items.json
+++ /dev/null
@@ -1,25 +0,0 @@
-{
-    "docs" : [
-        {
-            "_index" : "test",
-            "_type" : "type",
-            "_id" : "1",
-            "_source" : false
-        },
-        {
-            "_index" : "test",
-            "_type" : "type",
-            "_id" : "2",
-            "_source" : ["field3", "field4"]
-        },
-        {
-            "_index" : "test",
-            "_type" : "type",
-            "_id" : "3",
-            "_source" : {
-                "include": ["user"],
-                "exclude": ["user.location"]
-            }
-        }
-    ]
-}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java b/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java
index 793d365..b9099d0 100644
--- a/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/MultiMatchQueryIT.java
@@ -28,7 +28,6 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.MatchQueryBuilder;
 import org.elasticsearch.index.query.MultiMatchQueryBuilder;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHits;
@@ -155,7 +154,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         MatchQueryBuilder.Type type = randomBoolean() ? null : MatchQueryBuilder.Type.BOOLEAN;
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         Set<String> topNIds = Sets.newHashSet("theone", "theother");
         for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
             topNIds.remove(searchResponse.getHits().getAt(i).getId());
@@ -167,25 +166,25 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).useDisMax(false).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).useDisMax(false).type(type))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theone"), hasId("theother")));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(type))).get();
         assertFirstHit(searchResponse, hasId("theother"));
 
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
     }
@@ -194,18 +193,18 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
     public void testPhraseType() {
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("Man the Ultimate", "full_name_phrase", "first_name_phrase", "last_name_phrase", "category_phrase")
-                        .operator(Operator.OR).type(MatchQueryBuilder.Type.PHRASE))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(MatchQueryBuilder.Type.PHRASE))).get();
         assertFirstHit(searchResponse, hasId("ultimate2"));
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("Captain", "full_name_phrase", "first_name_phrase", "last_name_phrase", "category_phrase")
-                        .operator(Operator.OR).type(MatchQueryBuilder.Type.PHRASE))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(MatchQueryBuilder.Type.PHRASE))).get();
         assertThat(searchResponse.getHits().getTotalHits(), greaterThan(1l));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("the Ul", "full_name_phrase", "first_name_phrase", "last_name_phrase", "category_phrase")
-                        .operator(Operator.OR).type(MatchQueryBuilder.Type.PHRASE_PREFIX))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).type(MatchQueryBuilder.Type.PHRASE_PREFIX))).get();
         assertSearchHits(searchResponse, "ultimate2", "ultimate1");
         assertHitCount(searchResponse, 2l);
     }
@@ -264,7 +263,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         Float cutoffFrequency = randomBoolean() ? Math.min(1, numDocs * 1.f / between(10, 20)) : 1.f / between(10, 20);
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).cutoffFrequency(cutoffFrequency))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).cutoffFrequency(cutoffFrequency))).get();
         Set<String> topNIds = Sets.newHashSet("theone", "theother");
         for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
             topNIds.remove(searchResponse.getHits().getAt(i).getId());
@@ -277,39 +276,39 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         cutoffFrequency = randomBoolean() ? Math.min(1, numDocs * 1.f / between(10, 20)) : 1.f / between(10, 20);
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).useDisMax(false).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).useDisMax(false).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theone"), hasId("theother")));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
         long size = searchResponse.getHits().getTotalHits();
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).useDisMax(false).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).useDisMax(false).type(type))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theone"), hasId("theother")));
         assertThat("common terms expected to be a way smaller result set", size, lessThan(searchResponse.getHits().getTotalHits()));
 
         cutoffFrequency = randomBoolean() ? Math.min(1, numDocs * 1.f / between(10, 20)) : 1.f / between(10, 20);
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.OR).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.OR).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertFirstHit(searchResponse, hasId("theother"));
 
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
-                        .operator(Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
+                        .operator(MatchQueryBuilder.Operator.AND).cutoffFrequency(cutoffFrequency).type(type))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "first_name", "last_name", "category")
-                        .operator(Operator.AND).cutoffFrequency(cutoffFrequency)
+                        .operator(MatchQueryBuilder.Operator.AND).cutoffFrequency(cutoffFrequency)
                         .analyzer("category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS))).get();
         assertHitCount(searchResponse, 1l);
@@ -331,7 +330,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 SearchResponse left = client().prepareSearch("test").setSize(numDocs)
                         .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
                         .setQuery(randomizeType(multiMatchQueryBuilder
-                                .operator(Operator.OR).type(type))).get();
+                                .operator(MatchQueryBuilder.Operator.OR).type(type))).get();
 
                 SearchResponse right = client().prepareSearch("test").setSize(numDocs)
                         .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
@@ -347,7 +346,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
             {
                 MatchQueryBuilder.Type type = randomBoolean() ? null : MatchQueryBuilder.Type.BOOLEAN;
                 String minShouldMatch = randomBoolean() ? null : "" + between(0, 1);
-                Operator op = randomBoolean() ? Operator.AND : Operator.OR;
+                MatchQueryBuilder.Operator op = randomBoolean() ? MatchQueryBuilder.Operator.AND : MatchQueryBuilder.Operator.OR;
                 MultiMatchQueryBuilder multiMatchQueryBuilder = randomBoolean() ? multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category") :
                         multiMatchQuery("captain america", "*_name", randomBoolean() ? "category" : "categ*");
                 SearchResponse left = client().prepareSearch("test").setSize(numDocs)
@@ -368,7 +367,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
 
             {
                 String minShouldMatch = randomBoolean() ? null : "" + between(0, 1);
-                Operator op = randomBoolean() ? Operator.AND : Operator.OR;
+                MatchQueryBuilder.Operator op = randomBoolean() ? MatchQueryBuilder.Operator.AND : MatchQueryBuilder.Operator.OR;
                 SearchResponse left = client().prepareSearch("test").setSize(numDocs)
                         .addSort(SortBuilders.scoreSort()).addSort(SortBuilders.fieldSort("_uid"))
                         .setQuery(randomizeType(multiMatchQuery("capta", "full_name", "first_name", "last_name", "category")
@@ -386,7 +385,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
             }
             {
                 String minShouldMatch = randomBoolean() ? null : "" + between(0, 1);
-                Operator op = randomBoolean() ? Operator.AND : Operator.OR;
+                MatchQueryBuilder.Operator op = randomBoolean() ? MatchQueryBuilder.Operator.AND : MatchQueryBuilder.Operator.OR;
                 SearchResponse left;
                 if (randomBoolean()) {
                     left = client().prepareSearch("test").setSize(numDocs)
@@ -417,13 +416,13 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, hasId("theone"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero captain america", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, hasId("theone"));
         assertSecondHit(searchResponse, hasId("theother"));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
@@ -431,13 +430,13 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("marvel hero", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, hasId("theother"));
 
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
@@ -445,7 +444,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 .setQuery(randomizeType(multiMatchQuery("captain america 15", "full_name", "first_name", "last_name", "category", "skill")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .analyzer("category")
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
 
@@ -466,7 +465,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .cutoffFrequency(0.1f)
                         .analyzer("category")
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertFirstHit(searchResponse, anyOf(hasId("theother"), hasId("theone")));
         long numResults = searchResponse.getHits().totalHits();
 
@@ -474,7 +473,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .analyzer("category")
-                        .operator(Operator.OR))).get();
+                        .operator(MatchQueryBuilder.Operator.OR))).get();
         assertThat(numResults, lessThan(searchResponse.getHits().getTotalHits()));
         assertFirstHit(searchResponse, hasId("theone"));
 
@@ -484,28 +483,28 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
                         .analyzer("category")
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("theone"));
         // counter example
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(randomBoolean() ? MultiMatchQueryBuilder.Type.CROSS_FIELDS : null)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 0l);
 
         // counter example
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("captain america marvel hero", "first_name", "last_name", "category")
                         .type(randomBoolean() ? MultiMatchQueryBuilder.Type.CROSS_FIELDS : null)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertHitCount(searchResponse, 0l);
 
         // test if boosts work
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("the ultimate", "full_name", "first_name", "last_name^2", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertFirstHit(searchResponse, hasId("ultimate1"));   // has ultimate in the last_name and that is boosted
         assertSecondHit(searchResponse, hasId("ultimate2"));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
@@ -515,7 +514,7 @@ public class MultiMatchQueryIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch("test")
                 .setQuery(randomizeType(multiMatchQuery("the ultimate", "full_name", "first_name", "last_name", "category")
                         .type(MultiMatchQueryBuilder.Type.CROSS_FIELDS)
-                        .operator(Operator.AND))).get();
+                        .operator(MatchQueryBuilder.Operator.AND))).get();
         assertFirstHit(searchResponse, hasId("ultimate2"));
         assertSecondHit(searchResponse, hasId("ultimate1"));
         assertThat(searchResponse.getHits().hits()[0].getScore(), greaterThan(searchResponse.getHits().hits()[1].getScore()));
diff --git a/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java b/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
index 0b7bc87..7fa543a 100644
--- a/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.search.query;
 
 import org.apache.lucene.util.English;
+import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
 import org.elasticsearch.action.index.IndexRequestBuilder;
@@ -31,8 +32,15 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.mapper.MapperParsingException;
-import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.BoolQueryBuilder;
+import org.elasticsearch.index.query.CommonTermsQueryBuilder.Operator;
+import org.elasticsearch.index.query.MatchQueryBuilder;
 import org.elasticsearch.index.query.MatchQueryBuilder.Type;
+import org.elasticsearch.index.query.MultiMatchQueryBuilder;
+import org.elasticsearch.index.query.QueryBuilders;
+import org.elasticsearch.index.query.QueryStringQueryBuilder;
+import org.elasticsearch.index.query.TermQueryBuilder;
+import org.elasticsearch.index.query.WrapperQueryBuilder;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.SearchHit;
@@ -56,8 +64,24 @@ import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
 import static org.elasticsearch.test.VersionUtils.randomVersion;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
-import static org.hamcrest.Matchers.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFirstHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHits;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSecondHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertThirdHit;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasId;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasScore;
+import static org.hamcrest.Matchers.allOf;
+import static org.hamcrest.Matchers.closeTo;
+import static org.hamcrest.Matchers.containsString;
+import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.greaterThan;
+import static org.hamcrest.Matchers.is;
 
 public class SearchQueryIT extends ESIntegTestCase {
 
@@ -327,18 +351,18 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("2"));
 
         // try the same with match query
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.OR)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.OR)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
         assertThirdHit(searchResponse, hasId("3"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND).analyzer("stop")).get();
         assertHitCount(searchResponse, 3l);
         // stop drops "the" since its a stopword
         assertFirstHit(searchResponse, hasId("1"));
@@ -346,7 +370,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("2"));
 
         // try the same with multi match query
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the quick brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the quick brown", "field1", "field2").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
         assertSecondHit(searchResponse, hasId("1"));
@@ -419,18 +443,18 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("2"));
 
         // try the same with match query
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.OR)).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.OR)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("1"));
         assertSecondHit(searchResponse, hasId("2"));
         assertThirdHit(searchResponse, hasId("3"));
 
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND).analyzer("stop")).get();
         assertHitCount(searchResponse, 3l);
         // stop drops "the" since its a stopword
         assertFirstHit(searchResponse, hasId("1"));
@@ -443,7 +467,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertSecondHit(searchResponse, hasId("2"));
 
         // try the same with multi match query
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the fast brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the fast brown", "field1", "field2").cutoffFrequency(3).operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 3l);
         assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
         assertSecondHit(searchResponse, hasId("1"));
@@ -914,7 +938,7 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         client().admin().indices().prepareRefresh("test").get();
         builder = multiMatchQuery("value1", "field1", "field2")
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+                .operator(MatchQueryBuilder.Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
         searchResponse = client().prepareSearch()
                 .setQuery(builder)
                 .get();
@@ -923,14 +947,14 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         refresh();
         builder = multiMatchQuery("value1", "field1", "field3^1.5")
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+                .operator(MatchQueryBuilder.Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
         searchResponse = client().prepareSearch().setQuery(builder).get();
         assertHitCount(searchResponse, 2l);
         assertSearchHits(searchResponse, "3", "1");
 
         client().admin().indices().prepareRefresh("test").get();
         builder = multiMatchQuery("value1").field("field1").field("field3", 1.5f)
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+                .operator(MatchQueryBuilder.Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
         searchResponse = client().prepareSearch().setQuery(builder).get();
         assertHitCount(searchResponse, 2l);
         assertSearchHits(searchResponse, "3", "1");
@@ -1573,9 +1597,10 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test").setQuery(
-                spanNearQuery(3)
+                spanNearQuery()
                         .clause(spanTermQuery("description", "foo"))
-                        .clause(spanTermQuery("description", "other"))).get();
+                        .clause(spanTermQuery("description", "other"))
+                        .slop(3)).get();
         assertHitCount(searchResponse, 3l);
     }
 
@@ -1620,22 +1645,33 @@ public class SearchQueryIT extends ESIntegTestCase {
         refresh();
 
         SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(1)
+                .setQuery(spanNotQuery().include(spanNearQuery()
                         .clause(QueryBuilders.spanTermQuery("description", "quick"))
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "brown"))).get();
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "brown"))).get();
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(1)
+                .setQuery(spanNotQuery().include(spanNearQuery()
                         .clause(QueryBuilders.spanTermQuery("description", "quick"))
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "sleeping")).dist(5)).get();
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "sleeping")).dist(5)).get();
         assertHitCount(searchResponse, 1l);
 
         searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(1)
+                .setQuery(spanNotQuery().include(spanNearQuery()
                         .clause(QueryBuilders.spanTermQuery("description", "quick"))
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "jumped")).pre(1).post(1)).get();
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "jumped")).pre(1).post(1)).get();
         assertHitCount(searchResponse, 1l);
+
+        try {
+            client().prepareSearch("test")
+                    .setQuery(spanNotQuery().include(spanNearQuery()
+                            .clause(QueryBuilders.spanTermQuery("description", "quick"))
+                            .clause(QueryBuilders.spanTermQuery("description", "fox")).slop(1)).exclude(spanTermQuery("description", "jumped")).dist(2).pre(2)
+                    ).get();
+            fail("ElasticsearchIllegalArgumentException should have been caught");
+        } catch (ElasticsearchException e) {
+            assertThat("ElasticsearchIllegalArgumentException should have been caught", e.getDetailedMessage(), containsString("spanNot can either use [dist] or [pre] & [post] (or none)"));
+        }
     }
 
     @Test
@@ -1731,18 +1767,18 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
         refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fast").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fast").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
 
         client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
         refresh();
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
     }
 
@@ -1762,12 +1798,12 @@ public class SearchQueryIT extends ESIntegTestCase {
 
         client().prepareIndex("test", "test", "1").setSource("text", "the fox runs across the street").get();
         refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
 
         client().prepareIndex("test", "test", "2").setSource("text", "run fox run").get();
         refresh();
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(MatchQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
     }
 
@@ -1788,19 +1824,19 @@ public class SearchQueryIT extends ESIntegTestCase {
         client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
         refresh();
 
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("fast").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("fast").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1);
 
         client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
         refresh();
 
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(QueryStringQueryBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 2);
     }
 
@@ -1826,7 +1862,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         SearchResponse response = client()
                 .prepareSearch("test")
                 .setQuery(
-                        queryStringQuery("foo.baz").useDisMax(false).defaultOperator(Operator.AND)
+                        queryStringQuery("foo.baz").useDisMax(false).defaultOperator(QueryStringQueryBuilder.Operator.AND)
                                 .field("field1").field("field2")).get();
         assertHitCount(response, 1l);
     }
@@ -1892,7 +1928,7 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertSearchHits(searchResponse, "1", "2", "3");
         searchResponse = client().prepareSearch("index1", "index2", "index3")
                 .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
-                        .noMatchQuery(QueryBuilders.matchAllQuery())).get();
+                        .noMatchQuery("all")).get();
         assertHitCount(searchResponse, 3l);
         assertSearchHits(searchResponse, "1", "2", "3");
 
@@ -1903,7 +1939,6 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertFirstHit(searchResponse, hasId("1"));
     }
 
-    @AwaitsFix(bugUrl = "https://github.com/elastic/elasticsearch/issues/12822")
     @Test // https://github.com/elasticsearch/elasticsearch/issues/2416
     public void testIndicesQuerySkipParsing() throws Exception {
         createIndex("simple");
diff --git a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
index a8c5ccb..e41c451 100644
--- a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
@@ -23,7 +23,7 @@ import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.BoolQueryBuilder;
-import org.elasticsearch.index.query.Operator;
+import org.elasticsearch.index.query.SimpleQueryStringBuilder;
 import org.elasticsearch.index.query.SimpleQueryStringFlag;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
@@ -33,7 +33,10 @@ import java.util.Locale;
 import java.util.concurrent.ExecutionException;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.*;
+import static org.elasticsearch.index.query.QueryBuilders.boolQuery;
+import static org.elasticsearch.index.query.QueryBuilders.queryStringQuery;
+import static org.elasticsearch.index.query.QueryBuilders.simpleQueryStringQuery;
+import static org.elasticsearch.index.query.QueryBuilders.termQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.hamcrest.Matchers.equalTo;
 
@@ -67,7 +70,7 @@ public class SimpleQueryStringIT extends ESIntegTestCase {
         assertFirstHit(searchResponse, hasId("3"));
 
         searchResponse = client().prepareSearch().setQuery(
-                simpleQueryStringQuery("foo bar").defaultOperator(Operator.AND)).get();
+                simpleQueryStringQuery("foo bar").defaultOperator(SimpleQueryStringBuilder.Operator.AND)).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("3"));
 
@@ -248,21 +251,21 @@ public class SimpleQueryStringIT extends ESIntegTestCase {
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("foo | bar")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.OR)).get();
         assertHitCount(searchResponse, 3l);
         assertSearchHits(searchResponse, "1", "2", "3");
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("foo | bar")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.NONE)).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("3"));
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("baz | egg*")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.NONE)).get();
         assertHitCount(searchResponse, 0l);
 
@@ -279,7 +282,7 @@ public class SimpleQueryStringIT extends ESIntegTestCase {
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("baz | egg*")
-                        .defaultOperator(Operator.AND)
+                        .defaultOperator(SimpleQueryStringBuilder.Operator.AND)
                         .flags(SimpleQueryStringFlag.WHITESPACE, SimpleQueryStringFlag.PREFIX)).get();
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("4"));
diff --git a/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java b/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
index 5b559da..6aa31ca 100644
--- a/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
+++ b/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
@@ -33,7 +33,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.MatchQueryBuilder;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
 import org.elasticsearch.script.Script;
@@ -117,7 +116,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         ensureYellow();
         refresh();
         SearchResponse searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                 .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "quick brown").slop(2).boost(4.0f)).setRescoreQueryWeight(2))
                 .setRescoreWindow(5).execute().actionGet();
 
@@ -127,7 +126,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         assertThat(searchResponse.getHits().getHits()[2].getId(), equalTo("2"));
 
         searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                 .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(3)))
                 .setRescoreWindow(5).execute().actionGet();
 
@@ -137,7 +136,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         assertThirdHit(searchResponse, hasId("3"));
 
         searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                 .setRescorer(RescoreBuilder.queryRescorer((QueryBuilders.matchPhraseQuery("field1", "the quick brown"))))
                 .setRescoreWindow(5).execute().actionGet();
 
@@ -180,7 +179,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         client().admin().indices().prepareRefresh("test").execute().actionGet();
         SearchResponse searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
                 .setSize(5)
                 .setRescorer(
@@ -195,7 +194,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
 
         searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
                 .setSize(5)
                 .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
@@ -212,7 +211,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         // Make sure non-zero from works:
         searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(2)
                 .setSize(5)
                 .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
@@ -321,7 +320,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
 
         SearchResponse searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
             .setSize(5).execute().actionGet();
         assertThat(searchResponse.getHits().hits().length, equalTo(4));
@@ -334,7 +333,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
         // Now, penalizing rescore (nothing matches the rescore query):
         searchResponse = client()
                 .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(MatchQueryBuilder.Operator.OR))
                 .setFrom(0)
                 .setSize(5)
                 .setRescorer(
@@ -426,7 +425,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                     .prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR))
                     .setFrom(0)
                     .setSize(resultSize)
                     .setRescorer(
@@ -441,7 +440,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
             SearchResponse plain = client().prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR)).setFrom(0).setSize(resultSize)
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR)).setFrom(0).setSize(resultSize)
                     .execute().actionGet();
             
             // check equivalence
@@ -451,7 +450,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                     .prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR))
                     .setFrom(0)
                     .setSize(resultSize)
                     .setRescorer(
@@ -469,7 +468,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                     .prepareSearch()
                     .setSearchType(SearchType.QUERY_THEN_FETCH)
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(MatchQueryBuilder.Operator.OR))
                     .setFrom(0)
                     .setSize(resultSize)
                     .setRescorer(
@@ -504,7 +503,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
             SearchResponse searchResponse = client()
                     .prepareSearch()
                     .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                     .setRescorer(
                             RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(2).boost(4.0f))
                                     .setQueryWeight(0.5f).setRescoreQueryWeight(0.4f)).setRescoreWindow(5).setExplain(true).execute()
@@ -542,7 +541,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
             SearchResponse searchResponse = client()
                     .prepareSearch()
                     .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                     .setRescorer(innerRescoreQuery).setRescoreWindow(5).setExplain(true).execute()
                     .actionGet();
             assertHitCount(searchResponse, 3);
@@ -565,7 +564,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                 searchResponse = client()
                         .prepareSearch()
                         .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                        .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                        .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(MatchQueryBuilder.Operator.OR))
                         .addRescorer(innerRescoreQuery).setRescoreWindow(5)
                         .addRescorer(outerRescoreQuery).setRescoreWindow(10)
                         .setExplain(true).get();
diff --git a/core/src/test/java/org/elasticsearch/test/ESTestCase.java b/core/src/test/java/org/elasticsearch/test/ESTestCase.java
index a28302b..b1f0a8f 100644
--- a/core/src/test/java/org/elasticsearch/test/ESTestCase.java
+++ b/core/src/test/java/org/elasticsearch/test/ESTestCase.java
@@ -379,27 +379,17 @@ public abstract class ESTestCase extends LuceneTestCase {
         return RandomizedTest.randomRealisticUnicodeOfCodepointLength(codePoints);
     }
 
-    public static String[] generateRandomStringArray(int maxArraySize, int maxStringSize, boolean allowNull, boolean allowEmpty) {
+    public static String[] generateRandomStringArray(int maxArraySize, int maxStringSize, boolean allowNull) {
         if (allowNull && random().nextBoolean()) {
             return null;
         }
-        int arraySize = randomIntBetween(allowEmpty ? 0 : 1, maxArraySize);
-        String[] array = new String[arraySize];
-        for (int i = 0; i < arraySize; i++) {
+        String[] array = new String[random().nextInt(maxArraySize)]; // allow empty arrays
+        for (int i = 0; i < array.length; i++) {
             array[i] = RandomStrings.randomAsciiOfLength(random(), maxStringSize);
         }
         return array;
     }
 
-    public static String[] generateRandomStringArray(int maxArraySize, int maxStringSize, boolean allowNull) {
-        return generateRandomStringArray(maxArraySize, maxStringSize, allowNull, true);
-    }
-
-    public static String randomTimeValue() {
-        final String[] values = new String[]{"d", "H", "ms", "s", "S", "w"};
-        return randomIntBetween(0, 1000) + randomFrom(values);
-    }
-
     /**
      * Runs the code block for 10 seconds waiting for no assertion to trip.
      */
diff --git a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
index 1a5eede..48ad3f8 100644
--- a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
+++ b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
@@ -633,7 +633,7 @@ public final class InternalTestCluster extends TestCluster {
                 .put("name", name)
                 .put("discovery.id.seed", seed)
                 .build();
-        MockNode node = new MockNode(finalSettings, true, version, plugins);
+        MockNode node = new MockNode(finalSettings, version, plugins);
         return new NodeAndClient(name, node);
     }
 
@@ -881,7 +881,7 @@ public final class InternalTestCluster extends TestCluster {
             Settings finalSettings = Settings.builder().put(node.settings()).put(newSettings).build();
             Collection<Class<? extends Plugin>> plugins = node.getPlugins();
             Version version = node.getVersion();
-            node = new MockNode(finalSettings, true, version, plugins);
+            node = new MockNode(finalSettings, version, plugins);
             node.start();
         }
 
diff --git a/core/src/test/java/org/elasticsearch/test/geo/RandomShapeGenerator.java b/core/src/test/java/org/elasticsearch/test/geo/RandomShapeGenerator.java
index 9583c67..e0945d0 100644
--- a/core/src/test/java/org/elasticsearch/test/geo/RandomShapeGenerator.java
+++ b/core/src/test/java/org/elasticsearch/test/geo/RandomShapeGenerator.java
@@ -63,6 +63,14 @@ public class RandomShapeGenerator {
         }
     }
 
+    public static ShapeBuilder createShape(Random r) throws InvalidShapeException {
+        return createShapeNear(r, null);
+    }
+
+    public static ShapeBuilder createShape(Random r, ShapeType st) {
+        return createShapeNear(r, null, st);
+    }
+
     public static ShapeBuilder createShapeNear(Random r, Point nearPoint) throws InvalidShapeException {
         return createShape(r, nearPoint, null, null);
     }
@@ -211,7 +219,8 @@ public class RandomShapeGenerator {
                     try {
                         pgb.build();
                     } catch (InvalidShapeException e) {
-                        return null;
+                        // jts bug rarely results in an invalid shape, if it does happen we try again instead of returning null
+                        return createShape(r, nearPoint, within, st, validate);
                     }
                 }
                 return pgb;
diff --git a/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java b/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
index c253a75..d9b9b49 100644
--- a/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
+++ b/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
@@ -80,7 +80,7 @@ public class AssertingLocalTransport extends LocalTransport {
         ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersionBetween(random, minVersion, maxVersion), response);
         super.handleParsedResponse(response, handler);
     }
-
+    
     @Override
     public void sendRequest(final DiscoveryNode node, final long requestId, final String action, final TransportRequest request, TransportRequestOptions options) throws IOException, TransportException {
         ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersionBetween(random, minVersion, maxVersion), request);
diff --git a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
index 03ac788..a2433a9 100644
--- a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
+++ b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
@@ -52,8 +52,9 @@ import org.elasticsearch.http.HttpServerTransport;
 import org.elasticsearch.index.query.BoolQueryBuilder;
 import org.elasticsearch.index.query.GeoShapeQueryBuilder;
 import org.elasticsearch.index.query.MoreLikeThisQueryBuilder;
+import org.elasticsearch.index.query.MoreLikeThisQueryBuilder.Item;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.TermsQueryBuilder;
+import org.elasticsearch.index.query.TermsLookupQueryBuilder;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.rest.RestController;
 import org.elasticsearch.script.Script;
@@ -160,7 +161,7 @@ public class ContextAndHeaderTransportIT extends ESIntegTestCase {
                 .setSource(jsonBuilder().startObject().field("username", "foo").endObject()).get();
         transportClient().admin().indices().prepareRefresh(queryIndex, lookupIndex).get();
 
-        TermsQueryBuilder termsLookupFilterBuilder = QueryBuilders.termsLookupQuery("username").lookupIndex(lookupIndex).lookupType("type").lookupId("1").lookupPath("followers");
+        TermsLookupQueryBuilder termsLookupFilterBuilder = QueryBuilders.termsLookupQuery("username").lookupIndex(lookupIndex).lookupType("type").lookupId("1").lookupPath("followers");
         BoolQueryBuilder queryBuilder = QueryBuilders.boolQuery().must(QueryBuilders.matchAllQuery()).must(termsLookupFilterBuilder);
 
         SearchResponse searchResponse = transportClient()
@@ -229,7 +230,7 @@ public class ContextAndHeaderTransportIT extends ESIntegTestCase {
         transportClient().admin().indices().prepareRefresh(lookupIndex, queryIndex).get();
 
         MoreLikeThisQueryBuilder moreLikeThisQueryBuilder = QueryBuilders.moreLikeThisQuery("name")
-                .addItem(new MoreLikeThisQueryBuilder.Item(lookupIndex, "type", "1"))
+                .addLikeItem(new Item(lookupIndex, "type", "1"))
                 .minTermFreq(1)
                 .minDocFreq(1);
 
diff --git a/core/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortIntegrationIT.java b/core/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortIntegrationIT.java
index e945f16..48c0215 100644
--- a/core/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortIntegrationIT.java
+++ b/core/src/test/java/org/elasticsearch/transport/netty/NettyTransportMultiPortIntegrationIT.java
@@ -72,7 +72,7 @@ public class NettyTransportMultiPortIntegrationIT extends ESIntegTestCase {
                 .put(TransportModule.TRANSPORT_TYPE_KEY, "netty")
                 .put("path.home", createTempDir().toString())
                 .build();
-        try (TransportClient transportClient = TransportClient.builder().settings(settings).loadConfigSettings(false).build()) {
+        try (TransportClient transportClient = TransportClient.builder().settings(settings).build()) {
             transportClient.addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName("127.0.0.1"), randomPort));
             ClusterHealthResponse response = transportClient.admin().cluster().prepareHealth().get();
             assertThat(response.getStatus(), is(ClusterHealthStatus.GREEN));
diff --git a/core/src/test/java/org/elasticsearch/tribe/elasticsearch.yml b/core/src/test/java/org/elasticsearch/tribe/elasticsearch.yml
deleted file mode 100644
index 89f4922..0000000
--- a/core/src/test/java/org/elasticsearch/tribe/elasticsearch.yml
+++ /dev/null
@@ -1,3 +0,0 @@
-cluster.name: tribe_node_cluster
-tribe.t1.cluster.name: tribe1
-tribe.t2.cluster.name: tribe2
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java b/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
index 832f5d3..b55fd55 100644
--- a/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
@@ -236,7 +236,7 @@ public class SimpleValidateQueryIT extends ESIntegTestCase {
                 containsString("+field:pidgin (field:huge field:brown)"), true);
         assertExplanation(QueryBuilders.commonTermsQuery("field", "the brown").analyzer("stop"),
                 containsString("field:brown"), true);
-
+        
         // match queries with cutoff frequency
         assertExplanation(QueryBuilders.matchQuery("field", "huge brown pidgin").cutoffFrequency(1),
                 containsString("+field:pidgin (field:huge field:brown)"), true);
@@ -276,7 +276,11 @@ public class SimpleValidateQueryIT extends ESIntegTestCase {
         assertThat(client().admin().indices().prepareValidateQuery("test").setSource(new BytesArray("{\"query\": {\"term\" : { \"user\" : \"kimchy\" }}, \"foo\": \"bar\"}")).get().isValid(), equalTo(false));
     }
 
-    private static void assertExplanation(QueryBuilder queryBuilder, Matcher<String> matcher, boolean withRewrite) {
+    private void assertExplanation(QueryBuilder queryBuilder, Matcher<String> matcher) {
+        assertExplanation(queryBuilder, matcher, false);
+    }
+
+    private void assertExplanation(QueryBuilder queryBuilder, Matcher<String> matcher, boolean withRewrite) {
         ValidateQueryResponse response = client().admin().indices().prepareValidateQuery("test")
                 .setTypes("type1")
                 .setQuery(queryBuilder)
diff --git a/core/src/test/resources/org/elasticsearch/action/bulk/bulk-log.json b/core/src/test/resources/org/elasticsearch/action/bulk/bulk-log.json
new file mode 100644
index 0000000..9c3663c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/bulk/bulk-log.json
@@ -0,0 +1,24 @@
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug2/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug2/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug2/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
+{"index":{"_index":"logstash-2014.03.30","_type":"logs"}}
+{"message":"in24.inetnebr.com--[01/Aug2/1995:00:00:01-0400]\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"2001839","@version":"1","@timestamp":"2014-03-30T12:38:10.048Z","host":["romeo","in24.inetnebr.com"],"monthday":1,"month":8,"year":1995,"time":"00:00:01","tz":"-0400","request":"\"GET/shuttle/missions/sts-68/news/sts-68-mcc-05.txtHTTP/1.0\"","httpresponse":"200","size":1839,"rtime":"1995-08-01T00:00:01.000Z"}
diff --git a/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk.json b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk.json
new file mode 100644
index 0000000..cf76477
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk.json
@@ -0,0 +1,5 @@
+{ "index":{"_index":"test","_type":"type1","_id":"1"} }
+{ "field1" : "value1" }
+{ "delete" : { "_index" : "test", "_type" : "type1", "_id" : "2" } }
+{ "create" : { "_index" : "test", "_type" : "type1", "_id" : "3" } }
+{ "field1" : "value3" }
diff --git a/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk10.json b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk10.json
new file mode 100644
index 0000000..3556dc2
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk10.json
@@ -0,0 +1,15 @@
+{ "index"  : {"_index":null, "_type":"type1", "_id":"0"} }
+{ "field1" : "value1" }
+{ "index"  : {"_index":"test", "_type":null, "_id":"0"} }
+{ "field1" : "value1" }
+{ "index"  : {"_index":"test", "_type":"type1", "_id":null} }
+{ "field1" : "value1" }
+{ "delete"  : {"_index":null, "_type":"type1", "_id":"0"} }
+{ "delete"  : {"_index":"test", "_type":null, "_id":"0"} }
+{ "delete"  : {"_index":"test", "_type":"type1", "_id":null} }
+{ "create"  : {"_index":null, "_type":"type1", "_id":"0"} }
+{ "field1" : "value1" }
+{ "create"  : {"_index":"test", "_type":null, "_id":"0"} }
+{ "field1" : "value1" }
+{ "create"  : {"_index":"test", "_type":"type1", "_id":null} }
+{ "field1" : "value1" }
diff --git a/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk2.json b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk2.json
new file mode 100644
index 0000000..7cd4f99
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk2.json
@@ -0,0 +1,5 @@
+{ "index":{ } }
+{ "field1" : "value1" }
+{ "delete" : { "_id" : "2" } }
+{ "create" : { "_id" : "3" } }
+{ "field1" : "value3" }
diff --git a/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk3.json b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk3.json
new file mode 100644
index 0000000..7cd4f99
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk3.json
@@ -0,0 +1,5 @@
+{ "index":{ } }
+{ "field1" : "value1" }
+{ "delete" : { "_id" : "2" } }
+{ "create" : { "_id" : "3" } }
+{ "field1" : "value3" }
diff --git a/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk4.json b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk4.json
new file mode 100644
index 0000000..8b916b8
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk4.json
@@ -0,0 +1,7 @@
+{ "update" : {"_id" : "1", "_retry_on_conflict" : 2} }
+{ "doc" : {"field" : "value"} }
+{ "update" : { "_id" : "0", "_type" : "type1", "_index" : "index1" } }
+{ "script" : "counter += param1", "lang" : "js", "params" : {"param1" : 1}, "upsert" : {"counter" : 1}}
+{ "delete" : { "_id" : "2" } }
+{ "create" : { "_id" : "3" } }
+{ "field1" : "value3" }
diff --git a/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk5.json b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk5.json
new file mode 100644
index 0000000..6ad5ff3
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk5.json
@@ -0,0 +1,5 @@
+{ "index": {"_type": "type1","_id": "1"} }
+{ "field1" : "value1" }
+{ "delete" : { "_type" : "type1", "_id" : "2" } }
+{ "create" : { "_type" : "type1", "_id" : "3" } }
+{ "field1" : "value3" }
diff --git a/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk6.json b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk6.json
new file mode 100644
index 0000000..e9c9796
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk6.json
@@ -0,0 +1,6 @@
+{"index": {"_index": "test", "_type": "doc", "_source": {"hello": "world"}, "_id": 0}}
+{"field1": "value0"}
+{"index": {"_index": "test", "_type": "doc", "_id": 1}}
+{"field1": "value1"}
+{"index": {"_index": "test", "_type": "doc", "_id": 2}}
+{"field1": "value2"}
diff --git a/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk7.json b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk7.json
new file mode 100644
index 0000000..a642d9c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk7.json
@@ -0,0 +1,6 @@
+{"index": {"_index": "test", "_type": "doc", "_id": 0}}
+{"field1": "value0"}
+{"index": {"_index": "test", "_type": "doc", "_id": 1}}
+{"field1": "value1"}
+{"index": {"_index": "test", "_type": "doc", "_id": 2, "_unkown": ["foo", "bar"]}}
+{"field1": "value2"}
diff --git a/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk8.json b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk8.json
new file mode 100644
index 0000000..c1a94b1
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk8.json
@@ -0,0 +1,6 @@
+{"index": {"_index": "test", "_type": "doc", "_id": 0}}
+{"field1": "value0"}
+{"index": {"_index": "test", "_type": "doc", "_id": 1, "_foo": "bar"}}
+{"field1": "value1"}
+{"index": {"_index": "test", "_type": "doc", "_id": 2}}
+{"field1": "value2"}
diff --git a/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk9.json b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk9.json
new file mode 100644
index 0000000..ebdbf75
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/bulk/simple-bulk9.json
@@ -0,0 +1,4 @@
+{"index": {}}
+{"field1": "value0"}
+{"index": ["bar"] }
+{"field1": "value1"}
diff --git a/core/src/test/resources/org/elasticsearch/action/percolate/mpercolate1.json b/core/src/test/resources/org/elasticsearch/action/percolate/mpercolate1.json
new file mode 100644
index 0000000..4407939
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/percolate/mpercolate1.json
@@ -0,0 +1,16 @@
+{"percolate" : {"index" : "my-index1", "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local", "ignore_unavailable" : false}}
+{"doc" : {"field1" : "value1"}}
+{"percolate" : {"indices" : ["my-index2", "my-index3"], "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local", "ignore_unavailable" : true}}
+{"doc" : {"field1" : "value2"}}
+{"count" : {"indices" : ["my-index4", "my-index5"], "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local", "expand_wildcards" : "open,closed"}}
+{"doc" : {"field1" : "value3"}}
+{"percolate" : {"id" : "1", "index" : "my-index6", "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local", "expand_wildcards" : ["open", "closed"]}}
+{}
+{"count" : {"id" : "2", "index" : "my-index7", "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local"}}
+{}
+{"percolate" : {"index" : "my-index8", "type" : "my-type1", "routing" : "my-routing-1", "preference" : "primary"}}
+{"doc" : {"field1" : "value4"}}
+{"percolate" : {"id" : "3", "index" : "my-index9", "type" : "my-type1", "percolate_index": "percolate-index1", "percolate_type": "other-type", "percolate_preference": "_local", "percolate_routing": "percolate-routing-1"}}
+{}
+{"percolate" : {"id" : "4", "index" : "my-index10", "type" : "my-type1", "allow_no_indices": false, "expand_wildcards" : ["open"]}}
+{}
diff --git a/core/src/test/resources/org/elasticsearch/action/percolate/mpercolate2.json b/core/src/test/resources/org/elasticsearch/action/percolate/mpercolate2.json
new file mode 100644
index 0000000..fa676cf
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/percolate/mpercolate2.json
@@ -0,0 +1,6 @@
+{"percolate" : {"routing" : "my-routing-1", "preference" : "_local"}}
+{"doc" : {"field1" : "value1"}}
+{"percolate" : {"index" : "my-index1", "type" : "my-type1", "routing" : "my-routing-1", "preference" : "_local", "ignore_unavailable" : true}}
+{"doc" : {"field1" : "value2"}}
+{"percolate" : {}}
+{"doc" : {"field1" : "value3"}}
diff --git a/core/src/test/resources/org/elasticsearch/action/termvectors/multiRequest1.json b/core/src/test/resources/org/elasticsearch/action/termvectors/multiRequest1.json
new file mode 100644
index 0000000..fcb5e3a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/termvectors/multiRequest1.json
@@ -0,0 +1,13 @@
+{
+    "ids": ["1","2"],
+    "parameters": {
+        "field_statistics": false,
+        "term_statistics": true,
+        "payloads":false,
+        "offsets":false,
+        "positions":false,
+        "fields":["a","b","c"],
+        "_index": "testidx",
+        "_type":"test"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/action/termvectors/multiRequest2.json b/core/src/test/resources/org/elasticsearch/action/termvectors/multiRequest2.json
new file mode 100644
index 0000000..a0709ef
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/termvectors/multiRequest2.json
@@ -0,0 +1,26 @@
+{
+   "docs": [
+      {
+         "_id": "1",
+         "field_statistics": false,
+         "term_statistics": true,
+         "payloads": false,
+         "offsets": false,
+         "positions": false,
+         "fields":["a","b","c"],
+         "_index": "testidx",
+         "_type": "test"
+      },
+      {
+         "_id": "2",
+         "field_statistics": false,
+         "term_statistics": true,
+         "payloads": false,
+         "offsets": false,
+         "positions": false,
+         "fields":["a","b","c"],
+         "_index": "testidx",
+         "_type": "test"
+      }
+   ]
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/action/termvectors/multiRequest3.json b/core/src/test/resources/org/elasticsearch/action/termvectors/multiRequest3.json
new file mode 100644
index 0000000..457f43c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/action/termvectors/multiRequest3.json
@@ -0,0 +1,16 @@
+{
+   "ids": ["1","2"],
+   "parameters": {
+      "_index": "testidx",
+      "_type": "test",
+      "filter": {
+         "max_num_terms": 20,
+         "min_term_freq": 1,
+         "max_term_freq": 20,
+         "min_doc_freq": 1,
+         "max_doc_freq": 20,
+         "min_word_length": 1,
+         "max_word_length": 20
+      }
+   }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/common/settings/loader/indentation-settings.yml b/core/src/test/resources/org/elasticsearch/common/settings/loader/indentation-settings.yml
new file mode 100644
index 0000000..cd14c5f
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/common/settings/loader/indentation-settings.yml
@@ -0,0 +1,10 @@
+ test1:
+   value1: value1
+   test2:
+     value2: value2
+     value3: 2
+   test3:
+     - test3-1
+     - test3-2
+test4:
+  value4: value4
diff --git a/core/src/test/resources/org/elasticsearch/common/settings/loader/indentation-with-explicit-document-start-settings.yml b/core/src/test/resources/org/elasticsearch/common/settings/loader/indentation-with-explicit-document-start-settings.yml
new file mode 100644
index 0000000..e02a357
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/common/settings/loader/indentation-with-explicit-document-start-settings.yml
@@ -0,0 +1,11 @@
+ test1:
+   value1: value1
+   test2:
+     value2: value2
+     value3: 2
+   test3:
+     - test3-1
+     - test3-2
+---
+test4:
+  value4: value4
diff --git a/core/src/test/resources/org/elasticsearch/common/settings/loader/test-settings.json b/core/src/test/resources/org/elasticsearch/common/settings/loader/test-settings.json
new file mode 100644
index 0000000..7190648
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/common/settings/loader/test-settings.json
@@ -0,0 +1,10 @@
+{
+    test1:{
+        value1:"value1",
+        test2:{
+            value2:"value2",
+            value3:2
+        },
+        test3:["test3-1", "test3-2"]
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/common/settings/loader/test-settings.yml b/core/src/test/resources/org/elasticsearch/common/settings/loader/test-settings.yml
new file mode 100644
index 0000000..b533ae0
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/common/settings/loader/test-settings.yml
@@ -0,0 +1,8 @@
+test1:
+  value1: value1
+  test2:
+    value2: value2
+    value3: 2
+  test3:
+    - test3-1
+    - test3-2
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/cjk_analysis.json b/core/src/test/resources/org/elasticsearch/index/analysis/cjk_analysis.json
new file mode 100644
index 0000000..89a1281
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/cjk_analysis.json
@@ -0,0 +1,37 @@
+{
+   "index":{
+      "analysis":{
+         "filter":{
+            "cjk_all_flags":{
+               "type":"cjk_bigram",
+               "output_unigrams":true,
+               "ignored_scripts":[
+                  "han",
+                  "hiragana",
+                  "katakana",
+                  "hangul",
+                  "foobar"
+               ]
+            },
+            "cjk_han_only":{
+               "type":"cjk_bigram",
+               "output_unigrams":false,
+               "ignored_scripts":[
+                  "hiragana"
+               ]
+            },
+            "cjk_han_unigram_only":{
+               "type":"cjk_bigram",
+               "output_unigrams":true,
+               "ignored_scripts":[
+                  "hiragana"
+               ]
+            },
+            "cjk_no_flags":{
+               "type":"cjk_bigram",
+               "output_unigrams":false
+            }
+         }
+      }
+   }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/commongrams/common_words.txt b/core/src/test/resources/org/elasticsearch/index/analysis/commongrams/common_words.txt
new file mode 100644
index 0000000..f97b799
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/commongrams/common_words.txt
@@ -0,0 +1,2 @@
+brown
+fox
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/commongrams/commongrams.json b/core/src/test/resources/org/elasticsearch/index/analysis/commongrams/commongrams.json
new file mode 100644
index 0000000..377b403
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/commongrams/commongrams.json
@@ -0,0 +1,29 @@
+{
+    "index":{
+        "analysis":{
+            "analyzer":{
+                "commongramsAnalyzer":{
+                    "tokenizer":"whitespace",
+                    "filter":[ "common_grams" ]
+                },
+                "commongramsAnalyzer_file":{
+                    "tokenizer":"whitespace",
+                    "filter":[ "common_grams_file" ]
+                }
+            },
+            "filter":{
+                "common_grams":{
+                    "type":"common_grams",
+                    "common_words":[
+                        "brown",
+                        "fox"
+                    ]
+                },
+                "common_grams_file":{
+                    "type":"common_grams",
+                    "common_words_path":"common_words.txt"
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/commongrams/commongrams_query_mode.json b/core/src/test/resources/org/elasticsearch/index/analysis/commongrams/commongrams_query_mode.json
new file mode 100644
index 0000000..4151c46
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/commongrams/commongrams_query_mode.json
@@ -0,0 +1,31 @@
+{
+    "index":{
+        "analysis":{
+            "analyzer":{
+                "commongramsAnalyzer":{
+                    "tokenizer":"whitespace",
+                    "filter":[ "common_grams" ]
+                },
+                "commongramsAnalyzer_file":{
+                    "tokenizer":"whitespace",
+                    "filter":[ "common_grams_file" ]
+                }
+            },
+            "filter":{
+                "common_grams":{
+                    "type":"common_grams",
+                    "query_mode" : true,
+                    "common_words":[
+                        "brown",
+                        "fox"
+                    ]
+                },
+                "common_grams_file":{
+                    "type":"common_grams",
+                    "query_mode" : true,
+                    "common_words_path":"common_words.txt"
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/keep_analysis.json b/core/src/test/resources/org/elasticsearch/index/analysis/keep_analysis.json
new file mode 100644
index 0000000..233d6f3
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/keep_analysis.json
@@ -0,0 +1,19 @@
+{
+    "index":{
+        "analysis":{
+            "filter":{
+                "my_keep_filter":{
+                    "type":"keep",
+                    "keep_words" : ["Hello", "worlD"],
+                    "keep_words_case" : true
+                },
+                "my_case_sensitive_keep_filter":{
+                    "type":"keep",
+                    "keep_words" : ["Hello", "worlD"],
+                    "enable_position_increments" : false,
+                    "version" : "4.2"
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/pattern_capture.json b/core/src/test/resources/org/elasticsearch/index/analysis/pattern_capture.json
new file mode 100644
index 0000000..d82fb98
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/pattern_capture.json
@@ -0,0 +1,46 @@
+{
+   "index": {
+      "number_of_shards": 1,
+      "number_of_replicas": 0,
+      "analysis": {
+         "filter": {
+            "single": {
+               "type": "pattern_capture",
+               "patterns": "((...)...)"
+            },
+            "multi": {
+               "type": "pattern_capture",
+               "patterns": [
+                  "(\\d+)",
+                  "([a-z]+)"
+               ]
+            },
+            "preserve": {
+               "type": "pattern_capture",
+               "preserve_original": false,
+               "patterns": "((...)...)"
+            }
+         },
+         "analyzer": {
+            "single": {
+               "tokenizer": "keyword",
+               "filter": [
+                  "single"
+               ]
+            },
+            "multi": {
+               "tokenizer": "keyword",
+               "filter": [
+                  "multi"
+               ]
+            },
+            "preserve": {
+               "tokenizer": "keyword",
+               "filter": [
+                  "preserve"
+               ]
+            }
+         }
+      }
+   }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/shingle_analysis.json b/core/src/test/resources/org/elasticsearch/index/analysis/shingle_analysis.json
new file mode 100644
index 0000000..33c09fe
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/shingle_analysis.json
@@ -0,0 +1,23 @@
+{
+    "index":{
+        "analysis":{
+            "filter":{
+                "shingle_inverse":{
+                    "type":"shingle",
+                    "max_shingle_size" : 3,
+                    "min_shingle_size" : 3,
+                    "output_unigrams" : false,
+                    "output_unigrams_if_no_shingles" : true,
+                    "token_separator" : "_"
+                },
+                "shingle_filler":{
+                    "type":"shingle",
+                    "max_shingle_size" : 3,
+                    "min_shingle_size" : 2,
+                    "output_unigrams" : false,
+                    "filler_token" : "FILLER"
+                }
+            }            
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/stop.json b/core/src/test/resources/org/elasticsearch/index/analysis/stop.json
new file mode 100644
index 0000000..717c9fd
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/stop.json
@@ -0,0 +1,18 @@
+{
+    "index":{
+        "number_of_shards":1,
+        "number_of_replicas":0,
+        "analysis":{
+            "analyzer":{
+                "analyzer1":{
+                    "type":"stop",
+                    "stopwords":["_english_"]
+                },
+                "analyzer2":{
+                    "type":"stop",
+                    "stopwords":"_english_"
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/synonyms/synonyms.json b/core/src/test/resources/org/elasticsearch/index/analysis/synonyms/synonyms.json
new file mode 100644
index 0000000..fe5f4d4
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/synonyms/synonyms.json
@@ -0,0 +1,72 @@
+{
+    "index":{
+        "analysis":{
+            "analyzer":{
+                "synonymAnalyzer":{
+                    "tokenizer":"standard",
+                    "filter":[ "synonym" ]
+                },
+                "synonymAnalyzer_file":{
+                    "tokenizer":"standard",
+                    "filter":[ "synonym_file" ]
+                },
+                "synonymAnalyzerWordnet":{
+                    "tokenizer":"standard",
+                    "filter":[ "synonymWordnet" ]
+                },
+                "synonymAnalyzerWordnet_file":{
+                    "tokenizer":"standard",
+                    "filter":[ "synonymWordnet_file" ]
+                },
+                "synonymAnalyzerWithsettings":{
+                    "tokenizer":"trigram",
+                    "filter":["synonymWithTokenizerSettings"]
+                }
+            },
+            "tokenizer":{
+                "trigram" : {
+                    "type" : "ngram",
+                    "min_gram" : 3,
+                    "max_gram" : 3
+                }
+            },
+            "filter":{
+                "synonym":{
+                    "type":"synonym",
+                    "synonyms":[
+                        "kimchy => shay",
+                        "dude => elasticsearch",
+                        "abides => man!"
+                    ]
+                },
+                "synonym_file":{
+                    "type":"synonym",
+                    "synonyms_path":"synonyms.txt"
+                },
+                "synonymWordnet":{
+                    "type":"synonym",
+                    "format":"wordnet",
+                    "synonyms":[
+                        "s(100000001,1,'abstain',v,1,0).",
+                        "s(100000001,2,'refrain',v,1,0).",
+                        "s(100000001,3,'desist',v,1,0)."
+                    ]
+                },
+                "synonymWordnet_file":{
+                    "type":"synonym",
+                    "format":"wordnet",
+                    "synonyms_path":"synonyms_wordnet.txt"
+                },
+                "synonymWithTokenizerSettings":{
+                    "type":"synonym",
+                    "synonyms":[
+                        "kimchy => shay"
+                    ],
+                    "tokenizer" : "trigram",
+                    "min_gram" : 3,
+                    "max_gram" : 3
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/synonyms/synonyms.txt b/core/src/test/resources/org/elasticsearch/index/analysis/synonyms/synonyms.txt
new file mode 100644
index 0000000..ef4b225
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/synonyms/synonyms.txt
@@ -0,0 +1,3 @@
+kimchy => shay
+dude => elasticsearch
+abides => man!
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/synonyms/synonyms_wordnet.txt b/core/src/test/resources/org/elasticsearch/index/analysis/synonyms/synonyms_wordnet.txt
new file mode 100644
index 0000000..f7b68e3
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/synonyms/synonyms_wordnet.txt
@@ -0,0 +1,3 @@
+s(100000001,1,'abstain',v,1,0).
+s(100000001,2,'refrain',v,1,0).
+s(100000001,3,'desist',v,1,0).
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/test1.json b/core/src/test/resources/org/elasticsearch/index/analysis/test1.json
new file mode 100644
index 0000000..2434963
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/test1.json
@@ -0,0 +1,84 @@
+{
+    "index":{
+        "analysis":{
+            "tokenizer":{
+                "standard":{
+                    "type":"standard"
+                }
+            },
+            "char_filter":{
+                "my_html":{
+                    "type":"html_strip",
+                    "escaped_tags":["xxx", "yyy"],
+                    "read_ahead":1024
+                },
+                "my_pattern":{
+                    "type":"pattern_replace",
+                    "pattern":"sample(.*)",
+                    "replacement":"replacedSample $1"
+                },
+                "my_mapping":{
+                    "type":"mapping",
+                    "mappings":["ph=>f", "qu=>q"]
+                }
+            },
+            "filter":{
+                "stop":{
+                    "type":"stop",
+                    "stopwords":["test-stop"]
+                },
+                "stop2":{
+                    "type":"stop",
+                    "stopwords":["stop2-1", "stop2-2"]
+                },
+                "my":{
+                    "type":"myfilter"
+                },
+                "dict_dec":{
+                    "type":"dictionary_decompounder",
+                    "word_list":["donau", "dampf", "schiff", "spargel", "creme", "suppe"]
+                }
+            },
+            "analyzer":{
+                "standard":{
+                    "alias":"alias1,alias2",
+                    "type":"standard",
+                    "stopwords":["test1", "test2", "test3"]
+                },
+                "custom1":{
+                    "alias":["alias4", "alias5"],
+                    "tokenizer":"standard",
+                    "filter":["stop", "stop2"]
+                },
+                "custom2":{
+                    "tokenizer":"standard",
+                    "char_filter":["html_strip", "my_html"]
+                },
+                "custom3":{
+                    "tokenizer":"standard",
+                    "char_filter":["my_pattern"]
+                },
+                "custom4":{
+                    "tokenizer":"standard",
+                    "filter":["my"]
+                },
+                "custom5":{
+                    "tokenizer":"standard",
+                    "char_filter":["my_mapping"]
+                },
+                "custom6":{
+                    "tokenizer":"standard",
+                    "position_increment_gap": 256
+                },
+                "czechAnalyzerWithStemmer":{
+                    "tokenizer":"standard",
+                    "filter":["standard", "lowercase", "stop", "czech_stem"]
+                },
+                "decompoundingAnalyzer":{
+                    "tokenizer":"standard",
+                    "filter":["dict_dec"]
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/analysis/test1.yml b/core/src/test/resources/org/elasticsearch/index/analysis/test1.yml
new file mode 100644
index 0000000..196e4ef
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/analysis/test1.yml
@@ -0,0 +1,62 @@
+index :
+  analysis :
+    tokenizer :
+      standard :
+        type : standard
+    char_filter :
+      my_html :
+        type : html_strip
+        escaped_tags : [xxx, yyy]
+        read_ahead : 1024
+      my_pattern :
+        type: pattern_replace
+        pattern: sample(.*)
+        replacement: replacedSample $1
+      my_mapping :
+        type : mapping
+        mappings : [ph=>f, qu=>q]
+    filter :
+      stop :
+        type : stop
+        stopwords : [test-stop]
+      stop2 :
+        type : stop
+        stopwords : [stop2-1, stop2-2]
+      my :
+        type : myfilter
+      dict_dec :
+        type : dictionary_decompounder
+        word_list : [donau, dampf, schiff, spargel, creme, suppe]
+    analyzer :
+      standard :
+        alias: alias1,alias2
+        type : standard
+        stopwords : [test1, test2, test3]
+      custom1 :
+        alias : [alias4, alias5]
+        tokenizer : standard
+        filter : [stop, stop2]
+      custom2 :
+        tokenizer : standard
+        char_filter : [html_strip, my_html]
+      custom3 :
+        tokenizer : standard
+        char_filter : [my_pattern]
+      custom4 :
+        tokenizer : standard
+        filter : [my]
+      custom5 :
+        tokenizer : standard
+        char_filter : [my_mapping]
+      custom6 :
+        tokenizer : standard
+        position_increment_gap: 256
+      custom7 :
+        type : standard
+        version: 3.6
+      czechAnalyzerWithStemmer :
+        tokenizer : standard
+        filter : [standard, lowercase, stop, czech_stem]
+      decompoundingAnalyzer :
+        tokenizer : standard
+        filter : [dict_dec]
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping.json
new file mode 100644
index 0000000..f956b84
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping.json
@@ -0,0 +1,56 @@
+{
+    "person":{
+        "_all":{
+            "enabled":true,
+            "omit_norms":true
+        },
+        "properties":{
+            "name":{
+                "type":"object",
+                "dynamic":false,
+                "properties":{
+                    "first":{
+                        "type":"string",
+                        "store":"yes",
+                        "include_in_all":false
+                    },
+                    "last":{
+                        "type":"string",
+                        "index":"not_analyzed",
+                        "boost":2.0
+                    }
+                }
+            },
+            "address":{
+                "type":"object",
+                "include_in_all":false,
+                "properties":{
+                    "first":{
+                        "properties":{
+                            "location":{
+                                "type":"string",
+                                "store":"yes"
+                            }
+                        }
+                    },
+                    "last":{
+                        "properties":{
+                            "location":{
+                                "type":"string",
+                                "include_in_all":true
+                            }
+                        }
+                    }
+                }
+            },
+            "simple1":{
+                "type":"long",
+                "include_in_all":true
+            },
+            "simple2":{
+                "type":"long",
+                "include_in_all":false
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping_boost_omit_positions_on_all.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping_boost_omit_positions_on_all.json
new file mode 100644
index 0000000..452ef9f
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping_boost_omit_positions_on_all.json
@@ -0,0 +1,56 @@
+{
+    "person":{
+        "_all":{
+            "enabled": true ,
+            "index_options" : "freqs"
+        },
+        "properties":{
+            "name":{
+                "type":"object",
+                "dynamic":false,
+                "properties":{
+                    "first":{
+                        "type":"string",
+                        "store":"yes",
+                        "include_in_all":false
+                    },
+                    "last":{
+                        "type":"string",
+                        "index":"not_analyzed",
+			"boost": 2.0
+                    }
+                }
+            },
+            "address":{
+                "type":"object",
+                "include_in_all":false,
+                "properties":{
+                    "first":{
+                        "properties":{
+                            "location":{
+                                "type":"string",
+                                "store":"yes"
+                            }
+                        }
+                    },
+                    "last":{
+                        "properties":{
+                            "location":{
+                                "type":"string",
+                                "include_in_all":true
+                            }
+                        }
+                    }
+                }
+            },
+            "simple1":{
+                "type":"long",
+                "include_in_all":true
+            },
+            "simple2":{
+                "type":"long",
+                "include_in_all":false
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping_offsets_on_all.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping_offsets_on_all.json
new file mode 100644
index 0000000..f6b0699
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping_offsets_on_all.json
@@ -0,0 +1,56 @@
+{
+    "person":{
+        "_all":{
+            "enabled": true ,
+            "index_options" : "offsets"
+        },
+        "properties":{
+            "name":{
+                "type":"object",
+                "dynamic":false,
+                "properties":{
+                    "first":{
+                        "type":"string",
+                        "store":"yes",
+                        "include_in_all":false
+                    },
+                    "last":{
+                        "type":"string",
+                        "index":"not_analyzed",
+			"boost": 2.0
+                    }
+                }
+            },
+            "address":{
+                "type":"object",
+                "include_in_all":false,
+                "properties":{
+                    "first":{
+                        "properties":{
+                            "location":{
+                                "type":"string",
+                                "store":"yes"
+                            }
+                        }
+                    },
+                    "last":{
+                        "properties":{
+                            "location":{
+                                "type":"string",
+                                "include_in_all":true
+                            }
+                        }
+                    }
+                }
+            },
+            "simple1":{
+                "type":"long",
+                "include_in_all":true
+            },
+            "simple2":{
+                "type":"long",
+                "include_in_all":false
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping_omit_positions_on_all.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping_omit_positions_on_all.json
new file mode 100644
index 0000000..f8e418c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/mapping_omit_positions_on_all.json
@@ -0,0 +1,55 @@
+{
+    "person":{
+        "_all":{
+            "enabled": true ,
+            "index_options" : "freqs"
+        },
+        "properties":{
+            "name":{
+                "type":"object",
+                "dynamic":false,
+                "properties":{
+                    "first":{
+                        "type":"string",
+                        "store":"yes",
+                        "include_in_all":false
+                    },
+                    "last":{
+                        "type":"string",
+                        "index":"not_analyzed"
+                    }
+                }
+            },
+            "address":{
+                "type":"object",
+                "include_in_all":false,
+                "properties":{
+                    "first":{
+                        "properties":{
+                            "location":{
+                                "type":"string",
+                                "store":"yes"
+                            }
+                        }
+                    },
+                    "last":{
+                        "properties":{
+                            "location":{
+                                "type":"string",
+                                "include_in_all":true
+                            }
+                        }
+                    }
+                }
+            },
+            "simple1":{
+                "type":"long",
+                "include_in_all":true
+            },
+            "simple2":{
+                "type":"long",
+                "include_in_all":false
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/misplaced_mapping_key_in_root.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/misplaced_mapping_key_in_root.json
new file mode 100644
index 0000000..f08757a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/misplaced_mapping_key_in_root.json
@@ -0,0 +1,11 @@
+{
+    "mapping": {
+        "test": {
+            "properties": {
+                "foo": {
+                    "type": "string"
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/misplaced_type_in_root.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/misplaced_type_in_root.json
new file mode 100644
index 0000000..f4b325c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/misplaced_type_in_root.json
@@ -0,0 +1,8 @@
+{
+    "type": "string",
+    "properties": {
+        "foo": {
+            "type": "string"
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/mistyped_type_in_root.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/mistyped_type_in_root.json
new file mode 100644
index 0000000..19edf59
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/mistyped_type_in_root.json
@@ -0,0 +1,9 @@
+{
+    "testX": {
+        "properties": {
+            "foo": {
+                "type": "string"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/multifield-mapping_default.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/multifield-mapping_default.json
new file mode 100644
index 0000000..6a5f044
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/multifield-mapping_default.json
@@ -0,0 +1,21 @@
+{
+    "test": {
+        "properties": {
+            "foo": {
+                "type": "nested",
+                "properties": {
+                    "bar": {
+                        "type": "string",
+                        "index": "not_analyzed",
+                        "fields": {
+                            "lower": {
+                                "analyzer": "standard",
+                                "type": "string"
+                            }
+                        }
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/multifield-mapping_include_in_all_set_to_false.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/multifield-mapping_include_in_all_set_to_false.json
new file mode 100644
index 0000000..5a0ad92
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/multifield-mapping_include_in_all_set_to_false.json
@@ -0,0 +1,23 @@
+{
+    "test": {
+        "properties": {
+            "foo": {
+                "type": "nested",
+                "include_in_all": false,
+                "properties": {
+                    "bar": {
+                        "type": "string",
+                        "index": "not_analyzed",
+                        "include_in_all": false,
+                        "fields": {
+                            "lower": {
+                                "analyzer": "standard",
+                                "type": "string"
+                            }
+                        }
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/noboost-mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/noboost-mapping.json
new file mode 100644
index 0000000..799a3ab
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/noboost-mapping.json
@@ -0,0 +1,54 @@
+{
+    "person":{
+        "_all":{
+            "enabled":true
+        },
+        "properties":{
+            "name":{
+                "type":"object",
+                "dynamic":false,
+                "properties":{
+                    "first":{
+                        "type":"string",
+                        "store":"yes",
+                        "include_in_all":false
+                    },
+                    "last":{
+                        "type":"string",
+                        "index":"not_analyzed"
+                    }
+                }
+            },
+            "address":{
+                "type":"object",
+                "include_in_all":false,
+                "properties":{
+                    "first":{
+                        "properties":{
+                            "location":{
+                                "type":"string",
+                                "store":"yes"
+                            }
+                        }
+                    },
+                    "last":{
+                        "properties":{
+                            "location":{
+                                "type":"string",
+                                "include_in_all":true
+                            }
+                        }
+                    }
+                }
+            },
+            "simple1":{
+                "type":"long",
+                "include_in_all":true
+            },
+            "simple2":{
+                "type":"long",
+                "include_in_all":false
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/store-mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/store-mapping.json
new file mode 100644
index 0000000..8f653a3
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/store-mapping.json
@@ -0,0 +1,55 @@
+{
+    "person":{
+        "_all":{
+            "enabled":true,
+            "store":"yes"
+        },
+        "properties":{
+            "name":{
+                "type":"object",
+                "dynamic":false,
+                "properties":{
+                    "first":{
+                        "type":"string",
+                        "store":"yes",
+                        "include_in_all":false
+                    },
+                    "last":{
+                        "type":"string",
+                        "index":"not_analyzed",
+                        "boost":2.0
+                    }
+                }
+            },
+            "address":{
+                "type":"object",
+                "include_in_all":false,
+                "properties":{
+                    "first":{
+                        "properties":{
+                            "location":{
+                                "type":"string",
+                                "store":"yes"
+                            }
+                        }
+                    },
+                    "last":{
+                        "properties":{
+                            "location":{
+                                "type":"string"
+                            }
+                        }
+                    }
+                }
+            },
+            "simple1":{
+                "type":"long",
+                "include_in_all":true
+            },
+            "simple2":{
+                "type":"long",
+                "include_in_all":false
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/test1.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/test1.json
new file mode 100644
index 0000000..4437d3f
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/test1.json
@@ -0,0 +1,16 @@
+{
+    "name":{
+        "first":"shay",
+        "last":"banon"
+    },
+    "address":{
+        "first":{
+            "location":"first location"
+        },
+        "last":{
+            "location":"last location"
+        }
+    },
+    "simple1":1,
+    "simple2":2
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/type_date_detection_mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/type_date_detection_mapping.json
new file mode 100644
index 0000000..c2db712
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/type_date_detection_mapping.json
@@ -0,0 +1,8 @@
+{
+    "date_detection" : false,
+    "properties": {
+        "foo": {
+            "type": "string"
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/type_dynamic_date_formats_mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/type_dynamic_date_formats_mapping.json
new file mode 100644
index 0000000..7e6afd3
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/type_dynamic_date_formats_mapping.json
@@ -0,0 +1,8 @@
+{
+    "dynamic_date_formats" : ["yyyy-MM-dd", "dd-MM-yyyy"],
+    "properties": {
+        "foo": {
+            "type": "string"
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/type_dynamic_template_mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/type_dynamic_template_mapping.json
new file mode 100644
index 0000000..b155fb7
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/type_dynamic_template_mapping.json
@@ -0,0 +1,17 @@
+{
+    "dynamic_templates" : [
+        {
+            "dynamic_template_name" : {
+                "match" : "*",
+                "mapping" : {
+                    "store" : true
+                }
+            }
+        }
+    ],
+    "properties": {
+        "foo": {
+            "type": "string"
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/all/type_numeric_detection_mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/all/type_numeric_detection_mapping.json
new file mode 100644
index 0000000..4729354
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/all/type_numeric_detection_mapping.json
@@ -0,0 +1,8 @@
+{
+    "numeric_detection" : false,
+    "properties": {
+        "foo": {
+            "type": "string"
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-data.json b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-data.json
new file mode 100644
index 0000000..b7439dc
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-data.json
@@ -0,0 +1,4 @@
+{
+    "name":"some name",
+    "age":1
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-mapping.json
new file mode 100644
index 0000000..d99067c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/genericstore/test-mapping.json
@@ -0,0 +1,14 @@
+{
+    "person":{
+        "dynamic_templates":[
+            {
+                "template_1":{
+                    "match":"*",
+                    "mapping":{
+                        "store":"yes"
+                    }
+                }
+            }
+        ]
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-data.json b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-data.json
new file mode 100644
index 0000000..2e6ec99
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-data.json
@@ -0,0 +1,14 @@
+{
+    "name":"top_level",
+    "obj1":{
+        "name":"obj1_level",
+        "obj2":{
+            "name":"obj2_level"
+        }
+    },
+    "obj3":{
+        "obj4":{
+            "prop1":"prop1_value"
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-mapping.json
new file mode 100644
index 0000000..dce33da
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/pathmatch/test-mapping.json
@@ -0,0 +1,30 @@
+{
+    "person":{
+        "dynamic_templates":[
+            {
+                "template_1":{
+                    "path_match":"obj1.obj2.*",
+                    "mapping":{
+                        "store":"no"
+                    }
+                }
+            },
+            {
+                "template_2":{
+                    "path_match":"obj1.*",
+                    "mapping":{
+                        "store":"yes"
+                    }
+                }
+            },
+            {
+                "template_3":{
+                    "path_match":"*.obj4.*",
+                    "mapping":{
+                        "type":"string"
+                    }
+                }
+            }
+        ]
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/simple/test-data.json b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/simple/test-data.json
new file mode 100644
index 0000000..1ed3c50
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/simple/test-data.json
@@ -0,0 +1,6 @@
+{
+    "name":"some name",
+    "age":1,
+    "multi1":"multi 1",
+    "multi2":"multi 2"
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/simple/test-mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/simple/test-mapping.json
new file mode 100644
index 0000000..9c8f8d8
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/dynamictemplate/simple/test-mapping.json
@@ -0,0 +1,33 @@
+{
+    "person":{
+        "dynamic_templates":[
+            {
+                "tempalte_1":{
+                    "match":"multi*",
+                    "mapping":{
+                        "type":"{dynamic_type}",
+                        "index":"analyzed",
+                        "store":"yes",
+                        "fields":{
+                            "org":{
+                                "type":"{dynamic_type}",
+                                "index":"not_analyzed",
+                                "store":"yes"
+                            }
+                        }
+                    }
+                }
+            },
+            {
+                "template_2":{
+                    "match":"*",
+                    "match_mapping_type":"string",
+                    "mapping":{
+                        "type":"string",
+                        "index":"not_analyzed"
+                    }
+                }
+            }
+        ]
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-data.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-data.json
new file mode 100644
index 0000000..c539fcc
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-data.json
@@ -0,0 +1,4 @@
+{
+    _id:1,
+    name:"some name"
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping1.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping1.json
new file mode 100644
index 0000000..61f08af
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping1.json
@@ -0,0 +1,11 @@
+{
+    person:{
+        properties:{
+            "name":{
+                type:"string",
+                index:"analyzed",
+                store:"yes"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping2.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping2.json
new file mode 100644
index 0000000..02ce895
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping2.json
@@ -0,0 +1,27 @@
+{
+    "person" :{
+        "properties" :{
+            "name":{
+                "type" :"string",
+                "index" :"analyzed",
+                "store" :"yes",
+                "fields":{
+                    "name":{
+                        "type" :"string",
+                        "index" :"analyzed",
+                        "store" :"yes"
+                    },
+                    "indexed":{
+                        "type" :"string",
+                        "index" :"analyzed"
+                    },
+                    "not_indexed":{
+                        "type" :"string",
+                        "index" :"no",
+                        "store" :"yes"
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping3.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping3.json
new file mode 100644
index 0000000..ea07675
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping3.json
@@ -0,0 +1,32 @@
+{
+    "person" : {
+        "properties" :{
+            "name" : {
+                "type" : "string",
+                "index" : "analyzed",
+                "store" : "yes",
+                "fields": {
+                    "name" : {
+                        "type" : "string",
+                        "index" : "analyzed",
+                        "store" : "yes"
+                    },
+                    "indexed":{
+                        type:"string",
+                        index:"analyzed"
+                    },
+                    "not_indexed":{
+                        type:"string",
+                        index:"no",
+                        store:"yes"
+                    },
+                    "not_indexed2":{
+                        type:"string",
+                        index:"no",
+                        store:"yes"
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping4.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping4.json
new file mode 100644
index 0000000..384c263
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/test-mapping4.json
@@ -0,0 +1,18 @@
+{
+    person:{
+        properties:{
+            "name":{
+                type:"string",
+                index:"analyzed",
+                store:"yes",
+                "fields":{
+                    "not_indexed3":{
+                        type:"string",
+                        index:"no",
+                        store:"yes"
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/upgrade1.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/upgrade1.json
new file mode 100644
index 0000000..6206592
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/upgrade1.json
@@ -0,0 +1,25 @@
+{
+    person:{
+        properties:{
+            "name":{
+                type:"multi_field",
+                "fields":{
+                    "name":{
+                        type:"string",
+                        index:"analyzed",
+                        store:"yes"
+                    },
+                    "indexed":{
+                        type:"string",
+                        index:"analyzed"
+                    },
+                    "not_indexed":{
+                        type:"string",
+                        index:"no",
+                        store:"yes"
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/upgrade2.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/upgrade2.json
new file mode 100644
index 0000000..4a8fbf6
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/upgrade2.json
@@ -0,0 +1,30 @@
+{
+    person:{
+        properties:{
+            "name":{
+                type:"multi_field",
+                "fields":{
+                    "name":{
+                        type:"string",
+                        index:"analyzed",
+                        store:"yes"
+                    },
+                    "indexed":{
+                        type:"string",
+                        index:"analyzed"
+                    },
+                    "not_indexed":{
+                        type:"string",
+                        index:"no",
+                        store:"yes"
+                    },
+                    "not_indexed2":{
+                        type:"string",
+                        index:"no",
+                        store:"yes"
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/upgrade3.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/upgrade3.json
new file mode 100644
index 0000000..9b30978
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/merge/upgrade3.json
@@ -0,0 +1,16 @@
+{
+    person:{
+        properties:{
+            "name":{
+                type:"multi_field",
+                "fields":{
+                    "not_indexed3":{
+                        type:"string",
+                        index:"no",
+                        store:"yes"
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-data.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-data.json
new file mode 100644
index 0000000..2e8ab25
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-data.json
@@ -0,0 +1,7 @@
+{
+    "age":28,
+    "name":"some name",
+    "object1":{
+        "multi1":"2010-01-01"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type-completion.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type-completion.json
new file mode 100644
index 0000000..d36e9d2
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type-completion.json
@@ -0,0 +1,30 @@
+{
+  "type":{
+    "properties":{
+      "a":{
+        "type":"multi_field",
+        "fields":{
+          "a":{
+            "type":"string",
+            "index":"not_analyzed"
+          },
+          "b":{
+            "type":"completion"
+          }
+        }
+      },
+      "b":{
+        "type":"multi_field",
+        "fields":{
+          "a":{
+            "type":"string",
+            "index":"not_analyzed"
+          },
+          "b":{
+            "type":"completion"
+          }
+        }
+      }
+    }
+  }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type-geo_point.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type-geo_point.json
new file mode 100644
index 0000000..c7d11be
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type-geo_point.json
@@ -0,0 +1,30 @@
+{
+  "type":{
+    "properties":{
+      "a":{
+        "type":"multi_field",
+        "fields":{
+          "a":{
+            "type":"string",
+            "index":"not_analyzed"
+          },
+          "b":{
+            "type":"geo_point"
+          }
+        }
+      },
+      "b":{
+        "type":"multi_field",
+        "fields":{
+          "a":{
+            "type":"string",
+            "index":"not_analyzed"
+          },
+          "b":{
+            "type":"geo_point"
+          }
+        }
+      }
+    }
+  }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type-no-default-field.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type-no-default-field.json
new file mode 100644
index 0000000..99b74c0
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type-no-default-field.json
@@ -0,0 +1,32 @@
+{
+  "person": {
+    "properties": {
+      "name": {
+        "type": "multi_field",
+        "fields": {
+          "indexed": {
+            "type": "string",
+            "index": "analyzed"
+          },
+          "not_indexed": {
+            "type": "string",
+            "index": "no",
+            "store": "yes"
+          }
+        }
+      },
+      "age": {
+        "type": "multi_field",
+        "fields": {
+          "not_stored": {
+            "type": "long"
+          },
+          "stored": {
+            "type": "long",
+            "store": "yes"
+          }
+        }
+      }
+    }
+  }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type.json
new file mode 100644
index 0000000..b099b9a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-field-type.json
@@ -0,0 +1,55 @@
+{
+    "person":{
+        "properties":{
+            "name":{
+                "type":"multi_field",
+                "fields":{
+                    "name":{
+                        "type":"string",
+                        "index":"analyzed",
+                        "store":"yes"
+                    },
+                    "indexed":{
+                        "type":"string",
+                        "index":"analyzed"
+                    },
+                    "not_indexed":{
+                        "type":"string",
+                        "index":"no",
+                        "store":"yes"
+                    },
+                    "test1" : {
+                        "type":"string",
+                        "index":"analyzed",
+                        "store" : "yes",
+                        "fielddata" : {
+                            "loading" : "eager"
+                        }
+                    },
+                    "test2" : {
+                        "type" : "token_count",
+                        "store" : "yes",
+                        "index" : "not_analyzed",
+                        "analyzer" : "simple"
+                    }
+                }
+            },
+            "object1":{
+                "properties":{
+                    "multi1":{
+                        "type":"multi_field",
+                        "fields":{
+                            "multi1":{
+                                "type":"date"
+                            },
+                            "string":{
+                                "type":"string",
+                                "index":"not_analyzed"
+                            }
+                        }
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-fields.json b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-fields.json
new file mode 100644
index 0000000..b116665
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/multifield/test-multi-fields.json
@@ -0,0 +1,50 @@
+{
+  "person": {
+    "properties": {
+      "name": {
+        "type": "string",
+        "index": "analyzed",
+        "store": "yes",
+        "fields": {
+          "indexed": {
+            "type": "string",
+            "index": "analyzed",
+            "store": "no"
+          },
+          "not_indexed": {
+            "type": "string",
+            "index": "no",
+            "store": "yes"
+          },
+          "test1": {
+            "type": "string",
+            "index": "analyzed",
+            "store": "yes",
+            "fielddata": {
+              "loading": "eager"
+            }
+          },
+          "test2": {
+            "type": "token_count",
+            "index": "not_analyzed",
+            "store": "yes",
+            "analyzer": "simple"
+          }
+        }
+      },
+      "object1": {
+        "properties": {
+          "multi1": {
+            "type": "date",
+            "fields": {
+              "string": {
+                "type": "string",
+                "index": "not_analyzed"
+              }
+            }
+          }
+        }
+      }
+    }
+  }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/path/test-mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/path/test-mapping.json
new file mode 100644
index 0000000..8af451a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/path/test-mapping.json
@@ -0,0 +1,28 @@
+{
+    "person":{
+        "properties":{
+            "name1":{
+                "type":"object",
+                "properties":{
+                    "first1":{
+                        "type":"string"
+                    },
+                    "last1":{
+                        "type":"string"
+                    }
+                }
+            },
+            "name2":{
+                "type":"object",
+                "properties":{
+                    "first2":{
+                        "type":"string"
+                    },
+                    "last2":{
+                        "type":"string"
+                    }
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/simple/test-mapping.json b/core/src/test/resources/org/elasticsearch/index/mapper/simple/test-mapping.json
new file mode 100644
index 0000000..e001673
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/simple/test-mapping.json
@@ -0,0 +1,84 @@
+{
+    person:{
+        "_meta":{
+            "param1":"value1"
+        },
+        date_formats:["yyyy-MM-dd", "dd-MM-yyyy"],
+        dynamic:false,
+        enabled:true,
+        _source:{
+        },
+        properties:{
+            name:{
+                type:"object",
+                dynamic:false,
+                properties:{
+                    first:{
+                        type:"string",
+                        store:"yes"
+                    },
+                    last:{
+                        type:"string",
+                        index:"not_analyzed"
+                    }
+                }
+            },
+            address:{
+                type:"object",
+                properties:{
+                    first:{
+                        properties:{
+                            location:{
+                                type:"string",
+                                store:"yes"
+                            }
+                        }
+                    },
+                    last:{
+                        properties:{
+                            location:{
+                                type:"string"
+                            }
+                        }
+                    }
+                }
+            },
+            age:{
+                type:"integer",
+                null_value:0
+            },
+            birthdate:{
+                type:"date",
+                format:"yyyy-MM-dd"
+            },
+            nerd:{
+                type:"boolean"
+            },
+            dogs:{
+                type:"string"
+            },
+            complex:{
+                type:"object",
+                properties:{
+                    value1:{
+                        type:"string"
+                    },
+                    value2:{
+                        type:"string"
+                    }
+                }
+            },
+            complex2:{
+                type:"object",
+                properties:{
+                    value1:{
+                        type:"string"
+                    },
+                    value2:{
+                        type:"string"
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1-notype-noid.json b/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1-notype-noid.json
new file mode 100644
index 0000000..eb71b7a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1-notype-noid.json
@@ -0,0 +1,39 @@
+{
+    name:{
+        first:"shay",
+        last:"banon"
+    },
+    address:{
+        first:{
+            location:"first location"
+        },
+        last:{
+            location:"last location"
+        }
+    },
+    age:32,
+    birthDate:"1977-11-15",
+    nerd:true,
+    dogs:["buck", "mia"],
+    complex:[
+        {
+            value1:"value1"
+        },
+        {
+            value2:"value2"
+        }
+    ],
+    complex2:[
+        [
+            {
+                value1:"value1"
+            }
+        ],
+        [
+            {
+                value2:"value2"
+            }
+        ]
+    ],
+    nullValue:null
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1-notype.json b/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1-notype.json
new file mode 100644
index 0000000..e91f2f5
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1-notype.json
@@ -0,0 +1,40 @@
+{
+    _id:"1",
+    name:{
+        first:"shay",
+        last:"banon"
+    },
+    address:{
+        first:{
+            location:"first location"
+        },
+        last:{
+            location:"last location"
+        }
+    },
+    age:32,
+    birthDate:"1977-11-15",
+    nerd:true,
+    dogs:["buck", "mia"],
+    complex:[
+        {
+            value1:"value1"
+        },
+        {
+            value2:"value2"
+        }
+    ],
+    complex2:[
+        [
+            {
+                value1:"value1"
+            }
+        ],
+        [
+            {
+                value2:"value2"
+            }
+        ]
+    ],
+    nullValue:null
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1-withtype.json b/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1-withtype.json
new file mode 100644
index 0000000..5711d58
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1-withtype.json
@@ -0,0 +1,42 @@
+{
+    person:{
+        _id:"1",
+        name:{
+            first:"shay",
+            last:"banon"
+        },
+        address:{
+            first:{
+                location:"first location"
+            },
+            last:{
+                location:"last location"
+            }
+        },
+        age:32,
+        birthDate:"1977-11-15",
+        nerd:true,
+        dogs:["buck", "mia"],
+        complex:[
+            {
+                value1:"value1"
+            },
+            {
+                value2:"value2"
+            }
+        ],
+        complex2:[
+            [
+                {
+                    value1:"value1"
+                }
+            ],
+            [
+                {
+                    value2:"value2"
+                }
+            ]
+        ],
+        nullValue:null
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1.json b/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1.json
new file mode 100644
index 0000000..a4e64e9
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/simple/test1.json
@@ -0,0 +1,39 @@
+{
+    name:{
+        first:"shay",
+        last:"banon"
+    },
+    address:{
+        first:{
+            location:"first location"
+        },
+        last:{
+            location:"last location"
+        }
+    },
+    age:32,
+    birthDate:"1977-11-15",
+    nerd:true,
+    dogs:["buck", "mia"],
+    complex:[
+        {
+            value1:"value1"
+        },
+        {
+            value2:"value2"
+        }
+    ],
+    complex2:[
+        [
+            {
+                value1:"value1"
+            }
+        ],
+        [
+            {
+                value2:"value2"
+            }
+        ]
+    ],
+    nullValue:null
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/update/all_mapping_create_index.json b/core/src/test/resources/org/elasticsearch/index/mapper/update/all_mapping_create_index.json
new file mode 100644
index 0000000..e9604ae
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/update/all_mapping_create_index.json
@@ -0,0 +1,31 @@
+{
+  "mappings": {
+    "type": {
+      "_all": {
+        "store": true,
+        "store_term_vectors": true,
+        "store_term_vector_offsets": true,
+        "store_term_vector_positions": true,
+        "store_term_vector_payloads": true,
+        "omit_norms": true,
+        "analyzer": "standard",
+        "search_analyzer": "whitespace",
+        "similarity": "my_similarity",
+        "fielddata": {
+           "format": "paged_bytes"
+        }
+      }
+    }
+  },
+  "settings": {
+    "similarity": {
+      "my_similarity": {
+        "type": "DFR",
+        "basic_model": "g",
+        "after_effect": "l",
+        "normalization": "h2",
+        "normalization.h2.c": "3.0"
+      }
+    }
+  }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/update/all_mapping_update_with_conflicts.json b/core/src/test/resources/org/elasticsearch/index/mapper/update/all_mapping_update_with_conflicts.json
new file mode 100644
index 0000000..252aafe
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/update/all_mapping_update_with_conflicts.json
@@ -0,0 +1,19 @@
+{
+  "type": {
+    "_all": {
+      "store": false,
+      "enabled": false,
+      "store_term_vectors": false,
+      "store_term_vector_offsets": false,
+      "store_term_vector_positions": false,
+      "store_term_vector_payloads": false,
+      "omit_norms": false,
+      "analyzer": "whitespace",
+      "search_analyzer": "standard",
+      "similarity": "bm25",
+      "fielddata": {
+          "format": "paged_bytes"
+      }
+    }
+  }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/mapper/update/default_mapping_with_disabled_root_types.json b/core/src/test/resources/org/elasticsearch/index/mapper/update/default_mapping_with_disabled_root_types.json
new file mode 100644
index 0000000..5f49a6f
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/mapper/update/default_mapping_with_disabled_root_types.json
@@ -0,0 +1 @@
+{"type":{"_timestamp":{"enabled":false}}}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/and-filter-cache.json b/core/src/test/resources/org/elasticsearch/index/query/and-filter-cache.json
new file mode 100644
index 0000000..41cc482
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/and-filter-cache.json
@@ -0,0 +1,21 @@
+{
+    "filtered":{
+      "filter":{
+            "and":{
+                "filters":[
+                    {
+                        "term":{
+                            "name.first":"shay1"
+                        }
+                    },
+                    {
+                        "term":{
+                            "name.first":"shay4"
+                        }
+                    }
+                ],
+                "_cache" : true
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/and-filter-named.json b/core/src/test/resources/org/elasticsearch/index/query/and-filter-named.json
new file mode 100644
index 0000000..605a193
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/and-filter-named.json
@@ -0,0 +1,26 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "and":{
+                "filters":[
+                    {
+                        "term":{
+                            "name.first":"shay1"
+                        }
+                    },
+                    {
+                        "term":{
+                            "name.first":"shay4"
+                        }
+                    }
+                ],
+                "_name":"test"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/and-filter.json b/core/src/test/resources/org/elasticsearch/index/query/and-filter.json
new file mode 100644
index 0000000..752add1
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/and-filter.json
@@ -0,0 +1,25 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "and":{
+                "filters":[
+                    {
+                        "term":{
+                            "name.first":"shay1"
+                        }
+                    },
+                    {
+                        "term":{
+                            "name.first":"shay4"
+                        }
+                    }
+                ]
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/and-filter2.json b/core/src/test/resources/org/elasticsearch/index/query/and-filter2.json
new file mode 100644
index 0000000..580b8e9
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/and-filter2.json
@@ -0,0 +1,23 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "and":[
+                {
+                    "term":{
+                        "name.first":"shay1"
+                    }
+                },
+                {
+                    "term":{
+                        "name.first":"shay4"
+                    }
+                }
+            ]
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/bool-filter.json b/core/src/test/resources/org/elasticsearch/index/query/bool-filter.json
new file mode 100644
index 0000000..484e517
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/bool-filter.json
@@ -0,0 +1,35 @@
+{
+    filtered:{
+        query:{
+            term:{
+                "name.first":"shay"
+            }
+        },
+        filter:{
+            bool:{
+                must:[
+                    {
+                        term:{
+                            "name.first":"shay1"
+                        }
+                    },
+                    {
+                        term:{
+                            "name.first":"shay4"
+                        }
+                    }
+                ],
+                must_not:{
+                    term:{
+                        "name.first":"shay2"
+                    }
+                },
+                should:{
+                    term:{
+                        "name.first":"shay3"
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/bool-query-with-empty-clauses-for-parsing.json b/core/src/test/resources/org/elasticsearch/index/query/bool-query-with-empty-clauses-for-parsing.json
new file mode 100644
index 0000000..5864359
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/bool-query-with-empty-clauses-for-parsing.json
@@ -0,0 +1,17 @@
+{
+  "filtered": {
+    "filter": {
+      "nested": {
+        "path": "nested",
+        "query": {
+          "bool": {
+            "must": [],
+            "must_not": [],
+            "should": []
+          }
+        }
+      },
+      "query": []
+    }
+  }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/bool.json b/core/src/test/resources/org/elasticsearch/index/query/bool.json
new file mode 100644
index 0000000..1619fcf
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/bool.json
@@ -0,0 +1,30 @@
+{
+    bool:{
+        must:[
+            {
+                query_string:{
+                    default_field:"content",
+                    query:"test1"
+                }
+            },
+            {
+                query_string:{
+                    default_field:"content",
+                    query:"test4"
+                }
+            }
+        ],
+        must_not:{
+            query_string:{
+                default_field:"content",
+                query:"test2"
+            }
+        },
+        should:{
+            query_string:{
+                default_field:"content",
+                query:"test3"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/boosting-query.json b/core/src/test/resources/org/elasticsearch/index/query/boosting-query.json
new file mode 100644
index 0000000..87b6e6d
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/boosting-query.json
@@ -0,0 +1,15 @@
+{
+    "boosting":{
+        "positive":{
+            "term":{
+                "field1":"value1"
+            }
+        },
+        "negative":{
+            "term":{
+                "field2":"value2"
+            }
+        },
+        "negative_boost":0.2
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/child-mapping.json b/core/src/test/resources/org/elasticsearch/index/query/child-mapping.json
new file mode 100644
index 0000000..6f3b6e5
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/child-mapping.json
@@ -0,0 +1,12 @@
+{
+    "child":{
+        "properties":{
+            "field":{
+                "type":"string"
+            }
+        },
+        "_parent" : {
+          "type" : "person"
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/commonTerms-query1.json b/core/src/test/resources/org/elasticsearch/index/query/commonTerms-query1.json
new file mode 100644
index 0000000..b2728da
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/commonTerms-query1.json
@@ -0,0 +1,11 @@
+{
+    "common" : {
+        "dogs" : {
+            "query" : "buck mia tom",
+            "cutoff_frequency" : 1,
+            "minimum_should_match" : {
+                "low_freq" : 2
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/commonTerms-query2.json b/core/src/test/resources/org/elasticsearch/index/query/commonTerms-query2.json
new file mode 100644
index 0000000..aeb281b
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/commonTerms-query2.json
@@ -0,0 +1,11 @@
+{
+    "common" : {
+        "dogs" : {
+            "query" : "buck mia tom",
+            "minimum_should_match" : {
+                "high_freq" : "50%",
+                "low_freq" : "5<20%"
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/commonTerms-query3.json b/core/src/test/resources/org/elasticsearch/index/query/commonTerms-query3.json
new file mode 100644
index 0000000..f276209
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/commonTerms-query3.json
@@ -0,0 +1,9 @@
+{
+    "common" : {
+        "dogs" : {
+            "query" : "buck mia tom",
+            "cutoff_frequency" : 1,
+            "minimum_should_match" : 2
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/constantScore-query.json b/core/src/test/resources/org/elasticsearch/index/query/constantScore-query.json
new file mode 100644
index 0000000..bf59bc5
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/constantScore-query.json
@@ -0,0 +1,9 @@
+{
+    constant_score:{
+        filter:{
+            term:{
+                "name.last":"banon"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/data.json b/core/src/test/resources/org/elasticsearch/index/query/data.json
new file mode 100644
index 0000000..79f139f
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/data.json
@@ -0,0 +1,43 @@
+{
+    name:{
+        first:"shay",
+        last:"banon"
+    },
+    address:{
+        first:{
+            location:"first location"
+        },
+        last:{
+            location:"last location"
+        }
+    },
+    age:32,
+    birthDate:"1977-11-15",
+    nerd:true,
+    dogs:["buck", "mia"],
+    complex:[
+        {
+            value1:"value1"
+        },
+        {
+            value2:"value2"
+        }
+    ],
+    complex2:[
+        [
+            {
+                value1:"value1"
+            }
+        ],
+        [
+            {
+                value2:"value2"
+            }
+        ]
+    ],
+    nullValue:null,
+    "location":{
+        "lat":1.1,
+        "lon":1.2
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_format.json b/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_format.json
new file mode 100644
index 0000000..9459678
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_format.json
@@ -0,0 +1,13 @@
+{
+    "constant_score": {
+        "filter": {
+            "range" : {
+                "born" : {
+                    "gte": "01/01/2012",
+                    "lt": "2030",
+                    "format": "dd/MM/yyyy||yyyy"
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_format_invalid.json b/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_format_invalid.json
new file mode 100644
index 0000000..7b5c272
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_format_invalid.json
@@ -0,0 +1,13 @@
+{
+    "constant_score": {
+        "filter": {
+            "range" : {
+                "born" : {
+                    "gte": "01/01/2012",
+                    "lt": "2030",
+                    "format": "yyyy"
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_timezone.json b/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_timezone.json
new file mode 100644
index 0000000..158550a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_timezone.json
@@ -0,0 +1,13 @@
+{
+    "constant_score": {
+        "filter": {
+            "range" : {
+                "born" : {
+                    "gte": "2012-01-01",
+                    "lte": "now",
+                    "time_zone": "+01:00"
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_timezone_numeric_field.json b/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_timezone_numeric_field.json
new file mode 100644
index 0000000..6e07194
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/date_range_filter_timezone_numeric_field.json
@@ -0,0 +1,13 @@
+{
+    "constant_score": {
+        "filter": {
+            "range" : {
+                "age" : {
+                    "gte": "0",
+                    "lte": "100",
+                    "time_zone": "-01:00"
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/date_range_query_boundaries_exclusive.json b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_boundaries_exclusive.json
new file mode 100644
index 0000000..30fe50a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_boundaries_exclusive.json
@@ -0,0 +1,8 @@
+{
+    "range" : {
+        "born" : {
+            "gt": "2014-11-05||/M",
+            "lt": "2014-12-08||/d"
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/date_range_query_boundaries_inclusive.json b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_boundaries_inclusive.json
new file mode 100644
index 0000000..3f3aab0
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_boundaries_inclusive.json
@@ -0,0 +1,8 @@
+{
+    "range" : {
+        "born" : {
+            "gte": "2014-11-05||/M",
+            "lte": "2014-12-08||/d"
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/date_range_query_format.json b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_format.json
new file mode 100644
index 0000000..f679dc9
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_format.json
@@ -0,0 +1,9 @@
+{
+    "range" : {
+        "born" : {
+            "gte": "01/01/2012",
+            "lt": "2030",
+            "format": "dd/MM/yyyy||yyyy"
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/date_range_query_format_invalid.json b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_format_invalid.json
new file mode 100644
index 0000000..307e977
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_format_invalid.json
@@ -0,0 +1,9 @@
+{
+    "range" : {
+        "born" : {
+            "gte": "01/01/2012",
+            "lt": "2030",
+            "format": "yyyy"
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/date_range_query_timezone.json b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_timezone.json
new file mode 100644
index 0000000..0cabb15
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_timezone.json
@@ -0,0 +1,9 @@
+{
+    "range" : {
+        "born" : {
+            "gte": "2012-01-01",
+            "lte": "now",
+            "time_zone": "+01:00"
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/date_range_query_timezone_numeric_field.json b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_timezone_numeric_field.json
new file mode 100644
index 0000000..b7526a2
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/date_range_query_timezone_numeric_field.json
@@ -0,0 +1,9 @@
+{
+    "range" : {
+        "age" : {
+            "gte": "0",
+            "lte": "100",
+            "time_zone": "-01:00"
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/disMax.json b/core/src/test/resources/org/elasticsearch/index/query/disMax.json
new file mode 100644
index 0000000..99da2df
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/disMax.json
@@ -0,0 +1,18 @@
+{
+    dis_max:{
+        tie_breaker:0.7,
+        boost:1.2,
+        queries:[
+            {
+                term:{
+                    "name.first":"first"
+                }
+            },
+            {
+                term:{
+                    "name.last":"last"
+                }
+            }
+        ]
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/disMax2.json b/core/src/test/resources/org/elasticsearch/index/query/disMax2.json
new file mode 100644
index 0000000..ea92d64
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/disMax2.json
@@ -0,0 +1,14 @@
+{
+    "dis_max":{
+        "queries":[
+            {
+                "prefix":{
+                    "name.first":{
+                        "value":"sh",
+                        "boost":1.2
+                    }
+                }
+            }
+        ]
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/faulty-function-score-query.json b/core/src/test/resources/org/elasticsearch/index/query/faulty-function-score-query.json
new file mode 100644
index 0000000..07f906c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/faulty-function-score-query.json
@@ -0,0 +1,15 @@
+{
+    "function_score":{
+        "query":{
+            "term":{
+                "name.last":"banon"
+            }
+        },
+        "functions": { 
+            {
+            "boost_factor" : 3
+            }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/field3.json b/core/src/test/resources/org/elasticsearch/index/query/field3.json
new file mode 100644
index 0000000..61e349f
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/field3.json
@@ -0,0 +1,9 @@
+{
+    field:{
+        age:{
+            query:34,
+            boost:2.0,
+            enable_position_increments:false
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/filtered-query.json b/core/src/test/resources/org/elasticsearch/index/query/filtered-query.json
new file mode 100644
index 0000000..8eea99a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/filtered-query.json
@@ -0,0 +1,14 @@
+{
+    filtered:{
+        query:{
+            term:{
+                "name.first":"shay"
+            }
+        },
+        filter:{
+            term:{
+                "name.last":"banon"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/filtered-query2.json b/core/src/test/resources/org/elasticsearch/index/query/filtered-query2.json
new file mode 100644
index 0000000..b23faf4
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/filtered-query2.json
@@ -0,0 +1,14 @@
+{
+    filtered:{
+        filter:{
+            term:{
+                "name.last":"banon"
+            }
+        },
+        query:{
+            term:{
+                "name.first":"shay"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/filtered-query3.json b/core/src/test/resources/org/elasticsearch/index/query/filtered-query3.json
new file mode 100644
index 0000000..4a9db49
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/filtered-query3.json
@@ -0,0 +1,19 @@
+{
+    filtered:{
+        filter:{
+            range:{
+                age:{
+                    from:"23",
+                    to:"54",
+                    include_lower:true,
+                    include_upper:false
+                }
+            }
+        },
+        query:{
+            term:{
+                "name.first":"shay"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/filtered-query4.json b/core/src/test/resources/org/elasticsearch/index/query/filtered-query4.json
new file mode 100644
index 0000000..8c10013
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/filtered-query4.json
@@ -0,0 +1,17 @@
+{
+    filtered:{
+        query:{
+            wildcard:{
+                "name.first":{
+                    wildcard:"sh*",
+                    boost:1.1
+                }
+            }
+        },
+        filter:{
+            term:{
+                "name.last":"banon"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/fquery-filter.json b/core/src/test/resources/org/elasticsearch/index/query/fquery-filter.json
new file mode 100644
index 0000000..6015334
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/fquery-filter.json
@@ -0,0 +1,19 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "fquery":{
+                "query":{
+                    "term":{
+                        "name.last":"banon"
+                    }
+                },
+                "_name":"test"
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/fquery-with-empty-bool-query.json b/core/src/test/resources/org/elasticsearch/index/query/fquery-with-empty-bool-query.json
new file mode 100644
index 0000000..6a6a48c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/fquery-with-empty-bool-query.json
@@ -0,0 +1,18 @@
+{
+  "fquery": {
+    "query": {
+      "filtered": {
+        "query": {
+          "term": {
+            "text": "apache"
+          }
+        },
+        "filter": {
+          "term": {
+            "text": "apache"
+          }
+        }
+      }
+    }
+  }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/function-filter-score-query.json b/core/src/test/resources/org/elasticsearch/index/query/function-filter-score-query.json
new file mode 100644
index 0000000..e78c549
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/function-filter-score-query.json
@@ -0,0 +1,30 @@
+
+
+{
+    "function_score":{
+        "query":{
+            "term":{
+                "name.last":"banon"
+            }
+        },
+        "functions":  [
+            {
+                "boost_factor": 3,
+                "filter": {
+                    term:{
+                        "name.last":"banon"
+                    }
+                }
+            },
+            {
+                "boost_factor": 3
+            },
+            {
+                "boost_factor": 3
+            }
+        ],
+        "boost" : 3,
+        "score_mode" : "avg",
+        "max_boost" : 10
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/function-score-query-causing-NPE.json b/core/src/test/resources/org/elasticsearch/index/query/function-score-query-causing-NPE.json
new file mode 100644
index 0000000..283682b
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/function-score-query-causing-NPE.json
@@ -0,0 +1,9 @@
+{
+    "function_score": {
+      "script_score": {
+        "script": "_index['text']['foo'].tf()"
+      },
+      "weight": 2
+    }
+}
+
diff --git a/core/src/test/resources/org/elasticsearch/index/query/fuzzy-with-fields.json b/core/src/test/resources/org/elasticsearch/index/query/fuzzy-with-fields.json
new file mode 100644
index 0000000..7636496
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/fuzzy-with-fields.json
@@ -0,0 +1,10 @@
+{
+    "fuzzy":{
+        "name.first":{
+            "value":"sh",
+            "fuzziness": "AUTO",
+            "prefix_length":1,
+            "boost":2.0
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/fuzzy-with-fields2.json b/core/src/test/resources/org/elasticsearch/index/query/fuzzy-with-fields2.json
new file mode 100644
index 0000000..095ecc6
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/fuzzy-with-fields2.json
@@ -0,0 +1,9 @@
+{
+    "fuzzy":{
+        "age":{
+            "value":12,
+            "fuzziness":5,
+            "boost":2.0
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/fuzzy.json b/core/src/test/resources/org/elasticsearch/index/query/fuzzy.json
new file mode 100644
index 0000000..27d8dee
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/fuzzy.json
@@ -0,0 +1,5 @@
+{
+    "fuzzy":{
+        "name.first":"sh"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geoShape-filter.json b/core/src/test/resources/org/elasticsearch/index/query/geoShape-filter.json
new file mode 100644
index 0000000..a4392ae
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geoShape-filter.json
@@ -0,0 +1,21 @@
+{
+    "filtered" : {
+        "query" : {
+            "match_all" : {}
+        },
+        "filter" : {
+            "geo_shape" : {
+                "country" : {
+                    "shape" : {
+                        "type" : "Envelope",
+                        "coordinates" : [
+                            [-45, 45],
+                            [45, -45]
+                        ]
+                    },
+                    "relation" : "intersects"
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geoShape-query.json b/core/src/test/resources/org/elasticsearch/index/query/geoShape-query.json
new file mode 100644
index 0000000..e0af827
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geoShape-query.json
@@ -0,0 +1,14 @@
+{
+    "geo_shape" : {
+        "country" : {
+            "shape" : {
+                "type" : "Envelope",
+                "coordinates" : [
+                    [-45, 45],
+                    [45, -45]
+                ]
+            },
+            "relation" : "intersects"
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox-named.json b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox-named.json
new file mode 100644
index 0000000..6db6d5a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox-named.json
@@ -0,0 +1,16 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_bounding_box":{
+                "location":{
+                    "top_left":[-70, 40],
+                    "bottom_right":[-80, 30]
+                },
+                "_name":"test"
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox1.json b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox1.json
new file mode 100644
index 0000000..8d04915
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox1.json
@@ -0,0 +1,15 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_bounding_box":{
+                "location":{
+                    "top_left":[-70, 40],
+                    "bottom_right":[-80, 30]
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox2.json b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox2.json
new file mode 100644
index 0000000..6321654
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox2.json
@@ -0,0 +1,21 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_bounding_box":{
+                "location":{
+                    "top_left":{
+                        "lat":40,
+                        "lon":-70
+                    },
+                    "bottom_right":{
+                        "lat":30,
+                        "lon":-80
+                    }
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox3.json b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox3.json
new file mode 100644
index 0000000..0899960
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox3.json
@@ -0,0 +1,15 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_bounding_box":{
+                "location":{
+                    "top_left":"40, -70",
+                    "bottom_right":"30, -80"
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox4.json b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox4.json
new file mode 100644
index 0000000..170a02d
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox4.json
@@ -0,0 +1,15 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_bounding_box":{
+                "location":{
+                    "top_left":"drn5x1g8cu2y",
+                    "bottom_right":"30, -80"
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox5.json b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox5.json
new file mode 100644
index 0000000..347a463
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox5.json
@@ -0,0 +1,15 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_bounding_box":{
+                "location":{
+                    "top_right":"40, -80",
+                    "bottom_left":"30, -70"
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox6.json b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox6.json
new file mode 100644
index 0000000..96ccbd0
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_boundingbox6.json
@@ -0,0 +1,17 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_bounding_box":{
+                "location":{
+                    "right": -80,
+                    "top": 40,
+                    "left": -70,
+                    "bottom": 30
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance-named.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance-named.json
new file mode 100644
index 0000000..a3e0be9
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance-named.json
@@ -0,0 +1,17 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":"12mi",
+                "location":{
+                    "lat":40,
+                    "lon":-70
+                },
+                "_name":"test"
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance1.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance1.json
new file mode 100644
index 0000000..cf3b0ab
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance1.json
@@ -0,0 +1,16 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":"12mi",
+                "location":{
+                    "lat":40,
+                    "lon":-70
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance10.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance10.json
new file mode 100644
index 0000000..067b39e
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance10.json
@@ -0,0 +1,17 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":19.312128,
+                "unit":"km",
+                "location":{
+                    "lat":40,
+                    "lon":-70
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance11.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance11.json
new file mode 100644
index 0000000..008d5b5
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance11.json
@@ -0,0 +1,16 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":"19.312128km",
+                "location":{
+                    "lat":40,
+                    "lon":-70
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance12.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance12.json
new file mode 100644
index 0000000..8769223
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance12.json
@@ -0,0 +1,17 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":"12mi",
+                "unit":"km",
+                "location":{
+                    "lat":40,
+                    "lon":-70
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance2.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance2.json
new file mode 100644
index 0000000..3283867
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance2.json
@@ -0,0 +1,13 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":"12mi",
+                "location":[-70, 40]
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance3.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance3.json
new file mode 100644
index 0000000..193f234
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance3.json
@@ -0,0 +1,13 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":"12mi",
+                "location":"40, -70"
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance4.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance4.json
new file mode 100644
index 0000000..56a7409
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance4.json
@@ -0,0 +1,13 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":"12mi",
+                "location":"drn5x1g8cu2y"
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance5.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance5.json
new file mode 100644
index 0000000..bea9a3d
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance5.json
@@ -0,0 +1,17 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":12,
+                "unit":"mi",
+                "location":{
+                    "lat":40,
+                    "lon":-70
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance6.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance6.json
new file mode 100644
index 0000000..4afa128
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance6.json
@@ -0,0 +1,17 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":"12",
+                "unit":"mi",
+                "location":{
+                    "lat":40,
+                    "lon":-70
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance7.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance7.json
new file mode 100644
index 0000000..7fcf8bd
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance7.json
@@ -0,0 +1,16 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":"19.312128",
+                "location":{
+                    "lat":40,
+                    "lon":-70
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance8.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance8.json
new file mode 100644
index 0000000..3bafd16
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance8.json
@@ -0,0 +1,16 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":19.312128,
+                "location":{
+                    "lat":40,
+                    "lon":-70
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_distance9.json b/core/src/test/resources/org/elasticsearch/index/query/geo_distance9.json
new file mode 100644
index 0000000..e6c8f12
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_distance9.json
@@ -0,0 +1,17 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_distance":{
+                "distance":"19.312128",
+                "unit":"km",
+                "location":{
+                    "lat":40,
+                    "lon":-70
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_polygon-named.json b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon-named.json
new file mode 100644
index 0000000..91256c1
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon-named.json
@@ -0,0 +1,19 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_polygon":{
+                "location":{
+                    "points":[
+                        [-70, 40],
+                        [-80, 30],
+                        [-90, 20]
+                    ]
+                },
+                "_name":"test"
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_polygon1.json b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon1.json
new file mode 100644
index 0000000..99ac329
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon1.json
@@ -0,0 +1,18 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_polygon":{
+                "location":{
+                    "points":[
+                        [-70, 40],
+                        [-80, 30],
+                        [-90, 20]
+                    ]
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_polygon2.json b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon2.json
new file mode 100644
index 0000000..588b22f
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon2.json
@@ -0,0 +1,27 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_polygon":{
+                "location":{
+                    "points":[
+                        {
+                            "lat":40,
+                            "lon":-70
+                        },
+                        {
+                            "lat":30,
+                            "lon":-80
+                        },
+                        {
+                            "lat":20,
+                            "lon":-90
+                        }
+                    ]
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_polygon3.json b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon3.json
new file mode 100644
index 0000000..d6d905b
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon3.json
@@ -0,0 +1,18 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_polygon":{
+                "location":{
+                    "points":[
+                        "40, -70",
+                        "30, -80",
+                        "20, -90"
+                    ]
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_polygon4.json b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon4.json
new file mode 100644
index 0000000..ae9608d
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon4.json
@@ -0,0 +1,18 @@
+{
+    "filtered":{
+        "query":{
+            "match_all":{}
+        },
+        "filter":{
+            "geo_polygon":{
+                "location":{
+                    "points":[
+                        "drn5x1g8cu2y",
+                        "30, -80",
+                        "20, -90"
+                    ]
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_1.json b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_1.json
new file mode 100644
index 0000000..e079d64
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_1.json
@@ -0,0 +1,20 @@
+{
+    "filtered": {
+        "query": {
+            "match_all": {}
+        },
+        "filter": {
+            "geo_polygon": {
+                "location": {
+                    "points": {
+                        "points": [
+                            [-70, 40],
+                            [-80, 30],
+                            [-90, 20]
+                        ]
+                    }
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_2.json b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_2.json
new file mode 100644
index 0000000..0955c26
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_2.json
@@ -0,0 +1,22 @@
+{
+    "filtered": {
+        "query": {
+            "match_all": {}
+        },
+        "filter": {
+            "geo_polygon": {
+                "location": {
+                    "points": [
+                        [-70, 40],
+                        [-80, 30],
+                        [-90, 20]
+                    ],
+                    "something_else": {
+
+                    }
+
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_3.json b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_3.json
new file mode 100644
index 0000000..0ac2a7b
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_3.json
@@ -0,0 +1,12 @@
+{
+    "filtered": {
+        "query": {
+            "match_all": {}
+        },
+        "filter": {
+            "geo_polygon": {
+                "location": ["WRONG"]
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_4.json b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_4.json
new file mode 100644
index 0000000..51f6ad0
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_4.json
@@ -0,0 +1,19 @@
+{
+    "filtered": {
+        "query": {
+            "match_all": {}
+        },
+        "filter": {
+            "geo_polygon": {
+                "location": {
+                    "points": [
+                        [-70, 40],
+                        [-80, 30],
+                        [-90, 20]
+                    ]
+                },
+                "bla": true
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_5.json b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_5.json
new file mode 100644
index 0000000..6f058f5
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/geo_polygon_exception_5.json
@@ -0,0 +1,19 @@
+{
+    "filtered": {
+        "query": {
+            "match_all": {}
+        },
+        "filter": {
+            "geo_polygon": {
+                "location": {
+                    "points": [
+                        [-70, 40],
+                        [-80, 30],
+                        [-90, 20]
+                    ]
+                },
+                "bla": ["array"]
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/has-child-in-and-filter-cached.json b/core/src/test/resources/org/elasticsearch/index/query/has-child-in-and-filter-cached.json
new file mode 100644
index 0000000..4b055cb
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/has-child-in-and-filter-cached.json
@@ -0,0 +1,19 @@
+{
+  "filtered":{
+    "filter":{
+      "and" : {
+        "filters" : [
+          {
+            "has_child" : {
+              "type" : "child",
+              "query" : {
+                "match_all" : {}
+              }
+            }
+          }
+        ],
+        "_cache" : true
+      }
+    }
+  }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/has-child.json b/core/src/test/resources/org/elasticsearch/index/query/has-child.json
new file mode 100644
index 0000000..c87ac17
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/has-child.json
@@ -0,0 +1,13 @@
+{
+  "filtered":{
+    "filter":{
+      "has_child" : {
+        "type" : "child",
+        "query" : {
+          "match_all" : {}
+        },
+        "_cache" : true
+      }
+    }
+  }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/mapping.json b/core/src/test/resources/org/elasticsearch/index/query/mapping.json
new file mode 100644
index 0000000..3939249
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/mapping.json
@@ -0,0 +1,15 @@
+{
+    "person":{
+        "properties":{
+            "location":{
+                "type":"geo_point"
+            },
+            "country" : {
+                "type" : "geo_shape"
+            },
+            "born":{
+                "type":"date"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/match-query-bad-type.json b/core/src/test/resources/org/elasticsearch/index/query/match-query-bad-type.json
new file mode 100644
index 0000000..47d1227
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/match-query-bad-type.json
@@ -0,0 +1,8 @@
+{
+    "match" : {
+        "message" : {
+            "query" : "this is a test",
+            "type" : "doesNotExist"
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/match-with-fuzzy-transpositions.json b/core/src/test/resources/org/elasticsearch/index/query/match-with-fuzzy-transpositions.json
new file mode 100644
index 0000000..5f4fe8b
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/match-with-fuzzy-transpositions.json
@@ -0,0 +1 @@
+{ "match": { "body": { "query": "fuzzy", "fuzziness": 1, "fuzzy_transpositions": true }} }
diff --git a/core/src/test/resources/org/elasticsearch/index/query/match-without-fuzzy-transpositions.json b/core/src/test/resources/org/elasticsearch/index/query/match-without-fuzzy-transpositions.json
new file mode 100644
index 0000000..06c77aa
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/match-without-fuzzy-transpositions.json
@@ -0,0 +1 @@
+{ "match": { "body": { "query": "fuzzy", "fuzziness": 1, "fuzzy_transpositions": false }} }
diff --git a/core/src/test/resources/org/elasticsearch/index/query/matchAll.json b/core/src/test/resources/org/elasticsearch/index/query/matchAll.json
new file mode 100644
index 0000000..3325646
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/matchAll.json
@@ -0,0 +1,5 @@
+{
+    match_all:{
+        boost:1.2
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/match_all_empty1.json b/core/src/test/resources/org/elasticsearch/index/query/match_all_empty1.json
new file mode 100644
index 0000000..6dd141f
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/match_all_empty1.json
@@ -0,0 +1,3 @@
+{
+    "match_all": {}
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/match_all_empty2.json b/core/src/test/resources/org/elasticsearch/index/query/match_all_empty2.json
new file mode 100644
index 0000000..a0549df
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/match_all_empty2.json
@@ -0,0 +1,3 @@
+{
+    "match_all": []
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/mlt-items.json b/core/src/test/resources/org/elasticsearch/index/query/mlt-items.json
new file mode 100644
index 0000000..d7839ac
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/mlt-items.json
@@ -0,0 +1,22 @@
+{
+    "more_like_this" : {
+        "fields" : ["name.first", "name.last"],
+        "like_text": "Apache Lucene",
+        "like" : [
+        {
+            "_index" : "test",
+            "_type" : "person",
+            "_id" : "1"
+        },
+        {
+            "_index" : "test",
+            "_type" : "person",
+            "_id" : "2"
+        }
+        ],
+        "ids" : ["3", "4"],
+        "include" : true,
+        "min_term_freq" : 1,
+        "max_query_terms" : 12
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/mlt.json b/core/src/test/resources/org/elasticsearch/index/query/mlt.json
new file mode 100644
index 0000000..d3d98be
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/mlt.json
@@ -0,0 +1,8 @@
+{
+    "more_like_this" : {
+        "fields" : ["name.first", "name.last"],
+        "like_text" : "something",
+        "min_term_freq" : 1,
+        "max_query_terms" : 12
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/multiMatch-query-bad-type.json b/core/src/test/resources/org/elasticsearch/index/query/multiMatch-query-bad-type.json
new file mode 100644
index 0000000..9c3b751
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/multiMatch-query-bad-type.json
@@ -0,0 +1,7 @@
+{
+    "multi_match": {
+        "query": "foo bar",
+        "fields": [ "myField", "otherField" ],
+        "type":"doesNotExist"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/multiMatch-query-fields-as-string.json b/core/src/test/resources/org/elasticsearch/index/query/multiMatch-query-fields-as-string.json
new file mode 100644
index 0000000..d29211d
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/multiMatch-query-fields-as-string.json
@@ -0,0 +1,6 @@
+{
+    "multi_match": {
+        "query": "foo bar",
+        "fields": "myField"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/multiMatch-query-simple.json b/core/src/test/resources/org/elasticsearch/index/query/multiMatch-query-simple.json
new file mode 100644
index 0000000..904ba0e
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/multiMatch-query-simple.json
@@ -0,0 +1,6 @@
+{
+    "multi_match": {
+        "query": "foo bar",
+        "fields": [ "myField", "otherField" ]
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/not-filter.json b/core/src/test/resources/org/elasticsearch/index/query/not-filter.json
new file mode 100644
index 0000000..42c48d8
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/not-filter.json
@@ -0,0 +1,18 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "not":{
+                "filter":{
+                    "term":{
+                        "name.first":"shay1"
+                    }
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/not-filter2.json b/core/src/test/resources/org/elasticsearch/index/query/not-filter2.json
new file mode 100644
index 0000000..6defaff
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/not-filter2.json
@@ -0,0 +1,16 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "not":{
+                "term":{
+                    "name.first":"shay1"
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/not-filter3.json b/core/src/test/resources/org/elasticsearch/index/query/not-filter3.json
new file mode 100644
index 0000000..ab61335
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/not-filter3.json
@@ -0,0 +1,16 @@
+{
+    "filtered":{
+        "filter":{
+            "not":{
+                "term":{
+                    "name.first":"shay1"
+                }
+            }
+        },
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/or-filter.json b/core/src/test/resources/org/elasticsearch/index/query/or-filter.json
new file mode 100644
index 0000000..b1e73fa
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/or-filter.json
@@ -0,0 +1,25 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "or":{
+                "filters":[
+                    {
+                        "term":{
+                            "name.first":"shay1"
+                        }
+                    },
+                    {
+                        "term":{
+                            "name.first":"shay4"
+                        }
+                    }
+                ]
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/or-filter2.json b/core/src/test/resources/org/elasticsearch/index/query/or-filter2.json
new file mode 100644
index 0000000..2c15e9a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/or-filter2.json
@@ -0,0 +1,23 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "or":[
+                {
+                    "term":{
+                        "name.first":"shay1"
+                    }
+                },
+                {
+                    "term":{
+                        "name.first":"shay4"
+                    }
+                }
+            ]
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/prefix-boost.json b/core/src/test/resources/org/elasticsearch/index/query/prefix-boost.json
new file mode 100644
index 0000000..4da623a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/prefix-boost.json
@@ -0,0 +1,8 @@
+{
+    "prefix":{
+        "name.first":{
+            "value":"sh",
+            "boost":1.2
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/prefix-filter-named.json b/core/src/test/resources/org/elasticsearch/index/query/prefix-filter-named.json
new file mode 100644
index 0000000..de01701
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/prefix-filter-named.json
@@ -0,0 +1,15 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "prefix":{
+                "name.first":"sh",
+                "_name":"test"
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/prefix-filter.json b/core/src/test/resources/org/elasticsearch/index/query/prefix-filter.json
new file mode 100644
index 0000000..1f2e42e
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/prefix-filter.json
@@ -0,0 +1,14 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "prefix":{
+                "name.first":"sh"
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/prefix-with-boost.json b/core/src/test/resources/org/elasticsearch/index/query/prefix-with-boost.json
new file mode 100644
index 0000000..83e56cb
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/prefix-with-boost.json
@@ -0,0 +1,8 @@
+{
+    prefix:{
+        "name.first":{
+            prefix:"sh",
+            boost:2.0
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/prefix.json b/core/src/test/resources/org/elasticsearch/index/query/prefix.json
new file mode 100644
index 0000000..49f5261
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/prefix.json
@@ -0,0 +1,5 @@
+{
+    prefix:{
+        "name.first":"sh"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/query-fields-match.json b/core/src/test/resources/org/elasticsearch/index/query/query-fields-match.json
new file mode 100644
index 0000000..c15cdf3
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/query-fields-match.json
@@ -0,0 +1,7 @@
+{
+    query_string:{
+        fields:["name.*"],
+        use_dis_max:false,
+        query:"test"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/query-fields1.json b/core/src/test/resources/org/elasticsearch/index/query/query-fields1.json
new file mode 100644
index 0000000..84abcaa
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/query-fields1.json
@@ -0,0 +1,7 @@
+{
+    query_string:{
+        fields:["content", "name"],
+        use_dis_max:false,
+        query:"test"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/query-fields2.json b/core/src/test/resources/org/elasticsearch/index/query/query-fields2.json
new file mode 100644
index 0000000..ab39c87
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/query-fields2.json
@@ -0,0 +1,7 @@
+{
+    query_string:{
+        fields:["content", "name"],
+        use_dis_max:true,
+        query:"test"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/query-fields3.json b/core/src/test/resources/org/elasticsearch/index/query/query-fields3.json
new file mode 100644
index 0000000..8114c1b
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/query-fields3.json
@@ -0,0 +1,7 @@
+{
+    query_string:{
+        fields:["content^2.2", "name"],
+        use_dis_max:true,
+        query:"test"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/query-filter.json b/core/src/test/resources/org/elasticsearch/index/query/query-filter.json
new file mode 100644
index 0000000..dee136d
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/query-filter.json
@@ -0,0 +1,16 @@
+{
+    filtered:{
+        query:{
+            term:{
+                "name.first":"shay"
+            }
+        },
+        filter:{
+            query:{
+                term:{
+                    "name.last":"banon"
+                }
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/query-regexp-max-determinized-states.json b/core/src/test/resources/org/elasticsearch/index/query/query-regexp-max-determinized-states.json
new file mode 100644
index 0000000..023b90e
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/query-regexp-max-determinized-states.json
@@ -0,0 +1,7 @@
+{
+    query_string: {
+        default_field: "content",
+        query:"/foo*bar/",
+	max_determinized_states: 5000
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/query-regexp-too-many-determinized-states.json b/core/src/test/resources/org/elasticsearch/index/query/query-regexp-too-many-determinized-states.json
new file mode 100644
index 0000000..0d2d41a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/query-regexp-too-many-determinized-states.json
@@ -0,0 +1,6 @@
+{
+    query_string: {
+        default_field: "content",
+        query: "/[ac]*a[ac]{50,200}/"
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/query-timezone-incorrect.json b/core/src/test/resources/org/elasticsearch/index/query/query-timezone-incorrect.json
new file mode 100644
index 0000000..3bffb0f
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/query-timezone-incorrect.json
@@ -0,0 +1,6 @@
+{
+    "query_string":{
+        "time_zone":"This timezone does not exist",
+        "query":"date:[2012 TO 2014]"
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/query-timezone.json b/core/src/test/resources/org/elasticsearch/index/query/query-timezone.json
new file mode 100644
index 0000000..e2fcc0e
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/query-timezone.json
@@ -0,0 +1,6 @@
+{
+    "query_string":{
+        "time_zone":"Europe/Paris",
+        "query":"date:[2012 TO 2014]"
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/query.json b/core/src/test/resources/org/elasticsearch/index/query/query.json
new file mode 100644
index 0000000..f07a0d8
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/query.json
@@ -0,0 +1,7 @@
+{
+    query_string:{
+        default_field:"content",
+        phrase_slop:1,
+        query:"test"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/query2.json b/core/src/test/resources/org/elasticsearch/index/query/query2.json
new file mode 100644
index 0000000..410e05c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/query2.json
@@ -0,0 +1,6 @@
+{
+    query_string:{
+        default_field:"age",
+        query:"12~0.2"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/range-filter-named.json b/core/src/test/resources/org/elasticsearch/index/query/range-filter-named.json
new file mode 100644
index 0000000..1b50177
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/range-filter-named.json
@@ -0,0 +1,20 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "range":{
+                "age":{
+                    "from":"23",
+                    "to":"54",
+                    "include_lower":true,
+                    "include_upper":false
+                },
+                "_name":"test"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/range-filter.json b/core/src/test/resources/org/elasticsearch/index/query/range-filter.json
new file mode 100644
index 0000000..3842e0b
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/range-filter.json
@@ -0,0 +1,19 @@
+{
+    filtered:{
+        query:{
+            term:{
+                "name.first":"shay"
+            }
+        },
+        filter:{
+            range:{
+                age:{
+                    from:"23",
+                    to:"54",
+                    include_lower:true,
+                    include_upper:false
+                }
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/range.json b/core/src/test/resources/org/elasticsearch/index/query/range.json
new file mode 100644
index 0000000..cc2363f
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/range.json
@@ -0,0 +1,10 @@
+{
+    range:{
+        age:{
+            from:"23",
+            to:"54",
+            include_lower:true,
+            include_upper:false
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/range2.json b/core/src/test/resources/org/elasticsearch/index/query/range2.json
new file mode 100644
index 0000000..c116b3c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/range2.json
@@ -0,0 +1,8 @@
+{
+    range:{
+        age:{
+            gte:"23",
+            lt:"54"
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/regexp-boost.json b/core/src/test/resources/org/elasticsearch/index/query/regexp-boost.json
new file mode 100644
index 0000000..ed8699b
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/regexp-boost.json
@@ -0,0 +1,8 @@
+{
+    "regexp":{
+        "name.first":{
+            "value":"sh",
+            "boost":1.2
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-flags-named-cached.json b/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-flags-named-cached.json
new file mode 100644
index 0000000..112f8fb
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-flags-named-cached.json
@@ -0,0 +1,20 @@
+{
+    "filtered": {
+        "query": {
+            "term": {
+                "name.first": "shay"
+            }
+        },
+        "filter": {
+            "regexp":{
+                "name.first" : {
+                    "value" : "s.*y",
+                    "flags" : "INTERSECTION|COMPLEMENT|EMPTY"
+                },
+                "_name":"test",
+                "_cache" : true,
+                "_cache_key" : "key"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-flags.json b/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-flags.json
new file mode 100644
index 0000000..a5d7307
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-flags.json
@@ -0,0 +1,18 @@
+{
+    "filtered": {
+        "query": {
+            "term": {
+                "name.first": "shay"
+            }
+        },
+        "filter": {
+            "regexp":{
+                "name.first" : {
+                    "value" : "s.*y",
+                    "flags" : "INTERSECTION|COMPLEMENT|EMPTY"
+                },
+                "_name":"test"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-max-determinized-states.json b/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-max-determinized-states.json
new file mode 100644
index 0000000..2672ac6
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-max-determinized-states.json
@@ -0,0 +1,17 @@
+{
+    "filtered": {
+        "query": {
+            "term": {
+                "name.first": "shay"
+            }
+        },
+        "filter": {
+            "regexp": {
+                "name.first": {
+		    "value": "s.*y",
+		    "max_determinized_states": 6000
+		}
+            }
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-named.json b/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-named.json
new file mode 100644
index 0000000..ac96b3e
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/regexp-filter-named.json
@@ -0,0 +1,15 @@
+{
+    "filtered": {
+        "query": {
+            "term": {
+                "name.first": "shay"
+            }
+        },
+        "filter": {
+            "regexp":{
+                "name.first" : "s.*y",
+                "_name" : "test"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/regexp-filter.json b/core/src/test/resources/org/elasticsearch/index/query/regexp-filter.json
new file mode 100644
index 0000000..d7c7bfd
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/regexp-filter.json
@@ -0,0 +1,14 @@
+{
+    "filtered": {
+        "query": {
+            "term": {
+                "name.first": "shay"
+            }
+        },
+        "filter": {
+            "regexp":{
+                "name.first" : "s.*y"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/regexp-max-determinized-states.json b/core/src/test/resources/org/elasticsearch/index/query/regexp-max-determinized-states.json
new file mode 100644
index 0000000..df2f5cc
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/regexp-max-determinized-states.json
@@ -0,0 +1,8 @@
+{
+    "regexp": {
+        "name.first": {
+            "value": "s.*y",
+            "max_determinized_states": 5000
+        }
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/regexp.json b/core/src/test/resources/org/elasticsearch/index/query/regexp.json
new file mode 100644
index 0000000..6c3d694
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/regexp.json
@@ -0,0 +1,5 @@
+{
+    "regexp":{
+        "name.first": "s.*y"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/simple-query-string.json b/core/src/test/resources/org/elasticsearch/index/query/simple-query-string.json
new file mode 100644
index 0000000..9208e88
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/simple-query-string.json
@@ -0,0 +1,8 @@
+{
+  "simple_query_string": {
+    "query": "foo bar",
+    "analyzer": "keyword",
+    "fields": ["body^5","_all"],
+    "default_operator": "and"
+  }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-fuzzy-range.json b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-fuzzy-range.json
new file mode 100644
index 0000000..d9ca05b
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-fuzzy-range.json
@@ -0,0 +1,13 @@
+{
+	"span_multi":{
+		"match":{
+			"fuzzy":{
+        		"age":{
+		            "value":12,
+		            "fuzziness":5,
+		            "boost":2.0
+		        }
+    		}
+    	}
+	}
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-fuzzy-term.json b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-fuzzy-term.json
new file mode 100644
index 0000000..edb58e3
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-fuzzy-term.json
@@ -0,0 +1,12 @@
+{
+	"span_multi":{
+		"match":{
+			"fuzzy" : {
+				"user" : {
+	                "value" : "ki",
+	                "boost" : 1.08
+	            }
+	    	}
+		}
+	}
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-prefix.json b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-prefix.json
new file mode 100644
index 0000000..62918d6
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-prefix.json
@@ -0,0 +1,7 @@
+{
+	"span_multi":{
+		"match":{
+			"prefix" : { "user" :  { "value" : "ki", "boost" : 1.08 } }
+		}
+	}
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-range-numeric.json b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-range-numeric.json
new file mode 100644
index 0000000..d9db8a4
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-range-numeric.json
@@ -0,0 +1,16 @@
+{
+	"span_multi":{
+		"match":{
+			"range" : {
+     		   "age" : { 
+            		"from" : 10, 
+            		"to" : 20, 
+            		"include_lower" : true, 
+            		"include_upper": false, 
+            		"boost" : 2.0
+       			}
+    		}
+		}
+	}
+}
+
diff --git a/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-range-term.json b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-range-term.json
new file mode 100644
index 0000000..8c4da31
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-range-term.json
@@ -0,0 +1,16 @@
+{
+	"span_multi":{
+		"match":{
+			"range" : {
+     		   "user" : { 
+            		"from" : "alice", 
+            		"to" : "bob", 
+            		"include_lower" : true, 
+            		"include_upper": false, 
+            		"boost" : 2.0
+       			}
+    		}
+		}
+	}
+}
+
diff --git a/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-wildcard.json b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-wildcard.json
new file mode 100644
index 0000000..a2eaeb7
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/span-multi-term-wildcard.json
@@ -0,0 +1,7 @@
+{
+	"span_multi":{
+		"match":{
+			"wildcard" : { "user" : {"value": "ki*y" , "boost" : 1.08}}
+		}
+	}
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/spanContaining.json b/core/src/test/resources/org/elasticsearch/index/query/spanContaining.json
new file mode 100644
index 0000000..13f91d8
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/spanContaining.json
@@ -0,0 +1,14 @@
+{
+    span_containing:{
+        big:{
+            span_term:{
+                age:34
+            }
+        },
+        little:{
+            span_term:{
+                age:35
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/spanFieldMaskingTerm.json b/core/src/test/resources/org/elasticsearch/index/query/spanFieldMaskingTerm.json
new file mode 100644
index 0000000..9849c10
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/spanFieldMaskingTerm.json
@@ -0,0 +1,29 @@
+{
+   span_near:{
+      clauses:[
+         {
+            span_term:{
+               age:34
+            }
+         },
+         {
+            span_term:{
+               age:35
+            }
+         },
+         {
+           field_masking_span:{
+              query:{
+                 span_term:{
+                    age_1 : 36
+                 }
+              },
+              field:"age"
+           }
+         }
+      ],
+      slop:12,
+      in_order:false,
+      collect_payloads:false
+   }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/spanFirst.json b/core/src/test/resources/org/elasticsearch/index/query/spanFirst.json
new file mode 100644
index 0000000..9972c76
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/spanFirst.json
@@ -0,0 +1,10 @@
+{
+    span_first:{
+        match:{
+            span_term:{
+                age:34
+            }
+        },
+        end:12
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/spanNear.json b/core/src/test/resources/org/elasticsearch/index/query/spanNear.json
new file mode 100644
index 0000000..ce17063
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/spanNear.json
@@ -0,0 +1,24 @@
+{
+    span_near:{
+        clauses:[
+            {
+                span_term:{
+                    age:34
+                }
+            },
+            {
+                span_term:{
+                    age:35
+                }
+            },
+            {
+                span_term:{
+                    age:36
+                }
+            }
+        ],
+        slop:12,
+        in_order:false,
+        collect_payloads:false
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/spanNot.json b/core/src/test/resources/org/elasticsearch/index/query/spanNot.json
new file mode 100644
index 0000000..c90de33
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/spanNot.json
@@ -0,0 +1,14 @@
+{
+    span_not:{
+        include:{
+            span_term:{
+                age:34
+            }
+        },
+        exclude:{
+            span_term:{
+                age:35
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/spanOr.json b/core/src/test/resources/org/elasticsearch/index/query/spanOr.json
new file mode 100644
index 0000000..06c5262
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/spanOr.json
@@ -0,0 +1,21 @@
+{
+    span_or:{
+        clauses:[
+            {
+                span_term:{
+                    age:34
+                }
+            },
+            {
+                span_term:{
+                    age:35
+                }
+            },
+            {
+                span_term:{
+                    age:36
+                }
+            }
+        ]
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/spanOr2.json b/core/src/test/resources/org/elasticsearch/index/query/spanOr2.json
new file mode 100644
index 0000000..b64ce1c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/spanOr2.json
@@ -0,0 +1,30 @@
+{
+    "span_or":{
+        "clauses":[
+            {
+                "span_term":{
+                    "age":{
+                        "value":34,
+                        "boost":1.0
+                    }
+                }
+            },
+            {
+                "span_term":{
+                    "age":{
+                        "value":35,
+                        "boost":1.0
+                    }
+                }
+            },
+            {
+                "span_term":{
+                    "age":{
+                        "value":36,
+                        "boost":1.0
+                    }
+                }
+            }
+        ]
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/spanTerm.json b/core/src/test/resources/org/elasticsearch/index/query/spanTerm.json
new file mode 100644
index 0000000..0186593
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/spanTerm.json
@@ -0,0 +1,5 @@
+{
+    span_term:{
+        age:34
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/spanWithin.json b/core/src/test/resources/org/elasticsearch/index/query/spanWithin.json
new file mode 100644
index 0000000..7cf767c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/spanWithin.json
@@ -0,0 +1,14 @@
+{
+    span_within:{
+        big:{
+            span_term:{
+                age:34
+            }
+        },
+        little:{
+            span_term:{
+                age:35
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/starColonStar.json b/core/src/test/resources/org/elasticsearch/index/query/starColonStar.json
new file mode 100644
index 0000000..c769ca0
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/starColonStar.json
@@ -0,0 +1,5 @@
+{
+    "query_string": {
+        "query": "*:*"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/term-array-invalid.json b/core/src/test/resources/org/elasticsearch/index/query/term-array-invalid.json
new file mode 100644
index 0000000..a198bc2
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/term-array-invalid.json
@@ -0,0 +1,5 @@
+{
+    "term": {
+        "age": [34, 35]
+    }
+}
diff --git a/core/src/test/resources/org/elasticsearch/index/query/term-filter-broken-multi-terms-2.json b/core/src/test/resources/org/elasticsearch/index/query/term-filter-broken-multi-terms-2.json
new file mode 100644
index 0000000..b71de53
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/term-filter-broken-multi-terms-2.json
@@ -0,0 +1,10 @@
+{
+  "filtered": {
+    "filter": {
+      "term": {
+        "name.first": { "value": "shay" },
+        "name.last": { "value": "banon" }
+      }
+    }
+  }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/term-filter-broken-multi-terms.json b/core/src/test/resources/org/elasticsearch/index/query/term-filter-broken-multi-terms.json
new file mode 100644
index 0000000..aabd6e4
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/term-filter-broken-multi-terms.json
@@ -0,0 +1,10 @@
+{
+  "filtered":{
+    "query":{
+      "term":{
+        "name.first": "shay",
+        "name.last" : "banon"
+      }
+    }
+  }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/term-filter-named.json b/core/src/test/resources/org/elasticsearch/index/query/term-filter-named.json
new file mode 100644
index 0000000..c23b7b3
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/term-filter-named.json
@@ -0,0 +1,15 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "term":{
+                "name.last":"banon",
+                "_name":"test"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/term-filter.json b/core/src/test/resources/org/elasticsearch/index/query/term-filter.json
new file mode 100644
index 0000000..11d2bfd
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/term-filter.json
@@ -0,0 +1,14 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "term":{
+                "name.last":"banon"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/term-with-boost.json b/core/src/test/resources/org/elasticsearch/index/query/term-with-boost.json
new file mode 100644
index 0000000..5f33cd5
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/term-with-boost.json
@@ -0,0 +1,8 @@
+{
+    term:{
+        age:{
+            value:34,
+            boost:2.0
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/term.json b/core/src/test/resources/org/elasticsearch/index/query/term.json
new file mode 100644
index 0000000..378cf42
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/term.json
@@ -0,0 +1,5 @@
+{
+    term:{
+        age:34
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/terms-filter-named.json b/core/src/test/resources/org/elasticsearch/index/query/terms-filter-named.json
new file mode 100644
index 0000000..2cb8c7a
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/terms-filter-named.json
@@ -0,0 +1,15 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "terms":{
+                "name.last":["banon", "kimchy"],
+                "_name":"test"
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/terms-filter.json b/core/src/test/resources/org/elasticsearch/index/query/terms-filter.json
new file mode 100644
index 0000000..04a8d26
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/terms-filter.json
@@ -0,0 +1,14 @@
+{
+    "filtered":{
+        "query":{
+            "term":{
+                "name.first":"shay"
+            }
+        },
+        "filter":{
+            "terms":{
+                "name.last":["banon", "kimchy"]
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/terms-query-options.json b/core/src/test/resources/org/elasticsearch/index/query/terms-query-options.json
new file mode 100644
index 0000000..48263a5
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/terms-query-options.json
@@ -0,0 +1,8 @@
+{
+    "terms":{
+        "name.first":["shay", "test", "elasticsearch"],
+        "disable_coord":true,
+        "boost":2.0,
+        "min_should_match":2
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/terms-query.json b/core/src/test/resources/org/elasticsearch/index/query/terms-query.json
new file mode 100644
index 0000000..a3e0d08
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/terms-query.json
@@ -0,0 +1,5 @@
+{
+    "terms":{
+        "name.first":["shay", "test"]
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/wildcard-boost.json b/core/src/test/resources/org/elasticsearch/index/query/wildcard-boost.json
new file mode 100644
index 0000000..53c8d82
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/wildcard-boost.json
@@ -0,0 +1,8 @@
+{
+    "wildcard":{
+        "name.first":{
+            "value":"sh*",
+            "boost":1.2
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/index/query/wildcard.json b/core/src/test/resources/org/elasticsearch/index/query/wildcard.json
new file mode 100644
index 0000000..c8ed852
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/index/query/wildcard.json
@@ -0,0 +1,5 @@
+{
+    wildcard:{
+        "name.first":"sh*"
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/indices/template/template0.json b/core/src/test/resources/org/elasticsearch/indices/template/template0.json
new file mode 100644
index 0000000..af055fd
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/indices/template/template0.json
@@ -0,0 +1,11 @@
+{
+    "template" : "foo*",
+    "order" : 10,
+    "settings" : {
+        "index.number_of_shards": 10,
+        "index.number_of_replicas": 0
+    },
+    "aliases" : {
+        "{index}-alias" : {}
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/indices/template/template1.json b/core/src/test/resources/org/elasticsearch/indices/template/template1.json
new file mode 100644
index 0000000..030fb54
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/indices/template/template1.json
@@ -0,0 +1,11 @@
+{
+    "template" : "foo*",
+    "order" : 10,
+    "settings" : {
+        "number_of_shards": 10,
+        "number_of_replicas": 0
+    },
+    "aliases" : {
+        "{index}-alias" : {}
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/indices/template/template2.json b/core/src/test/resources/org/elasticsearch/indices/template/template2.json
new file mode 100644
index 0000000..d4a376c
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/indices/template/template2.json
@@ -0,0 +1,13 @@
+{
+    "template" : "foo*",
+    "order" : 10,
+    "settings" : {
+        "index" : {
+            "number_of_shards": 10,
+            "number_of_replicas": 0
+        }
+    },
+    "aliases" : {
+        "{index}-alias" : {}
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/indices/template/template3.json b/core/src/test/resources/org/elasticsearch/indices/template/template3.json
new file mode 100644
index 0000000..7231a6e
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/indices/template/template3.json
@@ -0,0 +1,13 @@
+{
+    "mytemplate" : {
+        "template" : "foo*",
+        "order" : 10,
+        "settings" : {
+            "index.number_of_shards": 10,
+            "index.number_of_replicas": 0
+        },
+        "aliases" : {
+            "{index}-alias" : {}
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/indices/template/template4.json b/core/src/test/resources/org/elasticsearch/indices/template/template4.json
new file mode 100644
index 0000000..52dcaa6
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/indices/template/template4.json
@@ -0,0 +1,13 @@
+{
+    "mytemplate" : {
+        "template" : "foo*",
+        "order" : 10,
+        "settings" : {
+            "number_of_shards": 10,
+            "number_of_replicas": 0
+        },
+        "aliases" : {
+            "{index}-alias" : {}
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/indices/template/template5.json b/core/src/test/resources/org/elasticsearch/indices/template/template5.json
new file mode 100644
index 0000000..803bec0
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/indices/template/template5.json
@@ -0,0 +1,15 @@
+{
+    "mytemplate" : {
+        "template" : "foo*",
+        "order" : 10,
+        "settings" : {
+            "index" : {
+                "number_of_shards": 10,
+                "number_of_replicas": 0
+            }
+        },
+        "aliases" : {
+            "{index}-alias" : {}
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/plugins/loading/classpath/es-plugin-test.properties b/core/src/test/resources/org/elasticsearch/plugins/loading/classpath/es-plugin-test.properties
new file mode 100644
index 0000000..f57bea5
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/plugins/loading/classpath/es-plugin-test.properties
@@ -0,0 +1,19 @@
+################################################################
+# Licensed to Elasticsearch under one or more contributor
+# license agreements. See the NOTICE file distributed with
+# this work for additional information regarding copyright
+# ownership. Elasticsearch licenses this file to you under
+# the Apache License, Version 2.0 (the "License"); you may
+# not use this file except in compliance  with the License.
+# You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+################################################################
+plugin=org.elasticsearch.plugins.loading.classpath.InClassPathPlugin
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/search/aggregations/bucket/agg-filter-with-empty-bool.json b/core/src/test/resources/org/elasticsearch/search/aggregations/bucket/agg-filter-with-empty-bool.json
new file mode 100644
index 0000000..f730b43
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/search/aggregations/bucket/agg-filter-with-empty-bool.json
@@ -0,0 +1,33 @@
+{
+  "aggs": {
+    "issue7240": {
+      "aggs": {
+        "terms": {
+          "terms": {
+            "field": "field"
+          }
+        }
+      },
+      "filter": {
+        "fquery": {
+          "query": {
+            "filtered": {
+              "query": {
+                "bool": {}
+              },
+              "filter": {
+                "fquery": {
+                  "query": {
+                    "query_string": {
+                      "query": "_type:apache"
+                    }
+                  }
+                }
+              }
+            }
+          }
+        }
+      }
+    }
+  }
+}
diff --git a/core/src/test/resources/org/elasticsearch/search/child/bool-query-with-empty-clauses.json b/core/src/test/resources/org/elasticsearch/search/child/bool-query-with-empty-clauses.json
new file mode 100644
index 0000000..844b591
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/search/child/bool-query-with-empty-clauses.json
@@ -0,0 +1,19 @@
+{
+"query": {
+  "filtered": {
+    "filter": {
+      "has_parent": {
+        "type": "foo",
+        "query": {
+          "bool": {
+            "must": [],
+            "must_not": [],
+            "should": []
+          }
+        }
+      },
+      "query": []
+    }
+  }
+}
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/search/morelikethis/items.json b/core/src/test/resources/org/elasticsearch/search/morelikethis/items.json
new file mode 100644
index 0000000..dc56fc3
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/search/morelikethis/items.json
@@ -0,0 +1,25 @@
+{
+    "docs" : [
+        {
+            "_index" : "test",
+            "_type" : "type",
+            "_id" : "1",
+            "_source" : false
+        },
+        {
+            "_index" : "test",
+            "_type" : "type",
+            "_id" : "2",
+            "_source" : ["field3", "field4"]
+        },
+        {
+            "_index" : "test",
+            "_type" : "type",
+            "_id" : "3",
+            "_source" : {
+                "include": ["user"],
+                "exclude": ["user.location"]
+            }
+        }
+    ]
+}
\ No newline at end of file
diff --git a/core/src/test/resources/org/elasticsearch/tribe/elasticsearch.yml b/core/src/test/resources/org/elasticsearch/tribe/elasticsearch.yml
new file mode 100644
index 0000000..89f4922
--- /dev/null
+++ b/core/src/test/resources/org/elasticsearch/tribe/elasticsearch.yml
@@ -0,0 +1,3 @@
+cluster.name: tribe_node_cluster
+tribe.t1.cluster.name: tribe1
+tribe.t2.cluster.name: tribe2
\ No newline at end of file
diff --git a/dev-tools/src/main/resources/forbidden/core-signatures.txt b/dev-tools/src/main/resources/forbidden/core-signatures.txt
index 8b343b5..975f6ba 100644
--- a/dev-tools/src/main/resources/forbidden/core-signatures.txt
+++ b/dev-tools/src/main/resources/forbidden/core-signatures.txt
@@ -91,3 +91,4 @@ com.google.common.base.Objects
 com.google.common.base.Predicate
 com.google.common.base.Predicates
 com.google.common.base.Strings
+com.google.common.base.Throwables
diff --git a/docs/reference/index-modules/allocation/filtering.asciidoc b/docs/reference/index-modules/allocation/filtering.asciidoc
index 99fd1dc..4c2b7f4 100644
--- a/docs/reference/index-modules/allocation/filtering.asciidoc
+++ b/docs/reference/index-modules/allocation/filtering.asciidoc
@@ -81,9 +81,11 @@ one set of nodes to another:
 These special attributes are also supported:
 
 [horizontal]
-`_name`::   Match nodes by node name
-`_ip`::     Match nodes by IP address (the IP address associated with the hostname)
-`_host`::   Match nodes by hostname
+`_name`::       Match nodes by node name
+`_host_ip`::    Match nodes by host IP address (IP associated with hostname)
+`_publish_ip`:: Match nodes by publish IP address
+`_ip`::         Match either `_host_ip` or `_publish_ip`
+`_host`::       Match nodes by hostname
 
 All attribute values can be specified with wildcards, eg:
 
diff --git a/docs/reference/mapping/types/geo-shape.asciidoc b/docs/reference/mapping/types/geo-shape.asciidoc
index 563d04d..d974847 100644
--- a/docs/reference/mapping/types/geo-shape.asciidoc
+++ b/docs/reference/mapping/types/geo-shape.asciidoc
@@ -62,6 +62,16 @@ outer ring vertices in counterclockwise order with inner ring(s) vertices (holes
 in clockwise order. Setting this parameter in the geo_shape mapping explicitly
 sets vertex order for the coordinate list of a geo_shape field but can be
 overridden in each individual GeoJSON document.
+
+|`points_only` |Setting this option to `true` (defaults to `false`) configures
+the `geo_shape` field type for point shapes only (NOTE: Multi-Points are not
+yet supported). This optimizes index and search performance for the `geohash` and
+`quadtree` when it is known that only points will be indexed. At present geo_shape
+queries can not be executed on `geo_point` field types. This option bridges the gap
+by improving point performance on a `geo_shape` field so that `geo_shape` queries are
+optimal on a point only field.
+
+
 |=======================================================================
 
 [float]
diff --git a/docs/reference/migration/migrate_2_0/java.asciidoc b/docs/reference/migration/migrate_2_0/java.asciidoc
index d5e9acf..9871df4 100644
--- a/docs/reference/migration/migrate_2_0/java.asciidoc
+++ b/docs/reference/migration/migrate_2_0/java.asciidoc
@@ -21,6 +21,17 @@ Settings settings = Settings.settingsBuilder()
 Client client = TransportClient.builder().settings(settings).build();
 --------------------------------------------------
 
+The transport client also no longer supports loading settings from config files.
+If you have have a config file, you can load into settings yourself before
+consturcting the transport client:
+
+[source,java]
+--------------------------------------------------
+Settings settings = Settings.settingsBuilder()
+        .loadFromPath(pathToYourSettingsFile).build();
+Client client = TransportClient.builder().settings(settings).build();
+--------------------------------------------------
+
 ==== Automatically thread client listeners
 
 Previously, the user had to set request listener threads to `true` when on the
@@ -78,3 +89,36 @@ WrapperQueryBuilder internally.
 
 The `TermsQueryBuilder#execution` method has been removed as it has no effect, it is ignored by the
  corresponding parser.
+
+==== ImmutableSettings removed
+
+Use `Settings.builder()` instead of `ImmutableSettings.builder()`.
+
+==== InetSocketTransportAddress removed
+
+Use `InetSocketTransportAddress(InetSocketAddress address)` instead of `InetSocketTransportAddress(String, int)`.
+You can create an InetSocketAddress instance with `InetSocketAddress(String, int)`. For example:
+
+[source,java]
+-----------------------------
+new InetSocketTransportAddress(new InetSocketAddress("127.0.0.1", 0));
+-----------------------------
+
+==== Shading and package relocation removed
+
+Elasticsearch used to shade its dependencies and to relocate packages. We no longer use shading or relocation.
+You might need to change your imports to the original package names:
+
+* `com.google.common` was `org.elasticsearch.common` 
+* `com.carrotsearch.hppc` was `org.elasticsearch.common.hppc`
+* `jsr166e` was `org.elasticsearch.common.util.concurrent.jsr166e`
+* `com.fasterxml.jackson` was `org.elasticsearch.common.jackson`
+* `org.joda.time` was `org.elasticsearch.common.joda.time`
+* `org.joda.convert` was `org.elasticsearch.common.joda.convert`
+* `org.jboss.netty` was `org.elasticsearch.common.netty`
+* `com.ning.compress` was `org.elasticsearch.common.compress`
+* `com.github.mustachejava` was `org.elasticsearch.common.mustache`
+* `com.tdunning.math.stats` was `org.elasticsearch.common.stats`
+* `org.apache.commons.lang` was `org.elasticsearch.common.lang`
+* `org.apache.commons.cli` was `org.elasticsearch.common.cli.commons`
+ 
diff --git a/docs/reference/migration/migrate_2_1.asciidoc b/docs/reference/migration/migrate_2_1.asciidoc
index a530fc1..f3008aa 100644
--- a/docs/reference/migration/migrate_2_1.asciidoc
+++ b/docs/reference/migration/migrate_2_1.asciidoc
@@ -41,4 +41,12 @@ thought of as a delete operation followed by an index operation.
 ==== `indices.fielddata.cache.expire`
 
 The experimental feature `indices.fielddata.cache.expire` has been removed.
-For indices that have this setting configured, this config will be ignored.
\ No newline at end of file
+For indices that have this setting configured, this config will be ignored.
+
+=== More Like This
+
+The MoreLikeThisQueryBuilder#ignoreLike methods have been deprecating in favor
+to using the unlike methods.
+
+MoreLikeThisBuilder#addItem has been deprecated in favor to using
+MoreLikeThisBuilder#addLikeItem.
\ No newline at end of file
diff --git a/docs/reference/migration/migrate_3_0.asciidoc b/docs/reference/migration/migrate_3_0.asciidoc
index 55f0ad4..a0c96da 100644
--- a/docs/reference/migration/migrate_3_0.asciidoc
+++ b/docs/reference/migration/migrate_3_0.asciidoc
@@ -63,3 +63,12 @@ Scroll requests sorted by `_doc` have been optimized to more efficiently resume
 from where the previous request stopped, so this will have the same performance
 characteristics as the former `scan` search type.
 
+=== Parent/Child changes
+
+The `children` aggregation, parent child inner hits and `has_child` and `has_parent` queries will not work on indices
+with `_parent` field mapping created before version `2.0.0`. The data of these indices need to be re-indexed into a new index.
+
+The format of the join between parent and child documents have changed with the `2.0.0` release. The old
+format can't read from version `3.0.0` and onwards. The new format allows for a much more efficient and
+scalable join between parent and child documents and the join data structures are stored on on disk
+data structures as opposed as before the join data structures were stored in the jvm heap space.
\ No newline at end of file
diff --git a/docs/reference/migration/migrate_query_refactoring.asciidoc b/docs/reference/migration/migrate_query_refactoring.asciidoc
deleted file mode 100644
index 3bac18f..0000000
--- a/docs/reference/migration/migrate_query_refactoring.asciidoc
+++ /dev/null
@@ -1,81 +0,0 @@
-[[breaking-changes query-refactoring]]
-== Breaking changes on the query-refactoring branch
-
-This section discusses changes that are breaking to the current rest or java-api
-on the query-refactoring feature branch.
-
-=== Plugins
-
-Plugins implementing custom queries need to implement the `fromXContent(QueryParseContext)` method in their
-`QueryParser` subclass rather than `parse`. This method will take care of parsing the query from `XContent` format
-into an intermediate query representation that can be streamed between the nodes in binary format, effectively the
-query object used in the java api. Also, the query parser needs to implement the `getBuilderPrototype` method that
-returns a prototype of the streamable query, which allows to deserialize an incoming query by calling
-`readFrom(StreamInput)` against it, which will create a new object, see usages of `Writeable`. The `QueryParser`
-also needs to declare the generic type of the query that it supports and it's able to parse.
-The query object can then transform itself into a lucene query through the new `toQuery(QueryShardContext)` method,
-which returns a lucene query to be executed on the data node. The query implementation also needs to implement the
-`validate` method that allows to validate the content of the query, no matter whether it came in through the java api
-directly or through the REST layer.
-
-=== Java-API
-
-==== BoostingQueryBuilder
-
-Removed setters for mandatory positive/negative query. Both arguments now have
-to be supplied at construction time already and have to be non-null.
-
-==== SpanContainingQueryBuilder
-
-Removed setters for mandatory big/little inner span queries. Both arguments now have
-to be supplied at construction time already and have to be non-null. Updated
-static factory methods in QueryBuilders accordingly.
-
-==== SpanNearQueryBuilder
-
-Removed setter for mandatory slop parameter, needs to be set in constructor now.
-Updated the static factory methods in QueryBuilders accordingly.
-
-==== SpanNotQueryBuilder
-
-Removed setter for mandatory include/exclude span query clause, needs to be set in constructor now.
-Updated the static factory methods in QueryBuilders and tests accordingly.
-
-==== SpanWithinQueryBuilder
-
-Removed setters for mandatory big/little inner span queries. Both arguments now have
-to be supplied at construction time already and have to be non-null. Updated
-static factory methods in QueryBuilders accordingly.
-
-==== QueryFilterBuilder
-
-Removed the setter `queryName(String queryName)` since this field is not supported
-in this type of query. Use `FQueryFilterBuilder.queryName(String queryName)` instead 
-when in need to wrap a named query as a filter.
-
-==== WrapperQueryBuilder
-
-Removed `wrapperQueryBuilder(byte[] source, int offset, int length)`. Instead simply
-use  `wrapperQueryBuilder(byte[] source)`. Updated the static factory methods in
-QueryBuilders accordingly.
-
-==== Operator
-
-Removed the enums called `Operator` from `MatchQueryBuilder`, `QueryStringQueryBuilder`,
-`SimpleQueryStringBuilder`, and `CommonTermsQueryBuilder` in favour of using the enum
-defined in `org.elasticsearch.index.query.Operator` in an effort to consolidate the
-codebase and avoid duplication.
-
-==== queryName and boost support
-
-Support for `queryName` and `boost` has been streamlined to all of the queries. That is
-a breaking change till queries get sent over the network as serialized json rather
-than in `Streamable` format. In fact whenever additional fields are added to the json
-representation of the query, older nodes might throw error when they find unknown fields.
-
-==== InnerHitsBuilder
-
-InnerHitsBuilder now has a dedicated addParentChildInnerHits and addNestedInnerHits methods
-to differentiate between inner hits for nested vs. parent / child documents. This change
-makes the type / path parameter mandatory.
-
diff --git a/docs/reference/query-dsl/has-parent-query.asciidoc b/docs/reference/query-dsl/has-parent-query.asciidoc
index 2b84811..70e9ba5 100644
--- a/docs/reference/query-dsl/has-parent-query.asciidoc
+++ b/docs/reference/query-dsl/has-parent-query.asciidoc
@@ -24,20 +24,21 @@ in the same manner as the `has_child` query.
 [float]
 ==== Scoring capabilities
 
-The `has_parent` also has scoring support. The default is `false` which
-ignores the score from the parent document. The score is in this
+The `has_parent` also has scoring support. The
+supported score types are `score` or `none`. The default is `none` and
+this ignores the score from the parent document. The score is in this
 case equal to the boost on the `has_parent` query (Defaults to 1). If
-the score is set to `true`, then the score of the matching parent
+the score type is set to `score`, then the score of the matching parent
 document is aggregated into the child documents belonging to the
 matching parent document. The score type can be specified with the
-`score` field inside the `has_parent` query:
+`score_mode` field inside the `has_parent` query:
 
 [source,js]
 --------------------------------------------------
 {
     "has_parent" : {
         "parent_type" : "blog",
-        "score" : true,
+        "score_mode" : "score",
         "query" : {
             "term" : {
                 "tag" : "something"
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats b/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats
index 38aa352..8f60521 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats
+++ b/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats
@@ -63,16 +63,10 @@ setup() {
     dpkg -s 'elasticsearch'
 }
 
-##################################
-# Check that the package is correctly installed
-##################################
 @test "[DEB] verify package installation" {
     verify_package_installation
 }
 
-##################################
-# Check that Elasticsearch is working
-##################################
 @test "[DEB] test elasticsearch" {
     start_elasticsearch_service
 
@@ -152,3 +146,24 @@ setup() {
     run dpkg -s 'elasticsearch'
     [ "$status" -eq 1 ]
 }
+
+@test "[DEB] reinstall package" {
+    dpkg -i elasticsearch-$(cat version).deb
+}
+
+@test "[DEB] package is installed by reinstall" {
+    dpkg -s 'elasticsearch'
+}
+
+@test "[DEB] verify package reinstallation" {
+    verify_package_installation
+}
+
+@test "[DEB] repurge package" {
+    dpkg --purge 'elasticsearch'
+}
+
+@test "[DEB] package has been completly removed again" {
+    run dpkg -s 'elasticsearch'
+    [ "$status" -eq 1 ]
+}
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats b/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats
index b5d8a7b..588fe38 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats
+++ b/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats
@@ -62,25 +62,16 @@ setup() {
     rpm -qe 'elasticsearch'
 }
 
-##################################
-# Check that the package is correctly installed
-##################################
 @test "[RPM] verify package installation" {
     verify_package_installation
 }
 
-##################################
-# Check that Elasticsearch is working
-##################################
 @test "[RPM] test elasticsearch" {
     start_elasticsearch_service
 
     run_elasticsearch_tests
 }
 
-##################################
-# Uninstall RPM package
-##################################
 @test "[RPM] remove package" {
     rpm -e 'elasticsearch'
 }
@@ -117,3 +108,25 @@ setup() {
 
     assert_file_not_exist "/etc/sysconfig/elasticsearch"
 }
+
+
+@test "[RPM] reinstall package" {
+    rpm -i elasticsearch-$(cat version).rpm
+}
+
+@test "[RPM] package is installed by reinstall" {
+    rpm -qe 'elasticsearch'
+}
+
+@test "[RPM] verify package reinstallation" {
+    verify_package_installation
+}
+
+@test "[RPM] reremove package" {
+    rpm -e 'elasticsearch'
+}
+
+@test "[RPM] package has been removed again" {
+    run rpm -qe 'elasticsearch'
+    [ "$status" -eq 1 ]
+}

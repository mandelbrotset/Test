diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/get/GetIndexResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/get/GetIndexResponse.java
index f0cc490..0930f8f 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/get/GetIndexResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/get/GetIndexResponse.java
@@ -28,7 +28,6 @@ import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.search.warmer.IndexWarmersMetaData;
 
 import java.io.IOException;
@@ -123,7 +122,7 @@ public class GetIndexResponse extends ActionResponse {
                         in.readString(),
                         in.readStringArray(),
                         in.readOptionalBoolean(),
-                        SearchSourceBuilder.PROTOTYPE.readFrom(in))
+                        in.readBytesReference())
                 );
             }
             warmersMapBuilder.put(key, Collections.unmodifiableList(warmerEntryBuilder));
@@ -174,7 +173,7 @@ public class GetIndexResponse extends ActionResponse {
                 out.writeString(warmerEntry.name());
                 out.writeStringArray(warmerEntry.types());
                 out.writeOptionalBoolean(warmerEntry.requestCache());
-                warmerEntry.source().writeTo(out);
+                out.writeBytesReference(warmerEntry.source());
             }
         }
         out.writeVInt(mappings.size());
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/get/GetWarmersResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/get/GetWarmersResponse.java
index 45040da..3ed444c 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/get/GetWarmersResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/get/GetWarmersResponse.java
@@ -20,12 +20,12 @@
 package org.elasticsearch.action.admin.indices.warmer.get;
 
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
+import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionResponse;
+import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.search.warmer.IndexWarmersMetaData;
 
 import java.io.IOException;
@@ -69,7 +69,7 @@ public class GetWarmersResponse extends ActionResponse {
             for (int j = 0; j < valueSize; j++) {
                 String name = in.readString();
                 String[] types = in.readStringArray();
-                SearchSourceBuilder source = SearchSourceBuilder.PROTOTYPE.readFrom(in);
+                BytesReference source = in.readBytesReference();
                 Boolean queryCache = null;
                 queryCache = in.readOptionalBoolean();
                 warmerEntryBuilder.add(new IndexWarmersMetaData.Entry(
@@ -94,7 +94,7 @@ public class GetWarmersResponse extends ActionResponse {
             for (IndexWarmersMetaData.Entry warmerEntry : indexEntry.value) {
                 out.writeString(warmerEntry.name());
                 out.writeStringArray(warmerEntry.types());
-                warmerEntry.source().writeTo(out);
+                out.writeBytesReference(warmerEntry.source());
                 out.writeOptionalBoolean(warmerEntry.requestCache());
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/put/TransportPutWarmerAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/put/TransportPutWarmerAction.java
index 883b429..18246f6 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/put/TransportPutWarmerAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/put/TransportPutWarmerAction.java
@@ -38,7 +38,6 @@ import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.IndexNotFoundException;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.search.warmer.IndexWarmersMetaData;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
@@ -115,9 +114,11 @@ public class TransportPutWarmerAction extends TransportMasterNodeAction<PutWarme
                         MetaData metaData = currentState.metaData();
                         String[] concreteIndices = indexNameExpressionResolver.concreteIndices(currentState, request.searchRequest().indicesOptions(), request.searchRequest().indices());
 
-                        SearchSourceBuilder source = null;
-                        if (request.searchRequest().source() != null) {
+                        BytesReference source = null;
+                        if (request.searchRequest().source() != null && request.searchRequest().source().length() > 0) {
                             source = request.searchRequest().source();
+                        } else if (request.searchRequest().extraSource() != null && request.searchRequest().extraSource().length() > 0) {
+                            source = request.searchRequest().extraSource();
                         }
 
                         // now replace it on the metadata
diff --git a/core/src/main/java/org/elasticsearch/action/count/CountRequest.java b/core/src/main/java/org/elasticsearch/action/count/CountRequest.java
index 80c03e6..05e193a 100644
--- a/core/src/main/java/org/elasticsearch/action/count/CountRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/count/CountRequest.java
@@ -33,7 +33,6 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.search.builder.SearchSourceBuilder;
 
 import java.io.IOException;
@@ -45,6 +44,9 @@ import static org.elasticsearch.search.internal.SearchContext.DEFAULT_TERMINATE_
 /**
  * A request to count the number of documents matching a specific query. Best created with
  * {@link org.elasticsearch.client.Requests#countRequest(String...)}.
+ * <p>
+ * The request requires the query source to be set either using {@link #source(QuerySourceBuilder)},
+ * or {@link #source(byte[])}.
  *
  * @see CountResponse
  * @see org.elasticsearch.client.Client#count(CountRequest)
@@ -62,12 +64,12 @@ public class CountRequest extends BroadcastRequest<CountRequest> {
     @Nullable
     private String preference;
 
+    private BytesReference source;
+
     private String[] types = Strings.EMPTY_ARRAY;
 
     private int terminateAfter = DEFAULT_TERMINATE_AFTER;
 
-    private SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
-
     /**
      * Constructs a new count request against the provided indices. No indices provided means it will
      * run against all indices.
@@ -92,21 +94,67 @@ public class CountRequest extends BroadcastRequest<CountRequest> {
         return this;
     }
 
+    /**
+     * The source to execute.
+     */
+    public BytesReference source() {
+        return source;
+    }
 
     /**
-     * The query to execute
+     * The source to execute.
      */
-    public CountRequest query(QueryBuilder queryBuilder) {
-        this.searchSourceBuilder = new SearchSourceBuilder().query(queryBuilder);
+    public CountRequest source(QuerySourceBuilder sourceBuilder) {
+        this.source = sourceBuilder.buildAsBytes(Requests.CONTENT_TYPE);
         return this;
     }
 
-    public CountRequest searchSource(SearchSourceBuilder searchSourceBuilder) {
-        this.searchSourceBuilder = searchSourceBuilder;
+    /**
+     * The source to execute in the form of a map.
+     */
+    @SuppressWarnings("unchecked")
+    public CountRequest source(Map querySource) {
+        try {
+            XContentBuilder builder = XContentFactory.contentBuilder(Requests.CONTENT_TYPE);
+            builder.map(querySource);
+            return source(builder);
+        } catch (IOException e) {
+            throw new ElasticsearchGenerationException("Failed to generate [" + querySource + "]", e);
+        }
+    }
+
+    public CountRequest source(XContentBuilder builder) {
+        this.source = builder.bytes();
         return this;
     }
 
+    /**
+     * The source to execute. It is preferable to use either {@link #source(byte[])}
+     * or {@link #source(QuerySourceBuilder)}.
+     */
+    public CountRequest source(String querySource) {
+        this.source = new BytesArray(querySource);
+        return this;
+    }
 
+    /**
+     * The source to execute.
+     */
+    public CountRequest source(byte[] querySource) {
+        return source(querySource, 0, querySource.length);
+    }
+
+    /**
+     * The source to execute.
+     */
+    public CountRequest source(byte[] querySource, int offset, int length) {
+        return source(new BytesArray(querySource, offset, length));
+    }
+
+    public CountRequest source(BytesReference querySource) {
+        this.source = querySource;
+        return this;
+    }
 
     /**
      * The types of documents the query will run against. Defaults to all types.
@@ -184,7 +232,7 @@ public class CountRequest extends BroadcastRequest<CountRequest> {
     public String toString() {
         String sSource = "_na_";
         try {
-            sSource = XContentHelper.toString(searchSourceBuilder);
+            sSource = XContentHelper.convertToJson(source, false);
         } catch (Exception e) {
             // ignore
         }
@@ -192,6 +240,13 @@ public class CountRequest extends BroadcastRequest<CountRequest> {
     }
 
     public SearchRequest toSearchRequest() {
+        SearchRequest searchRequest = new SearchRequest(indices());
+        searchRequest.indicesOptions(indicesOptions());
+        searchRequest.types(types());
+        searchRequest.routing(routing());
+        searchRequest.preference(preference());
+        searchRequest.source(source());
+        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
         searchSourceBuilder.size(0);
         if (minScore() != DEFAULT_MIN_SCORE) {
             searchSourceBuilder.minScore(minScore());
@@ -199,16 +254,7 @@ public class CountRequest extends BroadcastRequest<CountRequest> {
         if (terminateAfter() != DEFAULT_TERMINATE_AFTER) {
             searchSourceBuilder.terminateAfter(terminateAfter());
         }
-        SearchRequest searchRequest = new SearchRequest(indices());
-        searchRequest.source(searchSourceBuilder);
-        searchRequest.indicesOptions(indicesOptions());
-        searchRequest.types(types());
-        searchRequest.routing(routing());
-        searchRequest.preference(preference());
+        searchRequest.extraSource(searchSourceBuilder);
         return searchRequest;
     }
-
-    SearchSourceBuilder sourceBuilder() {
-        return searchSourceBuilder;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/action/count/CountRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/count/CountRequestBuilder.java
index 068e197..54c60e5 100644
--- a/core/src/main/java/org/elasticsearch/action/count/CountRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/count/CountRequestBuilder.java
@@ -31,13 +31,14 @@ import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 
 /**
  * A count action request builder.
  */
 public class CountRequestBuilder extends BroadcastOperationRequestBuilder<CountRequest, CountResponse, CountRequestBuilder> {
 
+    private QuerySourceBuilder sourceBuilder;
+
     public CountRequestBuilder(ElasticsearchClient client, CountAction action) {
         super(client, action, new CountRequest());
     }
@@ -87,18 +88,44 @@ public class CountRequestBuilder extends BroadcastOperationRequestBuilder<CountR
     }
 
     /**
+     * The query source to execute.
+     *
+     * @see org.elasticsearch.index.query.QueryBuilders
+     */
+    public CountRequestBuilder setQuery(QueryBuilder queryBuilder) {
+        sourceBuilder().setQuery(queryBuilder);
+        return this;
+    }
+
+    /**
+     * The query binary to execute
+     */
+    public CountRequestBuilder setQuery(BytesReference queryBinary) {
+        sourceBuilder().setQuery(queryBinary);
+        return this;
+    }
+
+    /**
+     * Constructs a new builder with a raw search query.
+     */
+    public CountRequestBuilder setQuery(XContentBuilder query) {
+        return setQuery(query.bytes());
+    }
+
+
+    /**
      * The source to execute.
      */
-    public CountRequestBuilder setSource(SearchSourceBuilder source) {
-        request().searchSource(source);
+    public CountRequestBuilder setSource(BytesReference source) {
+        request().source(source);
         return this;
     }
 
     /**
      * The query source to execute.
      */
-    public CountRequestBuilder setQuery(QueryBuilder<?> builder) {
-        request.query(builder);
+    public CountRequestBuilder setSource(byte[] querySource) {
+        request.source(querySource);
         return this;
     }
 
@@ -108,6 +135,21 @@ public class CountRequestBuilder extends BroadcastOperationRequestBuilder<CountR
     }
 
     @Override
+    protected CountRequest beforeExecute(CountRequest request) {
+        if (sourceBuilder != null) {
+            request.source(sourceBuilder);
+        }
+        return request;
+    }
+
+    private QuerySourceBuilder sourceBuilder() {
+        if (sourceBuilder == null) {
+            sourceBuilder = new QuerySourceBuilder();
+        }
+        return sourceBuilder;
+    }
+
+    @Override
     public void execute(ActionListener<CountResponse> listener) {
         CountRequest countRequest = beforeExecute(request);
         client.execute(SearchAction.INSTANCE, countRequest.toSearchRequest(), new DelegatingActionListener<SearchResponse, CountResponse>(listener) {
@@ -120,8 +162,15 @@ public class CountRequestBuilder extends BroadcastOperationRequestBuilder<CountR
 
     @Override
     public String toString() {
-        if (request.sourceBuilder() != null) {
-            return request.sourceBuilder().toString();
+        if (sourceBuilder != null) {
+            return sourceBuilder.toString();
+        }
+        if (request.source() != null) {
+            try {
+                return XContentHelper.convertToJson(request.source().toBytesArray(), false, true);
+            } catch (Exception e) {
+                return "{ \"error\" : \"" + ExceptionsHelper.detailedMessage(e) + "\"}";
+            }
         }
         return new QuerySourceBuilder().toString();
     }
diff --git a/core/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java b/core/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java
index a3236e9..d754d96 100644
--- a/core/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/search/MultiSearchRequest.java
@@ -24,14 +24,22 @@ import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.CompositeIndicesRequest;
 import org.elasticsearch.action.IndicesRequest;
 import org.elasticsearch.action.support.IndicesOptions;
+import org.elasticsearch.common.Nullable;
+import org.elasticsearch.common.bytes.BytesArray;
+import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.xcontent.XContent;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 
 import static org.elasticsearch.action.ValidateActions.addValidationError;
+import static org.elasticsearch.common.xcontent.support.XContentMapValues.*;
 
 /**
  * A multi search API request.
@@ -60,6 +68,107 @@ public class MultiSearchRequest extends ActionRequest<MultiSearchRequest> implem
         return this;
     }
 
+    public MultiSearchRequest add(byte[] data, int from, int length,
+            boolean isTemplateRequest, @Nullable String[] indices, @Nullable String[] types, @Nullable String searchType) throws Exception {
+        return add(new BytesArray(data, from, length), isTemplateRequest, indices, types, searchType, null, IndicesOptions.strictExpandOpenAndForbidClosed(), true);
+    }
+
+    public MultiSearchRequest add(BytesReference data, boolean isTemplateRequest, @Nullable String[] indices, @Nullable String[] types, @Nullable String searchType, IndicesOptions indicesOptions) throws Exception {
+        return add(data, isTemplateRequest, indices, types, searchType, null, indicesOptions, true);
+    }
+
+    public MultiSearchRequest add(BytesReference data, boolean isTemplateRequest, @Nullable String[] indices, @Nullable String[] types, @Nullable String searchType, @Nullable String routing, IndicesOptions indicesOptions, boolean allowExplicitIndex) throws Exception {
+        XContent xContent = XContentFactory.xContent(data);
+        int from = 0;
+        int length = data.length();
+        byte marker = xContent.streamSeparator();
+        while (true) {
+            int nextMarker = findNextMarker(marker, from, data, length);
+            if (nextMarker == -1) {
+                break;
+            }
+            // support first line with \n
+            if (nextMarker == 0) {
+                from = nextMarker + 1;
+                continue;
+            }
+
+            SearchRequest searchRequest = new SearchRequest();
+            if (indices != null) {
+                searchRequest.indices(indices);
+            }
+            if (indicesOptions != null) {
+                searchRequest.indicesOptions(indicesOptions);
+            }
+            if (types != null && types.length > 0) {
+                searchRequest.types(types);
+            }
+            if (routing != null) {
+                searchRequest.routing(routing);
+            }
+            searchRequest.searchType(searchType);
+
+            IndicesOptions defaultOptions = IndicesOptions.strictExpandOpenAndForbidClosed();
+
+
+            // now parse the action
+            if (nextMarker - from > 0) {
+                try (XContentParser parser = xContent.createParser(data.slice(from, nextMarker - from))) {
+                    Map<String, Object> source = parser.map();
+                    for (Map.Entry<String, Object> entry : source.entrySet()) {
+                        Object value = entry.getValue();
+                        if ("index".equals(entry.getKey()) || "indices".equals(entry.getKey())) {
+                            if (!allowExplicitIndex) {
+                                throw new IllegalArgumentException("explicit index in multi percolate is not allowed");
+                            }
+                            searchRequest.indices(nodeStringArrayValue(value));
+                        } else if ("type".equals(entry.getKey()) || "types".equals(entry.getKey())) {
+                            searchRequest.types(nodeStringArrayValue(value));
+                        } else if ("search_type".equals(entry.getKey()) || "searchType".equals(entry.getKey())) {
+                            searchRequest.searchType(nodeStringValue(value, null));
+                        } else if ("request_cache".equals(entry.getKey()) || "requestCache".equals(entry.getKey())) {
+                            searchRequest.requestCache(nodeBooleanValue(value));
+                        } else if ("preference".equals(entry.getKey())) {
+                            searchRequest.preference(nodeStringValue(value, null));
+                        } else if ("routing".equals(entry.getKey())) {
+                            searchRequest.routing(nodeStringValue(value, null));
+                        }
+                    }
+                    defaultOptions = IndicesOptions.fromMap(source, defaultOptions);
+                }
+            }
+            searchRequest.indicesOptions(defaultOptions);
+
+            // move pointers
+            from = nextMarker + 1;
+            // now for the body
+            nextMarker = findNextMarker(marker, from, data, length);
+            if (nextMarker == -1) {
+                break;
+            }
+            if (isTemplateRequest) {
+                searchRequest.templateSource(data.slice(from,  nextMarker - from));
+            } else {
+                searchRequest.source(data.slice(from, nextMarker - from));
+            }
+            // move pointers
+            from = nextMarker + 1;
+
+            add(searchRequest);
+        }
+
+        return this;
+    }
+
+    private int findNextMarker(byte marker, int from, BytesReference data, int length) {
+        for (int i = from; i < length; i++) {
+            if (data.get(i) == marker) {
+                return i;
+            }
+        }
+        return -1;
+    }
+
     public List<SearchRequest> requests() {
         return this.requests;
     }
diff --git a/core/src/main/java/org/elasticsearch/action/search/SearchRequest.java b/core/src/main/java/org/elasticsearch/action/search/SearchRequest.java
index 538fb05..9348185 100644
--- a/core/src/main/java/org/elasticsearch/action/search/SearchRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/search/SearchRequest.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.action.search;
 
+import org.elasticsearch.ElasticsearchGenerationException;
 import org.elasticsearch.action.ActionRequest;
 import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.IndicesRequest;
@@ -32,11 +33,17 @@ import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.script.ScriptService;
+import org.elasticsearch.script.ScriptService.ScriptType;
 import org.elasticsearch.script.Template;
+import org.elasticsearch.script.mustache.MustacheScriptEngineService;
 import org.elasticsearch.search.Scroll;
 import org.elasticsearch.search.builder.SearchSourceBuilder;
 
 import java.io.IOException;
+import java.util.Map;
 
 import static org.elasticsearch.search.Scroll.readScroll;
 
@@ -46,7 +53,9 @@ import static org.elasticsearch.search.Scroll.readScroll;
  * <p>
  * Note, the search {@link #source(org.elasticsearch.search.builder.SearchSourceBuilder)}
  * is required. The search source is the different search options, including aggregations and such.
- * </p>
+ * <p>
+ * There is an option to specify an addition search source using the {@link #extraSource(org.elasticsearch.search.builder.SearchSourceBuilder)}.
+ *
  * @see org.elasticsearch.client.Requests#searchRequest(String...)
  * @see org.elasticsearch.client.Client#search(SearchRequest)
  * @see SearchResponse
@@ -62,8 +71,12 @@ public class SearchRequest extends ActionRequest<SearchRequest> implements Indic
     @Nullable
     private String preference;
 
-    private SearchSourceBuilder source;
+    private BytesReference templateSource;
+    private Template template;
 
+    private BytesReference source;
+
+    private BytesReference extraSource;
     private Boolean requestCache;
 
     private Scroll scroll;
@@ -74,8 +87,6 @@ public class SearchRequest extends ActionRequest<SearchRequest> implements Indic
 
     private IndicesOptions indicesOptions = DEFAULT_INDICES_OPTIONS;
 
-    private Template template;
-
     public SearchRequest() {
     }
 
@@ -89,8 +100,10 @@ public class SearchRequest extends ActionRequest<SearchRequest> implements Indic
         this.indices = searchRequest.indices;
         this.routing = searchRequest.routing;
         this.preference = searchRequest.preference;
+        this.templateSource = searchRequest.templateSource;
         this.template = searchRequest.template;
         this.source = searchRequest.source;
+        this.extraSource = searchRequest.extraSource;
         this.requestCache = searchRequest.requestCache;
         this.scroll = searchRequest.scroll;
         this.types = searchRequest.types;
@@ -116,9 +129,9 @@ public class SearchRequest extends ActionRequest<SearchRequest> implements Indic
     /**
      * Constructs a new search request against the provided indices with the given search source.
      */
-    public SearchRequest(String[] indices, SearchSourceBuilder source) {
+    public SearchRequest(String[] indices, byte[] source) {
         indices(indices);
-        this.source = source;
+        this.source = new BytesArray(source);
     }
 
     @Override
@@ -234,17 +247,60 @@ public class SearchRequest extends ActionRequest<SearchRequest> implements Indic
      * The source of the search request.
      */
     public SearchRequest source(SearchSourceBuilder sourceBuilder) {
-        this.source = sourceBuilder;
+        this.source = sourceBuilder.buildAsBytes(Requests.CONTENT_TYPE);
+        return this;
+    }
+
+    /**
+     * The search source to execute.
+     */
+    public SearchRequest source(BytesReference source) {
+        this.source = source;
         return this;
     }
 
+
     /**
      * The search source to execute.
      */
-    public SearchSourceBuilder source() {
+    public BytesReference source() {
         return source;
     }
 
+    /**
+     * The search source template to execute.
+     */
+    public BytesReference templateSource() {
+        return templateSource;
+    }
+
+    /**
+     * Allows to provide additional source that will be used as well.
+     */
+    public SearchRequest extraSource(SearchSourceBuilder sourceBuilder) {
+        if (sourceBuilder == null) {
+            extraSource = null;
+            return this;
+        }
+        this.extraSource = sourceBuilder.buildAsBytes(Requests.CONTENT_TYPE);
+        return this;
+    }
+
+    /**
+     * Allows to provide template as source.
+     */
+    public SearchRequest templateSource(BytesReference template) {
+        this.templateSource = template;
+        return this;
+    }
+
+    /**
+     * The template of the search request.
+     */
+    public SearchRequest templateSource(String template) {
+        this.templateSource = new BytesArray(template);
+        return this;
+    }
 
     /**
      * The stored template
@@ -261,6 +317,88 @@ public class SearchRequest extends ActionRequest<SearchRequest> implements Indic
     }
 
     /**
+     * The name of the stored template
+     * 
+     * @deprecated use {@link #template(Template)} instead.
+     */
+    @Deprecated
+    public void templateName(String templateName) {
+        updateOrCreateScript(templateName, null, null, null);
+    }
+
+    /**
+     * The type of the stored template
+     * 
+     * @deprecated use {@link #template(Template)} instead.
+     */
+    @Deprecated
+    public void templateType(ScriptService.ScriptType templateType) {
+        updateOrCreateScript(null, templateType, null, null);
+    }
+
+    /**
+     * Template parameters used for rendering
+     * 
+     * @deprecated use {@link #template(Template)} instead.
+     */
+    @Deprecated
+    public void templateParams(Map<String, Object> params) {
+        updateOrCreateScript(null, null, null, params);
+    }
+
+    /**
+     * The name of the stored template
+     * 
+     * @deprecated use {@link #template()} instead.
+     */
+    @Deprecated
+    public String templateName() {
+        return template == null ? null : template.getScript();
+    }
+
+    /**
+     * The name of the stored template
+     * 
+     * @deprecated use {@link #template()} instead.
+     */
+    @Deprecated
+    public ScriptService.ScriptType templateType() {
+        return template == null ? null : template.getType();
+    }
+
+    /**
+     * Template parameters used for rendering
+     * 
+     * @deprecated use {@link #template()} instead.
+     */
+    @Deprecated
+    public Map<String, Object> templateParams() {
+        return template == null ? null : template.getParams();
+    }
+
+    private void updateOrCreateScript(String templateContent, ScriptType type, String lang, Map<String, Object> params) {
+        Template template = template();
+        if (template == null) {
+            template = new Template(templateContent == null ? "" : templateContent, type == null ? ScriptType.INLINE : type, lang, null,
+                    params);
+        } else {
+            String newTemplateContent = templateContent == null ? template.getScript() : templateContent;
+            ScriptType newTemplateType = type == null ? template.getType() : type;
+            String newTemplateLang = lang == null ? template.getLang() : lang;
+            Map<String, Object> newTemplateParams = params == null ? template.getParams() : params;
+            template = new Template(newTemplateContent, newTemplateType, MustacheScriptEngineService.NAME, null, newTemplateParams);
+        }
+        template(template);
+    }
+
+    /**
+     * Additional search source to execute.
+     */
+    public BytesReference extraSource() {
+        return this.extraSource;
+    }
+
+    /**
      * The tye of search to execute.
      */
     public SearchType searchType() {
@@ -335,13 +473,17 @@ public class SearchRequest extends ActionRequest<SearchRequest> implements Indic
             scroll = readScroll(in);
         }
 
-        source = SearchSourceBuilder.PROTOTYPE.readFrom(in);
+        source = in.readBytesReference();
+        extraSource = in.readBytesReference();
 
         types = in.readStringArray();
         indicesOptions = IndicesOptions.readIndicesOptions(in);
 
+        templateSource = in.readBytesReference();
+        if (in.readBoolean()) {
+            template = Template.readTemplate(in);
+        }
         requestCache = in.readOptionalBoolean();
-        template = in.readOptionalStreamable(new Template());
     }
 
     @Override
@@ -363,10 +505,18 @@ public class SearchRequest extends ActionRequest<SearchRequest> implements Indic
             out.writeBoolean(true);
             scroll.writeTo(out);
         }
-        source.writeTo(out);
+        out.writeBytesReference(source);
+        out.writeBytesReference(extraSource);
         out.writeStringArray(types);
         indicesOptions.writeIndicesOptions(out);
+
+        out.writeBytesReference(templateSource);
+        boolean hasTemplate = template != null;
+        out.writeBoolean(hasTemplate);
+        if (hasTemplate) {
+            template.writeTo(out);
+        }
+
         out.writeOptionalBoolean(requestCache);
-        out.writeOptionalStreamable(template);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java
index 75392c7..a570080 100644
--- a/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/search/SearchRequestBuilder.java
@@ -26,9 +26,11 @@ import org.elasticsearch.client.ElasticsearchClient;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.script.Script;
+import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.script.Template;
 import org.elasticsearch.search.Scroll;
 import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;
@@ -40,7 +42,7 @@ import org.elasticsearch.search.sort.SortBuilder;
 import org.elasticsearch.search.sort.SortOrder;
 import org.elasticsearch.search.suggest.SuggestBuilder;
 
-import java.util.Arrays;
+import java.util.Map;
 
 /**
  * A search action request builder.
@@ -121,6 +123,14 @@ public class SearchRequestBuilder extends ActionRequestBuilder<SearchRequest, Se
     }
 
     /**
+     * An optional timeout to control how long search is allowed to take.
+     */
+    public SearchRequestBuilder setTimeout(String timeout) {
+        sourceBuilder().timeout(timeout);
+        return this;
+    }
+
+    /**
      * An optional document count, upon collecting which the search
      * query will early terminate
      */
@@ -170,16 +180,118 @@ public class SearchRequestBuilder extends ActionRequestBuilder<SearchRequest, Se
      *
      * @see org.elasticsearch.index.query.QueryBuilders
      */
-    public SearchRequestBuilder setQuery(QueryBuilder<?> queryBuilder) {
+    public SearchRequestBuilder setQuery(QueryBuilder queryBuilder) {
         sourceBuilder().query(queryBuilder);
         return this;
     }
 
     /**
+     * Constructs a new search source builder with a raw search query.
+     */
+    public SearchRequestBuilder setQuery(String query) {
+        sourceBuilder().query(query);
+        return this;
+    }
+
+    /**
+     * Constructs a new search source builder with a raw search query.
+     */
+    public SearchRequestBuilder setQuery(BytesReference queryBinary) {
+        sourceBuilder().query(queryBinary);
+        return this;
+    }
+
+    /**
+     * Constructs a new search source builder with a raw search query.
+     */
+    public SearchRequestBuilder setQuery(byte[] queryBinary) {
+        sourceBuilder().query(queryBinary);
+        return this;
+    }
+
+    /**
+     * Constructs a new search source builder with a raw search query.
+     */
+    public SearchRequestBuilder setQuery(byte[] queryBinary, int queryBinaryOffset, int queryBinaryLength) {
+        sourceBuilder().query(queryBinary, queryBinaryOffset, queryBinaryLength);
+        return this;
+    }
+
+    /**
+     * Constructs a new search source builder with a raw search query.
+     */
+    public SearchRequestBuilder setQuery(XContentBuilder query) {
+        sourceBuilder().query(query);
+        return this;
+    }
+
+    /**
+     * Constructs a new search source builder with a raw search query.
+     */
+    public SearchRequestBuilder setQuery(Map query) {
+        sourceBuilder().query(query);
+        return this;
+    }
+
+    /**
      * Sets a filter that will be executed after the query has been executed and only has affect on the search hits
      * (not aggregations). This filter is always executed as last filtering mechanism.
      */
-    public SearchRequestBuilder setPostFilter(QueryBuilder<?> postFilter) {
+    public SearchRequestBuilder setPostFilter(QueryBuilder postFilter) {
+        sourceBuilder().postFilter(postFilter);
+        return this;
+    }
+
+    /**
+     * Sets a filter on the query executed that only applies to the search query
+     * (and not aggs for example).
+     */
+    public SearchRequestBuilder setPostFilter(String postFilter) {
+        sourceBuilder().postFilter(postFilter);
+        return this;
+    }
+
+    /**
+     * Sets a filter on the query executed that only applies to the search query
+     * (and not aggs for example).
+     */
+    public SearchRequestBuilder setPostFilter(BytesReference postFilter) {
+        sourceBuilder().postFilter(postFilter);
+        return this;
+    }
+
+    /**
+     * Sets a filter on the query executed that only applies to the search query
+     * (and not aggs for example).
+     */
+    public SearchRequestBuilder setPostFilter(byte[] postFilter) {
+        sourceBuilder().postFilter(postFilter);
+        return this;
+    }
+
+    /**
+     * Sets a filter on the query executed that only applies to the search query
+     * (and not aggs for example).
+     */
+    public SearchRequestBuilder setPostFilter(byte[] postFilter, int postFilterOffset, int postFilterLength) {
+        sourceBuilder().postFilter(postFilter, postFilterOffset, postFilterLength);
+        return this;
+    }
+
+    /**
+     * Sets a filter on the query executed that only applies to the search query
+     * (and not aggs for example).
+     */
+    public SearchRequestBuilder setPostFilter(XContentBuilder postFilter) {
+        sourceBuilder().postFilter(postFilter);
+        return this;
+    }
+
+    /**
+     * Sets a filter on the query executed that only applies to the search query
+     * (and not aggs for example).
+     */
+    public SearchRequestBuilder setPostFilter(Map postFilter) {
         sourceBuilder().postFilter(postFilter);
         return this;
     }
@@ -353,7 +465,7 @@ public class SearchRequestBuilder extends ActionRequestBuilder<SearchRequest, Se
      * the source of the document will be returned.
      */
     public SearchRequestBuilder addFields(String... fields) {
-        sourceBuilder().fields(Arrays.asList(fields));
+        sourceBuilder().fields(fields);
         return this;
     }
 
@@ -365,23 +477,267 @@ public class SearchRequestBuilder extends ActionRequestBuilder<SearchRequest, Se
         return this;
     }
 
-    public SearchRequestBuilder highlighter(HighlightBuilder highlightBuilder) {
-        sourceBuilder().highlighter(highlightBuilder);
+    /**
+     * Sets a raw (xcontent) binary representation of addAggregation to use.
+     */
+    public SearchRequestBuilder setAggregations(BytesReference aggregations) {
+        sourceBuilder().aggregations(aggregations);
+        return this;
+    }
+
+    /**
+     * Sets a raw (xcontent) binary representation of addAggregation to use.
+     */
+    public SearchRequestBuilder setAggregations(byte[] aggregations) {
+        sourceBuilder().aggregations(aggregations);
+        return this;
+    }
+
+    /**
+     * Sets a raw (xcontent) binary representation of addAggregation to use.
+     */
+    public SearchRequestBuilder setAggregations(byte[] aggregations, int aggregationsOffset, int aggregationsLength) {
+        sourceBuilder().aggregations(aggregations, aggregationsOffset, aggregationsLength);
+        return this;
+    }
+
+    /**
+     * Sets a raw (xcontent) binary representation of addAggregation to use.
+     */
+    public SearchRequestBuilder setAggregations(XContentBuilder aggregations) {
+        sourceBuilder().aggregations(aggregations);
+        return this;
+    }
+
+    /**
+     * Sets a raw (xcontent) binary representation of addAggregation to use.
+     */
+    public SearchRequestBuilder setAggregations(Map aggregations) {
+        sourceBuilder().aggregations(aggregations);
+        return this;
+    }
+
+    /**
+     * Adds a field to be highlighted with default fragment size of 100 characters, and
+     * default number of fragments of 5.
+     *
+     * @param name The field to highlight
+     */
+    public SearchRequestBuilder addHighlightedField(String name) {
+        highlightBuilder().field(name);
+        return this;
+    }
+
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters), and
+     * default number of fragments of 5.
+     *
+     * @param name         The field to highlight
+     * @param fragmentSize The size of a fragment in characters
+     */
+    public SearchRequestBuilder addHighlightedField(String name, int fragmentSize) {
+        highlightBuilder().field(name, fragmentSize);
+        return this;
+    }
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters), and
+     * a provided (maximum) number of fragments.
+     *
+     * @param name              The field to highlight
+     * @param fragmentSize      The size of a fragment in characters
+     * @param numberOfFragments The (maximum) number of fragments
+     */
+    public SearchRequestBuilder addHighlightedField(String name, int fragmentSize, int numberOfFragments) {
+        highlightBuilder().field(name, fragmentSize, numberOfFragments);
+        return this;
+    }
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters),
+     * a provided (maximum) number of fragments and an offset for the highlight.
+     *
+     * @param name              The field to highlight
+     * @param fragmentSize      The size of a fragment in characters
+     * @param numberOfFragments The (maximum) number of fragments
+     */
+    public SearchRequestBuilder addHighlightedField(String name, int fragmentSize, int numberOfFragments,
+                                                    int fragmentOffset) {
+        highlightBuilder().field(name, fragmentSize, numberOfFragments, fragmentOffset);
+        return this;
+    }
+
+    /**
+     * Adds a highlighted field.
+     */
+    public SearchRequestBuilder addHighlightedField(HighlightBuilder.Field field) {
+        highlightBuilder().field(field);
+        return this;
+    }
+
+    /**
+     * Set a tag scheme that encapsulates a built in pre and post tags. The allows schemes
+     * are <tt>styled</tt> and <tt>default</tt>.
+     *
+     * @param schemaName The tag scheme name
+     */
+    public SearchRequestBuilder setHighlighterTagsSchema(String schemaName) {
+        highlightBuilder().tagsSchema(schemaName);
+        return this;
+    }
+
+    public SearchRequestBuilder setHighlighterFragmentSize(Integer fragmentSize) {
+        highlightBuilder().fragmentSize(fragmentSize);
+        return this;
+    }
+
+    public SearchRequestBuilder setHighlighterNumOfFragments(Integer numOfFragments) {
+        highlightBuilder().numOfFragments(numOfFragments);
+        return this;
+    }
+
+    public SearchRequestBuilder setHighlighterFilter(Boolean highlightFilter) {
+        highlightBuilder().highlightFilter(highlightFilter);
+        return this;
+    }
+
+    /**
+     * The encoder to set for highlighting
+     */
+    public SearchRequestBuilder setHighlighterEncoder(String encoder) {
+        highlightBuilder().encoder(encoder);
+        return this;
+    }
+
+    /**
+     * Explicitly set the pre tags that will be used for highlighting.
+     */
+    public SearchRequestBuilder setHighlighterPreTags(String... preTags) {
+        highlightBuilder().preTags(preTags);
+        return this;
+    }
+
+    /**
+     * Explicitly set the post tags that will be used for highlighting.
+     */
+    public SearchRequestBuilder setHighlighterPostTags(String... postTags) {
+        highlightBuilder().postTags(postTags);
+        return this;
+    }
+
+    /**
+     * The order of fragments per field. By default, ordered by the order in the
+     * highlighted text. Can be <tt>score</tt>, which then it will be ordered
+     * by score of the fragments.
+     */
+    public SearchRequestBuilder setHighlighterOrder(String order) {
+        highlightBuilder().order(order);
+        return this;
+    }
+
+    public SearchRequestBuilder setHighlighterRequireFieldMatch(boolean requireFieldMatch) {
+        highlightBuilder().requireFieldMatch(requireFieldMatch);
+        return this;
+    }
+
+    public SearchRequestBuilder setHighlighterBoundaryMaxScan(Integer boundaryMaxScan) {
+        highlightBuilder().boundaryMaxScan(boundaryMaxScan);
+        return this;
+    }
+
+    public SearchRequestBuilder setHighlighterBoundaryChars(char[] boundaryChars) {
+        highlightBuilder().boundaryChars(boundaryChars);
         return this;
     }
 
     /**
-     * Delegates to
-     * {@link org.elasticsearch.search.suggest.SuggestBuilder#addSuggestion(org.elasticsearch.search.suggest.SuggestBuilder.SuggestionBuilder)}
-     * .
+     * The highlighter type to use.
      */
-    public SearchRequestBuilder suggest(SuggestBuilder suggestBuilder) {
-        sourceBuilder().suggest(suggestBuilder);
+    public SearchRequestBuilder setHighlighterType(String type) {
+        highlightBuilder().highlighterType(type);
         return this;
     }
 
-    public SearchRequestBuilder innerHits(InnerHitsBuilder innerHitsBuilder) {
-        sourceBuilder().innerHits(innerHitsBuilder);
+    public SearchRequestBuilder setHighlighterFragmenter(String fragmenter) {
+        highlightBuilder().fragmenter(fragmenter);
+        return this;
+    }
+
+    /**
+     * Sets a query to be used for highlighting all fields instead of the search query.
+     */
+    public SearchRequestBuilder setHighlighterQuery(QueryBuilder highlightQuery) {
+        highlightBuilder().highlightQuery(highlightQuery);
+        return this;
+    }
+
+    /**
+     * Sets the size of the fragment to return from the beginning of the field if there are no matches to
+     * highlight and the field doesn't also define noMatchSize.
+     *
+     * @param noMatchSize integer to set or null to leave out of request.  default is null.
+     * @return this builder for chaining
+     */
+    public SearchRequestBuilder setHighlighterNoMatchSize(Integer noMatchSize) {
+        highlightBuilder().noMatchSize(noMatchSize);
+        return this;
+    }
+
+    /**
+     * Sets the maximum number of phrases the fvh will consider if the field doesn't also define phraseLimit.
+     */
+    public SearchRequestBuilder setHighlighterPhraseLimit(Integer phraseLimit) {
+        highlightBuilder().phraseLimit(phraseLimit);
+        return this;
+    }
+
+    public SearchRequestBuilder setHighlighterOptions(Map<String, Object> options) {
+        highlightBuilder().options(options);
+        return this;
+    }
+
+    /**
+     * Forces to highlight fields based on the source even if fields are stored separately.
+     */
+    public SearchRequestBuilder setHighlighterForceSource(Boolean forceSource) {
+        highlightBuilder().forceSource(forceSource);
+        return this;
+    }
+
+    /**
+     * Send the fields to be highlighted using a syntax that is specific about the order in which they should be highlighted.
+     *
+     * @return this for chaining
+     */
+    public SearchRequestBuilder setHighlighterExplicitFieldOrder(boolean explicitFieldOrder) {
+        highlightBuilder().useExplicitFieldOrder(explicitFieldOrder);
+        return this;
+    }
+
+    public SearchRequestBuilder addParentChildInnerHits(String name, String type,  InnerHitsBuilder.InnerHit innerHit) {
+        innerHitsBuilder().addParentChildInnerHits(name, type, innerHit);
+        return this;
+    }
+
+    public SearchRequestBuilder addNestedInnerHits(String name, String path,  InnerHitsBuilder.InnerHit innerHit) {
+        innerHitsBuilder().addNestedInnerHits(name, path, innerHit);
+        return this;
+    }
+
+    /**
+     * Delegates to {@link org.elasticsearch.search.suggest.SuggestBuilder#setText(String)}.
+     */
+    public SearchRequestBuilder setSuggestText(String globalText) {
+        suggestBuilder().setText(globalText);
+        return this;
+    }
+
+    /**
+     * Delegates to {@link org.elasticsearch.search.suggest.SuggestBuilder#addSuggestion(org.elasticsearch.search.suggest.SuggestBuilder.SuggestionBuilder)}.
+     */
+    public SearchRequestBuilder addSuggestion(SuggestBuilder.SuggestionBuilder<?> suggestion) {
+        suggestBuilder().addSuggestion(suggestion);
         return this;
     }
 
@@ -455,7 +811,9 @@ public class SearchRequestBuilder extends ActionRequestBuilder<SearchRequest, Se
     }
 
     /**
-     * Sets the source of the request as a SearchSourceBuilder.
+     * Sets the source of the request as a SearchSourceBuilder. Note, settings anything other
+     * than the search type will cause this source to be overridden, consider using
+     * {@link #setExtraSource(SearchSourceBuilder)} instead.
      */
     public SearchRequestBuilder setSource(SearchSourceBuilder source) {
         request.source(source);
@@ -463,6 +821,26 @@ public class SearchRequestBuilder extends ActionRequestBuilder<SearchRequest, Se
     }
 
     /**
+     * Sets the source of the request as a json string. Note, settings anything other
+     * than the search type will cause this source to be overridden, consider using
+     * {@link #setExtraSource(SearchSourceBuilder)} instead.
+     */
+    public SearchRequestBuilder setSource(BytesReference source) {
+        request.source(source);
+        return this;
+    }
+
+    /**
+     * Sets the an addtional source of the request as a SearchSourceBuilder. All values and
+     * settings set on the extra source will override the corresponding settings on the specified
+     * source.
+     */
+    public SearchRequestBuilder setExtraSource(SearchSourceBuilder source) {
+        request.extraSource(source);
+        return this;
+    }
+
+    /**
      * template stuff
      */
     public SearchRequestBuilder setTemplate(Template template) {
@@ -470,6 +848,16 @@ public class SearchRequestBuilder extends ActionRequestBuilder<SearchRequest, Se
         return this;
     }
 
+    public SearchRequestBuilder setTemplateSource(String source) {
+        request.templateSource(source);
+        return this;
+    }
+
+    public SearchRequestBuilder setTemplateSource(BytesReference source) {
+        request.templateSource(source);
+        return this;
+    }
+
     /**
      * Sets if this request should use the request cache or not, assuming that it can (for
      * example, if "now" is used, it will never be cached). By default (not set, or null,
@@ -504,7 +892,7 @@ public class SearchRequestBuilder extends ActionRequestBuilder<SearchRequest, Se
         }
         if (request.source() != null) {
             try {
-                return XContentHelper.toString(request.source());
+                return XContentHelper.convertToJson(request.source().toBytesArray(), false, true);
             } catch (Exception e) {
                 return "{ \"error\" : \"" + ExceptionsHelper.detailedMessage(e) + "\"}";
             }
@@ -534,4 +922,16 @@ public class SearchRequestBuilder extends ActionRequestBuilder<SearchRequest, Se
         }
         return sourceBuilder;
     }
+
+    private HighlightBuilder highlightBuilder() {
+        return sourceBuilder().highlighter();
+    }
+
+    private InnerHitsBuilder innerHitsBuilder() {
+        return sourceBuilder().innerHitsBuilder();
+    }
+
+    private SuggestBuilder suggestBuilder() {
+        return sourceBuilder().suggest();
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/action/termvectors/dfs/DfsOnlyRequest.java b/core/src/main/java/org/elasticsearch/action/termvectors/dfs/DfsOnlyRequest.java
index 1c89ee1..86d575d 100644
--- a/core/src/main/java/org/elasticsearch/action/termvectors/dfs/DfsOnlyRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/termvectors/dfs/DfsOnlyRequest.java
@@ -27,6 +27,7 @@ import org.elasticsearch.action.search.SearchRequest;
 import org.elasticsearch.action.support.broadcast.BroadcastRequest;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.index.query.BoolQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.search.builder.SearchSourceBuilder;
@@ -102,7 +103,12 @@ public class DfsOnlyRequest extends BroadcastRequest<DfsOnlyRequest> {
 
     @Override
     public String toString() {
-        String sSource = searchRequest.source().toString();
+        String sSource = "_na_";
+        try {
+            sSource = XContentHelper.convertToJson(searchRequest.source(), false);
+        } catch (IOException e) {
+            // ignore
+        }
         return "[" + Arrays.toString(indices) + "]" + Arrays.toString(types()) + ", source[" + sSource + "]";
     }
 
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java
index 5d2fe42..6ea1d0e 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java
@@ -21,7 +21,6 @@ package org.elasticsearch.cluster.metadata;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.Diff;
@@ -41,11 +40,7 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.settings.loader.SettingsLoader;
-import org.elasticsearch.common.xcontent.FromXContentBuilder;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.search.warmer.IndexWarmersMetaData;
@@ -61,14 +56,12 @@ import java.util.Map;
 
 import static org.elasticsearch.cluster.node.DiscoveryNodeFilters.OpType.AND;
 import static org.elasticsearch.cluster.node.DiscoveryNodeFilters.OpType.OR;
-import static org.elasticsearch.common.settings.Settings.readSettingsFromStream;
-import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.elasticsearch.common.settings.Settings.writeSettingsToStream;
+import static org.elasticsearch.common.settings.Settings.*;
 
 /**
  *
  */
-public class IndexMetaData implements Diffable<IndexMetaData>, FromXContentBuilder<IndexMetaData>, ToXContent {
+public class IndexMetaData implements Diffable<IndexMetaData>, FromXContentBuilder<IndexMetaData>, ToXContent  {
 
     public static final IndexMetaData PROTO = IndexMetaData.builder("")
             .settings(Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT))
@@ -531,8 +524,7 @@ public class IndexMetaData implements Diffable<IndexMetaData>, FromXContentBuild
     }
 
     @Override
-    public IndexMetaData fromXContent(XContentParser parser, ParseFieldMatcher parseFieldMatcher)
-            throws IOException {
+    public IndexMetaData fromXContent(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException {
         return Builder.fromXContent(parser);
     }
 
@@ -713,7 +705,7 @@ public class IndexMetaData implements Diffable<IndexMetaData>, FromXContentBuild
         public int numberOfReplicas() {
             return settings.getAsInt(SETTING_NUMBER_OF_REPLICAS, -1);
         }
-
+        
         public Builder creationDate(long creationDate) {
             settings = settingsBuilder().put(settings).put(SETTING_CREATION_DATE, creationDate).build();
             return this;
diff --git a/core/src/main/java/org/elasticsearch/common/bytes/PagedBytesReference.java b/core/src/main/java/org/elasticsearch/common/bytes/PagedBytesReference.java
index 1477179..add383b 100644
--- a/core/src/main/java/org/elasticsearch/common/bytes/PagedBytesReference.java
+++ b/core/src/main/java/org/elasticsearch/common/bytes/PagedBytesReference.java
@@ -311,10 +311,6 @@ public class PagedBytesReference implements BytesReference {
             return true;
         }
 
-        if (obj == null) {
-            return false;
-        }
-
         if (!(obj instanceof PagedBytesReference)) {
             return BytesReference.Helper.bytesEqual(this, (BytesReference) obj);
         }
diff --git a/core/src/main/java/org/elasticsearch/common/geo/builders/ShapeBuilder.java b/core/src/main/java/org/elasticsearch/common/geo/builders/ShapeBuilder.java
index 0c1a12d..2380b97 100644
--- a/core/src/main/java/org/elasticsearch/common/geo/builders/ShapeBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/geo/builders/ShapeBuilder.java
@@ -27,6 +27,7 @@ import com.vividsolutions.jts.geom.Coordinate;
 import com.vividsolutions.jts.geom.Geometry;
 import com.vividsolutions.jts.geom.GeometryFactory;
 import org.elasticsearch.ElasticsearchParseException;
+import org.elasticsearch.action.support.ToXContentToBytes;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.ESLoggerFactory;
 import org.elasticsearch.common.unit.DistanceUnit.Distance;
@@ -34,7 +35,6 @@ import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.common.xcontent.json.JsonXContent;
 import org.elasticsearch.index.mapper.geo.GeoShapeFieldMapper;
 
 import java.io.IOException;
@@ -43,7 +43,7 @@ import java.util.*;
 /**
  * Basic class for building GeoJSON shapes like Polygons, Linestrings, etc 
  */
-public abstract class ShapeBuilder implements ToXContent {
+public abstract class ShapeBuilder extends ToXContentToBytes {
 
     protected static final ESLogger LOGGER = ESLoggerFactory.getLogger(ShapeBuilder.class.getName());
 
@@ -209,16 +209,6 @@ public abstract class ShapeBuilder implements ToXContent {
      */
     public static EnvelopeBuilder newEnvelope(Orientation orientation) { return new EnvelopeBuilder(orientation); }
 
-    @Override
-    public String toString() {
-        try {
-            XContentBuilder xcontent = JsonXContent.contentBuilder();
-            return toXContent(xcontent, EMPTY_PARAMS).prettyPrint().string();
-        } catch (IOException e) {
-            return super.toString();
-        }
-    }
-
     /**
      * Create a new Shape from this builder. Since calling this method could change the
      * defined shape. (by inserting new coordinates or change the position of points)
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
index 92d499a..57850da 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/StreamInput.java
@@ -34,6 +34,7 @@ import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.text.StringAndBytesText;
 import org.elasticsearch.common.text.Text;
 import org.elasticsearch.index.query.QueryBuilder;
+import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
 import org.joda.time.DateTime;
 import org.joda.time.DateTimeZone;
 
@@ -586,6 +587,13 @@ public abstract class StreamInput extends InputStream {
         return readNamedWriteable(QueryBuilder.class);
     }
 
+    /**
+     * Reads a {@link org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder} from the current stream
+     */
+    public ScoreFunctionBuilder<?> readScoreFunction() throws IOException {
+        return readNamedWriteable(ScoreFunctionBuilder.class);
+    }
+
     public static StreamInput wrap(BytesReference reference) {
         if (reference.hasArray() == false) {
             reference = reference.toBytesArray();
diff --git a/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java b/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
index 1f1562f..16128e4 100644
--- a/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
+++ b/core/src/main/java/org/elasticsearch/common/io/stream/StreamOutput.java
@@ -32,6 +32,7 @@ import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.text.Text;
 import org.elasticsearch.index.query.QueryBuilder;
+import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
 import org.joda.time.ReadableInstant;
 
 import java.io.EOFException;
@@ -588,4 +589,11 @@ public abstract class StreamOutput extends OutputStream {
     public void writeQuery(QueryBuilder queryBuilder) throws IOException {
         writeNamedWriteable(queryBuilder);
     }
+
+    /**
+     * Writes a {@link ScoreFunctionBuilder} to the current stream
+     */
+    public void writeScoreFunction(ScoreFunctionBuilder<?> scoreFunctionBuilder) throws IOException {
+        writeNamedWriteable(scoreFunctionBuilder);
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/MoreLikeThisQuery.java b/core/src/main/java/org/elasticsearch/common/lucene/search/MoreLikeThisQuery.java
index cdfa9ad..4107964 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/MoreLikeThisQuery.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/MoreLikeThisQuery.java
@@ -158,7 +158,7 @@ public class MoreLikeThisQuery extends Query {
         if (this.unlikeText != null || this.unlikeFields != null) {
             handleUnlike(mlt, this.unlikeText, this.unlikeFields);
         }
-        
+
         return createQuery(mlt);
     }
 
@@ -182,7 +182,7 @@ public class MoreLikeThisQuery extends Query {
 
         BooleanQuery bq = bqBuilder.build();
         bq.setBoost(getBoost());
-        return bq;    
+        return bq;
     }
 
     private void handleUnlike(XMoreLikeThis mlt, String[] unlikeText, Fields[] unlikeFields) throws IOException {
@@ -257,8 +257,8 @@ public class MoreLikeThisQuery extends Query {
         this.unlikeFields = unlikeFields;
     }
 
-    public void setUnlikeText(List<String> unlikeText) {
-        this.unlikeText = unlikeText.toArray(Strings.EMPTY_ARRAY);
+    public void setUnlikeText(String[] unlikeText) {
+        this.unlikeText = unlikeText;
     }
 
     public String[] getMoreLikeFields() {
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/CombineFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/CombineFunction.java
index 41a5b85..3876e6f 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/CombineFunction.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/CombineFunction.java
@@ -20,20 +20,21 @@
 package org.elasticsearch.common.lucene.search.function;
 
 import org.apache.lucene.search.Explanation;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.io.stream.Writeable;
 
-public enum CombineFunction {
-    MULT {
+import java.io.IOException;
+import java.util.Locale;
+
+public enum CombineFunction implements Writeable<CombineFunction> {
+    MULTIPLY {
         @Override
         public float combine(double queryScore, double funcScore, double maxBoost) {
             return toFloat(queryScore * Math.min(funcScore, maxBoost));
         }
 
         @Override
-        public String getName() {
-            return "multiply";
-        }
-
-        @Override
         public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation boostExpl = Explanation.match(maxBoost, "maxBoost");
             Explanation minExpl = Explanation.match(
@@ -51,11 +52,6 @@ public enum CombineFunction {
         }
 
         @Override
-        public String getName() {
-            return "replace";
-        }
-
-        @Override
         public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation boostExpl = Explanation.match(maxBoost, "maxBoost");
             return Explanation.match(
@@ -72,11 +68,6 @@ public enum CombineFunction {
         }
 
         @Override
-        public String getName() {
-            return "sum";
-        }
-
-        @Override
         public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation minExpl = Explanation.match(Math.min(funcExpl.getValue(), maxBoost), "min of:",
                     funcExpl, Explanation.match(maxBoost, "maxBoost"));
@@ -92,11 +83,6 @@ public enum CombineFunction {
         }
 
         @Override
-        public String getName() {
-            return "avg";
-        }
-
-        @Override
         public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation minExpl = Explanation.match(Math.min(funcExpl.getValue(), maxBoost), "min of:",
                     funcExpl, Explanation.match(maxBoost, "maxBoost"));
@@ -113,11 +99,6 @@ public enum CombineFunction {
         }
 
         @Override
-        public String getName() {
-            return "min";
-        }
-
-        @Override
         public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation innerMinExpl = Explanation.match(
                     Math.min(funcExpl.getValue(), maxBoost), "min of:",
@@ -135,11 +116,6 @@ public enum CombineFunction {
         }
 
         @Override
-        public String getName() {
-            return "max";
-        }
-
-        @Override
         public Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost) {
             Explanation innerMinExpl = Explanation.match(
                     Math.min(funcExpl.getValue(), maxBoost), "min of:",
@@ -153,8 +129,6 @@ public enum CombineFunction {
 
     public abstract float combine(double queryScore, double funcScore, double maxBoost);
 
-    public abstract String getName();
-
     public static float toFloat(double input) {
         assert deviation(input) <= 0.001 : "input " + input + " out of float scope for function score deviation: " + deviation(input);
         return (float) input;
@@ -166,4 +140,26 @@ public enum CombineFunction {
     }
 
     public abstract Explanation explain(Explanation queryExpl, Explanation funcExpl, float maxBoost);
+
+    @Override
+    public void writeTo(StreamOutput out) throws IOException {
+        out.writeVInt(this.ordinal());
+    }
+
+    @Override
+    public CombineFunction readFrom(StreamInput in) throws IOException {
+        int ordinal = in.readVInt();
+        if (ordinal < 0 || ordinal >= values().length) {
+            throw new IOException("Unknown CombineFunction ordinal [" + ordinal + "]");
+        }
+        return values()[ordinal];
+    }
+
+    public static CombineFunction readCombineFunctionFrom(StreamInput in) throws IOException {
+        return CombineFunction.MULTIPLY.readFrom(in);
+    }
+
+    public static CombineFunction fromString(String combineFunction) {
+        return valueOf(combineFunction.toUpperCase(Locale.ROOT));
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java
index cb2babb..89c5f5f 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FieldValueFactorFunction.java
@@ -22,11 +22,16 @@ package org.elasticsearch.common.lucene.search.function;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.Explanation;
 import org.elasticsearch.ElasticsearchException;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.index.fielddata.FieldData;
 import org.elasticsearch.index.fielddata.IndexNumericFieldData;
 import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;
 
+import java.io.IOException;
 import java.util.Locale;
+import java.util.Objects;
 
 /**
  * A function_score function that multiplies the score with the value of a
@@ -45,7 +50,7 @@ public class FieldValueFactorFunction extends ScoreFunction {
 
     public FieldValueFactorFunction(String field, float boostFactor, Modifier modifierType, Double missing,
             IndexNumericFieldData indexFieldData) {
-        super(CombineFunction.MULT);
+        super(CombineFunction.MULTIPLY);
         this.field = field;
         this.boostFactor = boostFactor;
         this.modifier = modifierType;
@@ -103,11 +108,19 @@ public class FieldValueFactorFunction extends ScoreFunction {
         return false;
     }
 
+    @Override
+    protected boolean doEquals(ScoreFunction other) {
+        FieldValueFactorFunction fieldValueFactorFunction = (FieldValueFactorFunction) other;
+        return this.boostFactor == fieldValueFactorFunction.boostFactor &&
+                Objects.equals(this.field, fieldValueFactorFunction.field) &&
+                Objects.equals(this.modifier, fieldValueFactorFunction.modifier);
+    }
+
     /**
      * The Type class encapsulates the modification types that can be applied
      * to the score/value product.
      */
-    public enum Modifier {
+    public enum Modifier implements Writeable<Modifier> {
         NONE {
             @Override
             public double apply(double n) {
@@ -172,8 +185,30 @@ public class FieldValueFactorFunction extends ScoreFunction {
         public abstract double apply(double n);
 
         @Override
+        public void writeTo(StreamOutput out) throws IOException {
+            out.writeVInt(this.ordinal());
+        }
+
+        public static Modifier readModifierFrom(StreamInput in) throws IOException {
+            return Modifier.NONE.readFrom(in);
+        }
+
+        @Override
+        public Modifier readFrom(StreamInput in) throws IOException {
+            int ordinal = in.readVInt();
+            if (ordinal < 0 || ordinal >= values().length) {
+                throw new IOException("Unknown Modifier ordinal [" + ordinal + "]");
+            }
+            return values()[ordinal];
+        }
+
+        @Override
         public String toString() {
             return super.toString().toLowerCase(Locale.ROOT);
         }
+
+        public static Modifier fromString(String modifier) {
+            return valueOf(modifier.toUpperCase(Locale.ROOT));
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java
index ebe25b8..7e94792 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FiltersFunctionScoreQuery.java
@@ -29,14 +29,13 @@ import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Weight;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.common.lucene.Lucene;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-import java.util.Locale;
-import java.util.Set;
+import java.util.*;
 
 /**
  * A query that allows for a pluggable boost function / filter. If it matches
@@ -55,53 +54,63 @@ public class FiltersFunctionScoreQuery extends Query {
 
         @Override
         public boolean equals(Object o) {
-            if (this == o)
+            if (this == o) {
                 return true;
-            if (o == null || getClass() != o.getClass())
+            }
+            if (o == null || getClass() != o.getClass()) {
                 return false;
-
+            }
             FilterFunction that = (FilterFunction) o;
-
-            if (filter != null ? !filter.equals(that.filter) : that.filter != null)
-                return false;
-            if (function != null ? !function.equals(that.function) : that.function != null)
-                return false;
-
-            return true;
+            return Objects.equals(this.filter, that.filter) && Objects.equals(this.function, that.function);
         }
 
         @Override
         public int hashCode() {
-            int result = filter != null ? filter.hashCode() : 0;
-            result = 31 * result + (function != null ? function.hashCode() : 0);
-            return result;
+            return Objects.hash(super.hashCode(), filter, function);
         }
     }
 
-    public static enum ScoreMode {
-        First, Avg, Max, Sum, Min, Multiply
+    public enum ScoreMode implements Writeable<ScoreMode> {
+        FIRST, AVG, MAX, SUM, MIN, MULTIPLY;
+
+        @Override
+        public void writeTo(StreamOutput out) throws IOException {
+            out.writeVInt(this.ordinal());
+        }
+
+        @Override
+        public ScoreMode readFrom(StreamInput in) throws IOException {
+            int ordinal = in.readVInt();
+            if (ordinal < 0 || ordinal >= values().length) {
+                throw new IOException("Unknown ScoreMode ordinal [" + ordinal + "]");
+            }
+            return values()[ordinal];
+        }
+
+        public static ScoreMode readScoreModeFrom(StreamInput in) throws IOException {
+            return ScoreMode.MULTIPLY.readFrom(in);
+        }
+
+        public static ScoreMode fromString(String scoreMode) {
+            return valueOf(scoreMode.toUpperCase(Locale.ROOT));
+        }
     }
 
     Query subQuery;
     final FilterFunction[] filterFunctions;
     final ScoreMode scoreMode;
     final float maxBoost;
-    private Float minScore;
+    private final Float minScore;
 
-    protected CombineFunction combineFunction;
+    final protected CombineFunction combineFunction;
 
-    public FiltersFunctionScoreQuery(Query subQuery, ScoreMode scoreMode, FilterFunction[] filterFunctions, float maxBoost, Float minScore) {
+    public FiltersFunctionScoreQuery(Query subQuery, ScoreMode scoreMode, FilterFunction[] filterFunctions, float maxBoost, Float minScore, CombineFunction combineFunction) {
         this.subQuery = subQuery;
         this.scoreMode = scoreMode;
         this.filterFunctions = filterFunctions;
         this.maxBoost = maxBoost;
-        combineFunction = CombineFunction.MULT;
-        this.minScore = minScore;
-    }
-
-    public FiltersFunctionScoreQuery setCombineFunction(CombineFunction combineFunction) {
         this.combineFunction = combineFunction;
-        return this;
+        this.minScore = minScore;
     }
 
     public Query getSubQuery() {
@@ -227,35 +236,34 @@ public class FiltersFunctionScoreQuery extends Query {
             // filters
             double factor = 1.0;
             switch (scoreMode) {
-            case First:
-
+            case FIRST:
                 factor = filterExplanations.get(0).getValue();
                 break;
-            case Max:
+            case MAX:
                 factor = Double.NEGATIVE_INFINITY;
-                for (int i = 0; i < filterExplanations.size(); i++) {
-                    factor = Math.max(filterExplanations.get(i).getValue(), factor);
+                for (Explanation filterExplanation : filterExplanations) {
+                    factor = Math.max(filterExplanation.getValue(), factor);
                 }
                 break;
-            case Min:
+            case MIN:
                 factor = Double.POSITIVE_INFINITY;
-                for (int i = 0; i < filterExplanations.size(); i++) {
-                    factor = Math.min(filterExplanations.get(i).getValue(), factor);
+                for (Explanation filterExplanation : filterExplanations) {
+                    factor = Math.min(filterExplanation.getValue(), factor);
                 }
                 break;
-            case Multiply:
-                for (int i = 0; i < filterExplanations.size(); i++) {
-                    factor *= filterExplanations.get(i).getValue();
+            case MULTIPLY:
+                for (Explanation filterExplanation : filterExplanations) {
+                    factor *= filterExplanation.getValue();
                 }
                 break;
-            default: // Avg / Total
+            default:
                 double totalFactor = 0.0f;
-                for (int i = 0; i < filterExplanations.size(); i++) {
-                    totalFactor += filterExplanations.get(i).getValue();
+                for (Explanation filterExplanation : filterExplanations) {
+                    totalFactor += filterExplanation.getValue();
                 }
                 if (weightSum != 0) {
                     factor = totalFactor;
-                    if (scoreMode == ScoreMode.Avg) {
+                    if (scoreMode == ScoreMode.AVG) {
                         factor /= weightSum;
                     }
                 }
@@ -293,58 +301,64 @@ public class FiltersFunctionScoreQuery extends Query {
             // be costly to call score(), so we explicitly check if scores
             // are needed
             float subQueryScore = needsScores ? scorer.score() : 0f;
-            if (scoreMode == ScoreMode.First) {
-                for (int i = 0; i < filterFunctions.length; i++) {
-                    if (docSets[i].get(docId)) {
-                        factor = functions[i].score(docId, subQueryScore);
-                        break;
+            switch(scoreMode) {
+                case FIRST:
+                    for (int i = 0; i < filterFunctions.length; i++) {
+                        if (docSets[i].get(docId)) {
+                            factor = functions[i].score(docId, subQueryScore);
+                            break;
+                        }
                     }
-                }
-            } else if (scoreMode == ScoreMode.Max) {
-                double maxFactor = Double.NEGATIVE_INFINITY;
-                for (int i = 0; i < filterFunctions.length; i++) {
-                    if (docSets[i].get(docId)) {
-                        maxFactor = Math.max(functions[i].score(docId, subQueryScore), maxFactor);
+                    break;
+                case MAX:
+                    double maxFactor = Double.NEGATIVE_INFINITY;
+                    for (int i = 0; i < filterFunctions.length; i++) {
+                        if (docSets[i].get(docId)) {
+                            maxFactor = Math.max(functions[i].score(docId, subQueryScore), maxFactor);
+                        }
                     }
-                }
-                if (maxFactor != Float.NEGATIVE_INFINITY) {
-                    factor = maxFactor;
-                }
-            } else if (scoreMode == ScoreMode.Min) {
-                double minFactor = Double.POSITIVE_INFINITY;
-                for (int i = 0; i < filterFunctions.length; i++) {
-                    if (docSets[i].get(docId)) {
-                        minFactor = Math.min(functions[i].score(docId, subQueryScore), minFactor);
+                    if (maxFactor != Float.NEGATIVE_INFINITY) {
+                        factor = maxFactor;
                     }
-                }
-                if (minFactor != Float.POSITIVE_INFINITY) {
-                    factor = minFactor;
-                }
-            } else if (scoreMode == ScoreMode.Multiply) {
-                for (int i = 0; i < filterFunctions.length; i++) {
-                    if (docSets[i].get(docId)) {
-                        factor *= functions[i].score(docId, subQueryScore);
+                    break;
+                case MIN:
+                    double minFactor = Double.POSITIVE_INFINITY;
+                    for (int i = 0; i < filterFunctions.length; i++) {
+                        if (docSets[i].get(docId)) {
+                            minFactor = Math.min(functions[i].score(docId, subQueryScore), minFactor);
+                        }
                     }
-                }
-            } else { // Avg / Total
-                double totalFactor = 0.0f;
-                float weightSum = 0;
-                for (int i = 0; i < filterFunctions.length; i++) {
-                    if (docSets[i].get(docId)) {
-                        totalFactor += functions[i].score(docId, subQueryScore);
-                        if (filterFunctions[i].function instanceof WeightFactorFunction) {
-                            weightSum+= ((WeightFactorFunction)filterFunctions[i].function).getWeight();
-                        } else {
-                            weightSum++;
+                    if (minFactor != Float.POSITIVE_INFINITY) {
+                        factor = minFactor;
+                    }
+                    break;
+                case MULTIPLY:
+                    for (int i = 0; i < filterFunctions.length; i++) {
+                        if (docSets[i].get(docId)) {
+                            factor *= functions[i].score(docId, subQueryScore);
                         }
                     }
-                }
-                if (weightSum != 0) {
-                    factor = totalFactor;
-                    if (scoreMode == ScoreMode.Avg) {
-                        factor /= weightSum;
+                    break;
+                default: // Avg / Total
+                    double totalFactor = 0.0f;
+                    float weightSum = 0;
+                    for (int i = 0; i < filterFunctions.length; i++) {
+                        if (docSets[i].get(docId)) {
+                            totalFactor += functions[i].score(docId, subQueryScore);
+                            if (filterFunctions[i].function instanceof WeightFactorFunction) {
+                                weightSum+= ((WeightFactorFunction)filterFunctions[i].function).getWeight();
+                            } else {
+                                weightSum++;
+                            }
+                        }
                     }
-                }
+                    if (weightSum != 0) {
+                        factor = totalFactor;
+                        if (scoreMode == ScoreMode.AVG) {
+                            factor /= weightSum;
+                        }
+                    }
+                    break;
             }
             return scoreCombiner.combine(subQueryScore, factor, maxBoost);
         }
@@ -364,19 +378,20 @@ public class FiltersFunctionScoreQuery extends Query {
 
     @Override
     public boolean equals(Object o) {
-        if (o == null || getClass() != o.getClass())
-            return false;
-        FiltersFunctionScoreQuery other = (FiltersFunctionScoreQuery) o;
-        if (this.getBoost() != other.getBoost())
-            return false;
-        if (!this.subQuery.equals(other.subQuery)) {
+        if (this == o) {
+            return true;
+        }
+        if (super.equals(o) == false) {
             return false;
         }
-        return Arrays.equals(this.filterFunctions, other.filterFunctions);
+        FiltersFunctionScoreQuery other = (FiltersFunctionScoreQuery) o;
+        return Objects.equals(this.subQuery, other.subQuery) && this.maxBoost == other.maxBoost &&
+                Objects.equals(this.combineFunction, other.combineFunction) && Objects.equals(this.minScore, other.minScore) &&
+                Arrays.equals(this.filterFunctions, other.filterFunctions);
     }
 
     @Override
     public int hashCode() {
-        return subQuery.hashCode() + 31 * Arrays.hashCode(filterFunctions) ^ Float.floatToIntBits(getBoost());
+        return Objects.hash(super.hashCode(), subQuery, maxBoost, combineFunction, minScore, filterFunctions);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FunctionScoreQuery.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FunctionScoreQuery.java
index 2a88296..907d669 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/FunctionScoreQuery.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/FunctionScoreQuery.java
@@ -23,7 +23,6 @@ import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.*;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.ToStringUtils;
 
 import java.io.IOException;
@@ -35,31 +34,27 @@ import java.util.Set;
  */
 public class FunctionScoreQuery extends Query {
 
+    public static final float DEFAULT_MAX_BOOST = Float.MAX_VALUE;
+
     Query subQuery;
     final ScoreFunction function;
-    float maxBoost = Float.MAX_VALUE;
-    CombineFunction combineFunction;
-    private Float minScore = null;
+    final float maxBoost;
+    final CombineFunction combineFunction;
+    private Float minScore;
 
-    public FunctionScoreQuery(Query subQuery, ScoreFunction function, Float minScore) {
+    public FunctionScoreQuery(Query subQuery, ScoreFunction function, Float minScore, CombineFunction combineFunction, float maxBoost) {
         this.subQuery = subQuery;
         this.function = function;
-        this.combineFunction = function == null? CombineFunction.MULT : function.getDefaultScoreCombiner();
+        this.combineFunction = combineFunction;
         this.minScore = minScore;
+        this.maxBoost = maxBoost;
     }
 
     public FunctionScoreQuery(Query subQuery, ScoreFunction function) {
         this.subQuery = subQuery;
         this.function = function;
         this.combineFunction = function.getDefaultScoreCombiner();
-    }
-
-    public void setCombineFunction(CombineFunction combineFunction) {
-        this.combineFunction = combineFunction;
-    }
-    
-    public void setMaxBoost(float maxBoost) {
-        this.maxBoost = maxBoost;
+        this.maxBoost = DEFAULT_MAX_BOOST;
     }
 
     public float getMaxBoost() {
@@ -193,15 +188,20 @@ public class FunctionScoreQuery extends Query {
 
     @Override
     public boolean equals(Object o) {
-        if (o == null || getClass() != o.getClass())
+        if (this == o) {
+            return true;
+        }
+        if (super.equals(o) == false) {
             return false;
+        }
         FunctionScoreQuery other = (FunctionScoreQuery) o;
-        return this.getBoost() == other.getBoost() && this.subQuery.equals(other.subQuery) && (this.function != null ? this.function.equals(other.function) : other.function == null)
-                && this.maxBoost == other.maxBoost;
+        return Objects.equals(this.subQuery, other.subQuery) && Objects.equals(this.function, other.function)
+                && Objects.equals(this.combineFunction, other.combineFunction)
+                && Objects.equals(this.minScore, other.minScore) && this.maxBoost == other.maxBoost;
     }
 
     @Override
     public int hashCode() {
-        return subQuery.hashCode() + 31 * Objects.hashCode(function) ^ Float.floatToIntBits(getBoost());
+        return Objects.hash(super.hashCode(), subQuery.hashCode(), function, combineFunction, minScore, maxBoost);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/RandomScoreFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/RandomScoreFunction.java
index bc1962a..cb34cbc 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/RandomScoreFunction.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/RandomScoreFunction.java
@@ -38,7 +38,7 @@ public class RandomScoreFunction extends ScoreFunction {
      * Default constructor. Only useful for constructing as a placeholder, but should not be used for actual scoring.
      */
     public RandomScoreFunction() {
-        super(CombineFunction.MULT);
+        super(CombineFunction.MULTIPLY);
         uidFieldData = null;
     }
 
@@ -50,7 +50,7 @@ public class RandomScoreFunction extends ScoreFunction {
      * @param uidFieldData The field data for _uid to use for generating consistent random values for the same id
      */
     public RandomScoreFunction(int seed, int salt, IndexFieldData<?> uidFieldData) {
-        super(CombineFunction.MULT);
+        super(CombineFunction.MULTIPLY);
         this.originalSeed = seed;
         this.saltedSeed = seed ^ salt;
         this.uidFieldData = uidFieldData;
@@ -85,4 +85,11 @@ public class RandomScoreFunction extends ScoreFunction {
     public boolean needsScores() {
         return false;
     }
+
+    @Override
+    protected boolean doEquals(ScoreFunction other) {
+        RandomScoreFunction randomScoreFunction = (RandomScoreFunction) other;
+        return this.originalSeed == randomScoreFunction.originalSeed &&
+                this.saltedSeed == randomScoreFunction.saltedSeed;
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScoreFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScoreFunction.java
index 1f12336..f4551d4 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScoreFunction.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScoreFunction.java
@@ -22,6 +22,7 @@ package org.elasticsearch.common.lucene.search.function;
 import org.apache.lucene.index.LeafReaderContext;
 
 import java.io.IOException;
+import java.util.Objects;
 
 /**
  *
@@ -46,4 +47,23 @@ public abstract class ScoreFunction {
      * @return {@code true} if scores are needed.
      */
     public abstract boolean needsScores();
+
+    @Override
+    public final boolean equals(Object obj) {
+        if (this == obj) {
+            return true;
+        }
+        if (obj == null || getClass() != obj.getClass()) {
+            return false;
+        }
+
+        ScoreFunction other = (ScoreFunction) obj;
+        return Objects.equals(scoreCombiner, other.scoreCombiner) &&
+                doEquals(other);
+    }
+
+    /**
+     * Indicates whether some other {@link ScoreFunction} object of the same type is "equal to" this one.
+     */
+    protected abstract boolean doEquals(ScoreFunction other);
 }
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java
index 1ff3cdd..a715c61 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/ScriptScoreFunction.java
@@ -29,6 +29,7 @@ import org.elasticsearch.script.ScriptException;
 import org.elasticsearch.script.SearchScript;
 
 import java.io.IOException;
+import java.util.Objects;
 
 public class ScriptScoreFunction extends ScoreFunction {
 
@@ -136,4 +137,9 @@ public class ScriptScoreFunction extends ScoreFunction {
         return "script" + sScript.toString();
     }
 
+    @Override
+    protected boolean doEquals(ScoreFunction other) {
+        ScriptScoreFunction scriptScoreFunction = (ScriptScoreFunction) other;
+        return Objects.equals(this.sScript, scriptScoreFunction.sScript);
+    }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/search/function/WeightFactorFunction.java b/core/src/main/java/org/elasticsearch/common/lucene/search/function/WeightFactorFunction.java
index c585da42..fa70480 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/search/function/WeightFactorFunction.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/search/function/WeightFactorFunction.java
@@ -23,18 +23,19 @@ import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.Explanation;
 
 import java.io.IOException;
+import java.util.Objects;
 
 /**
  *
  */
 public class WeightFactorFunction extends ScoreFunction {
 
-    private static final ScoreFunction SCORE_ONE = new ScoreOne(CombineFunction.MULT);
+    private static final ScoreFunction SCORE_ONE = new ScoreOne(CombineFunction.MULTIPLY);
     private final ScoreFunction scoreFunction;
     private float weight = 1.0f;
 
     public WeightFactorFunction(float weight, ScoreFunction scoreFunction) {
-        super(CombineFunction.MULT);
+        super(CombineFunction.MULTIPLY);
         if (scoreFunction == null) {
             this.scoreFunction = SCORE_ONE;
         } else {
@@ -44,7 +45,7 @@ public class WeightFactorFunction extends ScoreFunction {
     }
 
     public WeightFactorFunction(float weight) {
-        super(CombineFunction.MULT);
+        super(CombineFunction.MULTIPLY);
         this.scoreFunction = SCORE_ONE;
         this.weight = weight;
     }
@@ -81,6 +82,17 @@ public class WeightFactorFunction extends ScoreFunction {
         return weight;
     }
 
+    public ScoreFunction getScoreFunction() {
+        return scoreFunction;
+    }
+
+    @Override
+    protected boolean doEquals(ScoreFunction other) {
+        WeightFactorFunction weightFactorFunction = (WeightFactorFunction) other;
+        return this.weight == weightFactorFunction.weight &&
+                Objects.equals(this.scoreFunction, weightFactorFunction.scoreFunction);
+    }
+
     private static class ScoreOne extends ScoreFunction {
 
         protected ScoreOne(CombineFunction scoreCombiner) {
@@ -106,5 +118,10 @@ public class WeightFactorFunction extends ScoreFunction {
         public boolean needsScores() {
             return false;
         }
+
+        @Override
+        protected boolean doEquals(ScoreFunction other) {
+            return true;
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
index b5a62c8..403ed19 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
@@ -118,11 +118,10 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
         if (shape != null) {
             XContentBuilder builder = XContentFactory.jsonBuilder();
             shape.toXContent(builder, EMPTY_PARAMS);
-            BytesReference bytes = builder.bytes();
-            if (bytes.length() == 0) {
+            this.shapeBytes = shape.buildAsBytes(XContentType.JSON);
+            if (this.shapeBytes.length() == 0) {
                 throw new IllegalArgumentException("shape must not be empty");
             }
-            this.shapeBytes = bytes;
         } else {
             throw new IllegalArgumentException("shape must not be null");
         }
diff --git a/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java b/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
index 720d57d..4c71b3b 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
@@ -96,8 +96,7 @@ public class IndexQueryParserService extends AbstractIndexComponent {
     private final boolean queryStringAllowLeadingWildcard;
     private final ParseFieldMatcher parseFieldMatcher;
     private final boolean defaultAllowUnmappedFields;
-
-    private Client client;
+    private final Client client;
 
     @Inject
     public IndexQueryParserService(Index index, @IndexSettings Settings indexSettings, Settings settings,
@@ -150,7 +149,7 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         return this.queryStringLenient;
     }
 
-    public IndicesQueriesRegistry indicesQueriesRegistry() {
+    IndicesQueriesRegistry indicesQueriesRegistry() {
         return indicesQueriesRegistry;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
index bd43475..f777654 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilder.java
@@ -75,11 +75,11 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
     public static final boolean DEFAULT_FAIL_ON_UNSUPPORTED_FIELDS = true;
 
     // document inputs
-    private final List<String> fields;
-    private List<String> likeTexts = new ArrayList<>();
-    private List<String> unlikeTexts = new ArrayList<>();
-    private List<Item> likeItems = new ArrayList<>();
-    private List<Item> unlikeItems = new ArrayList<>();
+    private final String[] fields;
+    private final String[] likeTexts;
+    private String[] unlikeTexts = Strings.EMPTY_ARRAY;
+    private final Item[] likeItems;
+    private Item[] unlikeItems = new Item[0];
 
     // term selection parameters
     private int maxQueryTerms = DEFAULT_MAX_QUERY_TERMS;
@@ -99,7 +99,7 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
     // other parameters
     private boolean failOnUnsupportedField = DEFAULT_FAIL_ON_UNSUPPORTED_FIELDS;
 
-    static final MoreLikeThisQueryBuilder PROTOTYPE = new MoreLikeThisQueryBuilder();
+    static final MoreLikeThisQueryBuilder PROTOTYPE = new MoreLikeThisQueryBuilder(new String[]{"_na_"}, null);
 
     /**
      * A single item to be used for a {@link MoreLikeThisQueryBuilder}.
@@ -437,82 +437,66 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
 
     /**
      * Constructs a new more like this query which uses the "_all" field.
+     * @param likeTexts the text to use when generating the 'More Like This' query.
+     * @param likeItems the documents to use when generating the 'More Like This' query.
      */
-    public MoreLikeThisQueryBuilder() {
-        this.fields = null;
-    }
-
-    /**
-     * Sets the field names that will be used when generating the 'More Like This' query.
-     *
-     * @param fields the field names that will be used when generating the 'More Like This' query.
-     */
-    public MoreLikeThisQueryBuilder(String... fields) {
-        this(Collections.unmodifiableList(Arrays.asList(fields)));
+    public MoreLikeThisQueryBuilder(String[] likeTexts, Item[] likeItems) {
+        this(null, likeTexts, likeItems);
     }
 
     /**
      * Sets the field names that will be used when generating the 'More Like This' query.
      *
      * @param fields the field names that will be used when generating the 'More Like This' query.
+     * @param likeTexts the text to use when generating the 'More Like This' query.
+     * @param likeItems the documents to use when generating the 'More Like This' query.
      */
-    public MoreLikeThisQueryBuilder(List<String> fields) {
+    public MoreLikeThisQueryBuilder(@Nullable String[] fields, @Nullable String[] likeTexts, @Nullable Item[] likeItems) {
+        // TODO we allow null here for the _all field, but this is forbidden in the parser. Re-check
+        if (fields != null && fields.length == 0) {
+            throw new IllegalArgumentException("mlt query requires 'fields' to be specified");
+        }
+        if ((likeTexts == null || likeTexts.length == 0) && (likeItems == null || likeItems.length == 0)) {
+            throw new IllegalArgumentException("mlt query requires either 'like' texts or items to be specified.");
+        }
         this.fields = fields;
+        this.likeTexts = Optional.ofNullable(likeTexts).orElse(Strings.EMPTY_ARRAY);
+        this.likeItems = Optional.ofNullable(likeItems).orElse(new Item[0]);
     }
 
-    public List<String> fields() {
-        return fields;
+    public String[] fields() {
+        return this.fields;
     }
 
-    /**
-     * Sets the text to use in order to find documents that are "like" this.
-     *
-     * @param likeTexts the text to use when generating the 'More Like This' query.
-     */
-    public MoreLikeThisQueryBuilder like(String... likeTexts) {
-        this.likeTexts = Collections.unmodifiableList(Arrays.asList(likeTexts));
-        return this;
-    }
-
-    public List<String> likeTexts() {
+    public String[] likeTexts() {
         return likeTexts;
     }
 
-    /**
-     * Sets the documents to use in order to find documents that are "like" this.
-     *
-     * @param likeItems the documents to use when generating the 'More Like This' query.
-     */
-    public MoreLikeThisQueryBuilder like(Item... likeItems) {
-        this.likeItems = Collections.unmodifiableList(Arrays.asList(likeItems));
-        return this;
-    }
-
-    public List<Item> likeItems() {
+    public Item[] likeItems() {
         return likeItems;
     }
 
     /**
      * Sets the text from which the terms should not be selected from.
      */
-    public MoreLikeThisQueryBuilder unlike(String... unlikeTexts) {
-        this.unlikeTexts = Collections.unmodifiableList(Arrays.asList(unlikeTexts));
+    public MoreLikeThisQueryBuilder unlike(String[] unlikeTexts) {
+        this.unlikeTexts = Optional.ofNullable(unlikeTexts).orElse(Strings.EMPTY_ARRAY);
         return this;
     }
 
-    public List<String> unlikeTexts() {
+    public String[] unlikeTexts() {
         return unlikeTexts;
     }
 
     /**
      * Sets the documents from which the terms should not be selected from.
      */
-    public MoreLikeThisQueryBuilder unlike(Item... unlikeItems) {
-        this.unlikeItems = Collections.unmodifiableList(Arrays.asList(unlikeItems));
+    public MoreLikeThisQueryBuilder unlike(Item[] unlikeItems) {
+        this.unlikeItems = Optional.ofNullable(unlikeItems).orElse(new Item[0]);
         return this;
     }
 
-    public List<Item> unlikeItems() {
+    public Item[] unlikeItems() {
         return unlikeItems;
     }
 
@@ -685,20 +669,18 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
     }
 
     /**
-     * The text to use in order to find documents that are "like" this.
+     * Converts an array of String ids to and Item[].
+     * @param ids the ids to convert
+     * @return the new items array
+     * @deprecated construct the items array externaly and use it in the constructor / setter
      */
     @Deprecated
-    public MoreLikeThisQueryBuilder likeText(String likeText) {
-        return like(likeText);
-    }
-
-    @Deprecated
-    public MoreLikeThisQueryBuilder ids(String... ids) {
+    public static Item[] ids(String... ids) {
         Item[] items = new Item[ids.length];
         for (int i = 0; i < items.length; i++) {
             items[i] = new Item(null, null, ids[i]);
         }
-        return like(items);
+        return items;
     }
 
     @Override
@@ -708,9 +690,7 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
             builder.field(MoreLikeThisQueryParser.Field.FIELDS.getPreferredName(), fields);
         }
         buildLikeField(builder, MoreLikeThisQueryParser.Field.LIKE.getPreferredName(), likeTexts, likeItems);
-        if (!unlikeTexts.isEmpty() || !unlikeItems.isEmpty()) {
-            buildLikeField(builder, MoreLikeThisQueryParser.Field.UNLIKE.getPreferredName(), unlikeTexts, unlikeItems);
-        }
+        buildLikeField(builder, MoreLikeThisQueryParser.Field.UNLIKE.getPreferredName(), unlikeTexts, unlikeItems);
         builder.field(MoreLikeThisQueryParser.Field.MAX_QUERY_TERMS.getPreferredName(), maxQueryTerms);
         builder.field(MoreLikeThisQueryParser.Field.MIN_TERM_FREQ.getPreferredName(), minTermFreq);
         builder.field(MoreLikeThisQueryParser.Field.MIN_DOC_FREQ.getPreferredName(), minDocFreq);
@@ -731,15 +711,17 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         builder.endObject();
     }
 
-    private static void buildLikeField(XContentBuilder builder, String fieldName, List<String> texts, List<Item> items) throws IOException {
-        builder.startArray(fieldName);
-        for (String text : texts) {
-            builder.value(text);
-        }
-        for (Item item : items) {
-            builder.value(item);
+    private static void buildLikeField(XContentBuilder builder, String fieldName, String[] texts, Item[] items) throws IOException {
+        if (texts.length > 0 || items.length > 0) {
+            builder.startArray(fieldName);
+            for (String text : texts) {
+                builder.value(text);
+            }
+            for (Item item : items) {
+                builder.value(item);
+            }
+            builder.endArray();
         }
-        builder.endArray();
     }
 
     @Override
@@ -799,15 +781,15 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         mltQuery.setMoreLikeFields(moreLikeFields.toArray(Strings.EMPTY_ARRAY));
 
         // handle like texts
-        if (likeTexts.isEmpty() == false) {
+        if (likeTexts.length > 0) {
             mltQuery.setLikeText(likeTexts);
         }
-        if (unlikeTexts.isEmpty() == false) {
+        if (unlikeTexts.length > 0) {
             mltQuery.setUnlikeText(unlikeTexts);
         }
 
         // handle items
-        if (likeItems.isEmpty() == false) {
+        if (likeItems.length > 0) {
             return handleItems(context, mltQuery, likeItems, unlikeItems, include, moreLikeFields, useDefaultField);
         } else {
             return mltQuery;
@@ -828,7 +810,7 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         return moreLikeFields;
     }
 
-    private Query handleItems(QueryShardContext context, MoreLikeThisQuery mltQuery, List<Item> likeItems, List<Item> unlikeItems,
+    private Query handleItems(QueryShardContext context, MoreLikeThisQuery mltQuery, Item[] likeItems, Item[] unlikeItems,
                               boolean include, List<String> moreLikeFields, boolean useDefaultField) throws IOException {
         // set default index, type and fields if not specified
         for (Item item : likeItems) {
@@ -845,7 +827,7 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         mltQuery.setLikeText(getFieldsFor(responses, likeItems));
 
         // getting the Fields for unliked items
-        if (!unlikeItems.isEmpty()) {
+        if (unlikeItems.length > 0) {
             org.apache.lucene.index.Fields[] unlikeFields = getFieldsFor(responses, unlikeItems);
             if (unlikeFields.length > 0) {
                 mltQuery.setUnlikeText(unlikeFields);
@@ -885,22 +867,20 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         }
     }
 
-    private MultiTermVectorsResponse fetchResponse(Client client, List<Item> likeItems, @Nullable List<Item> unlikeItems,
+    private MultiTermVectorsResponse fetchResponse(Client client, Item[] likeItems, @Nullable Item[] unlikeItems,
                                                    SearchContext searchContext) throws IOException {
         MultiTermVectorsRequest request = new MultiTermVectorsRequest();
         for (Item item : likeItems) {
             request.add(item.toTermVectorsRequest());
         }
-        if (unlikeItems != null) {
-            for (Item item : unlikeItems) {
-                request.add(item.toTermVectorsRequest());
-            }
+        for (Item item : unlikeItems) {
+            request.add(item.toTermVectorsRequest());
         }
         request.copyContextAndHeadersFrom(searchContext);
         return client.multiTermVectors(request).actionGet();
     }
 
-    private static Fields[] getFieldsFor(MultiTermVectorsResponse responses, List<Item> items) throws IOException {
+    private static Fields[] getFieldsFor(MultiTermVectorsResponse responses, Item[] items) throws IOException {
         List<Fields> likeFields = new ArrayList<>();
 
         Set<Item> selectedItems = new HashSet<>();
@@ -928,7 +908,7 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         return selectedItems.contains(new Item(response.getIndex(), response.getType(), response.getId()));
     }
 
-    private static void handleExclude(BooleanQuery boolQuery, List<Item> likeItems) {
+    private static void handleExclude(BooleanQuery boolQuery, Item[] likeItems) {
         // artificial docs get assigned a random id and should be disregarded
         List<BytesRef> uids = new ArrayList<>();
         for (Item item : likeItems) {
@@ -943,23 +923,13 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         }
     }
 
-    public QueryValidationException validate() {
-        QueryValidationException validationException = null;
-        if (likeTexts.isEmpty() && likeItems.isEmpty()) {
-            validationException = addValidationError("requires 'like' to be specified.", validationException);
-        }
-        if (fields != null && fields.isEmpty()) {
-            validationException = addValidationError("requires 'fields' to be specified", validationException);
-        }
-        return validationException;
-    }
-
     @Override
     protected MoreLikeThisQueryBuilder doReadFrom(StreamInput in) throws IOException {
-        MoreLikeThisQueryBuilder moreLikeThisQueryBuilder = new MoreLikeThisQueryBuilder((List<String>) in.readGenericValue());
-        moreLikeThisQueryBuilder.likeTexts = (List<String>) in.readGenericValue();
-        moreLikeThisQueryBuilder.unlikeTexts = (List<String>) in.readGenericValue();
-        moreLikeThisQueryBuilder.likeItems = readItems(in);
+        String[] fields = in.readOptionalStringArray();
+        String[] likeTexts = in.readStringArray();
+        Item[] likeItems = readItems(in);
+        MoreLikeThisQueryBuilder moreLikeThisQueryBuilder = new MoreLikeThisQueryBuilder(fields, likeTexts, likeItems);
+        moreLikeThisQueryBuilder.unlikeTexts = in.readStringArray();
         moreLikeThisQueryBuilder.unlikeItems = readItems(in);
         moreLikeThisQueryBuilder.maxQueryTerms = in.readVInt();
         moreLikeThisQueryBuilder.minTermFreq = in.readVInt();
@@ -976,21 +946,21 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         return moreLikeThisQueryBuilder;
     }
 
-    private static List<Item> readItems(StreamInput in) throws IOException {
-        List<Item> items = new ArrayList<>();
+    private static Item[] readItems(StreamInput in) throws IOException {
         int size = in.readVInt();
+        Item[] items = new Item[size];
         for (int i = 0; i < size; i++) {
-            items.add(Item.readItemFrom(in));
+            items[i] = Item.readItemFrom(in);
         }
         return items;
     }
 
     @Override
     protected void doWriteTo(StreamOutput out) throws IOException {
-        out.writeGenericValue(fields);
-        out.writeGenericValue(likeTexts);
-        out.writeGenericValue(unlikeTexts);
+        out.writeOptionalStringArray(fields);
+        out.writeStringArray(likeTexts);
         writeItems(likeItems, out);
+        out.writeStringArray(unlikeTexts);
         writeItems(unlikeItems, out);
         out.writeVInt(maxQueryTerms);
         out.writeVInt(minTermFreq);
@@ -1006,8 +976,8 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
         out.writeBoolean(failOnUnsupportedField);
     }
 
-    private static void writeItems(List<Item> items, StreamOutput out) throws IOException {
-        out.writeVInt(items.size());
+    private static void writeItems(Item[] items, StreamOutput out) throws IOException {
+        out.writeVInt(items.length);
         for (Item item : items) {
             item.writeTo(out);
         }
@@ -1015,18 +985,19 @@ public class MoreLikeThisQueryBuilder extends AbstractQueryBuilder<MoreLikeThisQ
 
     @Override
     protected int doHashCode() {
-        return Objects.hash(fields, likeTexts, unlikeTexts, likeItems, unlikeItems, maxQueryTerms, minTermFreq,
-                minDocFreq, maxDocFreq, minWordLength, maxWordLength, Arrays.hashCode(stopWords), analyzer, minimumShouldMatch,
-                boostTerms, include, failOnUnsupportedField);
+        return Objects.hash(Arrays.hashCode(fields), Arrays.hashCode(likeTexts),
+                Arrays.hashCode(unlikeTexts), Arrays.hashCode(likeItems), Arrays.hashCode(unlikeItems),
+                maxQueryTerms, minTermFreq, minDocFreq, maxDocFreq, minWordLength, maxWordLength,
+                Arrays.hashCode(stopWords), analyzer, minimumShouldMatch, boostTerms, include, failOnUnsupportedField);
     }
 
     @Override
     protected boolean doEquals(MoreLikeThisQueryBuilder other) {
-        return Objects.equals(fields, other.fields) &&
-                Objects.equals(likeTexts, other.likeTexts) &&
-                Objects.equals(unlikeTexts, other.unlikeTexts) &&
-                Objects.equals(likeItems, other.likeItems) &&
-                Objects.equals(unlikeItems, other.unlikeItems) &&
+        return Arrays.equals(fields, other.fields) &&
+                Arrays.equals(likeTexts, other.likeTexts) &&
+                Arrays.equals(unlikeTexts, other.unlikeTexts) &&
+                Arrays.equals(likeItems, other.likeItems) &&
+                Arrays.equals(unlikeItems, other.unlikeItems) &&
                 Objects.equals(maxQueryTerms, other.maxQueryTerms) &&
                 Objects.equals(minTermFreq, other.minTermFreq) &&
                 Objects.equals(minDocFreq, other.minDocFreq) &&
diff --git a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
index c925a59..41dc904 100644
--- a/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/MoreLikeThisQueryParser.java
@@ -187,11 +187,15 @@ public class MoreLikeThisQueryParser extends BaseQueryParser<MoreLikeThisQueryBu
             throw new ParsingException(parser.getTokenLocation(), "more_like_this requires 'fields' to be non-empty");
         }
 
-        MoreLikeThisQueryBuilder moreLikeThisQueryBuilder = new MoreLikeThisQueryBuilder(fields)
-                .like(likeTexts.toArray(new String[likeTexts.size()]))
-                .unlike(unlikeTexts.toArray(new String[unlikeTexts.size()]))
-                .like(likeItems.toArray(new Item[likeItems.size()]))
-                .unlike(unlikeItems.toArray(new Item[unlikeItems.size()]))
+        String[] fieldsArray = fields == null ? null : fields.toArray(new String[fields.size()]);
+        String[] likeTextsArray = likeTexts.isEmpty() ? null : likeTexts.toArray(new String[likeTexts.size()]);
+        String[] unlikeTextsArray = unlikeTexts.isEmpty() ? null : unlikeTexts.toArray(new String[unlikeTexts.size()]);
+        Item[] likeItemsArray = likeItems.isEmpty() ? null : likeItems.toArray(new Item[likeItems.size()]);
+        Item[] unlikeItemsArray = unlikeItems.isEmpty() ? null : unlikeItems.toArray(new Item[unlikeItems.size()]);
+
+        MoreLikeThisQueryBuilder moreLikeThisQueryBuilder = new MoreLikeThisQueryBuilder(fieldsArray, likeTextsArray, likeItemsArray)
+                .unlike(unlikeTextsArray)
+                .unlike(unlikeItemsArray)
                 .maxQueryTerms(maxQueryTerms)
                 .minTermFreq(minTermFreq)
                 .minDocFreq(minDocFreq)
diff --git a/core/src/main/java/org/elasticsearch/index/query/Operator.java b/core/src/main/java/org/elasticsearch/index/query/Operator.java
index 22b5469..78f7fc8 100644
--- a/core/src/main/java/org/elasticsearch/index/query/Operator.java
+++ b/core/src/main/java/org/elasticsearch/index/query/Operator.java
@@ -26,6 +26,7 @@ import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.common.util.CollectionUtils;
 
 import java.io.IOException;
+import java.util.Locale;
 
 public enum Operator implements Writeable<Operator> {
     OR, AND;
@@ -56,7 +57,11 @@ public enum Operator implements Writeable<Operator> {
 
     @Override
     public Operator readFrom(StreamInput in) throws IOException {
-        return Operator.values()[in.readVInt()];
+        int ordinal = in.readVInt();
+        if (ordinal < 0 || ordinal >= values().length) {
+            throw new IOException("Unknown Operator ordinal [" + ordinal + "]");
+        }
+        return values()[ordinal];
     }
 
     public static Operator readOperatorFrom(StreamInput in) throws IOException {
@@ -69,15 +74,10 @@ public enum Operator implements Writeable<Operator> {
     }
 
     public static Operator fromString(String op) {
-        for (Operator operator : Operator.values()) {
-            if (operator.name().equalsIgnoreCase(op)) {
-                return operator;
-            }
-        }
-        throw Operator.newOperatorException(op);
+        return valueOf(op.toUpperCase(Locale.ROOT));
     }
 
     private static IllegalArgumentException newOperatorException(String op) {
-        return new IllegalArgumentException("operator needs to be either " + CollectionUtils.arrayAsArrayList(Operator.values()) + ", but not [" + op + "]");
+        return new IllegalArgumentException("operator needs to be either " + CollectionUtils.arrayAsArrayList(values()) + ", but not [" + op + "]");
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java b/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
index 42014a5..df823e1 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
@@ -24,6 +24,7 @@ import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.geo.ShapeRelation;
 import org.elasticsearch.common.geo.builders.ShapeBuilder;
+import org.elasticsearch.index.query.MoreLikeThisQueryBuilder.Item;
 import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
 import org.elasticsearch.index.search.MatchQuery;
@@ -372,19 +373,34 @@ public abstract class QueryBuilders {
     }
 
     /**
-     * A query that allows to define a custom scoring function.
+     * A function_score query with no functions.
      *
      * @param queryBuilder The query to custom score
+     * @return the function score query
      */
     public static FunctionScoreQueryBuilder functionScoreQuery(QueryBuilder queryBuilder) {
         return new FunctionScoreQueryBuilder(queryBuilder);
     }
 
     /**
-     * A query that allows to define a custom scoring function.
+     * A query that allows to define a custom scoring function
+     *
+     * @param queryBuilder The query to custom score
+     * @param filterFunctionBuilders the filters and functions to execute
+     * @return the function score query
+     */
+    public static FunctionScoreQueryBuilder functionScoreQuery(QueryBuilder queryBuilder, FunctionScoreQueryBuilder.FilterFunctionBuilder[] filterFunctionBuilders) {
+        return new FunctionScoreQueryBuilder(queryBuilder, filterFunctionBuilders);
+    }
+
+    /**
+     * A query that allows to define a custom scoring function
+     *
+     * @param filterFunctionBuilders the filters and functions to execute
+     * @return the function score query
      */
-    public static FunctionScoreQueryBuilder functionScoreQuery() {
-        return new FunctionScoreQueryBuilder();
+    public static FunctionScoreQueryBuilder functionScoreQuery(FunctionScoreQueryBuilder.FilterFunctionBuilder[] filterFunctionBuilders) {
+        return new FunctionScoreQueryBuilder(filterFunctionBuilders);
     }
 
     /**
@@ -403,25 +419,47 @@ public abstract class QueryBuilders {
      * @param function     The function builder used to custom score
      */
     public static FunctionScoreQueryBuilder functionScoreQuery(QueryBuilder queryBuilder, ScoreFunctionBuilder function) {
-        return (new FunctionScoreQueryBuilder(queryBuilder)).add(function);
+        return (new FunctionScoreQueryBuilder(queryBuilder, function));
     }
 
     /**
-     * A more like this query that finds documents that are "like" the provided {@link MoreLikeThisQueryBuilder#likeText(String)}
+     * A more like this query that finds documents that are "like" the provided texts or documents
      * which is checked against the fields the query is constructed with.
      *
-     * @param fields The fields to run the query against
+     * @param fields the field names that will be used when generating the 'More Like This' query.
+     * @param likeTexts the text to use when generating the 'More Like This' query.
+     * @param likeItems the documents to use when generating the 'More Like This' query.
+     */
+    public static MoreLikeThisQueryBuilder moreLikeThisQuery(String[] fields, String[] likeTexts, Item[] likeItems) {
+        return new MoreLikeThisQueryBuilder(fields, likeTexts, likeItems);
+    }
+
+    /**
+     * A more like this query that finds documents that are "like" the provided texts or documents
+     * which is checked against the "_all" field.
+     * @param likeTexts the text to use when generating the 'More Like This' query.
+     * @param likeItems the documents to use when generating the 'More Like This' query.
+     */
+    public static MoreLikeThisQueryBuilder moreLikeThisQuery(String[] likeTexts, Item[] likeItems) {
+        return moreLikeThisQuery(null, likeTexts, likeItems);
+    }
+
+    /**
+     * A more like this query that finds documents that are "like" the provided texts
+     * which is checked against the "_all" field.
+     * @param likeTexts the text to use when generating the 'More Like This' query.
      */
-    public static MoreLikeThisQueryBuilder moreLikeThisQuery(String... fields) {
-        return new MoreLikeThisQueryBuilder(fields);
+    public static MoreLikeThisQueryBuilder moreLikeThisQuery(String[] likeTexts) {
+        return moreLikeThisQuery(null, likeTexts, null);
     }
 
     /**
-     * A more like this query that finds documents that are "like" the provided {@link MoreLikeThisQueryBuilder#likeText(String)}
+     * A more like this query that finds documents that are "like" the provided documents
      * which is checked against the "_all" field.
+     * @param likeItems the documents to use when generating the 'More Like This' query.
      */
-    public static MoreLikeThisQueryBuilder moreLikeThisQuery() {
-        return new MoreLikeThisQueryBuilder();
+    public static MoreLikeThisQueryBuilder moreLikeThisQuery(Item[] likeItems) {
+        return moreLikeThisQuery(null, null, likeItems);
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java b/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
index 6dd2e49..38d27f3 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
@@ -110,7 +110,9 @@ public class QueryShardContext {
     }
 
     public void parseFieldMatcher(ParseFieldMatcher parseFieldMatcher) {
+        //norelease ParseFieldMatcher is currently duplicated, this should be cleaned up
         this.parseFieldMatcher = parseFieldMatcher;
+        this.parseContext.parseFieldMatcher(parseFieldMatcher);
     }
 
     public ParseFieldMatcher parseFieldMatcher() {
@@ -119,7 +121,7 @@ public class QueryShardContext {
 
     public void reset() {
         allowUnmappedFields = indexQueryParser.defaultAllowUnmappedFields();
-        this.parseFieldMatcher = ParseFieldMatcher.EMPTY;
+        this.parseFieldMatcher(ParseFieldMatcher.EMPTY);
         this.lookup = null;
         this.namedQueries.clear();
         this.nestedScope = new NestedScope();
diff --git a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
index 9869bf7..e08f704 100644
--- a/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/TemplateQueryParser.java
@@ -18,26 +18,17 @@
  */
 package org.elasticsearch.index.query;
 
-import org.elasticsearch.ElasticsearchParseException;
-import org.elasticsearch.common.HasContextAndHeaders;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.ParsingException;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.lease.Releasables;
-import org.elasticsearch.common.xcontent.XContent;
-import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.script.*;
-import org.elasticsearch.script.mustache.MustacheScriptEngineService;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
+import org.elasticsearch.script.ScriptService;
+import org.elasticsearch.script.Template;
 
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
 
-import static org.elasticsearch.common.Strings.hasLength;
-
 /**
  * In the simplest case, parse template string and variables from the request,
  * compile the template and execute the template against the given variables.
@@ -100,6 +91,4 @@ public class TemplateQueryParser extends BaseQueryParser<TemplateQueryBuilder> {
     public TemplateQueryBuilder getBuilderPrototype() {
         return TemplateQueryBuilder.PROTOTYPE;
     }
-
-
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunction.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunction.java
index 44e3763..85d755c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunction.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunction.java
@@ -32,9 +32,9 @@ import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionParse
 
 public interface DecayFunction {
 
-    public double evaluate(double value, double scale);
+    double evaluate(double value, double scale);
 
-    public Explanation explainFunction(String valueString, double value, double scale);
+    Explanation explainFunction(String valueString, double value, double scale);
 
     /**
      * The final scale parameter is computed from the scale parameter given by
@@ -49,6 +49,5 @@ public interface DecayFunction {
      *            the value which decay function should take once the distance
      *            reaches this scale
      * */
-    public double processScale(double scale, double decay);
-
+    double processScale(double scale, double decay);
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionBuilder.java
index 96aabb2..8302b87 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionBuilder.java
@@ -19,73 +19,515 @@
 
 package org.elasticsearch.index.query.functionscore;
 
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.search.Explanation;
+import org.elasticsearch.ElasticsearchParseException;
+import org.elasticsearch.common.ParsingException;
+import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.common.geo.GeoDistance;
+import org.elasticsearch.common.geo.GeoPoint;
+import org.elasticsearch.common.geo.GeoUtils;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.lucene.search.function.CombineFunction;
+import org.elasticsearch.common.lucene.search.function.LeafScoreFunction;
+import org.elasticsearch.common.lucene.search.function.ScoreFunction;
+import org.elasticsearch.common.unit.DistanceUnit;
+import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.fielddata.*;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.mapper.core.DateFieldMapper;
+import org.elasticsearch.index.mapper.core.NumberFieldMapper;
+import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
+import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.search.MultiValueMode;
 
 import java.io.IOException;
-import java.util.Locale;
+import java.util.Objects;
 
-public abstract class DecayFunctionBuilder extends ScoreFunctionBuilder {
+public abstract class DecayFunctionBuilder<DFB extends DecayFunctionBuilder> extends ScoreFunctionBuilder<DFB> {
 
     protected static final String ORIGIN = "origin";
     protected static final String SCALE = "scale";
     protected static final String DECAY = "decay";
     protected static final String OFFSET = "offset";
 
-    private String fieldName;
-    private Object origin;
-    private Object scale;
-    private double decay = -1;
-    private Object offset;
-    private MultiValueMode multiValueMode = null;
+    public static double DEFAULT_DECAY = 0.5;
+    public static MultiValueMode DEFAULT_MULTI_VALUE_MODE = MultiValueMode.MIN;
 
-    public DecayFunctionBuilder(String fieldName, Object origin, Object scale) {
-        this.fieldName = fieldName;
-        this.origin = origin;
-        this.scale = scale;
+    private final String fieldName;
+    //parsing of origin, scale, offset and decay depends on the field type, delayed to the data node that has the mapping for it
+    private final BytesReference functionBytes;
+    private MultiValueMode multiValueMode = DEFAULT_MULTI_VALUE_MODE;
+
+    protected DecayFunctionBuilder(String fieldName, Object origin, Object scale, Object offset) {
+        this(fieldName, origin, scale, offset, DEFAULT_DECAY);
     }
 
-    public DecayFunctionBuilder setDecay(double decay) {
+    protected DecayFunctionBuilder(String fieldName, Object origin, Object scale, Object offset, double decay) {
+        if (fieldName == null) {
+            throw new IllegalArgumentException("decay function: field name must not be null");
+        }
+        if (scale == null) {
+            throw new IllegalArgumentException("decay function: scale must not be null");
+        }
         if (decay <= 0 || decay >= 1.0) {
-            throw new IllegalStateException("scale weight parameter must be in range 0..1!");
+            throw new IllegalStateException("decay function: decay must be in range 0..1!");
+        }
+        this.fieldName = fieldName;
+        try {
+            XContentBuilder builder = XContentFactory.jsonBuilder();
+            builder.startObject();
+            if (origin != null) {
+                builder.field(ORIGIN, origin);
+            }
+            builder.field(SCALE, scale);
+            if (offset != null) {
+                builder.field(OFFSET, offset);
+            }
+            builder.field(DECAY, decay);
+            builder.endObject();
+            this.functionBytes = builder.bytes();
+        } catch (IOException e) {
+            throw new IllegalArgumentException("unable to build inner function object",e);
         }
-        this.decay = decay;
-        return this;
     }
 
-    public DecayFunctionBuilder setOffset(Object offset) {
-        this.offset = offset;
-        return this;
+    protected DecayFunctionBuilder(String fieldName, BytesReference functionBytes) {
+        if (fieldName == null) {
+            throw new IllegalArgumentException("decay function: field name must not be null");
+        }
+        if (functionBytes == null) {
+            throw new IllegalArgumentException("decay function: function must not be null");
+        }
+        this.fieldName = fieldName;
+        this.functionBytes = functionBytes;
+    }
+
+    public String getFieldName() {
+        return this.fieldName;
+    }
+
+    public BytesReference getFunctionBytes() {
+        return this.functionBytes;
     }
 
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject(getName());
-        builder.startObject(fieldName);
-        if (origin != null) {
-            builder.field(ORIGIN, origin);
-        }
-        builder.field(SCALE, scale);
-        if (decay > 0) {
-            builder.field(DECAY, decay);
-        }
-        if (offset != null) {
-            builder.field(OFFSET, offset);
-        }
-        builder.endObject();
-        if (multiValueMode != null) {
-            builder.field(DecayFunctionParser.MULTI_VALUE_MODE.getPreferredName(), multiValueMode.name());
-        }
+        builder.field(fieldName);
+        XContentParser parser = XContentFactory.xContent(functionBytes).createParser(functionBytes);
+        builder.copyCurrentStructure(parser);
+        builder.field(DecayFunctionParser.MULTI_VALUE_MODE.getPreferredName(), multiValueMode.name());
         builder.endObject();
     }
 
     public ScoreFunctionBuilder setMultiValueMode(MultiValueMode multiValueMode) {
+        if (multiValueMode == null) {
+            throw new IllegalArgumentException("decay function: multi_value_mode must not be null");
+        }
         this.multiValueMode = multiValueMode;
         return this;
     }
 
-    public ScoreFunctionBuilder setMultiValueMode(String multiValueMode) {
-        this.multiValueMode = MultiValueMode.fromString(multiValueMode.toUpperCase(Locale.ROOT));
-        return this;
+    public MultiValueMode getMultiValueMode() {
+        return this.multiValueMode;
+    }
+
+    @Override
+    protected DFB doReadFrom(StreamInput in) throws IOException {
+        DFB decayFunctionBuilder = createFunctionBuilder(in.readString(), in.readBytesReference());
+        decayFunctionBuilder.setMultiValueMode(MultiValueMode.readMultiValueModeFrom(in));
+        return decayFunctionBuilder;
+    }
+
+    protected abstract DFB createFunctionBuilder(String fieldName, BytesReference functionBytes);
+
+    @Override
+    protected void doWriteTo(StreamOutput out) throws IOException {
+        out.writeString(fieldName);
+        out.writeBytesReference(functionBytes);
+        multiValueMode.writeTo(out);
+    }
+
+    @Override
+    protected boolean doEquals(DFB functionBuilder) {
+        return Objects.equals(this.fieldName, functionBuilder.getFieldName()) &&
+                Objects.equals(this.functionBytes, functionBuilder.getFunctionBytes()) &&
+                Objects.equals(this.multiValueMode, functionBuilder.getMultiValueMode());
+    }
+
+    @Override
+    protected int doHashCode() {
+        return Objects.hash(this.fieldName, this.functionBytes, this.multiValueMode);
+    }
+
+    @Override
+    protected ScoreFunction doToFunction(QueryShardContext context) throws IOException {
+        XContentParser parser = XContentFactory.xContent(functionBytes).createParser(functionBytes);
+        return parseVariable(fieldName, parser, context, multiValueMode);
+    }
+
+    /**
+     * Override this function if you want to produce your own scorer.
+     * */
+    protected abstract DecayFunction getDecayFunction();
+
+    private AbstractDistanceScoreFunction parseVariable(String fieldName, XContentParser parser, QueryShardContext context, MultiValueMode mode) throws IOException {
+        //the field must exist, else we cannot read the value for the doc later
+        MappedFieldType fieldType = context.fieldMapper(fieldName);
+        if (fieldType == null) {
+            throw new ParsingException(parser.getTokenLocation(), "unknown field [{}]", fieldName);
+        }
+
+        // dates and time need special handling
+        parser.nextToken();
+        if (fieldType instanceof DateFieldMapper.DateFieldType) {
+            return parseDateVariable(parser, context, (DateFieldMapper.DateFieldType) fieldType, mode);
+        } else if (fieldType instanceof GeoPointFieldMapper.GeoPointFieldType) {
+            return parseGeoVariable(parser, context, (GeoPointFieldMapper.GeoPointFieldType) fieldType, mode);
+        } else if (fieldType instanceof NumberFieldMapper.NumberFieldType) {
+            return parseNumberVariable(parser, context, (NumberFieldMapper.NumberFieldType) fieldType, mode);
+        } else {
+            throw new ParsingException(parser.getTokenLocation(), "field [{}] is of type [{}], but only numeric types are supported.", fieldName, fieldType);
+        }
+    }
+
+    private AbstractDistanceScoreFunction parseNumberVariable(XContentParser parser, QueryShardContext context,
+                                                              NumberFieldMapper.NumberFieldType fieldType, MultiValueMode mode) throws IOException {
+        XContentParser.Token token;
+        String parameterName = null;
+        double scale = 0;
+        double origin = 0;
+        double decay = 0.5;
+        double offset = 0.0d;
+        boolean scaleFound = false;
+        boolean refFound = false;
+        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
+            if (token == XContentParser.Token.FIELD_NAME) {
+                parameterName = parser.currentName();
+            } else if (DecayFunctionBuilder.SCALE.equals(parameterName)) {
+                scale = parser.doubleValue();
+                scaleFound = true;
+            } else if (DecayFunctionBuilder.DECAY.equals(parameterName)) {
+                decay = parser.doubleValue();
+            } else if (DecayFunctionBuilder.ORIGIN.equals(parameterName)) {
+                origin = parser.doubleValue();
+                refFound = true;
+            } else if (DecayFunctionBuilder.OFFSET.equals(parameterName)) {
+                offset = parser.doubleValue();
+            } else {
+                throw new ElasticsearchParseException("parameter [{}] not supported!", parameterName);
+            }
+        }
+        if (!scaleFound || !refFound) {
+            throw new ElasticsearchParseException("both [{}] and [{}] must be set for numeric fields.", DecayFunctionBuilder.SCALE, DecayFunctionBuilder.ORIGIN);
+        }
+        IndexNumericFieldData numericFieldData = context.getForField(fieldType);
+        return new NumericFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), numericFieldData, mode);
+    }
+
+    private AbstractDistanceScoreFunction parseGeoVariable(XContentParser parser, QueryShardContext context,
+                                                           GeoPointFieldMapper.GeoPointFieldType fieldType, MultiValueMode mode) throws IOException {
+        XContentParser.Token token;
+        String parameterName = null;
+        GeoPoint origin = new GeoPoint();
+        String scaleString = null;
+        String offsetString = "0km";
+        double decay = 0.5;
+        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
+            if (token == XContentParser.Token.FIELD_NAME) {
+                parameterName = parser.currentName();
+            } else if (DecayFunctionBuilder.SCALE.equals(parameterName)) {
+                scaleString = parser.text();
+            } else if (DecayFunctionBuilder.ORIGIN.equals(parameterName)) {
+                origin = GeoUtils.parseGeoPoint(parser);
+            } else if (DecayFunctionBuilder.DECAY.equals(parameterName)) {
+                decay = parser.doubleValue();
+            } else if (DecayFunctionBuilder.OFFSET.equals(parameterName)) {
+                offsetString = parser.text();
+            } else {
+                throw new ElasticsearchParseException("parameter [{}] not supported!", parameterName);
+            }
+        }
+        if (origin == null || scaleString == null) {
+            throw new ElasticsearchParseException("[{}] and [{}] must be set for geo fields.", DecayFunctionBuilder.ORIGIN, DecayFunctionBuilder.SCALE);
+        }
+        double scale = DistanceUnit.DEFAULT.parse(scaleString, DistanceUnit.DEFAULT);
+        double offset = DistanceUnit.DEFAULT.parse(offsetString, DistanceUnit.DEFAULT);
+        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
+        return new GeoFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), indexFieldData, mode);
+
+    }
+
+    private AbstractDistanceScoreFunction parseDateVariable(XContentParser parser, QueryShardContext context,
+                                                            DateFieldMapper.DateFieldType dateFieldType, MultiValueMode mode) throws IOException {
+        XContentParser.Token token;
+        String parameterName = null;
+        String scaleString = null;
+        String originString = null;
+        String offsetString = "0d";
+        double decay = 0.5;
+        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
+            if (token == XContentParser.Token.FIELD_NAME) {
+                parameterName = parser.currentName();
+            } else if (DecayFunctionBuilder.SCALE.equals(parameterName)) {
+                scaleString = parser.text();
+            } else if (DecayFunctionBuilder.ORIGIN.equals(parameterName)) {
+                originString = parser.text();
+            } else if (DecayFunctionBuilder.DECAY.equals(parameterName)) {
+                decay = parser.doubleValue();
+            } else if (DecayFunctionBuilder.OFFSET.equals(parameterName)) {
+                offsetString = parser.text();
+            } else {
+                throw new ElasticsearchParseException("parameter [{}] not supported!", parameterName);
+            }
+        }
+        long origin;
+        if (originString == null) {
+            origin = context.nowInMillis();
+        } else {
+            origin = dateFieldType.parseToMilliseconds(originString, false, null, null);
+        }
+
+        if (scaleString == null) {
+            throw new ElasticsearchParseException("[{}] must be set for date fields.", DecayFunctionBuilder.SCALE);
+        }
+        TimeValue val = TimeValue.parseTimeValue(scaleString, TimeValue.timeValueHours(24), DecayFunctionParser.class.getSimpleName() + ".scale");
+        double scale = val.getMillis();
+        val = TimeValue.parseTimeValue(offsetString, TimeValue.timeValueHours(24), DecayFunctionParser.class.getSimpleName() + ".offset");
+        double offset = val.getMillis();
+        IndexNumericFieldData numericFieldData = context.getForField(dateFieldType);
+        return new NumericFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), numericFieldData, mode);
+    }
+
+    static class GeoFieldDataScoreFunction extends AbstractDistanceScoreFunction {
+
+        private final GeoPoint origin;
+        private final IndexGeoPointFieldData fieldData;
+
+        private static final GeoDistance distFunction = GeoDistance.DEFAULT;
+
+        public GeoFieldDataScoreFunction(GeoPoint origin, double scale, double decay, double offset, DecayFunction func,
+                                         IndexGeoPointFieldData fieldData, MultiValueMode mode) {
+            super(scale, decay, offset, func, mode);
+            this.origin = origin;
+            this.fieldData = fieldData;
+        }
+
+        @Override
+        public boolean needsScores() {
+            return false;
+        }
+
+        @Override
+        protected NumericDoubleValues distance(LeafReaderContext context) {
+            final MultiGeoPointValues geoPointValues = fieldData.load(context).getGeoPointValues();
+            return mode.select(new MultiValueMode.UnsortedNumericDoubleValues() {
+                @Override
+                public int count() {
+                    return geoPointValues.count();
+                }
+
+                @Override
+                public void setDocument(int docId) {
+                    geoPointValues.setDocument(docId);
+                }
+
+                @Override
+                public double valueAt(int index) {
+                    GeoPoint other = geoPointValues.valueAt(index);
+                    return Math.max(0.0d, distFunction.calculate(origin.lat(), origin.lon(), other.lat(), other.lon(), DistanceUnit.METERS) - offset);
+                }
+            }, 0.0);
+        }
+
+        @Override
+        protected String getDistanceString(LeafReaderContext ctx, int docId) {
+            StringBuilder values = new StringBuilder(mode.name());
+            values.append(" of: [");
+            final MultiGeoPointValues geoPointValues = fieldData.load(ctx).getGeoPointValues();
+            geoPointValues.setDocument(docId);
+            final int num = geoPointValues.count();
+            if (num > 0) {
+                for (int i = 0; i < num; i++) {
+                    GeoPoint value = geoPointValues.valueAt(i);
+                    values.append("Math.max(arcDistance(");
+                    values.append(value).append("(=doc value),").append(origin).append("(=origin)) - ").append(offset).append("(=offset), 0)");
+                    if (i != num - 1) {
+                        values.append(", ");
+                    }
+                }
+            } else {
+                values.append("0.0");
+            }
+            values.append("]");
+            return values.toString();
+        }
+
+        @Override
+        protected String getFieldName() {
+            return fieldData.getFieldNames().fullName();
+        }
+
+        @Override
+        protected boolean doEquals(ScoreFunction other) {
+            GeoFieldDataScoreFunction geoFieldDataScoreFunction = (GeoFieldDataScoreFunction) other;
+            return super.doEquals(other) &&
+                    Objects.equals(this.origin, geoFieldDataScoreFunction.origin);
+        }
+    }
+
+    static class NumericFieldDataScoreFunction extends AbstractDistanceScoreFunction {
+
+        private final IndexNumericFieldData fieldData;
+        private final double origin;
+
+        public NumericFieldDataScoreFunction(double origin, double scale, double decay, double offset, DecayFunction func,
+                                             IndexNumericFieldData fieldData, MultiValueMode mode) {
+            super(scale, decay, offset, func, mode);
+            this.fieldData = fieldData;
+            this.origin = origin;
+        }
+
+        @Override
+        public boolean needsScores() {
+            return false;
+        }
+
+        @Override
+        protected NumericDoubleValues distance(LeafReaderContext context) {
+            final SortedNumericDoubleValues doubleValues = fieldData.load(context).getDoubleValues();
+            return mode.select(new MultiValueMode.UnsortedNumericDoubleValues() {
+                @Override
+                public int count() {
+                    return doubleValues.count();
+                }
+
+                @Override
+                public void setDocument(int docId) {
+                    doubleValues.setDocument(docId);
+                }
+
+                @Override
+                public double valueAt(int index) {
+                    return Math.max(0.0d, Math.abs(doubleValues.valueAt(index) - origin) - offset);
+                }
+            }, 0.0);
+        }
+
+        @Override
+        protected String getDistanceString(LeafReaderContext ctx, int docId) {
+
+            StringBuilder values = new StringBuilder(mode.name());
+            values.append("[");
+            final SortedNumericDoubleValues doubleValues = fieldData.load(ctx).getDoubleValues();
+            doubleValues.setDocument(docId);
+            final int num = doubleValues.count();
+            if (num > 0) {
+                for (int i = 0; i < num; i++) {
+                    double value = doubleValues.valueAt(i);
+                    values.append("Math.max(Math.abs(");
+                    values.append(value).append("(=doc value) - ").append(origin).append("(=origin))) - ").append(offset).append("(=offset), 0)");
+                    if (i != num - 1) {
+                        values.append(", ");
+                    }
+                }
+            } else {
+                values.append("0.0");
+            }
+            values.append("]");
+            return values.toString();
+
+        }
+
+        @Override
+        protected String getFieldName() {
+            return fieldData.getFieldNames().fullName();
+        }
+
+        @Override
+        protected boolean doEquals(ScoreFunction other) {
+            NumericFieldDataScoreFunction numericFieldDataScoreFunction = (NumericFieldDataScoreFunction) other;
+            if (super.doEquals(other) == false) {
+                return false;
+            }
+            return Objects.equals(this.origin, numericFieldDataScoreFunction.origin);
+        }
+    }
+
+    /**
+     * This is the base class for scoring a single field.
+     *
+     * */
+    public static abstract class AbstractDistanceScoreFunction extends ScoreFunction {
+
+        private final double scale;
+        protected final double offset;
+        private final DecayFunction func;
+        protected final MultiValueMode mode;
+
+        public AbstractDistanceScoreFunction(double userSuppiedScale, double decay, double offset, DecayFunction func, MultiValueMode mode) {
+            super(CombineFunction.MULTIPLY);
+            this.mode = mode;
+            if (userSuppiedScale <= 0.0) {
+                throw new IllegalArgumentException(FunctionScoreQueryBuilder.NAME + " : scale must be > 0.0.");
+            }
+            if (decay <= 0.0 || decay >= 1.0) {
+                throw new IllegalArgumentException(FunctionScoreQueryBuilder.NAME
+                        + " : decay must be in the range [0..1].");
+            }
+            this.scale = func.processScale(userSuppiedScale, decay);
+            this.func = func;
+            if (offset < 0.0d) {
+                throw new IllegalArgumentException(FunctionScoreQueryBuilder.NAME + " : offset must be > 0.0");
+            }
+            this.offset = offset;
+        }
+
+        /**
+         * This function computes the distance from a defined origin. Since
+         * the value of the document is read from the index, it cannot be
+         * guaranteed that the value actually exists. If it does not, we assume
+         * the user handles this case in the query and return 0.
+         * */
+        protected abstract NumericDoubleValues distance(LeafReaderContext context);
+
+        @Override
+        public final LeafScoreFunction getLeafScoreFunction(final LeafReaderContext ctx) {
+            final NumericDoubleValues distance = distance(ctx);
+            return new LeafScoreFunction() {
+
+                @Override
+                public double score(int docId, float subQueryScore) {
+                    return func.evaluate(distance.get(docId), scale);
+                }
+
+                @Override
+                public Explanation explainScore(int docId, Explanation subQueryScore) throws IOException {
+                    return Explanation.match(
+                            CombineFunction.toFloat(score(docId, subQueryScore.getValue())),
+                            "Function for field " + getFieldName() + ":",
+                            func.explainFunction(getDistanceString(ctx, docId), distance.get(docId), scale));
+                }
+            };
+        }
+
+        protected abstract String getDistanceString(LeafReaderContext ctx, int docId);
+
+        protected abstract String getFieldName();
+
+        @Override
+        protected boolean doEquals(ScoreFunction other) {
+            AbstractDistanceScoreFunction distanceScoreFunction = (AbstractDistanceScoreFunction) other;
+            return Objects.equals(this.scale, distanceScoreFunction.scale) &&
+                    Objects.equals(this.offset, distanceScoreFunction.offset) &&
+                    Objects.equals(this.mode, distanceScoreFunction.mode) &&
+                    Objects.equals(this.func, distanceScoreFunction.func) &&
+                    Objects.equals(this.getFieldName(), distanceScoreFunction.getFieldName());
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
index f8f348b..1b4dbae 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/DecayFunctionParser.java
@@ -19,39 +19,20 @@
 
 package org.elasticsearch.index.query.functionscore;
 
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.Explanation;
-import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.ParseField;
-import org.elasticsearch.common.geo.GeoDistance;
-import org.elasticsearch.common.geo.GeoPoint;
-import org.elasticsearch.common.geo.GeoUtils;
-import org.elasticsearch.common.lucene.search.function.CombineFunction;
-import org.elasticsearch.common.lucene.search.function.LeafScoreFunction;
-import org.elasticsearch.common.lucene.search.function.ScoreFunction;
-import org.elasticsearch.common.unit.DistanceUnit;
-import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.fielddata.IndexGeoPointFieldData;
-import org.elasticsearch.index.fielddata.IndexNumericFieldData;
-import org.elasticsearch.index.fielddata.MultiGeoPointValues;
-import org.elasticsearch.index.fielddata.NumericDoubleValues;
-import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.core.DateFieldMapper;
-import org.elasticsearch.index.mapper.core.NumberFieldMapper;
-import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.common.ParsingException;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionBuilder;
 import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionParser;
 import org.elasticsearch.search.MultiValueMode;
-import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
-import java.util.Locale;
 
 /**
  * This class provides the basic functionality needed for adding a decay
@@ -65,8 +46,9 @@ import java.util.Locale;
  *      "fieldname1" : {
  *          "origin" = "someValue",
  *          "scale" = "someValue"
- *      }
- *
+ *      },
+ *      "multi_value_mode" : "min"
+ * }
  * </code>
  * </pre>
  *
@@ -84,396 +66,66 @@ import java.util.Locale;
  * parameters origin and scale.
  * <p>
  * To write a new scoring function, create a new class that inherits from this
- * one and implement the getDistanceFunction(). Furthermore, to create a builder,
- * override the getName() in {@link DecayFunctionBuilder}.
+ * one and implements {@link #getBuilderPrototype()} and {@link #getNames()}.
+ * Also create its corresponding {@link DecayFunctionBuilder}. The latter needs to
+ * implement {@link DecayFunctionBuilder#doReadFrom(StreamInput)} and
+ * {@link DecayFunctionBuilder#doWriteTo(StreamOutput)} for serialization purposes,
+ * {@link DecayFunctionBuilder#doEquals(DecayFunctionBuilder)} and
+ * {@link DecayFunctionBuilder#doHashCode()} for equality checks,
+ * {@link DecayFunctionBuilder#getName()} that returns the name of the function and
+ * {@link DecayFunctionBuilder#getDecayFunction()} which returns the corresponding lucene function.
  * <p>
  * See {@link GaussDecayFunctionBuilder} and {@link GaussDecayFunctionParser}
  * for an example. The parser furthermore needs to be registered in the
  * {@link org.elasticsearch.search.SearchModule SearchModule}.
  *
- * **/
+ */
 
-public abstract class DecayFunctionParser implements ScoreFunctionParser {
+public abstract class DecayFunctionParser<DFB extends DecayFunctionBuilder<DFB>> implements ScoreFunctionParser<DFB> {
 
     public static final ParseField MULTI_VALUE_MODE = new ParseField("multi_value_mode");
 
     /**
-     * Override this function if you want to produce your own scorer.
-     * */
-    public abstract DecayFunction getDecayFunction();
-
-    /**
      * Parses bodies of the kind
      *
      * <pre>
      * <code>
      * {
      *      "fieldname1" : {
-     *          "origin" = "someValue",
-     *          "scale" = "someValue"
-     *      }
-     *
+     *          "origin" : "someValue",
+     *          "scale" : "someValue"
+     *      },
+     *      "multi_value_mode" : "min"
      * }
      * </code>
      * </pre>
-     *
-     * */
+     */
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, ParsingException {
+    public DFB fromXContent(QueryParseContext context, XContentParser parser) throws IOException, ParsingException {
         String currentFieldName;
         XContentParser.Token token;
-        AbstractDistanceScoreFunction scoreFunction;
-        String multiValueMode = "MIN";
-        XContentBuilder variableContent = XContentFactory.jsonBuilder();
+        MultiValueMode multiValueMode = DecayFunctionBuilder.DEFAULT_MULTI_VALUE_MODE;
         String fieldName = null;
+        BytesReference functionBytes = null;
         while ((token = parser.nextToken()) == XContentParser.Token.FIELD_NAME) {
             currentFieldName = parser.currentName();
             token = parser.nextToken();
             if (token == XContentParser.Token.START_OBJECT) {
-                variableContent.copyCurrentStructure(parser);
                 fieldName = currentFieldName;
+                XContentBuilder builder = XContentFactory.jsonBuilder();
+                builder.copyCurrentStructure(parser);
+                functionBytes = builder.bytes();
             } else if (context.parseFieldMatcher().match(currentFieldName, MULTI_VALUE_MODE)) {
-                multiValueMode = parser.text();
-            } else {
-                throw new ElasticsearchParseException("malformed score function score parameters.");
-            }
-        }
-        if (fieldName == null) {
-            throw new ElasticsearchParseException("malformed score function score parameters.");
-        }
-        XContentParser variableParser = XContentFactory.xContent(variableContent.string()).createParser(variableContent.string());
-        scoreFunction = parseVariable(fieldName, variableParser, context, MultiValueMode.fromString(multiValueMode.toUpperCase(Locale.ROOT)));
-        return scoreFunction;
-    }
-
-    // parses origin and scale parameter for field "fieldName"
-    private AbstractDistanceScoreFunction parseVariable(String fieldName, XContentParser parser, QueryShardContext context, MultiValueMode mode) throws IOException {
-
-        // now, the field must exist, else we cannot read the value for
-        // the doc later
-        MappedFieldType fieldType = context.fieldMapper(fieldName);
-        if (fieldType == null) {
-            throw new ParsingException(context.parseContext().parser().getTokenLocation(), "unknown field [{}]", fieldName);
-        }
-
-        // dates and time need special handling
-        parser.nextToken();
-        if (fieldType instanceof DateFieldMapper.DateFieldType) {
-            return parseDateVariable(fieldName, parser, context, (DateFieldMapper.DateFieldType) fieldType, mode);
-        } else if (fieldType instanceof GeoPointFieldMapper.GeoPointFieldType) {
-            return parseGeoVariable(fieldName, parser, context, (GeoPointFieldMapper.GeoPointFieldType) fieldType, mode);
-        } else if (fieldType instanceof NumberFieldMapper.NumberFieldType) {
-            return parseNumberVariable(fieldName, parser, context, (NumberFieldMapper.NumberFieldType) fieldType, mode);
-        } else {
-            throw new ParsingException(context.parseContext().parser().getTokenLocation(), "field [{}] is of type [{}], but only numeric types are supported.", fieldName, fieldType);
-        }
-    }
-
-    private AbstractDistanceScoreFunction parseNumberVariable(String fieldName, XContentParser parser, QueryShardContext context,
-            NumberFieldMapper.NumberFieldType fieldType, MultiValueMode mode) throws IOException {
-        XContentParser.Token token;
-        String parameterName = null;
-        double scale = 0;
-        double origin = 0;
-        double decay = 0.5;
-        double offset = 0.0d;
-        boolean scaleFound = false;
-        boolean refFound = false;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                parameterName = parser.currentName();
-            } else if (parameterName.equals(DecayFunctionBuilder.SCALE)) {
-                scale = parser.doubleValue();
-                scaleFound = true;
-            } else if (parameterName.equals(DecayFunctionBuilder.DECAY)) {
-                decay = parser.doubleValue();
-            } else if (parameterName.equals(DecayFunctionBuilder.ORIGIN)) {
-                origin = parser.doubleValue();
-                refFound = true;
-            } else if (parameterName.equals(DecayFunctionBuilder.OFFSET)) {
-                offset = parser.doubleValue();
-            } else {
-                throw new ElasticsearchParseException("parameter [{}] not supported!", parameterName);
-            }
-        }
-        if (!scaleFound || !refFound) {
-            throw new ElasticsearchParseException("both [{}] and [{}] must be set for numeric fields.", DecayFunctionBuilder.SCALE, DecayFunctionBuilder.ORIGIN);
-        }
-        IndexNumericFieldData numericFieldData = context.getForField(fieldType);
-        return new NumericFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), numericFieldData, mode);
-    }
-
-    private AbstractDistanceScoreFunction parseGeoVariable(String fieldName, XContentParser parser, QueryShardContext context,
-            GeoPointFieldMapper.GeoPointFieldType fieldType, MultiValueMode mode) throws IOException {
-        XContentParser.Token token;
-        String parameterName = null;
-        GeoPoint origin = new GeoPoint();
-        String scaleString = null;
-        String offsetString = "0km";
-        double decay = 0.5;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                parameterName = parser.currentName();
-            } else if (parameterName.equals(DecayFunctionBuilder.SCALE)) {
-                scaleString = parser.text();
-            } else if (parameterName.equals(DecayFunctionBuilder.ORIGIN)) {
-                origin = GeoUtils.parseGeoPoint(parser);
-            } else if (parameterName.equals(DecayFunctionBuilder.DECAY)) {
-                decay = parser.doubleValue();
-            } else if (parameterName.equals(DecayFunctionBuilder.OFFSET)) {
-                offsetString = parser.text();
+                multiValueMode = MultiValueMode.fromString(parser.text());
             } else {
-                throw new ElasticsearchParseException("parameter [{}] not supported!", parameterName);
+                throw new ParsingException(parser.getTokenLocation(), "malformed score function score parameters.");
             }
         }
-        if (origin == null || scaleString == null) {
-            throw new ElasticsearchParseException("[{}] and [{}] must be set for geo fields.", DecayFunctionBuilder.ORIGIN, DecayFunctionBuilder.SCALE);
+        if (fieldName == null || functionBytes == null) {
+            throw new ParsingException(parser.getTokenLocation(), "malformed score function score parameters.");
         }
-        double scale = DistanceUnit.DEFAULT.parse(scaleString, DistanceUnit.DEFAULT);
-        double offset = DistanceUnit.DEFAULT.parse(offsetString, DistanceUnit.DEFAULT);
-        IndexGeoPointFieldData indexFieldData = context.getForField(fieldType);
-        return new GeoFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), indexFieldData, mode);
-
+        DFB functionBuilder = getBuilderPrototype().createFunctionBuilder(fieldName, functionBytes);
+        functionBuilder.setMultiValueMode(multiValueMode);
+        return functionBuilder;
     }
-
-    private AbstractDistanceScoreFunction parseDateVariable(String fieldName, XContentParser parser, QueryShardContext context,
-            DateFieldMapper.DateFieldType dateFieldType, MultiValueMode mode) throws IOException {
-        XContentParser.Token token;
-        String parameterName = null;
-        String scaleString = null;
-        String originString = null;
-        String offsetString = "0d";
-        double decay = 0.5;
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                parameterName = parser.currentName();
-            } else if (parameterName.equals(DecayFunctionBuilder.SCALE)) {
-                scaleString = parser.text();
-            } else if (parameterName.equals(DecayFunctionBuilder.ORIGIN)) {
-                originString = parser.text();
-            } else if (parameterName.equals(DecayFunctionBuilder.DECAY)) {
-                decay = parser.doubleValue();
-            } else if (parameterName.equals(DecayFunctionBuilder.OFFSET)) {
-                offsetString = parser.text();
-            } else {
-                throw new ElasticsearchParseException("parameter [{}] not supported!", parameterName);
-            }
-        }
-        long origin = SearchContext.current().nowInMillis();
-        if (originString != null) {
-            origin = dateFieldType.parseToMilliseconds(originString, false, null, null);
-        }
-
-        if (scaleString == null) {
-            throw new ElasticsearchParseException("[{}] must be set for date fields.", DecayFunctionBuilder.SCALE);
-        }
-        TimeValue val = TimeValue.parseTimeValue(scaleString, TimeValue.timeValueHours(24), getClass().getSimpleName() + ".scale");
-        double scale = val.getMillis();
-        val = TimeValue.parseTimeValue(offsetString, TimeValue.timeValueHours(24), getClass().getSimpleName() + ".offset");
-        double offset = val.getMillis();
-        IndexNumericFieldData numericFieldData = context.getForField(dateFieldType);
-        return new NumericFieldDataScoreFunction(origin, scale, decay, offset, getDecayFunction(), numericFieldData, mode);
-    }
-
-    static class GeoFieldDataScoreFunction extends AbstractDistanceScoreFunction {
-
-        private final GeoPoint origin;
-        private final IndexGeoPointFieldData fieldData;
-
-        private static final GeoDistance distFunction = GeoDistance.DEFAULT;
-
-        public GeoFieldDataScoreFunction(GeoPoint origin, double scale, double decay, double offset, DecayFunction func,
-                IndexGeoPointFieldData fieldData, MultiValueMode mode) {
-            super(scale, decay, offset, func, mode);
-            this.origin = origin;
-            this.fieldData = fieldData;
-        }
-
-        @Override
-        public boolean needsScores() {
-            return false;
-        }
-
-        @Override
-        protected NumericDoubleValues distance(LeafReaderContext context) {
-            final MultiGeoPointValues geoPointValues = fieldData.load(context).getGeoPointValues();
-            return mode.select(new MultiValueMode.UnsortedNumericDoubleValues() {
-                @Override
-                public int count() {
-                    return geoPointValues.count();
-                }
-
-                @Override
-                public void setDocument(int docId) {
-                    geoPointValues.setDocument(docId);
-                }
-
-                @Override
-                public double valueAt(int index) {
-                    GeoPoint other = geoPointValues.valueAt(index);
-                    return Math.max(0.0d, distFunction.calculate(origin.lat(), origin.lon(), other.lat(), other.lon(), DistanceUnit.METERS) - offset);
-                }
-            }, 0.0);
-        }
-
-        @Override
-        protected String getDistanceString(LeafReaderContext ctx, int docId) {
-            StringBuilder values = new StringBuilder(mode.name());
-            values.append(" of: [");
-            final MultiGeoPointValues geoPointValues = fieldData.load(ctx).getGeoPointValues();
-            geoPointValues.setDocument(docId);
-            final int num = geoPointValues.count();
-            if (num > 0) {
-                for (int i = 0; i < num; i++) {
-                    GeoPoint value = geoPointValues.valueAt(i);
-                    values.append("Math.max(arcDistance(");
-                    values.append(value).append("(=doc value),").append(origin).append("(=origin)) - ").append(offset).append("(=offset), 0)");
-                    if (i != num - 1) {
-                        values.append(", ");
-                    }
-                }
-            } else {
-                values.append("0.0");
-            }
-            values.append("]");
-            return values.toString();
-        }
-
-        @Override
-        protected String getFieldName() {
-            return fieldData.getFieldNames().fullName();
-        }
-    }
-
-    static class NumericFieldDataScoreFunction extends AbstractDistanceScoreFunction {
-
-        private final IndexNumericFieldData fieldData;
-        private final double origin;
-
-        public NumericFieldDataScoreFunction(double origin, double scale, double decay, double offset, DecayFunction func,
-                IndexNumericFieldData fieldData, MultiValueMode mode) {
-            super(scale, decay, offset, func, mode);
-            this.fieldData = fieldData;
-            this.origin = origin;
-        }
-
-        @Override
-        public boolean needsScores() {
-            return false;
-        }
-
-        @Override
-        protected NumericDoubleValues distance(LeafReaderContext context) {
-            final SortedNumericDoubleValues doubleValues = fieldData.load(context).getDoubleValues();
-            return mode.select(new MultiValueMode.UnsortedNumericDoubleValues() {
-                @Override
-                public int count() {
-                    return doubleValues.count();
-                }
-
-                @Override
-                public void setDocument(int docId) {
-                    doubleValues.setDocument(docId);
-                }
-
-                @Override
-                public double valueAt(int index) {
-                    return Math.max(0.0d, Math.abs(doubleValues.valueAt(index) - origin) - offset);
-                }
-            }, 0.0);
-        }
-
-        @Override
-        protected String getDistanceString(LeafReaderContext ctx, int docId) {
-
-            StringBuilder values = new StringBuilder(mode.name());
-            values.append("[");
-            final SortedNumericDoubleValues doubleValues = fieldData.load(ctx).getDoubleValues();
-            doubleValues.setDocument(docId);
-            final int num = doubleValues.count();
-            if (num > 0) {
-                for (int i = 0; i < num; i++) {
-                    double value = doubleValues.valueAt(i);
-                    values.append("Math.max(Math.abs(");
-                    values.append(value).append("(=doc value) - ").append(origin).append("(=origin))) - ").append(offset).append("(=offset), 0)");
-                    if (i != num - 1) {
-                        values.append(", ");
-                    }
-                }
-            } else {
-                values.append("0.0");
-            }
-            values.append("]");
-            return values.toString();
-
-        }
-
-        @Override
-        protected String getFieldName() {
-            return fieldData.getFieldNames().fullName();
-        }
-    }
-
-    /**
-     * This is the base class for scoring a single field.
-     *
-     * */
-    public static abstract class AbstractDistanceScoreFunction extends ScoreFunction {
-
-        private final double scale;
-        protected final double offset;
-        private final DecayFunction func;
-        protected final MultiValueMode mode;
-
-        public AbstractDistanceScoreFunction(double userSuppiedScale, double decay, double offset, DecayFunction func, MultiValueMode mode) {
-            super(CombineFunction.MULT);
-            this.mode = mode;
-            if (userSuppiedScale <= 0.0) {
-                throw new IllegalArgumentException(FunctionScoreQueryParser.NAME + " : scale must be > 0.0.");
-            }
-            if (decay <= 0.0 || decay >= 1.0) {
-                throw new IllegalArgumentException(FunctionScoreQueryParser.NAME
-                        + " : decay must be in the range [0..1].");
-            }
-            this.scale = func.processScale(userSuppiedScale, decay);
-            this.func = func;
-            if (offset < 0.0d) {
-                throw new IllegalArgumentException(FunctionScoreQueryParser.NAME + " : offset must be > 0.0");
-            }
-            this.offset = offset;
-        }
-
-        /**
-         * This function computes the distance from a defined origin. Since
-         * the value of the document is read from the index, it cannot be
-         * guaranteed that the value actually exists. If it does not, we assume
-         * the user handles this case in the query and return 0.
-         * */
-        protected abstract NumericDoubleValues distance(LeafReaderContext context);
-
-        @Override
-        public final LeafScoreFunction getLeafScoreFunction(final LeafReaderContext ctx) {
-            final NumericDoubleValues distance = distance(ctx);
-            return new LeafScoreFunction() {
-
-                @Override
-                public double score(int docId, float subQueryScore) {
-                    return func.evaluate(distance.get(docId), scale);
-                }
-
-                @Override
-                public Explanation explainScore(int docId, Explanation subQueryScore) throws IOException {
-                    return Explanation.match(
-                            CombineFunction.toFloat(score(docId, subQueryScore.getValue())),
-                            "Function for field " + getFieldName() + ":",
-                            func.explainFunction(getDistanceString(ctx, docId), distance.get(docId), scale));
-                }
-            };
-        }
-
-        protected abstract String getDistanceString(LeafReaderContext ctx, int docId);
-
-        protected abstract String getFieldName();
-    }
-
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
index e1726f9..d5c260f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilder.java
@@ -19,13 +19,24 @@
 
 package org.elasticsearch.index.query.functionscore;
 
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.Query;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.common.lucene.search.function.CombineFunction;
+import org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery;
+import org.elasticsearch.common.lucene.search.function.FunctionScoreQuery;
+import org.elasticsearch.common.lucene.search.function.ScoreFunction;
+import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.AbstractQueryBuilder;
-import org.elasticsearch.index.query.QueryBuilder;
+import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.functionscore.random.RandomScoreFunctionBuilder;
 
 import java.io.IOException;
-import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Locale;
+import java.util.Objects;
 
 /**
  * A query that uses a filters with a script associated with them to compute the
@@ -33,139 +44,169 @@ import java.util.ArrayList;
  */
 public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScoreQueryBuilder> {
 
-    private final QueryBuilder queryBuilder;
+    public static final String NAME = "function_score";
 
-    private Float maxBoost;
+    public static final CombineFunction DEFAULT_BOOST_MODE = CombineFunction.MULTIPLY;
+    public static final FiltersFunctionScoreQuery.ScoreMode DEFAULT_SCORE_MODE = FiltersFunctionScoreQuery.ScoreMode.MULTIPLY;
 
-    private String scoreMode;
+    private final QueryBuilder<?> query;
 
-    private String boostMode;
+    private float maxBoost = FunctionScoreQuery.DEFAULT_MAX_BOOST;
+
+    private FiltersFunctionScoreQuery.ScoreMode scoreMode = DEFAULT_SCORE_MODE;
+
+    private CombineFunction boostMode;
 
-    private ArrayList<QueryBuilder> filters = new ArrayList<>();
-    private ArrayList<ScoreFunctionBuilder> scoreFunctions = new ArrayList<>();
     private Float minScore = null;
 
-    static final FunctionScoreQueryBuilder PROTOTYPE = new FunctionScoreQueryBuilder();
+    private final FilterFunctionBuilder[] filterFunctionBuilders;
 
     /**
-     * Creates a function_score query that executes on documents that match query a query.
-     * Query and filter will be wrapped into a filtered_query.
+     * Creates a function_score query without functions
      *
-     * @param queryBuilder the query that defines which documents the function_score query will be executed on.
+     * @param query the query that needs to be custom scored
      */
-    public FunctionScoreQueryBuilder(QueryBuilder queryBuilder) {
-        this.queryBuilder = queryBuilder;
+    public FunctionScoreQueryBuilder(QueryBuilder<?> query) {
+        this(query, new FilterFunctionBuilder[0]);
     }
 
-    public FunctionScoreQueryBuilder() {
-        this.queryBuilder = null;
+    /**
+     * Creates a function_score query that executes the provided filters and functions on all documents
+     *
+     * @param filterFunctionBuilders the filters and functions
+     */
+    public FunctionScoreQueryBuilder(FilterFunctionBuilder[] filterFunctionBuilders) {
+        this(new MatchAllQueryBuilder(), filterFunctionBuilders);
     }
 
     /**
-     * Creates a function_score query that will execute the function scoreFunctionBuilder on all documents.
+     * Creates a function_score query that will execute the function provided on all documents
      *
      * @param scoreFunctionBuilder score function that is executed
      */
     public FunctionScoreQueryBuilder(ScoreFunctionBuilder scoreFunctionBuilder) {
-        if (scoreFunctionBuilder == null) {
-            throw new IllegalArgumentException("function_score: function must not be null");
-        }
-        queryBuilder = null;
-        this.filters.add(null);
-        this.scoreFunctions.add(scoreFunctionBuilder);
+        this(new MatchAllQueryBuilder(), new FilterFunctionBuilder[]{new FilterFunctionBuilder(scoreFunctionBuilder)});
     }
 
     /**
-     * Adds a score function that will will execute the function scoreFunctionBuilder on all documents matching the filter.
+     * Creates a function_score query that will execute the function provided in the context of the provided query
      *
-     * @param filter the filter that defines which documents the function_score query will be executed on.
+     * @param query the query to custom score
      * @param scoreFunctionBuilder score function that is executed
      */
-    public FunctionScoreQueryBuilder add(QueryBuilder filter, ScoreFunctionBuilder scoreFunctionBuilder) {
-        if (scoreFunctionBuilder == null) {
-            throw new IllegalArgumentException("function_score: function must not be null");
-        }
-        this.filters.add(filter);
-        this.scoreFunctions.add(scoreFunctionBuilder);
-        return this;
+    public FunctionScoreQueryBuilder(QueryBuilder<?> query, ScoreFunctionBuilder scoreFunctionBuilder) {
+        this(query, new FilterFunctionBuilder[]{new FilterFunctionBuilder(scoreFunctionBuilder)});
     }
 
     /**
-     * Adds a score function that will will execute the function scoreFunctionBuilder on all documents.
+     * Creates a function_score query that executes the provided filters and functions on documents that match a query.
      *
-     * @param scoreFunctionBuilder score function that is executed
+     * @param query the query that defines which documents the function_score query will be executed on.
+     * @param filterFunctionBuilders the filters and functions
      */
-    public FunctionScoreQueryBuilder add(ScoreFunctionBuilder scoreFunctionBuilder) {
-        if (scoreFunctionBuilder == null) {
-            throw new IllegalArgumentException("function_score: function must not be null");
+    public FunctionScoreQueryBuilder(QueryBuilder<?> query, FilterFunctionBuilder[] filterFunctionBuilders) {
+        if (query == null) {
+            throw new IllegalArgumentException("function_score: query must not be null");
         }
-        this.filters.add(null);
-        this.scoreFunctions.add(scoreFunctionBuilder);
-        return this;
+        if (filterFunctionBuilders == null) {
+            throw new IllegalArgumentException("function_score: filters and functions array must not be null");
+        }
+        for (FilterFunctionBuilder filterFunctionBuilder : filterFunctionBuilders) {
+            if (filterFunctionBuilder == null) {
+                throw new IllegalArgumentException("function_score: each filter and function must not be null");
+            }
+        }
+        this.query = query;
+        this.filterFunctionBuilders = filterFunctionBuilders;
+    }
+
+    /**
+     * Returns the query that defines which documents the function_score query will be executed on.
+     */
+    public QueryBuilder<?> query() {
+        return this.query;
+    }
+
+    /**
+     * Returns the filters and functions
+     */
+    public FilterFunctionBuilder[] filterFunctionBuilders() {
+        return this.filterFunctionBuilders;
     }
 
     /**
      * Score mode defines how results of individual score functions will be aggregated.
-     * Can be first, avg, max, sum, min, multiply
+     * @see org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery.ScoreMode
      */
-    public FunctionScoreQueryBuilder scoreMode(String scoreMode) {
+    public FunctionScoreQueryBuilder scoreMode(FiltersFunctionScoreQuery.ScoreMode scoreMode) {
+        if (scoreMode == null) {
+            throw new IllegalArgumentException("[" + NAME + "]  requires 'score_mode' field");
+        }
         this.scoreMode = scoreMode;
         return this;
     }
 
     /**
-     * Score mode defines how the combined result of score functions will influence the final score together with the sub query score.
-     * Can be replace, avg, max, sum, min, multiply
+     * Returns the score mode, meaning how results of individual score functions will be aggregated.
+     * @see org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery.ScoreMode
      */
-    public FunctionScoreQueryBuilder boostMode(String boostMode) {
-        this.boostMode = boostMode;
-        return this;
+    public FiltersFunctionScoreQuery.ScoreMode scoreMode() {
+        return this.scoreMode;
     }
 
     /**
-     * Score mode defines how the combined result of score functions will influence the final score together with the sub query score.
+     * Boost mode defines how the combined result of score functions will influence the final score together with the sub query score.
+     * @see CombineFunction
      */
     public FunctionScoreQueryBuilder boostMode(CombineFunction combineFunction) {
-        this.boostMode = combineFunction.getName();
+        if (combineFunction == null) {
+            throw new IllegalArgumentException("[" + NAME + "]  requires 'boost_mode' field");
+        }
+        this.boostMode = combineFunction;
         return this;
     }
 
     /**
-     * Tha maximum boost that will be applied by function score.
+     * Returns the boost mode, meaning how the combined result of score functions will influence the final score together with the sub query score.
+     * @see CombineFunction
+     */
+    public CombineFunction boostMode() {
+        return this.boostMode;
+    }
+
+    /**
+     * Sets the maximum boost that will be applied by function score.
      */
     public FunctionScoreQueryBuilder maxBoost(float maxBoost) {
         this.maxBoost = maxBoost;
         return this;
     }
 
+    /**
+     * Returns the maximum boost that will be applied by function score.
+     */
+    public float maxBoost() {
+        return this.maxBoost;
+    }
+
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(FunctionScoreQueryParser.NAME);
-        if (queryBuilder != null) {
+        builder.startObject(NAME);
+        if (query != null) {
             builder.field("query");
-            queryBuilder.toXContent(builder, params);
+            query.toXContent(builder, params);
         }
         builder.startArray("functions");
-        for (int i = 0; i < filters.size(); i++) {
-            builder.startObject();
-            if (filters.get(i) != null) {
-                builder.field("filter");
-                filters.get(i).toXContent(builder, params);
-            }
-            scoreFunctions.get(i).toXContent(builder, params);
-            builder.endObject();
+        for (FilterFunctionBuilder filterFunctionBuilder : filterFunctionBuilders) {
+            filterFunctionBuilder.toXContent(builder, params);
         }
         builder.endArray();
 
-        if (scoreMode != null) {
-            builder.field("score_mode", scoreMode);
-        }
+        builder.field("score_mode", scoreMode.name().toLowerCase(Locale.ROOT));
         if (boostMode != null) {
-            builder.field("boost_mode", boostMode);
-        }
-        if (maxBoost != null) {
-            builder.field("max_boost", maxBoost);
+            builder.field("boost_mode", boostMode.name().toLowerCase(Locale.ROOT));
         }
+        builder.field("max_boost", maxBoost);
         if (minScore != null) {
             builder.field("min_score", minScore);
         }
@@ -178,8 +219,175 @@ public class FunctionScoreQueryBuilder extends AbstractQueryBuilder<FunctionScor
         return this;
     }
 
+    public Float getMinScore() {
+        return this.minScore;
+    }
+
     @Override
     public String getWriteableName() {
-        return FunctionScoreQueryParser.NAME;
+        return FunctionScoreQueryBuilder.NAME;
+    }
+
+    @Override
+    protected boolean doEquals(FunctionScoreQueryBuilder other) {
+        return Objects.equals(this.query, other.query) &&
+                Arrays.equals(this.filterFunctionBuilders, other.filterFunctionBuilders) &&
+                Objects.equals(this.boostMode, other.boostMode) &&
+                Objects.equals(this.scoreMode, other.scoreMode) &&
+                Objects.equals(this.minScore, other.minScore) &&
+                Objects.equals(this.maxBoost, other.maxBoost);
+    }
+
+    @Override
+    protected int doHashCode() {
+        return Objects.hash(this.query, Arrays.hashCode(this.filterFunctionBuilders), this.boostMode, this.scoreMode, this.minScore, this.maxBoost);
+    }
+
+    @Override
+    protected FunctionScoreQueryBuilder doReadFrom(StreamInput in) throws IOException {
+        QueryBuilder<?> query = in.readQuery();
+        int size = in.readVInt();
+        FilterFunctionBuilder[] filterFunctionBuilders = new FilterFunctionBuilder[size];
+        for (int i = 0; i < size; i++) {
+            filterFunctionBuilders[i] = FilterFunctionBuilder.PROTOTYPE.readFrom(in);
+        }
+        FunctionScoreQueryBuilder functionScoreQueryBuilder = new FunctionScoreQueryBuilder(query, filterFunctionBuilders);
+        functionScoreQueryBuilder.maxBoost(in.readFloat());
+        if (in.readBoolean()) {
+            functionScoreQueryBuilder.setMinScore(in.readFloat());
+        }
+        if (in.readBoolean()) {
+            functionScoreQueryBuilder.boostMode(CombineFunction.readCombineFunctionFrom(in));
+        }
+        functionScoreQueryBuilder.scoreMode(FiltersFunctionScoreQuery.ScoreMode.readScoreModeFrom(in));
+        return functionScoreQueryBuilder;
+    }
+
+    @Override
+    protected void doWriteTo(StreamOutput out) throws IOException {
+        out.writeQuery(query);
+        out.writeVInt(filterFunctionBuilders.length);
+        for (FilterFunctionBuilder filterFunctionBuilder : filterFunctionBuilders) {
+            filterFunctionBuilder.writeTo(out);
+        }
+        out.writeFloat(maxBoost);
+        if (minScore == null) {
+            out.writeBoolean(false);
+        } else {
+            out.writeBoolean(true);
+            out.writeFloat(minScore);
+        }
+        if (boostMode == null) {
+            out.writeBoolean(false);
+        } else {
+            out.writeBoolean(true);
+            boostMode.writeTo(out);
+        }
+        scoreMode.writeTo(out);
+    }
+
+    @Override
+    protected Query doToQuery(QueryShardContext context) throws IOException {
+        FiltersFunctionScoreQuery.FilterFunction[] filterFunctions = new FiltersFunctionScoreQuery.FilterFunction[filterFunctionBuilders.length];
+        int i = 0;
+        for (FilterFunctionBuilder filterFunctionBuilder : filterFunctionBuilders) {
+            Query filter = filterFunctionBuilder.getFilter().toQuery(context);
+            ScoreFunction scoreFunction = filterFunctionBuilder.getScoreFunction().toFunction(context);
+            filterFunctions[i++] = new FiltersFunctionScoreQuery.FilterFunction(filter, scoreFunction);
+        }
+
+        Query query = this.query.toQuery(context);
+        if (query == null) {
+            query = new MatchAllDocsQuery();
+        }
+
+        // handle cases where only one score function and no filter was provided. In this case we create a FunctionScoreQuery.
+        if (filterFunctions.length == 0 || filterFunctions.length == 1 && (this.filterFunctionBuilders[0].getFilter().getName().equals(MatchAllQueryBuilder.NAME))) {
+            ScoreFunction function = filterFunctions.length == 0 ? null : filterFunctions[0].function;
+            CombineFunction combineFunction = this.boostMode;
+            if (combineFunction == null) {
+                if (function != null) {
+                    combineFunction = function.getDefaultScoreCombiner();
+                } else {
+                    combineFunction = DEFAULT_BOOST_MODE;
+                }
+            }
+            return new FunctionScoreQuery(query, function, minScore, combineFunction, maxBoost);
+        }
+        // in all other cases we create a FiltersFunctionScoreQuery
+        return new FiltersFunctionScoreQuery(query, scoreMode, filterFunctions, maxBoost, minScore, boostMode == null ? DEFAULT_BOOST_MODE : boostMode);
+    }
+
+    /**
+     * Function to be associated with an optional filter, meaning it will be executed only for the documents
+     * that match the given filter.
+     */
+    public static class FilterFunctionBuilder implements ToXContent, Writeable<FilterFunctionBuilder> {
+        private static final FilterFunctionBuilder PROTOTYPE = new FilterFunctionBuilder(EmptyQueryBuilder.PROTOTYPE, new RandomScoreFunctionBuilder());
+
+        private final QueryBuilder<?> filter;
+        private final ScoreFunctionBuilder scoreFunction;
+
+        public FilterFunctionBuilder(ScoreFunctionBuilder scoreFunctionBuilder) {
+            this(new MatchAllQueryBuilder(), scoreFunctionBuilder);
+        }
+
+        public FilterFunctionBuilder(QueryBuilder<?> filter, ScoreFunctionBuilder scoreFunction) {
+            if (filter == null) {
+                throw new IllegalArgumentException("function_score: filter must not be null");
+            }
+            if (scoreFunction == null) {
+                throw new IllegalArgumentException("function_score: function must not be null");
+            }
+            this.filter = filter;
+            this.scoreFunction = scoreFunction;
+        }
+
+        public QueryBuilder<?> getFilter() {
+            return filter;
+        }
+
+        public ScoreFunctionBuilder<?> getScoreFunction() {
+            return scoreFunction;
+        }
+
+        @Override
+        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
+            builder.startObject();
+            builder.field("filter");
+            filter.toXContent(builder, params);
+            scoreFunction.toXContent(builder, params);
+            builder.endObject();
+            return builder;
+        }
+
+        @Override
+        public int hashCode() {
+            return Objects.hash(filter, scoreFunction);
+        }
+
+        @Override
+        public boolean equals(Object obj) {
+            if (this == obj) {
+                return true;
+            }
+            if (obj == null || getClass() != obj.getClass()) {
+                return false;
+            }
+            FilterFunctionBuilder that = (FilterFunctionBuilder) obj;
+            return Objects.equals(this.filter, that.filter) &&
+                    Objects.equals(this.scoreFunction, that.scoreFunction);
+        }
+
+        @Override
+        public void writeTo(StreamOutput out) throws IOException {
+            out.writeQuery(filter);
+            out.writeScoreFunction(scoreFunction);
+        }
+
+        @Override
+        public FilterFunctionBuilder readFrom(StreamInput in) throws IOException {
+            return new FilterFunctionBuilder(in.readQuery(), in.readScoreFunction());
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
index 4024a7d..2bb35b0 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryParser.java
@@ -19,31 +19,28 @@
 
 package org.elasticsearch.index.query.functionscore;
 
-import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.ImmutableMap.Builder;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.Query;
-import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.ParsingException;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.lucene.search.function.*;
+import org.elasticsearch.common.lucene.search.function.CombineFunction;
+import org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery;
+import org.elasticsearch.common.lucene.search.function.FunctionScoreQuery;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.functionscore.weight.WeightBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.List;
 
 /**
  * Parser for function_score query
  */
-public class FunctionScoreQueryParser implements QueryParser {
+public class FunctionScoreQueryParser extends BaseQueryParser<FunctionScoreQueryBuilder> {
 
-    public static final String NAME = "function_score";
+    private static final FunctionScoreQueryBuilder PROTOTYPE = new FunctionScoreQueryBuilder(EmptyQueryBuilder.PROTOTYPE, new FunctionScoreQueryBuilder.FilterFunctionBuilder[0]);
 
     // For better readability of error message
     static final String MISPLACED_FUNCTION_MESSAGE_PREFIX = "you can either define [functions] array or a single function, not both. ";
@@ -51,7 +48,7 @@ public class FunctionScoreQueryParser implements QueryParser {
     public static final ParseField WEIGHT_FIELD = new ParseField("weight");
     private static final ParseField FILTER_FIELD = new ParseField("filter").withAllDeprecated("query");
 
-    ScoreFunctionParserMapper functionParserMapper;
+    private final ScoreFunctionParserMapper functionParserMapper;
 
     @Inject
     public FunctionScoreQueryParser(ScoreFunctionParserMapper functionParserMapper) {
@@ -60,54 +57,42 @@ public class FunctionScoreQueryParser implements QueryParser {
 
     @Override
     public String[] names() {
-        return new String[] { NAME, Strings.toCamelCase(NAME) };
-    }
-
-    private static final ImmutableMap<String, CombineFunction> combineFunctionsMap;
-
-    static {
-        CombineFunction[] values = CombineFunction.values();
-        Builder<String, CombineFunction> combineFunctionMapBuilder = ImmutableMap.builder();
-        for (CombineFunction combineFunction : values) {
-            combineFunctionMapBuilder.put(combineFunction.getName(), combineFunction);
-        }
-        combineFunctionsMap = combineFunctionMapBuilder.build();
+        return new String[] { FunctionScoreQueryBuilder.NAME, Strings.toCamelCase(FunctionScoreQueryBuilder.NAME) };
     }
 
     @Override
-    public Query parse(QueryShardContext context) throws IOException {
-        QueryParseContext parseContext = context.parseContext();
+    public FunctionScoreQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException {
         XContentParser parser = parseContext.parser();
 
-        Query query = null;
-        Query filter = null;
+        QueryBuilder query = null;
+        QueryBuilder filter = null;
         float boost = AbstractQueryBuilder.DEFAULT_BOOST;
         String queryName = null;
 
-        FiltersFunctionScoreQuery.ScoreMode scoreMode = FiltersFunctionScoreQuery.ScoreMode.Multiply;
-        ArrayList<FiltersFunctionScoreQuery.FilterFunction> filterFunctions = new ArrayList<>();
-        Float maxBoost = null;
+        FiltersFunctionScoreQuery.ScoreMode scoreMode = FunctionScoreQueryBuilder.DEFAULT_SCORE_MODE;
+        float maxBoost = FunctionScoreQuery.DEFAULT_MAX_BOOST;
         Float minScore = null;
 
         String currentFieldName = null;
         XContentParser.Token token;
-        CombineFunction combineFunction = CombineFunction.MULT;
+        CombineFunction combineFunction = null;
         // Either define array of functions and filters or only one function
         boolean functionArrayFound = false;
         boolean singleFunctionFound = false;
         String singleFunctionName = null;
+        List<FunctionScoreQueryBuilder.FilterFunctionBuilder> filterFunctionBuilders = new ArrayList<>();
 
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
             if (token == XContentParser.Token.FIELD_NAME) {
                 currentFieldName = parser.currentName();
             } else if ("query".equals(currentFieldName)) {
-                query = parseContext.parseInnerQuery();
+                query = parseContext.parseInnerQueryBuilder();
             } else if (parseContext.parseFieldMatcher().match(currentFieldName, FILTER_FIELD)) {
-                filter = parseContext.parseInnerFilter();
+                filter = parseContext.parseInnerFilterToQueryBuilder();
             } else if ("score_mode".equals(currentFieldName) || "scoreMode".equals(currentFieldName)) {
-                scoreMode = parseScoreMode(parseContext, parser);
+                scoreMode = FiltersFunctionScoreQuery.ScoreMode.fromString(parser.text());
             } else if ("boost_mode".equals(currentFieldName) || "boostMode".equals(currentFieldName)) {
-                combineFunction = parseBoostMode(parseContext, parser);
+                combineFunction = CombineFunction.fromString(parser.text());
             } else if ("max_boost".equals(currentFieldName) || "maxBoost".equals(currentFieldName)) {
                 maxBoost = parser.floatValue();
             } else if ("boost".equals(currentFieldName)) {
@@ -119,91 +104,73 @@ public class FunctionScoreQueryParser implements QueryParser {
             } else if ("functions".equals(currentFieldName)) {
                 if (singleFunctionFound) {
                     String errorString = "already found [" + singleFunctionName + "], now encountering [functions].";
-                    handleMisplacedFunctionsDeclaration(errorString);
+                    handleMisplacedFunctionsDeclaration(parser.getTokenLocation(), errorString);
                 }
-                currentFieldName = parseFiltersAndFunctions(context, parser, filterFunctions, currentFieldName);
                 functionArrayFound = true;
+                currentFieldName = parseFiltersAndFunctions(parseContext, parser, filterFunctionBuilders);
             } else {
-                ScoreFunction scoreFunction;
-                if (currentFieldName.equals("weight")) {
-                    scoreFunction = new WeightFactorFunction(parser.floatValue());
-
-                } else {
-                    // we try to parse a score function. If there is no score
-                    // function for the current field name,
-                    // functionParserMapper.get() will throw an Exception.
-                    scoreFunction = functionParserMapper.get(parser.getTokenLocation(), currentFieldName).parse(context, parser);
+                if (singleFunctionFound) {
+                    throw new ParsingException(parser.getTokenLocation(), "failed to parse [{}] query. already found function [{}], now encountering [{}]. use [functions] array if you want to define several functions.", FunctionScoreQueryBuilder.NAME, singleFunctionName, currentFieldName);
                 }
                 if (functionArrayFound) {
                     String errorString = "already found [functions] array, now encountering [" + currentFieldName + "].";
-                    handleMisplacedFunctionsDeclaration(errorString);
-                }
-                if (filterFunctions.size() > 0) {
-                    throw new ElasticsearchParseException("failed to parse [{}] query. already found function [{}], now encountering [{}]. use [functions] array if you want to define several functions.", NAME, singleFunctionName, currentFieldName);
+                    handleMisplacedFunctionsDeclaration(parser.getTokenLocation(), errorString);
                 }
-                filterFunctions.add(new FiltersFunctionScoreQuery.FilterFunction(null, scoreFunction));
                 singleFunctionFound = true;
                 singleFunctionName = currentFieldName;
+
+                ScoreFunctionBuilder<?> scoreFunction;
+                if (parseContext.parseFieldMatcher().match(currentFieldName, WEIGHT_FIELD)) {
+                    scoreFunction = new WeightBuilder().setWeight(parser.floatValue());
+                } else {
+                    // we try to parse a score function. If there is no score
+                    // function for the current field name,
+                    // functionParserMapper.get() will throw an Exception.
+                    scoreFunction = functionParserMapper.get(parser.getTokenLocation(), currentFieldName).fromXContent(parseContext, parser);
+                }
+                filterFunctionBuilders.add(new FunctionScoreQueryBuilder.FilterFunctionBuilder(scoreFunction));
             }
         }
+
         if (query == null && filter == null) {
-            query = Queries.newMatchAllQuery();
+            query = new MatchAllQueryBuilder();
         } else if (query == null && filter != null) {
-            query = new ConstantScoreQuery(filter);
+            query = new ConstantScoreQueryBuilder(filter);
         } else if (query != null && filter != null) {
-            final BooleanQuery.Builder filtered = new BooleanQuery.Builder();
-            filtered.add(query, Occur.MUST);
-            filtered.add(filter, Occur.FILTER);
-            query = filtered.build();
+            final BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder();
+            boolQueryBuilder.must(query);
+            boolQueryBuilder.filter(filter);
+            query = boolQueryBuilder;
         }
-        // if all filter elements returned null, just use the query
-        if (filterFunctions.isEmpty() && combineFunction == null) {
-            return query;
-        }
-        if (maxBoost == null) {
-            maxBoost = Float.MAX_VALUE;
-        }
-        Query result;
-        // handle cases where only one score function and no filter was
-        // provided. In this case we create a FunctionScoreQuery.
-        if (filterFunctions.size() == 0 || filterFunctions.size() == 1 && (filterFunctions.get(0).filter == null || Queries.isConstantMatchAllQuery(filterFunctions.get(0).filter))) {
-            ScoreFunction function = filterFunctions.size() == 0 ? null : filterFunctions.get(0).function;
-            FunctionScoreQuery theQuery = new FunctionScoreQuery(query, function, minScore);
-            if (combineFunction != null) {
-                theQuery.setCombineFunction(combineFunction);
-            }
-            theQuery.setMaxBoost(maxBoost);
-            result = theQuery;
-            // in all other cases we create a FiltersFunctionScoreQuery.
-        } else {
-            FiltersFunctionScoreQuery functionScoreQuery = new FiltersFunctionScoreQuery(query, scoreMode,
-                    filterFunctions.toArray(new FiltersFunctionScoreQuery.FilterFunction[filterFunctions.size()]), maxBoost, minScore);
-            if (combineFunction != null) {
-                functionScoreQuery.setCombineFunction(combineFunction);
-            }
-            result = functionScoreQuery;
+
+        FunctionScoreQueryBuilder functionScoreQueryBuilder = new FunctionScoreQueryBuilder(query,
+                filterFunctionBuilders.toArray(new FunctionScoreQueryBuilder.FilterFunctionBuilder[filterFunctionBuilders.size()]));
+        if (combineFunction != null) {
+            functionScoreQueryBuilder.boostMode(combineFunction);
         }
-        result.setBoost(boost);
-        if (queryName != null) {
-            context.addNamedQuery(queryName, query);
+        functionScoreQueryBuilder.scoreMode(scoreMode);
+        functionScoreQueryBuilder.maxBoost(maxBoost);
+        if (minScore != null) {
+            functionScoreQueryBuilder.setMinScore(minScore);
         }
-        return result;
+        functionScoreQueryBuilder.boost(boost);
+        functionScoreQueryBuilder.queryName(queryName);
+        return functionScoreQueryBuilder;
     }
 
-    private void handleMisplacedFunctionsDeclaration(String errorString) {
-        throw new ElasticsearchParseException("failed to parse [{}] query. [{}]", NAME, MISPLACED_FUNCTION_MESSAGE_PREFIX + errorString);
+    private static void handleMisplacedFunctionsDeclaration(XContentLocation contentLocation, String errorString) {
+        throw new ParsingException(contentLocation, "failed to parse [{}] query. [{}]", FunctionScoreQueryBuilder.NAME, MISPLACED_FUNCTION_MESSAGE_PREFIX + errorString);
     }
 
-    private String parseFiltersAndFunctions(QueryShardContext context, XContentParser parser,
-                                            ArrayList<FiltersFunctionScoreQuery.FilterFunction> filterFunctions, String currentFieldName) throws IOException {
-        QueryParseContext parseContext = context.parseContext();
+    private String parseFiltersAndFunctions(QueryParseContext parseContext, XContentParser parser, List<FunctionScoreQueryBuilder.FilterFunctionBuilder> filterFunctionBuilders) throws IOException {
+        String currentFieldName = null;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-            Query filter = null;
-            ScoreFunction scoreFunction = null;
+            QueryBuilder filter = null;
+            ScoreFunctionBuilder<?> scoreFunction = null;
             Float functionWeight = null;
             if (token != XContentParser.Token.START_OBJECT) {
-                throw new ParsingException(parser.getTokenLocation(), "failed to parse [{}]. malformed query, expected a [{}] while parsing functions but got a [{}] instead", XContentParser.Token.START_OBJECT, token, NAME);
+                throw new ParsingException(parser.getTokenLocation(), "failed to parse [{}]. malformed query, expected a [{}] while parsing functions but got a [{}] instead", XContentParser.Token.START_OBJECT, token, FunctionScoreQueryBuilder.NAME);
             } else {
                 while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                     if (token == XContentParser.Token.FIELD_NAME) {
@@ -212,69 +179,40 @@ public class FunctionScoreQueryParser implements QueryParser {
                         functionWeight = parser.floatValue();
                     } else {
                         if ("filter".equals(currentFieldName)) {
-                            filter = parseContext.parseInnerFilter();
+                            filter = parseContext.parseInnerFilterToQueryBuilder();
                         } else {
+                            if (scoreFunction != null) {
+                                throw new ParsingException(parser.getTokenLocation(), "failed to parse function_score functions. already found [{}], now encountering [{}].", scoreFunction.getName(), currentFieldName);
+                            }
                             // do not need to check null here,
                             // functionParserMapper throws exception if parser
                             // non-existent
                             ScoreFunctionParser functionParser = functionParserMapper.get(parser.getTokenLocation(), currentFieldName);
-                            scoreFunction = functionParser.parse(context, parser);
+                            scoreFunction = functionParser.fromXContent(parseContext, parser);
                         }
                     }
                 }
                 if (functionWeight != null) {
-                    scoreFunction = new WeightFactorFunction(functionWeight, scoreFunction);
+                    if (scoreFunction == null) {
+                        scoreFunction = new WeightBuilder().setWeight(functionWeight);
+                    } else {
+                        scoreFunction.setWeight(functionWeight);
+                    }
                 }
             }
             if (filter == null) {
-                filter = Queries.newMatchAllQuery();
+                filter = new MatchAllQueryBuilder();
             }
             if (scoreFunction == null) {
-                throw new ElasticsearchParseException("failed to parse [{}] query. an entry in functions list is missing a function.", NAME);
+                throw new ParsingException(parser.getTokenLocation(), "failed to parse [{}] query. an entry in functions list is missing a function.", FunctionScoreQueryBuilder.NAME);
             }
-            filterFunctions.add(new FiltersFunctionScoreQuery.FilterFunction(filter, scoreFunction));
-
+            filterFunctionBuilders.add(new FunctionScoreQueryBuilder.FilterFunctionBuilder(filter, scoreFunction));
         }
         return currentFieldName;
     }
 
-    private FiltersFunctionScoreQuery.ScoreMode parseScoreMode(QueryParseContext parseContext, XContentParser parser) throws IOException {
-        String scoreMode = parser.text();
-        if ("avg".equals(scoreMode)) {
-            return FiltersFunctionScoreQuery.ScoreMode.Avg;
-        } else if ("max".equals(scoreMode)) {
-            return FiltersFunctionScoreQuery.ScoreMode.Max;
-        } else if ("min".equals(scoreMode)) {
-            return FiltersFunctionScoreQuery.ScoreMode.Min;
-        } else if ("sum".equals(scoreMode)) {
-            return FiltersFunctionScoreQuery.ScoreMode.Sum;
-        } else if ("multiply".equals(scoreMode)) {
-            return FiltersFunctionScoreQuery.ScoreMode.Multiply;
-        } else if ("first".equals(scoreMode)) {
-            return FiltersFunctionScoreQuery.ScoreMode.First;
-        } else {
-            throw new ParsingException(parser.getTokenLocation(), "failed to parse [{}] query. illegal score_mode [{}]", NAME, scoreMode);
-        }
-    }
-
-    private CombineFunction parseBoostMode(QueryParseContext parseContext, XContentParser parser) throws IOException {
-        String boostMode = parser.text();
-        CombineFunction cf = combineFunctionsMap.get(boostMode);
-        if (cf == null) {
-            throw new ParsingException(parser.getTokenLocation(), "failed to parse [{}] query. illegal boost_mode [{}]", NAME, boostMode);
-        }
-        return cf;
-    }
-
-    //norelease to be removed once all queries are moved over to extend BaseQueryParser
-    @Override
-    public QueryBuilder fromXContent(QueryParseContext parseContext) throws IOException {
-        Query query = parse(parseContext.shardContext());
-        return new QueryWrappingQueryBuilder(query);
-    }
-
     @Override
     public FunctionScoreQueryBuilder getBuilderPrototype() {
-        return FunctionScoreQueryBuilder.PROTOTYPE;
+        return PROTOTYPE;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilder.java
index e4fc5cd..c2346cc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilder.java
@@ -19,21 +19,32 @@
 
 package org.elasticsearch.index.query.functionscore;
 
+import org.elasticsearch.common.io.stream.NamedWriteable;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.lucene.search.function.ScoreFunction;
+import org.elasticsearch.common.lucene.search.function.WeightFactorFunction;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.index.query.QueryShardContext;
 
 import java.io.IOException;
+import java.util.Objects;
 
-public abstract class ScoreFunctionBuilder implements ToXContent {
+public abstract class ScoreFunctionBuilder<FB extends ScoreFunctionBuilder> implements ToXContent, NamedWriteable<FB> {
+
+    protected Float weight;
+
+    public abstract String getName();
 
     public ScoreFunctionBuilder setWeight(float weight) {
         this.weight = weight;
         return this;
     }
 
-    private Float weight;
-
-    public abstract String getName();
+    public Float getWeight() {
+        return weight;
+    }
 
     protected void buildWeight(XContentBuilder builder) throws IOException {
         if (weight != null) {
@@ -49,4 +60,69 @@ public abstract class ScoreFunctionBuilder implements ToXContent {
     }
 
     protected abstract void doXContent(XContentBuilder builder, Params params) throws IOException;
+
+    @Override
+    public String getWriteableName() {
+        return getName();
+    }
+
+    @Override
+    public final void writeTo(StreamOutput out) throws IOException {
+        doWriteTo(out);
+        if (weight == null) {
+            out.writeBoolean(false);
+        } else {
+            out.writeBoolean(true);
+            out.writeFloat(weight);
+        }
+    }
+
+    protected abstract void doWriteTo(StreamOutput out) throws IOException;
+
+    @Override
+    public final FB readFrom(StreamInput in) throws IOException {
+        FB scoreFunctionBuilder = doReadFrom(in);
+        if (in.readBoolean()) {
+            scoreFunctionBuilder.setWeight(in.readFloat());
+        }
+        return scoreFunctionBuilder;
+    }
+
+    protected abstract FB doReadFrom(StreamInput in) throws IOException;
+
+    @Override
+    public boolean equals(Object obj) {
+        if (this == obj) {
+            return true;
+        }
+        if (obj == null || getClass() != obj.getClass()) {
+            return false;
+        }
+        @SuppressWarnings("unchecked")
+        FB other = (FB) obj;
+        return Objects.equals(weight, other.weight) &&
+                doEquals(other);
+    }
+
+    protected abstract boolean doEquals(FB functionBuilder);
+
+    @Override
+    public final int hashCode() {
+        return Objects.hash(getClass(), weight, doHashCode());
+    }
+
+    protected abstract int doHashCode();
+
+    /**
+     * Called on a data node, converts a {@link NamedWriteable} score function into its corresponding lucene function object.
+     */
+    public final ScoreFunction toFunction(QueryShardContext context) throws IOException {
+        ScoreFunction scoreFunction = doToFunction(context);
+        if (weight == null) {
+            return scoreFunction;
+        }
+        return new WeightFactorFunction(weight, scoreFunction);
+    }
+
+    protected abstract ScoreFunction doToFunction(QueryShardContext context) throws IOException;
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilders.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilders.java
index 23c1ca1..3c8416a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilders.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilders.java
@@ -29,29 +29,41 @@ import org.elasticsearch.index.query.functionscore.weight.WeightBuilder;
 import org.elasticsearch.script.Script;
 
 public class ScoreFunctionBuilders {
-   
+
     public static ExponentialDecayFunctionBuilder exponentialDecayFunction(String fieldName, Object origin, Object scale) {
-        return new ExponentialDecayFunctionBuilder(fieldName, origin, scale);
+        return new ExponentialDecayFunctionBuilder(fieldName, origin, scale, null);
     }
-    
-    public static ExponentialDecayFunctionBuilder exponentialDecayFunction(String fieldName, Object scale) {
-        return new ExponentialDecayFunctionBuilder(fieldName, null, scale);
+
+    public static ExponentialDecayFunctionBuilder exponentialDecayFunction(String fieldName, Object origin, Object scale, Object offset) {
+        return new ExponentialDecayFunctionBuilder(fieldName, origin, scale, offset);
     }
-    
+
+    public static ExponentialDecayFunctionBuilder exponentialDecayFunction(String fieldName, Object origin, Object scale, Object offset, double decay) {
+        return new ExponentialDecayFunctionBuilder(fieldName, origin, scale, offset, decay);
+    }
+
     public static GaussDecayFunctionBuilder gaussDecayFunction(String fieldName, Object origin, Object scale) {
-        return new GaussDecayFunctionBuilder(fieldName, origin, scale);
+        return new GaussDecayFunctionBuilder(fieldName, origin, scale, null);
     }
-    
-    public static GaussDecayFunctionBuilder gaussDecayFunction(String fieldName, Object scale) {
-        return new GaussDecayFunctionBuilder(fieldName, null, scale);
+
+    public static GaussDecayFunctionBuilder gaussDecayFunction(String fieldName, Object origin, Object scale, Object offset) {
+        return new GaussDecayFunctionBuilder(fieldName, origin, scale, offset);
     }
-    
+
+    public static GaussDecayFunctionBuilder gaussDecayFunction(String fieldName, Object origin, Object scale, Object offset, double decay) {
+        return new GaussDecayFunctionBuilder(fieldName, origin, scale, offset, decay);
+    }
+
     public static LinearDecayFunctionBuilder linearDecayFunction(String fieldName, Object origin, Object scale) {
-        return new LinearDecayFunctionBuilder(fieldName, origin, scale);
+        return new LinearDecayFunctionBuilder(fieldName, origin, scale, null);
     }
-    
-    public static LinearDecayFunctionBuilder linearDecayFunction(String fieldName, Object scale) {
-        return new LinearDecayFunctionBuilder(fieldName, null, scale);
+
+    public static LinearDecayFunctionBuilder linearDecayFunction(String fieldName, Object origin, Object scale, Object offset) {
+        return new LinearDecayFunctionBuilder(fieldName, origin, scale, offset);
+    }
+
+    public static LinearDecayFunctionBuilder linearDecayFunction(String fieldName, Object origin, Object scale, Object offset, double decay) {
+        return new LinearDecayFunctionBuilder(fieldName, origin, scale, offset, decay);
     }
 
     public static ScriptScoreFunctionBuilder scriptFunction(Script script) {
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
index 5802c59..df76f14 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParser.java
@@ -19,16 +19,17 @@
 
 package org.elasticsearch.index.query.functionscore;
 
-import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.common.ParsingException;
+import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
 
-public interface ScoreFunctionParser {
+public interface ScoreFunctionParser<FB extends ScoreFunctionBuilder<FB>> {
 
-    ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, ParsingException;
+    FB fromXContent(QueryParseContext context, XContentParser parser) throws IOException, ParsingException;
+
+    FB getBuilderPrototype();
 
     /**
      * Returns the name of the function, for example "linear", "gauss" etc. This
@@ -36,5 +37,4 @@ public interface ScoreFunctionParser {
      * {@link FunctionScoreQueryParser}.
      * */
     String[] getNames();
-
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java
index 1dd7140..c528c00 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/ScoreFunctionParserMapper.java
@@ -19,15 +19,20 @@
 
 package org.elasticsearch.index.query.functionscore;
 
+import java.util.Map;
+
 import org.elasticsearch.common.ParsingException;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
 import org.elasticsearch.common.xcontent.XContentLocation;
+import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.functionscore.exp.ExponentialDecayFunctionParser;
 import org.elasticsearch.index.query.functionscore.fieldvaluefactor.FieldValueFactorFunctionParser;
 import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionParser;
 import org.elasticsearch.index.query.functionscore.lin.LinearDecayFunctionParser;
 import org.elasticsearch.index.query.functionscore.random.RandomScoreFunctionParser;
 import org.elasticsearch.index.query.functionscore.script.ScriptScoreFunctionParser;
+import org.elasticsearch.index.query.functionscore.weight.WeightBuilder;
 
 import java.util.Collections;
 import java.util.HashMap;
@@ -36,22 +41,25 @@ import java.util.Set;
 
 public class ScoreFunctionParserMapper {
 
-    protected Map<String, ScoreFunctionParser> functionParsers;
+    protected Map<String, ScoreFunctionParser<?>> functionParsers;
 
     @Inject
-    public ScoreFunctionParserMapper(Set<ScoreFunctionParser> parsers) {
-        Map<String, ScoreFunctionParser> map = new HashMap<>();
+    public ScoreFunctionParserMapper(Set<ScoreFunctionParser> parsers, NamedWriteableRegistry namedWriteableRegistry) {
+        Map<String, ScoreFunctionParser<?>> map = new HashMap<>();
         // built-in parsers
-        addParser(new ScriptScoreFunctionParser(), map);
-        addParser(new GaussDecayFunctionParser(), map);
-        addParser(new LinearDecayFunctionParser(), map);
-        addParser(new ExponentialDecayFunctionParser(), map);
-        addParser(new RandomScoreFunctionParser(), map);
-        addParser(new FieldValueFactorFunctionParser(), map);
-        for (ScoreFunctionParser scoreFunctionParser : parsers) {
-            addParser(scoreFunctionParser, map);
+        addParser(new ScriptScoreFunctionParser(), map, namedWriteableRegistry);
+        addParser(new GaussDecayFunctionParser(), map, namedWriteableRegistry);
+        addParser(new LinearDecayFunctionParser(), map, namedWriteableRegistry);
+        addParser(new ExponentialDecayFunctionParser(), map, namedWriteableRegistry);
+        addParser(new RandomScoreFunctionParser(), map, namedWriteableRegistry);
+        addParser(new FieldValueFactorFunctionParser(), map, namedWriteableRegistry);
+        for (ScoreFunctionParser<?> scoreFunctionParser : parsers) {
+            addParser(scoreFunctionParser, map, namedWriteableRegistry);
         }
         this.functionParsers = Collections.unmodifiableMap(map);
+        //weight doesn't have its own parser, so every function supports it out of the box.
+        //Can be a single function too when not associated to any other function, which is why it needs to be registered manually here.
+        namedWriteableRegistry.registerPrototype(ScoreFunctionBuilder.class, new WeightBuilder());
     }
 
     public ScoreFunctionParser get(XContentLocation contentLocation, String parserName) {
@@ -66,10 +74,11 @@ public class ScoreFunctionParserMapper {
         return functionParsers.get(parserName);
     }
 
-    private void addParser(ScoreFunctionParser scoreFunctionParser, Map<String, ScoreFunctionParser> map) {
+    private static void addParser(ScoreFunctionParser<?> scoreFunctionParser, Map<String, ScoreFunctionParser<?>> map, NamedWriteableRegistry namedWriteableRegistry) {
         for (String name : scoreFunctionParser.getNames()) {
             map.put(name, scoreFunctionParser);
+
         }
+        namedWriteableRegistry.registerPrototype(ScoreFunctionBuilder.class, scoreFunctionParser.getBuilderPrototype());
     }
-
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/exp/ExponentialDecayFunctionBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/exp/ExponentialDecayFunctionBuilder.java
index f4a730b..3c81393 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/exp/ExponentialDecayFunctionBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/exp/ExponentialDecayFunctionBuilder.java
@@ -20,12 +20,30 @@
 package org.elasticsearch.index.query.functionscore.exp;
 
 
+import org.apache.lucene.search.Explanation;
+import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.index.query.functionscore.DecayFunction;
 import org.elasticsearch.index.query.functionscore.DecayFunctionBuilder;
 
-public class ExponentialDecayFunctionBuilder extends DecayFunctionBuilder {
+public class ExponentialDecayFunctionBuilder extends DecayFunctionBuilder<ExponentialDecayFunctionBuilder> {
 
-    public ExponentialDecayFunctionBuilder(String fieldName, Object origin, Object scale) {
-        super(fieldName, origin, scale);
+    private static final DecayFunction EXP_DECAY_FUNCTION = new ExponentialDecayScoreFunction();
+
+    public ExponentialDecayFunctionBuilder(String fieldName, Object origin, Object scale, Object offset) {
+        super(fieldName, origin, scale, offset);
+    }
+
+    public ExponentialDecayFunctionBuilder(String fieldName, Object origin, Object scale, Object offset, double decay) {
+        super(fieldName, origin, scale, offset, decay);
+    }
+
+    private ExponentialDecayFunctionBuilder(String fieldName, BytesReference functionBytes) {
+        super(fieldName, functionBytes);
+    }
+
+    @Override
+    protected ExponentialDecayFunctionBuilder createFunctionBuilder(String fieldName, BytesReference functionBytes) {
+        return new ExponentialDecayFunctionBuilder(fieldName, functionBytes);
     }
 
     @Override
@@ -33,4 +51,41 @@ public class ExponentialDecayFunctionBuilder extends DecayFunctionBuilder {
         return ExponentialDecayFunctionParser.NAMES[0];
     }
 
+    @Override
+    public DecayFunction getDecayFunction() {
+        return EXP_DECAY_FUNCTION;
+    }
+
+    private static final class ExponentialDecayScoreFunction implements DecayFunction {
+
+        @Override
+        public double evaluate(double value, double scale) {
+            return Math.exp(scale * value);
+        }
+
+        @Override
+        public Explanation explainFunction(String valueExpl, double value, double scale) {
+            return Explanation.match(
+                    (float) evaluate(value, scale),
+                    "exp(- " + valueExpl + " * " + -1 * scale + ")");
+        }
+
+        @Override
+        public double processScale(double scale, double decay) {
+            return Math.log(decay) / scale;
+        }
+
+        @Override
+        public int hashCode() {
+            return this.getClass().hashCode();
+        }
+
+        @Override
+        public boolean equals(Object obj) {
+            if (super.equals(obj)) {
+                return true;
+            }
+            return obj != null && getClass() != obj.getClass();
+        }
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/exp/ExponentialDecayFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/exp/ExponentialDecayFunctionParser.java
index bab04d4..ab2661e 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/exp/ExponentialDecayFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/exp/ExponentialDecayFunctionParser.java
@@ -19,11 +19,11 @@
 
 package org.elasticsearch.index.query.functionscore.exp;
 
-import org.apache.lucene.search.Explanation;
-import org.elasticsearch.index.query.functionscore.DecayFunction;
 import org.elasticsearch.index.query.functionscore.DecayFunctionParser;
 
-public class ExponentialDecayFunctionParser extends DecayFunctionParser {
+public class ExponentialDecayFunctionParser extends DecayFunctionParser<ExponentialDecayFunctionBuilder> {
+
+    private static final ExponentialDecayFunctionBuilder PROTOTYPE = new ExponentialDecayFunctionBuilder("", "", "", "");
 
     public static final String[] NAMES = { "exp" };
 
@@ -32,31 +32,8 @@ public class ExponentialDecayFunctionParser extends DecayFunctionParser {
         return NAMES;
     }
 
-    static final DecayFunction decayFunction = new ExponentialDecayScoreFunction();
-
     @Override
-    public DecayFunction getDecayFunction() {
-        return decayFunction;
-    }
-
-    final static class ExponentialDecayScoreFunction implements DecayFunction {
-
-        @Override
-        public double evaluate(double value, double scale) {
-            return Math.exp(scale * value);
-        }
-
-        @Override
-        public Explanation explainFunction(String valueExpl, double value, double scale) {
-            return Explanation.match(
-                    (float) evaluate(value, scale),
-                    "exp(- " + valueExpl + " * " + -1 * scale + ")");
-        }
-
-        @Override
-        public double processScale(double scale, double decay) {
-            return Math.log(decay) / scale;
-        }
-
+    public ExponentialDecayFunctionBuilder getBuilderPrototype() {
+        return PROTOTYPE;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionBuilder.java
index 5d38c5a..f34484a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionBuilder.java
@@ -19,24 +19,39 @@
 
 package org.elasticsearch.index.query.functionscore.fieldvaluefactor;
 
+import org.elasticsearch.ElasticsearchException;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.lucene.search.function.FieldValueFactorFunction;
+import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.index.fielddata.IndexNumericFieldData;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
 
 import java.io.IOException;
 import java.util.Locale;
+import java.util.Objects;
 
 /**
  * Builder to construct {@code field_value_factor} functions for a function
  * score query.
  */
-public class FieldValueFactorFunctionBuilder extends ScoreFunctionBuilder {
-    private String field = null;
-    private Float factor = null;
-    private Double missing = null;
-    private FieldValueFactorFunction.Modifier modifier = null;
+public class FieldValueFactorFunctionBuilder extends ScoreFunctionBuilder<FieldValueFactorFunctionBuilder> {
+
+    public static final FieldValueFactorFunction.Modifier DEFAULT_MODIFIER = FieldValueFactorFunction.Modifier.NONE;
+    public static final float DEFAULT_FACTOR = 1;
+
+    private final String field;
+    private float factor = DEFAULT_FACTOR;
+    private Double missing;
+    private FieldValueFactorFunction.Modifier modifier = DEFAULT_MODIFIER;
 
     public FieldValueFactorFunctionBuilder(String fieldName) {
+        if (fieldName == null) {
+            throw new IllegalArgumentException("field_value_factor: field must not be null");
+        }
         this.field = fieldName;
     }
 
@@ -45,11 +60,19 @@ public class FieldValueFactorFunctionBuilder extends ScoreFunctionBuilder {
         return FieldValueFactorFunctionParser.NAMES[0];
     }
 
+    public String fieldName() {
+        return this.field;
+    }
+
     public FieldValueFactorFunctionBuilder factor(float boostFactor) {
         this.factor = boostFactor;
         return this;
     }
 
+    public float factor() {
+        return this.factor;
+    }
+
     /**
      * Value used instead of the field value for documents that don't have that field defined.
      */
@@ -58,29 +81,82 @@ public class FieldValueFactorFunctionBuilder extends ScoreFunctionBuilder {
         return this;
     }
 
+    public Double missing() {
+        return this.missing;
+    }
+
     public FieldValueFactorFunctionBuilder modifier(FieldValueFactorFunction.Modifier modifier) {
+        if (modifier == null) {
+            throw new IllegalArgumentException("field_value_factor: modifier must not be null");
+        }
         this.modifier = modifier;
         return this;
     }
 
+    public FieldValueFactorFunction.Modifier modifier() {
+        return this.modifier;
+    }
+
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject(getName());
-        if (field != null) {
-            builder.field("field", field);
+        builder.field("field", field);
+        builder.field("factor", factor);
+        if (missing != null) {
+            builder.field("missing", missing);
         }
+        builder.field("modifier", modifier.name().toLowerCase(Locale.ROOT));
+        builder.endObject();
+    }
 
-        if (factor != null) {
-            builder.field("factor", factor);
+    @Override
+    protected void doWriteTo(StreamOutput out) throws IOException {
+        out.writeString(field);
+        out.writeFloat(factor);
+        if (missing == null) {
+            out.writeBoolean(false);
+        } else {
+            out.writeBoolean(true);
+            out.writeDouble(missing);
         }
+        modifier.writeTo(out);
+    }
 
-        if (missing != null) {
-            builder.field("missing", missing);
+    @Override
+    protected FieldValueFactorFunctionBuilder doReadFrom(StreamInput in) throws IOException {
+        FieldValueFactorFunctionBuilder functionBuilder = new FieldValueFactorFunctionBuilder(in.readString());
+        functionBuilder.factor = in.readFloat();
+        if (in.readBoolean()) {
+            functionBuilder.missing = in.readDouble();
         }
+        functionBuilder.modifier = FieldValueFactorFunction.Modifier.readModifierFrom(in);
+        return functionBuilder;
+    }
 
-        if (modifier != null) {
-            builder.field("modifier", modifier.toString().toLowerCase(Locale.ROOT));
+    @Override
+    protected boolean doEquals(FieldValueFactorFunctionBuilder functionBuilder) {
+        return Objects.equals(this.field, functionBuilder.field) &&
+                Objects.equals(this.factor, functionBuilder.factor) &&
+                Objects.equals(this.missing, functionBuilder.missing) &&
+                Objects.equals(this.modifier, functionBuilder.modifier);
+    }
+
+    @Override
+    protected int doHashCode() {
+        return Objects.hash(this.field, this.factor, this.missing, this.modifier);
+    }
+
+    @Override
+    protected ScoreFunction doToFunction(QueryShardContext context) {
+        MappedFieldType fieldType = context.mapperService().smartNameFieldType(field);
+        IndexNumericFieldData fieldData = null;
+        if (fieldType == null) {
+            if(missing == null) {
+                throw new ElasticsearchException("Unable to find a field mapper for field [" + field + "]. No 'missing' value defined.");
+            }
+        } else {
+            fieldData = context.getForField(fieldType);
         }
-        builder.endObject();
+        return new FieldValueFactorFunction(field, factor, modifier, missing, fieldData);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
index d49d36a..06d6ba8 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/fieldvaluefactor/FieldValueFactorFunctionParser.java
@@ -19,20 +19,13 @@
 
 package org.elasticsearch.index.query.functionscore.fieldvaluefactor;
 
-import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.lucene.search.function.FieldValueFactorFunction;
-import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.fielddata.IndexNumericFieldData;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.common.ParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
-import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
-import java.util.Locale;
 
 /**
  * Parses out a function_score function that looks like:
@@ -48,16 +41,16 @@ import java.util.Locale;
  *     }
  * </pre>
  */
-public class FieldValueFactorFunctionParser implements ScoreFunctionParser {
+public class FieldValueFactorFunctionParser implements ScoreFunctionParser<FieldValueFactorFunctionBuilder> {
     public static String[] NAMES = { "field_value_factor", "fieldValueFactor" };
 
-    @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, ParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    private static final FieldValueFactorFunctionBuilder PROTOTYPE = new FieldValueFactorFunctionBuilder("");
 
+    @Override
+    public FieldValueFactorFunctionBuilder fromXContent(QueryParseContext parseContext, XContentParser parser) throws IOException, ParsingException {
         String currentFieldName = null;
         String field = null;
-        float boostFactor = 1;
+        float boostFactor = FieldValueFactorFunctionBuilder.DEFAULT_FACTOR;
         FieldValueFactorFunction.Modifier modifier = FieldValueFactorFunction.Modifier.NONE;
         Double missing = null;
         XContentParser.Token token;
@@ -70,7 +63,7 @@ public class FieldValueFactorFunctionParser implements ScoreFunctionParser {
                 } else if ("factor".equals(currentFieldName)) {
                     boostFactor = parser.floatValue();
                 } else if ("modifier".equals(currentFieldName)) {
-                    modifier = FieldValueFactorFunction.Modifier.valueOf(parser.text().toUpperCase(Locale.ROOT));
+                    modifier = FieldValueFactorFunction.Modifier.fromString(parser.text());
                 } else if ("missing".equals(currentFieldName)) {
                     missing = parser.doubleValue();
                 } else {
@@ -85,21 +78,20 @@ public class FieldValueFactorFunctionParser implements ScoreFunctionParser {
             throw new ParsingException(parser.getTokenLocation(), "[" + NAMES[0] + "] required field 'field' missing");
         }
 
-        SearchContext searchContext = SearchContext.current();
-        MappedFieldType fieldType = searchContext.mapperService().smartNameFieldType(field);
-        IndexNumericFieldData fieldData = null;
-        if (fieldType == null) {
-            if(missing == null) {
-                throw new ElasticsearchException("Unable to find a field mapper for field [" + field + "]. No 'missing' value defined.");
-            }
-        } else {
-            fieldData = searchContext.fieldData().getForField(fieldType);
+        FieldValueFactorFunctionBuilder fieldValueFactorFunctionBuilder = new FieldValueFactorFunctionBuilder(field).factor(boostFactor).modifier(modifier);
+        if (missing != null) {
+            fieldValueFactorFunctionBuilder.missing(missing);
         }
-        return new FieldValueFactorFunction(field, boostFactor, modifier, missing, fieldData);
+        return fieldValueFactorFunctionBuilder;
     }
 
     @Override
     public String[] getNames() {
         return NAMES;
     }
+
+    @Override
+    public FieldValueFactorFunctionBuilder getBuilderPrototype() {
+        return PROTOTYPE;
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionBuilder.java
index b9d6708..621b22a 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionBuilder.java
@@ -20,12 +20,30 @@
 package org.elasticsearch.index.query.functionscore.gauss;
 
 
+import org.apache.lucene.search.Explanation;
+import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.index.query.functionscore.DecayFunction;
 import org.elasticsearch.index.query.functionscore.DecayFunctionBuilder;
 
-public class GaussDecayFunctionBuilder extends DecayFunctionBuilder {
+public class GaussDecayFunctionBuilder extends DecayFunctionBuilder<GaussDecayFunctionBuilder> {
 
-    public GaussDecayFunctionBuilder(String fieldName, Object origin, Object scale) {
-        super(fieldName, origin, scale);
+    private static final DecayFunction GAUSS_DECAY_FUNCTION = new GaussScoreFunction();
+
+    public GaussDecayFunctionBuilder(String fieldName, Object origin, Object scale, Object offset) {
+        super(fieldName, origin, scale, offset);
+    }
+
+    public GaussDecayFunctionBuilder(String fieldName, Object origin, Object scale, Object offset, double decay) {
+        super(fieldName, origin, scale, offset, decay);
+    }
+
+    private GaussDecayFunctionBuilder(String fieldName, BytesReference functionBytes) {
+        super(fieldName, functionBytes);
+    }
+
+    @Override
+    protected GaussDecayFunctionBuilder createFunctionBuilder(String fieldName, BytesReference functionBytes) {
+        return new GaussDecayFunctionBuilder(fieldName, functionBytes);
     }
 
     @Override
@@ -33,4 +51,43 @@ public class GaussDecayFunctionBuilder extends DecayFunctionBuilder {
         return GaussDecayFunctionParser.NAMES[0];
     }
 
+    @Override
+    public DecayFunction getDecayFunction() {
+        return GAUSS_DECAY_FUNCTION;
+    }
+
+    private static final class GaussScoreFunction implements DecayFunction {
+
+        @Override
+        public double evaluate(double value, double scale) {
+            // note that we already computed scale^2 in processScale() so we do
+            // not need to square it here.
+            return Math.exp(0.5 * Math.pow(value, 2.0) / scale);
+        }
+
+        @Override
+        public Explanation explainFunction(String valueExpl, double value, double scale) {
+            return Explanation.match(
+                    (float) evaluate(value, scale),
+                    "exp(-0.5*pow(" + valueExpl + ",2.0)/" + -1 * scale + ")");
+        }
+
+        @Override
+        public double processScale(double scale, double decay) {
+            return 0.5 * Math.pow(scale, 2.0) / Math.log(decay);
+        }
+
+        @Override
+        public int hashCode() {
+            return this.getClass().hashCode();
+        }
+
+        @Override
+        public boolean equals(Object obj) {
+            if (super.equals(obj)) {
+                return true;
+            }
+            return obj != null && getClass() != obj.getClass();
+        }
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionParser.java
index 614050a..6304a62 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/gauss/GaussDecayFunctionParser.java
@@ -19,45 +19,21 @@
 
 package org.elasticsearch.index.query.functionscore.gauss;
 
-import org.apache.lucene.search.Explanation;
-import org.elasticsearch.index.query.functionscore.DecayFunction;
 import org.elasticsearch.index.query.functionscore.DecayFunctionParser;
 
-public class GaussDecayFunctionParser extends DecayFunctionParser {
+public class GaussDecayFunctionParser extends DecayFunctionParser<GaussDecayFunctionBuilder> {
 
-    static final DecayFunction decayFunction = new GaussScoreFunction();
-    public static final String[] NAMES = { "gauss" };
-
-    @Override
-    public DecayFunction getDecayFunction() {
-        return decayFunction;
-    }
-
-    final static class GaussScoreFunction implements DecayFunction {
-
-        @Override
-        public double evaluate(double value, double scale) {
-            // note that we already computed scale^2 in processScale() so we do
-            // not need to square it here.
-            return Math.exp(0.5 * Math.pow(value, 2.0) / scale);
-        }
+    private static final GaussDecayFunctionBuilder PROTOTYPE = new GaussDecayFunctionBuilder("", "", "", "");
 
-        @Override
-        public Explanation explainFunction(String valueExpl, double value, double scale) {
-            return Explanation.match(
-                    (float) evaluate(value, scale),
-                    "exp(-0.5*pow(" + valueExpl + ",2.0)/" + -1 * scale + ")");
-        }
-
-        @Override
-        public double processScale(double scale, double decay) {
-            return 0.5 * Math.pow(scale, 2.0) / Math.log(decay);
-        }
-    }
+    public static final String[] NAMES = { "gauss" };
 
     @Override
     public String[] getNames() {
         return NAMES;
     }
 
+    @Override
+    public GaussDecayFunctionBuilder getBuilderPrototype() {
+        return PROTOTYPE;
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/lin/LinearDecayFunctionBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/lin/LinearDecayFunctionBuilder.java
index dcb4eff..2e63aed 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/lin/LinearDecayFunctionBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/lin/LinearDecayFunctionBuilder.java
@@ -19,12 +19,25 @@
 
 package org.elasticsearch.index.query.functionscore.lin;
 
+import org.apache.lucene.search.Explanation;
+import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.index.query.functionscore.DecayFunction;
 import org.elasticsearch.index.query.functionscore.DecayFunctionBuilder;
 
-public class LinearDecayFunctionBuilder extends DecayFunctionBuilder {
+public class LinearDecayFunctionBuilder extends DecayFunctionBuilder<LinearDecayFunctionBuilder> {
 
-    public LinearDecayFunctionBuilder(String fieldName, Object origin, Object scale) {
-        super(fieldName, origin, scale);
+    private static final DecayFunction LINEAR_DECAY_FUNCTION = new LinearDecayScoreFunction();
+
+    public LinearDecayFunctionBuilder(String fieldName, Object origin, Object scale, Object offset) {
+        super(fieldName, origin, scale, offset);
+    }
+
+    public LinearDecayFunctionBuilder(String fieldName, Object origin, Object scale, Object offset, double decay) {
+        super(fieldName, origin, scale, offset, decay);
+    }
+
+    private LinearDecayFunctionBuilder(String fieldName, BytesReference functionBytes) {
+        super(fieldName, functionBytes);
     }
 
     @Override
@@ -32,4 +45,46 @@ public class LinearDecayFunctionBuilder extends DecayFunctionBuilder {
         return LinearDecayFunctionParser.NAMES[0];
     }
 
+    @Override
+    protected LinearDecayFunctionBuilder createFunctionBuilder(String fieldName, BytesReference functionBytes) {
+        return new LinearDecayFunctionBuilder(fieldName, functionBytes);
+    }
+
+    @Override
+    public DecayFunction getDecayFunction() {
+        return LINEAR_DECAY_FUNCTION;
+    }
+
+    private static final class LinearDecayScoreFunction implements DecayFunction {
+
+        @Override
+        public double evaluate(double value, double scale) {
+            return Math.max(0.0, (scale - value) / scale);
+        }
+
+        @Override
+        public Explanation explainFunction(String valueExpl, double value, double scale) {
+            return Explanation.match(
+                    (float) evaluate(value, scale),
+                    "max(0.0, ((" + scale + " - " + valueExpl + ")/" + scale + ")");
+        }
+
+        @Override
+        public double processScale(double scale, double decay) {
+            return scale / (1.0 - decay);
+        }
+
+        @Override
+        public int hashCode() {
+            return this.getClass().hashCode();
+        }
+
+        @Override
+        public boolean equals(Object obj) {
+            if (super.equals(obj)) {
+                return true;
+            }
+            return obj != null && getClass() != obj.getClass();
+        }
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/lin/LinearDecayFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/lin/LinearDecayFunctionParser.java
index 215a787..569304c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/lin/LinearDecayFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/lin/LinearDecayFunctionParser.java
@@ -19,44 +19,21 @@
 
 package org.elasticsearch.index.query.functionscore.lin;
 
-import org.apache.lucene.search.Explanation;
-import org.elasticsearch.index.query.functionscore.DecayFunction;
 import org.elasticsearch.index.query.functionscore.DecayFunctionParser;
 
-public class LinearDecayFunctionParser extends DecayFunctionParser {
+public class LinearDecayFunctionParser extends DecayFunctionParser<LinearDecayFunctionBuilder> {
 
     public static final String[] NAMES = { "linear" };
 
+    private static final LinearDecayFunctionBuilder PROTOTYPE = new LinearDecayFunctionBuilder("", "", "", "");
+
     @Override
     public String[] getNames() {
         return NAMES;
     }
 
-    static final DecayFunction decayFunction = new LinearDecayScoreFunction();
-
     @Override
-    public DecayFunction getDecayFunction() {
-        return decayFunction;
-    }
-
-    final static class LinearDecayScoreFunction implements DecayFunction {
-
-        @Override
-        public double evaluate(double value, double scale) { 
-            return Math.max(0.0, (scale - value) / scale);
-        }
-
-        @Override
-        public Explanation explainFunction(String valueExpl, double value, double scale) {
-            return Explanation.match(
-                    (float) evaluate(value, scale),
-                    "max(0.0, ((" + scale + " - " + valueExpl + ")/" + scale + ")");
-        }
-
-        @Override
-        public double processScale(double scale, double decay) {
-            return scale / (1.0 - decay);
-        }
-
+    public LinearDecayFunctionBuilder getBuilderPrototype() {
+        return PROTOTYPE;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionBuilder.java
index 22285f8..e62aabc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionBuilder.java
@@ -18,17 +18,27 @@
  */
 package org.elasticsearch.index.query.functionscore.random;
 
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.lucene.search.function.RandomScoreFunction;
+import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.index.fielddata.IndexFieldData;
+import org.elasticsearch.index.mapper.MappedFieldType;
+import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
+import org.elasticsearch.index.shard.ShardId;
+import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
+import java.util.Objects;
 
 /**
  * A function that computes a random score for the matched documents
  */
-public class RandomScoreFunctionBuilder extends ScoreFunctionBuilder {
+public class RandomScoreFunctionBuilder extends ScoreFunctionBuilder<RandomScoreFunctionBuilder> {
 
-    private Object seed = null;
+    private Integer seed;
 
     public RandomScoreFunctionBuilder() {
     }
@@ -54,7 +64,7 @@ public class RandomScoreFunctionBuilder extends ScoreFunctionBuilder {
      * @see #seed(int)
      */
     public RandomScoreFunctionBuilder seed(long seed) {
-        this.seed = seed;
+        this.seed = hash(seed);
         return this;
     }
 
@@ -63,19 +73,64 @@ public class RandomScoreFunctionBuilder extends ScoreFunctionBuilder {
      * @see #seed(int)
      */
     public RandomScoreFunctionBuilder seed(String seed) {
-        this.seed = seed;
+        if (seed == null) {
+            throw new IllegalArgumentException("random_score function: seed must not be null");
+        }
+        this.seed = seed.hashCode();
         return this;
     }
 
+    public Integer getSeed() {
+        return seed;
+    }
+
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject(getName());
-        if (seed instanceof Number) {
-            builder.field("seed", ((Number)seed).longValue());
-        } else if (seed != null) {
-            builder.field("seed", seed.toString());
+        if (seed != null) {
+            builder.field("seed", seed);
         }
         builder.endObject();
     }
 
+    @Override
+    protected RandomScoreFunctionBuilder doReadFrom(StreamInput in) throws IOException {
+        RandomScoreFunctionBuilder randomScoreFunctionBuilder = new RandomScoreFunctionBuilder();
+        randomScoreFunctionBuilder.seed = in.readInt();
+        return randomScoreFunctionBuilder;
+    }
+
+    @Override
+    protected void doWriteTo(StreamOutput out) throws IOException {
+        out.writeInt(seed);
+    }
+
+    @Override
+    protected boolean doEquals(RandomScoreFunctionBuilder functionBuilder) {
+        return Objects.equals(this.seed, functionBuilder.seed);
+    }
+
+    @Override
+    protected int doHashCode() {
+        return Objects.hash(this.seed);
+    }
+
+    @Override
+    protected ScoreFunction doToFunction(QueryShardContext context) {
+        final MappedFieldType fieldType = context.mapperService().smartNameFieldType("_uid");
+        if (fieldType == null) {
+            // mapper could be null if we are on a shard with no docs yet, so this won't actually be used
+            return new RandomScoreFunction();
+        }
+        //TODO find a way to not get the shard_id from the current search context? make it available in QueryShardContext?
+        //this currently causes NPE in FunctionScoreQueryBuilderTests#testToQuery
+        final ShardId shardId = SearchContext.current().indexShard().shardId();
+        final int salt = (context.index().name().hashCode() << 10) | shardId.id();
+        final IndexFieldData<?> uidFieldData = context.getForField(fieldType);
+        return new RandomScoreFunction(this.seed == null ? hash(context.nowInMillis()) : seed, salt, uidFieldData);
+    }
+
+    private static int hash(long value) {
+        return (int) (value ^ (value >>> 32));
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
index ec8cca4..9b062d4 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
@@ -22,24 +22,19 @@ package org.elasticsearch.index.query.functionscore.random;
 
 
 import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.lucene.search.function.RandomScoreFunction;
-import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.fielddata.IndexFieldData;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.common.ParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
-import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
 
-public class RandomScoreFunctionParser implements ScoreFunctionParser {
+public class RandomScoreFunctionParser implements ScoreFunctionParser<RandomScoreFunctionBuilder> {
 
     public static String[] NAMES = { "random_score", "randomScore" };
 
+    private static RandomScoreFunctionBuilder PROTOTYPE = new RandomScoreFunctionBuilder();
+
     @Inject
     public RandomScoreFunctionParser() {
     }
@@ -50,10 +45,8 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
     }
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, ParsingException {
-        QueryParseContext parseContext = context.parseContext();
-        int seed = -1;
-
+    public RandomScoreFunctionBuilder fromXContent(QueryParseContext parseContext, XContentParser parser) throws IOException, ParsingException {
+        RandomScoreFunctionBuilder randomScoreFunctionBuilder = new RandomScoreFunctionBuilder();
         String currentFieldName = null;
         XContentParser.Token token;
         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
@@ -63,15 +56,15 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
                 if ("seed".equals(currentFieldName)) {
                     if (token == XContentParser.Token.VALUE_NUMBER) {
                         if (parser.numberType() == XContentParser.NumberType.INT) {
-                            seed = parser.intValue();
+                            randomScoreFunctionBuilder.seed(parser.intValue());
                         } else if (parser.numberType() == XContentParser.NumberType.LONG) {
-                            seed = hash(parser.longValue());
+                            randomScoreFunctionBuilder.seed(parser.longValue());
                         } else {
                             throw new ParsingException(parser.getTokenLocation(), "random_score seed must be an int, long or string, not '"
                                     + token.toString() + "'");
                         }
                     } else if (token == XContentParser.Token.VALUE_STRING) {
-                        seed = parser.text().hashCode();
+                        randomScoreFunctionBuilder.seed(parser.text());
                     } else {
                         throw new ParsingException(parser.getTokenLocation(), "random_score seed must be an int/long or string, not '"
                                 + token.toString() + "'");
@@ -81,24 +74,11 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
                 }
             }
         }
-
-        final MappedFieldType fieldType = SearchContext.current().mapperService().smartNameFieldType("_uid");
-        if (fieldType == null) {
-            // mapper could be null if we are on a shard with no docs yet, so this won't actually be used
-            return new RandomScoreFunction();
-        }
-
-        if (seed == -1) {
-            seed = hash(context.nowInMillis());
-        }
-        final ShardId shardId = SearchContext.current().indexShard().shardId();
-        final int salt = (shardId.index().name().hashCode() << 10) | shardId.id();
-        final IndexFieldData<?> uidFieldData = SearchContext.current().fieldData().getForField(fieldType);
-
-        return new RandomScoreFunction(seed, salt, uidFieldData);
+        return randomScoreFunctionBuilder;
     }
 
-    private static final int hash(long value) {
-        return (int) (value ^ (value >>> 32));
+    @Override
+    public RandomScoreFunctionBuilder getBuilderPrototype() {
+        return PROTOTYPE;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionBuilder.java
index 023d8a6..266e75f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionBuilder.java
@@ -19,20 +19,27 @@
 
 package org.elasticsearch.index.query.functionscore.script;
 
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.lucene.search.function.ScoreFunction;
+import org.elasticsearch.common.lucene.search.function.ScriptScoreFunction;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.index.query.QueryShardContext;
+import org.elasticsearch.index.query.QueryShardException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.Script.ScriptField;
+import org.elasticsearch.script.ScriptContext;
+import org.elasticsearch.script.SearchScript;
 
 import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
+import java.util.Objects;
 
 /**
  * A function that uses a script to compute or influence the score of documents
  * that match with the inner query or filter.
  */
-public class ScriptScoreFunctionBuilder extends ScoreFunctionBuilder {
+public class ScriptScoreFunctionBuilder extends ScoreFunctionBuilder<ScriptScoreFunctionBuilder> {
 
     private final Script script;
 
@@ -43,6 +50,10 @@ public class ScriptScoreFunctionBuilder extends ScoreFunctionBuilder {
         this.script = script;
     }
 
+    public Script getScript() {
+        return this.script;
+    }
+
     @Override
     public void doXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject(getName());
@@ -54,4 +65,34 @@ public class ScriptScoreFunctionBuilder extends ScoreFunctionBuilder {
     public String getName() {
         return ScriptScoreFunctionParser.NAMES[0];
     }
+
+    @Override
+    protected void doWriteTo(StreamOutput out) throws IOException {
+        script.writeTo(out);
+    }
+
+    @Override
+    protected ScriptScoreFunctionBuilder doReadFrom(StreamInput in) throws IOException {
+        return new ScriptScoreFunctionBuilder(Script.readScript(in));
+    }
+
+    @Override
+    protected boolean doEquals(ScriptScoreFunctionBuilder functionBuilder) {
+        return Objects.equals(this.script, functionBuilder.script);
+    }
+
+    @Override
+    protected int doHashCode() {
+        return Objects.hash(this.script);
+    }
+
+    @Override
+    protected ScoreFunction doToFunction(QueryShardContext context) {
+        try {
+            SearchScript searchScript = context.scriptService().search(context.lookup(), script, ScriptContext.Standard.SEARCH);
+            return new ScriptScoreFunction(script, searchScript);
+        } catch (Exception e) {
+            throw new QueryShardException(context, "script_score: the script could not be loaded", e);
+        }
+    }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
index 4d2e205..d0dbccc 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/script/ScriptScoreFunctionParser.java
@@ -21,20 +21,14 @@
 
 package org.elasticsearch.index.query.functionscore.script;
 
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.lucene.search.function.ScoreFunction;
-import org.elasticsearch.common.lucene.search.function.ScriptScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.common.ParsingException;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.Script.ScriptField;
-import org.elasticsearch.script.ScriptContext;
 import org.elasticsearch.script.ScriptParameterParser;
 import org.elasticsearch.script.ScriptParameterParser.ScriptParameterValue;
-import org.elasticsearch.script.SearchScript;
 
 import java.io.IOException;
 import java.util.HashMap;
@@ -43,13 +37,11 @@ import java.util.Map;
 /**
  *
  */
-public class ScriptScoreFunctionParser implements ScoreFunctionParser {
+public class ScriptScoreFunctionParser implements ScoreFunctionParser<ScriptScoreFunctionBuilder> {
 
     public static String[] NAMES = { "script_score", "scriptScore" };
 
-    @Inject
-    public ScriptScoreFunctionParser() {
-    }
+    private static final ScriptScoreFunctionBuilder PROTOTYPE = new ScriptScoreFunctionBuilder(new Script(""));
 
     @Override
     public String[] getNames() {
@@ -57,8 +49,7 @@ public class ScriptScoreFunctionParser implements ScoreFunctionParser {
     }
 
     @Override
-    public ScoreFunction parse(QueryShardContext context, XContentParser parser) throws IOException, ParsingException {
-        QueryParseContext parseContext = context.parseContext();
+    public ScriptScoreFunctionBuilder fromXContent(QueryParseContext parseContext, XContentParser parser) throws IOException, ParsingException {
         ScriptParameterParser scriptParameterParser = new ScriptParameterParser();
         Script script = null;
         Map<String, Object> vars = null;
@@ -98,12 +89,11 @@ public class ScriptScoreFunctionParser implements ScoreFunctionParser {
             throw new ParsingException(parser.getTokenLocation(), NAMES[0] + " requires 'script' field");
         }
 
-        SearchScript searchScript;
-        try {
-            searchScript = context.scriptService().search(context.lookup(), script, ScriptContext.Standard.SEARCH);
-            return new ScriptScoreFunction(script, searchScript);
-        } catch (Exception e) {
-            throw new ParsingException(parser.getTokenLocation(), NAMES[0] + " the script could not be loaded", e);
-        }
+        return new ScriptScoreFunctionBuilder(script);
+    }
+
+    @Override
+    public ScriptScoreFunctionBuilder getBuilderPrototype() {
+        return PROTOTYPE;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/weight/WeightBuilder.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/weight/WeightBuilder.java
index 5b62843..a49eb19 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/weight/WeightBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/weight/WeightBuilder.java
@@ -19,8 +19,11 @@
 
 package org.elasticsearch.index.query.functionscore.weight;
 
-import org.elasticsearch.common.xcontent.ToXContent;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
 
 import java.io.IOException;
@@ -28,7 +31,7 @@ import java.io.IOException;
 /**
  * A query that multiplies the weight to the score.
  */
-public class WeightBuilder extends ScoreFunctionBuilder {
+public class WeightBuilder extends ScoreFunctionBuilder<WeightBuilder> {
 
     @Override
     public String getName() {
@@ -38,4 +41,30 @@ public class WeightBuilder extends ScoreFunctionBuilder {
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
     }
+
+    @Override
+    protected void doWriteTo(StreamOutput out) throws IOException {
+
+    }
+
+    @Override
+    protected WeightBuilder doReadFrom(StreamInput in) throws IOException {
+        return new WeightBuilder();
+    }
+
+    @Override
+    protected boolean doEquals(WeightBuilder functionBuilder) {
+        return true;
+    }
+
+    @Override
+    protected int doHashCode() {
+        return 0;
+    }
+
+    @Override
+    protected ScoreFunction doToFunction(QueryShardContext context) throws IOException {
+        //nothing to do here, weight will be applied by the parent class, no score function
+        return null;
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/search/stats/SearchSlowLog.java b/core/src/main/java/org/elasticsearch/index/search/stats/SearchSlowLog.java
index 108dab4..cfb7402 100644
--- a/core/src/main/java/org/elasticsearch/index/search/stats/SearchSlowLog.java
+++ b/core/src/main/java/org/elasticsearch/index/search/stats/SearchSlowLog.java
@@ -189,11 +189,24 @@ public final class SearchSlowLog{
                 sb.append("], ");
             }
             sb.append("search_type[").append(context.searchType()).append("], total_shards[").append(context.numberOfShards()).append("], ");
-            if (context.request().source() != null) {
-                sb.append("source[").append(context.request().source()).append("], ");
+            if (context.request().source() != null && context.request().source().length() > 0) {
+                try {
+                    sb.append("source[").append(XContentHelper.convertToJson(context.request().source(), reformat)).append("], ");
+                } catch (IOException e) {
+                    sb.append("source[_failed_to_convert_], ");
+                }
             } else {
                 sb.append("source[], ");
             }
+            if (context.request().extraSource() != null && context.request().extraSource().length() > 0) {
+                try {
+                    sb.append("extra_source[").append(XContentHelper.convertToJson(context.request().extraSource(), reformat)).append("], ");
+                } catch (IOException e) {
+                    sb.append("extra_source[_failed_to_convert_], ");
+                }
+            } else {
+                sb.append("extra_source[], ");
+            }
             return sb.toString();
         }
     }
diff --git a/core/src/main/java/org/elasticsearch/indices/cache/request/IndicesRequestCache.java b/core/src/main/java/org/elasticsearch/indices/cache/request/IndicesRequestCache.java
index 5048c7d..4ab4691 100644
--- a/core/src/main/java/org/elasticsearch/indices/cache/request/IndicesRequestCache.java
+++ b/core/src/main/java/org/elasticsearch/indices/cache/request/IndicesRequestCache.java
@@ -207,6 +207,11 @@ public class IndicesRequestCache extends AbstractComponent implements RemovalLis
      * Can the shard request be cached at all?
      */
     public boolean canCache(ShardSearchRequest request, SearchContext context) {
+        // TODO: for now, template is not supported, though we could use the generated bytes as the key
+        if (hasLength(request.templateSource())) {
+            return false;
+        }
+
         // for now, only enable it for requests with no hits
         if (context.size() != 0) {
             return false;
diff --git a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/validate/query/RestValidateQueryAction.java b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/validate/query/RestValidateQueryAction.java
index d67635c..6766196 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/validate/query/RestValidateQueryAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/validate/query/RestValidateQueryAction.java
@@ -29,13 +29,7 @@ import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.rest.BaseRestHandler;
-import org.elasticsearch.rest.BytesRestResponse;
-import org.elasticsearch.rest.RestChannel;
-import org.elasticsearch.rest.RestController;
-import org.elasticsearch.rest.RestRequest;
-import org.elasticsearch.rest.RestResponse;
+import org.elasticsearch.rest.*;
 import org.elasticsearch.rest.action.support.RestActions;
 import org.elasticsearch.rest.action.support.RestBuilderListener;
 
@@ -67,11 +61,9 @@ public class RestValidateQueryAction extends BaseRestHandler {
         if (RestActions.hasBodyContent(request)) {
             validateQueryRequest.source(RestActions.getRestContent(request));
         } else {
-            QueryBuilder<?> queryBuilder = RestActions.parseQuerySource(request);
-            if (queryBuilder != null) {
-                QuerySourceBuilder querySourceBuilder = new QuerySourceBuilder();
-                querySourceBuilder.setQuery(queryBuilder);
-                validateQueryRequest.source(querySourceBuilder.buildAsBytes());
+            QuerySourceBuilder querySourceBuilder = RestActions.parseQuerySource(request);
+            if (querySourceBuilder != null) {
+                validateQueryRequest.source(querySourceBuilder);
             }
         }
         validateQueryRequest.types(Strings.splitStringByCommaToArray(request.param("type")));
diff --git a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/warmer/put/RestPutWarmerAction.java b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/warmer/put/RestPutWarmerAction.java
index c50cf18..4c421cc 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/admin/indices/warmer/put/RestPutWarmerAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/admin/indices/warmer/put/RestPutWarmerAction.java
@@ -19,27 +19,17 @@
 package org.elasticsearch.rest.action.admin.indices.warmer.put;
 
 import org.elasticsearch.action.admin.indices.warmer.put.PutWarmerRequest;
+import org.elasticsearch.action.admin.indices.warmer.put.PutWarmerResponse;
 import org.elasticsearch.action.search.SearchRequest;
 import org.elasticsearch.action.support.IndicesOptions;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryParseContext;
-import org.elasticsearch.indices.query.IndicesQueriesRegistry;
-import org.elasticsearch.rest.BaseRestHandler;
-import org.elasticsearch.rest.RestChannel;
-import org.elasticsearch.rest.RestController;
-import org.elasticsearch.rest.RestRequest;
+import org.elasticsearch.rest.*;
 import org.elasticsearch.rest.action.support.AcknowledgedRestListener;
-import org.elasticsearch.rest.action.support.RestActions;
 import org.elasticsearch.search.builder.SearchSourceBuilder;
 
-import java.io.IOException;
-
 import static org.elasticsearch.rest.RestRequest.Method.POST;
 import static org.elasticsearch.rest.RestRequest.Method.PUT;
 
@@ -47,12 +37,9 @@ import static org.elasticsearch.rest.RestRequest.Method.PUT;
  */
 public class RestPutWarmerAction extends BaseRestHandler {
 
-    private final IndicesQueriesRegistry queryRegistry;
-
     @Inject
-    public RestPutWarmerAction(Settings settings, RestController controller, Client client, IndicesQueriesRegistry queryRegistry) {
+    public RestPutWarmerAction(Settings settings, RestController controller, Client client) {
         super(settings, controller, client);
-        this.queryRegistry = queryRegistry;
         controller.registerHandler(PUT, "/_warmer/{name}", this);
         controller.registerHandler(PUT, "/{index}/_warmer/{name}", this);
         controller.registerHandler(PUT, "/{index}/{type}/_warmer/{name}", this);
@@ -71,17 +58,12 @@ public class RestPutWarmerAction extends BaseRestHandler {
     }
 
     @Override
-    public void handleRequest(final RestRequest request, final RestChannel channel, final Client client) throws IOException {
+    public void handleRequest(final RestRequest request, final RestChannel channel, final Client client) {
         PutWarmerRequest putWarmerRequest = new PutWarmerRequest(request.param("name"));
-
-        BytesReference sourceBytes = RestActions.getRestContent(request);
-        XContentParser parser = XContentFactory.xContent(sourceBytes).createParser(sourceBytes);
-        QueryParseContext queryParseContext = new QueryParseContext(queryRegistry);
-        queryParseContext.reset(parser);
-        SearchSourceBuilder source = SearchSourceBuilder.PROTOTYPE.fromXContent(parser, queryParseContext);
         SearchRequest searchRequest = new SearchRequest(Strings.splitStringByCommaToArray(request.param("index")))
                 .types(Strings.splitStringByCommaToArray(request.param("type")))
-                .requestCache(request.paramAsBoolean("request_cache", null)).source(source);
+                .requestCache(request.paramAsBoolean("request_cache", null))
+                .source(request.content());
         searchRequest.indicesOptions(IndicesOptions.fromRequest(request, searchRequest.indicesOptions()));
         putWarmerRequest.searchRequest(searchRequest);
         putWarmerRequest.timeout(request.paramAsTime("timeout", putWarmerRequest.timeout()));
diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestCountAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestCountAction.java
index 86029e5..72057a9 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestCountAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestCountAction.java
@@ -19,48 +19,32 @@
 
 package org.elasticsearch.rest.action.cat;
 
-import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.count.CountRequest;
 import org.elasticsearch.action.count.CountResponse;
 import org.elasticsearch.action.support.QuerySourceBuilder;
-import org.elasticsearch.bootstrap.Elasticsearch;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.Table;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.index.query.QueryParseContext;
-import org.elasticsearch.indices.query.IndicesQueriesRegistry;
-import org.elasticsearch.rest.RestChannel;
-import org.elasticsearch.rest.RestController;
-import org.elasticsearch.rest.RestRequest;
-import org.elasticsearch.rest.RestResponse;
-import org.elasticsearch.rest.action.search.RestSearchAction;
+import org.elasticsearch.rest.*;
 import org.elasticsearch.rest.action.support.RestActions;
 import org.elasticsearch.rest.action.support.RestResponseListener;
 import org.elasticsearch.rest.action.support.RestTable;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.joda.time.format.DateTimeFormat;
 import org.joda.time.format.DateTimeFormatter;
 
-import java.io.IOException;
 import java.util.concurrent.TimeUnit;
 
 import static org.elasticsearch.rest.RestRequest.Method.GET;
 
 public class RestCountAction extends AbstractCatAction {
 
-    private final IndicesQueriesRegistry indicesQueriesRegistry;
-
     @Inject
-    public RestCountAction(Settings settings, RestController restController, RestController controller, Client client, IndicesQueriesRegistry indicesQueriesRegistry) {
+    public RestCountAction(Settings settings, RestController restController, RestController controller, Client client) {
         super(settings, controller, client);
         restController.registerHandler(GET, "/_cat/count", this);
         restController.registerHandler(GET, "/_cat/count/{index}", this);
-        this.indicesQueriesRegistry = indicesQueriesRegistry;
     }
 
     @Override
@@ -75,22 +59,14 @@ public class RestCountAction extends AbstractCatAction {
         CountRequest countRequest = new CountRequest(indices);
         String source = request.param("source");
         if (source != null) {
-            try (XContentParser requestParser = XContentFactory.xContent(source).createParser(source)) {
-                QueryParseContext context = new QueryParseContext(indicesQueriesRegistry);
-                context.reset(requestParser);
-                final SearchSourceBuilder builder = SearchSourceBuilder.PROTOTYPE.fromXContent(requestParser, context);
-                countRequest.searchSource(builder);
-            } catch (IOException e) {
-                throw new ElasticsearchException("failed to parse source", e);
-            }
+            countRequest.source(source);
         } else {
-            QueryBuilder<?> queryBuilder = RestActions.parseQuerySource(request);
-            if (queryBuilder != null) {
-                QuerySourceBuilder querySourceBuilder = new QuerySourceBuilder();
-                querySourceBuilder.setQuery(queryBuilder);
-                countRequest.query(queryBuilder);
+            QuerySourceBuilder querySourceBuilder = RestActions.parseQuerySource(request);
+            if (querySourceBuilder != null) {
+                countRequest.source(querySourceBuilder);
             }
         }
+
         client.count(countRequest, new RestResponseListener<CountResponse>(channel) {
             @Override
             public RestResponse buildResponse(CountResponse countResponse) throws Exception {
diff --git a/core/src/main/java/org/elasticsearch/rest/action/count/RestCountAction.java b/core/src/main/java/org/elasticsearch/rest/action/count/RestCountAction.java
index c0548ce..677f3af 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/count/RestCountAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/count/RestCountAction.java
@@ -19,49 +19,32 @@
 
 package org.elasticsearch.rest.action.count;
 
-import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.count.CountRequest;
 import org.elasticsearch.action.count.CountResponse;
 import org.elasticsearch.action.support.IndicesOptions;
 import org.elasticsearch.action.support.QuerySourceBuilder;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.index.query.QueryParseContext;
-import org.elasticsearch.indices.query.IndicesQueriesRegistry;
-import org.elasticsearch.rest.BaseRestHandler;
-import org.elasticsearch.rest.BytesRestResponse;
-import org.elasticsearch.rest.RestChannel;
-import org.elasticsearch.rest.RestController;
-import org.elasticsearch.rest.RestRequest;
-import org.elasticsearch.rest.RestResponse;
+import org.elasticsearch.rest.*;
 import org.elasticsearch.rest.action.support.RestActions;
 import org.elasticsearch.rest.action.support.RestBuilderListener;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
-
-import java.io.IOException;
 
 import static org.elasticsearch.action.count.CountRequest.DEFAULT_MIN_SCORE;
+import static org.elasticsearch.search.internal.SearchContext.DEFAULT_TERMINATE_AFTER;
 import static org.elasticsearch.rest.RestRequest.Method.GET;
 import static org.elasticsearch.rest.RestRequest.Method.POST;
 import static org.elasticsearch.rest.action.support.RestActions.buildBroadcastShardsHeader;
-import static org.elasticsearch.search.internal.SearchContext.DEFAULT_TERMINATE_AFTER;
 
 /**
  *
  */
 public class RestCountAction extends BaseRestHandler {
 
-    private final IndicesQueriesRegistry indicesQueriesRegistry;
-
     @Inject
-    public RestCountAction(Settings settings, RestController controller, Client client, IndicesQueriesRegistry indicesQueriesRegistry) {
+    public RestCountAction(Settings settings, RestController controller, Client client) {
         super(settings, controller, client);
         controller.registerHandler(POST, "/_count", this);
         controller.registerHandler(GET, "/_count", this);
@@ -69,7 +52,6 @@ public class RestCountAction extends BaseRestHandler {
         controller.registerHandler(GET, "/{index}/_count", this);
         controller.registerHandler(POST, "/{index}/{type}/_count", this);
         controller.registerHandler(GET, "/{index}/{type}/_count", this);
-        this.indicesQueriesRegistry = indicesQueriesRegistry;
     }
 
     @Override
@@ -77,19 +59,11 @@ public class RestCountAction extends BaseRestHandler {
         CountRequest countRequest = new CountRequest(Strings.splitStringByCommaToArray(request.param("index")));
         countRequest.indicesOptions(IndicesOptions.fromRequest(request, countRequest.indicesOptions()));
         if (RestActions.hasBodyContent(request)) {
-            BytesReference restContent = RestActions.getRestContent(request);
-            try (XContentParser requestParser = XContentFactory.xContent(restContent).createParser(restContent)) {
-                QueryParseContext context = new QueryParseContext(indicesQueriesRegistry);
-                context.reset(requestParser);
-                final SearchSourceBuilder builder = SearchSourceBuilder.PROTOTYPE.fromXContent(requestParser, context);
-                countRequest.searchSource(builder);
-            } catch (IOException e) {
-                throw new ElasticsearchException("failed to parse source", e);
-            }
+            countRequest.source(RestActions.getRestContent(request));
         } else {
-            QueryBuilder<?> queryBuilder = RestActions.parseQuerySource(request);
-            if (queryBuilder != null) {
-                countRequest.query(queryBuilder);
+            QuerySourceBuilder querySourceBuilder = RestActions.parseQuerySource(request);
+            if (querySourceBuilder != null) {
+                countRequest.source(querySourceBuilder);
             }
         }
         countRequest.routing(request.param("routing"));
diff --git a/core/src/main/java/org/elasticsearch/rest/action/exists/RestExistsAction.java b/core/src/main/java/org/elasticsearch/rest/action/exists/RestExistsAction.java
index 1fc8400..7cfe7ca 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/exists/RestExistsAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/exists/RestExistsAction.java
@@ -27,14 +27,7 @@ import org.elasticsearch.client.Client;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.rest.BaseRestHandler;
-import org.elasticsearch.rest.BytesRestResponse;
-import org.elasticsearch.rest.RestChannel;
-import org.elasticsearch.rest.RestController;
-import org.elasticsearch.rest.RestRequest;
-import org.elasticsearch.rest.RestResponse;
-import org.elasticsearch.rest.RestStatus;
+import org.elasticsearch.rest.*;
 import org.elasticsearch.rest.action.support.RestActions;
 import org.elasticsearch.rest.action.support.RestBuilderListener;
 
@@ -58,11 +51,9 @@ public class RestExistsAction extends BaseRestHandler {
         if (RestActions.hasBodyContent(request)) {
             existsRequest.source(RestActions.getRestContent(request));
         } else {
-            QueryBuilder<?> queryBuilder = RestActions.parseQuerySource(request);
-            if (queryBuilder != null) {
-                QuerySourceBuilder querySourceBuilder = new QuerySourceBuilder();
-                querySourceBuilder.setQuery(queryBuilder);
-                existsRequest.source(querySourceBuilder.buildAsBytes());
+            QuerySourceBuilder querySourceBuilder = RestActions.parseQuerySource(request);
+            if (querySourceBuilder != null) {
+                existsRequest.source(querySourceBuilder);
             }
         }
         existsRequest.routing(request.param("routing"));
diff --git a/core/src/main/java/org/elasticsearch/rest/action/search/RestMultiSearchAction.java b/core/src/main/java/org/elasticsearch/rest/action/search/RestMultiSearchAction.java
index 31bf0ab..af1f2f4 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/search/RestMultiSearchAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/search/RestMultiSearchAction.java
@@ -20,31 +20,16 @@
 package org.elasticsearch.rest.action.search;
 
 import org.elasticsearch.action.search.MultiSearchRequest;
-import org.elasticsearch.action.search.SearchRequest;
+import org.elasticsearch.action.search.MultiSearchResponse;
 import org.elasticsearch.action.support.IndicesOptions;
 import org.elasticsearch.client.Client;
-import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContent;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryParseContext;
-import org.elasticsearch.index.query.TemplateQueryParser;
-import org.elasticsearch.indices.query.IndicesQueriesRegistry;
 import org.elasticsearch.rest.*;
 import org.elasticsearch.rest.action.support.RestActions;
 import org.elasticsearch.rest.action.support.RestToXContentListener;
-import org.elasticsearch.script.Template;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 
-import java.util.Map;
-
-import static org.elasticsearch.common.xcontent.support.XContentMapValues.nodeBooleanValue;
-import static org.elasticsearch.common.xcontent.support.XContentMapValues.nodeStringArrayValue;
-import static org.elasticsearch.common.xcontent.support.XContentMapValues.nodeStringValue;
 import static org.elasticsearch.rest.RestRequest.Method.GET;
 import static org.elasticsearch.rest.RestRequest.Method.POST;
 
@@ -53,11 +38,9 @@ import static org.elasticsearch.rest.RestRequest.Method.POST;
 public class RestMultiSearchAction extends BaseRestHandler {
 
     private final boolean allowExplicitIndex;
-    private final IndicesQueriesRegistry indicesQueriesRegistry;
-
 
     @Inject
-    public RestMultiSearchAction(Settings settings, RestController controller, Client client, IndicesQueriesRegistry indicesQueriesRegistry) {
+    public RestMultiSearchAction(Settings settings, RestController controller, Client client) {
         super(settings, controller, client);
 
         controller.registerHandler(GET, "/_msearch", this);
@@ -75,7 +58,6 @@ public class RestMultiSearchAction extends BaseRestHandler {
         controller.registerHandler(POST, "/{index}/{type}/_msearch/template", this);
 
         this.allowExplicitIndex = settings.getAsBoolean("rest.action.multi.allow_explicit_index", true);
-        this.indicesQueriesRegistry = indicesQueriesRegistry;
     }
 
     @Override
@@ -87,117 +69,12 @@ public class RestMultiSearchAction extends BaseRestHandler {
         String path = request.path();
         boolean isTemplateRequest = isTemplateRequest(path);
         IndicesOptions indicesOptions = IndicesOptions.fromRequest(request, multiSearchRequest.indicesOptions());
-        parseRequest(multiSearchRequest, RestActions.getRestContent(request), isTemplateRequest, indices, types, request.param("search_type"), request.param("routing"), indicesOptions, allowExplicitIndex, indicesQueriesRegistry);
-        client.multiSearch(multiSearchRequest, new RestToXContentListener<>(channel));
+        multiSearchRequest.add(RestActions.getRestContent(request), isTemplateRequest, indices, types, request.param("search_type"), request.param("routing"), indicesOptions, allowExplicitIndex);
+
+        client.multiSearch(multiSearchRequest, new RestToXContentListener<MultiSearchResponse>(channel));
     }
 
     private boolean isTemplateRequest(String path) {
         return (path != null && path.endsWith("/template"));
     }
-
-    public static MultiSearchRequest parseRequest(MultiSearchRequest msr, BytesReference data, boolean isTemplateRequest,
-                                                   @Nullable String[] indices,
-                                                   @Nullable String[] types,
-                                                   @Nullable String searchType,
-                                                   @Nullable String routing,
-                                                   IndicesOptions indicesOptions,
-                                                   boolean allowExplicitIndex, IndicesQueriesRegistry indicesQueriesRegistry) throws Exception {
-        XContent xContent = XContentFactory.xContent(data);
-        int from = 0;
-        int length = data.length();
-        byte marker = xContent.streamSeparator();
-        final QueryParseContext queryParseContext = new QueryParseContext(indicesQueriesRegistry);
-        while (true) {
-            int nextMarker = findNextMarker(marker, from, data, length);
-            if (nextMarker == -1) {
-                break;
-            }
-            // support first line with \n
-            if (nextMarker == 0) {
-                from = nextMarker + 1;
-                continue;
-            }
-
-            SearchRequest searchRequest = new SearchRequest();
-            if (indices != null) {
-                searchRequest.indices(indices);
-            }
-            if (indicesOptions != null) {
-                searchRequest.indicesOptions(indicesOptions);
-            }
-            if (types != null && types.length > 0) {
-                searchRequest.types(types);
-            }
-            if (routing != null) {
-                searchRequest.routing(routing);
-            }
-            searchRequest.searchType(searchType);
-
-            IndicesOptions defaultOptions = IndicesOptions.strictExpandOpenAndForbidClosed();
-
-
-            // now parse the action
-            if (nextMarker - from > 0) {
-                try (XContentParser parser = xContent.createParser(data.slice(from, nextMarker - from))) {
-                    Map<String, Object> source = parser.map();
-                    for (Map.Entry<String, Object> entry : source.entrySet()) {
-                        Object value = entry.getValue();
-                        if ("index".equals(entry.getKey()) || "indices".equals(entry.getKey())) {
-                            if (!allowExplicitIndex) {
-                                throw new IllegalArgumentException("explicit index in multi percolate is not allowed");
-                            }
-                            searchRequest.indices(nodeStringArrayValue(value));
-                        } else if ("type".equals(entry.getKey()) || "types".equals(entry.getKey())) {
-                            searchRequest.types(nodeStringArrayValue(value));
-                        } else if ("search_type".equals(entry.getKey()) || "searchType".equals(entry.getKey())) {
-                            searchRequest.searchType(nodeStringValue(value, null));
-                        } else if ("request_cache".equals(entry.getKey()) || "requestCache".equals(entry.getKey())) {
-                            searchRequest.requestCache(nodeBooleanValue(value));
-                        } else if ("preference".equals(entry.getKey())) {
-                            searchRequest.preference(nodeStringValue(value, null));
-                        } else if ("routing".equals(entry.getKey())) {
-                            searchRequest.routing(nodeStringValue(value, null));
-                        }
-                    }
-                    defaultOptions = IndicesOptions.fromMap(source, defaultOptions);
-                }
-            }
-            searchRequest.indicesOptions(defaultOptions);
-
-            // move pointers
-            from = nextMarker + 1;
-            // now for the body
-            nextMarker = findNextMarker(marker, from, data, length);
-            if (nextMarker == -1) {
-                break;
-            }
-            final BytesReference slice = data.slice(from, nextMarker - from);
-            if (isTemplateRequest) {
-                try (XContentParser parser = XContentFactory.xContent(slice).createParser(slice)) {
-                    queryParseContext.reset(parser);
-                    Template template = TemplateQueryParser.parse(parser, queryParseContext.parseFieldMatcher(), "params", "template");
-                    searchRequest.template(template);
-                }
-            } else {
-                try (XContentParser requestParser = XContentFactory.xContent(slice).createParser(slice)) {
-                    queryParseContext.reset(requestParser);
-                    searchRequest.source(SearchSourceBuilder.PROTOTYPE.fromXContent(requestParser, queryParseContext));
-                }
-            }
-            // move pointers
-            from = nextMarker + 1;
-
-            msr.add(searchRequest);
-        }
-        return msr;
-    }
-
-    private static int findNextMarker(byte marker, int from, BytesReference data, int length) {
-        for (int i = from; i < length; i++) {
-            if (data.get(i) == marker) {
-                return i;
-            }
-        }
-        return -1;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java b/core/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java
index 3d8d37e..03a33e0 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java
@@ -20,20 +20,15 @@
 package org.elasticsearch.rest.action.search;
 
 import org.elasticsearch.action.search.SearchRequest;
+import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.action.support.IndicesOptions;
+import org.elasticsearch.action.support.QuerySourceBuilder;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.index.query.QueryParseContext;
-import org.elasticsearch.index.query.TemplateQueryParser;
-import org.elasticsearch.indices.query.IndicesQueriesRegistry;
 import org.elasticsearch.rest.BaseRestHandler;
 import org.elasticsearch.rest.RestChannel;
 import org.elasticsearch.rest.RestController;
@@ -41,15 +36,11 @@ import org.elasticsearch.rest.RestRequest;
 import org.elasticsearch.rest.action.exists.RestExistsAction;
 import org.elasticsearch.rest.action.support.RestActions;
 import org.elasticsearch.rest.action.support.RestStatusToXContentListener;
-import org.elasticsearch.script.Template;
 import org.elasticsearch.search.Scroll;
 import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.search.fetch.source.FetchSourceContext;
 import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.search.sort.SortOrder;
-import org.elasticsearch.search.suggest.SuggestBuilder;
-
-import java.io.IOException;
 
 import static org.elasticsearch.common.unit.TimeValue.parseTimeValue;
 import static org.elasticsearch.rest.RestRequest.Method.GET;
@@ -61,12 +52,9 @@ import static org.elasticsearch.search.suggest.SuggestBuilders.termSuggestion;
  */
 public class RestSearchAction extends BaseRestHandler {
 
-    private final IndicesQueriesRegistry queryRegistry;
-
     @Inject
-    public RestSearchAction(Settings settings, RestController controller, Client client, IndicesQueriesRegistry queryRegistry) {
+    public RestSearchAction(Settings settings, RestController controller, Client client) {
         super(settings, controller, client);
-        this.queryRegistry = queryRegistry;
         controller.registerHandler(GET, "/_search", this);
         controller.registerHandler(POST, "/_search", this);
         controller.registerHandler(GET, "/{index}/_search", this);
@@ -90,37 +78,24 @@ public class RestSearchAction extends BaseRestHandler {
     }
 
     @Override
-    public void handleRequest(final RestRequest request, final RestChannel channel, final Client client) throws IOException {
+    public void handleRequest(final RestRequest request, final RestChannel channel, final Client client) {
         SearchRequest searchRequest;
-        searchRequest = RestSearchAction.parseSearchRequest(queryRegistry, request, parseFieldMatcher);
-        client.search(searchRequest, new RestStatusToXContentListener<>(channel));
+        searchRequest = RestSearchAction.parseSearchRequest(request, parseFieldMatcher);
+        client.search(searchRequest, new RestStatusToXContentListener<SearchResponse>(channel));
     }
 
-    public static SearchRequest parseSearchRequest(IndicesQueriesRegistry indicesQueriesRegistry,  RestRequest request, ParseFieldMatcher parseFieldMatcher) throws IOException {
+    public static SearchRequest parseSearchRequest(RestRequest request, ParseFieldMatcher parseFieldMatcher) {
         String[] indices = Strings.splitStringByCommaToArray(request.param("index"));
         SearchRequest searchRequest = new SearchRequest(indices);
         // get the content, and put it in the body
         // add content/source as template if template flag is set
         boolean isTemplateRequest = request.path().endsWith("/template");
-        final SearchSourceBuilder builder;
         if (RestActions.hasBodyContent(request)) {
-            BytesReference restContent = RestActions.getRestContent(request);
-            QueryParseContext context = new QueryParseContext(indicesQueriesRegistry);
             if (isTemplateRequest) {
-                try (XContentParser parser = XContentFactory.xContent(restContent).createParser(restContent)) {
-                    context.reset(parser);
-                    Template template = TemplateQueryParser.parse(parser, context.parseFieldMatcher(), "params", "template");
-                    searchRequest.template(template);
-                }
-                builder = null;
+                searchRequest.templateSource(RestActions.getRestContent(request));
             } else {
-                try (XContentParser requestParser = XContentFactory.xContent(restContent).createParser(restContent)) {
-                    context.reset(requestParser);
-                    builder = SearchSourceBuilder.PROTOTYPE.fromXContent(requestParser, context);
-                }
+                searchRequest.source(RestActions.getRestContent(request));
             }
-        } else {
-            builder = null;
         }
 
         // do not allow 'query_and_fetch' or 'dfs_query_and_fetch' search types
@@ -133,15 +108,8 @@ public class RestSearchAction extends BaseRestHandler {
         } else {
             searchRequest.searchType(searchType);
         }
-        if (builder == null) {
-            SearchSourceBuilder extraBuilder = new SearchSourceBuilder();
-            if (parseSearchSource(extraBuilder, request)) {
-                searchRequest.source(extraBuilder);
-            }
-        } else {
-            parseSearchSource(builder, request);
-            searchRequest.source(builder);
-        }
+
+        searchRequest.extraSource(parseSearchSource(request));
         searchRequest.requestCache(request.paramAsBoolean("request_cache", null));
 
         String scroll = request.param("scroll");
@@ -157,89 +125,111 @@ public class RestSearchAction extends BaseRestHandler {
         return searchRequest;
     }
 
-    public static boolean parseSearchSource(final SearchSourceBuilder searchSourceBuilder, RestRequest request) {
+    public static SearchSourceBuilder parseSearchSource(RestRequest request) {
+        SearchSourceBuilder searchSourceBuilder = null;
 
-        boolean modified = false;
-        QueryBuilder<?> queryBuilder = RestActions.parseQuerySource(request);
-        if (queryBuilder != null) {
-            searchSourceBuilder.query(queryBuilder);
-            modified = true;
+        QuerySourceBuilder querySourceBuilder = RestActions.parseQuerySource(request);
+        if (querySourceBuilder != null) {
+            searchSourceBuilder = new SearchSourceBuilder();
+            searchSourceBuilder.query(querySourceBuilder);
         }
 
         int from = request.paramAsInt("from", -1);
         if (from != -1) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             searchSourceBuilder.from(from);
-            modified = true;
         }
         int size = request.paramAsInt("size", -1);
         if (size != -1) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             searchSourceBuilder.size(size);
-            modified = true;
         }
 
         if (request.hasParam("explain")) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             searchSourceBuilder.explain(request.paramAsBoolean("explain", null));
-            modified = true;
         }
         if (request.hasParam("version")) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             searchSourceBuilder.version(request.paramAsBoolean("version", null));
-            modified = true;
         }
         if (request.hasParam("timeout")) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             searchSourceBuilder.timeout(request.paramAsTime("timeout", null));
-            modified = true;
         }
         if (request.hasParam("terminate_after")) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             int terminateAfter = request.paramAsInt("terminate_after",
                     SearchContext.DEFAULT_TERMINATE_AFTER);
             if (terminateAfter < 0) {
                 throw new IllegalArgumentException("terminateAfter must be > 0");
             } else if (terminateAfter > 0) {
                 searchSourceBuilder.terminateAfter(terminateAfter);
-                modified = true;
             }
         }
 
         String sField = request.param("fields");
         if (sField != null) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             if (!Strings.hasText(sField)) {
                 searchSourceBuilder.noFields();
-                modified = true;
             } else {
                 String[] sFields = Strings.splitStringByCommaToArray(sField);
                 if (sFields != null) {
                     for (String field : sFields) {
                         searchSourceBuilder.field(field);
-                        modified = true;
                     }
                 }
             }
         }
         String sFieldDataFields = request.param("fielddata_fields");
         if (sFieldDataFields != null) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             if (Strings.hasText(sFieldDataFields)) {
                 String[] sFields = Strings.splitStringByCommaToArray(sFieldDataFields);
                 if (sFields != null) {
                     for (String field : sFields) {
                         searchSourceBuilder.fieldDataField(field);
-                        modified = true;
                     }
                 }
             }
         }
         FetchSourceContext fetchSourceContext = FetchSourceContext.parseFromRestRequest(request);
         if (fetchSourceContext != null) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             searchSourceBuilder.fetchSource(fetchSourceContext);
-            modified = true;
         }
 
         if (request.hasParam("track_scores")) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             searchSourceBuilder.trackScores(request.paramAsBoolean("track_scores", false));
-            modified = true;
         }
 
         String sSorts = request.param("sort");
         if (sSorts != null) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             String[] sorts = Strings.splitStringByCommaToArray(sSorts);
             for (String sort : sorts) {
                 int delimiter = sort.lastIndexOf(":");
@@ -248,33 +238,37 @@ public class RestSearchAction extends BaseRestHandler {
                     String reverse = sort.substring(delimiter + 1);
                     if ("asc".equals(reverse)) {
                         searchSourceBuilder.sort(sortField, SortOrder.ASC);
-                        modified = true;
                     } else if ("desc".equals(reverse)) {
                         searchSourceBuilder.sort(sortField, SortOrder.DESC);
-                        modified = true;
                     }
                 } else {
                     searchSourceBuilder.sort(sort);
-                    modified = true;
                 }
             }
         }
 
         String sStats = request.param("stats");
         if (sStats != null) {
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             searchSourceBuilder.stats(Strings.splitStringByCommaToArray(sStats));
-            modified = true;
         }
 
         String suggestField = request.param("suggest_field");
         if (suggestField != null) {
             String suggestText = request.param("suggest_text", request.param("q"));
             int suggestSize = request.paramAsInt("suggest_size", 5);
+            if (searchSourceBuilder == null) {
+                searchSourceBuilder = new SearchSourceBuilder();
+            }
             String suggestMode = request.param("suggest_mode");
-            searchSourceBuilder.suggest(new SuggestBuilder().addSuggestion(
-                    termSuggestion(suggestField).field(suggestField).text(suggestText).size(suggestSize).suggestMode(suggestMode)));
-            modified = true;
+            searchSourceBuilder.suggest().addSuggestion(
+                    termSuggestion(suggestField).field(suggestField).text(suggestText).size(suggestSize)
+                            .suggestMode(suggestMode)
+            );
         }
-        return modified;
+
+        return searchSourceBuilder;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java b/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
index 464870a..674aa69 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/support/RestActions.java
@@ -21,17 +21,13 @@ package org.elasticsearch.rest.action.support;
 
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.action.ShardOperationFailedException;
+import org.elasticsearch.action.support.QuerySourceBuilder;
 import org.elasticsearch.action.support.broadcast.BroadcastResponse;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.lucene.uid.Versions;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentBuilderString;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentType;
+import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.index.query.Operator;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.QueryStringQueryBuilder;
 import org.elasticsearch.rest.RestRequest;
@@ -89,7 +85,7 @@ public class RestActions {
         builder.endObject();
     }
 
-    public static QueryBuilder<?> parseQuerySource(RestRequest request) {
+    public static QuerySourceBuilder parseQuerySource(RestRequest request) {
         String queryString = request.param("q");
         if (queryString == null) {
             return null;
@@ -104,7 +100,7 @@ public class RestActions {
         if (defaultOperator != null) {
             queryBuilder.defaultOperator(Operator.fromString(defaultOperator));
         }
-        return queryBuilder;
+        return new QuerySourceBuilder().setQuery(queryBuilder);
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/search/MultiValueMode.java b/core/src/main/java/org/elasticsearch/search/MultiValueMode.java
index 32a341e..aec5cd1 100644
--- a/core/src/main/java/org/elasticsearch/search/MultiValueMode.java
+++ b/core/src/main/java/org/elasticsearch/search/MultiValueMode.java
@@ -23,10 +23,13 @@ package org.elasticsearch.search;
 import org.apache.lucene.index.*;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BitSet;
+import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.index.fielddata.FieldData;
 import org.elasticsearch.index.fielddata.NumericDoubleValues;
 import org.elasticsearch.index.fielddata.SortedBinaryDocValues;
@@ -38,7 +41,7 @@ import java.util.Locale;
 /**
  * Defines what values to pick in the case a document contains multiple values for a particular field.
  */
-public enum MultiValueMode {
+public enum MultiValueMode implements Writeable<MultiValueMode> {
 
     /**
      * Pick the sum of all the values.
@@ -941,4 +944,22 @@ public enum MultiValueMode {
         void setDocument(int docId);
         double valueAt(int index);
     }
+
+    @Override
+    public void writeTo(StreamOutput out) throws IOException {
+        out.writeVInt(this.ordinal());
+    }
+
+    public static MultiValueMode readMultiValueModeFrom(StreamInput in) throws IOException {
+        return MultiValueMode.AVG.readFrom(in);
+    }
+
+    @Override
+    public MultiValueMode readFrom(StreamInput in) throws IOException {
+        int ordinal = in.readVInt();
+        if (ordinal < 0 || ordinal >= values().length) {
+            throw new IOException("Unknown MultiValueMode ordinal [" + ordinal + "]");
+        }
+        return values()[ordinal];
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/SearchModule.java b/core/src/main/java/org/elasticsearch/search/SearchModule.java
index fec2a48..7959eaa 100644
--- a/core/src/main/java/org/elasticsearch/search/SearchModule.java
+++ b/core/src/main/java/org/elasticsearch/search/SearchModule.java
@@ -66,11 +66,7 @@ import org.elasticsearch.search.aggregations.bucket.significant.UnmappedSignific
 import org.elasticsearch.search.aggregations.bucket.significant.heuristics.SignificanceHeuristicParser;
 import org.elasticsearch.search.aggregations.bucket.significant.heuristics.SignificanceHeuristicParserMapper;
 import org.elasticsearch.search.aggregations.bucket.significant.heuristics.SignificanceHeuristicStreams;
-import org.elasticsearch.search.aggregations.bucket.terms.DoubleTerms;
-import org.elasticsearch.search.aggregations.bucket.terms.LongTerms;
-import org.elasticsearch.search.aggregations.bucket.terms.StringTerms;
-import org.elasticsearch.search.aggregations.bucket.terms.TermsParser;
-import org.elasticsearch.search.aggregations.bucket.terms.UnmappedTerms;
+import org.elasticsearch.search.aggregations.bucket.terms.*;
 import org.elasticsearch.search.aggregations.metrics.avg.AvgParser;
 import org.elasticsearch.search.aggregations.metrics.avg.InternalAvg;
 import org.elasticsearch.search.aggregations.metrics.cardinality.CardinalityParser;
@@ -150,7 +146,8 @@ import org.elasticsearch.search.query.QueryPhase;
 import org.elasticsearch.search.suggest.Suggester;
 import org.elasticsearch.search.suggest.Suggesters;
 
-import java.util.*;
+import java.util.HashSet;
+import java.util.Set;
 
 /**
  *
@@ -254,7 +251,7 @@ public class SearchModule extends AbstractModule {
         for (Class<? extends ScoreFunctionParser> clazz : functionScoreParsers) {
             parserMapBinder.addBinding().to(clazz);
         }
-        bind(ScoreFunctionParserMapper.class);
+        bind(ScoreFunctionParserMapper.class).asEagerSingleton();
     }
 
     protected void configureHighlighters() {
diff --git a/core/src/main/java/org/elasticsearch/search/SearchService.java b/core/src/main/java/org/elasticsearch/search/SearchService.java
index 879afc4..59ec671 100644
--- a/core/src/main/java/org/elasticsearch/search/SearchService.java
+++ b/core/src/main/java/org/elasticsearch/search/SearchService.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.search;
 
-import com.carrotsearch.hppc.ObjectFloatHashMap;
 import com.carrotsearch.hppc.ObjectHashSet;
 import com.carrotsearch.hppc.ObjectSet;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
@@ -29,6 +28,7 @@ import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.search.TopDocs;
+import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.cache.recycler.PageCacheRecycler;
@@ -39,6 +39,7 @@ import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
@@ -46,8 +47,8 @@ import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.common.util.concurrent.ConcurrentCollections;
 import org.elasticsearch.common.util.concurrent.ConcurrentMapLong;
 import org.elasticsearch.common.util.concurrent.FutureUtils;
-import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentLocation;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.Index;
@@ -62,7 +63,7 @@ import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.MappedFieldType.Loading;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
-import org.elasticsearch.index.query.QueryParseContext;
+import org.elasticsearch.index.query.TemplateQueryParser;
 import org.elasticsearch.index.search.stats.ShardSearchStats;
 import org.elasticsearch.index.search.stats.StatsGroupsParseElement;
 import org.elasticsearch.index.settings.IndexSettings;
@@ -75,10 +76,11 @@ import org.elasticsearch.indices.IndicesWarmer.WarmerContext;
 import org.elasticsearch.indices.cache.request.IndicesRequestCache;
 import org.elasticsearch.node.settings.NodeSettingsService;
 import org.elasticsearch.script.ExecutableScript;
+import org.elasticsearch.script.Script.ScriptParseException;
 import org.elasticsearch.script.ScriptContext;
 import org.elasticsearch.script.ScriptService;
-import org.elasticsearch.script.SearchScript;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
+import org.elasticsearch.script.Template;
+import org.elasticsearch.script.mustache.MustacheScriptEngineService;
 import org.elasticsearch.search.dfs.DfsPhase;
 import org.elasticsearch.search.dfs.DfsSearchResult;
 import org.elasticsearch.search.fetch.FetchPhase;
@@ -86,10 +88,6 @@ import org.elasticsearch.search.fetch.FetchSearchResult;
 import org.elasticsearch.search.fetch.QueryFetchSearchResult;
 import org.elasticsearch.search.fetch.ScrollQueryFetchSearchResult;
 import org.elasticsearch.search.fetch.ShardFetchRequest;
-import org.elasticsearch.search.fetch.fielddata.FieldDataFieldsContext;
-import org.elasticsearch.search.fetch.fielddata.FieldDataFieldsContext.FieldDataField;
-import org.elasticsearch.search.fetch.fielddata.FieldDataFieldsFetchSubPhase;
-import org.elasticsearch.search.fetch.script.ScriptFieldsContext.ScriptField;
 import org.elasticsearch.search.internal.DefaultSearchContext;
 import org.elasticsearch.search.internal.InternalScrollSearchRequest;
 import org.elasticsearch.search.internal.ScrollContext;
@@ -105,7 +103,7 @@ import org.elasticsearch.search.query.ScrollQuerySearchResult;
 import org.elasticsearch.search.warmer.IndexWarmersMetaData;
 import org.elasticsearch.threadpool.ThreadPool;
 
-import java.util.Arrays;
+import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.CountDownLatch;
@@ -114,6 +112,7 @@ import java.util.concurrent.Executor;
 import java.util.concurrent.ScheduledFuture;
 import java.util.concurrent.atomic.AtomicLong;
 
+import static org.elasticsearch.common.Strings.hasLength;
 import static org.elasticsearch.common.unit.TimeValue.timeValueMillis;
 import static org.elasticsearch.common.unit.TimeValue.timeValueMinutes;
 
@@ -573,15 +572,10 @@ public class SearchService extends AbstractLifecycleComponent<SearchService> {
                 context.scrollContext(new ScrollContext());
                 context.scrollContext().scroll = request.scroll();
             }
-            if (request.template() != null) {
-                ExecutableScript executable = this.scriptService.executable(request.template(), ScriptContext.Standard.SEARCH, context);
-                BytesReference run = (BytesReference) executable.run();
-                try (XContentParser parser = XContentFactory.xContent(run).createParser(run)) {
-                    // NOCOMMIT this override the source entirely
-                    request.source(SearchSourceBuilder.PROTOTYPE.fromXContent(parser, new QueryParseContext(indexService.queryParserService().indicesQueriesRegistry())));
-                }
-            }
+
+            parseTemplate(request, context);
             parseSource(context, request.source());
+            parseSource(context, request.extraSource());
 
             // if the from and size are still not set, default them
             if (context.from() == -1) {
@@ -670,194 +664,114 @@ public class SearchService extends AbstractLifecycleComponent<SearchService> {
         }
     }
 
-    private void parseSource(SearchContext context, SearchSourceBuilder source) throws SearchParseException {
-        // nothing to parse...
-        if (source == null) {
-            return;
-        }
+    private void parseTemplate(ShardSearchRequest request, SearchContext searchContext) {
 
-        context.from(source.from());
-        context.size(source.size());
-        ObjectFloatHashMap<String> indexBoostMap = source.indexBoost();
-        if (indexBoostMap != null) {
-            Float indexBoost = indexBoostMap.get(context.shardTarget().index());
-            if (indexBoost != null) {
-                context.queryBoost(indexBoost);
+        BytesReference processedQuery;
+        if (request.template() != null) {
+            ExecutableScript executable = this.scriptService.executable(request.template(), ScriptContext.Standard.SEARCH, searchContext);
+            processedQuery = (BytesReference) executable.run();
+        } else {
+            if (!hasLength(request.templateSource())) {
+                return;
             }
-        }
-        if (source.query() != null) {
-            context.parsedQuery(context.queryParserService().parse(source.query()));
-        }
-        if (source.postFilter() != null) {
-            context.parsedPostFilter(context.queryParserService().parse(source.postFilter()));
-        }
-        if (source.sorts() != null) {
-            XContentParser completeSortParser = null;
-            try {
-                XContentBuilder completeSortBuilder = XContentFactory.jsonBuilder();
-                completeSortBuilder.startObject();
-                completeSortBuilder.startArray("sort");
-                for (BytesReference sort : source.sorts()) {
-                    XContentParser parser = XContentFactory.xContent(sort).createParser(sort);
-                    parser.nextToken();
-                    completeSortBuilder.copyCurrentStructure(parser);
-                }
-                completeSortBuilder.endArray();
-                completeSortBuilder.endObject();
-                BytesReference completeSortBytes = completeSortBuilder.bytes();
-                completeSortParser = XContentFactory.xContent(completeSortBytes).createParser(completeSortBytes);
-                completeSortParser.nextToken();
-                completeSortParser.nextToken();
-                completeSortParser.nextToken();
-                this.elementParsers.get("sort").parse(completeSortParser, context);
-            } catch (Exception e) {
-                String sSource = "_na_";
-                try {
-                    sSource = source.toString();
-                } catch (Throwable e1) {
-                    // ignore
-                }
-                XContentLocation location = completeSortParser != null ? completeSortParser.getTokenLocation() : null;
-                throw new SearchParseException(context, "failed to parse sort source [" + sSource + "]", location, e);
-            } // NORELEASE fix this to be more elegant
-        }
-        context.trackScores(source.trackScores());
-        if (source.minScore() != null) {
-            context.minimumScore(source.minScore());
-        }
-        context.timeoutInMillis(source.timeoutInMillis());
-        context.terminateAfter(source.terminateAfter());
-        if (source.aggregations() != null) {
-            XContentParser completeAggregationsParser = null;
-            try {
-                XContentBuilder completeAggregationsBuilder = XContentFactory.jsonBuilder();
-                completeAggregationsBuilder.startObject();
-                for (BytesReference agg : source.aggregations()) {
-                    XContentParser parser = XContentFactory.xContent(agg).createParser(agg);
-                    parser.nextToken();
-                    parser.nextToken();
-                    completeAggregationsBuilder.field(parser.currentName());
-                    parser.nextToken();
-                    completeAggregationsBuilder.copyCurrentStructure(parser);
-                }
-                completeAggregationsBuilder.endObject();
-                BytesReference completeAggregationsBytes = completeAggregationsBuilder.bytes();
-                completeAggregationsParser = XContentFactory.xContent(completeAggregationsBytes).createParser(completeAggregationsBytes);
-                completeAggregationsParser.nextToken();
-                this.elementParsers.get("aggregations").parse(completeAggregationsParser, context);
-            } catch (Exception e) {
-                String sSource = "_na_";
-                try {
-                    sSource = source.toString();
-                } catch (Throwable e1) {
-                    // ignore
-                }
-                XContentLocation location = completeAggregationsParser != null ? completeAggregationsParser.getTokenLocation() : null;
-                throw new SearchParseException(context, "failed to parse rescore source [" + sSource + "]", location, e);
-            } // NORELEASE fix this to be more elegant
-        }
-        if (source.suggest() != null) {
-            XContentParser suggestParser = null;
+            XContentParser parser = null;
+            Template template = null;
+
             try {
-                suggestParser = XContentFactory.xContent(source.suggest()).createParser(source.suggest());
-                this.elementParsers.get("suggest").parse(suggestParser, context);
-            } catch (Exception e) {
-                String sSource = "_na_";
-                try {
-                    sSource = source.toString();
-                } catch (Throwable e1) {
-                    // ignore
+                parser = XContentFactory.xContent(request.templateSource()).createParser(request.templateSource());
+                template = TemplateQueryParser.parse(parser, searchContext.parseFieldMatcher(), "params", "template");
+
+                if (template.getType() == ScriptService.ScriptType.INLINE) {
+                    //Try to double parse for nested template id/file
+                    parser = null;
+                    try {
+                        ExecutableScript executable = this.scriptService.executable(template, ScriptContext.Standard.SEARCH, searchContext);
+                        processedQuery = (BytesReference) executable.run();
+                        parser = XContentFactory.xContent(processedQuery).createParser(processedQuery);
+                    } catch (ElasticsearchParseException epe) {
+                        //This was an non-nested template, the parse failure was due to this, it is safe to assume this refers to a file
+                        //for backwards compatibility and keep going
+                        template = new Template(template.getScript(), ScriptService.ScriptType.FILE, MustacheScriptEngineService.NAME,
+                                null, template.getParams());
+                        ExecutableScript executable = this.scriptService.executable(template, ScriptContext.Standard.SEARCH, searchContext);
+                        processedQuery = (BytesReference) executable.run();
+                    }
+                    if (parser != null) {
+                        try {
+                            Template innerTemplate = TemplateQueryParser.parse(parser, searchContext.parseFieldMatcher());
+                            if (hasLength(innerTemplate.getScript()) && !innerTemplate.getType().equals(ScriptService.ScriptType.INLINE)) {
+                                //An inner template referring to a filename or id
+                                template = new Template(innerTemplate.getScript(), innerTemplate.getType(),
+                                        MustacheScriptEngineService.NAME, null, template.getParams());
+                                ExecutableScript executable = this.scriptService.executable(template, ScriptContext.Standard.SEARCH,
+                                        searchContext);
+                                processedQuery = (BytesReference) executable.run();
+                            }
+                        } catch (ScriptParseException e) {
+                            // No inner template found, use original template from above
+                        }
+                    }
+                } else {
+                    ExecutableScript executable = this.scriptService.executable(template, ScriptContext.Standard.SEARCH, searchContext);
+                    processedQuery = (BytesReference) executable.run();
                 }
-                XContentLocation location = suggestParser != null ? suggestParser.getTokenLocation() : null;
-                throw new SearchParseException(context, "failed to parse suggest source [" + sSource + "]", location, e);
+            } catch (IOException e) {
+                throw new ElasticsearchParseException("Failed to parse template", e);
+            } finally {
+                Releasables.closeWhileHandlingException(parser);
+            }
+
+            if (!hasLength(template.getScript())) {
+                throw new ElasticsearchParseException("Template must have [template] field configured");
             }
         }
-        if (source.rescores() != null) {
-            XContentParser completeRescoreParser = null;
-            try {
-                XContentBuilder completeRescoreBuilder = XContentFactory.jsonBuilder();
-                completeRescoreBuilder.startArray();
-                for (BytesReference rescore : source.rescores()) {
-                    XContentParser parser = XContentFactory.xContent(rescore).createParser(rescore);
-                    parser.nextToken();
-                    completeRescoreBuilder.copyCurrentStructure(parser);
-                }
-                completeRescoreBuilder.endArray();
-                BytesReference completeRescoreBytes = completeRescoreBuilder.bytes();
-                completeRescoreParser = XContentFactory.xContent(completeRescoreBytes).createParser(completeRescoreBytes);
-                completeRescoreParser.nextToken();
-                this.elementParsers.get("rescore").parse(completeRescoreParser, context);
-            } catch (Exception e) {
-                String sSource = "_na_";
-                try {
-                    sSource = source.toString();
-                } catch (Throwable e1) {
-                    // ignore
-                }
-                XContentLocation location = completeRescoreParser != null ? completeRescoreParser.getTokenLocation() : null;
-                throw new SearchParseException(context, "failed to parse rescore source [" + sSource + "]", location, e);
-            } // NORELEASE fix this to be more elegant
-        }
-        if (source.fields() != null) {
-            context.fieldNames().addAll(source.fields());
-        }
-        if (source.explain() != null) {
-            context.explain(source.explain());
-        }
-        if (source.fetchSource() != null) {
-            context.fetchSourceContext(source.fetchSource());
+        request.source(processedQuery);
+    }
+
+    private void parseSource(SearchContext context, BytesReference source) throws SearchParseException {
+        // nothing to parse...
+        if (source == null || source.length() == 0) {
+            return;
         }
-        if (source.fieldDataFields() != null) {
-            FieldDataFieldsContext fieldDataFieldsContext = context.getFetchSubPhaseContext(FieldDataFieldsFetchSubPhase.CONTEXT_FACTORY);
-            for (String field : source.fieldDataFields()) {
-                fieldDataFieldsContext.add(new FieldDataField(field));
+        XContentParser parser = null;
+        try {
+            parser = XContentFactory.xContent(source).createParser(source);
+            XContentParser.Token token;
+            token = parser.nextToken();
+            if (token != XContentParser.Token.START_OBJECT) {
+                throw new ElasticsearchParseException("failed to parse search source. source must be an object, but found [{}] instead", token.name());
             }
-        }
-        if (source.highlighter() != null) {
-            XContentParser highlighterParser = null;
-            try {
-                highlighterParser = XContentFactory.xContent(source.highlighter()).createParser(source.highlighter());
-                this.elementParsers.get("highlight").parse(highlighterParser, context);
-            } catch (Exception e) {
-                String sSource = "_na_";
-                try {
-                    sSource = source.toString();
-                } catch (Throwable e1) {
-                    // ignore
+            while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
+                if (token == XContentParser.Token.FIELD_NAME) {
+                    String fieldName = parser.currentName();
+                    parser.nextToken();
+                    SearchParseElement element = elementParsers.get(fieldName);
+                    if (element == null) {
+                        throw new SearchParseException(context, "failed to parse search source. unknown search element [" + fieldName + "]", parser.getTokenLocation());
+                    }
+                    element.parse(parser, context);
+                } else {
+                    if (token == null) {
+                        throw new ElasticsearchParseException("failed to parse search source. end of query source reached but query is not complete.");
+                    } else {
+                        throw new ElasticsearchParseException("failed to parse search source. expected field name but got [{}]", token);
+                    }
                 }
-                XContentLocation location = highlighterParser != null ? highlighterParser.getTokenLocation() : null;
-                throw new SearchParseException(context, "failed to parse suggest source [" + sSource + "]", location, e);
             }
-        }
-        if (source.innerHits() != null) {
-            XContentParser innerHitsParser = null;
+        } catch (Throwable e) {
+            String sSource = "_na_";
             try {
-                innerHitsParser = XContentFactory.xContent(source.innerHits()).createParser(source.innerHits());
-                this.elementParsers.get("highlight").parse(innerHitsParser, context);
-            } catch (Exception e) {
-                String sSource = "_na_";
-                try {
-                    sSource = source.toString();
-                } catch (Throwable e1) {
-                    // ignore
-                }
-                XContentLocation location = innerHitsParser != null ? innerHitsParser.getTokenLocation() : null;
-                throw new SearchParseException(context, "failed to parse suggest source [" + sSource + "]", location, e);
+                sSource = XContentHelper.convertToJson(source, false);
+            } catch (Throwable e1) {
+                // ignore
             }
-        }
-        if (source.scriptFields() != null) {
-            for (org.elasticsearch.search.builder.SearchSourceBuilder.ScriptField field : source.scriptFields()) {
-                SearchScript searchScript = context.scriptService().search(context.lookup(), field.script(), ScriptContext.Standard.SEARCH);
-                context.scriptFields().add(new ScriptField(field.fieldName(), searchScript, false)); // NORELEASE need to have ignore_exception parsed somewhere
+            XContentLocation location = parser != null ? parser.getTokenLocation() : null;
+            throw new SearchParseException(context, "failed to parse search source [" + sSource + "]", location, e);
+        } finally {
+            if (parser != null) {
+                parser.close();
             }
         }
-        // NOCOMMIT need to work out what to do about term_vectors_fetch (previously handled by TermVectorsFetchParseElement) as this is not available as an option in SearchSourceBuilder
-        if (source.version() != null) {
-            context.version(source.version());
-        }
-        if (source.stats() != null) {
-            context.groupStats(Arrays.asList(source.stats())); // NORELEASE stats should be a list in SearchSourceBuilder
-        }
     }
 
     private static final int[] EMPTY_DOC_IDS = new int[0];
@@ -1153,19 +1067,14 @@ public class SearchService extends AbstractLifecycleComponent<SearchService> {
                             ShardSearchRequest request = new ShardSearchLocalRequest(indexShard.shardId(), indexMetaData.numberOfShards(),
                                     SearchType.QUERY_THEN_FETCH, entry.source(), entry.types(), entry.requestCache());
                             context = createContext(request, warmerContext.searcher());
-                            // if we use sort, we need to do query to sort on
-                            // it and load relevant field data
-                            // if not, we might as well set size=0 (and cache
-                            // if needed)
+                            // if we use sort, we need to do query to sort on it and load relevant field data
+                            // if not, we might as well set size=0 (and cache if needed)
                             if (context.sort() == null) {
                                 context.size(0);
                             }
                             boolean canCache = indicesQueryCache.canCache(request, context);
-                            // early terminate when we can cache, since we
-                            // can only do proper caching on top level searcher
-                            // also, if we can't cache, and its top, we don't
-                            // need to execute it, since we already did when its
-                            // not top
+                            // early terminate when we can cache, since we can only do proper caching on top level searcher
+                            // also, if we can't cache, and its top, we don't need to execute it, since we already did when its not top
                             if (canCache != top) {
                                 return;
                             }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/tophits/TopHitsBuilder.java b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/tophits/TopHitsBuilder.java
index a5202c6..62bd22a 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/tophits/TopHitsBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/tophits/TopHitsBuilder.java
@@ -19,8 +19,8 @@
 package org.elasticsearch.search.aggregations.metrics.tophits;
 
 import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;
 import org.elasticsearch.search.builder.SearchSourceBuilder;
@@ -29,6 +29,7 @@ import org.elasticsearch.search.sort.SortBuilder;
 import org.elasticsearch.search.sort.SortOrder;
 
 import java.io.IOException;
+import java.util.Map;
 
 /**
  * Builder for the {@link TopHits} aggregation.
@@ -172,6 +173,185 @@ public class TopHitsBuilder extends AbstractAggregationBuilder {
         return this;
     }
 
+    /**
+     * Adds a field to be highlighted with default fragment size of 100 characters, and
+     * default number of fragments of 5.
+     *
+     * @param name The field to highlight
+     */
+    public TopHitsBuilder addHighlightedField(String name) {
+        highlightBuilder().field(name);
+        return this;
+    }
+
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters), and
+     * default number of fragments of 5.
+     *
+     * @param name         The field to highlight
+     * @param fragmentSize The size of a fragment in characters
+     */
+    public TopHitsBuilder addHighlightedField(String name, int fragmentSize) {
+        highlightBuilder().field(name, fragmentSize);
+        return this;
+    }
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters), and
+     * a provided (maximum) number of fragments.
+     *
+     * @param name              The field to highlight
+     * @param fragmentSize      The size of a fragment in characters
+     * @param numberOfFragments The (maximum) number of fragments
+     */
+    public TopHitsBuilder addHighlightedField(String name, int fragmentSize, int numberOfFragments) {
+        highlightBuilder().field(name, fragmentSize, numberOfFragments);
+        return this;
+    }
+
+    /**
+     * Adds a field to be highlighted with a provided fragment size (in characters),
+     * a provided (maximum) number of fragments and an offset for the highlight.
+     *
+     * @param name              The field to highlight
+     * @param fragmentSize      The size of a fragment in characters
+     * @param numberOfFragments The (maximum) number of fragments
+     */
+    public TopHitsBuilder addHighlightedField(String name, int fragmentSize, int numberOfFragments,
+                                                    int fragmentOffset) {
+        highlightBuilder().field(name, fragmentSize, numberOfFragments, fragmentOffset);
+        return this;
+    }
+
+    /**
+     * Adds a highlighted field.
+     */
+    public TopHitsBuilder addHighlightedField(HighlightBuilder.Field field) {
+        highlightBuilder().field(field);
+        return this;
+    }
+
+    /**
+     * Set a tag scheme that encapsulates a built in pre and post tags. The allows schemes
+     * are <tt>styled</tt> and <tt>default</tt>.
+     *
+     * @param schemaName The tag scheme name
+     */
+    public TopHitsBuilder setHighlighterTagsSchema(String schemaName) {
+        highlightBuilder().tagsSchema(schemaName);
+        return this;
+    }
+
+    public TopHitsBuilder setHighlighterFragmentSize(Integer fragmentSize) {
+        highlightBuilder().fragmentSize(fragmentSize);
+        return this;
+    }
+
+    public TopHitsBuilder setHighlighterNumOfFragments(Integer numOfFragments) {
+        highlightBuilder().numOfFragments(numOfFragments);
+        return this;
+    }
+
+    public TopHitsBuilder setHighlighterFilter(Boolean highlightFilter) {
+        highlightBuilder().highlightFilter(highlightFilter);
+        return this;
+    }
+
+    /**
+     * The encoder to set for highlighting
+     */
+    public TopHitsBuilder setHighlighterEncoder(String encoder) {
+        highlightBuilder().encoder(encoder);
+        return this;
+    }
+
+    /**
+     * Explicitly set the pre tags that will be used for highlighting.
+     */
+    public TopHitsBuilder setHighlighterPreTags(String... preTags) {
+        highlightBuilder().preTags(preTags);
+        return this;
+    }
+
+    /**
+     * Explicitly set the post tags that will be used for highlighting.
+     */
+    public TopHitsBuilder setHighlighterPostTags(String... postTags) {
+        highlightBuilder().postTags(postTags);
+        return this;
+    }
+
+    /**
+     * The order of fragments per field. By default, ordered by the order in the
+     * highlighted text. Can be <tt>score</tt>, which then it will be ordered
+     * by score of the fragments.
+     */
+    public TopHitsBuilder setHighlighterOrder(String order) {
+        highlightBuilder().order(order);
+        return this;
+    }
+
+    public TopHitsBuilder setHighlighterRequireFieldMatch(boolean requireFieldMatch) {
+        highlightBuilder().requireFieldMatch(requireFieldMatch);
+        return this;
+    }
+
+    public TopHitsBuilder setHighlighterBoundaryMaxScan(Integer boundaryMaxScan) {
+        highlightBuilder().boundaryMaxScan(boundaryMaxScan);
+        return this;
+    }
+
+    public TopHitsBuilder setHighlighterBoundaryChars(char[] boundaryChars) {
+        highlightBuilder().boundaryChars(boundaryChars);
+        return this;
+    }
+
+    /**
+     * The highlighter type to use.
+     */
+    public TopHitsBuilder setHighlighterType(String type) {
+        highlightBuilder().highlighterType(type);
+        return this;
+    }
+
+    public TopHitsBuilder setHighlighterFragmenter(String fragmenter) {
+        highlightBuilder().fragmenter(fragmenter);
+        return this;
+    }
+
+    /**
+     * Sets a query to be used for highlighting all fields instead of the search query.
+     */
+    public TopHitsBuilder setHighlighterQuery(QueryBuilder highlightQuery) {
+        highlightBuilder().highlightQuery(highlightQuery);
+        return this;
+    }
+
+    /**
+     * Sets the size of the fragment to return from the beginning of the field if there are no matches to
+     * highlight and the field doesn't also define noMatchSize.
+     * @param noMatchSize integer to set or null to leave out of request.  default is null.
+     * @return this builder for chaining
+     */
+    public TopHitsBuilder setHighlighterNoMatchSize(Integer noMatchSize) {
+        highlightBuilder().noMatchSize(noMatchSize);
+        return this;
+    }
+
+    /**
+     * Sets the maximum number of phrases the fvh will consider if the field doesn't also define phraseLimit.
+     */
+    public TopHitsBuilder setHighlighterPhraseLimit(Integer phraseLimit) {
+        highlightBuilder().phraseLimit(phraseLimit);
+        return this;
+    }
+
+    public TopHitsBuilder setHighlighterOptions(Map<String, Object> options) {
+        highlightBuilder().options(options);
+        return this;
+    }
+
     @Override
     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject(getName()).field(type);
@@ -186,12 +366,7 @@ public class TopHitsBuilder extends AbstractAggregationBuilder {
         return sourceBuilder;
     }
 
-    public BytesReference highlighter() {
+    public HighlightBuilder highlightBuilder() {
         return sourceBuilder().highlighter();
     }
-
-    public TopHitsBuilder highlighter(HighlightBuilder highlightBuilder) {
-        sourceBuilder().highlighter(highlightBuilder);
-        return this;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/builder/OldSearchSourceBuilder.java b/core/src/main/java/org/elasticsearch/search/builder/OldSearchSourceBuilder.java
deleted file mode 100644
index 949628b..0000000
--- a/core/src/main/java/org/elasticsearch/search/builder/OldSearchSourceBuilder.java
+++ /dev/null
@@ -1,840 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.search.builder;
-
-import com.carrotsearch.hppc.ObjectFloatHashMap;
-
-import org.elasticsearch.ElasticsearchGenerationException;
-import org.elasticsearch.action.support.QuerySourceBuilder;
-import org.elasticsearch.action.support.ToXContentToBytes;
-import org.elasticsearch.client.Requests;
-import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.bytes.BytesArray;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-import org.elasticsearch.search.fetch.source.FetchSourceContext;
-import org.elasticsearch.search.highlight.HighlightBuilder;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.rescore.RescoreBuilder;
-import org.elasticsearch.search.sort.SortBuilder;
-import org.elasticsearch.search.sort.SortBuilders;
-import org.elasticsearch.search.sort.SortOrder;
-import org.elasticsearch.search.suggest.SuggestBuilder;
-
-import java.io.IOException;
-import java.nio.charset.StandardCharsets;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-
-/**
- * A search source builder allowing to easily build search source. Simple
- * construction using
- * {@link org.elasticsearch.search.builder.OldSearchSourceBuilder#searchSource()}
- */
-public class OldSearchSourceBuilder extends ToXContentToBytes {
-
-    /**
-     * A static factory method to construct a new search source.
-     */
-    public static OldSearchSourceBuilder searchSource() {
-        return new OldSearchSourceBuilder();
-    }
-
-    /**
-     * A static factory method to construct new search highlights.
-     */
-    public static HighlightBuilder highlight() {
-        return new HighlightBuilder();
-    }
-
-    private QuerySourceBuilder querySourceBuilder;
-
-    private QueryBuilder postQueryBuilder;
-
-    private BytesReference filterBinary;
-
-    private int from = -1;
-
-    private int size = -1;
-
-    private Boolean explain;
-
-    private Boolean version;
-
-    private List<SortBuilder> sorts;
-
-    private boolean trackScores = false;
-
-    private Float minScore;
-
-    private long timeoutInMillis = -1;
-    private int terminateAfter = SearchContext.DEFAULT_TERMINATE_AFTER;
-
-    private List<String> fieldNames;
-    private List<String> fieldDataFields;
-    private List<ScriptField> scriptFields;
-    private FetchSourceContext fetchSourceContext;
-
-    private List<AbstractAggregationBuilder> aggregations;
-    private BytesReference aggregationsBinary;
-
-    private HighlightBuilder highlightBuilder;
-
-    private SuggestBuilder suggestBuilder;
-
-    private InnerHitsBuilder innerHitsBuilder;
-
-    private List<RescoreBuilder> rescoreBuilders;
-    private Integer defaultRescoreWindowSize;
-
-    private ObjectFloatHashMap<String> indexBoost = null;
-
-    private String[] stats;
-
-    /**
-     * Constructs a new search source builder.
-     */
-    public OldSearchSourceBuilder() {
-    }
-
-    /**
-     * Sets the query provided as a {@link QuerySourceBuilder}
-     */
-    public OldSearchSourceBuilder query(QuerySourceBuilder querySourceBuilder) {
-        this.querySourceBuilder = querySourceBuilder;
-        return this;
-    }
-
-    /**
-     * Constructs a new search source builder with a search query.
-     *
-     * @see org.elasticsearch.index.query.QueryBuilders
-     */
-    public OldSearchSourceBuilder query(QueryBuilder query) {
-        if (this.querySourceBuilder == null) {
-            this.querySourceBuilder = new QuerySourceBuilder();
-        }
-        this.querySourceBuilder.setQuery(query);
-        return this;
-    }
-
-    /**
-     * Constructs a new search source builder with a raw search query.
-     */
-    public OldSearchSourceBuilder query(byte[] queryBinary) {
-        return query(queryBinary, 0, queryBinary.length);
-    }
-
-    /**
-     * Constructs a new search source builder with a raw search query.
-     */
-    public OldSearchSourceBuilder query(byte[] queryBinary, int queryBinaryOffset, int queryBinaryLength) {
-        return query(new BytesArray(queryBinary, queryBinaryOffset, queryBinaryLength));
-    }
-
-    /**
-     * Constructs a new search source builder with a raw search query.
-     */
-    public OldSearchSourceBuilder query(BytesReference queryBinary) {
-        if (this.querySourceBuilder == null) {
-            this.querySourceBuilder = new QuerySourceBuilder();
-        }
-        this.querySourceBuilder.setQuery(queryBinary);
-        return this;
-    }
-
-    /**
-     * Constructs a new search source builder with a raw search query.
-     */
-    public OldSearchSourceBuilder query(String queryString) {
-        return query(queryString.getBytes(StandardCharsets.UTF_8));
-    }
-
-    /**
-     * Constructs a new search source builder with a query from a builder.
-     */
-    public OldSearchSourceBuilder query(XContentBuilder query) {
-        return query(query.bytes());
-    }
-
-    /**
-     * Constructs a new search source builder with a query from a map.
-     */
-    @SuppressWarnings("unchecked")
-    public OldSearchSourceBuilder query(Map query) {
-        try {
-            XContentBuilder builder = XContentFactory.contentBuilder(Requests.CONTENT_TYPE);
-            builder.map(query);
-            return query(builder);
-        } catch (IOException e) {
-            throw new ElasticsearchGenerationException("Failed to generate [" + query + "]", e);
-        }
-    }
-
-    /**
-     * Sets a filter that will be executed after the query has been executed and
-     * only has affect on the search hits (not aggregations). This filter is
-     * always executed as last filtering mechanism.
-     */
-    public OldSearchSourceBuilder postFilter(QueryBuilder postFilter) {
-        this.postQueryBuilder = postFilter;
-        return this;
-    }
-
-    /**
-     * Sets a filter on the query executed that only applies to the search query
-     * (and not aggs for example).
-     */
-    public OldSearchSourceBuilder postFilter(String postFilterString) {
-        return postFilter(postFilterString.getBytes(StandardCharsets.UTF_8));
-    }
-
-    /**
-     * Sets a filter on the query executed that only applies to the search query
-     * (and not aggs for example).
-     */
-    public OldSearchSourceBuilder postFilter(byte[] postFilter) {
-        return postFilter(postFilter, 0, postFilter.length);
-    }
-
-    /**
-     * Sets a filter on the query executed that only applies to the search query
-     * (and not aggs for example).
-     */
-    public OldSearchSourceBuilder postFilter(byte[] postFilterBinary, int postFilterBinaryOffset, int postFilterBinaryLength) {
-        return postFilter(new BytesArray(postFilterBinary, postFilterBinaryOffset, postFilterBinaryLength));
-    }
-
-    /**
-     * Sets a filter on the query executed that only applies to the search query
-     * (and not aggs for example).
-     */
-    public OldSearchSourceBuilder postFilter(BytesReference postFilterBinary) {
-        this.filterBinary = postFilterBinary;
-        return this;
-    }
-
-    /**
-     * Constructs a new search source builder with a query from a builder.
-     */
-    public OldSearchSourceBuilder postFilter(XContentBuilder postFilter) {
-        return postFilter(postFilter.bytes());
-    }
-
-    /**
-     * Constructs a new search source builder with a query from a map.
-     */
-    @SuppressWarnings("unchecked")
-    public OldSearchSourceBuilder postFilter(Map postFilter) {
-        try {
-            XContentBuilder builder = XContentFactory.contentBuilder(Requests.CONTENT_TYPE);
-            builder.map(postFilter);
-            return postFilter(builder);
-        } catch (IOException e) {
-            throw new ElasticsearchGenerationException("Failed to generate [" + postFilter + "]", e);
-        }
-    }
-
-    /**
-     * From index to start the search from. Defaults to <tt>0</tt>.
-     */
-    public OldSearchSourceBuilder from(int from) {
-        this.from = from;
-        return this;
-    }
-
-    /**
-     * The number of search hits to return. Defaults to <tt>10</tt>.
-     */
-    public OldSearchSourceBuilder size(int size) {
-        this.size = size;
-        return this;
-    }
-
-    /**
-     * Sets the minimum score below which docs will be filtered out.
-     */
-    public OldSearchSourceBuilder minScore(float minScore) {
-        this.minScore = minScore;
-        return this;
-    }
-
-    /**
-     * Should each {@link org.elasticsearch.search.SearchHit} be returned with
-     * an explanation of the hit (ranking).
-     */
-    public OldSearchSourceBuilder explain(Boolean explain) {
-        this.explain = explain;
-        return this;
-    }
-
-    /**
-     * Should each {@link org.elasticsearch.search.SearchHit} be returned with a
-     * version associated with it.
-     */
-    public OldSearchSourceBuilder version(Boolean version) {
-        this.version = version;
-        return this;
-    }
-
-    /**
-     * An optional timeout to control how long search is allowed to take.
-     */
-    public OldSearchSourceBuilder timeout(TimeValue timeout) {
-        this.timeoutInMillis = timeout.millis();
-        return this;
-    }
-
-    /**
-     * An optional timeout to control how long search is allowed to take.
-     */
-    public OldSearchSourceBuilder timeout(String timeout) {
-        this.timeoutInMillis = TimeValue.parseTimeValue(timeout, null, getClass().getSimpleName() + ".timeout").millis();
-        return this;
-    }
-
-    /**
-     * An optional terminate_after to terminate the search after collecting
-     * <code>terminateAfter</code> documents
-     */
-    public OldSearchSourceBuilder terminateAfter(int terminateAfter) {
-        if (terminateAfter <= 0) {
-            throw new IllegalArgumentException("terminateAfter must be > 0");
-        }
-        this.terminateAfter = terminateAfter;
-        return this;
-    }
-
-    /**
-     * Adds a sort against the given field name and the sort ordering.
-     *
-     * @param name
-     *            The name of the field
-     * @param order
-     *            The sort ordering
-     */
-    public OldSearchSourceBuilder sort(String name, SortOrder order) {
-        return sort(SortBuilders.fieldSort(name).order(order));
-    }
-
-    /**
-     * Add a sort against the given field name.
-     *
-     * @param name
-     *            The name of the field to sort by
-     */
-    public OldSearchSourceBuilder sort(String name) {
-        return sort(SortBuilders.fieldSort(name));
-    }
-
-    /**
-     * Adds a sort builder.
-     */
-    public OldSearchSourceBuilder sort(SortBuilder sort) {
-        if (sorts == null) {
-            sorts = new ArrayList<>();
-        }
-        sorts.add(sort);
-        return this;
-    }
-
-    /**
-     * Applies when sorting, and controls if scores will be tracked as well.
-     * Defaults to <tt>false</tt>.
-     */
-    public OldSearchSourceBuilder trackScores(boolean trackScores) {
-        this.trackScores = trackScores;
-        return this;
-    }
-
-    /**
-     * Add an get to perform as part of the search.
-     */
-    public OldSearchSourceBuilder aggregation(AbstractAggregationBuilder aggregation) {
-        if (aggregations == null) {
-            aggregations = new ArrayList<>();
-        }
-        aggregations.add(aggregation);
-        return this;
-    }
-
-    /**
-     * Sets a raw (xcontent / json) addAggregation.
-     */
-    public OldSearchSourceBuilder aggregations(byte[] aggregationsBinary) {
-        return aggregations(aggregationsBinary, 0, aggregationsBinary.length);
-    }
-
-    /**
-     * Sets a raw (xcontent / json) addAggregation.
-     */
-    public OldSearchSourceBuilder aggregations(byte[] aggregationsBinary, int aggregationsBinaryOffset, int aggregationsBinaryLength) {
-        return aggregations(new BytesArray(aggregationsBinary, aggregationsBinaryOffset, aggregationsBinaryLength));
-    }
-
-    /**
-     * Sets a raw (xcontent / json) addAggregation.
-     */
-    public OldSearchSourceBuilder aggregations(BytesReference aggregationsBinary) {
-        this.aggregationsBinary = aggregationsBinary;
-        return this;
-    }
-
-    /**
-     * Sets a raw (xcontent / json) addAggregation.
-     */
-    public OldSearchSourceBuilder aggregations(XContentBuilder aggs) {
-        return aggregations(aggs.bytes());
-    }
-
-    /**
-     * Set the rescore window size for rescores that don't specify their window.
-     */
-    public OldSearchSourceBuilder defaultRescoreWindowSize(int defaultRescoreWindowSize) {
-        this.defaultRescoreWindowSize = defaultRescoreWindowSize;
-        return this;
-    }
-
-    /**
-     * Sets a raw (xcontent / json) addAggregation.
-     */
-    @SuppressWarnings("unchecked")
-    public OldSearchSourceBuilder aggregations(Map aggregations) {
-        try {
-            XContentBuilder builder = XContentFactory.contentBuilder(Requests.CONTENT_TYPE);
-            builder.map(aggregations);
-            return aggregations(builder);
-        } catch (IOException e) {
-            throw new ElasticsearchGenerationException("Failed to generate [" + aggregations + "]", e);
-        }
-    }
-
-    public HighlightBuilder highlighter() {
-        if (highlightBuilder == null) {
-            highlightBuilder = new HighlightBuilder();
-        }
-        return highlightBuilder;
-    }
-
-    /**
-     * Adds highlight to perform as part of the search.
-     */
-    public OldSearchSourceBuilder highlight(HighlightBuilder highlightBuilder) {
-        this.highlightBuilder = highlightBuilder;
-        return this;
-    }
-
-    public InnerHitsBuilder innerHitsBuilder() {
-        if (innerHitsBuilder == null) {
-            innerHitsBuilder = new InnerHitsBuilder();
-        }
-        return innerHitsBuilder;
-    }
-
-    public SuggestBuilder suggest() {
-        if (suggestBuilder == null) {
-            suggestBuilder = new SuggestBuilder("suggest");
-        }
-        return suggestBuilder;
-    }
-
-    public OldSearchSourceBuilder addRescorer(RescoreBuilder rescoreBuilder) {
-        if (rescoreBuilders == null) {
-            rescoreBuilders = new ArrayList<>();
-        }
-        rescoreBuilders.add(rescoreBuilder);
-        return this;
-    }
-
-    public OldSearchSourceBuilder clearRescorers() {
-        rescoreBuilders = null;
-        return this;
-    }
-
-    /**
-     * Indicates whether the response should contain the stored _source for
-     * every hit
-     */
-    public OldSearchSourceBuilder fetchSource(boolean fetch) {
-        if (this.fetchSourceContext == null) {
-            this.fetchSourceContext = new FetchSourceContext(fetch);
-        } else {
-            this.fetchSourceContext.fetchSource(fetch);
-        }
-        return this;
-    }
-
-    /**
-     * Indicate that _source should be returned with every hit, with an
-     * "include" and/or "exclude" set which can include simple wildcard
-     * elements.
-     *
-     * @param include
-     *            An optional include (optionally wildcarded) pattern to filter
-     *            the returned _source
-     * @param exclude
-     *            An optional exclude (optionally wildcarded) pattern to filter
-     *            the returned _source
-     */
-    public OldSearchSourceBuilder fetchSource(@Nullable String include, @Nullable String exclude) {
-        return fetchSource(include == null ? Strings.EMPTY_ARRAY : new String[] { include }, exclude == null ? Strings.EMPTY_ARRAY
-                : new String[] { exclude });
-    }
-
-    /**
-     * Indicate that _source should be returned with every hit, with an
-     * "include" and/or "exclude" set which can include simple wildcard
-     * elements.
-     *
-     * @param includes
-     *            An optional list of include (optionally wildcarded) pattern to
-     *            filter the returned _source
-     * @param excludes
-     *            An optional list of exclude (optionally wildcarded) pattern to
-     *            filter the returned _source
-     */
-    public OldSearchSourceBuilder fetchSource(@Nullable String[] includes, @Nullable String[] excludes) {
-        fetchSourceContext = new FetchSourceContext(includes, excludes);
-        return this;
-    }
-
-    /**
-     * Indicate how the _source should be fetched.
-     */
-    public OldSearchSourceBuilder fetchSource(@Nullable FetchSourceContext fetchSourceContext) {
-        this.fetchSourceContext = fetchSourceContext;
-        return this;
-    }
-
-    /**
-     * Sets no fields to be loaded, resulting in only id and type to be returned
-     * per field.
-     */
-    public OldSearchSourceBuilder noFields() {
-        this.fieldNames = Collections.emptyList();
-        return this;
-    }
-
-    /**
-     * Sets the fields to load and return as part of the search request. If none
-     * are specified, the source of the document will be returned.
-     */
-    public OldSearchSourceBuilder fields(List<String> fields) {
-        this.fieldNames = fields;
-        return this;
-    }
-
-    /**
-     * Adds the fields to load and return as part of the search request. If none
-     * are specified, the source of the document will be returned.
-     */
-    public OldSearchSourceBuilder fields(String... fields) {
-        if (fieldNames == null) {
-            fieldNames = new ArrayList<>();
-        }
-        Collections.addAll(fieldNames, fields);
-        return this;
-    }
-
-    /**
-     * Adds a field to load and return (note, it must be stored) as part of the
-     * search request. If none are specified, the source of the document will be
-     * return.
-     */
-    public OldSearchSourceBuilder field(String name) {
-        if (fieldNames == null) {
-            fieldNames = new ArrayList<>();
-        }
-        fieldNames.add(name);
-        return this;
-    }
-
-    /**
-     * Adds a field to load from the field data cache and return as part of the
-     * search request.
-     */
-    public OldSearchSourceBuilder fieldDataField(String name) {
-        if (fieldDataFields == null) {
-            fieldDataFields = new ArrayList<>();
-        }
-        fieldDataFields.add(name);
-        return this;
-    }
-
-    /**
-     * Adds a script field under the given name with the provided script.
-     *
-     * @param name
-     *            The name of the field
-     * @param script
-     *            The script
-     */
-    public OldSearchSourceBuilder scriptField(String name, Script script) {
-        if (scriptFields == null) {
-            scriptFields = new ArrayList<>();
-        }
-        scriptFields.add(new ScriptField(name, script));
-        return this;
-    }
-
-    /**
-     * Sets the boost a specific index will receive when the query is executeed
-     * against it.
-     *
-     * @param index
-     *            The index to apply the boost against
-     * @param indexBoost
-     *            The boost to apply to the index
-     */
-    public OldSearchSourceBuilder indexBoost(String index, float indexBoost) {
-        if (this.indexBoost == null) {
-            this.indexBoost = new ObjectFloatHashMap<>();
-        }
-        this.indexBoost.put(index, indexBoost);
-        return this;
-    }
-
-    /**
-     * The stats groups this request will be aggregated under.
-     */
-    public OldSearchSourceBuilder stats(String... statsGroups) {
-        this.stats = statsGroups;
-        return this;
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject();
-        innerToXContent(builder, params);
-        builder.endObject();
-        return builder;
-    }
-
-    public void innerToXContent(XContentBuilder builder, Params params) throws IOException {
-        if (from != -1) {
-            builder.field("from", from);
-        }
-        if (size != -1) {
-            builder.field("size", size);
-        }
-
-        if (timeoutInMillis != -1) {
-            builder.field("timeout", timeoutInMillis);
-        }
-
-        if (terminateAfter != SearchContext.DEFAULT_TERMINATE_AFTER) {
-            builder.field("terminate_after", terminateAfter);
-        }
-
-        if (querySourceBuilder != null) {
-            querySourceBuilder.innerToXContent(builder, params);
-        }
-
-        if (postQueryBuilder != null) {
-            builder.field("post_filter");
-            postQueryBuilder.toXContent(builder, params);
-        }
-
-        if (filterBinary != null) {
-            if (XContentFactory.xContentType(filterBinary) == builder.contentType()) {
-                builder.rawField("filter", filterBinary);
-            } else {
-                builder.field("filter_binary", filterBinary);
-            }
-        }
-
-        if (minScore != null) {
-            builder.field("min_score", minScore);
-        }
-
-        if (version != null) {
-            builder.field("version", version);
-        }
-
-        if (explain != null) {
-            builder.field("explain", explain);
-        }
-
-        if (fetchSourceContext != null) {
-            if (!fetchSourceContext.fetchSource()) {
-                builder.field("_source", false);
-            } else {
-                builder.startObject("_source");
-                builder.array("includes", fetchSourceContext.includes());
-                builder.array("excludes", fetchSourceContext.excludes());
-                builder.endObject();
-            }
-        }
-
-        if (fieldNames != null) {
-            if (fieldNames.size() == 1) {
-                builder.field("fields", fieldNames.get(0));
-            } else {
-                builder.startArray("fields");
-                for (String fieldName : fieldNames) {
-                    builder.value(fieldName);
-                }
-                builder.endArray();
-            }
-        }
-
-        if (fieldDataFields != null) {
-            builder.startArray("fielddata_fields");
-            for (String fieldName : fieldDataFields) {
-                builder.value(fieldName);
-            }
-            builder.endArray();
-        }
-
-        if (scriptFields != null) {
-            builder.startObject("script_fields");
-            for (ScriptField scriptField : scriptFields) {
-                builder.startObject(scriptField.fieldName());
-                builder.field("script", scriptField.script());
-                builder.endObject();
-            }
-            builder.endObject();
-        }
-
-        if (sorts != null) {
-            builder.startArray("sort");
-            for (SortBuilder sort : sorts) {
-                builder.startObject();
-                sort.toXContent(builder, params);
-                builder.endObject();
-            }
-            builder.endArray();
-        }
-
-        if (trackScores) {
-            builder.field("track_scores", true);
-        }
-
-        if (indexBoost != null) {
-            builder.startObject("indices_boost");
-            assert !indexBoost.containsKey(null);
-            final Object[] keys = indexBoost.keys;
-            final float[] values = indexBoost.values;
-            for (int i = 0; i < keys.length; i++) {
-                if (keys[i] != null) {
-                    builder.field((String) keys[i], values[i]);
-                }
-            }
-            builder.endObject();
-        }
-
-        if (aggregations != null) {
-            builder.field("aggregations");
-            builder.startObject();
-            for (AbstractAggregationBuilder aggregation : aggregations) {
-                aggregation.toXContent(builder, params);
-            }
-            builder.endObject();
-        }
-
-        if (aggregationsBinary != null) {
-            if (XContentFactory.xContentType(aggregationsBinary) == builder.contentType()) {
-                builder.rawField("aggregations", aggregationsBinary);
-            } else {
-                builder.field("aggregations_binary", aggregationsBinary);
-            }
-        }
-
-        if (highlightBuilder != null) {
-            highlightBuilder.toXContent(builder, params);
-        }
-
-        if (innerHitsBuilder != null) {
-            innerHitsBuilder.toXContent(builder, params);
-        }
-
-        if (suggestBuilder != null) {
-            suggestBuilder.toXContent(builder, params);
-        }
-
-        if (rescoreBuilders != null) {
-            // Strip empty rescoreBuilders from the request
-            Iterator<RescoreBuilder> itr = rescoreBuilders.iterator();
-            while (itr.hasNext()) {
-                if (itr.next().isEmpty()) {
-                    itr.remove();
-                }
-            }
-
-            // Now build the request taking care to skip empty lists and only send the object form
-            // if there is just one builder.
-            if (rescoreBuilders.size() == 1) {
-                builder.startObject("rescore");
-                rescoreBuilders.get(0).toXContent(builder, params);
-                if (rescoreBuilders.get(0).windowSize() == null && defaultRescoreWindowSize != null) {
-                    builder.field("window_size", defaultRescoreWindowSize);
-                }
-                builder.endObject();
-            } else if (!rescoreBuilders.isEmpty()) {
-                builder.startArray("rescore");
-                for (RescoreBuilder rescoreBuilder : rescoreBuilders) {
-                    builder.startObject();
-                    rescoreBuilder.toXContent(builder, params);
-                    if (rescoreBuilder.windowSize() == null && defaultRescoreWindowSize != null) {
-                        builder.field("window_size", defaultRescoreWindowSize);
-                    }
-                    builder.endObject();
-                }
-                builder.endArray();
-            }
-        }
-
-        if (stats != null) {
-            builder.startArray("stats");
-            for (String stat : stats) {
-                builder.value(stat);
-            }
-            builder.endArray();
-        }
-    }
-
-    private static class ScriptField {
-        private final String fieldName;
-        private final Script script;
-
-        private ScriptField(String fieldName, Script script) {
-            this.fieldName = fieldName;
-            this.script = script;
-        }
-
-        public String fieldName() {
-            return fieldName;
-        }
-
-        public Script script() {
-            return script;
-        }
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java b/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java
index 74891a0..3b87030 100644
--- a/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/builder/SearchSourceBuilder.java
@@ -20,25 +20,19 @@
 package org.elasticsearch.search.builder;
 
 import com.carrotsearch.hppc.ObjectFloatHashMap;
-import com.carrotsearch.hppc.cursors.ObjectCursor;
-
+import java.nio.charset.StandardCharsets;
+import org.elasticsearch.ElasticsearchGenerationException;
+import org.elasticsearch.action.support.QuerySourceBuilder;
 import org.elasticsearch.action.support.ToXContentToBytes;
+import org.elasticsearch.client.Requests;
 import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.ParseField;
-import org.elasticsearch.common.ParsingException;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.common.xcontent.XContentType;
 import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.aggregations.AbstractAggregationBuilder;
 import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
@@ -53,48 +47,19 @@ import org.elasticsearch.search.suggest.SuggestBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Arrays;
 import java.util.Collections;
+import java.util.Iterator;
 import java.util.List;
-import java.util.Objects;
+import java.util.Map;
 
 /**
  * A search source builder allowing to easily build search source. Simple
  * construction using
- * {@link org.elasticsearch.search.builder.NewSearchSourceBuilder#searchSource()}.
+ * {@link org.elasticsearch.search.builder.SearchSourceBuilder#searchSource()}.
  *
- * @see org.elasticsearch.action.search.SearchRequest#source(NewSearchSourceBuilder)
+ * @see org.elasticsearch.action.search.SearchRequest#source(SearchSourceBuilder)
  */
-/**
- *
- */
-public final class SearchSourceBuilder extends ToXContentToBytes implements Writeable<SearchSourceBuilder> {
-
-    public static final ParseField FROM_FIELD = new ParseField("from");
-    public static final ParseField SIZE_FIELD = new ParseField("size");
-    public static final ParseField TIMEOUT_FIELD = new ParseField("timeout");
-    public static final ParseField TERMINATE_AFTER_FIELD = new ParseField("terminate_after");
-    public static final ParseField QUERY_FIELD = new ParseField("query");
-    public static final ParseField POST_FILTER_FIELD = new ParseField("post_filter");
-    public static final ParseField MIN_SCORE_FIELD = new ParseField("min_score");
-    public static final ParseField VERSION_FIELD = new ParseField("version");
-    public static final ParseField EXPLAIN_FIELD = new ParseField("explain");
-    public static final ParseField _SOURCE_FIELD = new ParseField("_source");
-    public static final ParseField FIELDS_FIELD = new ParseField("fields");
-    public static final ParseField FIELDDATA_FIELDS_FIELD = new ParseField("fielddata_fields");
-    public static final ParseField SCRIPT_FIELDS_FIELD = new ParseField("script_fields");
-    public static final ParseField SCRIPT_FIELD = new ParseField("script");
-    public static final ParseField SORT_FIELD = new ParseField("sort");
-    public static final ParseField TRACK_SCORES_FIELD = new ParseField("track_scores");
-    public static final ParseField INDICES_BOOST_FIELD = new ParseField("indices_boost");
-    public static final ParseField AGGREGATIONS_FIELD = new ParseField("aggregations", "aggs");
-    public static final ParseField HIGHLIGHT_FIELD = new ParseField("highlight");
-    public static final ParseField INNER_HITS_FIELD = new ParseField("inner_hits");
-    public static final ParseField SUGGEST_FIELD = new ParseField("suggest");
-    public static final ParseField RESCORE_FIELD = new ParseField("rescore");
-    public static final ParseField STATS_FIELD = new ParseField("stats");
-
-    public static final SearchSourceBuilder PROTOTYPE = new SearchSourceBuilder();
+public class SearchSourceBuilder extends ToXContentToBytes {
 
     /**
      * A static factory method to construct a new search source.
@@ -110,9 +75,11 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
         return new HighlightBuilder();
     }
 
-    private QueryBuilder<?> queryBuilder;
+    private QuerySourceBuilder querySourceBuilder;
+
+    private QueryBuilder postQueryBuilder;
 
-    private QueryBuilder<?> postQueryBuilder;
+    private BytesReference filterBinary;
 
     private int from = -1;
 
@@ -122,7 +89,7 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
 
     private Boolean version;
 
-    private List<BytesReference> sorts;
+    private List<SortBuilder> sorts;
 
     private boolean trackScores = false;
 
@@ -136,15 +103,16 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     private List<ScriptField> scriptFields;
     private FetchSourceContext fetchSourceContext;
 
-    private List<BytesReference> aggregations;
+    private List<AbstractAggregationBuilder> aggregations;
+    private BytesReference aggregationsBinary;
 
-    private BytesReference highlightBuilder;
+    private HighlightBuilder highlightBuilder;
 
-    private BytesReference suggestBuilder;
+    private SuggestBuilder suggestBuilder;
 
-    private BytesReference innerHitsBuilder;
+    private InnerHitsBuilder innerHitsBuilder;
 
-    private List<BytesReference> rescoreBuilders;
+    private List<RescoreBuilder> rescoreBuilders;
     private Integer defaultRescoreWindowSize;
 
     private ObjectFloatHashMap<String> indexBoost = null;
@@ -158,20 +126,77 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     }
 
     /**
-     * Sets the search query for this request.
+     * Sets the query provided as a {@link QuerySourceBuilder}
+     */
+    public SearchSourceBuilder query(QuerySourceBuilder querySourceBuilder) {
+        this.querySourceBuilder = querySourceBuilder;
+        return this;
+    }
+
+    /**
+     * Constructs a new search source builder with a search query.
      *
      * @see org.elasticsearch.index.query.QueryBuilders
      */
-    public SearchSourceBuilder query(QueryBuilder<?> query) {
-        this.queryBuilder = query;
+    public SearchSourceBuilder query(QueryBuilder query) {
+        if (this.querySourceBuilder == null) {
+            this.querySourceBuilder = new QuerySourceBuilder();
+        }
+        this.querySourceBuilder.setQuery(query);
         return this;
     }
 
     /**
-     * Gets the query for this request
+     * Constructs a new search source builder with a raw search query.
+     */
+    public SearchSourceBuilder query(byte[] queryBinary) {
+        return query(queryBinary, 0, queryBinary.length);
+    }
+
+    /**
+     * Constructs a new search source builder with a raw search query.
      */
-    public QueryBuilder<?> query() {
-        return queryBuilder;
+    public SearchSourceBuilder query(byte[] queryBinary, int queryBinaryOffset, int queryBinaryLength) {
+        return query(new BytesArray(queryBinary, queryBinaryOffset, queryBinaryLength));
+    }
+
+    /**
+     * Constructs a new search source builder with a raw search query.
+     */
+    public SearchSourceBuilder query(BytesReference queryBinary) {
+        if (this.querySourceBuilder == null) {
+            this.querySourceBuilder = new QuerySourceBuilder();
+        }
+        this.querySourceBuilder.setQuery(queryBinary);
+        return this;
+    }
+
+    /**
+     * Constructs a new search source builder with a raw search query.
+     */
+    public SearchSourceBuilder query(String queryString) {
+        return query(queryString.getBytes(StandardCharsets.UTF_8));
+    }
+
+    /**
+     * Constructs a new search source builder with a query from a builder.
+     */
+    public SearchSourceBuilder query(XContentBuilder query) {
+        return query(query.bytes());
+    }
+
+    /**
+     * Constructs a new search source builder with a query from a map.
+     */
+    @SuppressWarnings("unchecked")
+    public SearchSourceBuilder query(Map query) {
+        try {
+            XContentBuilder builder = XContentFactory.contentBuilder(Requests.CONTENT_TYPE);
+            builder.map(query);
+            return query(builder);
+        } catch (IOException e) {
+            throw new ElasticsearchGenerationException("Failed to generate [" + query + "]", e);
+        }
     }
 
     /**
@@ -179,78 +204,96 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
      * only has affect on the search hits (not aggregations). This filter is
      * always executed as last filtering mechanism.
      */
-    public SearchSourceBuilder postFilter(QueryBuilder<?> postFilter) {
+    public SearchSourceBuilder postFilter(QueryBuilder postFilter) {
         this.postQueryBuilder = postFilter;
         return this;
     }
 
     /**
-     * Gets the post filter for this request
+     * Sets a filter on the query executed that only applies to the search query
+     * (and not aggs for example).
      */
-    public QueryBuilder<?> postFilter() {
-        return postQueryBuilder;
+    public SearchSourceBuilder postFilter(String postFilterString) {
+        return postFilter(postFilterString.getBytes(StandardCharsets.UTF_8));
     }
 
     /**
-     * From index to start the search from. Defaults to <tt>0</tt>.
+     * Sets a filter on the query executed that only applies to the search query
+     * (and not aggs for example).
      */
-    public SearchSourceBuilder from(int from) {
-        this.from = from;
-        return this;
+    public SearchSourceBuilder postFilter(byte[] postFilter) {
+        return postFilter(postFilter, 0, postFilter.length);
     }
 
     /**
-     * Gets the from index to start the search from.
-     **/
-    public int from() {
-        return from;
+     * Sets a filter on the query executed that only applies to the search query
+     * (and not aggs for example).
+     */
+    public SearchSourceBuilder postFilter(byte[] postFilterBinary, int postFilterBinaryOffset, int postFilterBinaryLength) {
+        return postFilter(new BytesArray(postFilterBinary, postFilterBinaryOffset, postFilterBinaryLength));
     }
 
     /**
-     * The number of search hits to return. Defaults to <tt>10</tt>.
+     * Sets a filter on the query executed that only applies to the search query
+     * (and not aggs for example).
      */
-    public SearchSourceBuilder size(int size) {
-        this.size = size;
+    public SearchSourceBuilder postFilter(BytesReference postFilterBinary) {
+        this.filterBinary = postFilterBinary;
         return this;
     }
 
     /**
-     * Gets the number of search hits to return.
+     * Constructs a new search source builder with a query from a builder.
      */
-    public int size() {
-        return size;
+    public SearchSourceBuilder postFilter(XContentBuilder postFilter) {
+        return postFilter(postFilter.bytes());
     }
 
     /**
-     * Sets the minimum score below which docs will be filtered out.
+     * Constructs a new search source builder with a query from a map.
      */
-    public SearchSourceBuilder minScore(float minScore) {
-        this.minScore = minScore;
+    @SuppressWarnings("unchecked")
+    public SearchSourceBuilder postFilter(Map postFilter) {
+        try {
+            XContentBuilder builder = XContentFactory.contentBuilder(Requests.CONTENT_TYPE);
+            builder.map(postFilter);
+            return postFilter(builder);
+        } catch (IOException e) {
+            throw new ElasticsearchGenerationException("Failed to generate [" + postFilter + "]", e);
+        }
+    }
+
+    /**
+     * From index to start the search from. Defaults to <tt>0</tt>.
+     */
+    public SearchSourceBuilder from(int from) {
+        this.from = from;
         return this;
     }
 
     /**
-     * Gets the minimum score below which docs will be filtered out.
+     * The number of search hits to return. Defaults to <tt>10</tt>.
      */
-    public Float minScore() {
-        return minScore;
+    public SearchSourceBuilder size(int size) {
+        this.size = size;
+        return this;
     }
 
     /**
-     * Should each {@link org.elasticsearch.search.SearchHit} be returned with
-     * an explanation of the hit (ranking).
+     * Sets the minimum score below which docs will be filtered out.
      */
-    public SearchSourceBuilder explain(Boolean explain) {
-        this.explain = explain;
+    public SearchSourceBuilder minScore(float minScore) {
+        this.minScore = minScore;
         return this;
     }
 
     /**
-     * Indicates whether each search hit will be returned with an explanation of
-     * the hit (ranking)
+     * Should each {@link org.elasticsearch.search.SearchHit} be returned with
+     * an explanation of the hit (ranking).
      */
-    public Boolean explain() {
-        return explain;
+    public SearchSourceBuilder explain(Boolean explain) {
+        this.explain = explain;
+        return this;
     }
 
     /**
@@ -263,14 +306,6 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     }
 
     /**
-     * Indicates whether the document's version will be included in the search
-     * hits.
-     */
-    public Boolean version() {
-        return version;
-    }
-
-    /**
      * An optional timeout to control how long search is allowed to take.
      */
     public SearchSourceBuilder timeout(TimeValue timeout) {
@@ -279,10 +314,11 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     }
 
     /**
-     * Gets the timeout to control how long search is allowed to take.
+     * An optional timeout to control how long search is allowed to take.
      */
-    public long timeoutInMillis() {
-        return timeoutInMillis;
+    public SearchSourceBuilder timeout(String timeout) {
+        this.timeoutInMillis = TimeValue.parseTimeValue(timeout, null, getClass().getSimpleName() + ".timeout").millis();
+        return this;
     }
 
     /**
@@ -298,13 +334,6 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     }
 
     /**
-     * Gets the number of documents to terminate after collecting.
-     */
-    public int terminateAfter() {
-        return terminateAfter;
-    }
-
-    /**
      * Adds a sort against the given field name and the sort ordering.
      *
      * @param name
@@ -330,26 +359,11 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
      * Adds a sort builder.
      */
     public SearchSourceBuilder sort(SortBuilder sort) {
-        try {
-            if (sorts == null) {
-                sorts = new ArrayList<>();
-            }
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            sort.toXContent(builder, EMPTY_PARAMS);
-            builder.endObject();
-            sorts.add(builder.bytes());
-            return this;
-        } catch (IOException e) {
-            throw new RuntimeException(e);
+        if (sorts == null) {
+            sorts = new ArrayList<>();
         }
-    }
-
-    /**
-     * Gets the bytes representing the sort builders for this request.
-     */
-    public List<BytesReference> sorts() {
-        return sorts;
+        sorts.add(sort);
+        return this;
     }
 
     /**
@@ -362,128 +376,102 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     }
 
     /**
-     * Indicates whether scores will be tracked for this request.
+     * Add an get to perform as part of the search.
      */
-    public boolean trackScores() {
-        return trackScores;
+    public SearchSourceBuilder aggregation(AbstractAggregationBuilder aggregation) {
+        if (aggregations == null) {
+            aggregations = new ArrayList<>();
+        }
+        aggregations.add(aggregation);
+        return this;
     }
 
     /**
-     * Add an aggregation to perform as part of the search.
+     * Sets a raw (xcontent / json) addAggregation.
      */
-    public SearchSourceBuilder aggregation(AbstractAggregationBuilder aggregation) {
-        try {
-            if (aggregations == null) {
-                aggregations = new ArrayList<>();
-            }
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            aggregation.toXContent(builder, EMPTY_PARAMS);
-            builder.endObject();
-            aggregations.add(builder.bytes());
-            return this;
-        } catch (IOException e) {
-            throw new RuntimeException(e);
-        }
+    public SearchSourceBuilder aggregations(byte[] aggregationsBinary) {
+        return aggregations(aggregationsBinary, 0, aggregationsBinary.length);
     }
 
     /**
-     * Gets the bytes representing the aggregation builders for this request.
+     * Sets a raw (xcontent / json) addAggregation.
      */
-    public List<BytesReference> aggregations() {
-        return aggregations;
+    public SearchSourceBuilder aggregations(byte[] aggregationsBinary, int aggregationsBinaryOffset, int aggregationsBinaryLength) {
+        return aggregations(new BytesArray(aggregationsBinary, aggregationsBinaryOffset, aggregationsBinaryLength));
     }
 
     /**
-     * Set the rescore window size for rescores that don't specify their window.
+     * Sets a raw (xcontent / json) addAggregation.
      */
-    public SearchSourceBuilder defaultRescoreWindowSize(int defaultRescoreWindowSize) {
-        this.defaultRescoreWindowSize = defaultRescoreWindowSize;
+    public SearchSourceBuilder aggregations(BytesReference aggregationsBinary) {
+        this.aggregationsBinary = aggregationsBinary;
         return this;
     }
 
     /**
-     * Get the rescore window size for rescores that don't specify their window.
+     * Sets a raw (xcontent / json) addAggregation.
      */
-    public int defaultRescoreWindowSize() {
-        return defaultRescoreWindowSize;
+    public SearchSourceBuilder aggregations(XContentBuilder aggs) {
+        return aggregations(aggs.bytes());
     }
 
     /**
-     * Adds highlight to perform as part of the search.
+     * Set the rescore window size for rescores that don't specify their window.
      */
-    public SearchSourceBuilder highlighter(HighlightBuilder highlightBuilder) {
-        try {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            highlightBuilder.innerXContent(builder, EMPTY_PARAMS);
-            builder.endObject();
-            this.highlightBuilder = builder.bytes();
-            return this;
-        } catch (IOException e) {
-            throw new RuntimeException(e);
-        }
+    public SearchSourceBuilder defaultRescoreWindowSize(int defaultRescoreWindowSize) {
+        this.defaultRescoreWindowSize = defaultRescoreWindowSize;
+        return this;
     }
 
     /**
-     * Gets the bytes representing the hightlighter builder for this request.
+     * Sets a raw (xcontent / json) addAggregation.
      */
-    public BytesReference highlighter() {
-        return highlightBuilder;
-    }
-
-    public SearchSourceBuilder innerHits(InnerHitsBuilder innerHitsBuilder) {
+    @SuppressWarnings("unchecked")
+    public SearchSourceBuilder aggregations(Map aggregations) {
         try {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            innerHitsBuilder.innerXContent(builder, EMPTY_PARAMS);
-            builder.endObject();
-            this.innerHitsBuilder = builder.bytes();
-            return this;
+            XContentBuilder builder = XContentFactory.contentBuilder(Requests.CONTENT_TYPE);
+            builder.map(aggregations);
+            return aggregations(builder);
         } catch (IOException e) {
-            throw new RuntimeException(e);
+            throw new ElasticsearchGenerationException("Failed to generate [" + aggregations + "]", e);
+        }
+    }
+
+    public HighlightBuilder highlighter() {
+        if (highlightBuilder == null) {
+            highlightBuilder = new HighlightBuilder();
         }
+        return highlightBuilder;
     }
 
     /**
-     * Gets the bytes representing the inner hits builder for this request.
+     * Adds highlight to perform as part of the search.
      */
-    public BytesReference innerHits() {
-        return innerHitsBuilder;
+    public SearchSourceBuilder highlight(HighlightBuilder highlightBuilder) {
+        this.highlightBuilder = highlightBuilder;
+        return this;
     }
 
-    public SearchSourceBuilder suggest(SuggestBuilder suggestBuilder) {
-        try {
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            suggestBuilder.toXContent(builder, EMPTY_PARAMS);
-            this.suggestBuilder = builder.bytes();
-            return this;
-        } catch (IOException e) {
-            throw new RuntimeException(e);
+    public InnerHitsBuilder innerHitsBuilder() {
+        if (innerHitsBuilder == null) {
+            innerHitsBuilder = new InnerHitsBuilder();
         }
+        return innerHitsBuilder;
     }
 
-    /**
-     * Gets the bytes representing the suggester builder for this request.
-     */
-    public BytesReference suggest() {
+    public SuggestBuilder suggest() {
+        if (suggestBuilder == null) {
+            suggestBuilder = new SuggestBuilder("suggest");
+        }
         return suggestBuilder;
     }
 
     public SearchSourceBuilder addRescorer(RescoreBuilder rescoreBuilder) {
-        try {
-            if (rescoreBuilders == null) {
-                rescoreBuilders = new ArrayList<>();
-            }
-            XContentBuilder builder = XContentFactory.jsonBuilder();
-            builder.startObject();
-            rescoreBuilder.toXContent(builder, EMPTY_PARAMS);
-            builder.endObject();
-            rescoreBuilders.add(builder.bytes());
-            return this;
-        } catch (IOException e) {
-            throw new RuntimeException(e);
+        if (rescoreBuilders == null) {
+            rescoreBuilders = new ArrayList<>();
         }
+        rescoreBuilders.add(rescoreBuilder);
+        return this;
     }
 
     public SearchSourceBuilder clearRescorers() {
@@ -492,13 +480,6 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     }
 
     /**
-     * Gets the bytes representing the rescore builders for this request.
-     */
-    public List<BytesReference> rescores() {
-        return rescoreBuilders;
-    }
-
-    /**
      * Indicates whether the response should contain the stored _source for
      * every hit
      */
@@ -554,23 +535,11 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     }
 
     /**
-     * Gets the {@link FetchSourceContext} which defines how the _source should
-     * be fetched.
-     */
-    public FetchSourceContext fetchSource() {
-        return fetchSourceContext;
-    }
-
-    /**
-     * Adds a field to load and return (note, it must be stored) as part of the
-     * search request. If none are specified, the source of the document will be
-     * return.
+     * Sets no fields to be loaded, resulting in only id and type to be returned
+     * per field.
      */
-    public SearchSourceBuilder field(String name) {
-        if (fieldNames == null) {
-            fieldNames = new ArrayList<>();
-        }
-        fieldNames.add(name);
+    public SearchSourceBuilder noFields() {
+        this.fieldNames = Collections.emptyList();
         return this;
     }
 
@@ -584,19 +553,28 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     }
 
     /**
-     * Sets no fields to be loaded, resulting in only id and type to be returned
-     * per field.
+     * Adds the fields to load and return as part of the search request. If none
+     * are specified, the source of the document will be returned.
      */
-    public SearchSourceBuilder noFields() {
-        this.fieldNames = Collections.emptyList();
+    public SearchSourceBuilder fields(String... fields) {
+        if (fieldNames == null) {
+            fieldNames = new ArrayList<>();
+        }
+        Collections.addAll(fieldNames, fields);
         return this;
     }
 
     /**
-     * Gets the fields to load and return as part of the search request.
+     * Adds a field to load and return (note, it must be stored) as part of the
+     * search request. If none are specified, the source of the document will be
+     * return.
      */
-    public List<String> fields() {
-        return fieldNames;
+    public SearchSourceBuilder field(String name) {
+        if (fieldNames == null) {
+            fieldNames = new ArrayList<>();
+        }
+        fieldNames.add(name);
+        return this;
     }
 
     /**
@@ -612,13 +590,6 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     }
 
     /**
-     * Gets the field-data fields.
-     */
-    public List<String> fieldDataFields() {
-        return fieldDataFields;
-    }
-
-    /**
      * Adds a script field under the given name with the provided script.
      *
      * @param name
@@ -635,13 +606,6 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     }
 
     /**
-     * Gets the script fields.
-     */
-    public List<ScriptField> scriptFields() {
-        return scriptFields;
-    }
-
-    /**
      * Sets the boost a specific index will receive when the query is executeed
      * against it.
      *
@@ -659,14 +623,6 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
     }
 
     /**
-     * Gets the boost a specific indices will receive when the query is
-     * executeed against them.
-     */
-    public ObjectFloatHashMap<String> indexBoost() {
-        return indexBoost;
-    }
-
-    /**
      * The stats groups this request will be aggregated under.
      */
     public SearchSourceBuilder stats(String... statsGroups) {
@@ -674,206 +630,6 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
         return this;
     }
 
-    /**
-     * The stats groups this request will be aggregated under.
-     */
-    public String[] stats() {
-        return stats;
-    }
-
-    public SearchSourceBuilder fromXContent(XContentParser parser, QueryParseContext context) throws IOException {
-        SearchSourceBuilder builder = new SearchSourceBuilder();
-        XContentParser.Token token;
-        String currentFieldName = null;
-        if ((token = parser.nextToken()) != XContentParser.Token.START_OBJECT) {
-            throw new ParsingException(parser.getTokenLocation(), "Expected [" + XContentParser.Token.START_OBJECT + "] but found [" + token + "]",
-                    parser.getTokenLocation());
-        }
-        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-            if (token == XContentParser.Token.FIELD_NAME) {
-                currentFieldName = parser.currentName();
-            } else if (token.isValue()) {
-                if (context.parseFieldMatcher().match(currentFieldName, FROM_FIELD)) {
-                    builder.from = parser.intValue();
-                } else if (context.parseFieldMatcher().match(currentFieldName, SIZE_FIELD)) {
-                    builder.size = parser.intValue();
-                } else if (context.parseFieldMatcher().match(currentFieldName, TIMEOUT_FIELD)) {
-                    builder.timeoutInMillis = parser.longValue();
-                } else if (context.parseFieldMatcher().match(currentFieldName, TERMINATE_AFTER_FIELD)) {
-                    builder.terminateAfter = parser.intValue();
-                } else if (context.parseFieldMatcher().match(currentFieldName, MIN_SCORE_FIELD)) {
-                    builder.minScore = parser.floatValue();
-                } else if (context.parseFieldMatcher().match(currentFieldName, VERSION_FIELD)) {
-                    builder.version = parser.booleanValue();
-                } else if (context.parseFieldMatcher().match(currentFieldName, EXPLAIN_FIELD)) {
-                    builder.explain = parser.booleanValue();
-                } else if (context.parseFieldMatcher().match(currentFieldName, TRACK_SCORES_FIELD)) {
-                    builder.trackScores = parser.booleanValue();
-                } else if (context.parseFieldMatcher().match(currentFieldName, _SOURCE_FIELD)) {
-                    FetchSourceContext fetchSourceContext = FetchSourceContext.parse(parser, context);
-                    builder.fetchSourceContext = fetchSourceContext;
-                } else if (context.parseFieldMatcher().match(currentFieldName, FIELDS_FIELD)) {
-                    List<String> fieldNames = new ArrayList<>();
-                    fieldNames.add(parser.text());
-                    builder.fieldNames = fieldNames;
-                } else if (context.parseFieldMatcher().match(currentFieldName, SORT_FIELD)) {
-                    builder.sort(parser.text());
-                } else {
-                    throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName + "].",
-                            parser.getTokenLocation());
-                }
-            } else if (token == XContentParser.Token.START_OBJECT) {
-                if (context.parseFieldMatcher().match(currentFieldName, QUERY_FIELD)) {
-                    builder.queryBuilder = context.parseInnerQueryBuilder();
-                } else if (context.parseFieldMatcher().match(currentFieldName, POST_FILTER_FIELD)) {
-                    builder.postQueryBuilder = context.parseInnerQueryBuilder();
-                } else if (context.parseFieldMatcher().match(currentFieldName, _SOURCE_FIELD)) {
-                    FetchSourceContext fetchSourceContext = FetchSourceContext.parse(parser, context);
-                    builder.fetchSourceContext = fetchSourceContext;
-                } else if (context.parseFieldMatcher().match(currentFieldName, SCRIPT_FIELDS_FIELD)) {
-                    List<ScriptField> scriptFields = new ArrayList<>();
-                    while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-                        String scriptFieldName = parser.currentName();
-                        token = parser.nextToken();
-                        if (token == XContentParser.Token.START_OBJECT) {
-                            while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-                                if (token == XContentParser.Token.FIELD_NAME) {
-                                    currentFieldName = parser.currentName();
-                                } else if (token.isValue()) {
-                                    if (context.parseFieldMatcher().match(currentFieldName, SCRIPT_FIELD)) {
-                                        scriptFields
-                                                .add(new ScriptField(scriptFieldName, Script.parse(parser, context.parseFieldMatcher())));
-                                    } else {
-                                        throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName
-                                                + "].", parser.getTokenLocation());
-                                    }
-                                } else if (token == XContentParser.Token.START_OBJECT) {
-                                    if (context.parseFieldMatcher().match(currentFieldName, SCRIPT_FIELD)) {
-                                        scriptFields
-                                                .add(new ScriptField(scriptFieldName, Script.parse(parser, context.parseFieldMatcher())));
-                                    } else {
-                                        throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName
-                                                + "].", parser.getTokenLocation());
-                                    }
-                                } else {
-                                    throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName
-                                            + "].", parser.getTokenLocation());
-                                }
-                            }
-                        } else {
-                            throw new ParsingException(parser.getTokenLocation(), "Expected [" + XContentParser.Token.START_OBJECT + "] in ["
-                                    + currentFieldName + "] but found [" + token + "]", parser.getTokenLocation());
-                        }
-                    }
-                    builder.scriptFields = scriptFields;
-                } else if (context.parseFieldMatcher().match(currentFieldName, INDICES_BOOST_FIELD)) {
-                    ObjectFloatHashMap<String> indexBoost = new ObjectFloatHashMap<String>();
-                    while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-                        if (token == XContentParser.Token.FIELD_NAME) {
-                            currentFieldName = parser.currentName();
-                        } else if (token.isValue()) {
-                            indexBoost.put(currentFieldName, parser.floatValue());
-                        } else {
-                            throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName + "].",
-                                    parser.getTokenLocation());
-                        }
-                    }
-                    builder.indexBoost = indexBoost;
-                } else if (context.parseFieldMatcher().match(currentFieldName, AGGREGATIONS_FIELD)) {
-                    List<BytesReference> aggregations = new ArrayList<>();
-                    while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-                        currentFieldName = parser.currentName();
-                        token = parser.nextToken();
-                        if (token == XContentParser.Token.START_OBJECT) {
-                            XContentBuilder xContentBuilder = XContentFactory.contentBuilder(parser.contentType());
-                            xContentBuilder.startObject();
-                            xContentBuilder.field(currentFieldName);
-                            xContentBuilder.copyCurrentStructure(parser);
-                            xContentBuilder.endObject();
-                            aggregations.add(xContentBuilder.bytes());
-                        } else {
-                            throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName + "].",
-                                    parser.getTokenLocation());
-                        }
-                    }
-                    builder.aggregations = aggregations;
-                } else if (context.parseFieldMatcher().match(currentFieldName, HIGHLIGHT_FIELD)) {
-                    XContentBuilder xContentBuilder = XContentFactory.contentBuilder(parser.contentType()).copyCurrentStructure(parser);
-                    builder.highlightBuilder = xContentBuilder.bytes();
-                } else if (context.parseFieldMatcher().match(currentFieldName, INNER_HITS_FIELD)) {
-                    XContentBuilder xContentBuilder = XContentFactory.contentBuilder(parser.contentType()).copyCurrentStructure(parser);
-                    builder.innerHitsBuilder = xContentBuilder.bytes();
-                } else if (context.parseFieldMatcher().match(currentFieldName, SUGGEST_FIELD)) {
-                    XContentBuilder xContentBuilder = XContentFactory.contentBuilder(parser.contentType()).copyCurrentStructure(parser);
-                    builder.suggestBuilder = xContentBuilder.bytes();
-                } else {
-                    throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName + "].",
-                            parser.getTokenLocation());
-                }
-            } else if (token == XContentParser.Token.START_ARRAY) {
-
-                if (context.parseFieldMatcher().match(currentFieldName, FIELDS_FIELD)) {
-                    List<String> fieldNames = new ArrayList<>();
-                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        if (token == XContentParser.Token.VALUE_STRING) {
-                            fieldNames.add(parser.text());
-                        } else {
-                            throw new ParsingException(parser.getTokenLocation(), "Expected [" + XContentParser.Token.VALUE_STRING + "] in ["
-                                    + currentFieldName + "] but found [" + token + "]", parser.getTokenLocation());
-                        }
-                    }
-                    builder.fieldNames = fieldNames;
-                } else if (context.parseFieldMatcher().match(currentFieldName, FIELDDATA_FIELDS_FIELD)) {
-                    List<String> fieldDataFields = new ArrayList<>();
-                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        if (token == XContentParser.Token.VALUE_STRING) {
-                            fieldDataFields.add(parser.text());
-                        } else {
-                            throw new ParsingException(parser.getTokenLocation(), "Expected [" + XContentParser.Token.VALUE_STRING + "] in ["
-                                    + currentFieldName + "] but found [" + token + "]", parser.getTokenLocation());
-                        }
-                    }
-                    builder.fieldDataFields = fieldDataFields;
-                } else if (context.parseFieldMatcher().match(currentFieldName, SORT_FIELD)) {
-                    List<BytesReference> sorts = new ArrayList<>();
-                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        XContentBuilder xContentBuilder = XContentFactory.contentBuilder(parser.contentType()).copyCurrentStructure(parser);
-                        sorts.add(xContentBuilder.bytes());
-                    }
-                    builder.sorts = sorts;
-                } else if (context.parseFieldMatcher().match(currentFieldName, RESCORE_FIELD)) {
-                    List<BytesReference> rescoreBuilders = new ArrayList<>();
-                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        XContentBuilder xContentBuilder = XContentFactory.contentBuilder(parser.contentType()).copyCurrentStructure(parser);
-                        rescoreBuilders.add(xContentBuilder.bytes());
-                    }
-                    builder.rescoreBuilders = rescoreBuilders;
-                } else if (context.parseFieldMatcher().match(currentFieldName, STATS_FIELD)) {
-                    List<String> stats = new ArrayList<>();
-                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                        if (token == XContentParser.Token.VALUE_STRING) {
-                            stats.add(parser.text());
-                        } else {
-                            throw new ParsingException(parser.getTokenLocation(), "Expected [" + XContentParser.Token.VALUE_STRING + "] in ["
-                                    + currentFieldName + "] but found [" + token + "]", parser.getTokenLocation());
-                        }
-                    }
-                    builder.stats = stats.toArray(new String[stats.size()]);
-                } else if (context.parseFieldMatcher().match(currentFieldName, _SOURCE_FIELD)) {
-                    FetchSourceContext fetchSourceContext = FetchSourceContext.parse(parser, context);
-                    builder.fetchSourceContext = fetchSourceContext;
-                } else {
-                    throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName + "].",
-                            parser.getTokenLocation());
-                }
-            } else {
-                throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName + "].",
-                        parser.getTokenLocation());
-            }
-        }
-        return builder;
-    }
-
     @Override
     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject();
@@ -884,49 +640,65 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
 
     public void innerToXContent(XContentBuilder builder, Params params) throws IOException {
         if (from != -1) {
-            builder.field(FROM_FIELD.getPreferredName(), from);
+            builder.field("from", from);
         }
         if (size != -1) {
-            builder.field(SIZE_FIELD.getPreferredName(), size);
+            builder.field("size", size);
         }
 
         if (timeoutInMillis != -1) {
-            builder.field(TIMEOUT_FIELD.getPreferredName(), timeoutInMillis);
+            builder.field("timeout", timeoutInMillis);
         }
 
         if (terminateAfter != SearchContext.DEFAULT_TERMINATE_AFTER) {
-            builder.field(TERMINATE_AFTER_FIELD.getPreferredName(), terminateAfter);
+            builder.field("terminate_after", terminateAfter);
         }
 
-        if (queryBuilder != null) {
-            builder.field(QUERY_FIELD.getPreferredName(), queryBuilder);
+        if (querySourceBuilder != null) {
+            querySourceBuilder.innerToXContent(builder, params);
         }
 
         if (postQueryBuilder != null) {
-            builder.field(POST_FILTER_FIELD.getPreferredName(), postQueryBuilder);
+            builder.field("post_filter");
+            postQueryBuilder.toXContent(builder, params);
+        }
+
+        if (filterBinary != null) {
+            if (XContentFactory.xContentType(filterBinary) == builder.contentType()) {
+                builder.rawField("filter", filterBinary);
+            } else {
+                builder.field("filter_binary", filterBinary);
+            }
         }
 
         if (minScore != null) {
-            builder.field(MIN_SCORE_FIELD.getPreferredName(), minScore);
+            builder.field("min_score", minScore);
         }
 
         if (version != null) {
-            builder.field(VERSION_FIELD.getPreferredName(), version);
+            builder.field("version", version);
         }
 
         if (explain != null) {
-            builder.field(EXPLAIN_FIELD.getPreferredName(), explain);
+            builder.field("explain", explain);
         }
 
         if (fetchSourceContext != null) {
-            builder.field(_SOURCE_FIELD.getPreferredName(), fetchSourceContext);
+            if (!fetchSourceContext.fetchSource()) {
+                builder.field("_source", false);
+            } else {
+                builder.startObject("_source");
+                builder.array("includes", fetchSourceContext.includes());
+                builder.array("excludes", fetchSourceContext.excludes());
+                builder.endObject();
+            }
         }
 
         if (fieldNames != null) {
             if (fieldNames.size() == 1) {
-                builder.field(FIELDS_FIELD.getPreferredName(), fieldNames.get(0));
+                builder.field("fields", fieldNames.get(0));
             } else {
-                builder.startArray(FIELDS_FIELD.getPreferredName());
+                builder.startArray("fields");
                 for (String fieldName : fieldNames) {
                     builder.value(fieldName);
                 }
@@ -935,15 +707,15 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
         }
 
         if (fieldDataFields != null) {
-            builder.startArray(FIELDDATA_FIELDS_FIELD.getPreferredName());
-            for (String fieldDataField : fieldDataFields) {
-                builder.value(fieldDataField);
+            builder.startArray("fielddata_fields");
+            for (String fieldName : fieldDataFields) {
+                builder.value(fieldName);
             }
             builder.endArray();
         }
 
         if (scriptFields != null) {
-            builder.startObject(SCRIPT_FIELDS_FIELD.getPreferredName());
+            builder.startObject("script_fields");
             for (ScriptField scriptField : scriptFields) {
                 builder.startObject(scriptField.fieldName());
                 builder.field("script", scriptField.script());
@@ -953,21 +725,21 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
         }
 
         if (sorts != null) {
-            builder.startArray(SORT_FIELD.getPreferredName());
-            for (BytesReference sort : sorts) {
-                XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(sort);
-                parser.nextToken();
-                builder.copyCurrentStructure(parser);
+            builder.startArray("sort");
+            for (SortBuilder sort : sorts) {
+                builder.startObject();
+                sort.toXContent(builder, params);
+                builder.endObject();
             }
             builder.endArray();
         }
 
         if (trackScores) {
-            builder.field(TRACK_SCORES_FIELD.getPreferredName(), true);
+            builder.field("track_scores", true);
         }
 
         if (indexBoost != null) {
-            builder.startObject(INDICES_BOOST_FIELD.getPreferredName());
+            builder.startObject("indices_boost");
             assert !indexBoost.containsKey(null);
             final Object[] keys = indexBoost.keys;
             final float[] values = indexBoost.values;
@@ -980,57 +752,76 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
         }
 
         if (aggregations != null) {
-            builder.field(AGGREGATIONS_FIELD.getPreferredName());
+            builder.field("aggregations");
             builder.startObject();
-            for (BytesReference aggregation : aggregations) {
-                XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(aggregation);
-                parser.nextToken();
-                parser.nextToken();
-                builder.copyCurrentStructure(parser);
+            for (AbstractAggregationBuilder aggregation : aggregations) {
+                aggregation.toXContent(builder, params);
             }
             builder.endObject();
         }
 
+        if (aggregationsBinary != null) {
+            if (XContentFactory.xContentType(aggregationsBinary) == builder.contentType()) {
+                builder.rawField("aggregations", aggregationsBinary);
+            } else {
+                builder.field("aggregations_binary", aggregationsBinary);
+            }
+        }
+
         if (highlightBuilder != null) {
-            builder.field(HIGHLIGHT_FIELD.getPreferredName());
-            XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(highlightBuilder);
-            parser.nextToken();
-            builder.copyCurrentStructure(parser);
+            highlightBuilder.toXContent(builder, params);
         }
 
         if (innerHitsBuilder != null) {
-            builder.field(INNER_HITS_FIELD.getPreferredName());
-            XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(innerHitsBuilder);
-            parser.nextToken();
-            builder.copyCurrentStructure(parser);
+            innerHitsBuilder.toXContent(builder, params);
         }
 
         if (suggestBuilder != null) {
-            builder.field(SUGGEST_FIELD.getPreferredName());
-            XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(suggestBuilder);
-            parser.nextToken();
-            builder.copyCurrentStructure(parser);
+            suggestBuilder.toXContent(builder, params);
         }
 
         if (rescoreBuilders != null) {
-            builder.startArray(RESCORE_FIELD.getPreferredName());
-            for (BytesReference rescoreBuilder : rescoreBuilders) {
-                XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(rescoreBuilder);
-                parser.nextToken();
-                builder.copyCurrentStructure(parser);
+            // Strip empty rescoreBuilders from the request
+            Iterator<RescoreBuilder> itr = rescoreBuilders.iterator();
+            while (itr.hasNext()) {
+                if (itr.next().isEmpty()) {
+                    itr.remove();
+                }
+            }
+
+            // Now build the request taking care to skip empty lists and only send the object form
+            // if there is just one builder.
+            if (rescoreBuilders.size() == 1) {
+                builder.startObject("rescore");
+                rescoreBuilders.get(0).toXContent(builder, params);
+                if (rescoreBuilders.get(0).windowSize() == null && defaultRescoreWindowSize != null) {
+                    builder.field("window_size", defaultRescoreWindowSize);
+                }
+                builder.endObject();
+            } else if (!rescoreBuilders.isEmpty()) {
+                builder.startArray("rescore");
+                for (RescoreBuilder rescoreBuilder : rescoreBuilders) {
+                    builder.startObject();
+                    rescoreBuilder.toXContent(builder, params);
+                    if (rescoreBuilder.windowSize() == null && defaultRescoreWindowSize != null) {
+                        builder.field("window_size", defaultRescoreWindowSize);
+                    }
+                    builder.endObject();
+                }
+                builder.endArray();
             }
-            builder.endArray();
         }
 
         if (stats != null) {
-            builder.array(STATS_FIELD.getPreferredName(), stats);
+            builder.startArray("stats");
+            for (String stat : stats) {
+                builder.value(stat);
+            }
+            builder.endArray();
         }
     }
 
-    public static class ScriptField implements Writeable<ScriptField>, ToXContent {
-
-        public static final ScriptField PROTOTYPE = new ScriptField(null, null);
-
+    private static class ScriptField {
         private final String fieldName;
         private final Script script;
 
@@ -1046,288 +837,5 @@ public final class SearchSourceBuilder extends ToXContentToBytes implements Writ
         public Script script() {
             return script;
         }
-
-        @Override
-        public ScriptField readFrom(StreamInput in) throws IOException {
-            return new ScriptField(in.readString(), Script.readScript(in));
-        }
-
-        @Override
-        public void writeTo(StreamOutput out) throws IOException {
-            out.writeString(fieldName);
-            script.writeTo(out);
-        }
-
-        @Override
-        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-            builder.startObject(fieldName);
-            builder.field(SCRIPT_FIELD.getPreferredName(), script);
-            builder.endObject();
-            return builder;
-        }
-
-        @Override
-        public int hashCode() {
-            return Objects.hash(fieldName, script);
-        }
-
-        @Override
-        public boolean equals(Object obj) {
-            if (obj == null) {
-                return false;
-            }
-            if (getClass() != obj.getClass()) {
-                return false;
-            }
-            ScriptField other = (ScriptField) obj;
-            return Objects.equals(fieldName, other.fieldName) && Objects.equals(script, other.script);
-        }
-    }
-
-    @Override
-    public SearchSourceBuilder readFrom(StreamInput in) throws IOException {
-        SearchSourceBuilder builder = new SearchSourceBuilder();
-        if (in.readBoolean()) {
-            int size = in.readVInt();
-            List<BytesReference> aggregations = new ArrayList<>(size);
-            for (int i = 0; i < size; i++) {
-                aggregations.add(in.readBytesReference());
-            }
-            builder.aggregations = aggregations;
-        }
-        if (in.readBoolean()) {
-            builder.defaultRescoreWindowSize = in.readVInt();
-        }
-        builder.explain = in.readOptionalBoolean();
-        builder.fetchSourceContext = FetchSourceContext.optionalReadFromStream(in);
-        boolean hasFieldDataFields = in.readBoolean();
-        if (hasFieldDataFields) {
-            int size = in.readVInt();
-            List<String> fieldDataFields = new ArrayList<>(size);
-            for (int i = 0; i < size; i++) {
-                fieldDataFields.add(in.readString());
-            }
-            builder.fieldDataFields = fieldDataFields;
-        }
-        boolean hasFieldNames = in.readBoolean();
-        if (hasFieldNames) {
-            int size = in.readVInt();
-            List<String> fieldNames = new ArrayList<>(size);
-            for (int i = 0; i < size; i++) {
-                fieldNames.add(in.readString());
-            }
-            builder.fieldNames = fieldNames;
-        }
-        builder.from = in.readVInt();
-        if (in.readBoolean()) {
-            builder.highlightBuilder = in.readBytesReference();
-        }
-        boolean hasIndexBoost = in.readBoolean();
-        if (hasIndexBoost) {
-            int size = in.readVInt();
-            ObjectFloatHashMap<String> indexBoost = new ObjectFloatHashMap<String>(size);
-            for (int i = 0; i < size; i++) {
-                indexBoost.put(in.readString(), in.readFloat());
-            }
-            builder.indexBoost = indexBoost;
-        }
-        if (in.readBoolean()) {
-            builder.innerHitsBuilder = in.readBytesReference();
-        }
-        if (in.readBoolean()) {
-            builder.minScore = in.readFloat();
-        }
-        if (in.readBoolean()) {
-            builder.postQueryBuilder = in.readQuery();
-        }
-        if (in.readBoolean()) {
-            builder.queryBuilder = in.readQuery();
-        }
-        if (in.readBoolean()) {
-            int size = in.readVInt();
-            List<BytesReference> rescoreBuilders = new ArrayList<>();
-            for (int i = 0; i < size; i++) {
-                rescoreBuilders.add(in.readBytesReference());
-            }
-            builder.rescoreBuilders = rescoreBuilders;
-        }
-        if (in.readBoolean()) {
-            int size = in.readVInt();
-            List<ScriptField> scriptFields = new ArrayList<>(size);
-            for (int i = 0; i < size; i++) {
-                scriptFields.add(ScriptField.PROTOTYPE.readFrom(in));
-            }
-            builder.scriptFields = scriptFields;
-        }
-        builder.size = in.readVInt();
-        if (in.readBoolean()) {
-            int size = in.readVInt();
-            List<BytesReference> sorts = new ArrayList<>();
-            for (int i = 0; i < size; i++) {
-                sorts.add(in.readBytesReference());
-            }
-            builder.sorts = sorts;
-        }
-        if (in.readBoolean()) {
-            builder.stats = in.readStringArray();
-        }
-        if (in.readBoolean()) {
-            builder.suggestBuilder = in.readBytesReference();
-        }
-        builder.terminateAfter = in.readVInt();
-        builder.timeoutInMillis = in.readLong();
-        builder.trackScores = in.readBoolean();
-        builder.version = in.readOptionalBoolean();
-        return builder;
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        boolean hasAggregations = aggregations != null;
-        out.writeBoolean(hasAggregations);
-        if (hasAggregations) {
-            out.writeVInt(aggregations.size());
-            for (BytesReference aggregation : aggregations) {
-                out.writeBytesReference(aggregation);
-            }
-        }
-        boolean hasDefaultRescoreWindowSize = defaultRescoreWindowSize != null;
-        out.writeBoolean(hasDefaultRescoreWindowSize);
-        if (hasDefaultRescoreWindowSize) {
-            out.writeVInt(defaultRescoreWindowSize);
-        }
-        out.writeOptionalBoolean(explain);
-        FetchSourceContext.optionalWriteToStream(fetchSourceContext, out);
-        boolean hasFieldDataFields = fieldDataFields != null;
-        out.writeBoolean(hasFieldDataFields);
-        if (hasFieldDataFields) {
-            out.writeVInt(fieldDataFields.size());
-            for (String field : fieldDataFields) {
-                out.writeString(field);
-            }
-        }
-        boolean hasFieldNames = fieldNames != null;
-        out.writeBoolean(hasFieldNames);
-        if (hasFieldNames) {
-            out.writeVInt(fieldNames.size());
-            for (String field : fieldNames) {
-                out.writeString(field);
-            }
-        }
-        out.writeVInt(from);
-        boolean hasHighlightBuilder = highlightBuilder != null;
-        out.writeBoolean(hasHighlightBuilder);
-        if (hasHighlightBuilder) {
-            out.writeBytesReference(highlightBuilder);
-        }
-        boolean hasIndexBoost = indexBoost != null;
-        out.writeBoolean(hasIndexBoost);
-        if (hasIndexBoost) {
-            out.writeVInt(indexBoost.size());
-            for (ObjectCursor<String> key : indexBoost.keys()) {
-                out.writeString(key.value);
-                out.writeFloat(indexBoost.get(key.value));
-            }
-        }
-        boolean hasInnerHitsBuilder = innerHitsBuilder != null;
-        out.writeBoolean(hasInnerHitsBuilder);
-        if (hasInnerHitsBuilder) {
-            out.writeBytesReference(innerHitsBuilder);
-        }
-        boolean hasMinScore = minScore != null;
-        out.writeBoolean(hasMinScore);
-        if (hasMinScore) {
-            out.writeFloat(minScore);
-        }
-        boolean hasPostQuery = postQueryBuilder != null;
-        out.writeBoolean(hasPostQuery);
-        if (hasPostQuery) {
-            out.writeQuery(postQueryBuilder);
-        }
-        boolean hasQuery = queryBuilder != null;
-        out.writeBoolean(hasQuery);
-        if (hasQuery) {
-            out.writeQuery(queryBuilder);
-        }
-        boolean hasRescoreBuilders = rescoreBuilders != null;
-        out.writeBoolean(hasRescoreBuilders);
-        if (hasRescoreBuilders) {
-            out.writeVInt(rescoreBuilders.size());
-            for (BytesReference rescoreBuilder : rescoreBuilders) {
-                out.writeBytesReference(rescoreBuilder);
-            }
-        }
-        boolean hasScriptFields = scriptFields != null;
-        out.writeBoolean(hasScriptFields);
-        if (hasScriptFields) {
-            out.writeVInt(scriptFields.size());
-            for (ScriptField scriptField : scriptFields) {
-                scriptField.writeTo(out);
-            }
-        }
-        out.writeVInt(size);
-        boolean hasSorts = sorts != null;
-        out.writeBoolean(hasSorts);
-        if (hasSorts) {
-            out.writeVInt(sorts.size());
-            for (BytesReference sort : sorts) {
-                out.writeBytesReference(sort);
-            }
-        }
-        boolean hasStats = stats != null;
-        out.writeBoolean(hasStats);
-        if (hasStats) {
-            out.writeStringArray(stats);
-        }
-        boolean hasSuggestBuilder = suggestBuilder != null;
-        out.writeBoolean(hasSuggestBuilder);
-        if (hasSuggestBuilder) {
-            out.writeBytesReference(suggestBuilder);
-        }
-        out.writeVInt(terminateAfter);
-        out.writeLong(timeoutInMillis);
-        out.writeBoolean(trackScores);
-        out.writeOptionalBoolean(version);
-    }
-
-    @Override
-    public int hashCode() {
-        return Objects.hash(aggregations, defaultRescoreWindowSize, explain, fetchSourceContext, fieldDataFields, fieldNames, from,
-                highlightBuilder, indexBoost, innerHitsBuilder, minScore, postQueryBuilder, queryBuilder, rescoreBuilders, scriptFields,
-                size, sorts, Arrays.hashCode(stats), suggestBuilder, terminateAfter, timeoutInMillis, trackScores, version);
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-        if (obj == null) {
-            return false;
-        }
-        if (obj.getClass() != getClass()) {
-            return false;
-        }
-        SearchSourceBuilder other = (SearchSourceBuilder) obj;
-        return Objects.equals(aggregations, other.aggregations)
-                && Objects.equals(defaultRescoreWindowSize, other.defaultRescoreWindowSize)
-                && Objects.equals(explain, other.explain)
-                && Objects.equals(fetchSourceContext, other.fetchSourceContext)
-                && Objects.equals(fieldDataFields, other.fieldDataFields)
-                && Objects.equals(fieldNames, other.fieldNames)
-                && Objects.equals(from, other.from)
-                && Objects.equals(highlightBuilder, other.highlightBuilder)
-                && Objects.equals(indexBoost, other.indexBoost)
-                && Objects.equals(innerHitsBuilder, other.innerHitsBuilder)
-                && Objects.equals(minScore, other.minScore)
-                && Objects.equals(postQueryBuilder, other.postQueryBuilder)
-                && Objects.equals(queryBuilder, other.queryBuilder)
-                && Objects.equals(rescoreBuilders, other.rescoreBuilders)
-                && Objects.equals(scriptFields, other.scriptFields)
-                && Objects.equals(size, other.size)
-                && Objects.equals(sorts, other.sorts)
-                && Objects.deepEquals(stats, other.stats)
-                && Objects.equals(suggestBuilder, other.suggestBuilder)
-                && Objects.equals(terminateAfter, other.terminateAfter)
-                && Objects.equals(timeoutInMillis, other.timeoutInMillis)
-                && Objects.equals(trackScores, other.trackScores)
-                && Objects.equals(version, other.version);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java
index 7941e17..a14fdfe 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsBuilder.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.search.fetch.innerhits;
 
 import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
@@ -43,16 +42,12 @@ public class InnerHitsBuilder implements ToXContent {
     @Override
     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject("inner_hits");
-        innerXContent(builder, params);
-        return builder.endObject();
-    }
-
-    public void innerXContent(XContentBuilder builder, Params params) throws IOException {
         for (Map.Entry<String, InnerHitsHolder> entry : innerHits.entrySet()) {
             builder.startObject(entry.getKey());
             entry.getValue().toXContent(builder, params);
             builder.endObject();
         }
+        return builder.endObject();
     }
 
     /**
@@ -266,12 +261,187 @@ public class InnerHitsBuilder implements ToXContent {
             return this;
         }
 
-        public BytesReference highlighter() {
+        public HighlightBuilder highlightBuilder() {
             return sourceBuilder().highlighter();
         }
 
-        public InnerHit highlighter(HighlightBuilder highlightBuilder) {
-            sourceBuilder().highlighter(highlightBuilder);
+        /**
+         * Adds a field to be highlighted with default fragment size of 100 characters, and
+         * default number of fragments of 5.
+         *
+         * @param name The field to highlight
+         */
+        public InnerHit addHighlightedField(String name) {
+            highlightBuilder().field(name);
+            return this;
+        }
+
+
+        /**
+         * Adds a field to be highlighted with a provided fragment size (in characters), and
+         * default number of fragments of 5.
+         *
+         * @param name         The field to highlight
+         * @param fragmentSize The size of a fragment in characters
+         */
+        public InnerHit addHighlightedField(String name, int fragmentSize) {
+            highlightBuilder().field(name, fragmentSize);
+            return this;
+        }
+
+        /**
+         * Adds a field to be highlighted with a provided fragment size (in characters), and
+         * a provided (maximum) number of fragments.
+         *
+         * @param name              The field to highlight
+         * @param fragmentSize      The size of a fragment in characters
+         * @param numberOfFragments The (maximum) number of fragments
+         */
+        public InnerHit addHighlightedField(String name, int fragmentSize, int numberOfFragments) {
+            highlightBuilder().field(name, fragmentSize, numberOfFragments);
+            return this;
+        }
+
+        /**
+         * Adds a field to be highlighted with a provided fragment size (in characters),
+         * a provided (maximum) number of fragments and an offset for the highlight.
+         *
+         * @param name              The field to highlight
+         * @param fragmentSize      The size of a fragment in characters
+         * @param numberOfFragments The (maximum) number of fragments
+         */
+        public InnerHit addHighlightedField(String name, int fragmentSize, int numberOfFragments,
+                                            int fragmentOffset) {
+            highlightBuilder().field(name, fragmentSize, numberOfFragments, fragmentOffset);
+            return this;
+        }
+
+        /**
+         * Adds a highlighted field.
+         */
+        public InnerHit addHighlightedField(HighlightBuilder.Field field) {
+            highlightBuilder().field(field);
+            return this;
+        }
+
+        /**
+         * Set a tag scheme that encapsulates a built in pre and post tags. The allows schemes
+         * are <tt>styled</tt> and <tt>default</tt>.
+         *
+         * @param schemaName The tag scheme name
+         */
+        public InnerHit setHighlighterTagsSchema(String schemaName) {
+            highlightBuilder().tagsSchema(schemaName);
+            return this;
+        }
+
+        public InnerHit setHighlighterFragmentSize(Integer fragmentSize) {
+            highlightBuilder().fragmentSize(fragmentSize);
+            return this;
+        }
+
+        public InnerHit setHighlighterNumOfFragments(Integer numOfFragments) {
+            highlightBuilder().numOfFragments(numOfFragments);
+            return this;
+        }
+
+        public InnerHit setHighlighterFilter(Boolean highlightFilter) {
+            highlightBuilder().highlightFilter(highlightFilter);
+            return this;
+        }
+
+        /**
+         * The encoder to set for highlighting
+         */
+        public InnerHit setHighlighterEncoder(String encoder) {
+            highlightBuilder().encoder(encoder);
+            return this;
+        }
+
+        /**
+         * Explicitly set the pre tags that will be used for highlighting.
+         */
+        public InnerHit setHighlighterPreTags(String... preTags) {
+            highlightBuilder().preTags(preTags);
+            return this;
+        }
+
+        /**
+         * Explicitly set the post tags that will be used for highlighting.
+         */
+        public InnerHit setHighlighterPostTags(String... postTags) {
+            highlightBuilder().postTags(postTags);
+            return this;
+        }
+
+        /**
+         * The order of fragments per field. By default, ordered by the order in the
+         * highlighted text. Can be <tt>score</tt>, which then it will be ordered
+         * by score of the fragments.
+         */
+        public InnerHit setHighlighterOrder(String order) {
+            highlightBuilder().order(order);
+            return this;
+        }
+
+        public InnerHit setHighlighterRequireFieldMatch(boolean requireFieldMatch) {
+            highlightBuilder().requireFieldMatch(requireFieldMatch);
+            return this;
+        }
+
+        public InnerHit setHighlighterBoundaryMaxScan(Integer boundaryMaxScan) {
+            highlightBuilder().boundaryMaxScan(boundaryMaxScan);
+            return this;
+        }
+
+        public InnerHit setHighlighterBoundaryChars(char[] boundaryChars) {
+            highlightBuilder().boundaryChars(boundaryChars);
+            return this;
+        }
+
+        /**
+         * The highlighter type to use.
+         */
+        public InnerHit setHighlighterType(String type) {
+            highlightBuilder().highlighterType(type);
+            return this;
+        }
+
+        public InnerHit setHighlighterFragmenter(String fragmenter) {
+            highlightBuilder().fragmenter(fragmenter);
+            return this;
+        }
+
+        /**
+         * Sets a query to be used for highlighting all fields instead of the search query.
+         */
+        public InnerHit setHighlighterQuery(QueryBuilder highlightQuery) {
+            highlightBuilder().highlightQuery(highlightQuery);
+            return this;
+        }
+
+        /**
+         * Sets the size of the fragment to return from the beginning of the field if there are no matches to
+         * highlight and the field doesn't also define noMatchSize.
+         *
+         * @param noMatchSize integer to set or null to leave out of request.  default is null.
+         * @return this builder for chaining
+         */
+        public InnerHit setHighlighterNoMatchSize(Integer noMatchSize) {
+            highlightBuilder().noMatchSize(noMatchSize);
+            return this;
+        }
+
+        /**
+         * Sets the maximum number of phrases the fvh will consider if the field doesn't also define phraseLimit.
+         */
+        public InnerHit setHighlighterPhraseLimit(Integer phraseLimit) {
+            highlightBuilder().phraseLimit(phraseLimit);
+            return this;
+        }
+
+        public InnerHit setHighlighterOptions(Map<String, Object> options) {
+            highlightBuilder().options(options);
             return this;
         }
 
@@ -290,8 +460,24 @@ public class InnerHitsBuilder implements ToXContent {
             return this;
         }
 
-        public InnerHit innerHits(InnerHitsBuilder innerHitsBuilder) {
-            sourceBuilder().innerHits(innerHitsBuilder);
+
+
+
+        /**
+         * Adds a nested inner hit definition that collects inner hits for hits
+         * on this inner hit level.
+         */
+        public InnerHit addNestedInnerHits(String name, String path, InnerHit innerHit) {
+            sourceBuilder().innerHitsBuilder().addNestedInnerHits(name, path, innerHit);
+            return this;
+        }
+
+        /**
+         * Adds a nested inner hit definition that collects inner hits for hits
+         * on this inner hit level.
+         */
+        public InnerHit addParentChildInnerHits(String name, String type, InnerHit innerHit) {
+            sourceBuilder().innerHitsBuilder().addParentChildInnerHits(name, type, innerHit);
             return this;
         }
 
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/source/FetchSourceContext.java b/core/src/main/java/org/elasticsearch/search/fetch/source/FetchSourceContext.java
index ae0a71d..9db7aea 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/source/FetchSourceContext.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/source/FetchSourceContext.java
@@ -19,30 +19,20 @@
 
 package org.elasticsearch.search.fetch.source;
 
+import org.elasticsearch.Version;
 import org.elasticsearch.common.Booleans;
-import org.elasticsearch.common.ParseField;
-import org.elasticsearch.common.ParsingException;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.io.stream.Streamable;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.rest.RestRequest;
 
 import java.io.IOException;
-import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.List;
 
 /**
  */
-public class FetchSourceContext implements Streamable, ToXContent {
-
-    public static final ParseField INCLUDES_FIELD = new ParseField("includes", "include");
-    public static final ParseField EXCLUDES_FIELD = new ParseField("excludes", "exclude");
+public class FetchSourceContext implements Streamable {
 
     public static final FetchSourceContext FETCH_SOURCE = new FetchSourceContext(true);
     public static final FetchSourceContext DO_NOT_FETCH_SOURCE = new FetchSourceContext(false);
@@ -51,11 +41,6 @@ public class FetchSourceContext implements Streamable, ToXContent {
     private String[] includes;
     private String[] excludes;
 
-    public static FetchSourceContext parse(XContentParser parser, QueryParseContext context) throws IOException {
-        FetchSourceContext fetchSourceContext = new FetchSourceContext();
-        fetchSourceContext.fromXContent(parser, context);
-        return fetchSourceContext;
-    }
 
     FetchSourceContext() {
 
@@ -187,86 +172,6 @@ public class FetchSourceContext implements Streamable, ToXContent {
         return null;
     }
 
-    public void fromXContent(XContentParser parser, QueryParseContext context) throws IOException {
-        XContentParser.Token token = parser.currentToken();
-        boolean fetchSource = true;
-        String[] includes = Strings.EMPTY_ARRAY;
-        String[] excludes = Strings.EMPTY_ARRAY;
-        if (token == XContentParser.Token.VALUE_BOOLEAN) {
-            fetchSource = parser.booleanValue();
-        } else if (token == XContentParser.Token.VALUE_STRING) {
-            includes = new String[]{parser.text()};
-        } else if (token == XContentParser.Token.START_ARRAY) {
-            ArrayList<String> list = new ArrayList<>();
-            while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                list.add(parser.text());
-            }
-            includes = list.toArray(new String[list.size()]);
-        } else if (token == XContentParser.Token.START_OBJECT) {
-            String currentFieldName = null;
-            while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
-                if (token == XContentParser.Token.FIELD_NAME) {
-                    currentFieldName = parser.currentName();
-                } else if (token == XContentParser.Token.START_ARRAY) {
-                    if (context.parseFieldMatcher().match(currentFieldName, INCLUDES_FIELD)) {
-                        List<String> includesList = new ArrayList<>();
-                        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                            if (token == XContentParser.Token.VALUE_STRING) {
-                                includesList.add(parser.text());
-                            } else {
-                                throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName + "].",
-                                        parser.getTokenLocation());
-                            }
-                        }
-                        includes = includesList.toArray(new String[includesList.size()]);
-                    } else if (context.parseFieldMatcher().match(currentFieldName, EXCLUDES_FIELD)) {
-                        List<String> excludesList = new ArrayList<>();
-                        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
-                            if (token == XContentParser.Token.VALUE_STRING) {
-                                excludesList.add(parser.text());
-                            } else {
-                                throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName + "].",
-                                        parser.getTokenLocation());
-                            }
-                        }
-                        excludes = excludesList.toArray(new String[excludesList.size()]);
-                    } else {
-                        throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName + "].",
-                                parser.getTokenLocation());
-                    }
-                } else if (token == XContentParser.Token.VALUE_STRING) {
-                    if (context.parseFieldMatcher().match(currentFieldName, INCLUDES_FIELD)) {
-                        includes = new String[] {parser.text()};
-                    } else if (context.parseFieldMatcher().match(currentFieldName, EXCLUDES_FIELD)) {
-                        excludes = new String[] {parser.text()};
-                    }
-                } else {
-                    throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token + " in [" + currentFieldName + "].",
-                            parser.getTokenLocation());
-                }
-            }
-        } else {
-            throw new ParsingException(parser.getTokenLocation(), "Expected one of [" + XContentParser.Token.VALUE_BOOLEAN + ", "
-                    + XContentParser.Token.START_OBJECT + "] but found [" + token + "]", parser.getTokenLocation());
-        }
-        this.fetchSource = fetchSource;
-        this.includes = includes;
-        this.excludes = excludes;
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        if (fetchSource) {
-            builder.startObject();
-            builder.array(INCLUDES_FIELD.getPreferredName(), includes);
-            builder.array(EXCLUDES_FIELD.getPreferredName(), excludes);
-            builder.endObject();
-        } else {
-            builder.value(false);
-        }
-        return builder;
-    }
-
     @Override
     public void readFrom(StreamInput in) throws IOException {
         fetchSource = in.readBoolean();
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java b/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java
index 7f1e19b..695598e 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java
@@ -227,9 +227,9 @@ public class HighlightBuilder implements ToXContent {
     }
 
     /**
-     * Set to true to cause a field to be highlighted only if a query matches that field.
-     * Default is false meaning that terms are highlighted on all requested fields regardless
-     * if the query matches specifically on them.
+     * Set to true to cause a field to be highlighted only if a query matches that field. 
+     * Default is false meaning that terms are highlighted on all requested fields regardless 
+     * if the query matches specifically on them. 
      */
     public HighlightBuilder requireFieldMatch(boolean requireFieldMatch) {
         this.requireFieldMatch = requireFieldMatch;
@@ -237,7 +237,7 @@ public class HighlightBuilder implements ToXContent {
     }
 
     /**
-     * When using the highlighterType <tt>fast-vector-highlighter</tt> this setting
+     * When using the highlighterType <tt>fast-vector-highlighter</tt> this setting 
      * controls how far to look for boundary characters, and defaults to 20.
      */
     public HighlightBuilder boundaryMaxScan(Integer boundaryMaxScan) {
@@ -246,8 +246,8 @@ public class HighlightBuilder implements ToXContent {
     }
 
     /**
-     * When using the highlighterType <tt>fast-vector-highlighter</tt> this setting
-     * defines what constitutes a boundary for highlighting. It’s a single string with
+     * When using the highlighterType <tt>fast-vector-highlighter</tt> this setting 
+     * defines what constitutes a boundary for highlighting. It’s a single string with 
      * each boundary character defined in it. It defaults to .,!? \t\n
      */
     public HighlightBuilder boundaryChars(char[] boundaryChars) {
@@ -258,7 +258,7 @@ public class HighlightBuilder implements ToXContent {
     /**
      * Set type of highlighter to use. Supported types
      * are <tt>highlighter</tt>, <tt>fast-vector-highlighter</tt> and <tt>postings-highlighter</tt>.
-     * The default option selected is dependent on the mappings defined for your index.
+     * The default option selected is dependent on the mappings defined for your index. 
      * Details of the different highlighter types are covered in the reference guide.
      */
     public HighlightBuilder highlighterType(String highlighterType) {
@@ -334,13 +334,6 @@ public class HighlightBuilder implements ToXContent {
     @Override
     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject("highlight");
-        innerXContent(builder, params);
-        builder.endObject();
-        return builder;
-    }
-
-
-    public void innerXContent(XContentBuilder builder, Params params) throws IOException {
         if (tagsSchema != null) {
             builder.field("tags_schema", tagsSchema);
         }
@@ -472,6 +465,8 @@ public class HighlightBuilder implements ToXContent {
                 builder.endObject();
             }
         }
+        builder.endObject();
+        return builder;
     }
 
     public static class Field {
diff --git a/core/src/main/java/org/elasticsearch/search/internal/ShardSearchLocalRequest.java b/core/src/main/java/org/elasticsearch/search/internal/ShardSearchLocalRequest.java
index 677f392..ca8c074 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/ShardSearchLocalRequest.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/ShardSearchLocalRequest.java
@@ -31,7 +31,6 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.script.Template;
 import org.elasticsearch.search.Scroll;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 
 import java.io.IOException;
 
@@ -66,7 +65,9 @@ public class ShardSearchLocalRequest extends ContextAndHeaderHolder implements S
     private Scroll scroll;
     private String[] types = Strings.EMPTY_ARRAY;
     private String[] filteringAliases;
-    private SearchSourceBuilder source;
+    private BytesReference source;
+    private BytesReference extraSource;
+    private BytesReference templateSource;
     private Template template;
     private Boolean requestCache;
     private long nowInMillis;
@@ -78,6 +79,8 @@ public class ShardSearchLocalRequest extends ContextAndHeaderHolder implements S
                             String[] filteringAliases, long nowInMillis) {
         this(shardRouting.shardId(), numberOfShards, searchRequest.searchType(),
                 searchRequest.source(), searchRequest.types(), searchRequest.requestCache());
+        this.extraSource = searchRequest.extraSource();
+        this.templateSource = searchRequest.templateSource();
         this.template = searchRequest.template();
         this.scroll = searchRequest.scroll();
         this.filteringAliases = filteringAliases;
@@ -95,8 +98,8 @@ public class ShardSearchLocalRequest extends ContextAndHeaderHolder implements S
         this.filteringAliases = filteringAliases;
     }
 
-    public ShardSearchLocalRequest(ShardId shardId, int numberOfShards, SearchType searchType, SearchSourceBuilder source, String[] types,
-            Boolean requestCache) {
+    public ShardSearchLocalRequest(ShardId shardId, int numberOfShards, SearchType searchType,
+                                   BytesReference source, String[] types, Boolean requestCache) {
         this.index = shardId.getIndex();
         this.shardId = shardId.id();
         this.numberOfShards = numberOfShards;
@@ -122,16 +125,21 @@ public class ShardSearchLocalRequest extends ContextAndHeaderHolder implements S
     }
 
     @Override
-    public SearchSourceBuilder source() {
+    public BytesReference source() {
         return source;
     }
 
     @Override
-    public void source(SearchSourceBuilder source) {
+    public void source(BytesReference source) {
         this.source = source;
     }
 
     @Override
+    public BytesReference extraSource() {
+        return extraSource;
+    }
+
+    @Override
     public int numberOfShards() {
         return numberOfShards;
     }
@@ -150,12 +158,18 @@ public class ShardSearchLocalRequest extends ContextAndHeaderHolder implements S
     public long nowInMillis() {
         return nowInMillis;
     }
+
     @Override
     public Template template() {
         return template;
     }
 
     @Override
+    public BytesReference templateSource() {
+        return templateSource;
+    }
+
+    @Override
     public Boolean requestCache() {
         return requestCache;
     }
@@ -174,13 +188,18 @@ public class ShardSearchLocalRequest extends ContextAndHeaderHolder implements S
         if (in.readBoolean()) {
             scroll = readScroll(in);
         }
-        if (in.readBoolean()) {
-            source = SearchSourceBuilder.PROTOTYPE.readFrom(in);
-        }
+
+        source = in.readBytesReference();
+        extraSource = in.readBytesReference();
+
         types = in.readStringArray();
         filteringAliases = in.readStringArray();
         nowInMillis = in.readVLong();
-        template = in.readOptionalStreamable(new Template());
+
+        templateSource = in.readBytesReference();
+        if (in.readBoolean()) {
+            template = Template.readTemplate(in);
+        }
         requestCache = in.readOptionalBoolean();
     }
 
@@ -197,20 +216,20 @@ public class ShardSearchLocalRequest extends ContextAndHeaderHolder implements S
             out.writeBoolean(true);
             scroll.writeTo(out);
         }
-        if (source == null) {
-            out.writeBoolean(false);
-        } else {
-            out.writeBoolean(true);
-            source.writeTo(out);
-
-        }
+        out.writeBytesReference(source);
+        out.writeBytesReference(extraSource);
         out.writeStringArray(types);
         out.writeStringArrayNullable(filteringAliases);
         if (!asKey) {
             out.writeVLong(nowInMillis);
         }
 
-        out.writeOptionalStreamable(template);
+        out.writeBytesReference(templateSource);
+        boolean hasTemplate = template != null;
+        out.writeBoolean(hasTemplate);
+        if (hasTemplate) {
+            template.writeTo(out);
+        }
         out.writeOptionalBoolean(requestCache);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/search/internal/ShardSearchRequest.java b/core/src/main/java/org/elasticsearch/search/internal/ShardSearchRequest.java
index fb631b0..6d9734f 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/ShardSearchRequest.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/ShardSearchRequest.java
@@ -20,11 +20,12 @@
 package org.elasticsearch.search.internal;
 
 import org.elasticsearch.action.search.SearchType;
+import org.elasticsearch.common.HasContext;
 import org.elasticsearch.common.HasContextAndHeaders;
+import org.elasticsearch.common.HasHeaders;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.script.Template;
 import org.elasticsearch.search.Scroll;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 
 import java.io.IOException;
 
@@ -41,9 +42,11 @@ public interface ShardSearchRequest extends HasContextAndHeaders {
 
     String[] types();
 
-    SearchSourceBuilder source();
+    BytesReference source();
 
-    void source(SearchSourceBuilder source);
+    void source(BytesReference source);
+
+    BytesReference extraSource();
 
     int numberOfShards();
 
@@ -55,6 +58,8 @@ public interface ShardSearchRequest extends HasContextAndHeaders {
 
     Template template();
 
+    BytesReference templateSource();
+
     Boolean requestCache();
 
     Scroll scroll();
diff --git a/core/src/main/java/org/elasticsearch/search/internal/ShardSearchTransportRequest.java b/core/src/main/java/org/elasticsearch/search/internal/ShardSearchTransportRequest.java
index 279d9d6..e7b1e2f 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/ShardSearchTransportRequest.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/ShardSearchTransportRequest.java
@@ -30,7 +30,6 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.script.Template;
 import org.elasticsearch.search.Scroll;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.transport.TransportRequest;
 
 import java.io.IOException;
@@ -88,16 +87,21 @@ public class ShardSearchTransportRequest extends TransportRequest implements Sha
     }
 
     @Override
-    public SearchSourceBuilder source() {
+    public BytesReference source() {
         return shardSearchLocalRequest.source();
     }
 
     @Override
-    public void source(SearchSourceBuilder source) {
+    public void source(BytesReference source) {
         shardSearchLocalRequest.source(source);
     }
 
     @Override
+    public BytesReference extraSource() {
+        return shardSearchLocalRequest.extraSource();
+    }
+
+    @Override
     public int numberOfShards() {
         return shardSearchLocalRequest.numberOfShards();
     }
@@ -116,12 +120,18 @@ public class ShardSearchTransportRequest extends TransportRequest implements Sha
     public long nowInMillis() {
         return shardSearchLocalRequest.nowInMillis();
     }
+
     @Override
     public Template template() {
         return shardSearchLocalRequest.template();
     }
 
     @Override
+    public BytesReference templateSource() {
+        return shardSearchLocalRequest.templateSource();
+    }
+
+    @Override
     public Boolean requestCache() {
         return shardSearchLocalRequest.requestCache();
     }
diff --git a/core/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java b/core/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java
index 4ff4ed1..6e881cb 100644
--- a/core/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java
+++ b/core/src/main/java/org/elasticsearch/search/warmer/IndexWarmersMetaData.java
@@ -23,6 +23,8 @@ import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.bytes.BytesArray;
+import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.ToXContent;
@@ -30,7 +32,6 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentType;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -66,10 +67,10 @@ public class IndexWarmersMetaData extends AbstractDiffable<IndexMetaData.Custom>
     public static class Entry {
         private final String name;
         private final String[] types;
-        private final SearchSourceBuilder source;
+        private final BytesReference source;
         private final Boolean requestCache;
 
-        public Entry(String name, String[] types, Boolean requestCache, SearchSourceBuilder source) {
+        public Entry(String name, String[] types, Boolean requestCache, BytesReference source) {
             this.name = name;
             this.types = types == null ? Strings.EMPTY_ARRAY : types;
             this.source = source;
@@ -85,7 +86,7 @@ public class IndexWarmersMetaData extends AbstractDiffable<IndexMetaData.Custom>
         }
 
         @Nullable
-        public SearchSourceBuilder source() {
+        public BytesReference source() {
             return this.source;
         }
 
@@ -140,9 +141,9 @@ public class IndexWarmersMetaData extends AbstractDiffable<IndexMetaData.Custom>
         for (int i = 0; i < entries.length; i++) {
             String name = in.readString();
             String[] types = in.readStringArray();
-            SearchSourceBuilder source = null;
+            BytesReference source = null;
             if (in.readBoolean()) {
-                source = SearchSourceBuilder.PROTOTYPE.readFrom(in);
+                source = in.readBytesReference();
             }
             Boolean queryCache;
             queryCache = in.readOptionalBoolean();
@@ -161,7 +162,7 @@ public class IndexWarmersMetaData extends AbstractDiffable<IndexMetaData.Custom>
                 out.writeBoolean(false);
             } else {
                 out.writeBoolean(true);
-                entry.source.writeTo(out);
+                out.writeBytesReference(entry.source());
             }
             out.writeOptionalBoolean(entry.requestCache());
         }
@@ -193,7 +194,7 @@ public class IndexWarmersMetaData extends AbstractDiffable<IndexMetaData.Custom>
             } else if (token == XContentParser.Token.START_OBJECT) {
                 String name = currentFieldName;
                 List<String> types = new ArrayList<>(2);
-                SearchSourceBuilder source = null;
+                BytesReference source = null;
                 Boolean queryCache = null;
                 while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                     if (token == XContentParser.Token.FIELD_NAME) {
@@ -206,12 +207,13 @@ public class IndexWarmersMetaData extends AbstractDiffable<IndexMetaData.Custom>
                         }
                     } else if (token == XContentParser.Token.START_OBJECT) {
                         if ("source".equals(currentFieldName)) {
-                            source = SearchSourceBuilder.PROTOTYPE.fromXContent(parser, null); // NOCOMMIT need context from somewhere
+                            XContentBuilder builder = XContentFactory.jsonBuilder().map(parser.mapOrdered());
+                            source = builder.bytes();
+                        }
+                    } else if (token == XContentParser.Token.VALUE_EMBEDDED_OBJECT) {
+                        if ("source".equals(currentFieldName)) {
+                            source = new BytesArray(parser.binaryValue());
                         }
-//                    } else if (token == XContentParser.Token.VALUE_EMBEDDED_OBJECT) {
-//                        if ("source".equals(currentFieldName)) {
-//                            source = new BytesArray(parser.binaryValue());
-//                        } NORELEASE do we need this?
                     } else if (token.isValue()) {
                         if ("requestCache".equals(currentFieldName) || "request_cache".equals(currentFieldName)) {
                             queryCache = parser.booleanValue();
@@ -237,12 +239,22 @@ public class IndexWarmersMetaData extends AbstractDiffable<IndexMetaData.Custom>
     }
 
     public static void toXContent(Entry entry, XContentBuilder builder, ToXContent.Params params) throws IOException {
+        boolean binary = params.paramAsBoolean("binary", false);
         builder.startObject(entry.name(), XContentBuilder.FieldCaseConversion.NONE);
         builder.field("types", entry.types());
         if (entry.requestCache() != null) {
             builder.field("requestCache", entry.requestCache());
         }
-        builder.field("source", entry.source());
+        builder.field("source");
+        if (binary) {
+            builder.value(entry.source());
+        } else {
+            Map<String, Object> mapping;
+            try (XContentParser parser = XContentFactory.xContent(entry.source()).createParser(entry.source())) {
+                mapping = parser.mapOrdered();
+            }
+            builder.map(mapping);
+        }
         builder.endObject();
     }
 
diff --git a/core/src/main/java/org/elasticsearch/transport/local/LocalTransport.java b/core/src/main/java/org/elasticsearch/transport/local/LocalTransport.java
index 179a5db..a500fb3 100644
--- a/core/src/main/java/org/elasticsearch/transport/local/LocalTransport.java
+++ b/core/src/main/java/org/elasticsearch/transport/local/LocalTransport.java
@@ -37,27 +37,11 @@ import org.elasticsearch.common.transport.TransportAddress;
 import org.elasticsearch.common.util.concurrent.AbstractRunnable;
 import org.elasticsearch.common.util.concurrent.EsExecutors;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.ActionNotFoundTransportException;
-import org.elasticsearch.transport.ConnectTransportException;
-import org.elasticsearch.transport.NodeNotConnectedException;
-import org.elasticsearch.transport.RemoteTransportException;
-import org.elasticsearch.transport.RequestHandlerRegistry;
-import org.elasticsearch.transport.ResponseHandlerFailureTransportException;
-import org.elasticsearch.transport.Transport;
-import org.elasticsearch.transport.TransportException;
-import org.elasticsearch.transport.TransportRequest;
-import org.elasticsearch.transport.TransportRequestOptions;
-import org.elasticsearch.transport.TransportResponse;
-import org.elasticsearch.transport.TransportResponseHandler;
-import org.elasticsearch.transport.TransportSerializationException;
-import org.elasticsearch.transport.TransportServiceAdapter;
-import org.elasticsearch.transport.Transports;
+import org.elasticsearch.transport.*;
 import org.elasticsearch.transport.support.TransportStatus;
 
 import java.io.IOException;
-import java.util.Collections;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.ThreadFactory;
 import java.util.concurrent.ThreadPoolExecutor;
@@ -81,7 +65,7 @@ public class LocalTransport extends AbstractLifecycleComponent<Transport> implem
     private final static ConcurrentMap<LocalTransportAddress, LocalTransport> transports = newConcurrentMap();
     private static final AtomicLong transportAddressIdGenerator = new AtomicLong();
     private final ConcurrentMap<DiscoveryNode, LocalTransport> connectedNodes = newConcurrentMap();
-    protected final NamedWriteableRegistry namedWriteableRegistry;
+    private final NamedWriteableRegistry namedWriteableRegistry;
 
     public static final String TRANSPORT_LOCAL_ADDRESS = "transport.local.address";
     public static final String TRANSPORT_LOCAL_WORKERS = "transport.local.workers";
diff --git a/core/src/test/java/org/elasticsearch/action/count/CountRequestBuilderTests.java b/core/src/test/java/org/elasticsearch/action/count/CountRequestBuilderTests.java
index 4bf5e7f..5d77247 100644
--- a/core/src/test/java/org/elasticsearch/action/count/CountRequestBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/action/count/CountRequestBuilderTests.java
@@ -28,10 +28,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentType;
-import org.elasticsearch.index.query.MatchAllQueryBuilder;
-import org.elasticsearch.index.query.MatchQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.test.ESTestCase;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
@@ -78,14 +75,58 @@ public class CountRequestBuilderTests extends ESTestCase {
     @Test
     public void testStringQueryToString() {
         CountRequestBuilder countRequestBuilder = client.prepareCount();
-        countRequestBuilder.setQuery(new MatchAllQueryBuilder());
-        assertThat(countRequestBuilder.toString(), containsString("match_all"));
+        String query = "{ \"match_all\" : {} }";
+        countRequestBuilder.setQuery(new BytesArray(query));
+        assertThat(countRequestBuilder.toString(), containsString("\"query\":{ \"match_all\" : {} }"));
+    }
+
+    @Test
+    public void testXContentBuilderQueryToString() throws IOException {
+        CountRequestBuilder countRequestBuilder = client.prepareCount();
+        XContentBuilder xContentBuilder = XContentFactory.contentBuilder(randomFrom(XContentType.values()));
+        xContentBuilder.startObject();
+        xContentBuilder.startObject("match_all");
+        xContentBuilder.endObject();
+        xContentBuilder.endObject();
+        countRequestBuilder.setQuery(xContentBuilder);
+        assertThat(countRequestBuilder.toString(), equalTo(new QuerySourceBuilder().setQuery(xContentBuilder.bytes()).toString()));
     }
 
     @Test
     public void testStringSourceToString() {
         CountRequestBuilder countRequestBuilder = client.prepareCount();
-        countRequestBuilder.setSource(new SearchSourceBuilder().query(new MatchAllQueryBuilder()));
-        assertThat(countRequestBuilder.toString(), containsString("match_all"));
+        String query = "{ \"query\": { \"match_all\" : {} } }";
+        countRequestBuilder.setSource(new BytesArray(query));
+        assertThat(countRequestBuilder.toString(), equalTo("{ \"query\": { \"match_all\" : {} } }"));
+    }
+
+    @Test
+    public void testXContentBuilderSourceToString() throws IOException {
+        CountRequestBuilder countRequestBuilder = client.prepareCount();
+        XContentBuilder xContentBuilder = XContentFactory.contentBuilder(randomFrom(XContentType.values()));
+        xContentBuilder.startObject();
+        xContentBuilder.startObject("match_all");
+        xContentBuilder.endObject();
+        xContentBuilder.endObject();
+        countRequestBuilder.setSource(xContentBuilder.bytes());
+        assertThat(countRequestBuilder.toString(), equalTo(XContentHelper.convertToJson(xContentBuilder.bytes(), false, true)));
+    }
+
+    @Test
+    public void testThatToStringDoesntWipeSource() {
+        String source = "{\n" +
+                "            \"query\" : {\n" +
+                "            \"match\" : {\n" +
+                "                \"field\" : {\n" +
+                "                    \"query\" : \"value\"" +
+                "                }\n" +
+                "            }\n" +
+                "        }\n" +
+                "        }";
+        CountRequestBuilder countRequestBuilder = client.prepareCount().setSource(new BytesArray(source));
+        String preToString = countRequestBuilder.request().source().toUtf8();
+        assertThat(countRequestBuilder.toString(), equalTo(source));
+        String postToString = countRequestBuilder.request().source().toUtf8();
+        assertThat(preToString, equalTo(postToString));
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/action/count/CountRequestTests.java b/core/src/test/java/org/elasticsearch/action/count/CountRequestTests.java
index cbf7822..407cfba 100644
--- a/core/src/test/java/org/elasticsearch/action/count/CountRequestTests.java
+++ b/core/src/test/java/org/elasticsearch/action/count/CountRequestTests.java
@@ -21,11 +21,15 @@ package org.elasticsearch.action.count;
 
 import org.elasticsearch.action.search.SearchRequest;
 import org.elasticsearch.action.support.IndicesOptions;
+import org.elasticsearch.action.support.QuerySourceBuilder;
+import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
+import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
+import java.util.Map;
+
 import static org.hamcrest.CoreMatchers.equalTo;
 import static org.hamcrest.CoreMatchers.notNullValue;
 import static org.hamcrest.CoreMatchers.nullValue;
@@ -52,9 +56,8 @@ public class CountRequestTests extends ESTestCase {
         if (randomBoolean()) {
             countRequest.preference(randomAsciiOfLengthBetween(1, 10));
         }
-        final boolean querySet;
-        if (querySet = randomBoolean()) {
-            countRequest.query(QueryBuilders.termQuery("field", "value"));
+        if (randomBoolean()) {
+            countRequest.source(new QuerySourceBuilder().setQuery(QueryBuilders.termQuery("field", "value")));
         }
         if (randomBoolean()) {
             countRequest.minScore(randomFloat());
@@ -69,19 +72,31 @@ public class CountRequestTests extends ESTestCase {
         assertThat(searchRequest.types(), equalTo(countRequest.types()));
         assertThat(searchRequest.routing(), equalTo(countRequest.routing()));
         assertThat(searchRequest.preference(), equalTo(countRequest.preference()));
-        SearchSourceBuilder source = searchRequest.source();
-        assertThat(source.size(), equalTo(0));
-        if (querySet) {
-            assertThat(source.query(), notNullValue());
+
+        if (countRequest.source() == null) {
+            assertThat(searchRequest.source(), nullValue());
         } else {
-            assertNull(source.query());
+            Map<String, Object> sourceMap = XContentHelper.convertToMap(searchRequest.source(), false).v2();
+            assertThat(sourceMap.size(), equalTo(1));
+            assertThat(sourceMap.get("query"), notNullValue());
         }
+
+        Map<String, Object> extraSourceMap = XContentHelper.convertToMap(searchRequest.extraSource(), false).v2();
+        int count = 1;
+        assertThat((Integer)extraSourceMap.get("size"), equalTo(0));
         if (countRequest.minScore() == CountRequest.DEFAULT_MIN_SCORE) {
-            assertThat(source.minScore(), nullValue());
+            assertThat(extraSourceMap.get("min_score"), nullValue());
+        } else {
+            assertThat(((Number)extraSourceMap.get("min_score")).floatValue(), equalTo(countRequest.minScore()));
+            count++;
+        }
+        if (countRequest.terminateAfter() == SearchContext.DEFAULT_TERMINATE_AFTER) {
+            assertThat(extraSourceMap.get("terminate_after"), nullValue());
         } else {
-            assertThat(source.minScore(), equalTo(countRequest.minScore()));
+            assertThat((Integer)extraSourceMap.get("terminate_after"), equalTo(countRequest.terminateAfter()));
+            count++;
         }
-        assertThat(source.terminateAfter(), equalTo(countRequest.terminateAfter()));
+        assertThat(extraSourceMap.size(), equalTo(count));
     }
 
     private static String[] randomStringArray() {
diff --git a/core/src/test/java/org/elasticsearch/action/search/MultiSearchRequestTests.java b/core/src/test/java/org/elasticsearch/action/search/MultiSearchRequestTests.java
index b07ba2f..5fd9bae 100644
--- a/core/src/test/java/org/elasticsearch/action/search/MultiSearchRequestTests.java
+++ b/core/src/test/java/org/elasticsearch/action/search/MultiSearchRequestTests.java
@@ -20,13 +20,6 @@
 package org.elasticsearch.action.search;
 
 import org.elasticsearch.action.support.IndicesOptions;
-import org.elasticsearch.common.bytes.BytesArray;
-import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.query.MatchAllQueryParser;
-import org.elasticsearch.indices.query.IndicesQueriesRegistry;
-import org.elasticsearch.rest.action.search.RestMultiSearchAction;
-import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.test.StreamsUtils;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
@@ -35,7 +28,6 @@ import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.Collections;
 
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.nullValue;
@@ -44,9 +36,8 @@ public class MultiSearchRequestTests extends ESTestCase {
 
     @Test
     public void simpleAdd() throws Exception {
-        IndicesQueriesRegistry registry = new IndicesQueriesRegistry(Settings.EMPTY, Collections.singleton(new MatchAllQueryParser()), new NamedWriteableRegistry());
         byte[] data = StreamsUtils.copyToBytesFromClasspath("/org/elasticsearch/action/search/simple-msearch1.json");
-        MultiSearchRequest request = RestMultiSearchAction.parseRequest(new MultiSearchRequest(), new BytesArray(data), false, null, null, null, null, IndicesOptions.strictExpandOpenAndForbidClosed(),true, registry);
+        MultiSearchRequest request = new MultiSearchRequest().add(data, 0, data.length, false, null, null, null);
         assertThat(request.requests().size(), equalTo(8));
         assertThat(request.requests().get(0).indices()[0], equalTo("test"));
         assertThat(request.requests().get(0).indicesOptions(), equalTo(IndicesOptions.fromOptions(true, true, true, true, IndicesOptions.strictExpandOpenAndForbidClosed())));
@@ -71,9 +62,8 @@ public class MultiSearchRequestTests extends ESTestCase {
 
     @Test
     public void simpleAdd2() throws Exception {
-        IndicesQueriesRegistry registry = new IndicesQueriesRegistry(Settings.EMPTY, Collections.singleton(new MatchAllQueryParser()), new NamedWriteableRegistry());
         byte[] data = StreamsUtils.copyToBytesFromClasspath("/org/elasticsearch/action/search/simple-msearch2.json");
-        MultiSearchRequest request =RestMultiSearchAction.parseRequest(new MultiSearchRequest(), new BytesArray(data), false, null, null, null, null, IndicesOptions.strictExpandOpenAndForbidClosed(), true, registry);
+        MultiSearchRequest request = new MultiSearchRequest().add(data, 0, data.length, false, null, null, null);
         assertThat(request.requests().size(), equalTo(5));
         assertThat(request.requests().get(0).indices()[0], equalTo("test"));
         assertThat(request.requests().get(0).types().length, equalTo(0));
@@ -90,9 +80,8 @@ public class MultiSearchRequestTests extends ESTestCase {
 
     @Test
     public void simpleAdd3() throws Exception {
-        IndicesQueriesRegistry registry = new IndicesQueriesRegistry(Settings.EMPTY, Collections.singleton(new MatchAllQueryParser()), new NamedWriteableRegistry());
         byte[] data = StreamsUtils.copyToBytesFromClasspath("/org/elasticsearch/action/search/simple-msearch3.json");
-        MultiSearchRequest request =RestMultiSearchAction.parseRequest(new MultiSearchRequest(), new BytesArray(data), false, null, null, null, null, IndicesOptions.strictExpandOpenAndForbidClosed(), true, registry);
+        MultiSearchRequest request = new MultiSearchRequest().add(data, 0, data.length, false, null, null, null);
         assertThat(request.requests().size(), equalTo(4));
         assertThat(request.requests().get(0).indices()[0], equalTo("test0"));
         assertThat(request.requests().get(0).indices()[1], equalTo("test1"));
@@ -110,9 +99,8 @@ public class MultiSearchRequestTests extends ESTestCase {
 
     @Test
     public void simpleAdd4() throws Exception {
-        IndicesQueriesRegistry registry = new IndicesQueriesRegistry(Settings.EMPTY, Collections.singleton(new MatchAllQueryParser()), new NamedWriteableRegistry());
         byte[] data = StreamsUtils.copyToBytesFromClasspath("/org/elasticsearch/action/search/simple-msearch4.json");
-        MultiSearchRequest request = RestMultiSearchAction.parseRequest(new MultiSearchRequest(), new BytesArray(data), false, null, null, null, null, IndicesOptions.strictExpandOpenAndForbidClosed(), true, registry);
+        MultiSearchRequest request = new MultiSearchRequest().add(data, 0, data.length, false, null, null, null);
         assertThat(request.requests().size(), equalTo(3));
         assertThat(request.requests().get(0).indices()[0], equalTo("test0"));
         assertThat(request.requests().get(0).indices()[1], equalTo("test1"));
@@ -132,9 +120,8 @@ public class MultiSearchRequestTests extends ESTestCase {
 
     @Test
     public void simpleAdd5() throws Exception {
-        IndicesQueriesRegistry registry = new IndicesQueriesRegistry(Settings.EMPTY, Collections.singleton(new MatchAllQueryParser()), new NamedWriteableRegistry());
         byte[] data = StreamsUtils.copyToBytesFromClasspath("/org/elasticsearch/action/search/simple-msearch5.json");
-        MultiSearchRequest request = RestMultiSearchAction.parseRequest(new MultiSearchRequest(), new BytesArray(data), true, null, null, null, null, IndicesOptions.strictExpandOpenAndForbidClosed(), true, registry);
+        MultiSearchRequest request = new MultiSearchRequest().add(data, 0, data.length, true, null, null, null);
         assertThat(request.requests().size(), equalTo(3));
         assertThat(request.requests().get(0).indices()[0], equalTo("test0"));
         assertThat(request.requests().get(0).indices()[1], equalTo("test1"));
@@ -150,18 +137,6 @@ public class MultiSearchRequestTests extends ESTestCase {
         assertThat(request.requests().get(2).types()[0], equalTo("type2"));
         assertThat(request.requests().get(2).types()[1], equalTo("type1"));
         assertThat(request.requests().get(2).routing(), equalTo("123"));
-        assertNotNull(request.requests().get(0).template());
-        assertNotNull(request.requests().get(1).template());
-        assertNotNull(request.requests().get(2).template());
-        assertEquals(ScriptService.ScriptType.INLINE, request.requests().get(0).template().getType());
-        assertEquals(ScriptService.ScriptType.INLINE, request.requests().get(1).template().getType());
-        assertEquals(ScriptService.ScriptType.INLINE, request.requests().get(2).template().getType());
-        assertEquals("{\"query\":{\"match_{{template}}\":{}}}", request.requests().get(0).template().getScript());
-        assertEquals("{\"query\":{\"match_{{template}}\":{}}}", request.requests().get(1).template().getScript());
-        assertEquals("{\"query\":{\"match_{{template}}\":{}}}", request.requests().get(2).template().getScript());
-        assertEquals(1, request.requests().get(0).template().getParams().size());
-        assertEquals(1, request.requests().get(1).template().getParams().size());
-        assertEquals(1, request.requests().get(2).template().getParams().size());
     }
 
     public void testResponseErrorToXContent() throws IOException {
diff --git a/core/src/test/java/org/elasticsearch/action/search/SearchRequestBuilderTests.java b/core/src/test/java/org/elasticsearch/action/search/SearchRequestBuilderTests.java
index cf9008c..1a05794 100644
--- a/core/src/test/java/org/elasticsearch/action/search/SearchRequestBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/action/search/SearchRequestBuilderTests.java
@@ -19,12 +19,13 @@
 
 package org.elasticsearch.action.search;
 
-import org.apache.lucene.util.LuceneTestCase.AwaitsFix;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.client.transport.TransportClient;
+import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentType;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.search.builder.SearchSourceBuilder;
@@ -35,9 +36,9 @@ import org.junit.Test;
 
 import java.io.IOException;
 
+import static org.hamcrest.CoreMatchers.containsString;
 import static org.hamcrest.CoreMatchers.equalTo;
 
-@AwaitsFix(bugUrl = "fix NOCOMMITs in code below")
 public class SearchRequestBuilderTests extends ESTestCase {
 
     private static Client client;
@@ -72,12 +73,31 @@ public class SearchRequestBuilderTests extends ESTestCase {
     }
 
     @Test
+    public void testXContentBuilderQueryToString() throws IOException {
+        SearchRequestBuilder searchRequestBuilder = client.prepareSearch();
+        XContentBuilder xContentBuilder = XContentFactory.contentBuilder(randomFrom(XContentType.values()));
+        xContentBuilder.startObject();
+        xContentBuilder.startObject("match_all");
+        xContentBuilder.endObject();
+        xContentBuilder.endObject();
+        searchRequestBuilder.setQuery(xContentBuilder);
+        assertThat(searchRequestBuilder.toString(), equalTo(new SearchSourceBuilder().query(xContentBuilder).toString()));
+    }
+
+    @Test
+    public void testStringQueryToString() {
+        SearchRequestBuilder searchRequestBuilder = client.prepareSearch();
+        String query = "{ \"match_all\" : {} }";
+        searchRequestBuilder.setQuery(query);
+        assertThat(searchRequestBuilder.toString(), containsString("\"query\":{ \"match_all\" : {} }"));
+    }
+
+    @Test
     public void testStringSourceToString() {
         SearchRequestBuilder searchRequestBuilder = client.prepareSearch();
         String source = "{ \"query\" : { \"match_all\" : {} } }";
-        // searchRequestBuilder.setSource(new BytesArray(source));
-        // assertThat(searchRequestBuilder.toString(), equalTo(source));
-        // NOCOMMIT fix this
+        searchRequestBuilder.setSource(new BytesArray(source));
+        assertThat(searchRequestBuilder.toString(), equalTo(source));
     }
 
     @Test
@@ -90,11 +110,8 @@ public class SearchRequestBuilderTests extends ESTestCase {
         xContentBuilder.endObject();
         xContentBuilder.endObject();
         xContentBuilder.endObject();
-        // searchRequestBuilder.setSource(xContentBuilder.bytes()); NOCOMMIT fix
-        // this
-        // assertThat(searchRequestBuilder.toString(),
-        // equalTo(XContentHelper.convertToJson(xContentBuilder.bytes(), false,
-        // true)));
+        searchRequestBuilder.setSource(xContentBuilder.bytes());
+        assertThat(searchRequestBuilder.toString(), equalTo(XContentHelper.convertToJson(xContentBuilder.bytes(), false, true)));
     }
 
     @Test
@@ -108,13 +125,10 @@ public class SearchRequestBuilderTests extends ESTestCase {
                 "            }\n" +
                 "        }\n" +
                 "        }";
-        // SearchRequestBuilder searchRequestBuilder =
-        // client.prepareSearch().setSource(new BytesArray(source));
-        // String preToString =
-        // searchRequestBuilder.request().source().toUtf8();
-        // assertThat(searchRequestBuilder.toString(), equalTo(source));
-        // String postToString =
-        // searchRequestBuilder.request().source().toUtf8();
-        // assertThat(preToString, equalTo(postToString)); NOCOMMIT FIX THIS
+        SearchRequestBuilder searchRequestBuilder = client.prepareSearch().setSource(new BytesArray(source));
+        String preToString = searchRequestBuilder.request().source().toUtf8();
+        assertThat(searchRequestBuilder.toString(), equalTo(source));
+        String postToString = searchRequestBuilder.request().source().toUtf8();
+        assertThat(preToString, equalTo(postToString));
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/benchmark/search/SuggestSearchBenchMark.java b/core/src/test/java/org/elasticsearch/benchmark/search/SuggestSearchBenchMark.java
index 89e176f..213a522 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/search/SuggestSearchBenchMark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/search/SuggestSearchBenchMark.java
@@ -32,7 +32,6 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.node.Node;
 import org.elasticsearch.search.suggest.Suggest.Suggestion.Entry.Option;
-import org.elasticsearch.search.suggest.SuggestBuilder;
 import org.elasticsearch.search.suggest.SuggestBuilders;
 
 import java.io.IOException;
@@ -42,9 +41,7 @@ import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
-import static org.elasticsearch.index.query.QueryBuilders.prefixQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.elasticsearch.node.NodeBuilder.nodeBuilder;
 
 /**
@@ -121,9 +118,7 @@ public class SuggestSearchBenchMark {
             String term = "prefix" + startChar;
             SearchResponse response = client.prepareSearch()
                     .setQuery(prefixQuery("field", term))
-                    .suggest(
-                            new SuggestBuilder().addSuggestion(SuggestBuilders.termSuggestion("field").field("field").text(term)
-                                    .suggestMode("always")))
+                    .addSuggestion(SuggestBuilders.termSuggestion("field").field("field").text(term).suggestMode("always"))
                     .execute().actionGet();
             if (response.getHits().totalHits() == 0) {
                 System.err.println("No hits");
@@ -140,9 +135,7 @@ public class SuggestSearchBenchMark {
             String term = "prefix" + startChar;
             SearchResponse response = client.prepareSearch()
                     .setQuery(matchQuery("field", term))
-                    .suggest(
-                            new SuggestBuilder().addSuggestion(SuggestBuilders.termSuggestion("field").text(term).field("field")
-                                    .suggestMode("always")))
+                    .addSuggestion(SuggestBuilders.termSuggestion("field").text(term).field("field").suggestMode("always"))
                     .execute().actionGet();
             timeTaken += response.getTookInMillis();
             if (response.getSuggest() == null) {
diff --git a/core/src/test/java/org/elasticsearch/broadcast/BroadcastActionsIT.java b/core/src/test/java/org/elasticsearch/broadcast/BroadcastActionsIT.java
index 78ca44b..e2da702 100644
--- a/core/src/test/java/org/elasticsearch/broadcast/BroadcastActionsIT.java
+++ b/core/src/test/java/org/elasticsearch/broadcast/BroadcastActionsIT.java
@@ -68,6 +68,15 @@ public class BroadcastActionsIT extends ESIntegTestCase {
             assertThat(countResponse.getSuccessfulShards(), equalTo(numShards.numPrimaries));
             assertThat(countResponse.getFailedShards(), equalTo(0));
         }
+
+        for (int i = 0; i < 5; i++) {
+            // test failed (simply query that can't be parsed)
+            try {
+                client().count(countRequest("test").source("{ term : { _type : \"type1 } }".getBytes(StandardCharsets.UTF_8))).actionGet();
+            } catch(SearchPhaseExecutionException e) {
+                assertThat(e.shardFailures().length, equalTo(numShards.numPrimaries));
+            }
+        }
     }
 
     private XContentBuilder source(String id, String nameValue) throws IOException {
diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java b/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java
index 66001f6..1aa1602 100644
--- a/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java
@@ -21,7 +21,6 @@ package org.elasticsearch.cluster;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.google.common.collect.ImmutableMap;
-
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.block.ClusterBlock;
 import org.elasticsearch.cluster.block.ClusterBlocks;
@@ -40,7 +39,6 @@ import org.elasticsearch.discovery.DiscoverySettings;
 import org.elasticsearch.gateway.GatewayService;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.search.warmer.IndexWarmersMetaData;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
@@ -533,7 +531,7 @@ public class ClusterStateDiffIT extends ESIntegTestCase {
                             randomName("warm"),
                             new String[]{randomName("type")},
                             randomBoolean(),
-                            new SearchSourceBuilder()) // NOCOMMIT this used to be new BytesArray(randomAsciiOfLength(1000)) whiat should it be now?
+                            new BytesArray(randomAsciiOfLength(1000)))
             );
         } else {
             return new IndexWarmersMetaData();
diff --git a/core/src/test/java/org/elasticsearch/document/DocumentActionsIT.java b/core/src/test/java/org/elasticsearch/document/DocumentActionsIT.java
index 7cc315c..dc64ffd 100644
--- a/core/src/test/java/org/elasticsearch/document/DocumentActionsIT.java
+++ b/core/src/test/java/org/elasticsearch/document/DocumentActionsIT.java
@@ -32,8 +32,6 @@ import org.elasticsearch.action.index.IndexResponse;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.search.MultiMatchQuery;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
@@ -165,6 +163,13 @@ public class DocumentActionsIT extends ESIntegTestCase {
             assertThat(countResponse.getSuccessfulShards(), equalTo(numShards.numPrimaries));
             assertThat(countResponse.getFailedShards(), equalTo(0));
 
+            // test failed (simply query that can't be parsed)
+            try {
+                client().count(countRequest("test").source("{ term : { _type : \"type1 } }")).actionGet();
+            } catch(SearchPhaseExecutionException e) {
+                assertThat(e.shardFailures().length, equalTo(numShards.numPrimaries));
+            }
+
             // count with no query is a match all one
             countResponse = client().prepareCount("test").execute().actionGet();
             assertThat("Failures " + countResponse.getShardFailures(), countResponse.getShardFailures() == null ? 0 : countResponse.getShardFailures().length, equalTo(0));
diff --git a/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java b/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java
index 174be8f..ca94b21 100644
--- a/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java
+++ b/core/src/test/java/org/elasticsearch/index/query/AbstractQueryTestCase.java
@@ -34,6 +34,7 @@ import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.common.ParseFieldMatcher;
+import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.compress.CompressedXContent;
 import org.elasticsearch.common.inject.AbstractModule;
@@ -60,6 +61,7 @@ import org.elasticsearch.index.analysis.AnalysisModule;
 import org.elasticsearch.index.cache.IndexCacheModule;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
+import org.elasticsearch.index.query.functionscore.ScoreFunctionParserMapper;
 import org.elasticsearch.index.query.support.QueryParsers;
 import org.elasticsearch.index.settings.IndexSettingsModule;
 import org.elasticsearch.index.similarity.SimilarityModule;
@@ -175,6 +177,7 @@ public abstract class AbstractQueryTestCase<QB extends AbstractQueryBuilder<QB>>
                     protected void configure() {
                         bind(Client.class).toInstance(proxy);
                         Multibinder.newSetBinder(binder(), ScoreFunctionParser.class);
+                        bind(ScoreFunctionParserMapper.class).asEagerSingleton();
                         bind(ClusterService.class).toProvider(Providers.of(clusterService));
                         bind(CircuitBreakerService.class).to(NoneCircuitBreakerService.class);
                         bind(NamedWriteableRegistry.class).asEagerSingleton();
@@ -281,23 +284,32 @@ public abstract class AbstractQueryTestCase<QB extends AbstractQueryBuilder<QB>>
     /**
      * Parses the query provided as string argument and compares it with the expected result provided as argument as a {@link QueryBuilder}
      */
-    protected void assertParsedQuery(String queryAsString, QueryBuilder<?> expectedQuery) throws IOException {
+    protected final void assertParsedQuery(String queryAsString, QueryBuilder<?> expectedQuery) throws IOException {
         assertParsedQuery(queryAsString, expectedQuery, ParseFieldMatcher.STRICT);
     }
 
-    protected void assertParsedQuery(String queryAsString, QueryBuilder<?> expectedQuery, ParseFieldMatcher matcher) throws IOException {
+    protected final void assertParsedQuery(String queryAsString, QueryBuilder<?> expectedQuery, ParseFieldMatcher matcher) throws IOException {
         QueryBuilder<?> newQuery = parseQuery(queryAsString, matcher);
         assertNotSame(newQuery, expectedQuery);
         assertEquals(expectedQuery, newQuery);
         assertEquals(expectedQuery.hashCode(), newQuery.hashCode());
     }
 
-    protected QueryBuilder<?> parseQuery(String queryAsString) throws IOException {
+    protected final QueryBuilder<?> parseQuery(String queryAsString) throws IOException {
         return parseQuery(queryAsString, ParseFieldMatcher.STRICT);
     }
 
-    protected QueryBuilder<?> parseQuery(String queryAsString, ParseFieldMatcher matcher) throws IOException {
+    protected final QueryBuilder<?> parseQuery(String queryAsString, ParseFieldMatcher matcher) throws IOException {
         XContentParser parser = XContentFactory.xContent(queryAsString).createParser(queryAsString);
+        return parseQuery(parser, matcher);
+    }
+
+    protected final QueryBuilder<?> parseQuery(BytesReference query) throws IOException {
+        XContentParser parser = XContentFactory.xContent(query).createParser(query);
+        return parseQuery(parser, ParseFieldMatcher.STRICT);
+    }
+
+    protected final QueryBuilder<?> parseQuery(XContentParser parser, ParseFieldMatcher matcher) throws IOException {
         QueryParseContext context = createParseContext();
         context.reset(parser);
         context.parseFieldMatcher(matcher);
@@ -461,8 +473,7 @@ public abstract class AbstractQueryTestCase<QB extends AbstractQueryBuilder<QB>>
     protected static QueryShardContext createShardContext() {
         QueryShardContext queryCreationContext = new QueryShardContext(index, queryParserService);
         queryCreationContext.reset();
-        queryCreationContext.parseFieldMatcher(ParseFieldMatcher.EMPTY);
-
+        queryCreationContext.parseFieldMatcher(ParseFieldMatcher.STRICT);
         return queryCreationContext;
     }
 
diff --git a/core/src/test/java/org/elasticsearch/index/query/CombineFunctionTests.java b/core/src/test/java/org/elasticsearch/index/query/CombineFunctionTests.java
new file mode 100644
index 0000000..94d0609
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/query/CombineFunctionTests.java
@@ -0,0 +1,130 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query;
+
+import org.elasticsearch.common.io.stream.BytesStreamOutput;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.lucene.search.function.CombineFunction;
+import org.elasticsearch.test.ESTestCase;
+
+import static org.hamcrest.Matchers.equalTo;
+
+public class CombineFunctionTests extends ESTestCase {
+
+    public void testValidOrdinals() {
+        assertThat(CombineFunction.MULTIPLY.ordinal(), equalTo(0));
+        assertThat(CombineFunction.REPLACE.ordinal(), equalTo(1));
+        assertThat(CombineFunction.SUM.ordinal(), equalTo(2));
+        assertThat(CombineFunction.AVG.ordinal(), equalTo(3));
+        assertThat(CombineFunction.MIN.ordinal(), equalTo(4));
+        assertThat(CombineFunction.MAX.ordinal(), equalTo(5));
+    }
+
+    public void testWriteTo() throws Exception {
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            CombineFunction.MULTIPLY.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(0));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            CombineFunction.REPLACE.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(1));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            CombineFunction.SUM.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(2));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            CombineFunction.AVG.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(3));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            CombineFunction.MIN.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(4));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            CombineFunction.MAX.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(5));
+            }
+        }
+    }
+
+    public void testReadFrom() throws Exception {
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(0);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(CombineFunction.readCombineFunctionFrom(in), equalTo(CombineFunction.MULTIPLY));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(1);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(CombineFunction.readCombineFunctionFrom(in), equalTo(CombineFunction.REPLACE));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(2);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(CombineFunction.readCombineFunctionFrom(in), equalTo(CombineFunction.SUM));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(3);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(CombineFunction.readCombineFunctionFrom(in), equalTo(CombineFunction.AVG));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(4);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(CombineFunction.readCombineFunctionFrom(in), equalTo(CombineFunction.MIN));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(5);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(CombineFunction.readCombineFunctionFrom(in), equalTo(CombineFunction.MAX));
+            }
+        }
+    }
+
+    public void testFromString() {
+        assertThat(CombineFunction.fromString("multiply"), equalTo(CombineFunction.MULTIPLY));
+        assertThat(CombineFunction.fromString("replace"), equalTo(CombineFunction.REPLACE));
+        assertThat(CombineFunction.fromString("sum"), equalTo(CombineFunction.SUM));
+        assertThat(CombineFunction.fromString("avg"), equalTo(CombineFunction.AVG));
+        assertThat(CombineFunction.fromString("min"), equalTo(CombineFunction.MIN));
+        assertThat(CombineFunction.fromString("max"), equalTo(CombineFunction.MAX));
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java
index 7f3763c..66ba602 100644
--- a/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java
@@ -135,6 +135,7 @@ public class GeoShapeQueryBuilderTests extends AbstractQueryTestCase<GeoShapeQue
      */
     @Override
     public void testToQuery() throws IOException {
+        //TODO figure out why this test might take up to 10 seconds once in a while
         assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
         super.testToQuery();
     }
diff --git a/core/src/test/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilderTests.java
index 6eb53ac..2b9c4d5 100644
--- a/core/src/test/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/MoreLikeThisQueryBuilderTests.java
@@ -26,9 +26,12 @@ import org.apache.lucene.index.memory.MemoryIndex;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.action.termvectors.*;
+import org.elasticsearch.action.termvectors.MultiTermVectorsItemResponse;
+import org.elasticsearch.action.termvectors.MultiTermVectorsRequest;
+import org.elasticsearch.action.termvectors.MultiTermVectorsResponse;
+import org.elasticsearch.action.termvectors.TermVectorsRequest;
+import org.elasticsearch.action.termvectors.TermVectorsResponse;
 import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.lucene.search.MoreLikeThisQuery;
@@ -49,8 +52,6 @@ import java.util.HashMap;
 import java.util.Map;
 import java.util.stream.Stream;
 
-import static org.hamcrest.Matchers.is;
-
 public class MoreLikeThisQueryBuilderTests extends AbstractQueryTestCase<MoreLikeThisQueryBuilder> {
 
     private static String[] randomFields;
@@ -133,17 +134,20 @@ public class MoreLikeThisQueryBuilderTests extends AbstractQueryTestCase<MoreLik
     @Override
     protected MoreLikeThisQueryBuilder doCreateTestQueryBuilder() {
         MoreLikeThisQueryBuilder queryBuilder;
-        if (randomBoolean()) { // for the default field
-            queryBuilder = new MoreLikeThisQueryBuilder();
-        } else {
-            queryBuilder = new MoreLikeThisQueryBuilder(randomFields);
-        }
+        String[] likeTexts = null;
+        Item[] likeItems = null;
         // like field is required
         if (randomBoolean()) {
-            queryBuilder.like(generateRandomStringArray(5, 5, false, false));
+            likeTexts = generateRandomStringArray(5, 5, false, false);
+        } else {
+            likeItems = randomLikeItems;
+        }
+        if (randomBoolean()) { // for the default field
+            queryBuilder = new MoreLikeThisQueryBuilder(likeTexts, likeItems);
         } else {
-            queryBuilder.like(randomLikeItems);
+            queryBuilder = new MoreLikeThisQueryBuilder(randomFields, likeTexts, likeItems);
         }
+
         if (randomBoolean()) {
             queryBuilder.unlike(generateRandomStringArray(5, 5, false, false));
         }
@@ -228,7 +232,7 @@ public class MoreLikeThisQueryBuilderTests extends AbstractQueryTestCase<MoreLik
 
     @Override
     protected void doAssertLuceneQuery(MoreLikeThisQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
-        if (!queryBuilder.likeItems().isEmpty()) {
+        if (queryBuilder.likeItems() != null && queryBuilder.likeItems().length > 0) {
             assertThat(query, Matchers.instanceOf(BooleanQuery.class));
         } else {
             // we rely on integration tests for a deeper check here
@@ -236,30 +240,23 @@ public class MoreLikeThisQueryBuilderTests extends AbstractQueryTestCase<MoreLik
         }
     }
 
-    @Test
-    public void testValidate() {
-        MoreLikeThisQueryBuilder queryBuilder = new MoreLikeThisQueryBuilder(Strings.EMPTY_ARRAY);
-        assertThat(queryBuilder.validate().validationErrors().size(), is(2));
-
-        queryBuilder = new MoreLikeThisQueryBuilder(Strings.EMPTY_ARRAY).like("some text");
-        assertThat(queryBuilder.validate().validationErrors().size(), is(1));
-
-        queryBuilder = new MoreLikeThisQueryBuilder("field").like(Strings.EMPTY_ARRAY);
-        assertThat(queryBuilder.validate().validationErrors().size(), is(1));
-
-        queryBuilder = new MoreLikeThisQueryBuilder("field").like(Item.EMPTY_ARRAY);
-        assertThat(queryBuilder.validate().validationErrors().size(), is(1));
+    @Test(expected=IllegalArgumentException.class)
+    public void testValidateEmptyFields() {
+        new MoreLikeThisQueryBuilder(new String[0], new String[]{"likeText"}, null);
+    }
 
-        queryBuilder = new MoreLikeThisQueryBuilder("field").like("some text");
-        assertNull(queryBuilder.validate());
+    @Test(expected=IllegalArgumentException.class)
+    public void testValidateEmptyLike() {
+        String[] likeTexts = randomBoolean() ? null : new String[0];
+        Item[] likeItems = randomBoolean() ? null : new Item[0];
+        new MoreLikeThisQueryBuilder(likeTexts, likeItems);
     }
 
     @Test
     public void testUnsupportedFields() throws IOException {
         assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
         String unsupportedField = randomFrom(INT_FIELD_NAME, DOUBLE_FIELD_NAME, DATE_FIELD_NAME);
-        MoreLikeThisQueryBuilder queryBuilder = new MoreLikeThisQueryBuilder(unsupportedField)
-                .like("some text")
+        MoreLikeThisQueryBuilder queryBuilder = new MoreLikeThisQueryBuilder(new String[] {unsupportedField}, new String[]{"some text"}, null)
                 .failOnUnsupportedField(true);
         try {
             queryBuilder.toQuery(createShardContext());
diff --git a/core/src/test/java/org/elasticsearch/index/query/OperatorTests.java b/core/src/test/java/org/elasticsearch/index/query/OperatorTests.java
new file mode 100644
index 0000000..f28688d
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/query/OperatorTests.java
@@ -0,0 +1,86 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query;
+
+import org.apache.lucene.queryparser.classic.QueryParser;
+import org.apache.lucene.search.BooleanClause;
+import org.elasticsearch.common.io.stream.BytesStreamOutput;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.test.ESTestCase;
+
+import static org.hamcrest.Matchers.equalTo;
+
+public class OperatorTests extends ESTestCase {
+
+    public void testValidOrdinals() {
+        assertThat(Operator.OR.ordinal(), equalTo(0));
+        assertThat(Operator.AND.ordinal(), equalTo(1));
+    }
+
+    public void testWriteTo() throws Exception {
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            Operator.OR.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(0));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            Operator.AND.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(1));
+            }
+        }
+    }
+
+    public void testReadFrom() throws Exception {
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(0);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(Operator.readOperatorFrom(in), equalTo(Operator.OR));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(1);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(Operator.readOperatorFrom(in), equalTo(Operator.AND));
+            }
+        }
+    }
+
+    public void testToBooleanClauseOccur() {
+        assertThat(Operator.AND.toBooleanClauseOccur(), equalTo(BooleanClause.Occur.MUST));
+        assertThat(Operator.OR.toBooleanClauseOccur(), equalTo(BooleanClause.Occur.SHOULD));
+    }
+
+    public void testToQueryParserOperator() {
+        assertThat(Operator.AND.toQueryParserOperator(), equalTo(QueryParser.Operator.AND));
+        assertThat(Operator.OR.toQueryParserOperator(), equalTo(QueryParser.Operator.OR));
+    }
+
+    public void testFromString() {
+        assertThat(Operator.fromString("and"), equalTo(Operator.AND));
+        assertThat(Operator.fromString("AND"), equalTo(Operator.AND));
+        assertThat(Operator.fromString("AnD"), equalTo(Operator.AND));
+        assertThat(Operator.fromString("or"), equalTo(Operator.OR));
+        assertThat(Operator.fromString("OR"), equalTo(Operator.OR));
+        assertThat(Operator.fromString("Or"), equalTo(Operator.OR));
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ScoreModeTests.java b/core/src/test/java/org/elasticsearch/index/query/ScoreModeTests.java
new file mode 100644
index 0000000..1b56d34
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/query/ScoreModeTests.java
@@ -0,0 +1,130 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query;
+
+import org.elasticsearch.common.io.stream.BytesStreamOutput;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery;
+import org.elasticsearch.test.ESTestCase;
+
+import static org.hamcrest.Matchers.equalTo;
+
+public class ScoreModeTests extends ESTestCase {
+
+    public void testValidOrdinals() {
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.FIRST.ordinal(), equalTo(0));
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.AVG.ordinal(), equalTo(1));
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.MAX.ordinal(), equalTo(2));
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.SUM.ordinal(), equalTo(3));
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.MIN.ordinal(), equalTo(4));
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.MULTIPLY.ordinal(), equalTo(5));
+    }
+
+    public void testWriteTo() throws Exception {
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FiltersFunctionScoreQuery.ScoreMode.FIRST.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(0));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FiltersFunctionScoreQuery.ScoreMode.AVG.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(1));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FiltersFunctionScoreQuery.ScoreMode.MAX.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(2));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FiltersFunctionScoreQuery.ScoreMode.SUM.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(3));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FiltersFunctionScoreQuery.ScoreMode.MIN.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(4));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FiltersFunctionScoreQuery.ScoreMode.MULTIPLY.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(5));
+            }
+        }
+    }
+
+    public void testReadFrom() throws Exception {
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(0);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FiltersFunctionScoreQuery.ScoreMode.readScoreModeFrom(in), equalTo(FiltersFunctionScoreQuery.ScoreMode.FIRST));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(1);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FiltersFunctionScoreQuery.ScoreMode.readScoreModeFrom(in), equalTo(FiltersFunctionScoreQuery.ScoreMode.AVG));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(2);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FiltersFunctionScoreQuery.ScoreMode.readScoreModeFrom(in), equalTo(FiltersFunctionScoreQuery.ScoreMode.MAX));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(3);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FiltersFunctionScoreQuery.ScoreMode.readScoreModeFrom(in), equalTo(FiltersFunctionScoreQuery.ScoreMode.SUM));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(4);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FiltersFunctionScoreQuery.ScoreMode.readScoreModeFrom(in), equalTo(FiltersFunctionScoreQuery.ScoreMode.MIN));
+            }
+        }
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(5);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FiltersFunctionScoreQuery.ScoreMode.readScoreModeFrom(in), equalTo(FiltersFunctionScoreQuery.ScoreMode.MULTIPLY));
+            }
+        }
+    }
+
+    public void testFromString() {
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.fromString("first"), equalTo(FiltersFunctionScoreQuery.ScoreMode.FIRST));
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.fromString("avg"), equalTo(FiltersFunctionScoreQuery.ScoreMode.AVG));
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.fromString("max"), equalTo(FiltersFunctionScoreQuery.ScoreMode.MAX));
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.fromString("sum"), equalTo(FiltersFunctionScoreQuery.ScoreMode.SUM));
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.fromString("min"), equalTo(FiltersFunctionScoreQuery.ScoreMode.MIN));
+        assertThat(FiltersFunctionScoreQuery.ScoreMode.fromString("multiply"), equalTo(FiltersFunctionScoreQuery.ScoreMode.MULTIPLY));
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTests.java
index 9a76c7a..534542d 100644
--- a/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/ScriptQueryBuilderTests.java
@@ -22,6 +22,7 @@ package org.elasticsearch.index.query;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.ScriptService.ScriptType;
+import org.elasticsearch.script.expression.ExpressionScriptEngineService;
 import org.junit.Test;
 
 import java.io.IOException;
@@ -43,7 +44,7 @@ public class ScriptQueryBuilderTests extends AbstractQueryTestCase<ScriptQueryBu
         } else {
             script = "5 * 2 > 2";
         }
-        return new ScriptQueryBuilder(new Script(script, ScriptType.INLINE, "expression", params));
+        return new ScriptQueryBuilder(new Script(script, ScriptType.INLINE, ExpressionScriptEngineService.NAME, params));
     }
 
     @Override
diff --git a/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java b/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
index 66abfbf..8d99d3d 100644
--- a/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java
@@ -20,41 +20,14 @@
 package org.elasticsearch.index.query;
 
 import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
-import org.apache.lucene.index.Fields;
-import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.index.*;
 import org.apache.lucene.index.memory.MemoryIndex;
 import org.apache.lucene.queries.BoostingQuery;
 import org.apache.lucene.queries.ExtendedCommonTermsQuery;
 import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.BooleanClause;
+import org.apache.lucene.search.*;
 import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.BoostQuery;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.DisjunctionMaxQuery;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.NumericRangeQuery;
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.RegexpQuery;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.TermRangeQuery;
-import org.apache.lucene.search.WildcardQuery;
-import org.apache.lucene.search.spans.FieldMaskingSpanQuery;
-import org.apache.lucene.search.spans.SpanContainingQuery;
-import org.apache.lucene.search.spans.SpanFirstQuery;
-import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
-import org.apache.lucene.search.spans.SpanNearQuery;
-import org.apache.lucene.search.spans.SpanNotQuery;
-import org.apache.lucene.search.spans.SpanOrQuery;
-import org.apache.lucene.search.spans.SpanTermQuery;
-import org.apache.lucene.search.spans.SpanWithinQuery;
+import org.apache.lucene.search.spans.*;
 import org.apache.lucene.spatial.prefix.IntersectsPrefixTreeFilter;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -69,8 +42,6 @@ import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.compress.CompressedXContent;
 import org.elasticsearch.common.lucene.search.MoreLikeThisQuery;
 import org.elasticsearch.common.lucene.search.Queries;
-import org.elasticsearch.common.lucene.search.function.FunctionScoreQuery;
-import org.elasticsearch.common.lucene.search.function.WeightFactorFunction;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.DistanceUnit;
 import org.elasticsearch.common.unit.Fuzziness;
@@ -81,11 +52,9 @@ import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.ParsedDocument;
 import org.elasticsearch.index.mapper.core.NumberFieldMapper;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
 import org.elasticsearch.index.search.geo.GeoDistanceRangeQuery;
 import org.elasticsearch.index.search.geo.GeoPolygonQuery;
 import org.elasticsearch.index.search.geo.InMemoryGeoBoundingBoxQuery;
-import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.test.ESSingleNodeTestCase;
 import org.hamcrest.Matchers;
 import org.junit.Before;
@@ -99,43 +68,11 @@ import java.util.List;
 import java.util.concurrent.ExecutionException;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.boolQuery;
-import static org.elasticsearch.index.query.QueryBuilders.boostingQuery;
-import static org.elasticsearch.index.query.QueryBuilders.commonTermsQuery;
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.disMaxQuery;
-import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.fuzzyQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.index.query.QueryBuilders.moreLikeThisQuery;
-import static org.elasticsearch.index.query.QueryBuilders.multiMatchQuery;
-import static org.elasticsearch.index.query.QueryBuilders.notQuery;
-import static org.elasticsearch.index.query.QueryBuilders.prefixQuery;
-import static org.elasticsearch.index.query.QueryBuilders.queryStringQuery;
-import static org.elasticsearch.index.query.QueryBuilders.rangeQuery;
-import static org.elasticsearch.index.query.QueryBuilders.regexpQuery;
-import static org.elasticsearch.index.query.QueryBuilders.spanContainingQuery;
-import static org.elasticsearch.index.query.QueryBuilders.spanFirstQuery;
-import static org.elasticsearch.index.query.QueryBuilders.spanNearQuery;
-import static org.elasticsearch.index.query.QueryBuilders.spanNotQuery;
-import static org.elasticsearch.index.query.QueryBuilders.spanOrQuery;
-import static org.elasticsearch.index.query.QueryBuilders.spanTermQuery;
-import static org.elasticsearch.index.query.QueryBuilders.spanWithinQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termsQuery;
-import static org.elasticsearch.index.query.QueryBuilders.wildcardQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.elasticsearch.test.StreamsUtils.copyToBytesFromClasspath;
 import static org.elasticsearch.test.StreamsUtils.copyToStringFromClasspath;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertBooleanSubQuery;
-import static org.hamcrest.Matchers.closeTo;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
-import static org.hamcrest.Matchers.sameInstance;
+import static org.hamcrest.Matchers.*;
 
 public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
 
@@ -937,8 +874,6 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         }
     }
 
-
-
     @Test
     public void testInQuery() throws IOException {
         IndexQueryParserService queryParser = queryParser();
@@ -1017,26 +952,6 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     }
 
     @Test
-    public void testCustomWeightFactorQueryBuilder_withFunctionScore() throws IOException {
-        IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(functionScoreQuery(termQuery("name.last", "banon"), ScoreFunctionBuilders.weightFactorFunction(1.3f))).query();
-        assertThat(parsedQuery, instanceOf(FunctionScoreQuery.class));
-        FunctionScoreQuery functionScoreQuery = (FunctionScoreQuery) parsedQuery;
-        assertThat(((TermQuery) functionScoreQuery.getSubQuery()).getTerm(), equalTo(new Term("name.last", "banon")));
-        assertThat((double) ((WeightFactorFunction) functionScoreQuery.getFunction()).getWeight(), closeTo(1.3, 0.001));
-    }
-
-    @Test
-    public void testCustomWeightFactorQueryBuilder_withFunctionScoreWithoutQueryGiven() throws IOException {
-        IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(functionScoreQuery(ScoreFunctionBuilders.weightFactorFunction(1.3f))).query();
-        assertThat(parsedQuery, instanceOf(FunctionScoreQuery.class));
-        FunctionScoreQuery functionScoreQuery = (FunctionScoreQuery) parsedQuery;
-        assertThat(functionScoreQuery.getSubQuery() instanceof MatchAllDocsQuery, equalTo(true));
-        assertThat((double) ((WeightFactorFunction) functionScoreQuery.getFunction()).getWeight(), closeTo(1.3, 0.001));
-    }
-
-    @Test
     public void testSpanTermQueryBuilder() throws IOException {
         IndexQueryParserService queryParser = queryParser();
         Query parsedQuery = queryParser.parse(spanTermQuery("age", 34)).query();
@@ -1316,7 +1231,7 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
     @Test
     public void testMoreLikeThisBuilder() throws Exception {
         IndexQueryParserService queryParser = queryParser();
-        Query parsedQuery = queryParser.parse(moreLikeThisQuery("name.first", "name.last").likeText("something").minTermFreq(1).maxQueryTerms(12)).query();
+        Query parsedQuery = queryParser.parse(moreLikeThisQuery(new String[] {"name.first", "name.last"}, new String[] {"something"}, null).minTermFreq(1).maxQueryTerms(12)).query();
         assertThat(parsedQuery, instanceOf(MoreLikeThisQuery.class));
         MoreLikeThisQuery mltQuery = (MoreLikeThisQuery) parsedQuery;
         assertThat(mltQuery.getMoreLikeFields()[0], equalTo("name.first"));
@@ -1894,15 +1809,6 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         assertTrue(ectQuery.isCoordDisabled());
     }
 
-    @Test(expected = ParsingException.class)
-    public void assureMalformedThrowsException() throws IOException {
-        IndexQueryParserService queryParser;
-        queryParser = queryParser();
-        String query;
-        query = copyToStringFromClasspath("/org/elasticsearch/index/query/faulty-function-score-query.json");
-        Query parsedQuery = queryParser.parse(query).query();
-    }
-
     @Test
     public void testFilterParsing() throws IOException {
         IndexQueryParserService queryParser;
@@ -1997,75 +1903,6 @@ public class SimpleIndexQueryParserTests extends ESSingleNodeTestCase {
         assertThat(parsedQuery, instanceOf(MatchAllDocsQuery.class));
     }
 
-    @Test
-    public void testProperErrorMessageWhenTwoFunctionsDefinedInQueryBody() throws IOException {
-        IndexQueryParserService queryParser = queryParser();
-        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/function-score-query-causing-NPE.json");
-        try {
-            queryParser.parse(query).query();
-            fail("FunctionScoreQueryParser should throw an exception here because two functions in body are not allowed.");
-        } catch (ParsingException e) {
-            assertThat(e.getDetailedMessage(), containsString("use [functions] array if you want to define several functions."));
-        }
-    }
-
-    @Test
-    public void testWeight1fStillProducesWeighFunction() throws IOException {
-        IndexQueryParserService queryParser = queryParser();
-        String queryString = jsonBuilder().startObject()
-                .startObject("function_score")
-                .startArray("functions")
-                .startObject()
-                .startObject("field_value_factor")
-                .field("field", "popularity")
-                .endObject()
-                .field("weight", 1.0)
-                .endObject()
-                .endArray()
-                .endObject()
-                .endObject().string();
-        IndexService indexService = createIndex("testidx", client().admin().indices().prepareCreate("testidx")
-                .addMapping("doc",jsonBuilder().startObject()
-                        .startObject("properties")
-                        .startObject("popularity").field("type", "float").endObject()
-                        .endObject()
-                        .endObject()));
-        SearchContext.setCurrent(createSearchContext(indexService));
-        Query query = queryParser.parse(queryString).query();
-        assertThat(query, instanceOf(FunctionScoreQuery.class));
-        assertThat(((FunctionScoreQuery) query).getFunction(), instanceOf(WeightFactorFunction.class));
-        SearchContext.removeCurrent();
-    }
-
-    @Test
-    public void testProperErrorMessagesForMisplacedWeightsAndFunctions() throws IOException {
-        IndexQueryParserService queryParser = queryParser();
-        String query = jsonBuilder().startObject().startObject("function_score")
-                .startArray("functions")
-                .startObject().startObject("script_score").field("script", "3").endObject().endObject()
-                .endArray()
-                .field("weight", 2)
-                .endObject().endObject().string();
-        try {
-            queryParser.parse(query).query();
-            fail("Expect exception here because array of functions and one weight in body is not allowed.");
-        } catch (ParsingException e) {
-            assertThat(e.getDetailedMessage(), containsString("you can either define [functions] array or a single function, not both. already found [functions] array, now encountering [weight]."));
-        }
-        query = jsonBuilder().startObject().startObject("function_score")
-                .field("weight", 2)
-                .startArray("functions")
-                .startObject().endObject()
-                .endArray()
-                .endObject().endObject().string();
-        try {
-            queryParser.parse(query).query();
-            fail("Expect exception here because array of functions and one weight in body is not allowed.");
-        } catch (ParsingException e) {
-            assertThat(e.getDetailedMessage(), containsString("you can either define [functions] array or a single function, not both. already found [weight], now encountering [functions]."));
-        }
-    }
-
     /**
      * helper to extract term from TermQuery.
      */
diff --git a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryIT.java b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryIT.java
index 639cd39..0c9fc74 100644
--- a/core/src/test/java/org/elasticsearch/index/query/TemplateQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/index/query/TemplateQueryIT.java
@@ -27,22 +27,14 @@ import org.elasticsearch.action.indexedscripts.put.PutIndexedScriptResponse;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.SearchRequest;
 import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.common.HasContextAndHeaders;
-import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.indices.query.IndicesQueriesRegistry;
 import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.script.ScriptService.ScriptType;
 import org.elasticsearch.script.Template;
 import org.elasticsearch.script.mustache.MustacheScriptEngineService;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
-import org.elasticsearch.search.internal.DefaultSearchContext;
 import org.elasticsearch.test.ESIntegTestCase;
-import org.elasticsearch.test.rest.FakeRestRequest;
 import org.junit.Before;
 import org.junit.Test;
 
@@ -94,40 +86,40 @@ public class TemplateQueryIT extends ESIntegTestCase {
         assertHitCount(sr, 2);
     }
 
-//    @Test NOCOMMIT fix this
-//    public void testTemplateInBodyWithSize() throws IOException {
-//        String request = "{\n" +
-//                "    \"size\":0," +
-//                "    \"query\": {\n" +
-//                "        \"template\": {\n" +
-//                "            \"query\": {\"match_{{template}}\": {}},\n" +
-//                "            \"params\" : {\n" +
-//                "                \"template\" : \"all\"\n" +
-//                "            }\n" +
-//                "        }\n" +
-//                "    }\n" +
-//                "}";
-//        SearchResponse sr = client().prepareSearch().setSource(new BytesArray(request))
-//                .execute().actionGet();
-//        assertNoFailures(sr);
-//        assertThat(sr.getHits().hits().length, equalTo(0));
-//        request = "{\n" +
-//                "    \"query\": {\n" +
-//                "        \"template\": {\n" +
-//                "            \"query\": {\"match_{{template}}\": {}},\n" +
-//                "            \"params\" : {\n" +
-//                "                \"template\" : \"all\"\n" +
-//                "            }\n" +
-//                "        }\n" +
-//                "    },\n" +
-//                "    \"size\":0" +
-//                "}";
-//
-//        sr = client().prepareSearch().setSource(new BytesArray(request))
-//                .execute().actionGet();
-//        assertNoFailures(sr);
-//        assertThat(sr.getHits().hits().length, equalTo(0));
-//    }
+    @Test
+    public void testTemplateInBodyWithSize() throws IOException {
+        String request = "{\n" +
+                "    \"size\":0," +
+                "    \"query\": {\n" +
+                "        \"template\": {\n" +
+                "            \"query\": {\"match_{{template}}\": {}},\n" +
+                "            \"params\" : {\n" +
+                "                \"template\" : \"all\"\n" +
+                "            }\n" +
+                "        }\n" +
+                "    }\n" +
+                "}";
+        SearchResponse sr = client().prepareSearch().setSource(new BytesArray(request))
+                .execute().actionGet();
+        assertNoFailures(sr);
+        assertThat(sr.getHits().hits().length, equalTo(0));
+        request = "{\n" +
+                "    \"query\": {\n" +
+                "        \"template\": {\n" +
+                "            \"query\": {\"match_{{template}}\": {}},\n" +
+                "            \"params\" : {\n" +
+                "                \"template\" : \"all\"\n" +
+                "            }\n" +
+                "        }\n" +
+                "    },\n" +
+                "    \"size\":0" +
+                "}";
+
+        sr = client().prepareSearch().setSource(new BytesArray(request))
+                .execute().actionGet();
+        assertNoFailures(sr);
+        assertThat(sr.getHits().hits().length, equalTo(0));
+    }
 
     @Test
     public void testTemplateWOReplacementInBody() throws IOException {
@@ -152,32 +144,28 @@ public class TemplateQueryIT extends ESIntegTestCase {
         assertHitCount(sr, 2);
     }
 
-    // NORELEASE These need to be tested in TemplateQueryBuilderTests
-    // @Test
-    // public void testRawEscapedTemplate() throws IOException {
-    // String query =
-    // "{\"template\": {\"query\": \"{\\\"match_{{template}}\\\": {}}\\\"\",\"params\" : {\"template\" : \"all\"}}}";
-    //
-    // SearchResponse sr = client().prepareSearch().setQuery(query).get();
-    // assertHitCount(sr, 2);
-    // }
-    //
-    // @Test
-    // public void testRawTemplate() throws IOException {
-    // String query =
-    // "{\"template\": {\"query\": {\"match_{{template}}\": {}},\"params\" : {\"template\" : \"all\"}}}";
-    // SearchResponse sr = client().prepareSearch().setQuery(query).get();
-    // assertHitCount(sr, 2);
-    // }
-    //
-    // @Test
-    // public void testRawFSTemplate() throws IOException {
-    // String query =
-    // "{\"template\": {\"file\": \"storedTemplate\",\"params\" : {\"template\" : \"all\"}}}";
-    //
-    // SearchResponse sr = client().prepareSearch().setQuery(query).get();
-    // assertHitCount(sr, 2);
-    // }
+    @Test
+    public void testRawEscapedTemplate() throws IOException {
+        String query = "{\"template\": {\"query\": \"{\\\"match_{{template}}\\\": {}}\\\"\",\"params\" : {\"template\" : \"all\"}}}";
+
+        SearchResponse sr = client().prepareSearch().setQuery(query).get();
+        assertHitCount(sr, 2);
+    }
+
+    @Test
+    public void testRawTemplate() throws IOException {
+        String query = "{\"template\": {\"query\": {\"match_{{template}}\": {}},\"params\" : {\"template\" : \"all\"}}}";
+        SearchResponse sr = client().prepareSearch().setQuery(query).get();
+        assertHitCount(sr, 2);
+    }
+
+    @Test
+    public void testRawFSTemplate() throws IOException {
+        String query = "{\"template\": {\"file\": \"storedTemplate\",\"params\" : {\"template\" : \"all\"}}}";
+
+        SearchResponse sr = client().prepareSearch().setQuery(query).get();
+        assertHitCount(sr, 2);
+    }
 
     @Test
     public void testSearchRequestTemplateSource() throws Exception {
@@ -185,18 +173,13 @@ public class TemplateQueryIT extends ESIntegTestCase {
         searchRequest.indices("_all");
 
         String query = "{ \"template\" : { \"query\": {\"match_{{template}}\": {} } }, \"params\" : { \"template\":\"all\" } }";
-        searchRequest.template(parseTemplate(query));
+        BytesReference bytesRef = new BytesArray(query);
+        searchRequest.templateSource(bytesRef);
 
         SearchResponse searchResponse = client().search(searchRequest).get();
         assertHitCount(searchResponse, 2);
     }
 
-    private Template parseTemplate(String template) throws IOException {
-        try (XContentParser parser = XContentFactory.xContent(template).createParser(template)) {
-            return TemplateQueryParser.parse(parser, ParseFieldMatcher.EMPTY, "params", "template");
-        }
-    }
-
     @Test
     // Releates to #6318
     public void testSearchRequestFail() throws Exception {
@@ -204,14 +187,16 @@ public class TemplateQueryIT extends ESIntegTestCase {
         searchRequest.indices("_all");
         try {
             String query = "{ \"template\" : { \"query\": {\"match_all\": {}}, \"size\" : \"{{my_size}}\"  } }";
-            searchRequest.template(parseTemplate(query));
+            BytesReference bytesRef = new BytesArray(query);
+            searchRequest.templateSource(bytesRef);
             client().search(searchRequest).get();
             fail("expected exception");
         } catch (Exception ex) {
             // expected - no params
         }
         String query = "{ \"template\" : { \"query\": {\"match_all\": {}}, \"size\" : \"{{my_size}}\"  }, \"params\" : { \"my_size\": 1 } }";
-        searchRequest.template(parseTemplate(query));
+        BytesReference bytesRef = new BytesArray(query);
+        searchRequest.templateSource(bytesRef);
 
         SearchResponse searchResponse = client().search(searchRequest).get();
         assertThat(searchResponse.getHits().hits().length, equalTo(1));
@@ -249,9 +234,10 @@ public class TemplateQueryIT extends ESIntegTestCase {
     public void testSearchTemplateQueryFromFile() throws Exception {
         SearchRequest searchRequest = new SearchRequest();
         searchRequest.indices("_all");
-        String query = "{" + "  \"file\": \"full-query-template\"," + "  \"params\":{" + "    \"mySize\": 2,"
+        String templateString = "{" + "  \"file\": \"full-query-template\"," + "  \"params\":{" + "    \"mySize\": 2,"
                 + "    \"myField\": \"text\"," + "    \"myValue\": \"value1\"" + "  }" + "}";
-        searchRequest.template(parseTemplate(query));
+        BytesReference bytesRef = new BytesArray(templateString);
+        searchRequest.templateSource(bytesRef);
         SearchResponse searchResponse = client().search(searchRequest).get();
         assertThat(searchResponse.getHits().hits().length, equalTo(1));
     }
@@ -263,9 +249,10 @@ public class TemplateQueryIT extends ESIntegTestCase {
     public void testTemplateQueryAsEscapedString() throws Exception {
         SearchRequest searchRequest = new SearchRequest();
         searchRequest.indices("_all");
-        String query = "{" + "  \"template\" : \"{ \\\"size\\\": \\\"{{size}}\\\", \\\"query\\\":{\\\"match_all\\\":{}}}\","
+        String templateString = "{" + "  \"template\" : \"{ \\\"size\\\": \\\"{{size}}\\\", \\\"query\\\":{\\\"match_all\\\":{}}}\","
                 + "  \"params\":{" + "    \"size\": 1" + "  }" + "}";
-        searchRequest.template(parseTemplate(query));
+        BytesReference bytesRef = new BytesArray(templateString);
+        searchRequest.templateSource(bytesRef);
         SearchResponse searchResponse = client().search(searchRequest).get();
         assertThat(searchResponse.getHits().hits().length, equalTo(1));
     }
@@ -281,7 +268,8 @@ public class TemplateQueryIT extends ESIntegTestCase {
         String templateString = "{"
                 + "  \"template\" : \"{ {{#use_size}} \\\"size\\\": \\\"{{size}}\\\", {{/use_size}} \\\"query\\\":{\\\"match_all\\\":{}}}\","
                 + "  \"params\":{" + "    \"size\": 1," + "    \"use_size\": true" + "  }" + "}";
-        searchRequest.template(parseTemplate(templateString));
+        BytesReference bytesRef = new BytesArray(templateString);
+        searchRequest.templateSource(bytesRef);
         SearchResponse searchResponse = client().search(searchRequest).get();
         assertThat(searchResponse.getHits().hits().length, equalTo(1));
     }
@@ -297,7 +285,8 @@ public class TemplateQueryIT extends ESIntegTestCase {
         String templateString = "{"
                 + "  \"inline\" : \"{ \\\"query\\\":{\\\"match_all\\\":{}} {{#use_size}}, \\\"size\\\": \\\"{{size}}\\\" {{/use_size}} }\","
                 + "  \"params\":{" + "    \"size\": 1," + "    \"use_size\": true" + "  }" + "}";
-        searchRequest.template(parseTemplate(templateString));
+        BytesReference bytesRef = new BytesArray(templateString);
+        searchRequest.templateSource(bytesRef);
         SearchResponse searchResponse = client().search(searchRequest).get();
         assertThat(searchResponse.getHits().hits().length, equalTo(1));
     }
@@ -462,15 +451,12 @@ public class TemplateQueryIT extends ESIntegTestCase {
                 .execute().actionGet();
         assertHitCount(sr, 1);
 
-        // "{\"template\": {\"id\": \"3\",\"params\" : {\"fieldParam\" : \"foo\"}}}";
-        Map<String, Object> params = new HashMap<>();
-        params.put("fieldParam", "foo");
-        TemplateQueryBuilder templateQuery = new TemplateQueryBuilder(new Template("3", ScriptType.INDEXED, null, null, params));
-        sr = client().prepareSearch().setQuery(templateQuery).get();
+        String query = "{\"template\": {\"id\": \"3\",\"params\" : {\"fieldParam\" : \"foo\"}}}";
+        sr = client().prepareSearch().setQuery(query).get();
         assertHitCount(sr, 4);
 
-        templateQuery = new TemplateQueryBuilder(new Template("/mustache/3", ScriptType.INDEXED, null, null, params));
-        sr = client().prepareSearch().setQuery(templateQuery).get();
+        query = "{\"template\": {\"id\": \"/mustache/3\",\"params\" : {\"fieldParam\" : \"foo\"}}}";
+        sr = client().prepareSearch().setQuery(query).get();
         assertHitCount(sr, 4);
     }
 
@@ -485,7 +471,7 @@ public class TemplateQueryIT extends ESIntegTestCase {
 
         int iterations = randomIntBetween(2, 11);
         for (int i = 1; i < iterations; i++) {
-            PutIndexedScriptResponse scriptResponse = client().preparePutIndexedScript(MustacheScriptEngineService.NAME, "git01",
+            PutIndexedScriptResponse scriptResponse = client().preparePutIndexedScript(MustacheScriptEngineService.NAME, "git01", 
                     "{\"query\": {\"match\": {\"searchtext\": {\"query\": \"{{P_Keyword1}}\",\"type\": \"ooophrase_prefix\"}}}}").get();
             assertEquals(i * 2 - 1, scriptResponse.getVersion());
 
@@ -521,7 +507,7 @@ public class TemplateQueryIT extends ESIntegTestCase {
         }
     }
 
-
+    
     @Test
     public void testIndexedTemplateWithArray() throws Exception {
       createIndex(ScriptService.SCRIPT_INDEX);
diff --git a/core/src/test/java/org/elasticsearch/index/query/functionscore/FieldValueFactorFunctionModifierTests.java b/core/src/test/java/org/elasticsearch/index/query/functionscore/FieldValueFactorFunctionModifierTests.java
new file mode 100644
index 0000000..4c30d14
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/query/functionscore/FieldValueFactorFunctionModifierTests.java
@@ -0,0 +1,200 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query.functionscore;
+
+import org.elasticsearch.common.io.stream.BytesStreamOutput;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.lucene.search.function.FieldValueFactorFunction;
+import org.elasticsearch.test.ESTestCase;
+
+import static org.hamcrest.Matchers.equalTo;
+
+public class FieldValueFactorFunctionModifierTests extends ESTestCase {
+
+    public void testValidOrdinals() {
+        assertThat(FieldValueFactorFunction.Modifier.NONE.ordinal(), equalTo(0));
+        assertThat(FieldValueFactorFunction.Modifier.LOG.ordinal(), equalTo(1));
+        assertThat(FieldValueFactorFunction.Modifier.LOG1P.ordinal(), equalTo(2));
+        assertThat(FieldValueFactorFunction.Modifier.LOG2P.ordinal(), equalTo(3));
+        assertThat(FieldValueFactorFunction.Modifier.LN.ordinal(), equalTo(4));
+        assertThat(FieldValueFactorFunction.Modifier.LN1P.ordinal(), equalTo(5));
+        assertThat(FieldValueFactorFunction.Modifier.LN2P.ordinal(), equalTo(6));
+        assertThat(FieldValueFactorFunction.Modifier.SQUARE.ordinal(), equalTo(7));
+        assertThat(FieldValueFactorFunction.Modifier.SQRT.ordinal(), equalTo(8));
+        assertThat(FieldValueFactorFunction.Modifier.RECIPROCAL.ordinal(), equalTo(9));
+    }
+
+    public void testWriteTo() throws Exception {
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FieldValueFactorFunction.Modifier.NONE.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(0));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FieldValueFactorFunction.Modifier.LOG.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(1));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FieldValueFactorFunction.Modifier.LOG1P.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(2));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FieldValueFactorFunction.Modifier.LOG2P.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(3));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FieldValueFactorFunction.Modifier.LN.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(4));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FieldValueFactorFunction.Modifier.LN1P.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(5));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FieldValueFactorFunction.Modifier.LN2P.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(6));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FieldValueFactorFunction.Modifier.SQUARE.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(7));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FieldValueFactorFunction.Modifier.SQRT.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(8));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            FieldValueFactorFunction.Modifier.RECIPROCAL.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(9));
+            }
+        }
+    }
+
+    public void testReadFrom() throws Exception {
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(0);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FieldValueFactorFunction.Modifier.readModifierFrom(in), equalTo(FieldValueFactorFunction.Modifier.NONE));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(1);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FieldValueFactorFunction.Modifier.readModifierFrom(in), equalTo(FieldValueFactorFunction.Modifier.LOG));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(2);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FieldValueFactorFunction.Modifier.readModifierFrom(in), equalTo(FieldValueFactorFunction.Modifier.LOG1P));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(3);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FieldValueFactorFunction.Modifier.readModifierFrom(in), equalTo(FieldValueFactorFunction.Modifier.LOG2P));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(4);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FieldValueFactorFunction.Modifier.readModifierFrom(in), equalTo(FieldValueFactorFunction.Modifier.LN));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(5);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FieldValueFactorFunction.Modifier.readModifierFrom(in), equalTo(FieldValueFactorFunction.Modifier.LN1P));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(6);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FieldValueFactorFunction.Modifier.readModifierFrom(in), equalTo(FieldValueFactorFunction.Modifier.LN2P));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(7);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FieldValueFactorFunction.Modifier.readModifierFrom(in), equalTo(FieldValueFactorFunction.Modifier.SQUARE));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(8);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FieldValueFactorFunction.Modifier.readModifierFrom(in), equalTo(FieldValueFactorFunction.Modifier.SQRT));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(9);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(FieldValueFactorFunction.Modifier.readModifierFrom(in), equalTo(FieldValueFactorFunction.Modifier.RECIPROCAL));
+            }
+        }
+    }
+
+    public void testFromString() {
+        assertThat(FieldValueFactorFunction.Modifier.fromString("none"), equalTo(FieldValueFactorFunction.Modifier.NONE));
+        assertThat(FieldValueFactorFunction.Modifier.fromString("log"), equalTo(FieldValueFactorFunction.Modifier.LOG));
+        assertThat(FieldValueFactorFunction.Modifier.fromString("log1p"), equalTo(FieldValueFactorFunction.Modifier.LOG1P));
+        assertThat(FieldValueFactorFunction.Modifier.fromString("log2p"), equalTo(FieldValueFactorFunction.Modifier.LOG2P));
+        assertThat(FieldValueFactorFunction.Modifier.fromString("ln"), equalTo(FieldValueFactorFunction.Modifier.LN));
+        assertThat(FieldValueFactorFunction.Modifier.fromString("ln1p"), equalTo(FieldValueFactorFunction.Modifier.LN1P));
+        assertThat(FieldValueFactorFunction.Modifier.fromString("ln2p"), equalTo(FieldValueFactorFunction.Modifier.LN2P));
+        assertThat(FieldValueFactorFunction.Modifier.fromString("square"), equalTo(FieldValueFactorFunction.Modifier.SQUARE));
+        assertThat(FieldValueFactorFunction.Modifier.fromString("sqrt"), equalTo(FieldValueFactorFunction.Modifier.SQRT));
+        assertThat(FieldValueFactorFunction.Modifier.fromString("reciprocal"), equalTo(FieldValueFactorFunction.Modifier.RECIPROCAL));
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilderTests.java
new file mode 100644
index 0000000..e1286c2
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/query/functionscore/FunctionScoreQueryBuilderTests.java
@@ -0,0 +1,603 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query.functionscore;
+
+import com.fasterxml.jackson.core.JsonParseException;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.TermQuery;
+import org.elasticsearch.common.ParsingException;
+import org.elasticsearch.common.lucene.search.function.*;
+import org.elasticsearch.common.xcontent.XContentType;
+import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.functionscore.exp.ExponentialDecayFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.fieldvaluefactor.FieldValueFactorFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.lin.LinearDecayFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.random.RandomScoreFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.script.ScriptScoreFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.weight.WeightBuilder;
+import org.elasticsearch.script.Script;
+import org.elasticsearch.script.ScriptService;
+import org.elasticsearch.script.expression.ExpressionScriptEngineService;
+import org.elasticsearch.search.MultiValueMode;
+import org.junit.Test;
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+
+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
+import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
+import static org.elasticsearch.index.query.QueryBuilders.termQuery;
+import static org.elasticsearch.test.StreamsUtils.copyToStringFromClasspath;
+import static org.hamcrest.Matchers.*;
+
+public class FunctionScoreQueryBuilderTests extends AbstractQueryTestCase<FunctionScoreQueryBuilder> {
+
+    @Override
+    protected FunctionScoreQueryBuilder doCreateTestQueryBuilder() {
+        FunctionScoreQueryBuilder functionScoreQueryBuilder;
+        switch(randomIntBetween(0, 3)) {
+            case 0:
+                int numFunctions = randomIntBetween(0, 3);
+                FunctionScoreQueryBuilder.FilterFunctionBuilder[] filterFunctionBuilders = new FunctionScoreQueryBuilder.FilterFunctionBuilder[numFunctions];
+                for (int i = 0; i < numFunctions; i++) {
+                    filterFunctionBuilders[i] = new FunctionScoreQueryBuilder.FilterFunctionBuilder(RandomQueryBuilder.createQuery(random()), randomScoreFunction());
+                }
+                if (randomBoolean()) {
+                    functionScoreQueryBuilder = new FunctionScoreQueryBuilder(RandomQueryBuilder.createQuery(random()), filterFunctionBuilders);
+                } else {
+                    functionScoreQueryBuilder = new FunctionScoreQueryBuilder(filterFunctionBuilders);
+                }
+                break;
+            case 1:
+                functionScoreQueryBuilder = new FunctionScoreQueryBuilder(randomScoreFunction());
+                break;
+            case 2:
+                functionScoreQueryBuilder = new FunctionScoreQueryBuilder(RandomQueryBuilder.createQuery(random()), randomScoreFunction());
+                break;
+            case 3:
+                functionScoreQueryBuilder = new FunctionScoreQueryBuilder(RandomQueryBuilder.createQuery(random()));
+                break;
+            default:
+                throw new UnsupportedOperationException();
+        }
+
+        if (randomBoolean()) {
+            functionScoreQueryBuilder.boostMode(randomFrom(CombineFunction.values()));
+        }
+        if (randomBoolean()) {
+            functionScoreQueryBuilder.scoreMode(randomFrom(FiltersFunctionScoreQuery.ScoreMode.values()));
+        }
+        if (randomBoolean()) {
+            functionScoreQueryBuilder.maxBoost(randomFloat());
+        }
+        if (randomBoolean()) {
+            functionScoreQueryBuilder.setMinScore(randomFloat());
+        }
+        return functionScoreQueryBuilder;
+    }
+
+    private static ScoreFunctionBuilder randomScoreFunction() {
+        if (randomBoolean()) {
+            return new WeightBuilder().setWeight(randomFloat());
+        }
+        ScoreFunctionBuilder functionBuilder;
+        //TODO random score function is temporarily disabled, it causes NPE in testToQuery when trying to access the shardId through SearchContext
+        switch (randomIntBetween(0, 2)) {
+            case 0:
+                DecayFunctionBuilder decayFunctionBuilder;
+                Float offset = randomBoolean() ? null : randomFloat();
+                double decay = randomDouble();
+                switch(randomIntBetween(0, 2)) {
+                    case 0:
+                        decayFunctionBuilder = new GaussDecayFunctionBuilder(INT_FIELD_NAME, randomFloat(), randomFloat(), offset, decay);
+                        break;
+                    case 1:
+                        decayFunctionBuilder = new ExponentialDecayFunctionBuilder(INT_FIELD_NAME, randomFloat(), randomFloat(), offset, decay);
+                        break;
+                    case 2:
+                        decayFunctionBuilder = new LinearDecayFunctionBuilder(INT_FIELD_NAME, randomFloat(), randomFloat(), offset, decay);
+                        break;
+                    default:
+                        throw new UnsupportedOperationException();
+                }
+                if (randomBoolean()) {
+                    decayFunctionBuilder.setMultiValueMode(randomFrom(MultiValueMode.values()));
+                }
+                functionBuilder = decayFunctionBuilder;
+                break;
+            case 1:
+                FieldValueFactorFunctionBuilder fieldValueFactorFunctionBuilder = new FieldValueFactorFunctionBuilder(INT_FIELD_NAME);
+                if (randomBoolean()) {
+                    fieldValueFactorFunctionBuilder.factor(randomFloat());
+                }
+                if (randomBoolean()) {
+                    fieldValueFactorFunctionBuilder.missing(randomDouble());
+                }
+                if (randomBoolean()) {
+                    fieldValueFactorFunctionBuilder.modifier(randomFrom(FieldValueFactorFunction.Modifier.values()));
+                }
+                functionBuilder = fieldValueFactorFunctionBuilder;
+                break;
+            case 2:
+                String script;
+                Map<String, Object> params = null;
+                if (randomBoolean()) {
+                    script = "5 * 2 > param";
+                    params = new HashMap<>();
+                    params.put("param", 1);
+                } else {
+                    script = "5 * 2 > 2";
+                }
+                functionBuilder = new ScriptScoreFunctionBuilder(new Script(script, ScriptService.ScriptType.INLINE, ExpressionScriptEngineService.NAME, params));
+                break;
+            case 3:
+                RandomScoreFunctionBuilder randomScoreFunctionBuilder = new RandomScoreFunctionBuilder();
+                if (randomBoolean()) {
+                    randomScoreFunctionBuilder.seed(randomLong());
+                } else if(randomBoolean()) {
+                    randomScoreFunctionBuilder.seed(randomInt());
+                } else {
+                    randomScoreFunctionBuilder.seed(randomAsciiOfLengthBetween(1, 10));
+                }
+                functionBuilder = randomScoreFunctionBuilder;
+                break;
+            default:
+                throw new UnsupportedOperationException();
+        }
+        if (randomBoolean()) {
+            functionBuilder.setWeight(randomFloat());
+        }
+        return functionBuilder;
+    }
+
+    @Override
+    protected void doAssertLuceneQuery(FunctionScoreQueryBuilder queryBuilder, Query query, QueryShardContext context) throws IOException {
+        assertThat(query, either(instanceOf(FunctionScoreQuery.class)).or(instanceOf(FiltersFunctionScoreQuery.class)));
+    }
+
+    /**
+     * Overridden here to ensure the test is only run if at least one type is
+     * present in the mappings. Functions require the field to be
+     * explicitly mapped
+     */
+    @Override
+    public void testToQuery() throws IOException {
+        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
+        super.testToQuery();
+    }
+
+    @Test
+    public void testIllegalArguments() {
+        try {
+            new FunctionScoreQueryBuilder((QueryBuilder<?>)null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder((ScoreFunctionBuilder)null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder((FunctionScoreQueryBuilder.FilterFunctionBuilder[])null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder(null, ScoreFunctionBuilders.randomFunction(123));
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder(new MatchAllQueryBuilder(), (ScoreFunctionBuilder)null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder(new MatchAllQueryBuilder(), (FunctionScoreQueryBuilder.FilterFunctionBuilder[])null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder(null, new FunctionScoreQueryBuilder.FilterFunctionBuilder[0]);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder(QueryBuilders.matchAllQuery(), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{null});
+            fail("content of array must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder.FilterFunctionBuilder(null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder.FilterFunctionBuilder(null, ScoreFunctionBuilders.randomFunction(123));
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder.FilterFunctionBuilder(new MatchAllQueryBuilder(), null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder(new MatchAllQueryBuilder()).scoreMode(null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FunctionScoreQueryBuilder(new MatchAllQueryBuilder()).boostMode(null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+    }
+
+    @Test
+    public void testParseFunctionsArray() throws IOException {
+        String functionScoreQuery = "{\n" +
+                    "    \"function_score\":{\n" +
+                    "        \"query\":{\n" +
+                    "            \"term\":{\n" +
+                    "                \"field1\":\"value1\"\n" +
+                    "            }\n" +
+                    "        },\n" +
+                    "        \"functions\":  [\n" +
+                    "            {\n" +
+                    "                \"random_score\":  {\n" +
+                    "                    \"seed\":123456\n" +
+                    "                },\n" +
+                    "                \"weight\": 3,\n" +
+                    "                \"filter\": {\n" +
+                    "                    \"term\":{\n" +
+                    "                        \"field2\":\"value2\"\n" +
+                    "                    }\n" +
+                    "                }\n" +
+                    "            },\n" +
+                    "            {\n" +
+                    "                \"filter\": {\n" +
+                    "                    \"term\":{\n" +
+                    "                        \"field3\":\"value3\"\n" +
+                    "                    }\n" +
+                    "                },\n" +
+                    "                \"weight\": 9\n" +
+                    "            },\n" +
+                    "            {\n" +
+                    "                \"gauss\":  {\n" +
+                    "                    \"field_name\":  {\n" +
+                    "                        \"origin\":0.5,\n" +
+                    "                        \"scale\":0.6\n" +
+                    "                    }\n" +
+                    "                }\n" +
+                    "            }\n" +
+                    "        ],\n" +
+                    "        \"boost\" : 3,\n" +
+                    "        \"score_mode\" : \"avg\",\n" +
+                    "        \"boost_mode\" : \"replace\",\n" +
+                    "        \"max_boost\" : 10\n" +
+                    "    }\n" +
+                    "}";
+
+        QueryBuilder<?> queryBuilder = parseQuery(functionScoreQuery);
+        //given that we copy part of the decay functions as bytes, we test that fromXContent and toXContent both work no matter what the initial format was
+        for (int i = 0; i <= XContentType.values().length; i++) {
+            assertThat(queryBuilder, instanceOf(FunctionScoreQueryBuilder.class));
+            FunctionScoreQueryBuilder functionScoreQueryBuilder = (FunctionScoreQueryBuilder) queryBuilder;
+            assertThat(functionScoreQueryBuilder.query(), instanceOf(TermQueryBuilder.class));
+            TermQueryBuilder termQueryBuilder = (TermQueryBuilder) functionScoreQueryBuilder.query();
+            assertThat(termQueryBuilder.fieldName(), equalTo("field1"));
+            assertThat(termQueryBuilder.value(), equalTo("value1"));
+            assertThat(functionScoreQueryBuilder.filterFunctionBuilders().length, equalTo(3));
+            assertThat(functionScoreQueryBuilder.filterFunctionBuilders()[0].getFilter(), instanceOf(TermQueryBuilder.class));
+            termQueryBuilder = (TermQueryBuilder) functionScoreQueryBuilder.filterFunctionBuilders()[0].getFilter();
+            assertThat(termQueryBuilder.fieldName(), equalTo("field2"));
+            assertThat(termQueryBuilder.value(), equalTo("value2"));
+            assertThat(functionScoreQueryBuilder.filterFunctionBuilders()[1].getFilter(), instanceOf(TermQueryBuilder.class));
+            termQueryBuilder = (TermQueryBuilder) functionScoreQueryBuilder.filterFunctionBuilders()[1].getFilter();
+            assertThat(termQueryBuilder.fieldName(), equalTo("field3"));
+            assertThat(termQueryBuilder.value(), equalTo("value3"));
+            assertThat(functionScoreQueryBuilder.filterFunctionBuilders()[2].getFilter(), instanceOf(MatchAllQueryBuilder.class));
+            assertThat(functionScoreQueryBuilder.filterFunctionBuilders()[0].getScoreFunction(), instanceOf(RandomScoreFunctionBuilder.class));
+            RandomScoreFunctionBuilder randomScoreFunctionBuilder = (RandomScoreFunctionBuilder) functionScoreQueryBuilder.filterFunctionBuilders()[0].getScoreFunction();
+            assertThat(randomScoreFunctionBuilder.getSeed(), equalTo(123456));
+            assertThat(randomScoreFunctionBuilder.getWeight(), equalTo(3f));
+            assertThat(functionScoreQueryBuilder.filterFunctionBuilders()[1].getScoreFunction(), instanceOf(WeightBuilder.class));
+            WeightBuilder weightBuilder = (WeightBuilder) functionScoreQueryBuilder.filterFunctionBuilders()[1].getScoreFunction();
+            assertThat(weightBuilder.getWeight(), equalTo(9f));
+            assertThat(functionScoreQueryBuilder.filterFunctionBuilders()[2].getScoreFunction(), instanceOf(GaussDecayFunctionBuilder.class));
+            GaussDecayFunctionBuilder gaussDecayFunctionBuilder = (GaussDecayFunctionBuilder) functionScoreQueryBuilder.filterFunctionBuilders()[2].getScoreFunction();
+            assertThat(gaussDecayFunctionBuilder.getFieldName(), equalTo("field_name"));
+            assertThat(functionScoreQueryBuilder.boost(), equalTo(3f));
+            assertThat(functionScoreQueryBuilder.scoreMode(), equalTo(FiltersFunctionScoreQuery.ScoreMode.AVG));
+            assertThat(functionScoreQueryBuilder.boostMode(), equalTo(CombineFunction.REPLACE));
+            assertThat(functionScoreQueryBuilder.maxBoost(), equalTo(10f));
+
+            if (i < XContentType.values().length) {
+                queryBuilder = parseQuery(((AbstractQueryBuilder)queryBuilder).buildAsBytes(XContentType.values()[i]));
+            }
+        }
+    }
+
+    @Test
+    public void testParseSingleFunction() throws IOException {
+        String functionScoreQuery = "{\n" +
+                "    \"function_score\":{\n" +
+                "        \"query\":{\n" +
+                "            \"term\":{\n" +
+                "                \"field1\":\"value1\"\n" +
+                "            }\n" +
+                "        },\n" +
+                "        \"gauss\":  {\n" +
+                "            \"field_name\":  {\n" +
+                "                \"origin\":0.5,\n" +
+                "                \"scale\":0.6\n" +
+                "            }\n" +
+                "         },\n" +
+                "        \"boost\" : 3,\n" +
+                "        \"score_mode\" : \"avg\",\n" +
+                "        \"boost_mode\" : \"replace\",\n" +
+                "        \"max_boost\" : 10\n" +
+                "    }\n" +
+                "}";
+
+        QueryBuilder<?> queryBuilder = parseQuery(functionScoreQuery);
+        //given that we copy part of the decay functions as bytes, we test that fromXContent and toXContent both work no matter what the initial format was
+        for (int i = 0; i <= XContentType.values().length; i++) {
+            assertThat(queryBuilder, instanceOf(FunctionScoreQueryBuilder.class));
+            FunctionScoreQueryBuilder functionScoreQueryBuilder = (FunctionScoreQueryBuilder) queryBuilder;
+            assertThat(functionScoreQueryBuilder.query(), instanceOf(TermQueryBuilder.class));
+            TermQueryBuilder termQueryBuilder = (TermQueryBuilder) functionScoreQueryBuilder.query();
+            assertThat(termQueryBuilder.fieldName(), equalTo("field1"));
+            assertThat(termQueryBuilder.value(), equalTo("value1"));
+            assertThat(functionScoreQueryBuilder.filterFunctionBuilders().length, equalTo(1));
+            assertThat(functionScoreQueryBuilder.filterFunctionBuilders()[0].getFilter(), instanceOf(MatchAllQueryBuilder.class));
+            assertThat(functionScoreQueryBuilder.filterFunctionBuilders()[0].getScoreFunction(), instanceOf(GaussDecayFunctionBuilder.class));
+            GaussDecayFunctionBuilder gaussDecayFunctionBuilder = (GaussDecayFunctionBuilder) functionScoreQueryBuilder.filterFunctionBuilders()[0].getScoreFunction();
+            assertThat(gaussDecayFunctionBuilder.getFieldName(), equalTo("field_name"));
+            assertThat(gaussDecayFunctionBuilder.getWeight(), nullValue());
+            assertThat(functionScoreQueryBuilder.boost(), equalTo(3f));
+            assertThat(functionScoreQueryBuilder.scoreMode(), equalTo(FiltersFunctionScoreQuery.ScoreMode.AVG));
+            assertThat(functionScoreQueryBuilder.boostMode(), equalTo(CombineFunction.REPLACE));
+            assertThat(functionScoreQueryBuilder.maxBoost(), equalTo(10f));
+
+            if (i < XContentType.values().length) {
+                queryBuilder = parseQuery(((AbstractQueryBuilder)queryBuilder).buildAsBytes(XContentType.values()[i]));
+            }
+        }
+    }
+
+    @Test
+    public void testProperErrorMessageWhenTwoFunctionsDefinedInQueryBody() throws IOException {
+        //without a functions array, we support only a single function, weight can't be associated with the function either.
+        String functionScoreQuery = "{\n" +
+                "    \"function_score\": {\n" +
+                "      \"script_score\": {\n" +
+                "        \"script\": \"_index['text']['foo'].tf()\"\n" +
+                "      },\n" +
+                "      \"weight\": 2\n" +
+                "    }\n" +
+                "}";
+        try {
+            parseQuery(functionScoreQuery);
+            fail("parsing should have failed");
+        } catch(ParsingException e) {
+            assertThat(e.getMessage(), containsString("use [functions] array if you want to define several functions."));
+        }
+    }
+
+    @Test
+    public void testProperErrorMessageWhenTwoFunctionsDefinedInFunctionsArray() throws IOException {
+        String functionScoreQuery = "{\n" +
+                "    \"function_score\":{\n" +
+                "        \"functions\":  [\n" +
+                "            {\n" +
+                "                \"random_score\":  {\n" +
+                "                    \"seed\":123456\n" +
+                "                },\n" +
+                "                \"weight\": 3,\n" +
+                "                \"script_score\": {\n" +
+                "                    \"script\": \"_index['text']['foo'].tf()\"\n" +
+                "                },\n" +
+                "                \"filter\": {\n" +
+                "                    \"term\":{\n" +
+                "                        \"field2\":\"value2\"\n" +
+                "                    }\n" +
+                "                }\n" +
+                "            }\n" +
+                "        ]\n" +
+                "    }\n" +
+                "}";
+
+        try {
+            parseQuery(functionScoreQuery);
+            fail("parsing should have failed");
+        } catch(ParsingException e) {
+            assertThat(e.getMessage(), containsString("failed to parse function_score functions. already found [random_score], now encountering [script_score]."));
+        }
+    }
+
+    @Test
+    public void testProperErrorMessageWhenMissingFunction() throws IOException {
+        String functionScoreQuery = "{\n" +
+                "    \"function_score\":{\n" +
+                "        \"functions\":  [\n" +
+                "            {\n" +
+                "                \"filter\": {\n" +
+                "                    \"term\":{\n" +
+                "                        \"field2\":\"value2\"\n" +
+                "                    }\n" +
+                "                }\n" +
+                "            }\n" +
+                "        ]\n" +
+                "    }\n" +
+                "}";
+        try {
+            parseQuery(functionScoreQuery);
+            fail("parsing should have failed");
+        } catch(ParsingException e) {
+            assertThat(e.getMessage(), containsString("an entry in functions list is missing a function."));
+        }
+    }
+
+    @Test
+    public void testWeight1fStillProducesWeightFunction() throws IOException {
+        assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0);
+        String queryString = jsonBuilder().startObject()
+                .startObject("function_score")
+                .startArray("functions")
+                .startObject()
+                .startObject("field_value_factor")
+                .field("field", INT_FIELD_NAME)
+                .endObject()
+                .field("weight", 1.0)
+                .endObject()
+                .endArray()
+                .endObject()
+                .endObject().string();
+        QueryBuilder<?> query = parseQuery(queryString);
+        assertThat(query, instanceOf(FunctionScoreQueryBuilder.class));
+        FunctionScoreQueryBuilder functionScoreQueryBuilder = (FunctionScoreQueryBuilder) query;
+        assertThat(functionScoreQueryBuilder.filterFunctionBuilders()[0].getScoreFunction(), instanceOf(FieldValueFactorFunctionBuilder.class));
+        FieldValueFactorFunctionBuilder fieldValueFactorFunctionBuilder = (FieldValueFactorFunctionBuilder) functionScoreQueryBuilder.filterFunctionBuilders()[0].getScoreFunction();
+        assertThat(fieldValueFactorFunctionBuilder.fieldName(), equalTo(INT_FIELD_NAME));
+        assertThat(fieldValueFactorFunctionBuilder.factor(), equalTo(FieldValueFactorFunctionBuilder.DEFAULT_FACTOR));
+        assertThat(fieldValueFactorFunctionBuilder.modifier(), equalTo(FieldValueFactorFunctionBuilder.DEFAULT_MODIFIER));
+        assertThat(fieldValueFactorFunctionBuilder.getWeight(), equalTo(1f));
+        assertThat(fieldValueFactorFunctionBuilder.missing(), nullValue());
+
+        Query luceneQuery = query.toQuery(createShardContext());
+        assertThat(luceneQuery, instanceOf(FunctionScoreQuery.class));
+        FunctionScoreQuery functionScoreQuery = (FunctionScoreQuery) luceneQuery;
+        assertThat(functionScoreQuery.getFunction(), instanceOf(WeightFactorFunction.class));
+        WeightFactorFunction weightFactorFunction = (WeightFactorFunction) functionScoreQuery.getFunction();
+        assertThat(weightFactorFunction.getWeight(), equalTo(1.0f));
+        assertThat(weightFactorFunction.getScoreFunction(), instanceOf(FieldValueFactorFunction.class));
+    }
+
+    @Test
+    public void testProperErrorMessagesForMisplacedWeightsAndFunctions() throws IOException {
+        String query = jsonBuilder().startObject().startObject("function_score")
+                .startArray("functions")
+                .startObject().startObject("script_score").field("script", "3").endObject().endObject()
+                .endArray()
+                .field("weight", 2)
+                .endObject().endObject().string();
+        try {
+            parseQuery(query);
+            fail("Expect exception here because array of functions and one weight in body is not allowed.");
+        } catch (ParsingException e) {
+            assertThat(e.getMessage(), containsString("you can either define [functions] array or a single function, not both. already found [functions] array, now encountering [weight]."));
+        }
+        query = jsonBuilder().startObject().startObject("function_score")
+                .field("weight", 2)
+                .startArray("functions")
+                .startObject().endObject()
+                .endArray()
+                .endObject().endObject().string();
+        try {
+            parseQuery(query);
+            fail("Expect exception here because array of functions and one weight in body is not allowed.");
+        } catch (ParsingException e) {
+            assertThat(e.getMessage(), containsString("you can either define [functions] array or a single function, not both. already found [weight], now encountering [functions]."));
+        }
+    }
+
+    @Test(expected = JsonParseException.class)
+    public void ensureMalformedThrowsException() throws IOException {
+        parseQuery(copyToStringFromClasspath("/org/elasticsearch/index/query/faulty-function-score-query.json"));
+    }
+
+    @Test
+    public void testCustomWeightFactorQueryBuilder_withFunctionScore() throws IOException {
+        Query parsedQuery = parseQuery(functionScoreQuery(termQuery("name.last", "banon"), ScoreFunctionBuilders.weightFactorFunction(1.3f)).buildAsBytes()).toQuery(createShardContext());
+        assertThat(parsedQuery, instanceOf(FunctionScoreQuery.class));
+        FunctionScoreQuery functionScoreQuery = (FunctionScoreQuery) parsedQuery;
+        assertThat(((TermQuery) functionScoreQuery.getSubQuery()).getTerm(), equalTo(new Term("name.last", "banon")));
+        assertThat((double) ((WeightFactorFunction) functionScoreQuery.getFunction()).getWeight(), closeTo(1.3, 0.001));
+    }
+
+    @Test
+    public void testCustomWeightFactorQueryBuilder_withFunctionScoreWithoutQueryGiven() throws IOException {
+        Query parsedQuery = parseQuery(functionScoreQuery(ScoreFunctionBuilders.weightFactorFunction(1.3f)).buildAsBytes()).toQuery(createShardContext());
+        assertThat(parsedQuery, instanceOf(FunctionScoreQuery.class));
+        FunctionScoreQuery functionScoreQuery = (FunctionScoreQuery) parsedQuery;
+        assertThat(functionScoreQuery.getSubQuery() instanceof MatchAllDocsQuery, equalTo(true));
+        assertThat((double) ((WeightFactorFunction) functionScoreQuery.getFunction()).getWeight(), closeTo(1.3, 0.001));
+    }
+
+    @Test
+    public void testFieldValueFactorFactorArray() throws IOException {
+        // don't permit an array of factors
+        String querySource = "{" +
+                "\"query\": {" +
+                "  \"function_score\": {" +
+                "    \"query\": {" +
+                "      \"match\": {\"name\": \"foo\"}" +
+                "      }," +
+                "      \"functions\": [" +
+                "        {" +
+                "          \"field_value_factor\": {" +
+                "            \"field\": \"test\"," +
+                "            \"factor\": [1.2,2]" +
+                "          }" +
+                "        }" +
+                "      ]" +
+                "    }" +
+                "  }" +
+                "}";
+        try {
+            parseQuery(querySource);
+            fail("parsing should have failed");
+        } catch(ParsingException e) {
+            assertThat(e.getMessage(), containsString("[field_value_factor] field 'factor' does not support lists or objects"));
+        }
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilderTests.java
new file mode 100644
index 0000000..30c2944
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/query/functionscore/ScoreFunctionBuilderTests.java
@@ -0,0 +1,146 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.query.functionscore;
+
+import org.elasticsearch.index.query.functionscore.exp.ExponentialDecayFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.fieldvaluefactor.FieldValueFactorFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.lin.LinearDecayFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.random.RandomScoreFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.script.ScriptScoreFunctionBuilder;
+import org.elasticsearch.test.ESTestCase;
+
+public class ScoreFunctionBuilderTests extends ESTestCase {
+
+    public void testIllegalArguments() {
+        try {
+            new RandomScoreFunctionBuilder().seed(null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new ScriptScoreFunctionBuilder(null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FieldValueFactorFunctionBuilder(null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new FieldValueFactorFunctionBuilder("").modifier(null);
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new GaussDecayFunctionBuilder(null, "", "", "");
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new GaussDecayFunctionBuilder("", "", null, "");
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new GaussDecayFunctionBuilder("", "", null, "", randomIntBetween(1, 100));
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new GaussDecayFunctionBuilder("", "", null, "", randomIntBetween(-100, -1));
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new LinearDecayFunctionBuilder(null, "", "", "");
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new LinearDecayFunctionBuilder("", "", null, "");
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new LinearDecayFunctionBuilder("", "", null, "", randomIntBetween(1, 100));
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new LinearDecayFunctionBuilder("", "", null, "", randomIntBetween(-100, -1));
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new ExponentialDecayFunctionBuilder(null, "", "", "");
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new ExponentialDecayFunctionBuilder("", "", null, "");
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new ExponentialDecayFunctionBuilder("", "", null, "", randomIntBetween(1, 100));
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new ExponentialDecayFunctionBuilder("", "", null, "", randomIntBetween(-100, -1));
+            fail("must not be null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/indices/IndicesOptionsIntegrationIT.java b/core/src/test/java/org/elasticsearch/indices/IndicesOptionsIntegrationIT.java
index 492370d..9cf2034 100644
--- a/core/src/test/java/org/elasticsearch/indices/IndicesOptionsIntegrationIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/IndicesOptionsIntegrationIT.java
@@ -48,10 +48,10 @@ import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.action.suggest.SuggestRequestBuilder;
 import org.elasticsearch.action.support.IndicesOptions;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.IndexNotFoundException;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.search.suggest.SuggestBuilders;
 import org.elasticsearch.search.warmer.IndexWarmersMetaData;
 import org.elasticsearch.test.ESIntegTestCase;
@@ -61,9 +61,7 @@ import static org.elasticsearch.action.percolate.PercolateSourceBuilder.docBuild
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.*;
 
 public class IndicesOptionsIntegrationIT extends ESIntegTestCase {
 
@@ -510,7 +508,7 @@ public class IndicesOptionsIntegrationIT extends ESIntegTestCase {
                 .setIndicesOptions(IndicesOptions.lenientExpandOpen())
                 .execute().actionGet();
         assertHitCount(response, 0l);
-
+        
         //you should still be able to run empty searches without things blowing up
         response  = client().prepareSearch()
                 .setIndicesOptions(IndicesOptions.lenientExpandOpen())
@@ -615,7 +613,7 @@ public class IndicesOptionsIntegrationIT extends ESIntegTestCase {
         assertThat(client().admin().indices().prepareExists("bar").get().isExists(), equalTo(false));
         assertThat(client().admin().indices().prepareExists("barbaz").get().isExists(), equalTo(false));
     }
-
+    
     @Test
     public void testPutWarmer() throws Exception {
         createIndex("foobar");
@@ -624,26 +622,26 @@ public class IndicesOptionsIntegrationIT extends ESIntegTestCase {
         assertThat(client().admin().indices().prepareGetWarmers("foobar").setWarmers("warmer1").get().getWarmers().size(), equalTo(1));
 
     }
-
+    
     @Test
     public void testPutWarmer_wildcard() throws Exception {
         createIndex("foo", "foobar", "bar", "barbaz");
         ensureYellow();
 
         verify(client().admin().indices().preparePutWarmer("warmer1").setSearchRequest(client().prepareSearch().setIndices("foo*").setQuery(QueryBuilders.matchAllQuery())), false);
-
+        
         assertThat(client().admin().indices().prepareGetWarmers("foo").setWarmers("warmer1").get().getWarmers().size(), equalTo(1));
         assertThat(client().admin().indices().prepareGetWarmers("foobar").setWarmers("warmer1").get().getWarmers().size(), equalTo(1));
         assertThat(client().admin().indices().prepareGetWarmers("bar").setWarmers("warmer1").get().getWarmers().size(), equalTo(0));
         assertThat(client().admin().indices().prepareGetWarmers("barbaz").setWarmers("warmer1").get().getWarmers().size(), equalTo(0));
 
         verify(client().admin().indices().preparePutWarmer("warmer2").setSearchRequest(client().prepareSearch().setIndices().setQuery(QueryBuilders.matchAllQuery())), false);
-
+        
         assertThat(client().admin().indices().prepareGetWarmers("foo").setWarmers("warmer2").get().getWarmers().size(), equalTo(1));
         assertThat(client().admin().indices().prepareGetWarmers("foobar").setWarmers("warmer2").get().getWarmers().size(), equalTo(1));
         assertThat(client().admin().indices().prepareGetWarmers("bar").setWarmers("warmer2").get().getWarmers().size(), equalTo(1));
         assertThat(client().admin().indices().prepareGetWarmers("barbaz").setWarmers("warmer2").get().getWarmers().size(), equalTo(1));
-
+        
     }
 
     @Test
@@ -654,7 +652,7 @@ public class IndicesOptionsIntegrationIT extends ESIntegTestCase {
         assertThat(client().admin().indices().prepareAliasesExist("foobar_alias").setIndices("foobar").get().exists(), equalTo(true));
 
     }
-
+    
     @Test
     public void testPutAlias_wildcard() throws Exception {
         createIndex("foo", "foobar", "bar", "barbaz");
@@ -671,13 +669,14 @@ public class IndicesOptionsIntegrationIT extends ESIntegTestCase {
         assertThat(client().admin().indices().prepareAliasesExist("foobar_alias").setIndices("foobar").get().exists(), equalTo(true));
         assertThat(client().admin().indices().prepareAliasesExist("foobar_alias").setIndices("bar").get().exists(), equalTo(true));
         assertThat(client().admin().indices().prepareAliasesExist("foobar_alias").setIndices("barbaz").get().exists(), equalTo(true));
-
+        
     }
-
+    
     @Test
     public void testDeleteWarmer() throws Exception {
-        SearchSourceBuilder source = new SearchSourceBuilder();
-        IndexWarmersMetaData.Entry entry = new IndexWarmersMetaData.Entry("test1", new String[] { "typ1" }, false, source);
+        IndexWarmersMetaData.Entry entry = new IndexWarmersMetaData.Entry(
+                "test1", new String[]{"typ1"}, false, new BytesArray("{\"query\" : { \"match_all\" : {}}}")
+        );
         assertAcked(prepareCreate("foobar").addCustom(new IndexWarmersMetaData(entry)));
         ensureYellow();
 
@@ -691,8 +690,9 @@ public class IndicesOptionsIntegrationIT extends ESIntegTestCase {
     public void testDeleteWarmer_wildcard() throws Exception {
         verify(client().admin().indices().prepareDeleteWarmer().setIndices("_all").setNames("test1"), true);
 
-        SearchSourceBuilder source = new SearchSourceBuilder();
-        IndexWarmersMetaData.Entry entry = new IndexWarmersMetaData.Entry("test1", new String[] { "type1" }, false, source);
+        IndexWarmersMetaData.Entry entry = new IndexWarmersMetaData.Entry(
+                "test1", new String[]{"type1"}, false, new BytesArray("{\"query\" : { \"match_all\" : {}}}")
+        );
         assertAcked(prepareCreate("foo").addCustom(new IndexWarmersMetaData(entry)));
         assertAcked(prepareCreate("foobar").addCustom(new IndexWarmersMetaData(entry)));
         assertAcked(prepareCreate("bar").addCustom(new IndexWarmersMetaData(entry)));
@@ -737,7 +737,7 @@ public class IndicesOptionsIntegrationIT extends ESIntegTestCase {
         assertThat(client().admin().indices().prepareGetMappings("foobar").get().mappings().get("foobar").get("type3"), notNullValue());
         assertThat(client().admin().indices().prepareGetMappings("bar").get().mappings().get("bar").get("type3"), notNullValue());
         assertThat(client().admin().indices().prepareGetMappings("barbaz").get().mappings().get("barbaz").get("type3"), notNullValue());
-
+        
 
         verify(client().admin().indices().preparePutMapping("c*").setType("type1").setSource("field", "type=string"), true);
 
@@ -883,7 +883,7 @@ public class IndicesOptionsIntegrationIT extends ESIntegTestCase {
     private static void verify(ActionRequestBuilder requestBuilder, boolean fail) {
         verify(requestBuilder, fail, 0);
     }
-
+    
     private static void verify(ActionRequestBuilder requestBuilder, boolean fail, long expectedCount) {
         if (fail) {
             if (requestBuilder instanceof MultiSearchRequestBuilder) {
diff --git a/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java b/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
index ed31a54..5ddeeaf 100644
--- a/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
+++ b/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java
@@ -45,9 +45,8 @@ import org.elasticsearch.index.percolator.PercolatorException;
 import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.QueryShardException;
-import org.elasticsearch.index.query.support.QueryInnerHits;
-import org.elasticsearch.common.ParsingException;
 import org.elasticsearch.index.query.functionscore.weight.WeightBuilder;
+import org.elasticsearch.index.query.support.QueryInnerHits;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.highlight.HighlightBuilder;
@@ -1421,7 +1420,7 @@ public class PercolatorIT extends ESIntegTestCase {
                 .setSize(5)
                 .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field("field1", "The quick brown fox jumps over the lazy dog").endObject()))
                 .setHighlightBuilder(new HighlightBuilder().field("field1"))
-                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new WeightBuilder().setWeight(5.5f)))
+                .setPercolateQuery(functionScoreQuery(new WeightBuilder().setWeight(5.5f)))
                 .setScore(true)
                 .execute().actionGet();
         assertNoFailures(response);
@@ -1453,7 +1452,7 @@ public class PercolatorIT extends ESIntegTestCase {
                 .setSize(5)
                 .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field("field1", "The quick brown fox jumps over the lazy dog").endObject()))
                 .setHighlightBuilder(new HighlightBuilder().field("field1"))
-                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new WeightBuilder().setWeight(5.5f)))
+                .setPercolateQuery(functionScoreQuery(new WeightBuilder().setWeight(5.5f)))
                 .setSortByScore(true)
                 .execute().actionGet();
         assertMatchCount(response, 5l);
@@ -1485,7 +1484,7 @@ public class PercolatorIT extends ESIntegTestCase {
                 .setSize(5)
                 .setPercolateDoc(docBuilder().setDoc(jsonBuilder().startObject().field("field1", "The quick brown fox jumps over the lazy dog").endObject()))
                 .setHighlightBuilder(new HighlightBuilder().field("field1").highlightQuery(QueryBuilders.matchQuery("field1", "jumps")))
-                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new WeightBuilder().setWeight(5.5f)))
+                .setPercolateQuery(functionScoreQuery(new WeightBuilder().setWeight(5.5f)))
                 .setSortByScore(true)
                 .execute().actionGet();
         assertMatchCount(response, 5l);
@@ -1522,7 +1521,7 @@ public class PercolatorIT extends ESIntegTestCase {
                 .setSize(5)
                 .setGetRequest(Requests.getRequest("test").type("type").id("1"))
                 .setHighlightBuilder(new HighlightBuilder().field("field1"))
-                .setPercolateQuery(functionScoreQuery(matchAllQuery()).add(new WeightBuilder().setWeight(5.5f)))
+                .setPercolateQuery(functionScoreQuery(new WeightBuilder().setWeight(5.5f)))
                 .setSortByScore(true)
                 .execute().actionGet();
         assertMatchCount(response, 5l);
diff --git a/core/src/test/java/org/elasticsearch/script/GroovyScriptIT.java b/core/src/test/java/org/elasticsearch/script/GroovyScriptIT.java
index 2f3ed9d..320b000 100644
--- a/core/src/test/java/org/elasticsearch/script/GroovyScriptIT.java
+++ b/core/src/test/java/org/elasticsearch/script/GroovyScriptIT.java
@@ -22,6 +22,7 @@ package org.elasticsearch.script;
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.lucene.search.function.CombineFunction;
 import org.elasticsearch.script.ScriptService.ScriptType;
 import org.elasticsearch.script.groovy.GroovyScriptEngineService;
@@ -31,15 +32,9 @@ import org.junit.Test;
 import java.util.ArrayList;
 import java.util.List;
 
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
-import static org.elasticsearch.index.query.QueryBuilders.scriptQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertOrderedSearchHits;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHits;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.hamcrest.Matchers.equalTo;
 
 /**
@@ -58,11 +53,11 @@ public class GroovyScriptIT extends ESIntegTestCase {
     }
 
     public void assertScript(String script) {
-        // SearchResponse resp = client().prepareSearch("test")
-        // .setSource(new BytesArray("{\"query\": {\"match_all\": {}}," +
-        // "\"sort\":{\"_script\": {\"script\": \""+ script +
-        // "; 1\", \"type\": \"number\", \"lang\": \"groovy\"}}}")).get();
-        // assertNoFailures(resp); NOCOMMIT fix this
+        SearchResponse resp = client().prepareSearch("test")
+                .setSource(new BytesArray("{\"query\": {\"match_all\": {}}," +
+                        "\"sort\":{\"_script\": {\"script\": \""+ script +
+                        "; 1\", \"type\": \"number\", \"lang\": \"groovy\"}}}")).get();
+        assertNoFailures(resp);
     }
 
     @Test
@@ -109,15 +104,13 @@ public class GroovyScriptIT extends ESIntegTestCase {
         refresh();
 
         // doc[] access
-        SearchResponse resp = client().prepareSearch("test").setQuery(functionScoreQuery(matchAllQuery())
-.add(
-                                scriptFunction(new Script("doc['bar'].value", ScriptType.INLINE, "groovy", null)))
+        SearchResponse resp = client().prepareSearch("test").setQuery(functionScoreQuery(scriptFunction(new Script("doc['bar'].value", ScriptType.INLINE, "groovy", null)))
             .boostMode(CombineFunction.REPLACE)).get();
 
         assertNoFailures(resp);
         assertOrderedSearchHits(resp, "3", "2", "1");
     }
-
+    
     public void testScoreAccess() {
         client().prepareIndex("test", "doc", "1").setSource("foo", "quick brow fox jumped over the lazy dog", "bar", 1).get();
         client().prepareIndex("test", "doc", "2").setSource("foo", "fast jumping spiders", "bar", 2).get();
@@ -125,8 +118,8 @@ public class GroovyScriptIT extends ESIntegTestCase {
         refresh();
 
         // _score can be accessed
-        SearchResponse resp = client().prepareSearch("test").setQuery(functionScoreQuery(matchQuery("foo", "dog"))
-            .add(scriptFunction(new Script("_score", ScriptType.INLINE, "groovy", null)))
+        SearchResponse resp = client().prepareSearch("test").setQuery(functionScoreQuery(matchQuery("foo", "dog"),
+                scriptFunction(new Script("_score", ScriptType.INLINE, "groovy", null)))
             .boostMode(CombineFunction.REPLACE)).get();
         assertNoFailures(resp);
         assertSearchHits(resp, "3", "1");
@@ -137,7 +130,7 @@ public class GroovyScriptIT extends ESIntegTestCase {
         resp = client()
                 .prepareSearch("test")
                 .setQuery(
-                        functionScoreQuery(matchQuery("foo", "dog")).add(
+                        functionScoreQuery(matchQuery("foo", "dog"),
                                 scriptFunction(new Script("_score > 0.0 ? _score : 0", ScriptType.INLINE, "groovy", null))).boostMode(
                                 CombineFunction.REPLACE)).get();
         assertNoFailures(resp);
diff --git a/core/src/test/java/org/elasticsearch/script/GroovySecurityIT.java b/core/src/test/java/org/elasticsearch/script/GroovySecurityIT.java
index f7bcd23..5ec89a6 100644
--- a/core/src/test/java/org/elasticsearch/script/GroovySecurityIT.java
+++ b/core/src/test/java/org/elasticsearch/script/GroovySecurityIT.java
@@ -108,30 +108,30 @@ public class GroovySecurityIT extends ESIntegTestCase {
 
     private void assertSuccess(String script) {
         logger.info("--> script: " + script);
-//        SearchResponse resp = client().prepareSearch("test")
-//                .setSource(new BytesArray("{\"query\": {\"match_all\": {}}," +
-//                        "\"sort\":{\"_script\": {\"script\": \"" + script +
-//                        "; doc['foo'].value + 2\", \"type\": \"number\", \"lang\": \"groovy\"}}}")).get();
-//        assertNoFailures(resp);
-//        assertEquals(1, resp.getHits().getTotalHits());
-//        assertThat(resp.getHits().getAt(0).getSortValues(), equalTo(new Object[]{7.0})); NOCOMMIT fix this
+        SearchResponse resp = client().prepareSearch("test")
+                .setSource(new BytesArray("{\"query\": {\"match_all\": {}}," +
+                        "\"sort\":{\"_script\": {\"script\": \"" + script +
+                        "; doc['foo'].value + 2\", \"type\": \"number\", \"lang\": \"groovy\"}}}")).get();
+        assertNoFailures(resp);
+        assertEquals(1, resp.getHits().getTotalHits());
+        assertThat(resp.getHits().getAt(0).getSortValues(), equalTo(new Object[]{7.0}));
     }
 
     private void assertFailure(String script) {
         logger.info("--> script: " + script);
-//        SearchResponse resp = client().prepareSearch("test")
-//                 .setSource(new BytesArray("{\"query\": {\"match_all\": {}}," +
-//                         "\"sort\":{\"_script\": {\"script\": \"" + script +
-//                         "; doc['foo'].value + 2\", \"type\": \"number\", \"lang\": \"groovy\"}}}")).get();
-//        assertEquals(0, resp.getHits().getTotalHits());
-//        ShardSearchFailure fails[] = resp.getShardFailures();
-//        // TODO: GroovyScriptExecutionException needs work:
-//        // fix it to preserve cause so we don't do this flaky string-check stuff
-//        for (ShardSearchFailure fail : fails) {
-//            assertThat(fail.getCause(), instanceOf(GroovyScriptExecutionException.class));
-//            assertTrue("unexpected exception" + fail.getCause(),
-//                       // different casing, depending on jvm impl...
-//                       fail.getCause().toString().toLowerCase(Locale.ROOT).contains("[access denied"));
-//        } NOCOMMIT fix this
+        SearchResponse resp = client().prepareSearch("test")
+                 .setSource(new BytesArray("{\"query\": {\"match_all\": {}}," +
+                         "\"sort\":{\"_script\": {\"script\": \"" + script +
+                         "; doc['foo'].value + 2\", \"type\": \"number\", \"lang\": \"groovy\"}}}")).get();
+        assertEquals(0, resp.getHits().getTotalHits());
+        ShardSearchFailure fails[] = resp.getShardFailures();
+        // TODO: GroovyScriptExecutionException needs work:
+        // fix it to preserve cause so we don't do this flaky string-check stuff
+        for (ShardSearchFailure fail : fails) {
+            assertThat(fail.getCause(), instanceOf(GroovyScriptExecutionException.class));
+            assertTrue("unexpected exception" + fail.getCause(),
+                       // different casing, depending on jvm impl...
+                       fail.getCause().toString().toLowerCase(Locale.ROOT).contains("[access denied"));
+        }
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/script/IndexedScriptIT.java b/core/src/test/java/org/elasticsearch/script/IndexedScriptIT.java
index bae6d7e..d82ae3d 100644
--- a/core/src/test/java/org/elasticsearch/script/IndexedScriptIT.java
+++ b/core/src/test/java/org/elasticsearch/script/IndexedScriptIT.java
@@ -82,12 +82,12 @@ public class IndexedScriptIT extends ESIntegTestCase {
 
         indexRandom(true, builders);
         String query = "{ \"query\" : { \"match_all\": {}} , \"script_fields\" : { \"test1\" : { \"script_id\" : \"script1\", \"lang\":\"groovy\" }, \"test2\" : { \"script_id\" : \"script2\", \"lang\":\"groovy\", \"params\":{\"factor\":3}  }}, size:1}";
-//        SearchResponse searchResponse = client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
-//        assertHitCount(searchResponse, 5);
-//        assertTrue(searchResponse.getHits().hits().length == 1);
-//        SearchHit sh = searchResponse.getHits().getAt(0);
-//        assertThat((Integer)sh.field("test1").getValue(), equalTo(2));
-//        assertThat((Integer)sh.field("test2").getValue(), equalTo(6)); NOCOMMIT fix this
+        SearchResponse searchResponse = client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
+        assertHitCount(searchResponse, 5);
+        assertTrue(searchResponse.getHits().hits().length == 1);
+        SearchHit sh = searchResponse.getHits().getAt(0);
+        assertThat((Integer)sh.field("test1").getValue(), equalTo(2));
+        assertThat((Integer)sh.field("test2").getValue(), equalTo(6));
     }
 
     // Relates to #10397
@@ -107,10 +107,10 @@ public class IndexedScriptIT extends ESIntegTestCase {
             String query = "{"
                     + " \"query\" : { \"match_all\": {}}, "
                     + " \"script_fields\" : { \"test_field\" : { \"script_id\" : \"script1\", \"lang\":\"groovy\" } } }";    
-//            SearchResponse searchResponse = client().prepareSearch().setSource(new BytesArray(query)).setIndices("test_index").setTypes("test_type").get();
-//            assertHitCount(searchResponse, 1);
-//            SearchHit sh = searchResponse.getHits().getAt(0);
-//            assertThat((Integer)sh.field("test_field").getValue(), equalTo(i)); NOCOMMIT fix this
+            SearchResponse searchResponse = client().prepareSearch().setSource(new BytesArray(query)).setIndices("test_index").setTypes("test_type").get();
+            assertHitCount(searchResponse, 1);
+            SearchHit sh = searchResponse.getHits().getAt(0);
+            assertThat((Integer)sh.field("test_field").getValue(), equalTo(i));
         }
     }
 
@@ -144,9 +144,9 @@ public class IndexedScriptIT extends ESIntegTestCase {
         client().prepareIndex("test", "scriptTest", "1").setSource("{\"theField\":\"foo\"}").get();
         refresh();
         String source = "{\"aggs\": {\"test\": { \"terms\" : { \"script_id\":\"script1\" } } } }";
-//        SearchResponse searchResponse = client().prepareSearch("test").setSource(new BytesArray(source)).get();
-//        assertHitCount(searchResponse, 1);
-//        assertThat(searchResponse.getAggregations().get("test"), notNullValue()); NOCOMMIT fix this
+        SearchResponse searchResponse = client().prepareSearch("test").setSource(new BytesArray(source)).get();
+        assertHitCount(searchResponse, 1);
+        assertThat(searchResponse.getAggregations().get("test"), notNullValue());
     }
 
     @Test
@@ -165,18 +165,18 @@ public class IndexedScriptIT extends ESIntegTestCase {
             assertThat(e.getMessage(), containsString("failed to execute script"));
             assertThat(e.getCause().getMessage(), containsString("scripts of type [indexed], operation [update] and lang [expression] are disabled"));
         }
-//        try {
-//            String query = "{ \"script_fields\" : { \"test1\" : { \"script_id\" : \"script1\", \"lang\":\"expression\" }}}";
-//            client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
-//            fail("search script should have been rejected");
-//        } catch(Exception e) {
-//            assertThat(e.toString(), containsString("scripts of type [indexed], operation [search] and lang [expression] are disabled"));
-//        }
-//        try {
-//            String source = "{\"aggs\": {\"test\": { \"terms\" : { \"script_id\":\"script1\", \"script_lang\":\"expression\" } } } }";
-//            client().prepareSearch("test").setSource(new BytesArray(source)).get();
-//        } catch(Exception e) {
-//            assertThat(e.toString(), containsString("scripts of type [indexed], operation [aggs] and lang [expression] are disabled"));
-//        } NOCOMMIT fix this
+        try {
+            String query = "{ \"script_fields\" : { \"test1\" : { \"script_id\" : \"script1\", \"lang\":\"expression\" }}}";
+            client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
+            fail("search script should have been rejected");
+        } catch(Exception e) {
+            assertThat(e.toString(), containsString("scripts of type [indexed], operation [search] and lang [expression] are disabled"));
+        }
+        try {
+            String source = "{\"aggs\": {\"test\": { \"terms\" : { \"script_id\":\"script1\", \"script_lang\":\"expression\" } } } }";
+            client().prepareSearch("test").setSource(new BytesArray(source)).get();
+        } catch(Exception e) {
+            assertThat(e.toString(), containsString("scripts of type [indexed], operation [aggs] and lang [expression] are disabled"));
+        }
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/script/OnDiskScriptIT.java b/core/src/test/java/org/elasticsearch/script/OnDiskScriptIT.java
index e28c927..617ae01 100644
--- a/core/src/test/java/org/elasticsearch/script/OnDiskScriptIT.java
+++ b/core/src/test/java/org/elasticsearch/script/OnDiskScriptIT.java
@@ -63,12 +63,12 @@ public class OnDiskScriptIT extends ESIntegTestCase {
         indexRandom(true, builders);
 
         String query = "{ \"query\" : { \"match_all\": {}} , \"script_fields\" : { \"test1\" : { \"script_file\" : \"script1\" }, \"test2\" : { \"script_file\" : \"script2\", \"params\":{\"factor\":3}  }}, size:1}";
-//        SearchResponse searchResponse = client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
-//        assertHitCount(searchResponse, 5);
-//        assertTrue(searchResponse.getHits().hits().length == 1);
-//        SearchHit sh = searchResponse.getHits().getAt(0);
-//        assertThat((Integer)sh.field("test1").getValue(), equalTo(2));
-//        assertThat((Integer)sh.field("test2").getValue(), equalTo(6)); NOCOMMIT fix this
+        SearchResponse searchResponse = client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
+        assertHitCount(searchResponse, 5);
+        assertTrue(searchResponse.getHits().hits().length == 1);
+        SearchHit sh = searchResponse.getHits().getAt(0);
+        assertThat((Integer)sh.field("test1").getValue(), equalTo(2));
+        assertThat((Integer)sh.field("test2").getValue(), equalTo(6));
     }
 
     @Test
@@ -82,12 +82,12 @@ public class OnDiskScriptIT extends ESIntegTestCase {
         indexRandom(true, builders);
 
         String query = "{ \"query\" : { \"match_all\": {}} , \"script_fields\" : { \"test1\" : { \"script_file\" : \"script1\" }, \"test2\" : { \"script_file\" : \"script1\", \"lang\":\"expression\"  }}, size:1}";
-//        SearchResponse searchResponse = client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
-//        assertHitCount(searchResponse, 5);
-//        assertTrue(searchResponse.getHits().hits().length == 1);
-//        SearchHit sh = searchResponse.getHits().getAt(0);
-//        assertThat((Integer)sh.field("test1").getValue(), equalTo(2));
-//        assertThat((Double)sh.field("test2").getValue(), equalTo(10d)); NOCOMMIT fix this
+        SearchResponse searchResponse = client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
+        assertHitCount(searchResponse, 5);
+        assertTrue(searchResponse.getHits().hits().length == 1);
+        SearchHit sh = searchResponse.getHits().getAt(0);
+        assertThat((Integer)sh.field("test1").getValue(), equalTo(2));
+        assertThat((Double)sh.field("test2").getValue(), equalTo(10d));
     }
 
     @Test
@@ -103,19 +103,19 @@ public class OnDiskScriptIT extends ESIntegTestCase {
         indexRandom(true, builders);
 
         String source = "{\"aggs\": {\"test\": { \"terms\" : { \"script_file\":\"script1\", \"lang\": \"expression\" } } } }";
-//        try {
-//            client().prepareSearch("test").setSource(new BytesArray(source)).get();
-//            fail("aggs script should have been rejected");
-//        } catch(Exception e) {
-//            assertThat(e.toString(), containsString("scripts of type [file], operation [aggs] and lang [expression] are disabled"));
-//        }
-//
-//        String query = "{ \"query\" : { \"match_all\": {}} , \"script_fields\" : { \"test1\" : { \"script_file\" : \"script1\", \"lang\":\"expression\" }}, size:1}";
-//        SearchResponse searchResponse = client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
-//        assertHitCount(searchResponse, 5);
-//        assertTrue(searchResponse.getHits().hits().length == 1);
-//        SearchHit sh = searchResponse.getHits().getAt(0);
-//        assertThat((Double)sh.field("test1").getValue(), equalTo(10d)); NOCOMMIT fix this
+        try {
+            client().prepareSearch("test").setSource(new BytesArray(source)).get();
+            fail("aggs script should have been rejected");
+        } catch(Exception e) {
+            assertThat(e.toString(), containsString("scripts of type [file], operation [aggs] and lang [expression] are disabled"));
+        }
+
+        String query = "{ \"query\" : { \"match_all\": {}} , \"script_fields\" : { \"test1\" : { \"script_file\" : \"script1\", \"lang\":\"expression\" }}, size:1}";
+        SearchResponse searchResponse = client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
+        assertHitCount(searchResponse, 5);
+        assertTrue(searchResponse.getHits().hits().length == 1);
+        SearchHit sh = searchResponse.getHits().getAt(0);
+        assertThat((Double)sh.field("test1").getValue(), equalTo(10d));
     }
 
     @Test
@@ -124,27 +124,27 @@ public class OnDiskScriptIT extends ESIntegTestCase {
         client().prepareIndex("test", "scriptTest", "1").setSource("{\"theField\":\"foo\"}").get();
         refresh();
         String source = "{\"aggs\": {\"test\": { \"terms\" : { \"script_file\":\"script1\", \"lang\": \"mustache\" } } } }";
-//        try {
-//            client().prepareSearch("test").setSource(new BytesArray(source)).get();
-//            fail("aggs script should have been rejected");
-//        } catch(Exception e) {
-//            assertThat(e.toString(), containsString("scripts of type [file], operation [aggs] and lang [mustache] are disabled"));
-//        }
-//        String query = "{ \"query\" : { \"match_all\": {}} , \"script_fields\" : { \"test1\" : { \"script_file\" : \"script1\", \"lang\":\"mustache\" }}, size:1}";
-//        try {
-//            client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
-//            fail("search script should have been rejected");
-//        } catch(Exception e) {
-//            assertThat(e.toString(), containsString("scripts of type [file], operation [search] and lang [mustache] are disabled"));
-//        }
-//        try {
-//            client().prepareUpdate("test", "scriptTest", "1")
-//                    .setScript(new Script("script1", ScriptService.ScriptType.FILE, MustacheScriptEngineService.NAME, null)).get();
-//            fail("update script should have been rejected");
-//        } catch (Exception e) {
-//            assertThat(e.getMessage(), containsString("failed to execute script"));
-//            assertThat(e.getCause().getMessage(), containsString("scripts of type [file], operation [update] and lang [mustache] are disabled"));
-//        } NOCOMMIT fix this
+        try {
+            client().prepareSearch("test").setSource(new BytesArray(source)).get();
+            fail("aggs script should have been rejected");
+        } catch(Exception e) {
+            assertThat(e.toString(), containsString("scripts of type [file], operation [aggs] and lang [mustache] are disabled"));
+        }
+        String query = "{ \"query\" : { \"match_all\": {}} , \"script_fields\" : { \"test1\" : { \"script_file\" : \"script1\", \"lang\":\"mustache\" }}, size:1}";
+        try {
+            client().prepareSearch().setSource(new BytesArray(query)).setIndices("test").setTypes("scriptTest").get();
+            fail("search script should have been rejected");
+        } catch(Exception e) {
+            assertThat(e.toString(), containsString("scripts of type [file], operation [search] and lang [mustache] are disabled"));
+        }
+        try {
+            client().prepareUpdate("test", "scriptTest", "1")
+                    .setScript(new Script("script1", ScriptService.ScriptType.FILE, MustacheScriptEngineService.NAME, null)).get();
+            fail("update script should have been rejected");
+        } catch (Exception e) {
+            assertThat(e.getMessage(), containsString("failed to execute script"));
+            assertThat(e.getCause().getMessage(), containsString("scripts of type [file], operation [update] and lang [mustache] are disabled"));
+        }
     }
 
 }
diff --git a/core/src/test/java/org/elasticsearch/script/expression/ExpressionScriptIT.java b/core/src/test/java/org/elasticsearch/script/expression/ExpressionScriptIT.java
index 25cb22d..7d5b2f8 100644
--- a/core/src/test/java/org/elasticsearch/script/expression/ExpressionScriptIT.java
+++ b/core/src/test/java/org/elasticsearch/script/expression/ExpressionScriptIT.java
@@ -27,6 +27,7 @@ import org.elasticsearch.action.search.SearchRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.action.update.UpdateRequestBuilder;
+import org.elasticsearch.common.lucene.search.function.CombineFunction;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.query.QueryBuilders;
@@ -106,7 +107,7 @@ public class ExpressionScriptIT extends ESIntegTestCase {
                 client().prepareIndex("test", "doc", "3").setSource("text", "hello hello goodebye"));
         ScoreFunctionBuilder score = ScoreFunctionBuilders.scriptFunction(new Script("1 / _score", ScriptType.INLINE, "expression", null));
         SearchRequestBuilder req = client().prepareSearch().setIndices("test");
-        req.setQuery(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("text", "hello"), score).boostMode("replace"));
+        req.setQuery(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("text", "hello"), score).boostMode(CombineFunction.REPLACE));
         req.setSearchType(SearchType.DFS_QUERY_THEN_FETCH); // make sure DF is consistent
         SearchResponse rsp = req.get();
         assertSearchResponse(rsp);
diff --git a/core/src/test/java/org/elasticsearch/search/MultiValueModeTests.java b/core/src/test/java/org/elasticsearch/search/MultiValueModeTests.java
index 5bf1a0e..a84bc09 100644
--- a/core/src/test/java/org/elasticsearch/search/MultiValueModeTests.java
+++ b/core/src/test/java/org/elasticsearch/search/MultiValueModeTests.java
@@ -24,6 +24,8 @@ import org.apache.lucene.index.*;
 import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
+import org.elasticsearch.common.io.stream.BytesStreamOutput;
+import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.index.fielddata.FieldData;
 import org.elasticsearch.index.fielddata.NumericDoubleValues;
 import org.elasticsearch.index.fielddata.SortedBinaryDocValues;
@@ -33,6 +35,8 @@ import org.elasticsearch.test.ESTestCase;
 import java.io.IOException;
 import java.util.Arrays;
 
+import static org.hamcrest.Matchers.equalTo;
+
 public class MultiValueModeTests extends ESTestCase {
 
     private static FixedBitSet randomRootDocs(int maxDoc) {
@@ -733,4 +737,94 @@ public class MultiValueModeTests extends ESTestCase {
             }
         }
     }
+
+    public void testValidOrdinals() {
+        assertThat(MultiValueMode.SUM.ordinal(), equalTo(0));
+        assertThat(MultiValueMode.AVG.ordinal(), equalTo(1));
+        assertThat(MultiValueMode.MEDIAN.ordinal(), equalTo(2));
+        assertThat(MultiValueMode.MIN.ordinal(), equalTo(3));
+        assertThat(MultiValueMode.MAX.ordinal(), equalTo(4));
+    }
+
+    public void testWriteTo() throws Exception {
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            MultiValueMode.SUM.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(0));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            MultiValueMode.AVG.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(1));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            MultiValueMode.MEDIAN.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(2));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            MultiValueMode.MIN.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(3));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            MultiValueMode.MAX.writeTo(out);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(in.readVInt(), equalTo(4));
+            }
+        }
+    }
+
+    public void testReadFrom() throws Exception {
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(0);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(MultiValueMode.readMultiValueModeFrom(in), equalTo(MultiValueMode.SUM));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(1);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(MultiValueMode.readMultiValueModeFrom(in), equalTo(MultiValueMode.AVG));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(2);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(MultiValueMode.readMultiValueModeFrom(in), equalTo(MultiValueMode.MEDIAN));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(3);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(MultiValueMode.readMultiValueModeFrom(in), equalTo(MultiValueMode.MIN));
+            }
+        }
+
+        try (BytesStreamOutput out = new BytesStreamOutput()) {
+            out.writeVInt(4);
+            try (StreamInput in = StreamInput.wrap(out.bytes())) {
+                assertThat(MultiValueMode.readMultiValueModeFrom(in), equalTo(MultiValueMode.MAX));
+            }
+        }
+    }
+
+    public void testFromString() {
+        assertThat(MultiValueMode.fromString("sum"), equalTo(MultiValueMode.SUM));
+        assertThat(MultiValueMode.fromString("avg"), equalTo(MultiValueMode.AVG));
+        assertThat(MultiValueMode.fromString("median"), equalTo(MultiValueMode.MEDIAN));
+        assertThat(MultiValueMode.fromString("min"), equalTo(MultiValueMode.MIN));
+        assertThat(MultiValueMode.fromString("max"), equalTo(MultiValueMode.MAX));
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/AggregationsBinaryIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/AggregationsBinaryIT.java
index e5634fe..631f705 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/AggregationsBinaryIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/AggregationsBinaryIT.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.search.aggregations;
 
-import org.apache.lucene.util.LuceneTestCase.AwaitsFix;
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.client.Requests;
@@ -42,8 +41,6 @@ import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.core.IsNull.notNullValue;
 
 @ESIntegTestCase.SuiteScopeTestCase
-@AwaitsFix(bugUrl = "needs fixing after the search request refactor. Do we need agg binary?")
-// NO RELEASE
 public class AggregationsBinaryIT extends ESIntegTestCase {
 
     private static final String STRING_FIELD_NAME = "s_value";
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/ParsingIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/ParsingIT.java
index 87307c0..64f80d6 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/ParsingIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/ParsingIT.java
@@ -31,151 +31,150 @@ import java.util.regex.Pattern;
 
 public class ParsingIT extends ESIntegTestCase {
 
-    // NORELEASE move these tests to unit tests when aggs refactoring is done
-//    @Test(expected=SearchPhaseExecutionException.class)
-//    public void testTwoTypes() throws Exception {
-//        createIndex("idx");
-//        ensureGreen();
-//        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
-//            .startObject()
-//                .startObject("in_stock")
-//                    .startObject("filter")
-//                        .startObject("range")
-//                            .startObject("stock")
-//                                .field("gt", 0)
-//                            .endObject()
-//                        .endObject()
-//                    .endObject()
-//                    .startObject("terms")
-//                        .field("field", "stock")
-//                    .endObject()
-//                .endObject()
-//            .endObject()).execute().actionGet();
-//    }
-//
-//    @Test(expected=SearchPhaseExecutionException.class)
-//    public void testTwoAggs() throws Exception {
-//        createIndex("idx");
-//        ensureGreen();
-//        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
-//            .startObject()
-//                .startObject("by_date")
-//                    .startObject("date_histogram")
-//                        .field("field", "timestamp")
-//                        .field("interval", "month")
-//                    .endObject()
-//                    .startObject("aggs")
-//                        .startObject("tag_count")
-//                            .startObject("cardinality")
-//                                .field("field", "tag")
-//                            .endObject()
-//                        .endObject()
-//                    .endObject()
-//                    .startObject("aggs") // 2nd "aggs": illegal
-//                        .startObject("tag_count2")
-//                            .startObject("cardinality")
-//                                .field("field", "tag")
-//                            .endObject()
-//                        .endObject()
-//                    .endObject()
-//            .endObject()).execute().actionGet();
-//    }
-//
-//    @Test(expected=SearchPhaseExecutionException.class)
-//    public void testInvalidAggregationName() throws Exception {
-//
-//        Matcher matcher = Pattern.compile("[^\\[\\]>]+").matcher("");
-//        String name;
-//        SecureRandom rand = new SecureRandom();
-//        int len = randomIntBetween(1, 5);
-//        char[] word = new char[len];
-//        while(true) {
-//            for (int i = 0; i < word.length; i++) {
-//                word[i] = (char) rand.nextInt(127);
-//            }
-//            name = String.valueOf(word);
-//            if (!matcher.reset(name).matches()) {
-//                break;
-//            }
-//        }
-//
-//        createIndex("idx");
-//        ensureGreen();
-//        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
-//            .startObject()
-//                .startObject(name)
-//                    .startObject("filter")
-//                        .startObject("range")
-//                            .startObject("stock")
-//                                .field("gt", 0)
-//                            .endObject()
-//                        .endObject()
-//                    .endObject()
-//            .endObject()).execute().actionGet();
-//    }
-//
-//    @Test(expected=SearchPhaseExecutionException.class)
-//    public void testSameAggregationName() throws Exception {
-//        createIndex("idx");
-//        ensureGreen();
-//        final String name = RandomStrings.randomAsciiOfLength(getRandom(), 10);
-//        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
-//            .startObject()
-//                .startObject(name)
-//                    .startObject("terms")
-//                        .field("field", "a")
-//                    .endObject()
-//                .endObject()
-//                .startObject(name)
-//                    .startObject("terms")
-//                        .field("field", "b")
-//                    .endObject()
-//                .endObject()
-//            .endObject()).execute().actionGet();
-//    }
-//
-//    @Test(expected=SearchPhaseExecutionException.class)
-//    public void testMissingName() throws Exception {
-//        createIndex("idx");
-//        ensureGreen();
-//        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
-//            .startObject()
-//                .startObject("by_date")
-//                    .startObject("date_histogram")
-//                        .field("field", "timestamp")
-//                        .field("interval", "month")
-//                    .endObject()
-//                    .startObject("aggs")
-//                        // the aggregation name is missing
-//                        //.startObject("tag_count")
-//                            .startObject("cardinality")
-//                                .field("field", "tag")
-//                            .endObject()
-//                        //.endObject()
-//                    .endObject()
-//            .endObject()).execute().actionGet();
-//    }
-//
-//    @Test(expected=SearchPhaseExecutionException.class)
-//    public void testMissingType() throws Exception {
-//        createIndex("idx");
-//        ensureGreen();
-//        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
-//            .startObject()
-//                .startObject("by_date")
-//                    .startObject("date_histogram")
-//                        .field("field", "timestamp")
-//                        .field("interval", "month")
-//                    .endObject()
-//                    .startObject("aggs")
-//                        .startObject("tag_count")
-//                            // the aggregation type is missing
-//                            //.startObject("cardinality")
-//                                .field("field", "tag")
-//                            //.endObject()
-//                        .endObject()
-//                    .endObject()
-//            .endObject()).execute().actionGet();
-//    }
+    @Test(expected=SearchPhaseExecutionException.class)
+    public void testTwoTypes() throws Exception {
+        createIndex("idx");
+        ensureGreen();
+        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
+            .startObject()
+                .startObject("in_stock")
+                    .startObject("filter")
+                        .startObject("range")
+                            .startObject("stock")
+                                .field("gt", 0)
+                            .endObject()
+                        .endObject()
+                    .endObject()
+                    .startObject("terms")
+                        .field("field", "stock")
+                    .endObject()
+                .endObject()
+            .endObject()).execute().actionGet();
+    }
+
+    @Test(expected=SearchPhaseExecutionException.class)
+    public void testTwoAggs() throws Exception {
+        createIndex("idx");
+        ensureGreen();
+        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
+            .startObject()
+                .startObject("by_date")
+                    .startObject("date_histogram")
+                        .field("field", "timestamp")
+                        .field("interval", "month")
+                    .endObject()
+                    .startObject("aggs")
+                        .startObject("tag_count")
+                            .startObject("cardinality")
+                                .field("field", "tag")
+                            .endObject()
+                        .endObject()
+                    .endObject()
+                    .startObject("aggs") // 2nd "aggs": illegal
+                        .startObject("tag_count2")
+                            .startObject("cardinality")
+                                .field("field", "tag")
+                            .endObject()
+                        .endObject()
+                    .endObject()
+            .endObject()).execute().actionGet();
+    }
+
+    @Test(expected=SearchPhaseExecutionException.class)
+    public void testInvalidAggregationName() throws Exception {
+
+        Matcher matcher = Pattern.compile("[^\\[\\]>]+").matcher("");
+        String name;
+        SecureRandom rand = new SecureRandom();
+        int len = randomIntBetween(1, 5);
+        char[] word = new char[len];
+        while(true) {
+            for (int i = 0; i < word.length; i++) {
+                word[i] = (char) rand.nextInt(127);
+            }
+            name = String.valueOf(word);
+            if (!matcher.reset(name).matches()) {
+                break;
+            }
+        }
+
+        createIndex("idx");
+        ensureGreen();
+        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
+            .startObject()
+                .startObject(name)
+                    .startObject("filter")
+                        .startObject("range")
+                            .startObject("stock")
+                                .field("gt", 0)
+                            .endObject()
+                        .endObject()
+                    .endObject()
+            .endObject()).execute().actionGet();
+    }
+
+    @Test(expected=SearchPhaseExecutionException.class)
+    public void testSameAggregationName() throws Exception {
+        createIndex("idx");
+        ensureGreen();
+        final String name = RandomStrings.randomAsciiOfLength(getRandom(), 10);
+        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
+            .startObject()
+                .startObject(name)
+                    .startObject("terms")
+                        .field("field", "a")
+                    .endObject()
+                .endObject()
+                .startObject(name)
+                    .startObject("terms")
+                        .field("field", "b")
+                    .endObject()
+                .endObject()
+            .endObject()).execute().actionGet();
+    }
+
+    @Test(expected=SearchPhaseExecutionException.class)
+    public void testMissingName() throws Exception {
+        createIndex("idx");
+        ensureGreen();
+        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
+            .startObject()
+                .startObject("by_date")
+                    .startObject("date_histogram")
+                        .field("field", "timestamp")
+                        .field("interval", "month")
+                    .endObject()
+                    .startObject("aggs")
+                        // the aggregation name is missing
+                        //.startObject("tag_count")
+                            .startObject("cardinality")
+                                .field("field", "tag")
+                            .endObject()
+                        //.endObject()
+                    .endObject()
+            .endObject()).execute().actionGet();
+    }
+
+    @Test(expected=SearchPhaseExecutionException.class)
+    public void testMissingType() throws Exception {
+        createIndex("idx");
+        ensureGreen();
+        client().prepareSearch("idx").setAggregations(JsonXContent.contentBuilder()
+            .startObject()
+                .startObject("by_date")
+                    .startObject("date_histogram")
+                        .field("field", "timestamp")
+                        .field("interval", "month")
+                    .endObject()
+                    .startObject("aggs")
+                        .startObject("tag_count")
+                            // the aggregation type is missing
+                            //.startObject("cardinality")
+                                .field("field", "tag")
+                            //.endObject()
+                        .endObject()
+                    .endObject()
+            .endObject()).execute().actionGet();
+    }
 
 }
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsIT.java
index 2bb98c2..dbae3c1 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsIT.java
@@ -1201,8 +1201,7 @@ public class DoubleTermsIT extends AbstractTermsTestCase {
                 .prepareSearch("idx")
                 .setTypes("type")
                 .setQuery(
-                        functionScoreQuery(matchAllQuery()).add(
-                                ScoreFunctionBuilders.scriptFunction(new Script("doc['" + SINGLE_VALUED_FIELD_NAME + "'].value"))))
+                        functionScoreQuery(ScoreFunctionBuilders.scriptFunction(new Script("doc['" + SINGLE_VALUED_FIELD_NAME + "'].value"))))
                 .addAggregation(
                         terms("terms").collectMode(randomFrom(SubAggCollectionMode.values())).script(
                                 new Script("ceil(_score.doubleValue()/3)"))).execute().actionGet();
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/TopHitsIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/TopHitsIT.java
index e165f01..ffab844 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/TopHitsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/TopHitsIT.java
@@ -24,6 +24,7 @@ import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.action.search.SearchType;
+import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.script.Script;
@@ -526,7 +527,7 @@ public class TopHitsIT extends ESIntegTestCase {
                                 .field(TERMS_AGGS_FIELD)
                                 .subAggregation(
                                         topHits("hits").setSize(1)
-                                            .highlighter(new HighlightBuilder().field("text"))
+                                            .addHighlightedField("text")
                                             .setExplain(true)
                                             .addFieldDataField("field1")
                                                 .addScriptField("script", new Script("doc['field1'].value"))
@@ -589,39 +590,38 @@ public class TopHitsIT extends ESIntegTestCase {
         }
     }
 
-    // @Test
-    // public void testFailWithSubAgg() throws Exception {
-    // String source = "{\n" +
-    // "  \"aggs\": {\n" +
-    // "    \"top-tags\": {\n" +
-    // "      \"terms\": {\n" +
-    // "        \"field\": \"tags\"\n" +
-    // "      },\n" +
-    // "      \"aggs\": {\n" +
-    // "        \"top_tags_hits\": {\n" +
-    // "          \"top_hits\": {},\n" +
-    // "          \"aggs\": {\n" +
-    // "            \"max\": {\n" +
-    // "              \"max\": {\n" +
-    // "                \"field\": \"age\"\n" +
-    // "              }\n" +
-    // "            }\n" +
-    // "          }\n" +
-    // "        }\n" +
-    // "      }\n" +
-    // "    }\n" +
-    // "  }\n" +
-    // "}";
-    // try {
-    // client().prepareSearch("idx").setTypes("type")
-    // .setSource(new BytesArray(source))
-    // .get();
-    // fail();
-    // } catch (SearchPhaseExecutionException e) {
-    // assertThat(e.toString(),
-    // containsString("Aggregator [top_tags_hits] of type [top_hits] cannot accept sub-aggregations"));
-    // }
-    // } NOCOMMIT fix this
+    @Test
+    public void testFailWithSubAgg() throws Exception {
+        String source = "{\n" +
+                "  \"aggs\": {\n" +
+                "    \"top-tags\": {\n" +
+                "      \"terms\": {\n" +
+                "        \"field\": \"tags\"\n" +
+                "      },\n" +
+                "      \"aggs\": {\n" +
+                "        \"top_tags_hits\": {\n" +
+                "          \"top_hits\": {},\n" +
+                "          \"aggs\": {\n" +
+                "            \"max\": {\n" +
+                "              \"max\": {\n" +
+                "                \"field\": \"age\"\n" +
+                "              }\n" +
+                "            }\n" +
+                "          }\n" +
+                "        }\n" +
+                "      }\n" +
+                "    }\n" +
+                "  }\n" +
+                "}";
+        try {
+            client().prepareSearch("idx").setTypes("type")
+                    .setSource(new BytesArray(source))
+                            .get();
+            fail();
+        } catch (SearchPhaseExecutionException e) {
+            assertThat(e.toString(), containsString("Aggregator [top_tags_hits] of type [top_hits] cannot accept sub-aggregations"));
+        }
+    }
 
     @Test
     public void testEmptyIndex() throws Exception {
@@ -849,7 +849,7 @@ public class TopHitsIT extends ESIntegTestCase {
                 .setQuery(nestedQuery("comments", matchQuery("comments.message", "comment").queryName("test")))
                 .addAggregation(
                         nested("to-comments").path("comments").subAggregation(
-                                topHits("top-comments").setSize(1).highlighter(new HighlightBuilder().field(hlField)).setExplain(true)
+                                topHits("top-comments").setSize(1).addHighlightedField(hlField).setExplain(true)
                                                 .addFieldDataField("comments.user")
                                         .addScriptField("script", new Script("doc['comments.user'].value")).setFetchSource("message", null)
                                         .setVersion(true).addSort("comments.date", SortOrder.ASC))).get();
@@ -901,7 +901,7 @@ public class TopHitsIT extends ESIntegTestCase {
                                         nested("to-comments")
                                                 .path("comments")
                                                 .subAggregation(topHits("comments")
-                                                        .highlighter(new HighlightBuilder().field(new HighlightBuilder.Field("comments.message").highlightQuery(matchQuery("comments.message", "text"))))
+                                                        .addHighlightedField(new HighlightBuilder.Field("comments.message").highlightQuery(matchQuery("comments.message", "text")))
                                                         .addSort("comments.id", SortOrder.ASC))
                                 )
                 )
diff --git a/core/src/test/java/org/elasticsearch/search/basic/TransportSearchFailuresIT.java b/core/src/test/java/org/elasticsearch/search/basic/TransportSearchFailuresIT.java
index e6c21ae..e5cc0ee 100644
--- a/core/src/test/java/org/elasticsearch/search/basic/TransportSearchFailuresIT.java
+++ b/core/src/test/java/org/elasticsearch/search/basic/TransportSearchFailuresIT.java
@@ -64,18 +64,18 @@ public class TransportSearchFailuresIT extends ESIntegTestCase {
         assertThat(refreshResponse.getTotalShards(), equalTo(test.totalNumShards));
         assertThat(refreshResponse.getSuccessfulShards(), equalTo(test.numPrimaries));
         assertThat(refreshResponse.getFailedShards(), equalTo(0));
-//        for (int i = 0; i < 5; i++) {
-//            try {
-//                SearchResponse searchResponse = client().search(searchRequest("test").source(new BytesArray("{ xxx }"))).actionGet();
-//                assertThat(searchResponse.getTotalShards(), equalTo(test.numPrimaries));
-//                assertThat(searchResponse.getSuccessfulShards(), equalTo(0));
-//                assertThat(searchResponse.getFailedShards(), equalTo(test.numPrimaries));
-//                fail("search should fail");
-//            } catch (ElasticsearchException e) {
-//                assertThat(e.unwrapCause(), instanceOf(SearchPhaseExecutionException.class));
-//                // all is well
-//            }
-//        } NOCOMMIT fix this
+        for (int i = 0; i < 5; i++) {
+            try {
+                SearchResponse searchResponse = client().search(searchRequest("test").source(new BytesArray("{ xxx }"))).actionGet();
+                assertThat(searchResponse.getTotalShards(), equalTo(test.numPrimaries));
+                assertThat(searchResponse.getSuccessfulShards(), equalTo(0));
+                assertThat(searchResponse.getFailedShards(), equalTo(test.numPrimaries));
+                fail("search should fail");
+            } catch (ElasticsearchException e) {
+                assertThat(e.unwrapCause(), instanceOf(SearchPhaseExecutionException.class));
+                // all is well
+            }
+        }
 
         allowNodes("test", 2);
         assertThat(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForNodes(">=2").execute().actionGet().isTimedOut(), equalTo(false));
@@ -93,18 +93,18 @@ public class TransportSearchFailuresIT extends ESIntegTestCase {
         assertThat(refreshResponse.getSuccessfulShards(), equalTo(test.totalNumShards));
         assertThat(refreshResponse.getFailedShards(), equalTo(0));
 
-//        for (int i = 0; i < 5; i++) {
-//            try {
-//                SearchResponse searchResponse = client().search(searchRequest("test").source(new BytesArray("{ xxx }"))).actionGet();
-//                assertThat(searchResponse.getTotalShards(), equalTo(test.numPrimaries));
-//                assertThat(searchResponse.getSuccessfulShards(), equalTo(0));
-//                assertThat(searchResponse.getFailedShards(), equalTo(test.numPrimaries));
-//                fail("search should fail");
-//            } catch (ElasticsearchException e) {
-//                assertThat(e.unwrapCause(), instanceOf(SearchPhaseExecutionException.class));
-//                // all is well
-//            }
-//        } NOCOMMIT fix this
+        for (int i = 0; i < 5; i++) {
+            try {
+                SearchResponse searchResponse = client().search(searchRequest("test").source(new BytesArray("{ xxx }"))).actionGet();
+                assertThat(searchResponse.getTotalShards(), equalTo(test.numPrimaries));
+                assertThat(searchResponse.getSuccessfulShards(), equalTo(0));
+                assertThat(searchResponse.getFailedShards(), equalTo(test.numPrimaries));
+                fail("search should fail");
+            } catch (ElasticsearchException e) {
+                assertThat(e.unwrapCause(), instanceOf(SearchPhaseExecutionException.class));
+                // all is well
+            }
+        }
 
         logger.info("Done Testing failed search");
     }
diff --git a/core/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchIT.java b/core/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchIT.java
index 8048a1e..a9b41ce 100644
--- a/core/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchIT.java
@@ -52,6 +52,7 @@ import static org.elasticsearch.action.search.SearchType.DFS_QUERY_AND_FETCH;
 import static org.elasticsearch.action.search.SearchType.DFS_QUERY_THEN_FETCH;
 import static org.elasticsearch.action.search.SearchType.QUERY_AND_FETCH;
 import static org.elasticsearch.action.search.SearchType.QUERY_THEN_FETCH;
+
 import static org.elasticsearch.client.Requests.createIndexRequest;
 import static org.elasticsearch.client.Requests.searchRequest;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
@@ -369,25 +370,25 @@ public class TransportTwoNodesSearchIT extends ESIntegTestCase {
         assertThat(all.getDocCount(), equalTo(100l));
     }
 
-//    @Test
-//    public void testFailedSearchWithWrongQuery() throws Exception {
-//        prepareData();
-//
-//        NumShards test = getNumShards("test");
-//
-//        logger.info("Start Testing failed search with wrong query");
-//        try {
-//            SearchResponse searchResponse = client().search(searchRequest("test").source(new BytesArray("{ xxx }"))).actionGet();
-//            assertThat(searchResponse.getTotalShards(), equalTo(test.numPrimaries));
-//            assertThat(searchResponse.getSuccessfulShards(), equalTo(0));
-//            assertThat(searchResponse.getFailedShards(), equalTo(test.numPrimaries));
-//            fail("search should fail");
-//        } catch (ElasticsearchException e) {
-//            assertThat(e.unwrapCause(), instanceOf(SearchPhaseExecutionException.class));
-//            // all is well
-//        }
-//        logger.info("Done Testing failed search");
-//    } NOCOMMIT fix this
+    @Test
+    public void testFailedSearchWithWrongQuery() throws Exception {
+        prepareData();
+
+        NumShards test = getNumShards("test");
+
+        logger.info("Start Testing failed search with wrong query");
+        try {
+            SearchResponse searchResponse = client().search(searchRequest("test").source(new BytesArray("{ xxx }"))).actionGet();
+            assertThat(searchResponse.getTotalShards(), equalTo(test.numPrimaries));
+            assertThat(searchResponse.getSuccessfulShards(), equalTo(0));
+            assertThat(searchResponse.getFailedShards(), equalTo(test.numPrimaries));
+            fail("search should fail");
+        } catch (ElasticsearchException e) {
+            assertThat(e.unwrapCause(), instanceOf(SearchPhaseExecutionException.class));
+            // all is well
+        }
+        logger.info("Done Testing failed search");
+    }
 
     @Test
     public void testFailedSearchWithWrongFrom() throws Exception {
@@ -427,8 +428,8 @@ public class TransportTwoNodesSearchIT extends ESIntegTestCase {
         logger.info("Start Testing failed multi search with a wrong query");
 
         MultiSearchResponse response = client().prepareMultiSearch()
-                // Add function score with a bogus score mode
-                .add(client().prepareSearch("test").setQuery(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("nid", 1)).scoreMode("foobar")))
+                // Add geo distance range query against a field that doesn't exist (should be a geo point for the query to work)
+                .add(client().prepareSearch("test").setQuery(QueryBuilders.geoDistanceRangeQuery("non_existing_field", 1, 1).from(10).to(15)))
                 .add(client().prepareSearch("test").setQuery(QueryBuilders.termQuery("nid", 2)))
                 .add(client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery()))
                 .execute().actionGet();
@@ -444,7 +445,6 @@ public class TransportTwoNodesSearchIT extends ESIntegTestCase {
         logger.info("Done Testing failed search");
     }
 
-
     @Test
     public void testFailedMultiSearchWithWrongQuery_withFunctionScore() throws Exception {
         prepareData();
@@ -453,7 +453,7 @@ public class TransportTwoNodesSearchIT extends ESIntegTestCase {
 
         MultiSearchResponse response = client().prepareMultiSearch()
                 // Add custom score query with bogus script
-                .add(client().prepareSearch("test").setQuery(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("nid", 1)).add(new ScriptScoreFunctionBuilder(new Script("foo", ScriptService.ScriptType.INLINE, "bar", null)))))
+                .add(client().prepareSearch("test").setQuery(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("nid", 1), new ScriptScoreFunctionBuilder(new Script("foo", ScriptService.ScriptType.INLINE, "bar", null)))))
                 .add(client().prepareSearch("test").setQuery(QueryBuilders.termQuery("nid", 2)))
                 .add(client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery()))
                 .execute().actionGet();
diff --git a/core/src/test/java/org/elasticsearch/search/builder/NewSearchSourceBuilderTests.java b/core/src/test/java/org/elasticsearch/search/builder/NewSearchSourceBuilderTests.java
deleted file mode 100644
index b259e72..0000000
--- a/core/src/test/java/org/elasticsearch/search/builder/NewSearchSourceBuilderTests.java
+++ /dev/null
@@ -1,623 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.search.builder;
-
-import org.elasticsearch.Version;
-import org.elasticsearch.action.admin.indices.mapping.put.PutMappingRequest;
-import org.elasticsearch.action.get.GetRequest;
-import org.elasticsearch.action.get.GetResponse;
-import org.elasticsearch.action.support.PlainActionFuture;
-import org.elasticsearch.action.termvectors.MultiTermVectorsRequest;
-import org.elasticsearch.action.termvectors.MultiTermVectorsResponse;
-import org.elasticsearch.client.Client;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.ParseFieldMatcher;
-import org.elasticsearch.common.compress.CompressedXContent;
-import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.inject.Injector;
-import org.elasticsearch.common.inject.ModulesBuilder;
-import org.elasticsearch.common.inject.multibindings.Multibinder;
-import org.elasticsearch.common.inject.util.Providers;
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.NamedWriteableAwareStreamInput;
-import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.settings.SettingsModule;
-import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.env.Environment;
-import org.elasticsearch.env.EnvironmentModule;
-import org.elasticsearch.index.Index;
-import org.elasticsearch.index.IndexNameModule;
-import org.elasticsearch.index.analysis.AnalysisModule;
-import org.elasticsearch.index.cache.IndexCacheModule;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.mapper.MapperServiceModule;
-import org.elasticsearch.index.query.AbstractQueryTestCase;
-import org.elasticsearch.index.query.IndexQueryParserService;
-import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.QueryParseContext;
-import org.elasticsearch.index.query.QueryShardContext;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionParser;
-import org.elasticsearch.index.settings.IndexSettingsModule;
-import org.elasticsearch.index.similarity.SimilarityModule;
-import org.elasticsearch.indices.IndicesModule;
-import org.elasticsearch.indices.analysis.IndicesAnalysisService;
-import org.elasticsearch.indices.breaker.CircuitBreakerService;
-import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.script.ScriptModule;
-import org.elasticsearch.search.aggregations.AggregationBuilders;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder.InnerHit;
-import org.elasticsearch.search.fetch.source.FetchSourceContext;
-import org.elasticsearch.search.highlight.HighlightBuilder;
-import org.elasticsearch.search.internal.SearchContext;
-import org.elasticsearch.search.rescore.RescoreBuilder;
-import org.elasticsearch.search.sort.SortBuilders;
-import org.elasticsearch.search.sort.SortOrder;
-import org.elasticsearch.search.suggest.SuggestBuilder;
-import org.elasticsearch.search.suggest.SuggestBuilders;
-import org.elasticsearch.test.ESTestCase;
-import org.elasticsearch.test.TestSearchContext;
-import org.elasticsearch.test.VersionUtils;
-import org.elasticsearch.test.cluster.TestClusterService;
-import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.threadpool.ThreadPoolModule;
-import org.junit.After;
-import org.junit.AfterClass;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.lang.reflect.InvocationHandler;
-import java.lang.reflect.Method;
-import java.lang.reflect.Proxy;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.TimeUnit;
-
-import static org.hamcrest.Matchers.equalTo;
-
-public class NewSearchSourceBuilderTests extends ESTestCase {
-
-    protected static final String STRING_FIELD_NAME = "mapped_string";
-    protected static final String STRING_FIELD_NAME_2 = "mapped_string_2";
-    protected static final String INT_FIELD_NAME = "mapped_int";
-    protected static final String DOUBLE_FIELD_NAME = "mapped_double";
-    protected static final String BOOLEAN_FIELD_NAME = "mapped_boolean";
-    protected static final String DATE_FIELD_NAME = "mapped_date";
-    protected static final String OBJECT_FIELD_NAME = "mapped_object";
-    protected static final String GEO_POINT_FIELD_NAME = "mapped_geo_point";
-    protected static final String GEO_SHAPE_FIELD_NAME = "mapped_geo_shape";
-    protected static final String[] MAPPED_FIELD_NAMES = new String[] { STRING_FIELD_NAME, INT_FIELD_NAME, DOUBLE_FIELD_NAME,
-            BOOLEAN_FIELD_NAME, DATE_FIELD_NAME, OBJECT_FIELD_NAME, GEO_POINT_FIELD_NAME, GEO_SHAPE_FIELD_NAME };
-    protected static final String[] MAPPED_LEAF_FIELD_NAMES = new String[] { STRING_FIELD_NAME, INT_FIELD_NAME, DOUBLE_FIELD_NAME,
-            BOOLEAN_FIELD_NAME, DATE_FIELD_NAME, GEO_POINT_FIELD_NAME };
-
-    private static Injector injector;
-    private static IndexQueryParserService queryParserService;
-
-    protected static IndexQueryParserService queryParserService() {
-        return queryParserService;
-    }
-
-    private static Index index;
-
-    protected static Index getIndex() {
-        return index;
-    }
-
-    private static String[] currentTypes;
-
-    protected static String[] getCurrentTypes() {
-        return currentTypes;
-    }
-
-    private static NamedWriteableRegistry namedWriteableRegistry;
-
-    private static String[] randomTypes;
-    private static ClientInvocationHandler clientInvocationHandler = new ClientInvocationHandler();
-
-    /**
-     * Setup for the whole base test class.
-     */
-    @BeforeClass
-    public static void init() throws IOException {
-        // we have to prefer CURRENT since with the range of versions we support it's rather unlikely to get the current actually.
-        Version version = randomBoolean() ? Version.CURRENT : VersionUtils.randomVersionBetween(random(), Version.V_2_0_0_beta1, Version.CURRENT);
-        Settings settings = Settings.settingsBuilder()
-                .put("name", AbstractQueryTestCase.class.toString())
-                .put("path.home", createTempDir())
-                .build();
-        Settings indexSettings = Settings.settingsBuilder()
-                .put(IndexMetaData.SETTING_VERSION_CREATED, version).build();
-        index = new Index(randomAsciiOfLengthBetween(1, 10));
-        final TestClusterService clusterService = new TestClusterService();
-        clusterService.setState(new ClusterState.Builder(clusterService.state()).metaData(new MetaData.Builder().put(
-                new IndexMetaData.Builder(index.name()).settings(indexSettings).numberOfShards(1).numberOfReplicas(0))));
-        final Client proxy = (Client) Proxy.newProxyInstance(Client.class.getClassLoader(), new Class[] { Client.class },
-                clientInvocationHandler);
-        injector = new ModulesBuilder().add(
-                new EnvironmentModule(new Environment(settings)),
-                new SettingsModule(settings),
-                new ThreadPoolModule(new ThreadPool(settings)),
-                new MapperServiceModule(),
-                new IndicesModule(settings) {
-                    @Override
-                    public void configure() {
-                        // skip services
-                        bindQueryParsersExtension();
-                    }
-                },
-                new ScriptModule(settings),
-                new IndexSettingsModule(index, indexSettings),
-                new IndexCacheModule(indexSettings),
-                new AnalysisModule(indexSettings, new IndicesAnalysisService(indexSettings)),
-                new SimilarityModule(indexSettings),
-                new IndexNameModule(index),
-                new AbstractModule() {
-                    @Override
-                    protected void configure() {
-                        bind(Client.class).toInstance(proxy);
-                        Multibinder.newSetBinder(binder(), ScoreFunctionParser.class);
-                        bind(ClusterService.class).toProvider(Providers.of(clusterService));
-                        bind(CircuitBreakerService.class).to(NoneCircuitBreakerService.class);
-                        bind(NamedWriteableRegistry.class).asEagerSingleton();
-                    }
-                }
-        ).createInjector();
-        queryParserService = injector.getInstance(IndexQueryParserService.class);
-        MapperService mapperService = injector.getInstance(MapperService.class);
-        //create some random type with some default field, those types will stick around for all of the subclasses
-        currentTypes = new String[randomIntBetween(0, 5)];
-        for (int i = 0; i < currentTypes.length; i++) {
-            String type = randomAsciiOfLengthBetween(1, 10);
-            mapperService.merge(type, new CompressedXContent(PutMappingRequest.buildFromSimplifiedDef(type,
-                    STRING_FIELD_NAME, "type=string",
-                    STRING_FIELD_NAME_2, "type=string",
-                    INT_FIELD_NAME, "type=integer",
-                    DOUBLE_FIELD_NAME, "type=double",
-                    BOOLEAN_FIELD_NAME, "type=boolean",
-                    DATE_FIELD_NAME, "type=date",
-                    OBJECT_FIELD_NAME, "type=object",
-                    GEO_POINT_FIELD_NAME, "type=geo_point,lat_lon=true,geohash=true,geohash_prefix=true",
-                    GEO_SHAPE_FIELD_NAME, "type=geo_shape"
-            ).string()), false, false);
-            // also add mappings for two inner field in the object field
-            mapperService.merge(type, new CompressedXContent("{\"properties\":{\""+OBJECT_FIELD_NAME+"\":{\"type\":\"object\","
-                    + "\"properties\":{\""+DATE_FIELD_NAME+"\":{\"type\":\"date\"},\""+INT_FIELD_NAME+"\":{\"type\":\"integer\"}}}}}"), false, false);
-            currentTypes[i] = type;
-        }
-        namedWriteableRegistry = injector.getInstance(NamedWriteableRegistry.class);
-    }
-
-    @AfterClass
-    public static void afterClass() throws Exception {
-        terminate(injector.getInstance(ThreadPool.class));
-        injector = null;
-        index = null;
-        queryParserService = null;
-        currentTypes = null;
-        namedWriteableRegistry = null;
-        randomTypes = null;
-    }
-
-    @Before
-    public void beforeTest() {
-        clientInvocationHandler.delegate = this;
-        //set some random types to be queried as part the search request, before each test
-        randomTypes = getRandomTypes();
-    }
-
-    protected void setSearchContext(String[] types) {
-        TestSearchContext testSearchContext = new TestSearchContext();
-        testSearchContext.setTypes(types);
-        SearchContext.setCurrent(testSearchContext);
-    }
-
-    @After
-    public void afterTest() {
-        clientInvocationHandler.delegate = null;
-        QueryShardContext.removeTypes();
-        SearchContext.removeCurrent();
-    }
-
-    protected final SearchSourceBuilder createSearchSourceBuilder() throws IOException {
-        SearchSourceBuilder builder = new SearchSourceBuilder();
-        if (randomBoolean()) {
-            builder.from(randomIntBetween(0, 10000));
-        }
-        if (randomBoolean()) {
-            builder.size(randomIntBetween(0, 10000));
-        }
-        if (randomBoolean()) {
-            builder.explain(randomBoolean());
-        }
-        if (randomBoolean()) {
-            builder.version(randomBoolean());
-        }
-        if (randomBoolean()) {
-            builder.trackScores(randomBoolean());
-        }
-        if (randomBoolean()) {
-            builder.minScore(randomFloat() * 1000);
-        }
-        if (randomBoolean()) {
-            builder.timeout(new TimeValue(randomIntBetween(1, 100), randomFrom(TimeUnit.values())));
-        }
-        if (randomBoolean()) {
-            builder.terminateAfter(randomIntBetween(1, 100000));
-        }
-        // if (randomBoolean()) {
-        // builder.defaultRescoreWindowSize(randomIntBetween(1, 100));
-        // }
-        if (randomBoolean()) {
-            int fieldsSize = randomInt(25);
-            List<String> fields = new ArrayList<>(fieldsSize);
-            for (int i = 0; i < fieldsSize; i++) {
-                fields.add(randomAsciiOfLengthBetween(5, 50));
-            }
-            builder.fields(fields);
-        }
-        if (randomBoolean()) {
-            int fieldDataFieldsSize = randomInt(25);
-            for (int i = 0; i < fieldDataFieldsSize; i++) {
-                builder.fieldDataField(randomAsciiOfLengthBetween(5, 50));
-            }
-        }
-        if (randomBoolean()) {
-            int scriptFieldsSize = randomInt(25);
-            for (int i = 0; i < scriptFieldsSize; i++) {
-                builder.scriptField(randomAsciiOfLengthBetween(5, 50), new Script("foo"));
-            }
-        }
-        if (randomBoolean()) {
-            FetchSourceContext fetchSourceContext;
-            int branch = randomInt(5);
-            String[] includes = new String[randomIntBetween(0, 20)];
-            for (int i = 0; i < includes.length; i++) {
-                includes[i] = randomAsciiOfLengthBetween(5, 20);
-            }
-            String[] excludes = new String[randomIntBetween(0, 20)];
-            for (int i = 0; i < excludes.length; i++) {
-                excludes[i] = randomAsciiOfLengthBetween(5, 20);
-            }
-            switch (branch) {
-            case 0:
-                fetchSourceContext = new FetchSourceContext(randomBoolean());
-                break;
-            case 1:
-                fetchSourceContext = new FetchSourceContext(includes, excludes);
-                break;
-            case 2:
-                fetchSourceContext = new FetchSourceContext(randomAsciiOfLengthBetween(5, 20), randomAsciiOfLengthBetween(5, 20));
-                break;
-            case 3:
-                fetchSourceContext = new FetchSourceContext(true, includes, excludes, randomBoolean());
-                break;
-            case 4:
-                fetchSourceContext = new FetchSourceContext(includes);
-                break;
-            case 5:
-                fetchSourceContext = new FetchSourceContext(randomAsciiOfLengthBetween(5, 20));
-                break;
-            default:
-                throw new IllegalStateException();
-            }
-            builder.fetchSource(fetchSourceContext);
-        }
-        if (randomBoolean()) {
-            String[] statsGroups = new String[randomIntBetween(0, 20)];
-            for (int i = 0; i < statsGroups.length; i++) {
-                statsGroups[i] = randomAsciiOfLengthBetween(5, 20);
-            }
-            builder.stats(statsGroups);
-        }
-        if (randomBoolean()) {
-            int indexBoostSize = randomIntBetween(1, 10);
-            for (int i = 0; i < indexBoostSize; i++) {
-                builder.indexBoost(randomAsciiOfLengthBetween(5, 20), randomFloat() * 10);
-            }
-        }
-        if (randomBoolean()) {
-            // NORELEASE make RandomQueryBuilder work outside of the
-            // AbstractQueryTestCase
-            // builder.query(RandomQueryBuilder.createQuery(getRandom()));
-            builder.query(QueryBuilders.termQuery(randomAsciiOfLengthBetween(5, 20), randomAsciiOfLengthBetween(5, 20)));
-        }
-        if (randomBoolean()) {
-            // NORELEASE make RandomQueryBuilder work outside of the
-            // AbstractQueryTestCase
-            // builder.postFilter(RandomQueryBuilder.createQuery(getRandom()));
-            builder.postFilter(QueryBuilders.termQuery(randomAsciiOfLengthBetween(5, 20), randomAsciiOfLengthBetween(5, 20)));
-        }
-        if (randomBoolean()) {
-            int numSorts = randomIntBetween(1, 5);
-            for (int i = 0; i < numSorts; i++) {
-                int branch = randomInt(5);
-                switch (branch) {
-                case 0:
-                    builder.sort(SortBuilders.fieldSort(randomAsciiOfLengthBetween(5, 20)).order(randomFrom(SortOrder.values())));
-                    break;
-                case 1:
-                    builder.sort(SortBuilders.geoDistanceSort(randomAsciiOfLengthBetween(5, 20))
-                            .geohashes(AbstractQueryTestCase.randomGeohash(1, 12)).order(randomFrom(SortOrder.values())));
-                    break;
-                case 2:
-                    builder.sort(SortBuilders.scoreSort().order(randomFrom(SortOrder.values())));
-                    break;
-                case 3:
-                    builder.sort(SortBuilders.scriptSort(new Script("foo"), "number").order(randomFrom(SortOrder.values())));
-                    break;
-                case 4:
-                    builder.sort(randomAsciiOfLengthBetween(5, 20));
-                    break;
-                case 5:
-                    builder.sort(randomAsciiOfLengthBetween(5, 20), randomFrom(SortOrder.values()));
-                    break;
-                }
-            }
-        }
-        if (randomBoolean()) {
-            // NORELEASE need a random highlight builder method
-            builder.highlighter(new HighlightBuilder().field(randomAsciiOfLengthBetween(5, 20)));
-        }
-        if (randomBoolean()) {
-            // NORELEASE need a random suggest builder method
-            builder.suggest(new SuggestBuilder().setText(randomAsciiOfLengthBetween(1, 5)).addSuggestion(
-                    SuggestBuilders.termSuggestion(randomAsciiOfLengthBetween(1, 5))));
-        }
-        if (randomBoolean()) {
-            // NORELEASE need a random inner hits builder method
-            InnerHitsBuilder innerHitsBuilder = new InnerHitsBuilder();
-            InnerHit innerHit = new InnerHit();
-            innerHit.field(randomAsciiOfLengthBetween(5, 20));
-            innerHitsBuilder.addNestedInnerHits(randomAsciiOfLengthBetween(5, 20), randomAsciiOfLengthBetween(5, 20), innerHit);
-            builder.innerHits(innerHitsBuilder);
-        }
-        if (randomBoolean()) {
-            int numRescores = randomIntBetween(1, 5);
-            for (int i = 0; i < numRescores; i++) {
-                // NORELEASE need a random rescore builder method
-                RescoreBuilder rescoreBuilder = new RescoreBuilder();
-                rescoreBuilder.rescorer(RescoreBuilder.queryRescorer(QueryBuilders.termQuery(randomAsciiOfLengthBetween(5, 20),
-                        randomAsciiOfLengthBetween(5, 20))));
-                builder.addRescorer(rescoreBuilder);
-            }
-        }
-        if (randomBoolean()) {
-            // NORELEASE need a random aggregation builder method
-            builder.aggregation(AggregationBuilders.avg(randomAsciiOfLengthBetween(5, 20)));
-        }
-        return builder;
-    }
-
-    /**
-     * Generic test that creates new query from the test query and checks both for equality
-     * and asserts equality on the two queries.
-     */
-    @Test
-    public void testFromXContent() throws IOException {
-        SearchSourceBuilder testBuilder = createSearchSourceBuilder();
-        SearchSourceBuilder newBuilder = parseQuery(testBuilder.toString(), ParseFieldMatcher.STRICT);
-        assertNotSame(testBuilder, newBuilder);
-        assertEquals(testBuilder, newBuilder);
-        assertEquals(testBuilder.hashCode(), newBuilder.hashCode());
-    }
-
-    protected SearchSourceBuilder parseQuery(String queryAsString, ParseFieldMatcher matcher) throws IOException {
-        XContentParser parser = XContentFactory.xContent(queryAsString).createParser(queryAsString);
-        QueryParseContext context = createParseContext();
-        context.reset(parser);
-        context.parseFieldMatcher(matcher);
-        return SearchSourceBuilder.PROTOTYPE.fromXContent(parser, context);
-    }
-
-    /**
-     * Test serialization and deserialization of the test query.
-     */
-    @Test
-    public void testSerialization() throws IOException {
-        SearchSourceBuilder testBuilder = createSearchSourceBuilder();
-        try (BytesStreamOutput output = new BytesStreamOutput()) {
-            testBuilder.writeTo(output);
-            try (StreamInput in = new NamedWriteableAwareStreamInput(StreamInput.wrap(output.bytes()), namedWriteableRegistry)) {
-                SearchSourceBuilder deserializedBuilder = SearchSourceBuilder.PROTOTYPE.readFrom(in);
-                assertEquals(deserializedBuilder, testBuilder);
-                assertEquals(deserializedBuilder.hashCode(), testBuilder.hashCode());
-                assertNotSame(deserializedBuilder, testBuilder);
-            }
-        }
-    }
-
-    @Test
-    public void testEqualsAndHashcode() throws IOException {
-        SearchSourceBuilder firstBuilder = createSearchSourceBuilder();
-        assertFalse("query is equal to null", firstBuilder.equals(null));
-        assertFalse("query is equal to incompatible type", firstBuilder.equals(""));
-        assertTrue("query is not equal to self", firstBuilder.equals(firstBuilder));
-        assertThat("same query's hashcode returns different values if called multiple times", firstBuilder.hashCode(),
-                equalTo(firstBuilder.hashCode()));
-
-        SearchSourceBuilder secondBuilder = copyBuilder(firstBuilder);
-        assertTrue("query is not equal to self", secondBuilder.equals(secondBuilder));
-        assertTrue("query is not equal to its copy", firstBuilder.equals(secondBuilder));
-        assertTrue("equals is not symmetric", secondBuilder.equals(firstBuilder));
-        assertThat("query copy's hashcode is different from original hashcode", secondBuilder.hashCode(), equalTo(firstBuilder.hashCode()));
-
-        SearchSourceBuilder thirdBuilder = copyBuilder(secondBuilder);
-        assertTrue("query is not equal to self", thirdBuilder.equals(thirdBuilder));
-        assertTrue("query is not equal to its copy", secondBuilder.equals(thirdBuilder));
-        assertThat("query copy's hashcode is different from original hashcode", secondBuilder.hashCode(), equalTo(thirdBuilder.hashCode()));
-        assertTrue("equals is not transitive", firstBuilder.equals(thirdBuilder));
-        assertThat("query copy's hashcode is different from original hashcode", firstBuilder.hashCode(), equalTo(thirdBuilder.hashCode()));
-        assertTrue("equals is not symmetric", thirdBuilder.equals(secondBuilder));
-        assertTrue("equals is not symmetric", thirdBuilder.equals(firstBuilder));
-    }
-
-    //we use the streaming infra to create a copy of the query provided as argument
-    protected SearchSourceBuilder copyBuilder(SearchSourceBuilder builder) throws IOException {
-        try (BytesStreamOutput output = new BytesStreamOutput()) {
-            builder.writeTo(output);
-            try (StreamInput in = new NamedWriteableAwareStreamInput(StreamInput.wrap(output.bytes()), namedWriteableRegistry)) {
-                SearchSourceBuilder secondQuery = SearchSourceBuilder.PROTOTYPE.readFrom(in);
-                return secondQuery;
-            }
-        }
-    }
-
-    /**
-     * @return a new {@link QueryShardContext} based on the base test index and queryParserService
-     */
-    protected static QueryShardContext createShardContext() {
-        QueryShardContext queryCreationContext = new QueryShardContext(index, queryParserService);
-        queryCreationContext.reset();
-        queryCreationContext.parseFieldMatcher(ParseFieldMatcher.EMPTY);
-        return queryCreationContext;
-    }
-
-    /**
-     * @return a new {@link QueryParseContext} based on the base test index and queryParserService
-     */
-    protected static QueryParseContext createParseContext() {
-        return createShardContext().parseContext();
-    }
-
-    protected String[] getRandomTypes() {
-        String[] types;
-        if (currentTypes.length > 0 && randomBoolean()) {
-            int numberOfQueryTypes = randomIntBetween(1, currentTypes.length);
-            types = new String[numberOfQueryTypes];
-            for (int i = 0; i < numberOfQueryTypes; i++) {
-                types[i] = randomFrom(currentTypes);
-            }
-        } else {
-            if (randomBoolean()) {
-                types = new String[] { MetaData.ALL };
-            } else {
-                types = new String[0];
-            }
-        }
-        return types;
-    }
-
-    private static class ClientInvocationHandler implements InvocationHandler {
-        NewSearchSourceBuilderTests delegate;
-
-        @Override
-        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
-            if (method.equals(Client.class.getDeclaredMethod("get", GetRequest.class))) {
-                return new PlainActionFuture<GetResponse>() {
-                    @Override
-                    public GetResponse get() throws InterruptedException, ExecutionException {
-                        return delegate.executeGet((GetRequest) args[0]);
-                    }
-                };
-            } else if (method.equals(Client.class.getDeclaredMethod("multiTermVectors", MultiTermVectorsRequest.class))) {
-                return new PlainActionFuture<MultiTermVectorsResponse>() {
-                    @Override
-                    public MultiTermVectorsResponse get() throws InterruptedException, ExecutionException {
-                        return delegate.executeMultiTermVectors((MultiTermVectorsRequest) args[0]);
-                    }
-                };
-            } else if (method.equals(Object.class.getDeclaredMethod("toString"))) {
-                return "MockClient";
-            }
-            throw new UnsupportedOperationException("this test can't handle calls to: " + method);
-        }
-
-    }
-
-    /**
-     * Override this to handle {@link Client#get(GetRequest)} calls from parsers
-     * / builders
-     */
-    protected GetResponse executeGet(GetRequest getRequest) {
-        throw new UnsupportedOperationException("this test can't handle GET requests");
-    }
-
-    /**
-     * Override this to handle {@link Client#get(GetRequest)} calls from parsers
-     * / builders
-     */
-    protected MultiTermVectorsResponse executeMultiTermVectors(MultiTermVectorsRequest mtvRequest) {
-        throw new UnsupportedOperationException("this test can't handle MultiTermVector requests");
-    }
-
-    public void testParseIncludeExclude() throws IOException {
-        SearchSourceBuilder builder = new SearchSourceBuilder();
-        {
-            String restContent = " { \"_source\": { \"includes\": \"include\", \"excludes\": \"*.field2\"}}";
-            try (XContentParser parser = XContentFactory.xContent(restContent).createParser(restContent)) {
-                SearchSourceBuilder searchSourceBuilder = builder.fromXContent(parser, new QueryParseContext(queryParserService.indicesQueriesRegistry()));
-                assertArrayEquals(new String[]{"*.field2" }, searchSourceBuilder.fetchSource().excludes());
-                assertArrayEquals(new String[]{"include" }, searchSourceBuilder.fetchSource().includes());
-            }
-        }
-        {
-            String restContent = " { \"_source\": false}";
-            try (XContentParser parser = XContentFactory.xContent(restContent).createParser(restContent)) {
-                SearchSourceBuilder searchSourceBuilder = builder.fromXContent(parser, new QueryParseContext(queryParserService.indicesQueriesRegistry()));
-                assertArrayEquals(new String[]{}, searchSourceBuilder.fetchSource().excludes());
-                assertArrayEquals(new String[]{}, searchSourceBuilder.fetchSource().includes());
-                assertFalse(searchSourceBuilder.fetchSource().fetchSource());
-            }
-        }
-    }
-
-    public void testParseSort() throws IOException {
-        SearchSourceBuilder builder = new SearchSourceBuilder();
-        {
-            String restContent = " { \"sort\": \"foo\"}";
-            try (XContentParser parser = XContentFactory.xContent(restContent).createParser(restContent)) {
-                SearchSourceBuilder searchSourceBuilder = builder.fromXContent(parser, new QueryParseContext(queryParserService.indicesQueriesRegistry()));
-                assertEquals(1, searchSourceBuilder.sorts().size());
-                assertEquals("{\"foo\":{}}", searchSourceBuilder.sorts().get(0).toUtf8());
-            }
-        }
-
-        {
-            String restContent = "{\"sort\" : [\n" +
-                    "        { \"post_date\" : {\"order\" : \"asc\"}},\n" +
-                    "        \"user\",\n" +
-                    "        { \"name\" : \"desc\" },\n" +
-                    "        { \"age\" : \"desc\" },\n" +
-                    "        \"_score\"\n" +
-                    "    ]}";
-            try (XContentParser parser = XContentFactory.xContent(restContent).createParser(restContent)) {
-                SearchSourceBuilder searchSourceBuilder = builder.fromXContent(parser, new QueryParseContext(queryParserService.indicesQueriesRegistry()));
-                assertEquals(5, searchSourceBuilder.sorts().size());
-                assertEquals("{\"post_date\":{\"order\":\"asc\"}}", searchSourceBuilder.sorts().get(0).toUtf8());
-                assertEquals("\"user\"", searchSourceBuilder.sorts().get(1).toUtf8());
-                assertEquals("{\"name\":\"desc\"}", searchSourceBuilder.sorts().get(2).toUtf8());
-                assertEquals("{\"age\":\"desc\"}", searchSourceBuilder.sorts().get(3).toUtf8());
-                assertEquals("\"_score\"", searchSourceBuilder.sorts().get(4).toUtf8());
-            }
-        }
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java b/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
index 120b7c9..982a3d9 100644
--- a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
@@ -27,7 +27,10 @@ import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.action.search.SearchType;
+
+import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.lucene.search.function.CombineFunction;
+import org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.index.cache.IndexCacheModule;
@@ -35,6 +38,7 @@ import org.elasticsearch.index.mapper.MergeMappingException;
 import org.elasticsearch.index.query.HasChildQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
+import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.search.aggregations.AggregationBuilders;
@@ -50,42 +54,15 @@ import org.hamcrest.Matchers;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.boolQuery;
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasParentQuery;
-import static org.elasticsearch.index.query.QueryBuilders.idsQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
-import static org.elasticsearch.index.query.QueryBuilders.multiMatchQuery;
-import static org.elasticsearch.index.query.QueryBuilders.notQuery;
-import static org.elasticsearch.index.query.QueryBuilders.prefixQuery;
-import static org.elasticsearch.index.query.QueryBuilders.queryStringQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termsQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
 import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.weightFactorFunction;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHit;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasId;
-import static org.hamcrest.Matchers.anyOf;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.notNullValue;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -676,7 +653,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "child",
                                 QueryBuilders.functionScoreQuery(matchQuery("c_field2", 0),
                                         scriptFunction(new Script("doc['c_field1'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).scoreMode(ScoreMode.Total)).get();
+                                        .boostMode(CombineFunction.REPLACE)).scoreMode(ScoreMode.Total)).get();
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("1"));
@@ -693,7 +670,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "child",
                                 QueryBuilders.functionScoreQuery(matchQuery("c_field2", 0),
                                         scriptFunction(new Script("doc['c_field1'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).scoreMode(ScoreMode.Max)).get();
+                                        .boostMode(CombineFunction.REPLACE)).scoreMode(ScoreMode.Max)).get();
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -710,7 +687,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "child",
                                 QueryBuilders.functionScoreQuery(matchQuery("c_field2", 0),
                                         scriptFunction(new Script("doc['c_field1'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).scoreMode(ScoreMode.Avg)).get();
+                                        .boostMode(CombineFunction.REPLACE)).scoreMode(ScoreMode.Avg)).get();
 
         assertThat(response.getHits().totalHits(), equalTo(3l));
         assertThat(response.getHits().hits()[0].id(), equalTo("3"));
@@ -727,7 +704,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
                                 "parent",
                                 QueryBuilders.functionScoreQuery(matchQuery("p_field1", "p_value3"),
                                         scriptFunction(new Script("doc['p_field2'].value")))
-                                        .boostMode(CombineFunction.REPLACE.getName())).score(true))
+                                        .boostMode(CombineFunction.REPLACE)).score(true))
                 .addSort(SortBuilders.fieldSort("c_field3")).addSort(SortBuilders.scoreSort()).get();
 
         assertThat(response.getHits().totalHits(), equalTo(7l));
@@ -1475,17 +1452,15 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         client().prepareIndex("test", "posts", "1").setParent("1").setSource("field", "bar").get();
         refresh();
 
-        // SearchResponse resp;
-        // resp = client().prepareSearch("test")
-        // .setSource(new
-        // BytesArray("{\"query\": {\"has_child\": {\"type\": \"posts\", \"query\": {\"match\": {\"field\": \"bar\"}}}}}")).get();
-        // assertHitCount(resp, 1L);
-        //
-        // // Now reverse the order for the type after the query
-        // resp = client().prepareSearch("test")
-        // .setSource(new
-        // BytesArray("{\"query\": {\"has_child\": {\"query\": {\"match\": {\"field\": \"bar\"}}, \"type\": \"posts\"}}}")).get();
-        // assertHitCount(resp, 1L); NOCOMMIT fix this
+        SearchResponse resp;
+        resp = client().prepareSearch("test")
+                .setSource(new BytesArray("{\"query\": {\"has_child\": {\"type\": \"posts\", \"query\": {\"match\": {\"field\": \"bar\"}}}}}")).get();
+        assertHitCount(resp, 1L);
+
+        // Now reverse the order for the type after the query
+        resp = client().prepareSearch("test")
+                .setSource(new BytesArray("{\"query\": {\"has_child\": {\"query\": {\"match\": {\"field\": \"bar\"}}, \"type\": \"posts\"}}}")).get();
+        assertHitCount(resp, 1L);
 
     }
 
@@ -1583,11 +1558,12 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
     private SearchResponse minMaxQuery(ScoreMode scoreMode, int minChildren, Integer maxChildren) throws SearchPhaseExecutionException {
         HasChildQueryBuilder hasChildQuery = hasChildQuery(
                 "child",
-                QueryBuilders.functionScoreQuery(constantScoreQuery(QueryBuilders.termQuery("foo", "two"))).boostMode("replace").scoreMode("sum")
-                        .add(QueryBuilders.matchAllQuery(), weightFactorFunction(1))
-                        .add(QueryBuilders.termQuery("foo", "three"), weightFactorFunction(1))
-                        .add(QueryBuilders.termQuery("foo", "four"), weightFactorFunction(1))).scoreMode(scoreMode)
-                .minChildren(minChildren);
+                QueryBuilders.functionScoreQuery(constantScoreQuery(QueryBuilders.termQuery("foo", "two")),
+                        new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(weightFactorFunction(1)),
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(QueryBuilders.termQuery("foo", "three"), weightFactorFunction(1)),
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(QueryBuilders.termQuery("foo", "four"), weightFactorFunction(1))
+                        }).boostMode(CombineFunction.REPLACE).scoreMode(FiltersFunctionScoreQuery.ScoreMode.SUM)).scoreMode(scoreMode).minChildren(minChildren);
 
         if (maxChildren != null) {
             hasChildQuery.maxChildren(maxChildren);
diff --git a/core/src/test/java/org/elasticsearch/search/fetch/FetchSubPhasePluginIT.java b/core/src/test/java/org/elasticsearch/search/fetch/FetchSubPhasePluginIT.java
index d336183..e07bb73 100644
--- a/core/src/test/java/org/elasticsearch/search/fetch/FetchSubPhasePluginIT.java
+++ b/core/src/test/java/org/elasticsearch/search/fetch/FetchSubPhasePluginIT.java
@@ -91,12 +91,11 @@ public class FetchSubPhasePluginIT extends ESIntegTestCase {
         String searchSource = jsonBuilder().startObject()
                 .field("term_vectors_fetch", "test")
                 .endObject().string();
-//        SearchResponse response = client().prepareSearch().setSource(new BytesArray(searchSource)).get();
-//        assertSearchResponse(response);
-//        assertThat(((Map<String, Integer>) response.getHits().getAt(0).field("term_vectors_fetch").getValues().get(0)).get("i"), equalTo(2));
-//        assertThat(((Map<String, Integer>) response.getHits().getAt(0).field("term_vectors_fetch").getValues().get(0)).get("am"), equalTo(2));
-//        assertThat(((Map<String, Integer>) response.getHits().getAt(0).field("term_vectors_fetch").getValues().get(0)).get("sam"), equalTo(1));
-        //  NOCOMMIT fix this
+        SearchResponse response = client().prepareSearch().setSource(new BytesArray(searchSource)).get();
+        assertSearchResponse(response);
+        assertThat(((Map<String, Integer>) response.getHits().getAt(0).field("term_vectors_fetch").getValues().get(0)).get("i"), equalTo(2));
+        assertThat(((Map<String, Integer>) response.getHits().getAt(0).field("term_vectors_fetch").getValues().get(0)).get("am"), equalTo(2));
+        assertThat(((Map<String, Integer>) response.getHits().getAt(0).field("term_vectors_fetch").getValues().get(0)).get("sam"), equalTo(1));
     }
 
     public static class FetchTermVectorsPlugin extends Plugin {
diff --git a/core/src/test/java/org/elasticsearch/search/fields/SearchFieldsIT.java b/core/src/test/java/org/elasticsearch/search/fields/SearchFieldsIT.java
index f4485a0..1075347 100644
--- a/core/src/test/java/org/elasticsearch/search/fields/SearchFieldsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/fields/SearchFieldsIT.java
@@ -513,26 +513,26 @@ public class SearchFieldsIT extends ESIntegTestCase {
         assertThat(searchResponse.getHits().getAt(0).field(field).getValues().get(1).toString(), equalTo("value2"));
     }
 
-//    @Test // see #8203
-//    public void testSingleValueFieldDatatField() throws ExecutionException, InterruptedException {
-//        createIndex("test");
-//        indexRandom(true, client().prepareIndex("test", "type", "1").setSource("test_field", "foobar"));
-//        refresh();
-//        SearchResponse searchResponse = client().prepareSearch("test").setTypes("type").setSource(new BytesArray(new BytesRef("{\"query\":{\"match_all\":{}},\"fielddata_fields\": \"test_field\"}"))).get();
-//        assertHitCount(searchResponse, 1);
-//        Map<String,SearchHitField> fields = searchResponse.getHits().getHits()[0].getFields();
-//        assertThat((String)fields.get("test_field").value(), equalTo("foobar"));
-//    } NOCOMMIT fix this
-
-//    @Test(expected = SearchPhaseExecutionException.class)
-//    public void testInvalidFieldDataField() throws ExecutionException, InterruptedException {
-//        createIndex("test");
-//        if (randomBoolean()) {
-//            client().prepareSearch("test").setTypes("type").setSource(new BytesArray(new BytesRef("{\"query\":{\"match_all\":{}},\"fielddata_fields\": {}}"))).get();
-//        } else {
-//            client().prepareSearch("test").setTypes("type").setSource(new BytesArray(new BytesRef("{\"query\":{\"match_all\":{}},\"fielddata_fields\": 1.0}"))).get();
-//        }
-//    } NOCOMMIT fix this
+    @Test // see #8203
+    public void testSingleValueFieldDatatField() throws ExecutionException, InterruptedException {
+        createIndex("test");
+        indexRandom(true, client().prepareIndex("test", "type", "1").setSource("test_field", "foobar"));
+        refresh();
+        SearchResponse searchResponse = client().prepareSearch("test").setTypes("type").setSource(new BytesArray(new BytesRef("{\"query\":{\"match_all\":{}},\"fielddata_fields\": \"test_field\"}"))).get();
+        assertHitCount(searchResponse, 1);
+        Map<String,SearchHitField> fields = searchResponse.getHits().getHits()[0].getFields();
+        assertThat((String)fields.get("test_field").value(), equalTo("foobar"));
+    }
+
+    @Test(expected = SearchPhaseExecutionException.class)
+    public void testInvalidFieldDataField() throws ExecutionException, InterruptedException {
+        createIndex("test");
+        if (randomBoolean()) {
+            client().prepareSearch("test").setTypes("type").setSource(new BytesArray(new BytesRef("{\"query\":{\"match_all\":{}},\"fielddata_fields\": {}}"))).get();
+        } else {
+            client().prepareSearch("test").setTypes("type").setSource(new BytesArray(new BytesRef("{\"query\":{\"match_all\":{}},\"fielddata_fields\": 1.0}"))).get();
+        }
+    }
 
     @Test
     public void testFieldsPulledFromFieldData() throws Exception {
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/DecayFunctionScoreIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/DecayFunctionScoreIT.java
index 9f34c4f..c2c2782 100644
--- a/core/src/test/java/org/elasticsearch/search/functionscore/DecayFunctionScoreIT.java
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/DecayFunctionScoreIT.java
@@ -24,15 +24,15 @@ import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.action.search.SearchType;
-import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.lucene.search.function.CombineFunction;
+import org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.MatchAllQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.functionscore.DecayFunctionBuilder;
-import org.elasticsearch.index.query.functionscore.gauss.GaussDecayFunctionBuilder;
+import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder;
+import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
+import org.elasticsearch.search.MultiValueMode;
 import org.elasticsearch.search.SearchHits;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.joda.time.DateTime;
@@ -48,24 +48,11 @@ import java.util.concurrent.ExecutionException;
 import static org.elasticsearch.client.Requests.indexRequest;
 import static org.elasticsearch.client.Requests.searchRequest;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.exponentialDecayFunction;
-import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.gaussDecayFunction;
-import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.linearDecayFunction;
+import static org.elasticsearch.index.query.QueryBuilders.*;
+import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.*;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.searchSource;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertOrderedSearchHits;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHits;
-import static org.hamcrest.Matchers.anyOf;
-import static org.hamcrest.Matchers.closeTo;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.isOneOf;
-import static org.hamcrest.Matchers.lessThan;
-import static org.hamcrest.Matchers.not;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
 
 
 public class DecayFunctionScoreIT extends ESIntegTestCase {
@@ -199,8 +186,8 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource()
                                 .size(numDummyDocs + 2)
-                                .query(functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 1.0, 5.0).setOffset(1.0))
-                                        .boostMode(CombineFunction.REPLACE.getName()))));
+                                .query(functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 1.0, 5.0, 1.0))
+                                        .boostMode(CombineFunction.REPLACE))));
         SearchResponse sr = response.actionGet();
         SearchHits sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));
@@ -218,8 +205,8 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
                         searchSource()
                                 .size(numDummyDocs + 2)
                                 .query(functionScoreQuery(termQuery("test", "value"),
-                                        exponentialDecayFunction("num", 1.0, 5.0).setOffset(1.0)).boostMode(
-                                        CombineFunction.REPLACE.getName()))));
+                                        exponentialDecayFunction("num", 1.0, 5.0, 1.0)).boostMode(
+                                        CombineFunction.REPLACE))));
         sr = response.actionGet();
         sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));
@@ -234,8 +221,8 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource()
                                 .size(numDummyDocs + 2)
-                                .query(functionScoreQuery(termQuery("test", "value"), linearDecayFunction("num", 1.0, 20.0).setOffset(1.0))
-                                        .boostMode(CombineFunction.REPLACE.getName()))));
+                                .query(functionScoreQuery(termQuery("test", "value"), linearDecayFunction("num", 1.0, 20.0, 1.0))
+                                        .boostMode(CombineFunction.REPLACE))));
         sr = response.actionGet();
         sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (numDummyDocs + 2)));
@@ -278,7 +265,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
                                 functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("loc", lonlat, "1000km")).boostMode(
-                                        CombineFunction.MULT.getName()))));
+                                        CombineFunction.MULTIPLY))));
         SearchResponse sr = response.actionGet();
         SearchHits sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (2)));
@@ -290,7 +277,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
                                 functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("loc", lonlat, "1000km")).boostMode(
-                                        CombineFunction.REPLACE.getName()))));
+                                        CombineFunction.REPLACE))));
         sr = response.actionGet();
         sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (2)));
@@ -320,7 +307,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
                                 functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("loc", point, "1000km")).boostMode(
-                                        CombineFunction.MULT.getName()))));
+                                        CombineFunction.MULTIPLY))));
         SearchResponse sr = response.actionGet();
         SearchHits sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (1)));
@@ -332,7 +319,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
                                 functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("loc", coords, "1000km")).boostMode(
-                                        CombineFunction.MULT.getName()))));
+                                        CombineFunction.MULTIPLY))));
         sr = response.actionGet();
         sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (1)));
@@ -357,8 +344,8 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         ActionFuture<SearchResponse> response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
-                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0).setDecay(0.5)).boost(
-                                        2.0f).boostMode(CombineFunction.MULT))));
+                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0, null, 0.5)).boost(
+                                        2.0f).boostMode(CombineFunction.MULTIPLY))));
         SearchResponse sr = response.actionGet();
         SearchHits sh = sr.getHits();
         assertThat(sh.getTotalHits(), equalTo((long) (1)));
@@ -368,7 +355,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
-                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0).setDecay(0.5)).boost(
+                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0, null, 0.5)).boost(
                                         2.0f).boostMode(CombineFunction.REPLACE))));
         sr = response.actionGet();
         sh = sr.getHits();
@@ -379,7 +366,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
-                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0).setDecay(0.5)).boost(
+                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0, null, 0.5)).boost(
                                         2.0f).boostMode(CombineFunction.SUM))));
         sr = response.actionGet();
         sh = sr.getHits();
@@ -391,7 +378,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
-                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0).setDecay(0.5)).boost(
+                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0, null, 0.5)).boost(
                                         2.0f).boostMode(CombineFunction.AVG))));
         sr = response.actionGet();
         sh = sr.getHits();
@@ -402,7 +389,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
-                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0).setDecay(0.5)).boost(
+                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0, null, 0.5)).boost(
                                         2.0f).boostMode(CombineFunction.MIN))));
         sr = response.actionGet();
         sh = sr.getHits();
@@ -413,7 +400,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
-                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0).setDecay(0.5)).boost(
+                                functionScoreQuery(termQuery("test", "value"), gaussDecayFunction("num", 0.0, 1.0, null, 0.5)).boost(
                                         2.0f).boostMode(CombineFunction.MAX))));
         sr = response.actionGet();
         sh = sr.getHits();
@@ -446,10 +433,10 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         SearchResponse sr = response.actionGet();
         assertOrderedSearchHits(sr, "2", "1");
     }
-
+    
     @Test
     public void testParseDateMath() throws Exception {
-
+        
         assertAcked(prepareCreate("test").addMapping(
                 "type1",
                 jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("test").field("type", "string")
@@ -470,7 +457,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
 
         assertNoFailures(sr);
         assertOrderedSearchHits(sr, "1", "2");
-
+        
         sr = client().search(
                 searchRequest().source(
                         searchSource().query(
@@ -481,11 +468,6 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
 
     }
 
-    @Test(expected = IllegalStateException.class)
-    public void testExceptionThrownIfScaleRefNotBetween0And1() throws Exception {
-        DecayFunctionBuilder gfb = new GaussDecayFunctionBuilder("num1", "2013-05-28", "1d").setDecay(100);
-    }
-
     @Test
     public void testValueMissingLin() throws Exception {
 
@@ -518,8 +500,10 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         ActionFuture<SearchResponse> response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
-                                functionScoreQuery(constantScoreQuery(termQuery("test", "value"))).add(linearDecayFunction("num1", "2013-05-28", "+3d"))
-                                        .add(linearDecayFunction("num2", "0.0", "1")).scoreMode("multiply"))));
+                                functionScoreQuery(constantScoreQuery(termQuery("test", "value")), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(linearDecayFunction("num1", "2013-05-28", "+3d")),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(linearDecayFunction("num2", "0.0", "1"))
+                                }).scoreMode(FiltersFunctionScoreQuery.ScoreMode.MULTIPLY))));
 
         SearchResponse sr = response.actionGet();
 
@@ -566,9 +550,11 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         ActionFuture<SearchResponse> response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
-                                functionScoreQuery(QueryBuilders.matchAllQuery()).add(linearDecayFunction("num1", "1000w"))
-                                        .add(gaussDecayFunction("num1", "1d")).add(exponentialDecayFunction("num1", "1000w"))
-                                        .scoreMode("multiply"))));
+                                functionScoreQuery(QueryBuilders.matchAllQuery(), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(linearDecayFunction("num1", null, "1000w")),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(gaussDecayFunction("num1", null, "1d")),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(exponentialDecayFunction("num1", null, "1000w"))
+                                }).scoreMode(FiltersFunctionScoreQuery.ScoreMode.MULTIPLY))));
 
         SearchResponse sr = response.actionGet();
         assertNoFailures(sr);
@@ -596,9 +582,9 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         List<IndexRequestBuilder> indexBuilders = new ArrayList<>();
 
         for (int i = 0; i < numDocs; i++) {
-            double lat = 100 + (int) (10.0 * (i) / (numDocs));
+            double lat = 100 + (int) (10.0 * (float) (i) / (float) (numDocs));
             double lon = 100;
-            int day = (int) (29.0 * (i) / (numDocs)) + 1;
+            int day = (int) (29.0 * (float) (i) / (float) (numDocs)) + 1;
             String dayString = day < 10 ? "0" + Integer.toString(day) : Integer.toString(day);
             String date = "2013-05-" + dayString;
 
@@ -617,11 +603,11 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         ActionFuture<SearchResponse> response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().size(numDocs).query(
-                                functionScoreQuery(termQuery("test", "value"))
-                                        .add(new MatchAllQueryBuilder(), linearDecayFunction("date", "2013-05-30", "+15d"))
-                                        .add(new MatchAllQueryBuilder(), linearDecayFunction("geo", lonlat, "1000km"))
-                                        .add(new MatchAllQueryBuilder(), linearDecayFunction("num", numDocs, numDocs / 2.0))
-                                        .scoreMode("multiply").boostMode(CombineFunction.REPLACE.getName()))));
+                                functionScoreQuery(termQuery("test", "value"), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(linearDecayFunction("date", "2013-05-30", "+15d")),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(linearDecayFunction("geo", lonlat, "1000km")),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(linearDecayFunction("num", numDocs, numDocs / 2.0))
+                                }).scoreMode(FiltersFunctionScoreQuery.ScoreMode.MULTIPLY).boostMode(CombineFunction.REPLACE))));
 
         SearchResponse sr = response.actionGet();
         assertNoFailures(sr);
@@ -656,10 +642,9 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource()
                                 .size(numDocs)
-                                .query(functionScoreQuery(termQuery("test", "value")).add(new MatchAllQueryBuilder(),
-                                        linearDecayFunction("type1.geo", lonlat, "1000km")).scoreMode("multiply"))));
+                                .query(functionScoreQuery(termQuery("test", "value"), linearDecayFunction("type1.geo", lonlat, "1000km"))
+                                        .scoreMode(FiltersFunctionScoreQuery.ScoreMode.MULTIPLY))));
         SearchResponse sr = response.actionGet();
-
     }
 
     @Test(expected = SearchPhaseExecutionException.class)
@@ -677,8 +662,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         ActionFuture<SearchResponse> response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
-                                functionScoreQuery(termQuery("test", "value")).add(new MatchAllQueryBuilder(),
-                                        linearDecayFunction("num", 1.0, 0.5)).scoreMode("multiply"))));
+                                functionScoreQuery(termQuery("test", "value"), linearDecayFunction("num", 1.0, 0.5)).scoreMode(FiltersFunctionScoreQuery.ScoreMode.MULTIPLY))));
         response.actionGet();
     }
 
@@ -697,8 +681,8 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         ActionFuture<SearchResponse> response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().query(
-                                functionScoreQuery().add(new MatchAllQueryBuilder(), linearDecayFunction("num", 1, 0.5)).scoreMode(
-                                        "multiply"))));
+                                functionScoreQuery(linearDecayFunction("num", 1, 0.5)).scoreMode(
+                                        FiltersFunctionScoreQuery.ScoreMode.MULTIPLY))));
         response.actionGet();
     }
 
@@ -742,7 +726,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         response = client().search(
                 searchRequest().source(
                         searchSource().query(
-                                functionScoreQuery(constantScoreQuery(termQuery("test", "value")), gaussDecayFunction("loc", lonlat, "1000km").setMultiValueMode("min")))));
+                                functionScoreQuery(constantScoreQuery(termQuery("test", "value")), gaussDecayFunction("loc", lonlat, "1000km").setMultiValueMode(MultiValueMode.MIN)))));
         sr = response.actionGet();
         assertSearchHits(sr, "1", "2");
         sh = sr.getHits();
@@ -752,7 +736,7 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         response = client().search(
                 searchRequest().source(
                         searchSource().query(
-                                functionScoreQuery(constantScoreQuery(termQuery("test", "value")), gaussDecayFunction("loc", lonlat, "1000km").setMultiValueMode("max")))));
+                                functionScoreQuery(constantScoreQuery(termQuery("test", "value")), gaussDecayFunction("loc", lonlat, "1000km").setMultiValueMode(MultiValueMode.MAX)))));
         sr = response.actionGet();
         assertSearchHits(sr, "1", "2");
         sh = sr.getHits();
@@ -781,22 +765,22 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         response = client().search(
                 searchRequest().source(
                         searchSource().query(
-                                functionScoreQuery(constantScoreQuery(termQuery("test", "value")), linearDecayFunction("num", "0", "10").setMultiValueMode("sum")))));
+                                functionScoreQuery(constantScoreQuery(termQuery("test", "value")), linearDecayFunction("num", "0", "10").setMultiValueMode(MultiValueMode.SUM)))));
         sr = response.actionGet();
         assertSearchHits(sr, "1", "2");
         sh = sr.getHits();
 
         assertThat(sh.getAt(0).getId(), equalTo("2"));
         assertThat(sh.getAt(1).getId(), equalTo("1"));
-        assertThat(1.0 - sh.getAt(0).getScore(), closeTo((1.0 - sh.getAt(1).getScore())/3.0, 1.e-6d));
+        assertThat((double)(1.0 - sh.getAt(0).getScore()), closeTo((double)((1.0 - sh.getAt(1).getScore())/3.0), 1.e-6d));
         response = client().search(
                 searchRequest().source(
                         searchSource().query(
-                                functionScoreQuery(constantScoreQuery(termQuery("test", "value")), linearDecayFunction("num", "0", "10").setMultiValueMode("avg")))));
+                                functionScoreQuery(constantScoreQuery(termQuery("test", "value")), linearDecayFunction("num", "0", "10").setMultiValueMode(MultiValueMode.AVG)))));
         sr = response.actionGet();
         assertSearchHits(sr, "1", "2");
         sh = sr.getHits();
-        assertThat((double) (sh.getAt(0).getScore()), closeTo((sh.getAt(1).getScore()), 1.e-6d));
+        assertThat((double) (sh.getAt(0).getScore()), closeTo((double) (sh.getAt(1).getScore()), 1.e-6d));
     }
 
     @Test
@@ -813,118 +797,30 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
 
         XContentBuilder query = XContentFactory.jsonBuilder();
         // query that contains a single function and a functions[] array
-        query.startObject().startObject("query").startObject("function_score").field("weight", "1").startArray("functions").startObject().startObject("script_score").field("script", "3").endObject().endObject().endArray().endObject().endObject().endObject();
-//        try {
-//            client().search(searchRequest().source(query.bytes())).actionGet();
-//            fail("Search should result in SearchPhaseExecutionException");
-//        } catch (SearchPhaseExecutionException e) {
-//            logger.info(e.shardFailures()[0].reason());
-//            assertThat(e.shardFailures()[0].reason(), containsString("already found [weight], now encountering [functions]."));
-//        }
-//
-//        query = XContentFactory.jsonBuilder();
-//        // query that contains a single function (but not boost factor) and a functions[] array
-//        query.startObject().startObject("query").startObject("function_score").startObject("random_score").field("seed", 3).endObject().startArray("functions").startObject().startObject("random_score").field("seed", 3).endObject().endObject().endArray().endObject().endObject().endObject();
-//        try {
-//            client().search(searchRequest().source(query.bytes())).actionGet();
-//            fail("Search should result in SearchPhaseExecutionException");
-//        } catch (SearchPhaseExecutionException e) {
-//            logger.info(e.shardFailures()[0].reason());
-//            assertThat(e.shardFailures()[0].reason(), containsString("already found [random_score], now encountering [functions]"));
-//            assertThat(e.shardFailures()[0].reason(), not(containsString("did you mean [boost] instead?")));
-//
-//        } NOCOMMIT fix this
-    }
-
-    // issue https://github.com/elasticsearch/elasticsearch/issues/6292
-    @Test
-    public void testMissingFunctionThrowsElasticsearchParseException() throws IOException {
-
-        // example from issue https://github.com/elasticsearch/elasticsearch/issues/6292
-        String doc = "{\n" +
-                "  \"text\": \"baseball bats\"\n" +
-                "}\n";
-
-        String query = "{\n" +
-                "    \"query\": {\n" +
-                "      \"function_score\": {\n" +
-                "        \"score_mode\": \"sum\",\n" +
-                "        \"boost_mode\": \"replace\",\n" +
-                "        \"functions\": [\n" +
-                "          {\n" +
-                "            \"filter\": {\n" +
-                "              \"term\": {\n" +
-                "                \"text\": \"baseball\"\n" +
-                "              }\n" +
-                "            }\n" +
-                "          }\n" +
-                "        ]\n" +
-                "      }\n" +
-                "    }\n" +
-                "}\n";
-
-        client().prepareIndex("t", "test").setSource(doc).get();
-        refresh();
-        ensureYellow("t");
-//        try {
-//            client().search(searchRequest().source(new BytesArray(query))).actionGet();
-//            fail("Should fail with SearchPhaseExecutionException");
-//        } catch (SearchPhaseExecutionException failure) {
-//            assertThat(failure.toString(), containsString("SearchParseException"));
-//            assertThat(failure.toString(), not(containsString("NullPointerException")));
-//        } NOCOMMIT fix this
-
-        query = "{\n" +
-                "    \"query\": {\n" +
-                "      \"function_score\": {\n" +
-                "        \"score_mode\": \"sum\",\n" +
-                "        \"boost_mode\": \"replace\",\n" +
-                "        \"functions\": [\n" +
-                "          {\n" +
-                "            \"filter\": {\n" +
-                "              \"term\": {\n" +
-                "                \"text\": \"baseball\"\n" +
-                "              }\n" +
-                "            },\n" +
-                "            \"weight\": 2\n" +
-                "          },\n" +
-                "          {\n" +
-                "            \"filter\": {\n" +
-                "              \"term\": {\n" +
-                "                \"text\": \"baseball\"\n" +
-                "              }\n" +
-                "            }\n" +
-                "          }\n" +
-                "        ]\n" +
-                "      }\n" +
-                "    }\n" +
-                "}";
-
-//        try {
-//            client().search(
-//                    searchRequest().source(new BytesArray(query))).actionGet();
-//            fail("Should fail with SearchPhaseExecutionException");
-//        } catch (SearchPhaseExecutionException failure) {
-//            assertThat(failure.toString(), containsString("SearchParseException"));
-//            assertThat(failure.toString(), not(containsString("NullPointerException")));
-//            assertThat(failure.toString(), containsString("an entry in functions list is missing a function"));
-//        } NOCOMMIT fix this
-
-        // next test java client
+        query.startObject().startObject("function_score").field("weight", "1").startArray("functions").startObject().startObject("script_score").field("script", "3").endObject().endObject().endArray().endObject().endObject();
         try {
-            client().prepareSearch("t").setQuery(QueryBuilders.functionScoreQuery(QueryBuilders.matchAllQuery(), null)).get();
-        } catch (IllegalArgumentException failure) {
-            assertThat(failure.toString(), containsString("function must not be null"));
-        }
-        try {
-            client().prepareSearch("t").setQuery(QueryBuilders.functionScoreQuery().add(QueryBuilders.matchAllQuery(), null)).get();
-        } catch (IllegalArgumentException failure) {
-            assertThat(failure.toString(), containsString("function must not be null"));
+            client().search(
+                    searchRequest().source(
+                            searchSource().query(query))).actionGet();
+            fail("Search should result in SearchPhaseExecutionException");
+        } catch (SearchPhaseExecutionException e) {
+            logger.info(e.shardFailures()[0].reason());
+            assertThat(e.shardFailures()[0].reason(), containsString("already found [weight], now encountering [functions]."));
         }
+
+        query = XContentFactory.jsonBuilder();
+        // query that contains a single function (but not boost factor) and a functions[] array
+        query.startObject().startObject("function_score").startObject("random_score").field("seed", 3).endObject().startArray("functions").startObject().startObject("random_score").field("seed", 3).endObject().endObject().endArray().endObject().endObject();
         try {
-            client().prepareSearch("t").setQuery(QueryBuilders.functionScoreQuery().add(null)).get();
-        } catch (IllegalArgumentException failure) {
-            assertThat(failure.toString(), containsString("function must not be null"));
+            client().search(
+                    searchRequest().source(
+                            searchSource().query(query))).actionGet();
+            fail("Search should result in SearchPhaseExecutionException");
+        } catch (SearchPhaseExecutionException e) {
+            logger.info(e.shardFailures()[0].reason());
+            assertThat(e.shardFailures()[0].reason(), containsString("already found [random_score], now encountering [functions]"));
+            assertThat(e.shardFailures()[0].reason(), not(containsString("did you mean [boost] instead?")));
+
         }
     }
 
@@ -945,11 +841,11 @@ public class DecayFunctionScoreIT extends ESIntegTestCase {
         SearchResponse response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().explain(true)
-                                .query(functionScoreQuery(termQuery("test", "value"))
-                                        .add(gaussDecayFunction("num", 1.0, 5.0).setOffset(1.0))
-                                        .add(linearDecayFunction("num", 1.0, 5.0).setOffset(1.0))
-                                        .add(exponentialDecayFunction("num", 1.0, 5.0).setOffset(1.0))
-                                        .boostMode(CombineFunction.REPLACE.getName())))).get();
+                                .query(functionScoreQuery(termQuery("test", "value"), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(gaussDecayFunction("num", 1.0, 5.0, 1.0)),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(linearDecayFunction("num", 1.0, 5.0, 1.0)),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(exponentialDecayFunction("num", 1.0, 5.0, 1.0))
+                                }).boostMode(CombineFunction.REPLACE)))).get();
         String explanation = response.getHits().getAt(0).getExplanation().toString();
         assertThat(explanation, containsString(" 1.0 = exp(-0.5*pow(MIN[Math.max(Math.abs(0.5(=doc value) - 1.0(=origin))) - 1.0(=offset), 0), Math.max(Math.abs(0.7(=doc value) - 1.0(=origin))) - 1.0(=offset), 0)],2.0)/18.033688011112044)"));
         assertThat(explanation, containsString("1.0 = max(0.0, ((10.0 - MIN[Math.max(Math.abs(0.5(=doc value) - 1.0(=origin))) - 1.0(=offset), 0), Math.max(Math.abs(0.7(=doc value) - 1.0(=origin))) - 1.0(=offset), 0)])/10.0)"));
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/ExplainableScriptIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/ExplainableScriptIT.java
index 1b942f6..eb7903f 100644
--- a/core/src/test/java/org/elasticsearch/search/functionscore/ExplainableScriptIT.java
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/ExplainableScriptIT.java
@@ -24,14 +24,10 @@ import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.lucene.search.function.CombineFunction;
 import org.elasticsearch.index.fielddata.ScriptDocValues;
 import org.elasticsearch.plugins.Plugin;
-import org.elasticsearch.script.AbstractDoubleSearchScript;
-import org.elasticsearch.script.ExecutableScript;
-import org.elasticsearch.script.ExplainableSearchScript;
-import org.elasticsearch.script.NativeScriptFactory;
-import org.elasticsearch.script.Script;
+import org.elasticsearch.script.*;
 import org.elasticsearch.script.ScriptService.ScriptType;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHits;
@@ -49,7 +45,6 @@ import java.util.Map;
 import java.util.concurrent.ExecutionException;
 
 import static org.elasticsearch.client.Requests.searchRequest;
-import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
 import static org.elasticsearch.index.query.QueryBuilders.termQuery;
@@ -79,9 +74,9 @@ public class ExplainableScriptIT extends ESIntegTestCase {
         ensureYellow();
         SearchResponse response = client().search(searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().explain(true).query(
-                                functionScoreQuery(termQuery("text", "text")).add(
+                                functionScoreQuery(termQuery("text", "text"),
                                         scriptFunction(new Script("native_explainable_script", ScriptType.INLINE, "native", null)))
-                                        .boostMode("replace")))).actionGet();
+                                        .boostMode(CombineFunction.REPLACE)))).actionGet();
 
         ElasticsearchAssertions.assertNoFailures(response);
         SearchHits hits = response.getHits();
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreBackwardCompatibilityIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreBackwardCompatibilityIT.java
index 80c4968..8bf957d 100644
--- a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreBackwardCompatibilityIT.java
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreBackwardCompatibilityIT.java
@@ -22,6 +22,7 @@ import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.test.ESBackcompatTestCase;
 import org.junit.Test;
@@ -110,11 +111,12 @@ public class FunctionScoreBackwardCompatibilityIT extends ESBackcompatTestCase {
         SearchResponse response = client().search(
                 searchRequest().source(
                         searchSource().query(
-                                functionScoreQuery(termQuery("text", "value"))
-                                        .add(gaussDecayFunction("loc", new GeoPoint(10, 20), "1000km"))
-                                        .add(scriptFunction(new Script("_index['text']['value'].tf()")))
-                                        .add(termQuery("text", "boosted"), weightFactorFunction(5))
-                        ))).actionGet();
+                                functionScoreQuery(termQuery("text", "value"), new FunctionScoreQueryBuilder.FilterFunctionBuilder[] {
+                                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(gaussDecayFunction("loc", new GeoPoint(10, 20), "1000km")),
+                                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(new Script("_index['text']['value'].tf()"))),
+                                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(termQuery("text", "boosted"), weightFactorFunction(5))
+                                        }
+                                )))).actionGet();
         assertSearchResponse(response);
         assertOrderedSearchHits(response, ids);
     }
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreFieldValueIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreFieldValueIT.java
index 55af7e8..419861d 100644
--- a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreFieldValueIT.java
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreFieldValueIT.java
@@ -21,7 +21,6 @@ package org.elasticsearch.search.functionscore;
 
 import org.elasticsearch.action.search.SearchPhaseExecutionException;
 import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.lucene.search.function.FieldValueFactorFunction;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
@@ -126,34 +125,5 @@ public class FunctionScoreFieldValueIT extends ESIntegTestCase {
             // This is fine, the query will throw an exception if executed
             // locally, instead of just having failures
         }
-
-//        // don't permit an array of factors
-//        try {
-//          String querySource = "{" +
-//            "\"query\": {" +
-//            "  \"function_score\": {" +
-//            "    \"query\": {" +
-//            "      \"match\": {\"name\": \"foo\"}" +
-//            "      }," +
-//            "      \"functions\": [" +
-//            "        {" +
-//            "          \"field_value_factor\": {" +
-//            "            \"field\": \"test\"," +
-//            "            \"factor\": [1.2,2]" +
-//            "          }" +
-//            "        }" +
-//            "      ]" +
-//            "    }" +
-//            "  }" +
-//            "}";
-//          response = client().prepareSearch("test")
-//          .setSource(new BytesArray(querySource))
-//                  .get();
-//          assertFailures(response);
-//        } catch (SearchPhaseExecutionException e) {
-//          // This is fine, the query will throw an exception if executed
-//          // locally, instead of just having failures
-//        } NOCOMMIT fix this
-
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreIT.java
index ae81dcb..4d78de1 100644
--- a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreIT.java
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScoreIT.java
@@ -25,8 +25,11 @@ import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.geo.GeoPoint;
+import org.elasticsearch.common.lucene.search.function.CombineFunction;
 import org.elasticsearch.common.lucene.search.function.FieldValueFactorFunction;
+import org.elasticsearch.common.lucene.search.function.FiltersFunctionScoreQuery;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.index.query.MatchAllQueryBuilder;
 import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder;
 import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilder;
 import org.elasticsearch.index.query.functionscore.weight.WeightBuilder;
@@ -90,21 +93,25 @@ public class FunctionScoreIT extends ESIntegTestCase {
         SearchResponse response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().explain(true).query(
-                                functionScoreQuery(termQuery("test", "value")).add(gaussDecayFunction("num", 5, 5)).add(exponentialDecayFunction("num", 5, 5)).add(linearDecayFunction("num", 5, 5))))).get();
+                                functionScoreQuery(termQuery("test", "value"), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(gaussDecayFunction("num", 5, 5)),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(exponentialDecayFunction("num", 5, 5)),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(linearDecayFunction("num", 5, 5))
+                                })))).get();
         String explanation = response.getHits().getAt(0).explanation().toString();
 
         checkQueryExplanationAppearsOnlyOnce(explanation);
         response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().explain(true).query(
-                                functionScoreQuery(termQuery("test", "value")).add(fieldValueFactorFunction("num"))))).get();
+                                functionScoreQuery(termQuery("test", "value"), fieldValueFactorFunction("num"))))).get();
         explanation = response.getHits().getAt(0).explanation().toString();
         checkQueryExplanationAppearsOnlyOnce(explanation);
 
         response = client().search(
                 searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                         searchSource().explain(true).query(
-                                functionScoreQuery(termQuery("test", "value")).add(randomFunction(10))))).get();
+                                functionScoreQuery(termQuery("test", "value"), randomFunction(10))))).get();
         explanation = response.getHits().getAt(0).explanation().toString();
 
         checkQueryExplanationAppearsOnlyOnce(explanation);
@@ -171,11 +178,11 @@ public class FunctionScoreIT extends ESIntegTestCase {
         SearchResponse responseWithWeights = client().search(
                 searchRequest().source(
                         searchSource().query(
-                                functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")))
-                                        .add(gaussDecayFunction(GEO_POINT_FIELD, new GeoPoint(10, 20), "1000km"))
-                                        .add(fieldValueFactorFunction(DOUBLE_FIELD).modifier(FieldValueFactorFunction.Modifier.LN).setWeight(2))
-                                        .add(scriptFunction(new Script("_index['" + TEXT_FIELD + "']['value'].tf()")).setWeight(3)))
-                                .explain(true))).actionGet();
+                                functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(gaussDecayFunction(GEO_POINT_FIELD, new GeoPoint(10, 20), "1000km")),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(fieldValueFactorFunction(DOUBLE_FIELD).modifier(FieldValueFactorFunction.Modifier.LN).setWeight(2)),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(new Script("_index['" + TEXT_FIELD + "']['value'].tf()")).setWeight(3))
+                                })).explain(true))).actionGet();
 
         assertThat(
                 responseWithWeights.getHits().getAt(0).getExplanation().toString(),
@@ -183,7 +190,7 @@ public class FunctionScoreIT extends ESIntegTestCase {
         responseWithWeights = client().search(
                 searchRequest().source(
                         searchSource().query(
-                                functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value"))).add(weightFactorFunction(4.0f)))
+                                functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")), weightFactorFunction(4.0f)))
                                 .explain(true))).actionGet();
         assertThat(
                 responseWithWeights.getHits().getAt(0).getExplanation().toString(),
@@ -203,19 +210,19 @@ public class FunctionScoreIT extends ESIntegTestCase {
         SearchResponse response = client().search(
                 searchRequest().source(
                         searchSource().query(
-                                functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")))
-                                        .add(gaussDecayFunction(GEO_POINT_FIELD, new GeoPoint(10, 20), "1000km"))
-                                        .add(fieldValueFactorFunction(DOUBLE_FIELD).modifier(FieldValueFactorFunction.Modifier.LN))
-                                        .add(scriptFunction(new Script("_index['" + TEXT_FIELD + "']['value'].tf()")))))).actionGet();
+                                functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(gaussDecayFunction(GEO_POINT_FIELD, new GeoPoint(10, 20), "1000km")),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(fieldValueFactorFunction(DOUBLE_FIELD).modifier(FieldValueFactorFunction.Modifier.LN)),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(new Script("_index['" + TEXT_FIELD + "']['value'].tf()")))
+                                })))).actionGet();
         SearchResponse responseWithWeights = client().search(
                 searchRequest().source(
                         searchSource().query(
-                                functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")))
-                                        .add(gaussDecayFunction(GEO_POINT_FIELD, new GeoPoint(10, 20), "1000km").setWeight(2))
-                                        .add(fieldValueFactorFunction(DOUBLE_FIELD).modifier(FieldValueFactorFunction.Modifier.LN)
-                                                .setWeight(2))
-                                        .add(scriptFunction(new Script("_index['" + TEXT_FIELD + "']['value'].tf()")).setWeight(2)))))
-                .actionGet();
+                                functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(gaussDecayFunction(GEO_POINT_FIELD, new GeoPoint(10, 20), "1000km").setWeight(2)),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(fieldValueFactorFunction(DOUBLE_FIELD).modifier(FieldValueFactorFunction.Modifier.LN).setWeight(2)),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(new Script("_index['" + TEXT_FIELD + "']['value'].tf()")).setWeight(2))
+                                })))).actionGet();
 
         assertSearchResponse(response);
         assertThat(response.getHits().getAt(0).getScore(), is(1.0f));
@@ -235,14 +242,16 @@ public class FunctionScoreIT extends ESIntegTestCase {
         ScoreFunctionBuilder[] scoreFunctionBuilders = getScoreFunctionBuilders();
         float[] weights = createRandomWeights(scoreFunctionBuilders.length);
         float[] scores = getScores(scoreFunctionBuilders);
-
-        String scoreMode = getRandomScoreMode();
-        FunctionScoreQueryBuilder withWeights = functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value"))).scoreMode(scoreMode);
         int weightscounter = 0;
+        FunctionScoreQueryBuilder.FilterFunctionBuilder[] filterFunctionBuilders = new FunctionScoreQueryBuilder.FilterFunctionBuilder[scoreFunctionBuilders.length];
         for (ScoreFunctionBuilder builder : scoreFunctionBuilders) {
-            withWeights.add(builder.setWeight(weights[weightscounter]));
+            filterFunctionBuilders[weightscounter] = new FunctionScoreQueryBuilder.FilterFunctionBuilder(builder.setWeight(weights[weightscounter]));
             weightscounter++;
         }
+        FiltersFunctionScoreQuery.ScoreMode scoreMode = randomFrom(FiltersFunctionScoreQuery.ScoreMode.AVG, FiltersFunctionScoreQuery.ScoreMode.SUM,
+                FiltersFunctionScoreQuery.ScoreMode.MIN, FiltersFunctionScoreQuery.ScoreMode.MAX, FiltersFunctionScoreQuery.ScoreMode.MULTIPLY);
+        FunctionScoreQueryBuilder withWeights = functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")), filterFunctionBuilders).scoreMode(scoreMode);
+
         SearchResponse responseWithWeights = client().search(
                 searchRequest().source(searchSource().query(withWeights))
         ).actionGet();
@@ -251,38 +260,48 @@ public class FunctionScoreIT extends ESIntegTestCase {
         assertThat((float) expectedScore / responseWithWeights.getHits().getAt(0).getScore(), is(1.0f));
     }
 
-    protected double computeExpectedScore(float[] weights, float[] scores, String scoreMode) {
-        double expectedScore = 0.0;
-        if ("multiply".equals(scoreMode)) {
-            expectedScore = 1.0;
-        }
-        if ("max".equals(scoreMode)) {
-            expectedScore = Float.MAX_VALUE * -1.0;
-        }
-        if ("min".equals(scoreMode)) {
-            expectedScore = Float.MAX_VALUE;
+    protected double computeExpectedScore(float[] weights, float[] scores, FiltersFunctionScoreQuery.ScoreMode scoreMode) {
+        double expectedScore;
+        switch(scoreMode) {
+            case MULTIPLY:
+                expectedScore = 1.0;
+                break;
+            case MAX:
+                expectedScore = Float.MAX_VALUE * -1.0;
+                break;
+            case MIN:
+                expectedScore = Float.MAX_VALUE;
+                break;
+            default:
+                expectedScore = 0.0;
+                break;
         }
 
         float weightSum = 0;
-
         for (int i = 0; i < weights.length; i++) {
             double functionScore = (double) weights[i] * scores[i];
             weightSum += weights[i];
-
-            if ("avg".equals(scoreMode)) {
-                expectedScore += functionScore;
-            } else if ("max".equals(scoreMode)) {
-                expectedScore = Math.max(functionScore, expectedScore);
-            } else if ("min".equals(scoreMode)) {
-                expectedScore = Math.min(functionScore, expectedScore);
-            } else if ("sum".equals(scoreMode)) {
-                expectedScore += functionScore;
-            } else if ("multiply".equals(scoreMode)) {
-                expectedScore *= functionScore;
+            switch(scoreMode) {
+                case AVG:
+                    expectedScore += functionScore;
+                    break;
+                case MAX:
+                    expectedScore = Math.max(functionScore, expectedScore);
+                    break;
+                case MIN:
+                    expectedScore = Math.min(functionScore, expectedScore);
+                    break;
+                case SUM:
+                    expectedScore += functionScore;
+                    break;
+                case MULTIPLY:
+                    expectedScore *= functionScore;
+                    break;
+                default:
+                    throw new UnsupportedOperationException();
             }
-
         }
-        if ("avg".equals(scoreMode)) {
+        if (scoreMode == FiltersFunctionScoreQuery.ScoreMode.AVG) {
             expectedScore /= weightSum;
         }
         return expectedScore;
@@ -309,8 +328,7 @@ public class FunctionScoreIT extends ESIntegTestCase {
         ScoreFunctionBuilder scoreFunctionBuilder = scoreFunctionBuilders[randomInt(3)];
         float[] weights = createRandomWeights(1);
         float[] scores = getScores(scoreFunctionBuilder);
-        FunctionScoreQueryBuilder withWeights = functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")));
-        withWeights.add(scoreFunctionBuilder.setWeight(weights[0]));
+        FunctionScoreQueryBuilder withWeights = functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")), scoreFunctionBuilder.setWeight(weights[0]));
 
         SearchResponse responseWithWeights = client().search(
                 searchRequest().source(searchSource().query(withWeights))
@@ -320,11 +338,6 @@ public class FunctionScoreIT extends ESIntegTestCase {
 
     }
 
-    private String getRandomScoreMode() {
-        String[] scoreModes = {"avg", "sum", "min", "max", "multiply"};
-        return scoreModes[randomInt(scoreModes.length - 1)];
-    }
-
     private float[] getScores(ScoreFunctionBuilder... scoreFunctionBuilders) {
         float[] scores = new float[scoreFunctionBuilders.length];
         int scorecounter = 0;
@@ -332,8 +345,7 @@ public class FunctionScoreIT extends ESIntegTestCase {
             SearchResponse response = client().search(
                     searchRequest().source(
                             searchSource().query(
-                                    functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")))
-                                            .add(builder)
+                                    functionScoreQuery(constantScoreQuery(termQuery(TEXT_FIELD, "value")), builder)
                             ))).actionGet();
             scores[scorecounter] = response.getHits().getAt(0).getScore();
             scorecounter++;
@@ -358,55 +370,55 @@ public class FunctionScoreIT extends ESIntegTestCase {
         return builders;
     }
 
-//    @Test
-//    public void checkWeightOnlyCreatesBoostFunction() throws IOException {
-//        assertAcked(prepareCreate(INDEX).addMapping(
-//                TYPE,
-//                MAPPING_WITH_DOUBLE_AND_GEO_POINT_AND_TEXT_FIELD));
-//        ensureYellow();
-//
-//        index(INDEX, TYPE, "1", SIMPLE_DOC);
-//        refresh();
-//        String query =jsonBuilder().startObject()
-//                .startObject("query")
-//                .startObject("function_score")
-//                .startArray("functions")
-//                .startObject()
-//                .field("weight",2)
-//                .endObject()
-//                .endArray()
-//                .endObject()
-//                .endObject()
-//                .endObject().string();
-//        SearchResponse response = client().search(
-//                searchRequest().source(new BytesArray(query))
-//                ).actionGet();
-//        assertSearchResponse(response);
-//        assertThat(response.getHits().getAt(0).score(), equalTo(2.0f));
-//
-//        query =jsonBuilder().startObject()
-//                .startObject("query")
-//                .startObject("function_score")
-//                .field("weight",2)
-//                .endObject()
-//                .endObject()
-//                .endObject().string();
-//        response = client().search(
-//                searchRequest().source(new BytesArray(query))
-//        ).actionGet();
-//        assertSearchResponse(response);
-//        assertThat(response.getHits().getAt(0).score(), equalTo(2.0f));
-//        response = client().search(
-//                searchRequest().source(searchSource().query(functionScoreQuery().add(new WeightBuilder().setWeight(2.0f))))
-//        ).actionGet();
-//        assertSearchResponse(response);
-//        assertThat(response.getHits().getAt(0).score(), equalTo(2.0f));
-//        response = client().search(
-//                searchRequest().source(searchSource().query(functionScoreQuery().add(weightFactorFunction(2.0f))))
-//        ).actionGet();
-//        assertSearchResponse(response);
-//        assertThat(response.getHits().getAt(0).score(), equalTo(2.0f));
-//    } NOCOMMIT fix this
+    @Test
+    public void checkWeightOnlyCreatesBoostFunction() throws IOException {
+        assertAcked(prepareCreate(INDEX).addMapping(
+                TYPE,
+                MAPPING_WITH_DOUBLE_AND_GEO_POINT_AND_TEXT_FIELD));
+        ensureYellow();
+
+        index(INDEX, TYPE, "1", SIMPLE_DOC);
+        refresh();
+        String query =jsonBuilder().startObject()
+                .startObject("query")
+                .startObject("function_score")
+                .startArray("functions")
+                .startObject()
+                .field("weight",2)
+                .endObject()
+                .endArray()
+                .endObject()
+                .endObject()
+                .endObject().string();
+        SearchResponse response = client().search(
+                searchRequest().source(new BytesArray(query))
+                ).actionGet();
+        assertSearchResponse(response);
+        assertThat(response.getHits().getAt(0).score(), equalTo(2.0f));
+
+        query =jsonBuilder().startObject()
+                .startObject("query")
+                .startObject("function_score")
+                .field("weight",2)
+                .endObject()
+                .endObject()
+                .endObject().string();
+        response = client().search(
+                searchRequest().source(new BytesArray(query))
+        ).actionGet();
+        assertSearchResponse(response);
+        assertThat(response.getHits().getAt(0).score(), equalTo(2.0f));
+        response = client().search(
+                searchRequest().source(searchSource().query(functionScoreQuery(new WeightBuilder().setWeight(2.0f))))
+        ).actionGet();
+        assertSearchResponse(response);
+        assertThat(response.getHits().getAt(0).score(), equalTo(2.0f));
+        response = client().search(
+                searchRequest().source(searchSource().query(functionScoreQuery(weightFactorFunction(2.0f))))
+        ).actionGet();
+        assertSearchResponse(response);
+        assertThat(response.getHits().getAt(0).score(), equalTo(2.0f));
+    }
 
     @Test
     public void testScriptScoresNested() throws IOException {
@@ -419,10 +431,10 @@ public class FunctionScoreIT extends ESIntegTestCase {
                         searchSource().query(
                                 functionScoreQuery(
                                         functionScoreQuery(
-functionScoreQuery().add(scriptFunction(new Script("1")))).add(
-                                                scriptFunction(new Script("_score.doubleValue()")))).add(
+                                                functionScoreQuery(scriptFunction(new Script("1"))),
+                                                scriptFunction(new Script("_score.doubleValue()"))),
                                         scriptFunction(new Script("_score.doubleValue()"))
-                                        )
+                                )
                         )
                 )
         ).actionGet();
@@ -438,7 +450,7 @@ functionScoreQuery().add(scriptFunction(new Script("1")))).add(
         refresh();
         SearchResponse response = client().search(
                 searchRequest().source(
-                        searchSource().query(functionScoreQuery().add(scriptFunction(new Script("_score.doubleValue()")))).aggregation(
+                        searchSource().query(functionScoreQuery(scriptFunction(new Script("_score.doubleValue()")))).aggregation(
                                 terms("score_agg").script(new Script("_score.doubleValue()")))
                 )
         ).actionGet();
@@ -457,7 +469,7 @@ functionScoreQuery().add(scriptFunction(new Script("1")))).add(
         SearchResponse searchResponse = client().search(
                 searchRequest().source(
                         searchSource().query(
-                                functionScoreQuery().add(scriptFunction(new Script(Float.toString(score)))).setMinScore(minScore)))
+                                functionScoreQuery(scriptFunction(new Script(Float.toString(score)))).setMinScore(minScore)))
         ).actionGet();
         if (score < minScore) {
             assertThat(searchResponse.getHits().getTotalHits(), is(0l));
@@ -466,11 +478,11 @@ functionScoreQuery().add(scriptFunction(new Script("1")))).add(
         }
 
         searchResponse = client().search(
-                searchRequest().source(searchSource().query(functionScoreQuery()
-.add(scriptFunction(new Script(Float.toString(score))))
-                                        .add(scriptFunction(new Script(Float.toString(score))))
-                        .scoreMode("avg").setMinScore(minScore)))
-        ).actionGet();
+                searchRequest().source(searchSource().query(functionScoreQuery(new MatchAllQueryBuilder(), new FunctionScoreQueryBuilder.FilterFunctionBuilder[] {
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(new Script(Float.toString(score)))),
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(new Script(Float.toString(score))))
+                        }).scoreMode(FiltersFunctionScoreQuery.ScoreMode.AVG).setMinScore(minScore)))
+                ).actionGet();
         if (score < minScore) {
             assertThat(searchResponse.getHits().getTotalHits(), is(0l));
         } else {
@@ -499,16 +511,15 @@ functionScoreQuery().add(scriptFunction(new Script("1")))).add(
         }
 
         SearchResponse searchResponse = client().search(
-                searchRequest().source(searchSource().query(functionScoreQuery()
-                        .add(scriptFunction(script))
+                searchRequest().source(searchSource().query(functionScoreQuery(scriptFunction(script))
                         .setMinScore(minScore)).size(numDocs))).actionGet();
         assertMinScoreSearchResponses(numDocs, searchResponse, numMatchingDocs);
 
         searchResponse = client().search(
-                searchRequest().source(searchSource().query(functionScoreQuery()
-                        .add(scriptFunction(script))
-                        .add(scriptFunction(script))
-                        .scoreMode("avg").setMinScore(minScore)).size(numDocs))).actionGet();
+                searchRequest().source(searchSource().query(functionScoreQuery(new MatchAllQueryBuilder(), new FunctionScoreQueryBuilder.FilterFunctionBuilder[] {
+                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(script)),
+                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(script))
+                }).scoreMode(FiltersFunctionScoreQuery.ScoreMode.AVG).setMinScore(minScore)).size(numDocs))).actionGet();
         assertMinScoreSearchResponses(numDocs, searchResponse, numMatchingDocs);
     }
 
@@ -531,15 +542,12 @@ functionScoreQuery().add(scriptFunction(new Script("1")))).add(
 
         // make sure that min_score works if functions is empty, see https://github.com/elastic/elasticsearch/issues/10253
         float termQueryScore = 0.19178301f;
-        testMinScoreApplied("sum", termQueryScore);
-        testMinScoreApplied("avg", termQueryScore);
-        testMinScoreApplied("max", termQueryScore);
-        testMinScoreApplied("min", termQueryScore);
-        testMinScoreApplied("multiply", termQueryScore);
-        testMinScoreApplied("replace", termQueryScore);
+        for (CombineFunction combineFunction : CombineFunction.values()) {
+            testMinScoreApplied(combineFunction, termQueryScore);
+        }
     }
 
-    protected void testMinScoreApplied(String boostMode, float expectedScore) throws InterruptedException, ExecutionException {
+    protected void testMinScoreApplied(CombineFunction boostMode, float expectedScore) throws InterruptedException, ExecutionException {
         SearchResponse response = client().search(
                 searchRequest().source(
                         searchSource().explain(true).query(
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScorePluginIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScorePluginIT.java
index 946fb59..4dab3c3 100644
--- a/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScorePluginIT.java
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/FunctionScorePluginIT.java
@@ -24,7 +24,7 @@ import org.elasticsearch.action.ActionFuture;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.common.Priority;
-import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.index.query.functionscore.DecayFunction;
 import org.elasticsearch.index.query.functionscore.DecayFunctionBuilder;
 import org.elasticsearch.index.query.functionscore.DecayFunctionParser;
@@ -41,7 +41,6 @@ import java.util.Collection;
 
 import static org.elasticsearch.client.Requests.indexRequest;
 import static org.elasticsearch.client.Requests.searchRequest;
-import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
 import static org.elasticsearch.index.query.QueryBuilders.termQuery;
@@ -82,7 +81,7 @@ public class FunctionScorePluginIT extends ESIntegTestCase {
         DecayFunctionBuilder gfb = new CustomDistanceScoreBuilder("num1", "2013-05-28", "+1d");
 
         ActionFuture<SearchResponse> response = client().search(searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
-                searchSource().explain(false).query(functionScoreQuery(termQuery("test", "value")).add(gfb))));
+                searchSource().explain(false).query(functionScoreQuery(termQuery("test", "value"), gfb))));
 
         SearchResponse sr = response.actionGet();
         ElasticsearchAssertions.assertNoFailures(sr);
@@ -109,10 +108,11 @@ public class FunctionScorePluginIT extends ESIntegTestCase {
         public void onModule(SearchModule scoreModule) {
             scoreModule.registerFunctionScoreParser(FunctionScorePluginIT.CustomDistanceScoreParser.class);
         }
-
     }
 
-    public static class CustomDistanceScoreParser extends DecayFunctionParser {
+    public static class CustomDistanceScoreParser extends DecayFunctionParser<CustomDistanceScoreBuilder> {
+
+        private static final CustomDistanceScoreBuilder PROTOTYPE = new CustomDistanceScoreBuilder("", "", "");
 
         public static final String[] NAMES = { "linear_mult", "linearMult" };
 
@@ -121,20 +121,46 @@ public class FunctionScorePluginIT extends ESIntegTestCase {
             return NAMES;
         }
 
-        static final DecayFunction decayFunction = new LinearMultScoreFunction();
+        @Override
+        public CustomDistanceScoreBuilder getBuilderPrototype() {
+            return PROTOTYPE;
+        }
+    }
+
+    public static class CustomDistanceScoreBuilder extends DecayFunctionBuilder<CustomDistanceScoreBuilder> {
+
+        public CustomDistanceScoreBuilder(String fieldName, Object origin, Object scale) {
+            super(fieldName, origin, scale, null);
+        }
+
+        private CustomDistanceScoreBuilder(String fieldName, BytesReference functionBytes) {
+            super(fieldName, functionBytes);
+        }
+
+        @Override
+        protected CustomDistanceScoreBuilder createFunctionBuilder(String fieldName, BytesReference functionBytes) {
+            return new CustomDistanceScoreBuilder(fieldName, functionBytes);
+        }
+
+        @Override
+        public String getName() {
+            return CustomDistanceScoreParser.NAMES[0];
+        }
 
         @Override
         public DecayFunction getDecayFunction() {
             return decayFunction;
         }
 
-        static class LinearMultScoreFunction implements DecayFunction {
+        private static final DecayFunction decayFunction = new LinearMultScoreFunction();
+
+        private static class LinearMultScoreFunction implements DecayFunction {
             LinearMultScoreFunction() {
             }
 
             @Override
             public double evaluate(double value, double scale) {
-                
+
                 return value;
             }
 
@@ -149,17 +175,4 @@ public class FunctionScorePluginIT extends ESIntegTestCase {
             }
         }
     }
-
-    public class CustomDistanceScoreBuilder extends DecayFunctionBuilder {
-
-        public CustomDistanceScoreBuilder(String fieldName, Object origin, Object scale) {
-            super(fieldName, origin, scale);
-        }
-
-        @Override
-        public String getName() {
-            return CustomDistanceScoreParser.NAMES[0];
-        }
-
-    }
 }
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java
index cdbe3be..094f528 100644
--- a/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java
@@ -20,6 +20,7 @@ package org.elasticsearch.search.functionscore;
 
 import org.apache.lucene.util.ArrayUtil;
 import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.index.query.functionscore.FunctionScoreQueryBuilder;
 import org.elasticsearch.index.query.functionscore.random.RandomScoreFunctionBuilder;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.ScriptService.ScriptType;
@@ -104,7 +105,7 @@ public class RandomScoreFunctionIT extends ESIntegTestCase {
 
     public void testScoreAccessWithinScript() throws Exception {
         assertAcked(prepareCreate("test").addMapping("type", "body", "type=string", "index",
-                "type=" + randomFrom(new String[] { "short", "float", "long", "integer", "double" })));
+                "type=" + randomFrom("short", "float", "long", "integer", "double")));
         ensureYellow();
 
         int docCount = randomIntBetween(100, 200);
@@ -120,9 +121,10 @@ public class RandomScoreFunctionIT extends ESIntegTestCase {
         SearchResponse resp = client()
                 .prepareSearch("test")
                 .setQuery(
-                        functionScoreQuery(matchQuery("body", "foo")).add(fieldValueFactorFunction("index").factor(2)).add(
-                                scriptFunction(new Script("log(doc['index'].value + (factor * _score))", ScriptType.INLINE, null, params))))
-                .get();
+                        functionScoreQuery(matchQuery("body", "foo"), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(fieldValueFactorFunction("index").factor(2)),
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(new Script("log(doc['index'].value + (factor * _score))", ScriptType.INLINE, null, params)))
+                        })).get();
         assertNoFailures(resp);
         SearchHit firstHit = resp.getHits().getAt(0);
         assertThat(firstHit.getScore(), greaterThan(1f));
@@ -131,9 +133,10 @@ public class RandomScoreFunctionIT extends ESIntegTestCase {
         resp = client()
                 .prepareSearch("test")
                 .setQuery(
-                        functionScoreQuery(matchQuery("body", "foo")).add(fieldValueFactorFunction("index").factor(2)).add(
-                                scriptFunction(new Script("log(doc['index'].value + (factor * _score.intValue()))", ScriptType.INLINE,
-                                        null, params)))).get();
+                        functionScoreQuery(matchQuery("body", "foo"), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(fieldValueFactorFunction("index").factor(2)),
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(new Script("log(doc['index'].value + (factor * _score.intValue()))", ScriptType.INLINE, null, params)))
+                        })).get();
         assertNoFailures(resp);
         firstHit = resp.getHits().getAt(0);
         assertThat(firstHit.getScore(), greaterThan(1f));
@@ -142,9 +145,10 @@ public class RandomScoreFunctionIT extends ESIntegTestCase {
         resp = client()
                 .prepareSearch("test")
                 .setQuery(
-                        functionScoreQuery(matchQuery("body", "foo")).add(fieldValueFactorFunction("index").factor(2)).add(
-                                scriptFunction(new Script("log(doc['index'].value + (factor * _score.longValue()))", ScriptType.INLINE,
-                                        null, params)))).get();
+                        functionScoreQuery(matchQuery("body", "foo"), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(fieldValueFactorFunction("index").factor(2)),
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(new Script("log(doc['index'].value + (factor * _score.longValue()))", ScriptType.INLINE, null, params)))
+                        })).get();
         assertNoFailures(resp);
         firstHit = resp.getHits().getAt(0);
         assertThat(firstHit.getScore(), greaterThan(1f));
@@ -153,9 +157,11 @@ public class RandomScoreFunctionIT extends ESIntegTestCase {
         resp = client()
                 .prepareSearch("test")
                 .setQuery(
-                        functionScoreQuery(matchQuery("body", "foo")).add(fieldValueFactorFunction("index").factor(2)).add(
-                                scriptFunction(new Script("log(doc['index'].value + (factor * _score.floatValue()))", ScriptType.INLINE,
-                                        null, params)))).get();
+                        functionScoreQuery(matchQuery("body", "foo"), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(fieldValueFactorFunction("index").factor(2)),
+                                new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(new Script("log(doc['index'].value + (factor * _score.floatValue()))",
+                                        ScriptType.INLINE, null, params)))
+                        })).get();
         assertNoFailures(resp);
         firstHit = resp.getHits().getAt(0);
         assertThat(firstHit.getScore(), greaterThan(1f));
@@ -164,9 +170,11 @@ public class RandomScoreFunctionIT extends ESIntegTestCase {
         resp = client()
                 .prepareSearch("test")
                 .setQuery(
-                        functionScoreQuery(matchQuery("body", "foo")).add(fieldValueFactorFunction("index").factor(2)).add(
-                                scriptFunction(new Script("log(doc['index'].value + (factor * _score.doubleValue()))", ScriptType.INLINE,
-                                        null, params)))).get();
+                        functionScoreQuery(matchQuery("body", "foo"), new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(fieldValueFactorFunction("index").factor(2)),
+                                        new FunctionScoreQueryBuilder.FilterFunctionBuilder(scriptFunction(new Script("log(doc['index'].value + (factor * _score.doubleValue()))",
+                                                ScriptType.INLINE, null, params)))
+                                })).get();
         assertNoFailures(resp);
         firstHit = resp.getHits().getAt(0);
         assertThat(firstHit.getScore(), greaterThan(1f));
diff --git a/core/src/test/java/org/elasticsearch/search/geo/GeoFilterIT.java b/core/src/test/java/org/elasticsearch/search/geo/GeoFilterIT.java
index 4a2c8bd..4548fbd 100644
--- a/core/src/test/java/org/elasticsearch/search/geo/GeoFilterIT.java
+++ b/core/src/test/java/org/elasticsearch/search/geo/GeoFilterIT.java
@@ -536,22 +536,22 @@ public class GeoFilterIT extends ESIntegTestCase {
 
             }
         }
-        // NORELEASE these should be tested in GeohashCellQueryBuilderTests
-//        logger.info("Testing lat/lon format");
-//        String pointTest1 = "{\"geohash_cell\": {\"pin\": {\"lat\": " + point.lat() + ",\"lon\": " + point.lon() + "},\"precision\": " + precision + ",\"neighbors\": true}}";
-//        SearchResponse results3 = client().prepareSearch("locations").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(pointTest1).execute().actionGet();
-//        assertHitCount(results3, neighbors.size() + 1);
-//
-//
-//        logger.info("Testing String format");
-//        String pointTest2 = "{\"geohash_cell\": {\"pin\": \"" + point.lat() + "," + point.lon() + "\",\"precision\": " + precision + ",\"neighbors\": true}}";
-//        SearchResponse results4 = client().prepareSearch("locations").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(pointTest2).execute().actionGet();
-//        assertHitCount(results4, neighbors.size() + 1);
-//
-//        logger.info("Testing Array format");
-//        String pointTest3 = "{\"geohash_cell\": {\"pin\": [" + point.lon() + "," + point.lat() + "],\"precision\": " + precision + ",\"neighbors\": true}}";
-//        SearchResponse results5 = client().prepareSearch("locations").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(pointTest3).execute().actionGet();
-//        assertHitCount(results5, neighbors.size() + 1);
+
+        logger.info("Testing lat/lon format");
+        String pointTest1 = "{\"geohash_cell\": {\"pin\": {\"lat\": " + point.lat() + ",\"lon\": " + point.lon() + "},\"precision\": " + precision + ",\"neighbors\": true}}";
+        SearchResponse results3 = client().prepareSearch("locations").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(pointTest1).execute().actionGet();
+        assertHitCount(results3, neighbors.size() + 1);
+
+
+        logger.info("Testing String format");
+        String pointTest2 = "{\"geohash_cell\": {\"pin\": \"" + point.lat() + "," + point.lon() + "\",\"precision\": " + precision + ",\"neighbors\": true}}";
+        SearchResponse results4 = client().prepareSearch("locations").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(pointTest2).execute().actionGet();
+        assertHitCount(results4, neighbors.size() + 1);
+
+        logger.info("Testing Array format");
+        String pointTest3 = "{\"geohash_cell\": {\"pin\": [" + point.lon() + "," + point.lat() + "],\"precision\": " + precision + ",\"neighbors\": true}}";
+        SearchResponse results5 = client().prepareSearch("locations").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(pointTest3).execute().actionGet();
+        assertHitCount(results5, neighbors.size() + 1);
     }
 
     @Test
diff --git a/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java b/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java
index 64b42a0..670d317 100644
--- a/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java
+++ b/core/src/test/java/org/elasticsearch/search/geo/GeoShapeIntegrationIT.java
@@ -225,44 +225,43 @@ public class GeoShapeIntegrationIT extends ESIntegTestCase {
         assertThat(before, equalTo(after));
     }
 
-    // NORELEASE  these should be tested in GeoShapeQueryBuilderTests
-//    @Test
-//    public void testParsingMultipleShapes() throws Exception {
-//        String mapping = XContentFactory.jsonBuilder()
-//                .startObject()
-//                .startObject("type1")
-//                .startObject("properties")
-//                .startObject("location1")
-//                .field("type", "geo_shape")
-//                .endObject()
-//                .startObject("location2")
-//                .field("type", "geo_shape")
-//                .endObject()
-//                .endObject()
-//                .endObject()
-//                .endObject()
-//                .string();
-//
-//        assertAcked(prepareCreate("test").addMapping("type1", mapping));
-//        ensureYellow();
-//
-//        String p1 = "\"location1\" : {\"type\":\"polygon\", \"coordinates\":[[[-10,-10],[10,-10],[10,10],[-10,10],[-10,-10]]]}";
-//        String p2 = "\"location2\" : {\"type\":\"polygon\", \"coordinates\":[[[-20,-20],[20,-20],[20,20],[-20,20],[-20,-20]]]}";
-//        String o1 = "{" + p1 + ", " + p2 + "}";
-//
-//        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource(o1));
-//
-//        String filter = "{\"geo_shape\": {\"location2\": {\"indexed_shape\": {"
-//                + "\"id\": \"1\","
-//                + "\"type\": \"type1\","
-//                + "\"index\": \"test\","
-//                + "\"path\": \"location2\""
-//                + "}}}}";
-//
-//        SearchResponse result = client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(filter).execute().actionGet();
-//        assertSearchResponse(result);
-//        assertHitCount(result, 1);
-//    }
+    @Test
+    public void testParsingMultipleShapes() throws Exception {
+        String mapping = XContentFactory.jsonBuilder()
+                .startObject()
+                .startObject("type1")
+                .startObject("properties")
+                .startObject("location1")
+                .field("type", "geo_shape")
+                .endObject()
+                .startObject("location2")
+                .field("type", "geo_shape")
+                .endObject()
+                .endObject()
+                .endObject()
+                .endObject()
+                .string();
+
+        assertAcked(prepareCreate("test").addMapping("type1", mapping));
+        ensureYellow();
+
+        String p1 = "\"location1\" : {\"type\":\"polygon\", \"coordinates\":[[[-10,-10],[10,-10],[10,10],[-10,10],[-10,-10]]]}";
+        String p2 = "\"location2\" : {\"type\":\"polygon\", \"coordinates\":[[[-20,-20],[20,-20],[20,20],[-20,20],[-20,-20]]]}";
+        String o1 = "{" + p1 + ", " + p2 + "}";
+
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource(o1));
+
+        String filter = "{\"geo_shape\": {\"location2\": {\"indexed_shape\": {"
+                + "\"id\": \"1\","
+                + "\"type\": \"type1\","
+                + "\"index\": \"test\","
+                + "\"path\": \"location2\""
+                + "}}}}";
+
+        SearchResponse result = client().prepareSearch("test").setQuery(QueryBuilders.matchAllQuery()).setPostFilter(filter).execute().actionGet();
+        assertSearchResponse(result);
+        assertHitCount(result, 1);
+    }
 
     @Test
     public void testShapeFetchingPath() throws Exception {
diff --git a/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighterSearchIT.java b/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighterSearchIT.java
index 5f5ecfc..7c1f163 100644
--- a/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighterSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/highlight/CustomHighlighterSearchIT.java
@@ -60,7 +60,7 @@ public class CustomHighlighterSearchIT extends ESIntegTestCase {
     public void testThatCustomHighlightersAreSupported() throws IOException {
         SearchResponse searchResponse = client().prepareSearch("test").setTypes("test")
                 .setQuery(QueryBuilders.matchAllQuery())
-                .highlighter(new HighlightBuilder().field("name").highlighterType("test-custom"))
+                .addHighlightedField("name").setHighlighterType("test-custom")
                 .execute().actionGet();
         assertHighlight(searchResponse, 0, "name", 0, equalTo("standard response for name at position 1"));
     }
@@ -75,7 +75,7 @@ public class CustomHighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse searchResponse = client().prepareSearch("test").setTypes("test")
                 .setQuery(QueryBuilders.matchAllQuery())
-                .highlighter(new HighlightBuilder().field(highlightConfig))
+                .addHighlightedField(highlightConfig)
                 .execute().actionGet();
 
         assertHighlight(searchResponse, 0, "name", 0, equalTo("standard response for name at position 1"));
@@ -87,8 +87,11 @@ public class CustomHighlighterSearchIT extends ESIntegTestCase {
         Map<String, Object> options = new HashMap<>();
         options.put("myGlobalOption", "someValue");
 
-        SearchResponse searchResponse = client().prepareSearch("test").setTypes("test").setQuery(QueryBuilders.matchAllQuery())
-                .highlighter(new HighlightBuilder().field("name").highlighterType("test-custom").options(options))
+        SearchResponse searchResponse = client().prepareSearch("test").setTypes("test")
+                .setQuery(QueryBuilders.matchAllQuery())
+                .setHighlighterOptions(options)
+                .setHighlighterType("test-custom")
+                .addHighlightedField("name")
                 .execute().actionGet();
 
         assertHighlight(searchResponse, 0, "name", 0, equalTo("standard response for name at position 1"));
@@ -100,9 +103,11 @@ public class CustomHighlighterSearchIT extends ESIntegTestCase {
         SearchResponse searchResponse = client().prepareSearch("test").setTypes("test")
                 .setQuery(QueryBuilders.boolQuery().must(QueryBuilders.matchAllQuery()).should(QueryBuilders
                         .termQuery("name", "arbitrary")))
-                .highlighter(
-                        new HighlightBuilder().highlighterType("test-custom").field("name").field("other_name").field("other_other_name")
-                                .useExplicitFieldOrder(true))
+                .setHighlighterType("test-custom")
+                .addHighlightedField("name")
+                .addHighlightedField("other_name")
+                .addHighlightedField("other_other_name")
+                .setHighlighterExplicitFieldOrder(true)
                 .get();
 
         assertHighlight(searchResponse, 0, "name", 0, equalTo("standard response for name at position 1"));
diff --git a/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java b/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
index 93fd7eb..4134c4f 100644
--- a/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
@@ -19,22 +19,20 @@
 package org.elasticsearch.search.highlight;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.settings.Settings.Builder;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.AbstractQueryBuilder;
+import org.elasticsearch.index.query.*;
 import org.elasticsearch.index.query.IdsQueryBuilder;
 import org.elasticsearch.index.query.MatchQueryBuilder;
+import org.elasticsearch.index.search.MatchQuery.Type;
+import org.elasticsearch.index.search.MatchQuery;
 import org.elasticsearch.index.query.MultiMatchQueryBuilder;
-import org.elasticsearch.index.query.Operator;
 import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.search.MatchQuery;
-import org.elasticsearch.index.search.MatchQuery.Type;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.builder.SearchSourceBuilder;
@@ -51,38 +49,12 @@ import java.util.Map;
 import static org.elasticsearch.client.Requests.searchRequest;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.boolQuery;
-import static org.elasticsearch.index.query.QueryBuilders.boostingQuery;
-import static org.elasticsearch.index.query.QueryBuilders.commonTermsQuery;
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.fuzzyQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchPhrasePrefixQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchPhraseQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
-import static org.elasticsearch.index.query.QueryBuilders.missingQuery;
-import static org.elasticsearch.index.query.QueryBuilders.multiMatchQuery;
-import static org.elasticsearch.index.query.QueryBuilders.prefixQuery;
-import static org.elasticsearch.index.query.QueryBuilders.queryStringQuery;
-import static org.elasticsearch.index.query.QueryBuilders.rangeQuery;
-import static org.elasticsearch.index.query.QueryBuilders.regexpQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.index.query.QueryBuilders.typeQuery;
-import static org.elasticsearch.index.query.QueryBuilders.wildcardQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.highlight;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.searchSource;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHighlight;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNotHighlighted;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.elasticsearch.test.hamcrest.RegexMatcher.matches;
-import static org.hamcrest.Matchers.anyOf;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.hasKey;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.startsWith;
+import static org.hamcrest.Matchers.*;
 
 public class HighlighterSearchIT extends ESIntegTestCase {
 
@@ -110,8 +82,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
                 .get();
         refresh();
         String highlighter = randomFrom(new String[]{"plain", "postings", "fvh"});
-        SearchResponse search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("text", "text")))
-                .highlighter(new HighlightBuilder().field(new Field("*").highlighterType(highlighter))).get();
+        SearchResponse search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("text", "text"))).addHighlightedField(new Field("*").highlighterType(highlighter)).get();
         assertHighlight(search, 0, "text", 0, equalTo("<em>text</em>"));
     }
 
@@ -150,17 +121,14 @@ public class HighlighterSearchIT extends ESIntegTestCase {
                 .setSource(jsonBuilder().startObject().field("long_text", builder.toString()).field("text", "text").endObject())
                 .get();
         refresh();
-        String highlighter = randomFrom(new String[] { "plain", "postings", "fvh" });
-        SearchResponse search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("text", "text")))
-                .highlighter(new HighlightBuilder().field(new Field("*").highlighterType(highlighter))).get();
+        String highlighter = randomFrom(new String[]{"plain", "postings", "fvh"});
+        SearchResponse search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("text", "text"))).addHighlightedField(new Field("*").highlighterType(highlighter)).get();
         assertHighlight(search, 0, "text", 0, equalTo("<em>text</em>"));
-        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("text", "text")))
-                .highlighter(new HighlightBuilder().field(new Field("long_text").highlighterType(highlighter))).get();
+        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("text", "text"))).addHighlightedField(new Field("long_text").highlighterType(highlighter)).get();
         assertNoFailures(search);
         assertThat(search.getHits().getAt(0).getHighlightFields().size(), equalTo(0));
 
-        search = client().prepareSearch().setQuery(prefixQuery("text", "te"))
-                .highlighter(new HighlightBuilder().field(new Field("long_text").highlighterType(highlighter))).get();
+        search = client().prepareSearch().setQuery(prefixQuery("text", "te")).addHighlightedField(new Field("long_text").highlighterType(highlighter)).get();
         assertNoFailures(search);
         assertThat(search.getHits().getAt(0).getHighlightFields().size(), equalTo(0));
     }
@@ -196,12 +164,10 @@ public class HighlighterSearchIT extends ESIntegTestCase {
                 .setSource(jsonBuilder().startObject().field("unstored_text", "text").field("text", "text").endObject())
                 .get();
         refresh();
-        String highlighter = randomFrom(new String[] { "plain", "postings", "fvh" });
-        SearchResponse search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("text", "text")))
-                .highlighter(new HighlightBuilder().field(new Field("*").highlighterType(highlighter))).get();
+        String highlighter = randomFrom(new String[]{"plain", "postings", "fvh"});
+        SearchResponse search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("text", "text"))).addHighlightedField(new Field("*").highlighterType(highlighter)).get();
         assertHighlight(search, 0, "text", 0, equalTo("<em>text</em>"));
-        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("text", "text")))
-                .highlighter(new HighlightBuilder().field(new Field("unstored_text"))).get();
+        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("text", "text"))).addHighlightedField(new Field("unstored_text")).get();
         assertNoFailures(search);
         assertThat(search.getHits().getAt(0).getHighlightFields().size(), equalTo(0));
     }
@@ -221,8 +187,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
             .setSource("name", builder.toString())
             .get();
         refresh();
-        SearchResponse search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name", "abc")))
-                .highlighter(new HighlightBuilder().field("name")).get();
+        SearchResponse search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name", "abc"))).addHighlightedField("name").get();
         assertHighlight(search, 0, "name", 0, startsWith("<em>abc</em> <em>abc</em> <em>abc</em> <em>abc</em>"));
     }
 
@@ -278,9 +243,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         client().prepareIndex("test", "test", "1")
             .setSource("name", "ARCOTEL Hotels Deutschland").get();
         refresh();
-        SearchResponse search = client().prepareSearch("test").setTypes("test")
-                .setQuery(matchQuery("name.autocomplete", "deut tel").operator(Operator.OR))
-                .highlighter(new HighlightBuilder().field("name.autocomplete")).execute().actionGet();
+        SearchResponse search = client().prepareSearch("test").setTypes("test").setQuery(matchQuery("name.autocomplete", "deut tel").operator(Operator.OR)).addHighlightedField("name.autocomplete").execute().actionGet();
         assertHighlight(search, 0, "name.autocomplete", 0, equalTo("ARCO<em>TEL</em> Ho<em>tel</em>s <em>Deut</em>schland"));
     }
 
@@ -310,22 +273,10 @@ public class HighlighterSearchIT extends ESIntegTestCase {
             .setSource("body", "Test: http://www.facebook.com http://elasticsearch.org http://xing.com http://cnn.com http://quora.com http://twitter.com this is a test for highlighting feature Test: http://www.facebook.com http://elasticsearch.org http://xing.com http://cnn.com http://quora.com http://twitter.com this is a test for highlighting feature")
             .get();
         refresh();
-        SearchResponse search = client().prepareSearch().setQuery(matchQuery("body", "Test: http://www.facebook.com ").type(Type.PHRASE))
-                .highlighter(new HighlightBuilder().field("body")).execute().actionGet();
+        SearchResponse search = client().prepareSearch().setQuery(matchQuery("body", "Test: http://www.facebook.com ").type(Type.PHRASE)).addHighlightedField("body").execute().actionGet();
         assertHighlight(search, 0, "body", 0, startsWith("<em>Test: http://www.facebook.com</em>"));
-        search = client()
-                .prepareSearch()
-                .setQuery(
-                        matchQuery(
-                                "body",
-                                "Test: http://www.facebook.com http://elasticsearch.org http://xing.com http://cnn.com http://quora.com http://twitter.com this is a test for highlighting feature Test: http://www.facebook.com http://elasticsearch.org http://xing.com http://cnn.com http://quora.com http://twitter.com this is a test for highlighting feature")
-                                .type(Type.PHRASE)).highlighter(new HighlightBuilder().field("body")).execute().actionGet();
-        assertHighlight(
-                search,
-                0,
-                "body",
-                0,
-                equalTo("<em>Test</em>: <em>http://www.facebook.com</em> <em>http://elasticsearch.org</em> <em>http://xing.com</em> <em>http://cnn.com</em> http://quora.com"));
+        search = client().prepareSearch().setQuery(matchQuery("body", "Test: http://www.facebook.com http://elasticsearch.org http://xing.com http://cnn.com http://quora.com http://twitter.com this is a test for highlighting feature Test: http://www.facebook.com http://elasticsearch.org http://xing.com http://cnn.com http://quora.com http://twitter.com this is a test for highlighting feature").type(Type.PHRASE)).addHighlightedField("body").execute().actionGet();
+        assertHighlight(search, 0, "body", 0, equalTo("<em>Test</em>: <em>http://www.facebook.com</em> <em>http://elasticsearch.org</em> <em>http://xing.com</em> <em>http://cnn.com</em> http://quora.com"));
     }
 
     @Test
@@ -359,43 +310,37 @@ public class HighlighterSearchIT extends ESIntegTestCase {
                     "name2", "avinci, unilog avinci, logicacmg, logica").get();
         refresh();
 
-        SearchResponse search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name", "logica m")))
-                .highlighter(new HighlightBuilder().field("name")).get();
+        SearchResponse search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name", "logica m"))).addHighlightedField("name").get();
         assertHighlight(search, 0, "name", 0, anyOf(equalTo("<em>logica</em>c<em>m</em>g ehe<em>m</em>als avinci - the know how co<em>m</em>pany"),
                 equalTo("avinci, unilog avinci, <em>logica</em>c<em>m</em>g, <em>logica</em>")));
         assertHighlight(search, 1, "name", 0, anyOf(equalTo("<em>logica</em>c<em>m</em>g ehe<em>m</em>als avinci - the know how co<em>m</em>pany"),
                 equalTo("avinci, unilog avinci, <em>logica</em>c<em>m</em>g, <em>logica</em>")));
 
-        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name", "logica ma")))
-                .highlighter(new HighlightBuilder().field("name")).get();
+        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name", "logica ma"))).addHighlightedField("name").get();
         assertHighlight(search, 0, "name", 0, anyOf(equalTo("<em>logica</em>cmg ehe<em>ma</em>ls avinci - the know how company"),
                 equalTo("avinci, unilog avinci, <em>logica</em>cmg, <em>logica</em>")));
         assertHighlight(search, 1, "name", 0, anyOf(equalTo("<em>logica</em>cmg ehe<em>ma</em>ls avinci - the know how company"),
                 equalTo("avinci, unilog avinci, <em>logica</em>cmg, <em>logica</em>")));
 
-        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name", "logica")))
-                .highlighter(new HighlightBuilder().field("name")).get();
+        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name", "logica"))).addHighlightedField("name").get();
         assertHighlight(search, 0, "name", 0, anyOf(equalTo("<em>logica</em>cmg ehemals avinci - the know how company"),
                 equalTo("avinci, unilog avinci, <em>logica</em>cmg, <em>logica</em>")));
         assertHighlight(search, 0, "name", 0, anyOf(equalTo("<em>logica</em>cmg ehemals avinci - the know how company"),
                 equalTo("avinci, unilog avinci, <em>logica</em>cmg, <em>logica</em>")));
 
-        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name2", "logica m")))
-                .highlighter(new HighlightBuilder().field("name2")).get();
+        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name2", "logica m"))).addHighlightedField("name2").get();
         assertHighlight(search, 0, "name2", 0, anyOf(equalTo("<em>logica</em>c<em>m</em>g ehe<em>m</em>als avinci - the know how co<em>m</em>pany"),
                 equalTo("avinci, unilog avinci, <em>logica</em>c<em>m</em>g, <em>logica</em>")));
         assertHighlight(search, 1, "name2", 0, anyOf(equalTo("<em>logica</em>c<em>m</em>g ehe<em>m</em>als avinci - the know how co<em>m</em>pany"),
                 equalTo("avinci, unilog avinci, <em>logica</em>c<em>m</em>g, <em>logica</em>")));
 
-        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name2", "logica ma")))
-                .highlighter(new HighlightBuilder().field("name2")).get();
+        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name2", "logica ma"))).addHighlightedField("name2").get();
         assertHighlight(search, 0, "name2", 0, anyOf(equalTo("<em>logica</em>cmg ehe<em>ma</em>ls avinci - the know how company"),
                 equalTo("avinci, unilog avinci, <em>logica</em>cmg, <em>logica</em>")));
         assertHighlight(search, 1, "name2", 0, anyOf(equalTo("<em>logica</em>cmg ehe<em>ma</em>ls avinci - the know how company"),
                 equalTo("avinci, unilog avinci, <em>logica</em>cmg, <em>logica</em>")));
 
-        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name2", "logica")))
-                .highlighter(new HighlightBuilder().field("name2")).get();
+        search = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("name2", "logica"))).addHighlightedField("name2").get();
         assertHighlight(search, 0, "name2", 0, anyOf(equalTo("<em>logica</em>cmg ehemals avinci - the know how company"),
                 equalTo("avinci, unilog avinci, <em>logica</em>cmg, <em>logica</em>")));
         assertHighlight(search, 1, "name2", 0, anyOf(equalTo("<em>logica</em>cmg ehemals avinci - the know how company"),
@@ -426,25 +371,22 @@ public class HighlighterSearchIT extends ESIntegTestCase {
                        "name2", "logicacmg ehemals avinci - the know how company").get();
         refresh();
         ensureGreen();
-        SearchResponse search = client().prepareSearch().setQuery(matchQuery("name", "logica m"))
-                .highlighter(new HighlightBuilder().field("name")).get();
+        SearchResponse search = client().prepareSearch().setQuery(matchQuery("name", "logica m")).addHighlightedField("name").get();
         assertHighlight(search, 0, "name", 0, equalTo("<em>logica</em>c<em>m</em>g ehe<em>m</em>als avinci - the know how co<em>m</em>pany"));
 
-        search = client().prepareSearch().setQuery(matchQuery("name", "logica ma")).highlighter(new HighlightBuilder().field("name")).get();
+        search = client().prepareSearch().setQuery(matchQuery("name", "logica ma")).addHighlightedField("name").get();
         assertHighlight(search, 0, "name", 0, equalTo("<em>logica</em>cmg ehe<em>ma</em>ls avinci - the know how company"));
 
-        search = client().prepareSearch().setQuery(matchQuery("name", "logica")).highlighter(new HighlightBuilder().field("name")).get();
+        search = client().prepareSearch().setQuery(matchQuery("name", "logica")).addHighlightedField("name").get();
         assertHighlight(search, 0, "name", 0, equalTo("<em>logica</em>cmg ehemals avinci - the know how company"));
 
-        search = client().prepareSearch().setQuery(matchQuery("name2", "logica m")).highlighter(new HighlightBuilder().field("name2"))
-                .get();
+        search = client().prepareSearch().setQuery(matchQuery("name2", "logica m")).addHighlightedField("name2").get();
         assertHighlight(search, 0, "name2", 0, equalTo("<em>logicacmg</em> <em>ehemals</em> avinci - the know how <em>company</em>"));
 
-        search = client().prepareSearch().setQuery(matchQuery("name2", "logica ma")).highlighter(new HighlightBuilder().field("name2"))
-                .get();
+        search = client().prepareSearch().setQuery(matchQuery("name2", "logica ma")).addHighlightedField("name2").get();
         assertHighlight(search, 0, "name2", 0, equalTo("<em>logicacmg</em> <em>ehemals</em> avinci - the know how company"));
 
-        search = client().prepareSearch().setQuery(matchQuery("name2", "logica")).highlighter(new HighlightBuilder().field("name2")).get();
+        search = client().prepareSearch().setQuery(matchQuery("name2", "logica")).addHighlightedField("name2").get();
         assertHighlight(search, 0, "name2", 0, equalTo("<em>logicacmg</em> ehemals avinci - the know how company"));
     }
 
@@ -464,19 +406,19 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("long_term", "thisisaverylongwordandmakessurethisfails foo highlighed"))
-                .highlighter(new HighlightBuilder().field("long_term", 18, 1))
+                .addHighlightedField("long_term", 18, 1)
                 .get();
         assertHighlight(search, 0, "long_term", 0, 1, equalTo("<em>thisisaverylongwordandmakessurethisfails</em>"));
 
         search = client().prepareSearch()
                 .setQuery(matchQuery("no_long_term", "test foo highlighed").type(Type.PHRASE).slop(3))
-                .highlighter(new HighlightBuilder().field("no_long_term", 18, 1).postTags("</b>").preTags("<b>"))
+                .addHighlightedField("no_long_term", 18, 1).setHighlighterPostTags("</b>").setHighlighterPreTags("<b>")
                 .get();
         assertNotHighlighted(search, 0, "no_long_term");
 
         search = client().prepareSearch()
                 .setQuery(matchQuery("no_long_term", "test foo highlighed").type(Type.PHRASE).slop(3))
-                .highlighter(new HighlightBuilder().field("no_long_term", 30, 1).postTags("</b>").preTags("<b>"))
+                .addHighlightedField("no_long_term", 30, 1).setHighlighterPostTags("</b>").setHighlighterPreTags("<b>")
                 .get();
 
         assertHighlight(search, 0, "no_long_term", 0, 1, equalTo("a <b>test</b> where <b>foo</b> is <b>highlighed</b> and"));
@@ -504,7 +446,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "bug"))
-                .highlighter(new HighlightBuilder().field("title", -1, 0))
+                .addHighlightedField("title", -1, 0)
                 .get();
 
         for (int i = 0; i < indexRequestBuilders.length; i++) {
@@ -513,7 +455,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         search = client().prepareSearch()
                 .setQuery(matchQuery("attachments.body", "attachment"))
-                .highlighter(new HighlightBuilder().field("attachments.body", -1, 0))
+                .addHighlightedField("attachments.body", -1, 0)
                 .get();
 
         for (int i = 0; i < indexRequestBuilders.length; i++) {
@@ -544,7 +486,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "bug"))
-                .highlighter(new HighlightBuilder().field("title", -1, 0))
+                .addHighlightedField("title", -1, 0)
                 .get();
 
         for (int i = 0; i < indexRequestBuilders.length; i++) {
@@ -553,7 +495,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         search = client().prepareSearch()
                 .setQuery(matchQuery("attachments.body", "attachment"))
-                .highlighter(new HighlightBuilder().field("attachments.body", -1, 2))
+                .addHighlightedField("attachments.body", -1, 2)
                 .execute().get();
 
         for (int i = 0; i < 5; i++) {
@@ -586,7 +528,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "bug"))
                 //asking for the whole field to be highlighted
-                .highlighter(new HighlightBuilder().field("title", -1, 0)).get();
+                .addHighlightedField("title", -1, 0).get();
 
         for (int i = 0; i < indexRequestBuilders.length; i++) {
             assertHighlight(search, i, "title", 0, equalTo("This is a test on the highlighting <em>bug</em> present in elasticsearch. Hopefully it works."));
@@ -596,7 +538,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         search = client().prepareSearch()
                 .setQuery(matchQuery("title", "bug"))
                 //sentences will be generated out of each value
-                .highlighter(new HighlightBuilder().field("title")).get();
+                .addHighlightedField("title").get();
 
         for (int i = 0; i < indexRequestBuilders.length; i++) {
             assertHighlight(search, i, "title", 0, equalTo("This is a test on the highlighting <em>bug</em> present in elasticsearch."));
@@ -605,7 +547,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         search = client().prepareSearch()
                 .setQuery(matchQuery("attachments.body", "attachment"))
-                .highlighter(new HighlightBuilder().field("attachments.body", -1, 2))
+                .addHighlightedField("attachments.body", -1, 2)
                 .get();
 
         for (int i = 0; i < indexRequestBuilders.length; i++) {
@@ -629,7 +571,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "bug"))
-                .highlighter(new HighlightBuilder().field("title", -1, 2).field("titleTV", -1, 2).requireFieldMatch(false))
+                .addHighlightedField("title", -1, 2)
+                .addHighlightedField("titleTV", -1, 2).setHighlighterRequireFieldMatch(false)
                 .get();
 
         assertHighlight(search, 0, "title", 0, equalTo("This is a test on the highlighting <em>bug</em> present in elasticsearch"));
@@ -639,7 +582,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         search = client().prepareSearch()
                 .setQuery(matchQuery("titleTV", "highlight"))
-                .highlighter(new HighlightBuilder().field("titleTV", -1, 2))
+                .addHighlightedField("titleTV", -1, 2)
                 .get();
 
         assertHighlight(search, 0, "titleTV", 0, equalTo("some text to <em>highlight</em>"));
@@ -659,7 +602,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1 and field2 produces different tags");
         SearchSourceBuilder source = searchSource()
                 .query(termQuery("field1", "test"))
-                .highlighter(highlight().order("score").preTags("<global>").postTags("</global>").fragmentSize(1).numOfFragments(1)
+                .highlight(highlight().order("score").preTags("<global>").postTags("</global>").fragmentSize(1).numOfFragments(1)
                         .field(new HighlightBuilder.Field("field1").numOfFragments(2))
                         .field(new HighlightBuilder.Field("field2").preTags("<field2>").postTags("</field2>").fragmentSize(50).requireFieldMatch(false)));
 
@@ -689,7 +632,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         SearchSourceBuilder source = searchSource()
                 //postings hl doesn't support require_field_match, its field needs to be queried directly
                 .query(termQuery("field-postings", "test"))
-                .highlighter(highlight().field("field*").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
+                .highlight(highlight().field("field*").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
 
         SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -718,42 +661,36 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         //works using stored field
         SearchResponse searchResponse = client().prepareSearch("test")
                 .setQuery(termQuery("field1", "quick"))
-                .highlighter(new HighlightBuilder().field(new Field("field1").preTags("<xxx>").postTags("</xxx>")))
+                .addHighlightedField(new Field("field1").preTags("<xxx>").postTags("</xxx>"))
                 .get();
         assertHighlight(searchResponse, 0, "field1", 0, 1, equalTo("The <xxx>quick</xxx> brown fox jumps over the lazy dog"));
 
         assertFailures(client().prepareSearch("test")
                         .setQuery(termQuery("field1", "quick"))
-                        .highlighter(
-                                new HighlightBuilder().field(new Field("field1").preTags("<xxx>").postTags("</xxx>")
-                                        .highlighterType("plain").forceSource(true))),
+                        .addHighlightedField(new Field("field1").preTags("<xxx>").postTags("</xxx>").highlighterType("plain").forceSource(true)),
                 RestStatus.BAD_REQUEST,
                 containsString("source is forced for fields [field1] but type [type1] has disabled _source"));
 
         assertFailures(client().prepareSearch("test")
                         .setQuery(termQuery("field1", "quick"))
-                        .highlighter(
-                                new HighlightBuilder().field(new Field("field1").preTags("<xxx>").postTags("</xxx>").highlighterType("fvh")
-                                        .forceSource(true))),
+                        .addHighlightedField(new Field("field1").preTags("<xxx>").postTags("</xxx>").highlighterType("fvh").forceSource(true)),
                 RestStatus.BAD_REQUEST,
                 containsString("source is forced for fields [field1] but type [type1] has disabled _source"));
 
         assertFailures(client().prepareSearch("test")
                 .setQuery(termQuery("field1", "quick"))
-                        .highlighter(
-                                new HighlightBuilder().field(new Field("field1").preTags("<xxx>").postTags("</xxx>")
-                                        .highlighterType("postings").forceSource(true))),
+                .addHighlightedField(new Field("field1").preTags("<xxx>").postTags("</xxx>").highlighterType("postings").forceSource(true)),
                 RestStatus.BAD_REQUEST,
                 containsString("source is forced for fields [field1] but type [type1] has disabled _source"));
 
         SearchSourceBuilder searchSource = SearchSourceBuilder.searchSource().query(termQuery("field1", "quick"))
-                .highlighter(highlight().forceSource(true).field("field1"));
+                .highlight(highlight().forceSource(true).field("field1"));
         assertFailures(client().prepareSearch("test").setSource(searchSource),
                 RestStatus.BAD_REQUEST,
                 containsString("source is forced for fields [field1] but type [type1] has disabled _source"));
 
         searchSource = SearchSourceBuilder.searchSource().query(termQuery("field1", "quick"))
-                .highlighter(highlight().forceSource(true).field("field*"));
+                .highlight(highlight().forceSource(true).field("field*"));
         assertFailures(client().prepareSearch("test").setSource(searchSource),
                 RestStatus.BAD_REQUEST,
                 matches("source is forced for fields \\[field\\d, field\\d\\] but type \\[type1\\] has disabled _source"));
@@ -771,7 +708,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
                 .query(termQuery("field1", "test"))
-                .highlighter(highlight().field("field1").order("score").preTags("<xxx>").postTags("</xxx>"));
+                .highlight(highlight().field("field1").order("score").preTags("<xxx>").postTags("</xxx>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -780,7 +717,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on _all, highlighting on field1");
         source = searchSource()
                 .query(termQuery("_all", "test"))
-                .highlighter(highlight().field("field1").order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
+                .highlight(highlight().field("field1").order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
 
         searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -789,7 +726,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on _all, highlighting on field2");
         source = searchSource()
                 .query(termQuery("_all", "quick"))
-                .highlighter(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
+                .highlight(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
 
         searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -798,7 +735,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on _all, highlighting on field2");
         source = searchSource()
                 .query(prefixQuery("_all", "qui"))
-                .highlighter(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
+                .highlight(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
 
         searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -807,7 +744,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on _all with constant score, highlighting on field2");
         source = searchSource()
                 .query(constantScoreQuery(prefixQuery("_all", "qui")))
-                .highlighter(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
+                .highlight(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
 
         searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -816,7 +753,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on _all with constant score, highlighting on field2");
         source = searchSource()
                 .query(boolQuery().should(constantScoreQuery(prefixQuery("_all", "qui"))))
-                .highlighter(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
+                .highlight(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
 
         searchResponse = client().prepareSearch("test").setSource(source).get();
         assertHighlight(searchResponse, 0, "field2", 0, 1, equalTo("The <xxx>quick</xxx> brown fox jumps over the lazy dog"));
@@ -834,7 +771,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
                 .query(termQuery("field1", "test"))
-                .highlighter(highlight().field("field1", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>"));
+                .highlight(highlight().field("field1", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -843,7 +780,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on _all, highlighting on field1");
         source = searchSource()
                 .query(termQuery("_all", "test"))
-                .highlighter(highlight().field("field1", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
+                .highlight(highlight().field("field1", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
 
         searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -853,7 +790,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on _all, highlighting on field2");
         source = searchSource()
                 .query(termQuery("_all", "quick"))
-                .highlighter(highlight().field("field2", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
+                .highlight(highlight().field("field2", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
 
         searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -863,7 +800,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on _all, highlighting on field2");
         source = searchSource()
                 .query(prefixQuery("_all", "qui"))
-                .highlighter(highlight().field("field2", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
+                .highlight(highlight().field("field2", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>").requireFieldMatch(false));
 
         searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -889,7 +826,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
                 .query(termQuery("field1", "t"))
-                .highlighter(highlight().highlighterType("fvh").field("field1", 20, 1).order("score").preTags("<xxx>").postTags("</xxx>"));
+                .highlight(highlight().highlighterType("fvh").field("field1", 20, 1).order("score").preTags("<xxx>").postTags("</xxx>"));
         SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
         assertHighlight(searchResponse, 0, "field1", 0, 1, containsString("<xxx>t</xxx>"));
         logger.info("--> done");
@@ -957,7 +894,9 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         Field fooField = new Field("foo").numOfFragments(1).order("score").fragmentSize(25)
                 .highlighterType("fvh").requireFieldMatch(requireFieldMatch);
-        SearchRequestBuilder req = client().prepareSearch("test").highlighter(new HighlightBuilder().field(fooField));
+        Field barField = new Field("bar").numOfFragments(1).order("score").fragmentSize(25)
+                .highlighterType("fvh").requireFieldMatch(requireFieldMatch);
+        SearchRequestBuilder req = client().prepareSearch("test").addHighlightedField(fooField);
 
         // First check highlighting without any matched fields set
         SearchResponse resp = req.setQuery(queryStringQuery("running scissors").field("foo")).get();
@@ -969,31 +908,21 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         // Add the subfield to the list of matched fields but don't match it.  Everything should still work
         // like before we added it.
-        fooField = new Field("foo").numOfFragments(1).order("score").fragmentSize(25).highlighterType("fvh")
-                .requireFieldMatch(requireFieldMatch);
         fooField.matchedFields("foo", "foo.plain");
-        req = client().prepareSearch("test").highlighter(new HighlightBuilder().field(fooField));
         resp = req.setQuery(queryStringQuery("running scissors").field("foo")).get();
         assertHighlight(resp, 0, "foo", 0, equalTo("<em>running</em> with <em>scissors</em>"));
 
-
         // Now make half the matches come from the stored field and half from just a matched field.
         resp = req.setQuery(queryStringQuery("foo.plain:running scissors").field("foo")).get();
         assertHighlight(resp, 0, "foo", 0, equalTo("<em>running</em> with <em>scissors</em>"));
 
         // Now remove the stored field from the matched field list.  That should work too.
-        fooField = new Field("foo").numOfFragments(1).order("score").fragmentSize(25).highlighterType("fvh")
-                .requireFieldMatch(requireFieldMatch);
         fooField.matchedFields("foo.plain");
-        req = client().prepareSearch("test").highlighter(new HighlightBuilder().field(fooField));
         resp = req.setQuery(queryStringQuery("foo.plain:running scissors").field("foo")).get();
         assertHighlight(resp, 0, "foo", 0, equalTo("<em>running</em> with scissors"));
 
         // Now make sure boosted fields don't blow up when matched fields is both the subfield and stored field.
-        fooField = new Field("foo").numOfFragments(1).order("score").fragmentSize(25).highlighterType("fvh")
-                .requireFieldMatch(requireFieldMatch);
         fooField.matchedFields("foo", "foo.plain");
-        req = client().prepareSearch("test").highlighter(new HighlightBuilder().field(fooField));
         resp = req.setQuery(queryStringQuery("foo.plain:running^5 scissors").field("foo")).get();
         assertHighlight(resp, 0, "foo", 0, equalTo("<em>running</em> with <em>scissors</em>"));
 
@@ -1020,46 +949,41 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // Speaking of two fields, you can have two fields, only one of which has matchedFields enabled
         QueryBuilder twoFieldsQuery = queryStringQuery("cats").field("foo").field("foo.plain", 5)
                 .field("bar").field("bar.plain", 5);
-        Field barField = new Field("bar").numOfFragments(1).order("score").fragmentSize(25).highlighterType("fvh")
-                .requireFieldMatch(requireFieldMatch);
-        resp = req.setQuery(twoFieldsQuery).highlighter(new HighlightBuilder().field(fooField).field(barField)).get();
+        resp = req.setQuery(twoFieldsQuery).addHighlightedField(barField).get();
         assertHighlight(resp, 0, "foo", 0, equalTo("junk junk <em>cats</em> junk junk"));
         assertHighlight(resp, 0, "bar", 0, equalTo("<em>cat</em> <em>cat</em> junk junk junk junk"));
+
         // And you can enable matchedField highlighting on both
         barField.matchedFields("bar", "bar.plain");
-        resp = req.setQuery(twoFieldsQuery).highlighter(new HighlightBuilder().field(fooField).field(barField)).get();
+        resp = req.get();
         assertHighlight(resp, 0, "foo", 0, equalTo("junk junk <em>cats</em> junk junk"));
         assertHighlight(resp, 0, "bar", 0, equalTo("junk junk <em>cats</em> junk junk"));
 
         // Setting a matchedField that isn't searched/doesn't exist is simply ignored.
         barField.matchedFields("bar", "candy");
-        resp = req.setQuery(twoFieldsQuery).highlighter(new HighlightBuilder().field(fooField).field(barField)).get();
+        resp = req.get();
         assertHighlight(resp, 0, "foo", 0, equalTo("junk junk <em>cats</em> junk junk"));
         assertHighlight(resp, 0, "bar", 0, equalTo("<em>cat</em> <em>cat</em> junk junk junk junk"));
 
         // If the stored field doesn't have a value it doesn't matter what you match, you get nothing.
         barField.matchedFields("bar", "foo.plain");
-        resp = req.setQuery(queryStringQuery("running scissors").field("foo.plain").field("bar"))
-                .highlighter(new HighlightBuilder().field(fooField).field(barField)).get();
+        resp = req.setQuery(queryStringQuery("running scissors").field("foo.plain").field("bar")).get();
         assertHighlight(resp, 0, "foo", 0, equalTo("<em>running</em> with <em>scissors</em>"));
         assertThat(resp.getHits().getAt(0).getHighlightFields(), not(hasKey("bar")));
 
         // If the stored field is found but the matched field isn't then you don't get a result either.
         fooField.matchedFields("bar.plain");
-        resp = req.setQuery(queryStringQuery("running scissors").field("foo").field("foo.plain").field("bar").field("bar.plain"))
-                .highlighter(new HighlightBuilder().field(fooField).field(barField)).get();
+        resp = req.setQuery(queryStringQuery("running scissors").field("foo").field("foo.plain").field("bar").field("bar.plain")).get();
         assertThat(resp.getHits().getAt(0).getHighlightFields(), not(hasKey("foo")));
 
         // But if you add the stored field to the list of matched fields then you'll get a result again
         fooField.matchedFields("foo", "bar.plain");
-        resp = req.setQuery(queryStringQuery("running scissors").field("foo").field("foo.plain").field("bar").field("bar.plain"))
-                .highlighter(new HighlightBuilder().field(fooField).field(barField)).get();
+        resp = req.setQuery(queryStringQuery("running scissors").field("foo").field("foo.plain").field("bar").field("bar.plain")).get();
         assertHighlight(resp, 0, "foo", 0, equalTo("<em>running</em> with <em>scissors</em>"));
         assertThat(resp.getHits().getAt(0).getHighlightFields(), not(hasKey("bar")));
 
         // You _can_ highlight fields that aren't subfields of one another.
-        resp = req.setQuery(queryStringQuery("weird").field("foo").field("foo.plain").field("bar").field("bar.plain"))
-                .highlighter(new HighlightBuilder().field(fooField).field(barField)).get();
+        resp = req.setQuery(queryStringQuery("weird").field("foo").field("foo.plain").field("bar").field("bar.plain")).get();
         assertHighlight(resp, 0, "foo", 0, equalTo("<em>weird</em>"));
         assertHighlight(resp, 0, "bar", 0, equalTo("<em>resul</em>t"));
 
@@ -1084,7 +1008,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         SearchResponse searchResponse = client().prepareSearch()
                 .setSize(COUNT)
                 .setQuery(termQuery("field1", "test"))
-                .highlighter(new HighlightBuilder().field("field1", 100, 0))
+                .addHighlightedField("field1", 100, 0)
                 .get();
         for (int i = 0; i < COUNT; i++) {
             SearchHit hit = searchResponse.getHits().getHits()[i];
@@ -1096,7 +1020,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         searchResponse = client().prepareSearch()
                 .setSize(COUNT)
                 .setQuery(termQuery("_all", "test"))
-                .highlighter(new HighlightBuilder().field("_all", 100, 0))
+                .addHighlightedField("_all", 100, 0)
                 .get();
         for (int i = 0; i < COUNT; i++) {
             SearchHit hit = searchResponse.getHits().getHits()[i];
@@ -1129,7 +1053,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "bug"))
-                .highlighter(new HighlightBuilder().field("title", -1, 0))
+                .addHighlightedField("title", -1, 0)
                 .get();
 
         for (int i = 0; i < 5; i++) {
@@ -1152,7 +1076,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "bug"))
-                .highlighter(new HighlightBuilder().field("title", 30, 1, 10))
+                .addHighlightedField("title", 30, 1, 10)
                 .get();
 
         for (int i = 0; i < 5; i++) {
@@ -1176,7 +1100,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "test"))
-                .highlighter(new HighlightBuilder().encoder("html").field("title", 50, 1, 10))
+                .setHighlighterEncoder("html")
+                .addHighlightedField("title", 50, 1, 10)
                 .get();
 
         for (int i = 0; i < indexRequestBuilders.length; i++) {
@@ -1199,7 +1124,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "test"))
-                .highlighter(new HighlightBuilder().encoder("html").field("title", 30, 1, 10))
+                .setHighlighterEncoder("html")
+                .addHighlightedField("title", 30, 1, 10)
                 .get();
 
         for (int i = 0; i < 5; i++) {
@@ -1222,7 +1148,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // simple search on body with standard analyzer with a simple field query
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "this is a test"))
-                .highlighter(new HighlightBuilder().encoder("html").field("title", 50, 1))
+                .setHighlighterEncoder("html")
+                .addHighlightedField("title", 50, 1)
                 .get();
 
         assertHighlight(search, 0, "title", 0, 1, equalTo("this is a <em>test</em>"));
@@ -1230,7 +1157,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // search on title.key and highlight on title
         search = client().prepareSearch()
                 .setQuery(matchQuery("title.key", "this is a test"))
-                .highlighter(new HighlightBuilder().encoder("html").field("title.key", 50, 1))
+                .setHighlighterEncoder("html")
+                .addHighlightedField("title.key", 50, 1)
                 .get();
 
         assertHighlight(search, 0, "title.key", 0, 1, equalTo("<em>this</em> <em>is</em> <em>a</em> <em>test</em>"));
@@ -1253,7 +1181,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // simple search on body with standard analyzer with a simple field query
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "this is a test"))
-                .highlighter(new HighlightBuilder().encoder("html").field("title", 50, 1))
+                .setHighlighterEncoder("html")
+                .addHighlightedField("title", 50, 1)
                 .get();
 
         assertHighlight(search, 0, "title", 0, 1, equalTo("this is a <em>test</em>"));
@@ -1261,7 +1190,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // search on title.key and highlight on title.key
         search = client().prepareSearch()
                 .setQuery(matchQuery("title.key", "this is a test"))
-                .highlighter(new HighlightBuilder().encoder("html").field("title.key", 50, 1))
+                .setHighlighterEncoder("html")
+                .addHighlightedField("title.key", 50, 1)
                 .get();
 
         assertHighlight(search, 0, "title.key", 0, 1, equalTo("<em>this</em> <em>is</em> <em>a</em> <em>test</em>"));
@@ -1284,7 +1214,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // simple search on body with standard analyzer with a simple field query
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "this is a test"))
-                .highlighter(new HighlightBuilder().encoder("html").field("title", 50, 1))
+                .setHighlighterEncoder("html")
+                .addHighlightedField("title", 50, 1)
                 .get();
 
         assertHighlight(search, 0, "title", 0, 1, equalTo("this is a <em>test</em>"));
@@ -1292,7 +1223,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // search on title.key and highlight on title
         search = client().prepareSearch()
                 .setQuery(matchQuery("title.key", "this is a test"))
-                .highlighter(new HighlightBuilder().encoder("html").field("title.key", 50, 1))
+                .setHighlighterEncoder("html")
+                .addHighlightedField("title.key", 50, 1)
                 .get();
 
         assertHighlight(search, 0, "title.key", 0, 1, equalTo("<em>this</em> <em>is</em> <em>a</em> <em>test</em>"));
@@ -1314,7 +1246,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // simple search on body with standard analyzer with a simple field query
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "this is a test"))
-                .highlighter(new HighlightBuilder().encoder("html").field("title", 50, 1))
+                .setHighlighterEncoder("html")
+                .addHighlightedField("title", 50, 1)
                 .get();
 
         assertHighlight(search, 0, "title", 0, 1, equalTo("this is a <em>test</em>"));
@@ -1322,7 +1255,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // search on title.key and highlight on title.key
         search = client().prepareSearch()
                 .setQuery(matchQuery("title.key", "this is a test"))
-                .highlighter(new HighlightBuilder().encoder("html").field("title.key", 50, 1))
+                .setHighlighterEncoder("html")
+                .addHighlightedField("title.key", 50, 1)
                 .get();
 
         assertHighlight(search, 0, "title.key", 0, 1, equalTo("<em>this</em> <em>is</em> <em>a</em> <em>test</em>"));
@@ -1343,20 +1277,22 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchPhraseQuery("title", "this is a test"))
-                .highlighter(new HighlightBuilder().field("title", 50, 1, 10))
+                .addHighlightedField("title", 50, 1, 10)
                 .get();
         assertNoFailures(search);
 
         assertFailures(client().prepareSearch()
                 .setQuery(matchPhraseQuery("title", "this is a test"))
-                        .highlighter(new HighlightBuilder().field("title", 50, 1, 10).highlighterType("fast-vector-highlighter")),
+                .addHighlightedField("title", 50, 1, 10)
+                .setHighlighterType("fast-vector-highlighter"),
                 RestStatus.BAD_REQUEST,
                 containsString("the field [title] should be indexed with term vector with position offsets to be used with fast vector highlighter"));
 
         //should not fail if there is a wildcard
         assertNoFailures(client().prepareSearch()
                 .setQuery(matchPhraseQuery("title", "this is a test"))
-                .highlighter(new HighlightBuilder().field("tit*", 50, 1, 10).highlighterType("fast-vector-highlighter")).get());
+                .addHighlightedField("tit*", 50, 1, 10)
+                .setHighlighterType("fast-vector-highlighter").get());
     }
 
     @Test
@@ -1374,7 +1310,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchPhraseQuery("title", "test for the workaround"))
-                .highlighter(new HighlightBuilder().field("title", 50, 1, 10))
+                .addHighlightedField("title", 50, 1, 10)
                 .get();
 
         for (int i = 0; i < indexRequestBuilders.length; i++) {
@@ -1385,7 +1321,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // Using plain highlighter instead of FVH
         search = client().prepareSearch()
                 .setQuery(matchPhraseQuery("title", "test for the workaround"))
-                .highlighter(new HighlightBuilder().field("title", 50, 1, 10).highlighterType("highlighter"))
+                .addHighlightedField("title", 50, 1, 10)
+                .setHighlighterType("highlighter")
                 .get();
 
         for (int i = 0; i < indexRequestBuilders.length; i++) {
@@ -1395,9 +1332,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // Using plain highlighter instead of FVH on the field level
         search = client().prepareSearch()
                 .setQuery(matchPhraseQuery("title", "test for the workaround"))
-                .highlighter(
-                        new HighlightBuilder().field(new HighlightBuilder.Field("title").highlighterType("highlighter")).highlighterType(
-                                "highlighter"))
+                .addHighlightedField(new HighlightBuilder.Field("title").highlighterType("highlighter"))
+                .setHighlighterType("highlighter")
                 .get();
 
         for (int i = 0; i < indexRequestBuilders.length; i++) {
@@ -1418,7 +1354,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("test")
                 .setQuery(QueryBuilders.matchQuery("tags", "tag"))
-                .highlighter(new HighlightBuilder().field("tags", -1, 0)).get();
+                .addHighlightedField("tags", -1, 0).get();
 
         assertHighlight(response, 0, "tags", 0, equalTo("this is a really long <em>tag</em> i would like to highlight"));
         assertHighlight(response, 0, "tags", 1, 2, equalTo("here is another one that is very long and has the <em>tag</em> token near the end"));
@@ -1435,7 +1371,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
                 .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
-                .highlighter(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
+                .highlight(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -1454,7 +1390,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
                 .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
-                .highlighter(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
+                .highlight(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -1474,7 +1410,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
                 .query(commonTermsQuery("field2", "quick brown").cutoffFrequency(100))
-                .highlighter(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
+                .highlight(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
         assertHighlight(searchResponse, 0, "field2", 0, 1, equalTo("The <x>quick</x> <x>brown</x> fox jumps over the lazy dog"));
@@ -1489,7 +1425,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         refresh();
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource().query(commonTermsQuery("field2", "quick brown").cutoffFrequency(100))
-                .highlighter(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
+                .highlight(highlight().field("field2").order("score").preTags("<x>").postTags("</x>"));
 
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
 
@@ -1519,7 +1455,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field0");
         SearchSourceBuilder source = searchSource()
                 .query(matchPhrasePrefixQuery("field0", "quick bro"))
-                .highlighter(highlight().field("field0").order("score").preTags("<x>").postTags("</x>"));
+                .highlight(highlight().field("field0").order("score").preTags("<x>").postTags("</x>"));
 
         SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -1528,7 +1464,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1");
         source = searchSource()
                 .query(matchPhrasePrefixQuery("field1", "quick bro"))
-                .highlighter(highlight().field("field1").order("score").preTags("<x>").postTags("</x>"));
+                .highlight(highlight().field("field1").order("score").preTags("<x>").postTags("</x>"));
 
         searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -1545,7 +1481,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         refresh();
 
         source = searchSource().postFilter(typeQuery("type2")).query(matchPhrasePrefixQuery("field3", "fast bro"))
-                .highlighter(highlight().field("field3").order("score").preTags("<x>").postTags("</x>"));
+                .highlight(highlight().field("field3").order("score").preTags("<x>").postTags("</x>"));
 
         searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -1553,7 +1489,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field4");
         source = searchSource().postFilter(typeQuery("type2")).query(matchPhrasePrefixQuery("field4", "the fast bro"))
-                .highlighter(highlight().field("field4").order("score").preTags("<x>").postTags("</x>"));
+                .highlight(highlight().field("field4").order("score").preTags("<x>").postTags("</x>"));
         searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
         assertHighlight(searchResponse, 0, "field4", 0, 1, anyOf(equalTo("<x>The quick browse</x> button is a fancy thing, right bro?"), equalTo("<x>The quick brown</x> fox jumps over the lazy dog")));
@@ -1561,7 +1497,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field4");
         source = searchSource().postFilter(typeQuery("type2")).query(matchPhrasePrefixQuery("field4", "a fast quick blue ca"))
-                .highlighter(highlight().field("field4").order("score").preTags("<x>").postTags("</x>"));
+                .highlight(highlight().field("field4").order("score").preTags("<x>").postTags("</x>"));
         searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
         assertHighlight(searchResponse, 0, "field4", 0, 1, equalTo("<x>a quick fast blue car</x>"));
@@ -1580,27 +1516,24 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("test")
                 .setQuery(QueryBuilders.matchQuery("tags", "long tag").type(MatchQuery.Type.PHRASE))
-                .highlighter(
-                        new HighlightBuilder().field(new HighlightBuilder.Field("tags").fragmentSize(-1).numOfFragments(2)
-                                .fragmenter("simple"))).get();
+                .addHighlightedField(new HighlightBuilder.Field("tags")
+                        .fragmentSize(-1).numOfFragments(2).fragmenter("simple")).get();
 
         assertHighlight(response, 0, "tags", 0, equalTo("this is a really <em>long</em> <em>tag</em> i would like to highlight"));
         assertHighlight(response, 0, "tags", 1, 2, equalTo("here is another one that is very <em>long</em> <em>tag</em> and has the <em>tag</em> token near the end"));
 
         response = client().prepareSearch("test")
                 .setQuery(QueryBuilders.matchQuery("tags", "long tag").type(MatchQuery.Type.PHRASE))
-                .highlighter(
-                        new HighlightBuilder().field(new HighlightBuilder.Field("tags").fragmentSize(-1).numOfFragments(2)
-                                .fragmenter("span"))).get();
+                .addHighlightedField(new HighlightBuilder.Field("tags")
+                        .fragmentSize(-1).numOfFragments(2).fragmenter("span")).get();
 
         assertHighlight(response, 0, "tags", 0, equalTo("this is a really <em>long</em> <em>tag</em> i would like to highlight"));
         assertHighlight(response, 0, "tags", 1, 2, equalTo("here is another one that is very <em>long</em> <em>tag</em> and has the <em>tag</em> token near the end"));
 
         assertFailures(client().prepareSearch("test")
                         .setQuery(QueryBuilders.matchQuery("tags", "long tag").type(MatchQuery.Type.PHRASE))
-                        .highlighter(
-                                new HighlightBuilder().field(new HighlightBuilder.Field("tags").fragmentSize(-1).numOfFragments(2)
-                                        .fragmenter("invalid"))),
+                        .addHighlightedField(new HighlightBuilder.Field("tags")
+                                .fragmentSize(-1).numOfFragments(2).fragmenter("invalid")),
                 RestStatus.BAD_REQUEST,
                 containsString("unknown fragmenter option [invalid] for the field [tags]"));
     }
@@ -1615,10 +1548,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("test")
                 .setQuery(QueryBuilders.matchQuery("field1", "fox"))
-                .highlighter(
-                        new HighlightBuilder().field(
-                                new HighlightBuilder.Field("field1").preTags("<1>").postTags("</1>").requireFieldMatch(true)).field(
-                                new HighlightBuilder.Field("field2").preTags("<2>").postTags("</2>").requireFieldMatch(false)))
+                .addHighlightedField(new HighlightBuilder.Field("field1").preTags("<1>").postTags("</1>").requireFieldMatch(true))
+                .addHighlightedField(new HighlightBuilder.Field("field2").preTags("<2>").postTags("</2>").requireFieldMatch(false))
                 .get();
         assertHighlight(response, 0, "field1", 0, 1, equalTo("The <b>quick<b> brown <1>fox</1>"));
         assertHighlight(response, 0, "field2", 0, 1, equalTo("The <b>slow<b> brown <2>fox</2>"));
@@ -1635,10 +1566,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("test")
                 .setQuery(QueryBuilders.matchQuery("field1", "fox"))
-                .highlighter(
-                        new HighlightBuilder().field(
-                                new HighlightBuilder.Field("field1").preTags("<1>").postTags("</1>").requireFieldMatch(true)).field(
-                                new HighlightBuilder.Field("field2").preTags("<2>").postTags("</2>").requireFieldMatch(false)))
+                .addHighlightedField(new HighlightBuilder.Field("field1").preTags("<1>").postTags("</1>").requireFieldMatch(true))
+                .addHighlightedField(new HighlightBuilder.Field("field2").preTags("<2>").postTags("</2>").requireFieldMatch(false))
                 .get();
         assertHighlight(response, 0, "field1", 0, 1, equalTo("The <b>quick<b> brown <1>fox</1>"));
         assertHighlight(response, 0, "field2", 0, 1, equalTo("The <b>slow<b> brown <2>fox</2>"));
@@ -1658,9 +1587,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // This query used to fail when the field to highlight was absent
         SearchResponse response = client().prepareSearch("test")
                 .setQuery(QueryBuilders.matchQuery("field", "highlight").type(MatchQuery.Type.BOOLEAN))
-                .highlighter(
-                        new HighlightBuilder().field(new HighlightBuilder.Field("highlight_field").fragmentSize(-1).numOfFragments(1)
-                                .fragmenter("simple"))).get();
+                .addHighlightedField(new HighlightBuilder.Field("highlight_field")
+                        .fragmentSize(-1).numOfFragments(1).fragmenter("simple")).get();
         assertThat(response.getHits().hits()[0].highlightFields().isEmpty(), equalTo(true));
     }
 
@@ -1679,9 +1607,13 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("test")
                 .setQuery(QueryBuilders.matchQuery("text", "test").type(MatchQuery.Type.BOOLEAN))
-                .highlighter(
-                        new HighlightBuilder().field("text").field("byte").field("short").field("int").field("long").field("float")
-                                .field("double"))
+                .addHighlightedField("text")
+                .addHighlightedField("byte")
+                .addHighlightedField("short")
+                .addHighlightedField("int")
+                .addHighlightedField("long")
+                .addHighlightedField("float")
+                .addHighlightedField("double")
                 .get();
         // Highlighting of numeric fields is not supported, but it should not raise errors
         // (this behavior is consistent with version 0.20)
@@ -1705,7 +1637,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("test")
                 .setQuery(QueryBuilders.matchQuery("text", "test").type(MatchQuery.Type.BOOLEAN))
-                .highlighter(new HighlightBuilder().field("text")).execute().actionGet();
+                .addHighlightedField("text").execute().actionGet();
         // PatternAnalyzer will throw an exception if it is resetted twice
         assertHitCount(response, 1l);
     }
@@ -1721,9 +1653,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         HighlightBuilder.Field field = new HighlightBuilder.Field("text");
 
-        HighlightBuilder highlightBuilder = new HighlightBuilder().field(field);
         SearchRequestBuilder search = client().prepareSearch("test").setQuery(QueryBuilders.matchQuery("text", "testing"))
-                .highlighter(highlightBuilder);
+                .addHighlightedField(field);
         Matcher<String> searchQueryMatcher = equalTo("<em>Testing</em> the highlight query feature");
 
         field.highlighterType("plain");
@@ -1736,12 +1667,9 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         response = search.get();
         assertHighlight(response, 0, "text", 0, searchQueryMatcher);
 
-        field = new HighlightBuilder.Field("text");
 
         Matcher<String> hlQueryMatcher = equalTo("Testing the highlight <em>query</em> feature");
         field.highlightQuery(matchQuery("text", "query"));
-        highlightBuilder = new HighlightBuilder().field(field);
-        search = client().prepareSearch("test").setQuery(QueryBuilders.matchQuery("text", "testing")).highlighter(highlightBuilder);
 
         field.highlighterType("fvh");
         response = search.get();
@@ -1756,7 +1684,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         assertHighlight(response, 0, "text", 0, hlQueryMatcher);
 
         // Make sure the the highlightQuery is taken into account when it is set on the highlight context instead of the field
-        highlightBuilder.highlightQuery(matchQuery("text", "query"));
+        search.setHighlighterQuery(matchQuery("text", "query"));
         field.highlighterType("fvh").highlightQuery(null);
         response = search.get();
         assertHighlight(response, 0, "text", 0, hlQueryMatcher);
@@ -1792,97 +1720,97 @@ public class HighlighterSearchIT extends ESIntegTestCase {
                 .fragmentSize(21)
                 .numOfFragments(1)
                 .highlighterType("plain");
-        SearchResponse response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        SearchResponse response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("fvh");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("postings");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         // When noMatchSize is set to 0 you also shouldn't get any
         field.highlighterType("plain").noMatchSize(0);
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("fvh");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("postings");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         // When noMatchSize is between 0 and the size of the string
         field.highlighterType("plain").noMatchSize(21);
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("I am pretty long so"));
 
         // The FVH also works but the fragment is longer than the plain highlighter because of boundary_max_scan
         field.highlighterType("fvh");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("I am pretty long so some"));
 
         // Postings hl also works but the fragment is the whole first sentence (size ignored)
         field.highlighterType("postings");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("I am pretty long so some of me should get cut off."));
 
         // We can also ask for a fragment longer than the input string and get the whole string
         field.highlighterType("plain").noMatchSize(text.length() * 2);
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo(text));
 
         field.highlighterType("fvh");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo(text));
 
         //no difference using postings hl as the noMatchSize is ignored (just needs to be greater than 0)
         field.highlighterType("postings");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("I am pretty long so some of me should get cut off."));
 
         // We can also ask for a fragment exactly the size of the input field and get the whole field
         field.highlighterType("plain").noMatchSize(text.length());
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo(text));
 
         field.highlighterType("fvh");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo(text));
 
         //no difference using postings hl as the noMatchSize is ignored (just needs to be greater than 0)
         field.highlighterType("postings");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("I am pretty long so some of me should get cut off."));
 
         // You can set noMatchSize globally in the highlighter as well
         field.highlighterType("plain").noMatchSize(null);
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field).noMatchSize(21)).get();
+        response = client().prepareSearch("test").setHighlighterNoMatchSize(21).addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("I am pretty long so"));
 
         field.highlighterType("fvh");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field).noMatchSize(21)).get();
+        response = client().prepareSearch("test").setHighlighterNoMatchSize(21).addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("I am pretty long so some"));
 
         field.highlighterType("postings");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field).noMatchSize(21)).get();
+        response = client().prepareSearch("test").setHighlighterNoMatchSize(21).addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("I am pretty long so some of me should get cut off."));
 
         // We don't break if noMatchSize is less than zero though
         field.highlighterType("plain").noMatchSize(randomIntBetween(Integer.MIN_VALUE, -1));
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("fvh");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("postings");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
     }
 
@@ -1903,16 +1831,16 @@ public class HighlighterSearchIT extends ESIntegTestCase {
                 .numOfFragments(1)
                 .highlighterType("plain")
                 .noMatchSize(21);
-        SearchResponse response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        SearchResponse response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("I am pretty long so"));
 
         field.highlighterType("fvh");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("I am pretty long so some"));
 
         // Postings hl also works but the fragment is the whole first sentence (size ignored)
         field.highlighterType("postings");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("I am pretty long so some of me should get cut off."));
 
         // And noMatchSize returns nothing when the first entry is empty string!
@@ -1923,19 +1851,19 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         field.highlighterType("plain");
         response = client().prepareSearch("test")
                 .setQuery(idsQueryBuilder)
-.highlighter(new HighlightBuilder().field(field)).get();
+                .addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("fvh");
         response = client().prepareSearch("test")
                 .setQuery(idsQueryBuilder)
-.highlighter(new HighlightBuilder().field(field)).get();
+                .addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("postings");
         response = client().prepareSearch("test")
                 .setQuery(idsQueryBuilder)
-.highlighter(new HighlightBuilder().field(field)).get();
+                .addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         // But if the field was actually empty then you should get no highlighting field
@@ -1945,19 +1873,19 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         field.highlighterType("plain");
         response = client().prepareSearch("test")
                 .setQuery(idsQueryBuilder)
-.highlighter(new HighlightBuilder().field(field)).get();
+                .addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("fvh");
         response = client().prepareSearch("test")
                 .setQuery(idsQueryBuilder)
-.highlighter(new HighlightBuilder().field(field)).get();
+                .addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("postings");
         response = client().prepareSearch("test")
                 .setQuery(idsQueryBuilder)
-.highlighter(new HighlightBuilder().field(field)).get();
+                .addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         // Same for if the field doesn't even exist on the document
@@ -1968,34 +1896,34 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         field.highlighterType("plain");
         response = client().prepareSearch("test")
                 .setQuery(idsQueryBuilder)
-.highlighter(new HighlightBuilder().field(field)).get();
+                .addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("fvh");
         response = client().prepareSearch("test")
                 .setQuery(idsQueryBuilder)
-.highlighter(new HighlightBuilder().field(field)).get();
+                .addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("fvh");
         response = client().prepareSearch("test")
                 .setQuery(idsQueryBuilder)
-.highlighter(new HighlightBuilder().field(field)).get();
+                .addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "postings");
 
         // Again same if the field isn't mapped
         field = new HighlightBuilder.Field("unmapped")
                 .highlighterType("plain")
                 .noMatchSize(21);
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("fvh");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
 
         field.highlighterType("postings");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertNotHighlighted(response, 0, "text");
     }
 
@@ -2017,32 +1945,32 @@ public class HighlighterSearchIT extends ESIntegTestCase {
                 .numOfFragments(0)
                 .highlighterType("plain")
                 .noMatchSize(20);
-        SearchResponse response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        SearchResponse response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("This is the first"));
 
         field.highlighterType("fvh");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("This is the first sentence"));
 
         // Postings hl also works but the fragment is the whole first sentence (size ignored)
         field.highlighterType("postings");
-        response = client().prepareSearch("test").highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 1, equalTo("This is the first sentence."));
 
         //if there's a match we only return the values with matches (whole value as number_of_fragments == 0)
         MatchQueryBuilder queryBuilder = QueryBuilders.matchQuery("text", "third fifth");
         field.highlighterType("plain");
-        response = client().prepareSearch("test").setQuery(queryBuilder).highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").setQuery(queryBuilder).addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 2, equalTo("This is the <em>third</em> sentence. This is the fourth sentence."));
         assertHighlight(response, 0, "text", 1, 2, equalTo("This is the <em>fifth</em> sentence"));
 
         field.highlighterType("fvh");
-        response = client().prepareSearch("test").setQuery(queryBuilder).highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").setQuery(queryBuilder).addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 2, equalTo("This is the <em>third</em> sentence. This is the fourth sentence."));
         assertHighlight(response, 0, "text", 1, 2, equalTo("This is the <em>fifth</em> sentence"));
 
         field.highlighterType("postings");
-        response = client().prepareSearch("test").setQuery(queryBuilder).highlighter(new HighlightBuilder().field(field)).get();
+        response = client().prepareSearch("test").setQuery(queryBuilder).addHighlightedField(field).get();
         assertHighlight(response, 0, "text", 0, 2, equalTo("This is the <em>third</em> sentence. This is the fourth sentence."));
         assertHighlight(response, 0, "text", 1, 2, equalTo("This is the <em>fifth</em> sentence"));
     }
@@ -2059,7 +1987,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
                 .query(termQuery("field1", "test"))
-                .highlighter(highlight().field("field1").preTags("<xxx>").postTags("</xxx>"));
+                .highlight(highlight().field("field1").preTags("<xxx>").postTags("</xxx>"));
         SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
         assertHighlight(searchResponse, 0, "field1", 0, 1, equalTo("this is a <xxx>test</xxx>"));
@@ -2067,7 +1995,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on field1, highlighting on field1");
         source = searchSource()
                 .query(termQuery("field1", "test"))
-                .highlighter(highlight().field("field1").preTags("<xxx>").postTags("</xxx>"));
+                .highlight(highlight().field("field1").preTags("<xxx>").postTags("</xxx>"));
 
         searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -2076,7 +2004,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on field2, highlighting on field2");
         source = searchSource()
                 .query(termQuery("field2", "quick"))
-                .highlighter(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>"));
+                .highlight(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>"));
 
         searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -2085,7 +2013,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on field2, highlighting on field2");
         source = searchSource()
                 .query(matchPhraseQuery("field2", "quick brown"))
-                .highlighter(highlight().field("field2").preTags("<xxx>").postTags("</xxx>"));
+                .highlight(highlight().field("field2").preTags("<xxx>").postTags("</xxx>"));
 
         searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -2096,7 +2024,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> searching on field2, highlighting on field2, falling back to the plain highlighter");
         source = searchSource()
                 .query(matchPhraseQuery("_all", "quick brown"))
-                .highlighter(highlight().field("field2").preTags("<xxx>").postTags("</xxx>").highlighterType("highlighter").requireFieldMatch(false));
+                .highlight(highlight().field("field2").preTags("<xxx>").postTags("</xxx>").highlighterType("highlighter").requireFieldMatch(false));
 
         searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -2113,9 +2041,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse response = client().prepareSearch("test")
                 .setQuery(QueryBuilders.matchQuery("field1", "fox"))
-                .highlighter(
-                        new HighlightBuilder().field(new HighlightBuilder.Field("field1").preTags("<1>").postTags("</1>")
-                                .requireFieldMatch(true)))
+                .addHighlightedField(new HighlightBuilder.Field("field1").preTags("<1>").postTags("</1>").requireFieldMatch(true))
                 .get();
         assertHighlight(response, 0, "field1", 0, 1, equalTo("The <b>quick<b> brown <1>fox</1>."));
     }
@@ -2133,7 +2059,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
                 .query(termQuery("field1", "fox"))
-                .highlighter(highlight()
+                .highlight(highlight()
                         .field(new HighlightBuilder.Field("field1").numOfFragments(5).preTags("<field1>").postTags("</field1>")));
 
         SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
@@ -2148,7 +2074,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         source = searchSource()
                 .query(termQuery("field1", "fox"))
-                .highlighter(highlight()
+                .highlight(highlight()
                         .field(new HighlightBuilder.Field("field1").numOfFragments(0).preTags("<field1>").postTags("</field1>")));
 
         searchResponse = client().search(searchRequest("test").source(source)).actionGet();
@@ -2198,7 +2124,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
             SearchSourceBuilder source = searchSource()
                     .query(multiMatchQueryBuilder)
-                    .highlighter(highlight().highlightQuery(randomBoolean() ? multiMatchQueryBuilder : null).highlighterType(highlighterType)
+                    .highlight(highlight().highlightQuery(randomBoolean() ? multiMatchQueryBuilder : null).highlighterType(highlighterType)
                             .field(new Field("field1").requireFieldMatch(true).preTags("<field1>").postTags("</field1>")));
             logger.info("Running multi-match type: [" + matchQueryType + "] highlight with type: [" + highlighterType + "]");
             SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
@@ -2222,7 +2148,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
                 .query(termQuery("field1", "sentence"))
-                .highlighter(highlight().field("field1").order("score"));
+                .highlight(highlight().field("field1").order("score"));
 
         SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
@@ -2252,7 +2178,8 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse searchResponse = client().prepareSearch()
                 .setQuery(matchQuery("title", "test"))
-                .highlighter(new HighlightBuilder().field("title").encoder("html")).get();
+                .setHighlighterEncoder("html")
+                .addHighlightedField("title").get();
 
         for (int i = 0; i < indexRequestBuilders.length; i++) {
             assertHighlight(searchResponse, i, "title", 0, 1, equalTo("This is a html escaping highlighting <em>test</em> for *&amp;?"));
@@ -2276,7 +2203,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         SearchResponse searchResponse = client().prepareSearch()
                 //lets make sure we analyze the query and we highlight the resulting terms
                 .setQuery(matchQuery("title", "This is a Test"))
-.highlighter(new HighlightBuilder().field("title")).get();
+                .addHighlightedField("title").get();
 
         assertHitCount(searchResponse, 1l);
         SearchHit hit = searchResponse.getHits().getAt(0);
@@ -2286,7 +2213,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // search on title.key and highlight on title
         searchResponse = client().prepareSearch()
                 .setQuery(matchQuery("title.key", "this is a test"))
-                .highlighter(new HighlightBuilder().field("title.key")).get();
+                .addHighlightedField("title.key").get();
         assertHitCount(searchResponse, 1l);
 
         //stopwords are now highlighted since we used only whitespace analyzer here
@@ -2310,7 +2237,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // simple search on body with standard analyzer with a simple field query
         SearchResponse searchResponse = client().prepareSearch()
                 .setQuery(matchQuery("title", "this is a test"))
-                .highlighter(new HighlightBuilder().field("title"))
+                .addHighlightedField("title")
                 .get();
 
         assertHighlight(searchResponse, 0, "title", 0, 1, equalTo("this is a <em>test</em>"));
@@ -2318,7 +2245,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         // search on title.key and highlight on title.key
         searchResponse = client().prepareSearch()
                 .setQuery(matchQuery("title.key", "this is a test"))
-                .highlighter(new HighlightBuilder().field("title.key")).get();
+                .addHighlightedField("title.key").get();
 
         assertHighlight(searchResponse, 0, "title.key", 0, 1, equalTo("<em>this</em> <em>is</em> <em>a</em> <em>test</em>"));
     }
@@ -2340,27 +2267,30 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch()
                 .setQuery(matchQuery("title", "this is a test"))
-                .highlighter(new HighlightBuilder().field("title"))
+                .addHighlightedField("title")
                 .get();
         assertNoFailures(search);
 
         assertFailures(client().prepareSearch()
                         .setQuery(matchQuery("title", "this is a test"))
-                        .highlighter(new HighlightBuilder().field("title").highlighterType("postings-highlighter")),
+                        .addHighlightedField("title")
+                        .setHighlighterType("postings-highlighter"),
                 RestStatus.BAD_REQUEST,
                 containsString("the field [title] should be indexed with positions and offsets in the postings list to be used with postings highlighter"));
 
 
         assertFailures(client().prepareSearch()
                         .setQuery(matchQuery("title", "this is a test"))
-                        .highlighter(new HighlightBuilder().field("title").highlighterType("postings")),
+                        .addHighlightedField("title")
+                        .setHighlighterType("postings"),
                 RestStatus.BAD_REQUEST,
                 containsString("the field [title] should be indexed with positions and offsets in the postings list to be used with postings highlighter"));
 
         //should not fail if there is a wildcard
         assertNoFailures(client().prepareSearch()
                         .setQuery(matchQuery("title", "this is a test"))
-                .highlighter(new HighlightBuilder().field("tit*").highlighterType("postings")).get());
+                        .addHighlightedField("tit*")
+                        .setHighlighterType("postings").get());
     }
 
     @Test
@@ -2374,7 +2304,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource()
                 .query(boostingQuery(termQuery("field2", "brown"), termQuery("field2", "foobar")).negativeBoost(0.5f))
-                .highlighter(highlight().field("field2").preTags("<x>").postTags("</x>"));
+                .highlight(highlight().field("field2").preTags("<x>").postTags("</x>"));
         SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
 
         assertHighlight(searchResponse, 0, "field2", 0, 1, equalTo("The quick <x>brown</x> fox jumps over the lazy dog!"));
@@ -2389,7 +2319,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         refresh();
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource().query(commonTermsQuery("field2", "quick brown").cutoffFrequency(100))
-                .highlighter(highlight().field("field2").preTags("<x>").postTags("</x>"));
+                .highlight(highlight().field("field2").preTags("<x>").postTags("</x>"));
         SearchResponse searchResponse = client().search(searchRequest("test").source(source)).actionGet();
         assertHitCount(searchResponse, 1l);
 
@@ -2415,7 +2345,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         logger.info("--> highlighting and searching on field2");
 
         SearchSourceBuilder source = searchSource().query(prefixQuery("field2", "qui"))
-                .highlighter(highlight().field("field2"));
+                .highlight(highlight().field("field2"));
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
         assertHighlight(searchResponse, 0, "field2", 0, 1, equalTo("The <em>quick</em> brown fox jumps over the lazy dog!"));
 
@@ -2430,7 +2360,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         refresh();
         logger.info("--> highlighting and searching on field2");
         SearchSourceBuilder source = searchSource().query(fuzzyQuery("field2", "quck"))
-                .highlighter(highlight().field("field2"));
+                .highlight(highlight().field("field2"));
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
 
         assertHighlight(searchResponse, 0, "field2", 0, 1, equalTo("The <em>quick</em> brown fox jumps over the lazy dog!"));
@@ -2445,7 +2375,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         refresh();
         logger.info("--> highlighting and searching on field2");
         SearchSourceBuilder source = searchSource().query(regexpQuery("field2", "qu[a-l]+k"))
-                .highlighter(highlight().field("field2"));
+                .highlight(highlight().field("field2"));
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
 
         assertHighlight(searchResponse, 0, "field2", 0, 1, equalTo("The <em>quick</em> brown fox jumps over the lazy dog!"));
@@ -2460,13 +2390,13 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         refresh();
         logger.info("--> highlighting and searching on field2");
         SearchSourceBuilder source = searchSource().query(wildcardQuery("field2", "qui*"))
-                .highlighter(highlight().field("field2"));
+                .highlight(highlight().field("field2"));
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
 
         assertHighlight(searchResponse, 0, "field2", 0, 1, equalTo("The <em>quick</em> brown fox jumps over the lazy dog!"));
 
         source = searchSource().query(wildcardQuery("field2", "qu*k"))
-                .highlighter(highlight().field("field2"));
+                .highlight(highlight().field("field2"));
         searchResponse = client().prepareSearch("test").setSource(source).get();
         assertHitCount(searchResponse, 1l);
 
@@ -2482,7 +2412,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         refresh();
         logger.info("--> highlighting and searching on field2");
         SearchSourceBuilder source = searchSource().query(rangeQuery("field2").gte("aaaa").lt("zzzz"))
-                .highlighter(highlight().field("field2"));
+                .highlight(highlight().field("field2"));
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
 
         assertHighlight(searchResponse, 0, "field2", 0, 1, equalTo("<em>aaab</em>"));
@@ -2497,7 +2427,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         refresh();
         logger.info("--> highlighting and searching on field2");
         SearchSourceBuilder source = searchSource().query(queryStringQuery("qui*").defaultField("field2"))
-                .highlighter(highlight().field("field2"));
+                .highlight(highlight().field("field2"));
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
         assertHighlight(searchResponse, 0, "field2", 0, 1, equalTo("The <em>quick</em> brown fox jumps over the lazy dog!"));
     }
@@ -2513,7 +2443,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource().query(constantScoreQuery(regexpQuery("field1", "pho[a-z]+")))
-                .highlighter(highlight().field("field1"));
+                .highlight(highlight().field("field1"));
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
         assertHighlight(searchResponse, 0, "field1", 0, 1, equalTo("The <em>photography</em> word will get highlighted"));
     }
@@ -2532,7 +2462,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
                 .should(constantScoreQuery(QueryBuilders.missingQuery("field1")))
                 .should(matchQuery("field1", "test"))
                 .should(constantScoreQuery(queryStringQuery("field1:photo*"))))
-                .highlighter(highlight().field("field1"));
+                .highlight(highlight().field("field1"));
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
         assertHighlight(searchResponse, 0, "field1", 0, 1, equalTo("The <em>photography</em> word will get highlighted"));
     }
@@ -2548,7 +2478,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource().query(boolQuery().must(prefixQuery("field1", "photo")).should(matchQuery("field1", "test").minimumShouldMatch("0")))
-                .highlighter(highlight().field("field1"));
+                .highlight(highlight().field("field1"));
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
         assertHighlight(searchResponse, 0, "field1", 0, 1, equalTo("The <em>photography</em> word will get highlighted"));
     }
@@ -2564,7 +2494,7 @@ public class HighlighterSearchIT extends ESIntegTestCase {
 
         logger.info("--> highlighting and searching on field1");
         SearchSourceBuilder source = searchSource().query(boolQuery().must(queryStringQuery("field1:photo*")).filter(missingQuery("field_null")))
-                .highlighter(highlight().field("field1"));
+                .highlight(highlight().field("field1"));
         SearchResponse searchResponse = client().prepareSearch("test").setSource(source).get();
         assertHighlight(searchResponse, 0, "field1", 0, 1, equalTo("The <em>photography</em> word will get highlighted"));
     }
@@ -2593,10 +2523,10 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         SearchRequestBuilder searchRequestBuilder = client().prepareSearch()
                 .setSize(COUNT)
                 .setQuery(termQuery("field1", "test"))
-                .highlighter(new HighlightBuilder().field("field1"));
+                .addHighlightedField("field1");
         SearchResponse searchResponse =
                 searchRequestBuilder.get();
-        assertHitCount(searchResponse, COUNT);
+        assertHitCount(searchResponse, (long)COUNT);
         assertThat(searchResponse.getHits().hits().length, equalTo(COUNT));
         for (SearchHit hit : searchResponse.getHits()) {
             String prefix = prefixes.get(hit.id());
@@ -2666,8 +2596,9 @@ public class HighlighterSearchIT extends ESIntegTestCase {
             phraseBoostTestCaseForClauses(String highlighterType, float boost, QueryBuilder terms, P phrase) {
         Matcher<String> highlightedMatcher = Matchers.either(containsString("<em>highlight words together</em>")).or(
                 containsString("<em>highlight</em> <em>words</em> <em>together</em>"));
-        SearchRequestBuilder search = client().prepareSearch("test").highlighter(
-                new HighlightBuilder().field("field1", 100, 1).order("score").highlighterType(highlighterType).requireFieldMatch(true));
+        SearchRequestBuilder search = client().prepareSearch("test").setHighlighterRequireFieldMatch(true)
+                .setHighlighterOrder("score").setHighlighterType(highlighterType)
+                .addHighlightedField("field1", 100, 1);
 
         // Try with a bool query
         phrase.boost(boost);
diff --git a/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java b/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java
index 417b6da..16c54c4 100644
--- a/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/innerhits/InnerHitsIT.java
@@ -33,7 +33,6 @@ import org.elasticsearch.script.Script;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHits;
 import org.elasticsearch.search.fetch.innerhits.InnerHitsBuilder;
-import org.elasticsearch.search.highlight.HighlightBuilder;
 import org.elasticsearch.search.sort.SortBuilders;
 import org.elasticsearch.search.sort.SortOrder;
 import org.elasticsearch.test.ESIntegTestCase;
@@ -44,24 +43,9 @@ import java.util.List;
 import java.util.Locale;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.boolQuery;
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasChildQuery;
-import static org.elasticsearch.index.query.QueryBuilders.hasParentQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
-import static org.elasticsearch.index.query.QueryBuilders.nestedQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAllSuccessful;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHit;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasId;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.elasticsearch.index.query.QueryBuilders.*;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
 
 /**
  */
@@ -102,14 +86,11 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .endObject()));
         indexRandom(true, requests);
 
-        InnerHitsBuilder innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addNestedInnerHits("comment", "comments",
-                new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.message", "fox")));
         // Inner hits can be defined in two ways: 1) with the query 2) as seperate inner_hit definition
         SearchRequest[] searchRequests = new SearchRequest[]{
                 client().prepareSearch("articles").setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits("comment", null))).request(),
                 client().prepareSearch("articles").setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")))
-                        .innerHits(innerHitsBuilder).request()
+                        .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.message", "fox"))).request()
         };
         for (SearchRequest searchRequest : searchRequests) {
             SearchResponse response = client().search(searchRequest).actionGet();
@@ -128,15 +109,10 @@ public class InnerHitsIT extends ESIntegTestCase {
             assertThat(innerHits.getAt(1).getNestedIdentity().getOffset(), equalTo(1));
         }
 
-        innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addNestedInnerHits("comment", "comments",
-                new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.message", "elephant")));
-        // Inner hits can be defined in two ways: 1) with the query 2) as
-        // seperate inner_hit definition
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")))
-                        .innerHits(innerHitsBuilder).request(),
+                        .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.message", "elephant"))).request(),
                 client().prepareSearch("articles")
                         .setQuery(nestedQuery("comments", matchQuery("comments.message", "elephant")).innerHit(new QueryInnerHits("comment", null))).request(),
                 client().prepareSearch("articles")
@@ -163,23 +139,21 @@ public class InnerHitsIT extends ESIntegTestCase {
             assertThat(innerHits.getAt(2).getNestedIdentity().getOffset(), equalTo(2));
         }
         InnerHitsBuilder.InnerHit innerHit = new InnerHitsBuilder.InnerHit();
-        innerHit.highlighter(new HighlightBuilder().field("comments.message"));
+        innerHit.highlightBuilder().field("comments.message");
         innerHit.setExplain(true);
         innerHit.addFieldDataField("comments.message");
         innerHit.addScriptField("script", new Script("doc['comments.message'].value"));
         innerHit.setSize(1);
-        innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addNestedInnerHits("comments", "comments", new InnerHitsBuilder.InnerHit()
-                            .setQuery(matchQuery("comments.message", "fox"))
-                            .highlighter(new HighlightBuilder().field("comments.message"))
-                            .setExplain(true)
-                            .addFieldDataField("comments.message")
-                            .addScriptField("script", new Script("doc['comments.message'].value"))
-                            .setSize(1));
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")))
-                        .innerHits(innerHitsBuilder).request(),
+                        .addNestedInnerHits("comments", "comments", new InnerHitsBuilder.InnerHit()
+                                .setQuery(matchQuery("comments.message", "fox"))
+                                .addHighlightedField("comments.message")
+                                .setExplain(true)
+                                .addFieldDataField("comments.message")
+                                .addScriptField("script", new Script("doc['comments.message'].value"))
+                                .setSize(1)).request(),
                 client().prepareSearch("articles")
                         .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, innerHit))).request()
         };
@@ -224,13 +198,11 @@ public class InnerHitsIT extends ESIntegTestCase {
         int size = randomIntBetween(0, numDocs);
         SearchResponse searchResponse;
         if (randomBoolean()) {
-            InnerHitsBuilder innerHitsBuilder = new InnerHitsBuilder();
-            innerHitsBuilder.addNestedInnerHits("a", "field1", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size)); // Sort order is DESC, because we reverse the inner objects during indexing!
-            innerHitsBuilder.addNestedInnerHits("b", "field2", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size));
             searchResponse = client().prepareSearch("idx")
                     .setSize(numDocs)
                     .addSort("_uid", SortOrder.ASC)
-                    .innerHits(innerHitsBuilder)
+                    .addNestedInnerHits("a", "field1", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size)) // Sort order is DESC, because we reverse the inner objects during indexing!
+                    .addNestedInnerHits("b", "field2", new InnerHitsBuilder.InnerHit().addSort("_doc", SortOrder.DESC).setSize(size))
                     .get();
         } else {
             BoolQueryBuilder boolQuery = new BoolQueryBuilder();
@@ -292,12 +264,10 @@ public class InnerHitsIT extends ESIntegTestCase {
         requests.add(client().prepareIndex("articles", "comment", "6").setParent("2").setSource("message", "elephant scared by mice x y"));
         indexRandom(true, requests);
 
-        InnerHitsBuilder innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "fox")));
         SearchRequest[] searchRequests = new SearchRequest[]{
                 client().prepareSearch("articles")
                         .setQuery(hasChildQuery("comment", matchQuery("message", "fox")))
-                        .innerHits(innerHitsBuilder)
+                        .addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "fox")))
                         .request(),
                 client().prepareSearch("articles")
                         .setQuery(hasChildQuery("comment", matchQuery("message", "fox")).innerHit(new QueryInnerHits("comment", null)))
@@ -320,12 +290,10 @@ public class InnerHitsIT extends ESIntegTestCase {
             assertThat(innerHits.getAt(1).type(), equalTo("comment"));
         }
 
-        innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "elephant")));
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(hasChildQuery("comment", matchQuery("message", "elephant")))
-                        .innerHits(innerHitsBuilder)
+                        .addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "elephant")))
                         .request(),
                 client().prepareSearch("articles")
                         .setQuery(hasChildQuery("comment", matchQuery("message", "elephant")).innerHit(new QueryInnerHits()))
@@ -349,24 +317,22 @@ public class InnerHitsIT extends ESIntegTestCase {
             assertThat(innerHits.getAt(2).type(), equalTo("comment"));
         }
         InnerHitsBuilder.InnerHit innerHit = new InnerHitsBuilder.InnerHit();
-        innerHit.highlighter(new HighlightBuilder().field("message"));
+        innerHit.highlightBuilder().field("message");
         innerHit.setExplain(true);
         innerHit.addFieldDataField("message");
         innerHit.addScriptField("script", new Script("doc['message'].value"));
         innerHit.setSize(1);
-        innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit()
-                            .setQuery(matchQuery("message", "fox"))
-                            .highlighter(new HighlightBuilder().field("message"))
-                            .setExplain(true)
-                            .addFieldDataField("message")
-                            .addScriptField("script", new Script("doc['message'].value"))
-                            .setSize(1));
         searchRequests = new SearchRequest[] {
                 client().prepareSearch("articles")
                         .setQuery(hasChildQuery("comment", matchQuery("message", "fox")))
-                        .innerHits(innerHitsBuilder)
-                        .request(),
+                        .addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit()
+                                        .setQuery(matchQuery("message", "fox"))
+                                        .addHighlightedField("message")
+                                        .setExplain(true)
+                                        .addFieldDataField("message")
+                                        .addScriptField("script", new Script("doc['message'].value"))
+                                        .setSize(1)
+                        ).request(),
 
                 client().prepareSearch("articles")
                         .setQuery(
@@ -417,16 +383,14 @@ public class InnerHitsIT extends ESIntegTestCase {
         indexRandom(true, requestBuilders);
 
         int size = randomIntBetween(0, numDocs);
-        InnerHitsBuilder innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addParentChildInnerHits("a", "child1", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size));
-        innerHitsBuilder.addParentChildInnerHits("b", "child2", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size));
         SearchResponse searchResponse;
         if (randomBoolean()) {
             searchResponse = client().prepareSearch("idx")
                     .setSize(numDocs)
                     .setTypes("parent")
                     .addSort("_uid", SortOrder.ASC)
-                    .innerHits(innerHitsBuilder)
+                    .addParentChildInnerHits("a", "child1", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size))
+                    .addParentChildInnerHits("b", "child2", new InnerHitsBuilder.InnerHit().addSort("_uid", SortOrder.ASC).setSize(size))
                     .get();
         } else {
             BoolQueryBuilder boolQuery = new BoolQueryBuilder();
@@ -482,15 +446,12 @@ public class InnerHitsIT extends ESIntegTestCase {
     }
 
     @Test
-    @AwaitsFix(bugUrl = "need validation of type or path defined in InnerHitsBuilder")
     public void testPathOrTypeMustBeDefined() {
         createIndex("articles");
         ensureGreen("articles");
         try {
-            InnerHitsBuilder innerHitsBuilder = new InnerHitsBuilder();
-            innerHitsBuilder.addParentChildInnerHits("comment", null, new InnerHitsBuilder.InnerHit());
             client().prepareSearch("articles")
-                    .innerHits(innerHitsBuilder)
+                    .addParentChildInnerHits("comment", null, new InnerHitsBuilder.InnerHit())
                     .get();
         } catch (Exception e) {
             assertThat(e.getMessage(), containsString("Failed to build"));
@@ -554,15 +515,13 @@ public class InnerHitsIT extends ESIntegTestCase {
         requests.add(client().prepareIndex("articles", "remark", "2").setParent("2").setRouting("2").setSource("message", "bad"));
         indexRandom(true, requests);
 
-        InnerHitsBuilder innerInnerHitsBuilder = new InnerHitsBuilder();
-        innerInnerHitsBuilder.addParentChildInnerHits("remark", "remark", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "good")));
-        InnerHitsBuilder innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit()
-                            .setQuery(hasChildQuery("remark", matchQuery("message", "good")))
-                            .innerHits(innerInnerHitsBuilder));
         SearchResponse response = client().prepareSearch("articles")
                 .setQuery(hasChildQuery("comment", hasChildQuery("remark", matchQuery("message", "good"))))
-                .innerHits(innerHitsBuilder)
+                .addParentChildInnerHits("comment", "comment",
+                        new InnerHitsBuilder.InnerHit()
+                                .setQuery(hasChildQuery("remark", matchQuery("message", "good")))
+                                .addParentChildInnerHits("remark", "remark", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "good")))
+                )
                 .get();
 
         assertNoFailures(response);
@@ -580,15 +539,13 @@ public class InnerHitsIT extends ESIntegTestCase {
         assertThat(innerHits.getAt(0).getId(), equalTo("1"));
         assertThat(innerHits.getAt(0).type(), equalTo("remark"));
 
-        innerInnerHitsBuilder = new InnerHitsBuilder();
-        innerInnerHitsBuilder.addParentChildInnerHits("remark", "remark", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "bad")));
-        innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addParentChildInnerHits("comment", "comment", new InnerHitsBuilder.InnerHit()
-                .setQuery(hasChildQuery("remark", matchQuery("message", "bad")))
-                .innerHits(innerInnerHitsBuilder));
         response = client().prepareSearch("articles")
                 .setQuery(hasChildQuery("comment", hasChildQuery("remark", matchQuery("message", "bad"))))
-                .innerHits(innerHitsBuilder)
+                .addParentChildInnerHits("comment", "comment",
+                        new InnerHitsBuilder.InnerHit()
+                                .setQuery(hasChildQuery("remark", matchQuery("message", "bad")))
+                                .addParentChildInnerHits("remark", "remark", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("message", "bad")))
+                )
                 .get();
 
         assertNoFailures(response);
@@ -650,16 +607,12 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .endObject()));
         indexRandom(true, requests);
 
-        InnerHitsBuilder innerInnerHitsBuilder = new InnerHitsBuilder();
-        innerInnerHitsBuilder.addNestedInnerHits("remark", "comments.remarks", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.remarks.message", "good")));
-        InnerHitsBuilder innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit()
-                .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "good")))
-                .innerHits(innerInnerHitsBuilder)
-        );
         SearchResponse response = client().prepareSearch("articles")
                 .setQuery(nestedQuery("comments", nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "good"))))
-                .innerHits(innerHitsBuilder).get();
+                .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit()
+                                .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "good")))
+                                .addNestedInnerHits("remark", "comments.remarks", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.remarks.message", "good")))
+                ).get();
         assertNoFailures(response);
         assertHitCount(response, 1);
         assertSearchHit(response, 1, hasId("1"));
@@ -696,15 +649,11 @@ public class InnerHitsIT extends ESIntegTestCase {
         assertThat(innerHits.getAt(0).getNestedIdentity().getChild().getField().string(), equalTo("remarks"));
         assertThat(innerHits.getAt(0).getNestedIdentity().getChild().getOffset(), equalTo(0));
 
-        innerInnerHitsBuilder = new InnerHitsBuilder();
-        innerInnerHitsBuilder.addNestedInnerHits("remark", "comments.remarks", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.remarks.message", "bad")));
-        innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit()
-                            .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad")))
-                            .innerHits(innerInnerHitsBuilder));
         response = client().prepareSearch("articles")
                 .setQuery(nestedQuery("comments", nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad"))))
-                .innerHits(innerHitsBuilder)
+                .addNestedInnerHits("comment", "comments", new InnerHitsBuilder.InnerHit()
+                        .setQuery(nestedQuery("comments.remarks", matchQuery("comments.remarks.message", "bad")))
+                        .addNestedInnerHits("remark", "comments.remarks", new InnerHitsBuilder.InnerHit().setQuery(matchQuery("comments.remarks.message", "bad"))))
                 .get();
         assertNoFailures(response);
         assertHitCount(response, 1);
@@ -752,8 +701,6 @@ public class InnerHitsIT extends ESIntegTestCase {
     }
 
     @Test
-    @AwaitsFix(bugUrl = "needs fixing following search request refactoring")
-    // NORELEASE
     public void testNestedInnerHitsWithStoredFieldsAndNoSourceBackcompat() throws Exception {
         assertAcked(prepareCreate("articles")
                 .setSettings(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id)
@@ -789,7 +736,7 @@ public class InnerHitsIT extends ESIntegTestCase {
         assertThat(response.getHits().getAt(0).getInnerHits().get("comments").getAt(0).getNestedIdentity().getField().string(), equalTo("comments"));
         assertThat(response.getHits().getAt(0).getInnerHits().get("comments").getAt(0).getNestedIdentity().getOffset(), equalTo(0));
         assertThat(response.getHits().getAt(0).getInnerHits().get("comments").getAt(0).getNestedIdentity().getChild(), nullValue());
-        assertThat(String.valueOf(response.getHits().getAt(0).getInnerHits().get("comments").getAt(0).fields().get("comments.message").getValue()), equalTo("fox eat quick"));
+        assertThat(String.valueOf((Object)response.getHits().getAt(0).getInnerHits().get("comments").getAt(0).fields().get("comments.message").getValue()), equalTo("fox eat quick"));
     }
 
     @Test
@@ -817,7 +764,7 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .endObject()));
         indexRandom(true, requests);
         InnerHitsBuilder.InnerHit builder = new InnerHitsBuilder.InnerHit();
-        builder.highlighter(new HighlightBuilder().field("comments.message"));
+        builder.highlightBuilder().field("comments.message");
         SearchResponse response = client().prepareSearch("articles")
                 .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, builder)))
                 .get();
@@ -833,8 +780,6 @@ public class InnerHitsIT extends ESIntegTestCase {
     }
 
     @Test
-    @AwaitsFix(bugUrl = "needs fixing following search request refactoring")
-    // NORELEASE
     public void testNestedInnerHitsWithExcludeSourceBackcompat() throws Exception {
         assertAcked(prepareCreate("articles").setSettings(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id)
                         .addMapping("article", jsonBuilder().startObject()
@@ -871,12 +816,10 @@ public class InnerHitsIT extends ESIntegTestCase {
         assertThat(response.getHits().getAt(0).getInnerHits().get("comments").getAt(0).getNestedIdentity().getField().string(), equalTo("comments"));
         assertThat(response.getHits().getAt(0).getInnerHits().get("comments").getAt(0).getNestedIdentity().getOffset(), equalTo(0));
         assertThat(response.getHits().getAt(0).getInnerHits().get("comments").getAt(0).getNestedIdentity().getChild(), nullValue());
-        assertThat(String.valueOf(response.getHits().getAt(0).getInnerHits().get("comments").getAt(0).fields().get("comments.message").getValue()), equalTo("fox eat quick"));
+        assertThat(String.valueOf((Object)response.getHits().getAt(0).getInnerHits().get("comments").getAt(0).fields().get("comments.message").getValue()), equalTo("fox eat quick"));
     }
 
     @Test
-    @AwaitsFix(bugUrl = "needs fixing following search request refactoring")
-    // NORELEASE
     public void testNestedInnerHitsHiglightWithExcludeSourceBackcompat() throws Exception {
         assertAcked(prepareCreate("articles").setSettings(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id)
                         .addMapping("article", jsonBuilder().startObject()
@@ -900,7 +843,7 @@ public class InnerHitsIT extends ESIntegTestCase {
                 .endObject()));
         indexRandom(true, requests);
         InnerHitsBuilder.InnerHit builder = new InnerHitsBuilder.InnerHit();
-        builder.highlighter(new HighlightBuilder().field("comments.message"));
+        builder.highlightBuilder().field("comments.message");
         SearchResponse response = client().prepareSearch("articles")
                 .setQuery(nestedQuery("comments", matchQuery("comments.message", "fox")).innerHit(new QueryInnerHits(null, builder)))
                         .get();
@@ -1012,23 +955,17 @@ public class InnerHitsIT extends ESIntegTestCase {
         requests.add(client().prepareIndex("royals", "baron", "baron4").setParent("earl4").setRouting("king").setSource("{}"));
         indexRandom(true, requests);
 
-        InnerHitsBuilder innerInnerHitsBuilder = new InnerHitsBuilder();
-        innerInnerHitsBuilder.addParentChildInnerHits("barons", "baron", new InnerHitsBuilder.InnerHit());
-        InnerHitsBuilder innerHitsBuilder = new InnerHitsBuilder();
-        innerHitsBuilder.addParentChildInnerHits("earls", "earl", new InnerHitsBuilder.InnerHit()
-                .addSort(SortBuilders.fieldSort("_uid").order(SortOrder.ASC))
-                .setSize(4)
-                .innerHits(innerInnerHitsBuilder)
-        );
-        innerInnerHitsBuilder = new InnerHitsBuilder();
-        innerInnerHitsBuilder.addParentChildInnerHits("kings", "king", new InnerHitsBuilder.InnerHit());
-        innerHitsBuilder.addParentChildInnerHits("princes", "prince",
-        new InnerHitsBuilder.InnerHit()
-            .innerHits(innerInnerHitsBuilder)
-        );
         SearchResponse response = client().prepareSearch("royals")
                 .setTypes("duke")
-                .innerHits(innerHitsBuilder)
+                .addParentChildInnerHits("earls", "earl", new InnerHitsBuilder.InnerHit()
+                                .addSort(SortBuilders.fieldSort("_uid").order(SortOrder.ASC))
+                                .setSize(4)
+                                .addParentChildInnerHits("barons", "baron", new InnerHitsBuilder.InnerHit())
+                )
+                .addParentChildInnerHits("princes", "prince",
+                        new InnerHitsBuilder.InnerHit()
+                        .addParentChildInnerHits("kings", "king", new InnerHitsBuilder.InnerHit())
+                )
                 .get();
         assertHitCount(response, 1);
         assertThat(response.getHits().getAt(0).getId(), equalTo("duke"));
diff --git a/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisIT.java b/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisIT.java
index dc98d0d..0e70015 100644
--- a/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisIT.java
+++ b/core/src/test/java/org/elasticsearch/search/morelikethis/MoreLikeThisIT.java
@@ -39,6 +39,7 @@ import java.util.ArrayList;
 import java.util.List;
 import java.util.concurrent.ExecutionException;
 
+import static org.elasticsearch.index.query.MoreLikeThisQueryBuilder.ids;
 import static org.elasticsearch.client.Requests.*;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
@@ -72,7 +73,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         logger.info("Running moreLikeThis");
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("test", "type1", "1")}).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 1l);
     }
 
@@ -92,7 +93,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         logger.info("Running moreLikeThis");
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("test", "type1", "1")}).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 0l);
     }
 
@@ -119,24 +120,24 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         logger.info("Running moreLikeThis on index");
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("test", "type1", "1")}).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 2l);
 
         logger.info("Running moreLikeThis on beta shard");
         response = client().prepareSearch("beta").setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("test", "type1", "1")}).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 1l);
         assertThat(response.getHits().getAt(0).id(), equalTo("3"));
 
         logger.info("Running moreLikeThis on release shard");
         response = client().prepareSearch("release").setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("test", "type1", "1")}).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 1l);
         assertThat(response.getHits().getAt(0).id(), equalTo("2"));
 
         logger.info("Running moreLikeThis on alias with node client");
         response = internalCluster().clientNodeClient().prepareSearch("beta").setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("test", "type1", "1")}).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(response, 1l);
         assertThat(response.getHits().getAt(0).id(), equalTo("3"));
     }
@@ -156,11 +157,11 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         assertThat(ensureGreen(), equalTo(ClusterHealthStatus.GREEN));
 
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("foo", "bar", "1"))).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("foo", "bar", "1")})).get();
         assertNoFailures(response);
         assertThat(response, notNullValue());
         response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("foo", "bar", "1"))).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("foo", "bar", "1")})).get();
         assertNoFailures(response);
         assertThat(response, notNullValue());
     }
@@ -182,7 +183,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         client().admin().indices().prepareRefresh("foo").execute().actionGet();
 
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("foo", "bar", "1").routing("2"))).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("foo", "bar", "1").routing("2")})).get();
         assertNoFailures(response);
         assertThat(response, notNullValue());
     }
@@ -205,7 +206,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
                 .execute().actionGet();
         client().admin().indices().prepareRefresh("foo").execute().actionGet();
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("foo", "bar", "1").routing("4000"))).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("foo", "bar", "1").routing("4000")})).get();
         assertNoFailures(response);
         assertThat(response, notNullValue());
     }
@@ -233,41 +234,41 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         // Implicit list of fields -> ignore numeric fields
         SearchResponse searchResponse = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("test", "type", "1")).minTermFreq(1).minDocFreq(1)).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("test", "type", "1")}).minTermFreq(1).minDocFreq(1)).get();
         assertHitCount(searchResponse, 1l);
 
         // Explicit list of fields including numeric fields -> fail
         assertThrows(client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder("string_value", "int_value").like(new Item("test", "type", "1")).minTermFreq(1).minDocFreq(1)), SearchPhaseExecutionException.class);
+                new MoreLikeThisQueryBuilder(new String[] {"string_value", "int_value"}, null, new Item[] {new Item("test", "type", "1")}).minTermFreq(1).minDocFreq(1)), SearchPhaseExecutionException.class);
 
         // mlt query with no field -> OK
-        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery().likeText("index").minTermFreq(1).minDocFreq(1)).execute().actionGet();
+        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery(new String[] {"index"}).minTermFreq(1).minDocFreq(1)).execute().actionGet();
         assertHitCount(searchResponse, 2l);
 
         // mlt query with string fields
-        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery("string_value").likeText("index").minTermFreq(1).minDocFreq(1)).execute().actionGet();
+        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery(new String[]{"string_value"}, new String[] {"index"}, null).minTermFreq(1).minDocFreq(1)).execute().actionGet();
         assertHitCount(searchResponse, 2l);
 
         // mlt query with at least a numeric field -> fail by default
-        assertThrows(client().prepareSearch().setQuery(moreLikeThisQuery("string_value", "int_value").likeText("index")), SearchPhaseExecutionException.class);
+        assertThrows(client().prepareSearch().setQuery(moreLikeThisQuery(new String[] {"string_value", "int_value"}, new String[] {"index"}, null)), SearchPhaseExecutionException.class);
 
         // mlt query with at least a numeric field -> fail by command
-        assertThrows(client().prepareSearch().setQuery(moreLikeThisQuery("string_value", "int_value").likeText("index").failOnUnsupportedField(true)), SearchPhaseExecutionException.class);
+        assertThrows(client().prepareSearch().setQuery(moreLikeThisQuery(new String[] {"string_value", "int_value"}, new String[] {"index"}, null).failOnUnsupportedField(true)), SearchPhaseExecutionException.class);
 
 
         // mlt query with at least a numeric field but fail_on_unsupported_field set to false
-        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery("string_value", "int_value").likeText("index").minTermFreq(1).minDocFreq(1).failOnUnsupportedField(false)).get();
+        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery(new String[] {"string_value", "int_value"}, new String[] {"index"}, null).minTermFreq(1).minDocFreq(1).failOnUnsupportedField(false)).get();
         assertHitCount(searchResponse, 2l);
 
         // mlt field query on a numeric field -> failure by default
-        assertThrows(client().prepareSearch().setQuery(moreLikeThisQuery("int_value").likeText("42").minTermFreq(1).minDocFreq(1)), SearchPhaseExecutionException.class);
+        assertThrows(client().prepareSearch().setQuery(moreLikeThisQuery(new String[] {"int_value"}, new String[] {"42"}, null).minTermFreq(1).minDocFreq(1)), SearchPhaseExecutionException.class);
 
         // mlt field query on a numeric field -> failure by command
-        assertThrows(client().prepareSearch().setQuery(moreLikeThisQuery("int_value").likeText("42").minTermFreq(1).minDocFreq(1).failOnUnsupportedField(true)),
+        assertThrows(client().prepareSearch().setQuery(moreLikeThisQuery(new String[] {"int_value"}, new String[] {"42"}, null).minTermFreq(1).minDocFreq(1).failOnUnsupportedField(true)),
                 SearchPhaseExecutionException.class);
 
         // mlt field query on a numeric field but fail_on_unsupported_field set to false
-        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery("int_value").likeText("42").minTermFreq(1).minDocFreq(1).failOnUnsupportedField(false)).execute().actionGet();
+        searchResponse = client().prepareSearch().setQuery(moreLikeThisQuery(new String[] {"int_value"}, new String[] {"42"}, null).minTermFreq(1).minDocFreq(1).failOnUnsupportedField(false)).execute().actionGet();
         assertHitCount(searchResponse, 0l);
     }
 
@@ -295,16 +296,16 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         logger.info("Running More Like This with include true");
         SearchResponse response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1).include(true).minimumShouldMatch("0%")).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("test", "type1", "1")}).minTermFreq(1).minDocFreq(1).include(true).minimumShouldMatch("0%")).get();
         assertOrderedSearchHits(response, "1", "2");
 
         response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("test", "type1", "2")).minTermFreq(1).minDocFreq(1).include(true).minimumShouldMatch("0%")).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("test", "type1", "2")}).minTermFreq(1).minDocFreq(1).include(true).minimumShouldMatch("0%")).get();
         assertOrderedSearchHits(response, "2", "1");
 
         logger.info("Running More Like This with include false");
         response = client().prepareSearch().setQuery(
-                new MoreLikeThisQueryBuilder().like(new Item("test", "type1", "1")).minTermFreq(1).minDocFreq(1).minimumShouldMatch("0%")).get();
+                new MoreLikeThisQueryBuilder(null, new Item[] {new Item("test", "type1", "1")}).minTermFreq(1).minDocFreq(1).minimumShouldMatch("0%")).get();
         assertSearchHits(response, "2");
     }
 
@@ -326,7 +327,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         indexRandom(true, builders);
 
         logger.info("Running MoreLikeThis");
-        MoreLikeThisQueryBuilder queryBuilder = QueryBuilders.moreLikeThisQuery("text").ids("1").include(true).minTermFreq(1).minDocFreq(1);
+        MoreLikeThisQueryBuilder queryBuilder = QueryBuilders.moreLikeThisQuery(new String[] {"text"}, null, ids("1")).include(true).minTermFreq(1).minDocFreq(1);
         SearchResponse mltResponse = client().prepareSearch().setTypes("type1").setQuery(queryBuilder).execute().actionGet();
         assertHitCount(mltResponse, 3l);
     }
@@ -354,8 +355,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         indexRandom(true, builders);
 
         logger.info("Running MoreLikeThis");
-        MoreLikeThisQueryBuilder queryBuilder = QueryBuilders.moreLikeThisQuery("text").include(true).minTermFreq(1).minDocFreq(1)
-                .like(new Item("test", "type0", "0"));
+        MoreLikeThisQueryBuilder queryBuilder = QueryBuilders.moreLikeThisQuery(new String[] {"text"}, null, new Item[] {new Item("test", "type0", "0")}).include(true).minTermFreq(1).minDocFreq(1);
 
         String[] types = new String[numOfTypes];
         for (int i = 0; i < numOfTypes; i++) {
@@ -388,7 +388,8 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         for (int i = 0; i < maxIters; i++) {
             int max_query_terms = randomIntBetween(1, values.length);
             logger.info("Running More Like This with max_query_terms = %s", max_query_terms);
-            MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery("text").ids("0").minTermFreq(1).minDocFreq(1)
+            MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery(new String[] {"text"}, null, new Item[] {new Item(null, null, "0")})
+                    .minTermFreq(1).minDocFreq(1)
                     .maxQueryTerms(max_query_terms).minimumShouldMatch("0%");
             SearchResponse response = client().prepareSearch("test").setTypes("type1")
                     .setQuery(mltQuery).execute().actionGet();
@@ -419,8 +420,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         logger.info("Testing each minimum_should_match from 0% - 100% with 10% increment ...");
         for (int i = 0; i <= 10; i++) {
             String minimumShouldMatch = (10 * i) + "%";
-            MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery("text")
-                    .likeText("1 2 3 4 5 6 7 8 9 10")
+            MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery(new String[] {"text"}, new String[] {"1 2 3 4 5 6 7 8 9 10"}, null)
                     .minTermFreq(1)
                     .minDocFreq(1)
                     .minimumShouldMatch(minimumShouldMatch);
@@ -452,8 +452,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         indexRandom(true, client().prepareIndex("test", "type1", "0").setSource(doc));
 
         logger.info("Checking the document matches ...");
-        MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery()
-                .like(new Item("test", "type1", doc).routing("0"))  // routing to ensure we hit the shard with the doc
+        MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery(new Item[] {new Item("test", "type1", doc).routing("0")})  // routing to ensure we hit the shard with the doc
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .maxQueryTerms(100)
@@ -484,8 +483,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
                 .field("text", "Hello World!")
                 .field("date", "this is not a date!")
                 .endObject();
-        MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery()
-                .like(new Item("test", "type1", malformedFieldDoc))
+        MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery(new Item[] {new Item("test", "type1", malformedFieldDoc)})
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .minimumShouldMatch("0%");
@@ -496,8 +494,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         logger.info("Checking with an empty document ...");
         XContentBuilder emptyDoc = jsonBuilder().startObject().endObject();
-        mltQuery = moreLikeThisQuery()
-                .like(new Item("test", "type1", emptyDoc))
+        mltQuery = moreLikeThisQuery(null, new Item[] {new Item("test", "type1", emptyDoc)})
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .minimumShouldMatch("0%");
@@ -508,8 +505,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
 
         logger.info("Checking when document is malformed ...");
         XContentBuilder malformedDoc = jsonBuilder().startObject();
-        mltQuery = moreLikeThisQuery()
-                .like(new Item("test", "type1", malformedDoc))
+        mltQuery = moreLikeThisQuery(null, new Item[] {new Item("test", "type1", malformedDoc)})
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .minimumShouldMatch("0%");
@@ -524,8 +520,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
                 .field("text", "Hello World!")
                 .field("date", "1000-01-01") // should be properly parsed but ignored ...
                 .endObject();
-        mltQuery = moreLikeThisQuery()
-                .like(new Item("test", "type1", normalDoc))
+        mltQuery = moreLikeThisQuery(null, new Item[] {new Item("test", "type1", normalDoc)})
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .minimumShouldMatch("100%");  // strict all terms must match but date is ignored
@@ -556,8 +551,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         indexRandom(true, builders);
 
         logger.info("First check the document matches all indexed docs.");
-        MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery()
-                .like(new Item("test", "type1", doc))
+        MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery(new Item[] {new Item("test", "type1", doc)})
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .maxQueryTerms(100)
@@ -568,12 +562,11 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         assertHitCount(response, numFields);
 
         logger.info("Now check like this doc, but ignore one doc in the index, then two and so on...");
-        List<Item> docs = new ArrayList<>();
+        List<Item> docs = new ArrayList<>(numFields);
         for (int i = 0; i < numFields; i++) {
             docs.add(new Item("test", "type1", i+""));
-            mltQuery = moreLikeThisQuery()
-                    .like(new Item("test", "type1", doc))
-                    .unlike(docs.toArray(Item.EMPTY_ARRAY))
+            mltQuery = moreLikeThisQuery(null, new Item[] {new Item("test", "type1", doc)})
+                    .unlike(docs.toArray(new Item[docs.size()]))
                     .minTermFreq(0)
                     .minDocFreq(0)
                     .maxQueryTerms(100)
@@ -602,8 +595,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
                         .field("text1", "elasticsearch")
                         .endObject()));
 
-        MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery()
-                .like(new Item("test", "type1", "1"))
+        MoreLikeThisQueryBuilder mltQuery = moreLikeThisQuery(new Item[] {new Item("test", "type1", "1")})
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .include(true)
@@ -613,8 +605,7 @@ public class MoreLikeThisIT extends ESIntegTestCase {
         assertSearchResponse(response);
         assertHitCount(response, 2);
 
-        mltQuery = moreLikeThisQuery("text")
-                .like(new Item("test", "type1", "1"))
+        mltQuery = moreLikeThisQuery(new String[] {"text"}, null, new Item[] {new Item("test", "type1", "1")})
                 .minTermFreq(0)
                 .minDocFreq(0)
                 .include(true)
diff --git a/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java b/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
index ac364a8..83a8008 100644
--- a/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
@@ -145,15 +145,15 @@ public class SearchQueryIT extends ESIntegTestCase {
                 client().prepareSearch().setQuery(matchAllQuery()).setPostFilter(notQuery(termQuery("field1", "value3"))).get(),
                 2l);
     }
-// NORELEASE  This should be tested in SearchSourceBuilderTests
-//    @Test
-//    public void passQueryAsStringTest() throws Exception {
-//        createIndex("test");
-//        client().prepareIndex("test", "type1", "1").setSource("field1", "value1_1", "field2", "value2_1").setRefresh(true).get();
-//
-//        SearchResponse searchResponse = client().prepareSearch().setQuery("{ \"term\" : { \"field1\" : \"value1_1\" }}").get();
-//        assertHitCount(searchResponse, 1l);
-//    }
+
+    @Test
+    public void passQueryAsStringTest() throws Exception {
+        createIndex("test");
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1_1", "field2", "value2_1").setRefresh(true).get();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery("{ \"term\" : { \"field1\" : \"value1_1\" }}").get();
+        assertHitCount(searchResponse, 1l);
+    }
 
     @Test
     public void testIndexOptions() throws Exception {
@@ -310,10 +310,9 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("2"));
 
-     // NORELEASE  This should be tested in SearchSourceBuilderTests
-//        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 4 } } } }").get();
-//        assertHitCount(searchResponse, 1l);
-//        assertFirstHit(searchResponse, hasId("2"));
+        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 4 } } } }").get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
 
         // Default
         searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1)).get();
@@ -403,10 +402,9 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertHitCount(searchResponse, 1l);
         assertFirstHit(searchResponse, hasId("2"));
 
-     // NORELEASE  This should be tested in SearchSourceBuilderTests
-//        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the fast lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 6 } } } }").get();
-//        assertHitCount(searchResponse, 1l);
-//        assertFirstHit(searchResponse, hasId("2"));
+        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the fast lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 6 } } } }").get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
 
         // Default
         searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1)).get();
@@ -1508,14 +1506,13 @@ public class SearchQueryIT extends ESIntegTestCase {
         assertHitCount(searchResponse, 2l);
     }
 
- // NORELEASE  This should be tested in SearchSourceBuilderTests
-//    @Test
-//    public void testEmptyTopLevelFilter() {
-//        client().prepareIndex("test", "type", "1").setSource("field", "value").setRefresh(true).get();
-//
-//        SearchResponse searchResponse = client().prepareSearch().setPostFilter("{}").get();
-//        assertHitCount(searchResponse, 1l);
-//    }
+    @Test
+    public void testEmptyTopLevelFilter() {
+        client().prepareIndex("test", "type", "1").setSource("field", "value").setRefresh(true).get();
+
+        SearchResponse searchResponse = client().prepareSearch().setPostFilter("{}").get();
+        assertHitCount(searchResponse, 1l);
+    }
 
     @Test // see #2926
     public void testMustNot() throws IOException, ExecutionException, InterruptedException {
@@ -2238,26 +2235,25 @@ functionScoreQuery(scriptFunction(new Script("_doc['score'].value")))).setMinSco
         }
     }
 
- // NORELEASE  This should be tested in SearchSourceBuilderTests
-//    @Test // see #7686.
-//    public void testIdsQueryWithInvalidValues() throws Exception {
-//        createIndex("test");
-//        indexRandom(true, false, client().prepareIndex("test", "type", "1").setSource("body", "foo"));
-//
-//        try {
-//            client().prepareSearch("test")
-//                    .setTypes("type")
-//                    .setQuery("{\n" +
-//                            "  \"ids\": {\n" +
-//                            "    \"values\": [[\"1\"]]\n" +
-//                            "  }\n" +
-//                            "}")
-//                    .get();
-//            fail("query is invalid and should have produced a parse exception");
-//        } catch (Exception e) {
-//            assertThat("query could not be parsed due to bad format: " + e.toString(),
-//                    e.toString().contains("Illegal value for id, expecting a string or number, got: START_ARRAY"),
-//                    equalTo(true));
-//        }
-//    }
+    @Test // see #7686.
+    public void testIdsQueryWithInvalidValues() throws Exception {
+        createIndex("test");
+        indexRandom(true, false, client().prepareIndex("test", "type", "1").setSource("body", "foo"));
+
+        try {
+            client().prepareSearch("test")
+                    .setTypes("type")
+                    .setQuery("{\n" +
+                            "  \"ids\": {\n" +
+                            "    \"values\": [[\"1\"]]\n" +
+                            "  }\n" +
+                            "}")
+                    .get();
+            fail("query is invalid and should have produced a parse exception");
+        } catch (Exception e) {
+            assertThat("query could not be parsed due to bad format: " + e.toString(),
+                    e.toString().contains("Illegal value for id, expecting a string or number, got: START_ARRAY"),
+                    equalTo(true));
+        }
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
index dc97447..bf3e458 100644
--- a/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/SimpleQueryStringIT.java
@@ -242,12 +242,10 @@ public class SimpleQueryStringIT extends ESIntegTestCase {
         assertHitCount(searchResponse, 3l);
         assertSearchHits(searchResponse, "1", "2", "3");
 
-
-        // NORELEASE  This should be tested in SimpleQueryStringQueryBuilderTests
-//        // Sending a negative 'flags' value is the same as SimpleQueryStringFlag.ALL
-//        searchResponse = client().prepareSearch().setQuery("{\"simple_query_string\": {\"query\": \"foo bar\", \"flags\": -1}}").get();
-//        assertHitCount(searchResponse, 3l);
-//        assertSearchHits(searchResponse, "1", "2", "3");
+        // Sending a negative 'flags' value is the same as SimpleQueryStringFlag.ALL
+        searchResponse = client().prepareSearch().setQuery("{\"simple_query_string\": {\"query\": \"foo bar\", \"flags\": -1}}").get();
+        assertHitCount(searchResponse, 3l);
+        assertSearchHits(searchResponse, "1", "2", "3");
 
         searchResponse = client().prepareSearch().setQuery(
                 simpleQueryStringQuery("foo | bar")
@@ -269,23 +267,23 @@ public class SimpleQueryStringIT extends ESIntegTestCase {
                         .flags(SimpleQueryStringFlag.NONE)).get();
         assertHitCount(searchResponse, 0l);
 
-//        searchResponse = client().prepareSearch().setSource(new BytesArray("{\n" +
-//                "  \"query\": {\n" +
-//                "    \"simple_query_string\": {\n" +
-//                "      \"query\": \"foo|bar\",\n" +
-//                "      \"default_operator\": \"AND\"," +
-//                "      \"flags\": \"NONE\"\n" +
-//                "    }\n" +
-//                "  }\n" +
-//                "}")).get();
-//        assertHitCount(searchResponse, 1l);
-//
-//        searchResponse = client().prepareSearch().setQuery(
-//                simpleQueryStringQuery("baz | egg*")
-//                        .defaultOperator(Operator.AND)
-//                        .flags(SimpleQueryStringFlag.WHITESPACE, SimpleQueryStringFlag.PREFIX)).get();
-//        assertHitCount(searchResponse, 1l);
-//        assertFirstHit(searchResponse, hasId("4")); NOCOMMIT fix this
+        searchResponse = client().prepareSearch().setSource(new BytesArray("{\n" +
+                "  \"query\": {\n" +
+                "    \"simple_query_string\": {\n" +
+                "      \"query\": \"foo|bar\",\n" +
+                "      \"default_operator\": \"AND\"," +
+                "      \"flags\": \"NONE\"\n" +
+                "    }\n" +
+                "  }\n" +
+                "}")).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(
+                simpleQueryStringQuery("baz | egg*")
+                        .defaultOperator(Operator.AND)
+                        .flags(SimpleQueryStringFlag.WHITESPACE, SimpleQueryStringFlag.PREFIX)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("4"));
     }
 
     @Test
diff --git a/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java b/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
index 3aba46c..5a22afe 100644
--- a/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
+++ b/core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java
@@ -48,19 +48,8 @@ import java.util.Comparator;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFirstHit;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFourthHit;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSecondHit;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertThirdHit;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasId;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasScore;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.lessThanOrEqualTo;
-import static org.hamcrest.Matchers.notNullValue;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -68,8 +57,6 @@ import static org.hamcrest.Matchers.notNullValue;
 public class QueryRescorerIT extends ESIntegTestCase {
 
     @Test
-    @AwaitsFix(bugUrl = "Need to fix default window size for rescorers so that they are applied")
-    // NORELEASE
     public void testEnforceWindowSize() {
         createIndex("test");
         // this
@@ -85,9 +72,9 @@ public class QueryRescorerIT extends ESIntegTestCase {
             SearchResponse searchResponse = client().prepareSearch()
                     .setQuery(QueryBuilders.matchAllQuery())
                     .setRescorer(RescoreBuilder.queryRescorer(
-                            QueryBuilders.functionScoreQuery(QueryBuilders.matchAllQuery())
-                                    .boostMode("replace").add(ScoreFunctionBuilders.weightFactorFunction(100))).setQueryWeight(0.0f).setRescoreQueryWeight(1.0f))
-                    .setRescoreWindow(1).setSize(randomIntBetween(2,10)).execute().actionGet();
+                            QueryBuilders.functionScoreQuery(QueryBuilders.matchAllQuery(),
+                                    ScoreFunctionBuilders.weightFactorFunction(100)).boostMode(CombineFunction.REPLACE)).setQueryWeight(0.0f).setRescoreQueryWeight(1.0f))
+                    .setRescoreWindow(1).setSize(randomIntBetween(2, 10)).execute().actionGet();
             assertSearchResponse(searchResponse);
             assertFirstHit(searchResponse, hasScore(100.f));
             int numDocsWith100AsAScore = 0;
@@ -228,8 +215,6 @@ public class QueryRescorerIT extends ESIntegTestCase {
 
     // Tests a rescore window smaller than number of hits:
     @Test
-    @AwaitsFix(bugUrl = "Need to fix default window size for rescorers so that they are applied")
-    // NORELEASE
     public void testSmallRescoreWindow() throws Exception {
         Builder builder = Settings.builder();
         builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
@@ -301,8 +286,6 @@ public class QueryRescorerIT extends ESIntegTestCase {
 
     // Tests a rescorer that penalizes the scores:
     @Test
-    @AwaitsFix(bugUrl = "Need to fix default window size for rescorers so that they are applied")
-    // NORELEASE
     public void testRescorerMadeScoresWorse() throws Exception {
         Builder builder = Settings.builder();
         builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
@@ -448,7 +431,7 @@ public class QueryRescorerIT extends ESIntegTestCase {
                     .setPreference("test") // ensure we hit the same shards for tie-breaking
                     .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR)).setFrom(0).setSize(resultSize)
                     .execute().actionGet();
-
+            
             // check equivalence
             assertEquivalent(query, plain, rescored);
 
@@ -604,15 +587,12 @@ public class QueryRescorerIT extends ESIntegTestCase {
                         .queryRescorer(
                                 QueryBuilders.boolQuery()
                                         .disableCoord(true)
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]))
-                                                .boostMode(CombineFunction.REPLACE)
-                                                .add(ScoreFunctionBuilders.scriptFunction(new Script("5.0f"))))
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]))
-                                                .boostMode(CombineFunction.REPLACE)
-                                                .add(ScoreFunctionBuilders.scriptFunction(new Script("7.0f"))))
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]))
-                                                .boostMode(CombineFunction.REPLACE)
-                                                .add(ScoreFunctionBuilders.scriptFunction(new Script("0.0f")))))
+                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]),
+                                                ScoreFunctionBuilders.scriptFunction(new Script("5.0f"))).boostMode(CombineFunction.REPLACE))
+                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]),
+                                                ScoreFunctionBuilders.scriptFunction(new Script("7.0f"))).boostMode(CombineFunction.REPLACE))
+                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]),
+                                                ScoreFunctionBuilders.scriptFunction(new Script("0.0f"))).boostMode(CombineFunction.REPLACE)))
                         .setQueryWeight(primaryWeight)
                         .setRescoreQueryWeight(secondaryWeight);
 
@@ -625,22 +605,18 @@ public class QueryRescorerIT extends ESIntegTestCase {
                         .setPreference("test") // ensure we hit the same shards for tie-breaking
                         .setQuery(QueryBuilders.boolQuery()
                                 .disableCoord(true)
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]))
-                                                .boostMode(CombineFunction.REPLACE)
-                                                .add(ScoreFunctionBuilders.scriptFunction(new Script("2.0f"))))
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]))
-                                                .boostMode(CombineFunction.REPLACE)
-                                                .add(ScoreFunctionBuilders.scriptFunction(new Script("3.0f"))))
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[2]))
-                                                .boostMode(CombineFunction.REPLACE)
-                                                .add(ScoreFunctionBuilders.scriptFunction(new Script("5.0f"))))
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]))
-                                                .boostMode(CombineFunction.REPLACE)
-                                                .add(ScoreFunctionBuilders.scriptFunction(new Script("0.2f")))))
-                        .setFrom(0)
-                        .setSize(10)
-                        .setRescorer(rescoreQuery)
-                        .setRescoreWindow(50).execute().actionGet();
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]),
+                                        ScoreFunctionBuilders.scriptFunction(new Script("2.0f"))).boostMode(CombineFunction.REPLACE))
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]),
+                                        ScoreFunctionBuilders.scriptFunction(new Script("3.0f"))).boostMode(CombineFunction.REPLACE))
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[2]),
+                                        ScoreFunctionBuilders.scriptFunction(new Script("5.0f"))).boostMode(CombineFunction.REPLACE))
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]),
+                                        ScoreFunctionBuilders.scriptFunction(new Script("0.2f"))).boostMode(CombineFunction.REPLACE)))
+                                .setFrom(0)
+                                .setSize(10)
+                                .setRescorer(rescoreQuery)
+                                .setRescoreWindow(50).execute().actionGet();
 
                 assertHitCount(rescored, 4);
 
@@ -690,17 +666,14 @@ public class QueryRescorerIT extends ESIntegTestCase {
     }
 
     @Test
-    @AwaitsFix(bugUrl = "Need to fix default window size for rescorers so that they are applied")
-    // NORELEASE
     public void testMultipleRescores() throws Exception {
         int numDocs = indexRandomNumbers("keyword", 1, true);
         QueryRescorer eightIsGreat = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(8)))
-                        .boostMode(CombineFunction.REPLACE).add(ScoreFunctionBuilders.scriptFunction(new Script("1000.0f")))).setScoreMode(
-                "total");
+                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(8)),
+                        ScoreFunctionBuilders.scriptFunction(new Script("1000.0f"))).boostMode(CombineFunction.REPLACE)).setScoreMode("total");
         QueryRescorer sevenIsBetter = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(7)))
-                        .boostMode(CombineFunction.REPLACE).add(ScoreFunctionBuilders.scriptFunction(new Script("10000.0f"))))
+                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(7)),
+                        ScoreFunctionBuilders.scriptFunction(new Script("10000.0f"))).boostMode(CombineFunction.REPLACE))
                 .setScoreMode("total");
 
         // First set the rescore window large enough that both rescores take effect
@@ -717,11 +690,11 @@ public class QueryRescorerIT extends ESIntegTestCase {
 
         // Now use one rescore to drag the number we're looking for into the window of another
         QueryRescorer ninetyIsGood = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*ninety*")).boostMode(CombineFunction.REPLACE)
-                        .add(ScoreFunctionBuilders.scriptFunction(new Script("1000.0f")))).setScoreMode("total");
+                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*ninety*"), ScoreFunctionBuilders.scriptFunction(new Script("1000.0f")))
+                        .boostMode(CombineFunction.REPLACE)).setScoreMode("total");
         QueryRescorer oneToo = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*one*")).boostMode(CombineFunction.REPLACE)
-                        .add(ScoreFunctionBuilders.scriptFunction(new Script("1000.0f")))).setScoreMode("total");
+                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*one*"), ScoreFunctionBuilders.scriptFunction(new Script("1000.0f")))
+                        .boostMode(CombineFunction.REPLACE)).setScoreMode("total");
         request.clearRescorers().addRescorer(ninetyIsGood).addRescorer(oneToo, 10);
         response = request.setSize(2).get();
         assertFirstHit(response, hasId("91"));
diff --git a/core/src/test/java/org/elasticsearch/search/sort/SimpleSortIT.java b/core/src/test/java/org/elasticsearch/search/sort/SimpleSortIT.java
index 21468a0..e487819 100644
--- a/core/src/test/java/org/elasticsearch/search/sort/SimpleSortIT.java
+++ b/core/src/test/java/org/elasticsearch/search/sort/SimpleSortIT.java
@@ -1908,11 +1908,10 @@ public class SimpleSortIT extends ESIntegTestCase {
         searchSourceBuilder.endArray();
         searchSourceBuilder.endObject();
 
-//        searchResponse = client().prepareSearch().setSource(searchSourceBuilder.bytes()).execute().actionGet();
-//        assertOrderedSearchHits(searchResponse, "d1", "d2");
-//        assertThat((Double) searchResponse.getHits().getAt(0).getSortValues()[0], closeTo(GeoDistance.PLANE.calculate(2.5, 1, 2, 1, DistanceUnit.KILOMETERS), 1.e-4));
-//        assertThat((Double) searchResponse.getHits().getAt(1).getSortValues()[0], closeTo(GeoDistance.PLANE.calculate(4.5, 1, 2, 1, DistanceUnit.KILOMETERS), 1.e-4));
-        // NOCOMMIT fix this
+        searchResponse = client().prepareSearch().setSource(searchSourceBuilder.bytes()).execute().actionGet();
+        assertOrderedSearchHits(searchResponse, "d1", "d2");
+        assertThat((Double) searchResponse.getHits().getAt(0).getSortValues()[0], closeTo(GeoDistance.PLANE.calculate(2.5, 1, 2, 1, DistanceUnit.KILOMETERS), 1.e-4));
+        assertThat((Double) searchResponse.getHits().getAt(1).getSortValues()[0], closeTo(GeoDistance.PLANE.calculate(4.5, 1, 2, 1, DistanceUnit.KILOMETERS), 1.e-4));
     }
 
     public void testSinglePointGeoDistanceSort() throws ExecutionException, InterruptedException, IOException {
@@ -1951,41 +1950,41 @@ public class SimpleSortIT extends ESIntegTestCase {
                 .execute().actionGet();
         checkCorrectSortOrderForGeoSort(searchResponse);
 
-//        String geoSortRequest = jsonBuilder().startObject().startArray("sort").startObject()
-//                .startObject("_geo_distance")
-//                .startArray("location").value(2f).value(2f).endArray()
-//                .field("unit", "km")
-//                .field("distance_type", "plane")
-//                .endObject()
-//                .endObject().endArray().string();
-//        searchResponse = client().prepareSearch().setSource(new BytesArray(geoSortRequest))
-//                .execute().actionGet();
-//        checkCorrectSortOrderForGeoSort(searchResponse);
-//
-//        geoSortRequest = jsonBuilder().startObject().startArray("sort").startObject()
-//                .startObject("_geo_distance")
-//                .field("location", "s037ms06g7h0")
-//                .field("unit", "km")
-//                .field("distance_type", "plane")
-//                .endObject()
-//                .endObject().endArray().string();
-//        searchResponse = client().prepareSearch().setSource(new BytesArray(geoSortRequest))
-//                .execute().actionGet();
-//        checkCorrectSortOrderForGeoSort(searchResponse);
-//
-//        geoSortRequest = jsonBuilder().startObject().startArray("sort").startObject()
-//                .startObject("_geo_distance")
-//                .startObject("location")
-//                .field("lat", 2)
-//                .field("lon", 2)
-//                .endObject()
-//                .field("unit", "km")
-//                .field("distance_type", "plane")
-//                .endObject()
-//                .endObject().endArray().string();
-//        searchResponse = client().prepareSearch().setSource(new BytesArray(geoSortRequest))
-//                .execute().actionGet();
-//        checkCorrectSortOrderForGeoSort(searchResponse); NOCOMMIT fix this
+        String geoSortRequest = jsonBuilder().startObject().startArray("sort").startObject()
+                .startObject("_geo_distance")
+                .startArray("location").value(2f).value(2f).endArray()
+                .field("unit", "km")
+                .field("distance_type", "plane")
+                .endObject()
+                .endObject().endArray().string();
+        searchResponse = client().prepareSearch().setSource(new BytesArray(geoSortRequest))
+                .execute().actionGet();
+        checkCorrectSortOrderForGeoSort(searchResponse);
+
+        geoSortRequest = jsonBuilder().startObject().startArray("sort").startObject()
+                .startObject("_geo_distance")
+                .field("location", "s037ms06g7h0")
+                .field("unit", "km")
+                .field("distance_type", "plane")
+                .endObject()
+                .endObject().endArray().string();
+        searchResponse = client().prepareSearch().setSource(new BytesArray(geoSortRequest))
+                .execute().actionGet();
+        checkCorrectSortOrderForGeoSort(searchResponse);
+
+        geoSortRequest = jsonBuilder().startObject().startArray("sort").startObject()
+                .startObject("_geo_distance")
+                .startObject("location")
+                .field("lat", 2)
+                .field("lon", 2)
+                .endObject()
+                .field("unit", "km")
+                .field("distance_type", "plane")
+                .endObject()
+                .endObject().endArray().string();
+        searchResponse = client().prepareSearch().setSource(new BytesArray(geoSortRequest))
+                .execute().actionGet();
+        checkCorrectSortOrderForGeoSort(searchResponse);
     }
 
     private void checkCorrectSortOrderForGeoSort(SearchResponse searchResponse) {
diff --git a/core/src/test/java/org/elasticsearch/search/stats/SearchStatsIT.java b/core/src/test/java/org/elasticsearch/search/stats/SearchStatsIT.java
index c1e54f9..be9bfde 100644
--- a/core/src/test/java/org/elasticsearch/search/stats/SearchStatsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/stats/SearchStatsIT.java
@@ -32,7 +32,6 @@ import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.search.stats.SearchStats.Stats;
 import org.elasticsearch.script.Script;
-import org.elasticsearch.search.highlight.HighlightBuilder;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
@@ -101,7 +100,7 @@ public class SearchStatsIT extends ESIntegTestCase {
         for (int i = 0; i < iters; i++) {
             SearchResponse searchResponse = internalCluster().clientNodeClient().prepareSearch()
                     .setQuery(QueryBuilders.termQuery("field", "value")).setStats("group1", "group2")
-                    .highlighter(new HighlightBuilder().field("field"))
+                    .addHighlightedField("field")
                     .addScriptField("scrip1", new Script("_source.field"))
                     .setSize(100)
                     .execute().actionGet();
@@ -138,9 +137,9 @@ public class SearchStatsIT extends ESIntegTestCase {
                 assertThat(total.getQueryTimeInMillis(), equalTo(0l));
             }
         }
-
+        
         assertThat(num, greaterThan(0));
-
+     
     }
 
     private Set<String> nodeIdsWithIndex(String... indices) {
diff --git a/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterSearchIT.java b/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterSearchIT.java
index df04d43..9b97afc 100644
--- a/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/suggest/CustomSuggesterSearchIT.java
@@ -20,12 +20,13 @@ package org.elasticsearch.search.suggest;
 
 import org.elasticsearch.action.search.SearchRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.util.CollectionUtils;
+import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
-import org.elasticsearch.test.ESIntegTestCase.Scope;
 import org.junit.Test;
 
 import java.io.IOException;
@@ -34,6 +35,7 @@ import java.util.List;
 import java.util.Locale;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
+import static org.elasticsearch.test.ESIntegTestCase.Scope;
 import static org.hamcrest.Matchers.hasSize;
 import static org.hamcrest.Matchers.is;
 
@@ -57,12 +59,11 @@ public class CustomSuggesterSearchIT extends ESIntegTestCase {
                 .endObject())
                 .setRefresh(true).execute().actionGet();
         ensureYellow();
-
+        
         String randomText = randomAsciiOfLength(10);
         String randomField = randomAsciiOfLength(10);
         String randomSuffix = randomAsciiOfLength(10);
-        SuggestBuilder suggestBuilder = new SuggestBuilder();
-        suggestBuilder.addSuggestion(
+        SearchRequestBuilder searchRequestBuilder = client().prepareSearch("test").setTypes("test").setFrom(0).setSize(1).addSuggestion(
                 new SuggestBuilder.SuggestionBuilder<SuggestBuilder.SuggestionBuilder>("someName", "custom") {
                     @Override
                     protected XContentBuilder innerToXContent(XContentBuilder builder, Params params) throws IOException {
@@ -72,8 +73,6 @@ public class CustomSuggesterSearchIT extends ESIntegTestCase {
                     }
                 }.text(randomText)
         );
-        SearchRequestBuilder searchRequestBuilder = client().prepareSearch("test").setTypes("test").setFrom(0).setSize(1)
-                .suggest(suggestBuilder);
 
         SearchResponse searchResponse = searchRequestBuilder.execute().actionGet();
 
diff --git a/core/src/test/java/org/elasticsearch/search/suggest/SuggestSearchIT.java b/core/src/test/java/org/elasticsearch/search/suggest/SuggestSearchIT.java
index 5e03a22..e55a736 100644
--- a/core/src/test/java/org/elasticsearch/search/suggest/SuggestSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/suggest/SuggestSearchIT.java
@@ -19,16 +19,12 @@
 
 package org.elasticsearch.search.suggest;
 
+import java.nio.charset.StandardCharsets;
 import com.google.common.io.Resources;
-
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
 import org.elasticsearch.action.index.IndexRequestBuilder;
-import org.elasticsearch.action.search.ReduceSearchPhaseException;
-import org.elasticsearch.action.search.SearchPhaseExecutionException;
-import org.elasticsearch.action.search.SearchRequestBuilder;
-import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.action.search.ShardSearchFailure;
+import org.elasticsearch.action.search.*;
 import org.elasticsearch.action.suggest.SuggestRequestBuilder;
 import org.elasticsearch.action.suggest.SuggestResponse;
 import org.elasticsearch.common.xcontent.XContentBuilder;
@@ -42,13 +38,7 @@ import org.elasticsearch.test.hamcrest.ElasticsearchAssertions;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.nio.charset.StandardCharsets;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 import java.util.concurrent.ExecutionException;
 
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
@@ -58,17 +48,8 @@ import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
 import static org.elasticsearch.search.suggest.SuggestBuilders.phraseSuggestion;
 import static org.elasticsearch.search.suggest.SuggestBuilders.termSuggestion;
 import static org.elasticsearch.search.suggest.phrase.PhraseSuggestionBuilder.candidateGenerator;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSuggestion;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSuggestionPhraseCollateMatchExists;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSuggestionSize;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertThrows;
-import static org.hamcrest.Matchers.anyOf;
-import static org.hamcrest.Matchers.endsWith;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.nullValue;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
 
 /**
  * Integration tests for term and phrase suggestions.  Many of these tests many requests that vary only slightly from one another.  Where
@@ -178,7 +159,7 @@ public class SuggestSearchIT extends ESIntegTestCase {
                 .put("index.analysis.filter.shingler.type", "shingle")
                 .put("index.analysis.filter.shingler.min_shingle_size", 2)
                 .put("index.analysis.filter.shingler.max_shingle_size", 3));
-
+        
         XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1")
                 .startObject("properties")
                 .startObject("name")
@@ -198,7 +179,7 @@ public class SuggestSearchIT extends ESIntegTestCase {
                 .endObject().endObject();
         assertAcked(builder.addMapping("type1", mapping));
         ensureGreen();
-
+        
 
         index("test", "type1", "1", "name", "I like iced tea");
         index("test", "type1", "2", "name", "I like tea.");
@@ -216,7 +197,7 @@ public class SuggestSearchIT extends ESIntegTestCase {
         searchSuggest = searchSuggest( "ice tea", phraseSuggestion);
         assertSuggestionSize(searchSuggest, 0, 0, "did_you_mean");
     }
-
+    
     @Test // see #2729
     public void testSizeOneShard() throws Exception {
         prepareCreate("test").setSettings(
@@ -231,7 +212,7 @@ public class SuggestSearchIT extends ESIntegTestCase {
 
         SearchResponse search = client().prepareSearch().setQuery(matchQuery("text", "spellchecker")).get();
         assertThat("didn't ask for suggestions but got some", search.getSuggest(), nullValue());
-
+        
         TermSuggestionBuilder termSuggestion = termSuggestion("test")
                 .suggestMode("always") // Always, otherwise the results can vary between requests.
                 .text("abcd")
@@ -244,7 +225,7 @@ public class SuggestSearchIT extends ESIntegTestCase {
         suggest = searchSuggest( termSuggestion);
         assertSuggestion(suggest, 0, "test", 5, "abc0");
     }
-
+    
     @Test
     public void testUnmappedField() throws IOException, InterruptedException, ExecutionException {
         CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
@@ -287,14 +268,16 @@ public class SuggestSearchIT extends ESIntegTestCase {
 
         phraseSuggestion.field("nosuchField");
         {
-            SearchRequestBuilder searchBuilder = client().prepareSearch().setSize(0);
-            searchBuilder.suggest(new SuggestBuilder().setText("tetsting sugestion").addSuggestion(phraseSuggestion));
-            assertThrows(searchBuilder, SearchPhaseExecutionException.class);
+            SearchRequestBuilder suggestBuilder = client().prepareSearch().setSize(0);
+            suggestBuilder.setSuggestText("tetsting sugestion");
+            suggestBuilder.addSuggestion(phraseSuggestion);
+            assertThrows(suggestBuilder, SearchPhaseExecutionException.class);
         }
         {
-            SearchRequestBuilder searchBuilder = client().prepareSearch().setSize(0);
-            searchBuilder.suggest(new SuggestBuilder().setText("tetsting sugestion").addSuggestion(phraseSuggestion));
-            assertThrows(searchBuilder, SearchPhaseExecutionException.class);
+            SearchRequestBuilder suggestBuilder = client().prepareSearch().setSize(0);
+            suggestBuilder.setSuggestText("tetsting sugestion");
+            suggestBuilder.addSuggestion(phraseSuggestion);
+            assertThrows(suggestBuilder, SearchPhaseExecutionException.class);
         }
     }
 
@@ -308,10 +291,10 @@ public class SuggestSearchIT extends ESIntegTestCase {
         index("test", "type1", "3", "text", "abbd");
         index("test", "type1", "4", "text", "abcc");
         refresh();
-
+        
         SearchResponse search = client().prepareSearch().setQuery(matchQuery("text", "spellcecker")).get();
         assertThat("didn't ask for suggestions but got some", search.getSuggest(), nullValue());
-
+        
         TermSuggestionBuilder termSuggest = termSuggestion("test")
                 .suggestMode("always") // Always, otherwise the results can vary between requests.
                 .text("abcd")
@@ -423,7 +406,7 @@ public class SuggestSearchIT extends ESIntegTestCase {
         // assertThat(suggest.get(3).getSuggestedWords().get("prefix_abcd").get(4).getTerm(), equalTo("prefix_abcc"));
         // assertThat(suggest.get(3).getSuggestedWords().get("prefix_abcd").get(4).getTerm(), equalTo("prefix_accd"));
     }
-
+    
     @Test // see #2817
     public void testStopwordsOnlyPhraseSuggest() throws IOException {
         assertAcked(prepareCreate("test").addMapping("typ1", "body", "type=string,analyzer=stopwd").setSettings(
@@ -441,7 +424,7 @@ public class SuggestSearchIT extends ESIntegTestCase {
                         .size(1));
         assertSuggestionSize(searchSuggest, 0, 0, "simple_phrase");
     }
-
+    
     @Test
     public void testPrefixLength() throws IOException {  // Stopped here
         CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
@@ -477,14 +460,14 @@ public class SuggestSearchIT extends ESIntegTestCase {
                         .addCandidateGenerator(PhraseSuggestionBuilder.candidateGenerator("body").prefixLength(4).minWordLength(1).suggestMode("always"))
                         .size(1).confidence(1.0f));
         assertSuggestion(searchSuggest, 0, "simple_phrase", "hello words");
-
+        
         searchSuggest = searchSuggest( "hello word",
                 phraseSuggestion("simple_phrase").field("body")
                         .addCandidateGenerator(PhraseSuggestionBuilder.candidateGenerator("body").prefixLength(2).minWordLength(1).suggestMode("always"))
                         .size(1).confidence(1.0f));
         assertSuggestion(searchSuggest, 0, "simple_phrase", "hello world");
     }
-
+    
     @Test
     @Nightly
     public void testMarvelHerosPhraseSuggest() throws IOException {
@@ -589,7 +572,7 @@ public class SuggestSearchIT extends ESIntegTestCase {
 
         searchSuggest = searchSuggest( "american ame", phraseSuggest);
         assertSuggestion(searchSuggest, 0, "simple_phrase", "american ace");
-
+        
         // try all smoothing methods
         phraseSuggest.smoothingModel(new PhraseSuggestionBuilder.LinearInterpolation(0.4,0.4,0.2));
         searchSuggest = searchSuggest( "Xor the Got-Jewel", phraseSuggest);
@@ -614,7 +597,7 @@ public class SuggestSearchIT extends ESIntegTestCase {
         // Check the name this time because we're repeating it which is funky
         assertThat(searchSuggest.getSuggestion("simple_phrase").getEntries().get(0).getText().string(), equalTo("Xor the Got-Jewel Xor the Got-Jewel Xor the Got-Jewel"));
     }
-
+    
     @Test
     public void testSizePararm() throws IOException {
         CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
@@ -629,7 +612,7 @@ public class SuggestSearchIT extends ESIntegTestCase {
                 .put("index.analysis.filter.my_shingle.output_unigrams", false)
                 .put("index.analysis.filter.my_shingle.min_shingle_size", 2)
                 .put("index.analysis.filter.my_shingle.max_shingle_size", 2));
-
+        
         XContentBuilder mapping = XContentFactory.jsonBuilder()
                 .startObject()
                     .startObject("type1")
@@ -702,7 +685,7 @@ public class SuggestSearchIT extends ESIntegTestCase {
                 .put("index.analysis.filter.my_shingle2.output_unigrams", true)
                 .put("index.analysis.filter.my_shingle2.min_shingle_size", 2)
                 .put("index.analysis.filter.my_shingle2.max_shingle_size", 2));
-
+        
         XContentBuilder mapping = XContentFactory.jsonBuilder()
                     .startObject().startObject("type1")
                     .startObject("_all").field("store", "yes").field("termVector", "with_positions_offsets").endObject()
@@ -828,16 +811,14 @@ public class SuggestSearchIT extends ESIntegTestCase {
 
         // When searching on a shard with a non existing mapping, we should fail
         SearchRequestBuilder request = client().prepareSearch().setSize(0)
-                .suggest(
-                        new SuggestBuilder().setText("tetsting sugestion").addSuggestion(
-                                phraseSuggestion("did_you_mean").field("fielddoesnotexist").maxErrors(5.0f)));
+            .setSuggestText("tetsting sugestion")
+            .addSuggestion(phraseSuggestion("did_you_mean").field("fielddoesnotexist").maxErrors(5.0f));
         assertThrows(request, SearchPhaseExecutionException.class);
 
         // When searching on a shard which does not hold yet any document of an existing type, we should not fail
         SearchResponse searchResponse = client().prepareSearch().setSize(0)
-                .suggest(
-                        new SuggestBuilder().setText("tetsting sugestion").addSuggestion(
-                                phraseSuggestion("did_you_mean").field("name").maxErrors(5.0f)))
+            .setSuggestText("tetsting sugestion")
+            .addSuggestion(phraseSuggestion("did_you_mean").field("name").maxErrors(5.0f))
             .get();
         ElasticsearchAssertions.assertNoFailures(searchResponse);
         ElasticsearchAssertions.assertSuggestion(searchResponse.getSuggest(), 0, 0, "did_you_mean", "testing suggestions");
@@ -879,9 +860,8 @@ public class SuggestSearchIT extends ESIntegTestCase {
 
         SearchResponse searchResponse = client().prepareSearch()
                 .setSize(0)
-                .suggest(
-                        new SuggestBuilder().setText("tetsting sugestion").addSuggestion(
-                                phraseSuggestion("did_you_mean").field("name").maxErrors(5.0f)))
+                .setSuggestText("tetsting sugestion")
+                .addSuggestion(phraseSuggestion("did_you_mean").field("name").maxErrors(5.0f))
                 .get();
 
         assertNoFailures(searchResponse);
@@ -1272,14 +1252,12 @@ public class SuggestSearchIT extends ESIntegTestCase {
     protected Suggest searchSuggest(String suggestText, int expectShardsFailed, SuggestionBuilder<?>... suggestions) {
         if (randomBoolean()) {
             SearchRequestBuilder builder = client().prepareSearch().setSize(0);
-            SuggestBuilder suggestBuilder = new SuggestBuilder();
             if (suggestText != null) {
-                suggestBuilder.setText(suggestText);
+                builder.setSuggestText(suggestText);
             }
             for (SuggestionBuilder<?> suggestion : suggestions) {
-                suggestBuilder.addSuggestion(suggestion);
+                builder.addSuggestion(suggestion);
             }
-            builder.suggest(suggestBuilder);
             SearchResponse actionGet = builder.execute().actionGet();
             assertThat(Arrays.toString(actionGet.getShardFailures()), actionGet.getFailedShards(), equalTo(expectShardsFailed));
             return actionGet.getSuggest();
diff --git a/core/src/test/java/org/elasticsearch/search/timeout/SearchTimeoutIT.java b/core/src/test/java/org/elasticsearch/search/timeout/SearchTimeoutIT.java
index 5a16d74..6197224 100644
--- a/core/src/test/java/org/elasticsearch/search/timeout/SearchTimeoutIT.java
+++ b/core/src/test/java/org/elasticsearch/search/timeout/SearchTimeoutIT.java
@@ -21,13 +21,11 @@ package org.elasticsearch.search.timeout;
 
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
-import java.util.concurrent.TimeUnit;
-
+import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
 import static org.elasticsearch.index.query.QueryBuilders.scriptQuery;
 import static org.hamcrest.Matchers.equalTo;
 
@@ -46,7 +44,7 @@ public class SearchTimeoutIT extends ESIntegTestCase {
         client().prepareIndex("test", "type", "1").setSource("field", "value").setRefresh(true).execute().actionGet();
 
         SearchResponse searchResponse = client().prepareSearch("test")
-                .setTimeout(new TimeValue(10, TimeUnit.MILLISECONDS))
+                .setTimeout("10ms")
                 .setQuery(scriptQuery(new Script("Thread.sleep(500); return true;")))
                 .execute().actionGet();
         assertThat(searchResponse.isTimedOut(), equalTo(true));
diff --git a/core/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java b/core/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java
index 9c24a11..5772543 100644
--- a/core/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java
+++ b/core/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java
@@ -53,8 +53,6 @@ import org.elasticsearch.cluster.metadata.IndexTemplateMetaData;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
-import org.elasticsearch.common.io.stream.NamedWriteableAwareStreamInput;
-import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.io.stream.Streamable;
@@ -84,7 +82,13 @@ import java.util.function.Function;
 import java.util.function.Predicate;
 import java.util.stream.Collectors;
 
-import static org.apache.lucene.util.LuceneTestCase.random;
+import static org.elasticsearch.test.ESTestCase.assertArrayEquals;
+import static org.elasticsearch.test.ESTestCase.assertEquals;
+import static org.elasticsearch.test.ESTestCase.assertFalse;
+import static org.elasticsearch.test.ESTestCase.assertNotNull;
+import static org.elasticsearch.test.ESTestCase.assertTrue;
+import static org.elasticsearch.test.ESTestCase.fail;
+import static org.elasticsearch.test.ESTestCase.random;
 import static org.elasticsearch.test.VersionUtils.randomVersion;
 import static org.hamcrest.CoreMatchers.equalTo;
 import static org.hamcrest.CoreMatchers.is;
@@ -98,12 +102,6 @@ import static org.hamcrest.Matchers.instanceOf;
 import static org.hamcrest.Matchers.not;
 import static org.hamcrest.Matchers.notNullValue;
 import static org.hamcrest.Matchers.nullValue;
-import static org.junit.Assert.assertArrayEquals;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
 
 /**
  *
@@ -665,10 +663,6 @@ public class ElasticsearchAssertions {
     }
 
     public static void assertVersionSerializable(Version version, Streamable streamable) {
-        assertVersionSerializable(version, streamable, null);
-    }
-
-    public static void assertVersionSerializable(Version version, Streamable streamable, NamedWriteableRegistry namedWriteableRegistry) {
         try {
             Streamable newInstance = tryCreateNewInstance(streamable);
             if (newInstance == null) {
@@ -680,15 +674,10 @@ public class ElasticsearchAssertions {
             }
             BytesReference orig = serialize(version, streamable);
             StreamInput input = StreamInput.wrap(orig);
-            if (namedWriteableRegistry != null) {
-                input = new NamedWriteableAwareStreamInput(input, namedWriteableRegistry);
-            }
             input.setVersion(version);
             newInstance.readFrom(input);
-            assertThat("Stream should be fully read with version [" + version + "] for streamable [" + streamable + "]", input.available(),
-                    equalTo(0));
-            assertThat("Serialization failed with version [" + version + "] bytes should be equal for streamable [" + streamable + "]",
-                    serialize(version, streamable), equalTo(orig));
+            assertThat("Stream should be fully read with version [" + version + "] for streamable [" + streamable + "]", input.available(), equalTo(0));
+            assertThat("Serialization failed with version [" + version + "] bytes should be equal for streamable [" + streamable + "]", serialize(version, streamable), equalTo(orig));
         } catch (Throwable ex) {
             throw new RuntimeException("failed to check serialization - version [" + version + "] for streamable [" + streamable + "]", ex);
         }
diff --git a/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java b/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
index 64cc401..c253a75 100644
--- a/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
+++ b/core/src/test/java/org/elasticsearch/test/transport/AssertingLocalTransport.java
@@ -77,15 +77,13 @@ public class AssertingLocalTransport extends LocalTransport {
 
     @Override
     protected void handleParsedResponse(final TransportResponse response, final TransportResponseHandler handler) {
-        ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersionBetween(random, minVersion, maxVersion), response,
-                namedWriteableRegistry);
+        ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersionBetween(random, minVersion, maxVersion), response);
         super.handleParsedResponse(response, handler);
     }
 
     @Override
     public void sendRequest(final DiscoveryNode node, final long requestId, final String action, final TransportRequest request, TransportRequestOptions options) throws IOException, TransportException {
-        ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersionBetween(random, minVersion, maxVersion), request,
-                namedWriteableRegistry);
+        ElasticsearchAssertions.assertVersionSerializable(VersionUtils.randomVersionBetween(random, minVersion, maxVersion), request);
         super.sendRequest(node, requestId, action, request, options);
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
index 09ab73b..abd0a06 100644
--- a/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
+++ b/core/src/test/java/org/elasticsearch/transport/ContextAndHeaderTransportIT.java
@@ -45,7 +45,6 @@ import org.elasticsearch.client.FilterClient;
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.Module;
-import org.elasticsearch.common.lucene.search.function.CombineFunction;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
@@ -56,7 +55,6 @@ import org.elasticsearch.index.query.MoreLikeThisQueryBuilder;
 import org.elasticsearch.index.query.MoreLikeThisQueryBuilder.Item;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.query.TermsQueryBuilder;
-import org.elasticsearch.index.query.functionscore.script.ScriptScoreFunctionBuilder;
 import org.elasticsearch.indices.cache.query.terms.TermsLookup;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.rest.RestController;
@@ -67,9 +65,7 @@ import org.elasticsearch.script.groovy.GroovyScriptEngineService;
 import org.elasticsearch.script.mustache.MustacheScriptEngineService;
 import org.elasticsearch.search.aggregations.AggregationBuilders;
 import org.elasticsearch.search.aggregations.pipeline.PipelineAggregatorBuilders;
-import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.search.suggest.Suggest;
-import org.elasticsearch.search.suggest.SuggestBuilder;
 import org.elasticsearch.search.suggest.phrase.PhraseSuggestionBuilder;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
@@ -233,8 +229,8 @@ public class ContextAndHeaderTransportIT extends ESIntegTestCase {
                 .get();
         transportClient().admin().indices().prepareRefresh(lookupIndex, queryIndex).get();
 
-        MoreLikeThisQueryBuilder moreLikeThisQueryBuilder = QueryBuilders.moreLikeThisQuery("name")
-                .like(new Item(lookupIndex, "type", "1"))
+        MoreLikeThisQueryBuilder moreLikeThisQueryBuilder = QueryBuilders.moreLikeThisQuery(new String[] {"name"}, null,
+                new Item[] {new Item(lookupIndex, "type", "1")})
                 .minTermFreq(1)
                 .minDocFreq(1);
 
@@ -277,11 +273,14 @@ public class ContextAndHeaderTransportIT extends ESIntegTestCase {
                 .get();
         transportClient().admin().indices().prepareRefresh(queryIndex).get();
 
+        // custom content, not sure how to specify "script_id" otherwise in the API
+        XContentBuilder builder = jsonBuilder().startObject().startObject("function_score").field("boost_mode", "replace").startArray("functions")
+                .startObject().startObject("script_score").field("script_id", "my_script").field("lang", "groovy").endObject().endObject().endArray().endObject().endObject();
+
         SearchResponse searchResponse = transportClient()
                 .prepareSearch(queryIndex)
-                .setQuery(
-                        QueryBuilders.functionScoreQuery().boostMode(CombineFunction.REPLACE)
-                                .add(new ScriptScoreFunctionBuilder(new Script("my_script", ScriptType.INDEXED, "groovy", null)))).get();
+                .setQuery(builder)
+                .get();
         assertNoFailures(searchResponse);
         assertHitCount(searchResponse, 1);
         assertThat(searchResponse.getHits().getMaxScore(), is(10.0f));
@@ -443,13 +442,11 @@ public class ContextAndHeaderTransportIT extends ESIntegTestCase {
                 MustacheScriptEngineService.NAME, null, null));
 
         SearchRequestBuilder searchRequestBuilder = transportClient().prepareSearch("test").setSize(0);
-        SuggestBuilder suggestBuilder = new SuggestBuilder();
         String suggestText = "united states house of representatives elections in washington 2006";
         if (suggestText != null) {
-            suggestBuilder.setText(suggestText);
+            searchRequestBuilder.setSuggestText(suggestText);
         }
-        suggestBuilder.addSuggestion(filteredFilterSuggest);
-        searchRequestBuilder.suggest(suggestBuilder);
+        searchRequestBuilder.addSuggestion(filteredFilterSuggest);
         SearchResponse actionGet = searchRequestBuilder.execute().actionGet();
         assertThat(Arrays.toString(actionGet.getShardFailures()), actionGet.getFailedShards(), equalTo(0));
         Suggest searchSuggest = actionGet.getSuggest();
diff --git a/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java b/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
index 505d416..22c959f 100644
--- a/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
+++ b/core/src/test/java/org/elasticsearch/validate/SimpleValidateQueryIT.java
@@ -19,7 +19,6 @@
 package org.elasticsearch.validate;
 
 import java.nio.charset.StandardCharsets;
-
 import org.elasticsearch.action.admin.indices.alias.Alias;
 import org.elasticsearch.action.admin.indices.validate.query.ValidateQueryResponse;
 import org.elasticsearch.client.Client;
@@ -28,6 +27,7 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.index.IndexNotFoundException;
+import org.elasticsearch.index.query.MoreLikeThisQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.test.ESIntegTestCase;
@@ -250,10 +250,10 @@ public class SimpleValidateQueryIT extends ESIntegTestCase {
                 containsString("field:jumps^0.75"), true);
 
         // more like this queries
-        assertExplanation(QueryBuilders.moreLikeThisQuery("field").ids("1")
+        assertExplanation(QueryBuilders.moreLikeThisQuery(new String[] { "field" }, null, MoreLikeThisQueryBuilder.ids("1"))
                         .include(true).minTermFreq(1).minDocFreq(1).maxQueryTerms(2),
                 containsString("field:huge field:pidgin"), true);
-        assertExplanation(QueryBuilders.moreLikeThisQuery("field").like("the huge pidgin")
+        assertExplanation(QueryBuilders.moreLikeThisQuery(new String[] { "field" }, new String[] {"the huge pidgin"}, null)
                         .minTermFreq(1).minDocFreq(1).maxQueryTerms(2),
                 containsString("field:huge field:pidgin"), true);
     }
diff --git a/core/src/test/resources/org/elasticsearch/action/search/simple-msearch1.json b/core/src/test/resources/org/elasticsearch/action/search/simple-msearch1.json
index eefec53..3d98f37 100644
--- a/core/src/test/resources/org/elasticsearch/action/search/simple-msearch1.json
+++ b/core/src/test/resources/org/elasticsearch/action/search/simple-msearch1.json
@@ -1,16 +1,16 @@
 {"index":"test", "ignore_unavailable" : true, "expand_wildcards" : "open,closed"}}
-{"query" : {"match_all" :{}}}
+{"query" : {"match_all" {}}}
 {"index" : "test", "type" : "type1", "expand_wildcards" : ["open", "closed"]}
-{"query" : {"match_all" :{}}}
+{"query" : {"match_all" {}}}
 {"index":"test", "ignore_unavailable" : false, "expand_wildcards" : ["open"]}}
-{"query" : {"match_all" :{}}}
+{"query" : {"match_all" {}}}
 {"index":"test", "ignore_unavailable" : true, "allow_no_indices": true, "expand_wildcards" : ["open", "closed"]}}
-{"query" : {"match_all" :{}}}
+{"query" : {"match_all" {}}}
 {"index":"test", "ignore_unavailable" : true, "allow_no_indices": false, "expand_wildcards" : ["closed"]}}
-{"query" : {"match_all" :{}}}
+{"query" : {"match_all" {}}}
 {}
-{"query" : {"match_all" :{}}}
+{"query" : {"match_all" {}}}
 {"search_type" : "dfs_query_then_fetch"}
-{"query" : {"match_all" :{}}}
+{"query" : {"match_all" {}}}
 
-{"query" : {"match_all" :{}}}
+{"query" : {"match_all" {}}}
diff --git a/core/src/test/resources/org/elasticsearch/action/search/simple-msearch2.json b/core/src/test/resources/org/elasticsearch/action/search/simple-msearch2.json
index 79330d8..e2e06d9 100644
--- a/core/src/test/resources/org/elasticsearch/action/search/simple-msearch2.json
+++ b/core/src/test/resources/org/elasticsearch/action/search/simple-msearch2.json
@@ -1,10 +1,10 @@
 {"index":"test"}
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
 {"index" : "test", "type" : "type1"}
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
 {}
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
 {"search_type" : "dfs_query_then_fetch"}
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
 
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
diff --git a/core/src/test/resources/org/elasticsearch/action/search/simple-msearch3.json b/core/src/test/resources/org/elasticsearch/action/search/simple-msearch3.json
index a6b52fd..6416720 100644
--- a/core/src/test/resources/org/elasticsearch/action/search/simple-msearch3.json
+++ b/core/src/test/resources/org/elasticsearch/action/search/simple-msearch3.json
@@ -1,8 +1,8 @@
 {"index":["test0", "test1"]}
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
 {"index" : "test2,test3", "type" : "type1"}
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
 {"index" : ["test4", "test1"], "type" :  [ "type2", "type1" ]}
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
 {"search_type" : "dfs_query_then_fetch"}
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
diff --git a/core/src/test/resources/org/elasticsearch/action/search/simple-msearch4.json b/core/src/test/resources/org/elasticsearch/action/search/simple-msearch4.json
index 844d8be..b98e24b 100644
--- a/core/src/test/resources/org/elasticsearch/action/search/simple-msearch4.json
+++ b/core/src/test/resources/org/elasticsearch/action/search/simple-msearch4.json
@@ -1,6 +1,6 @@
 {"index":["test0", "test1"], "request_cache": true}
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
 {"index" : "test2,test3", "type" : "type1", "preference": "_local"}
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
 {"index" : ["test4", "test1"], "type" :  [ "type2", "type1" ], "routing": "123"}
-{"query" : {"match_all" : {}}}
+{"query" : {"match_all" {}}}
diff --git a/core/src/test/resources/org/elasticsearch/action/search/simple-msearch5.json b/core/src/test/resources/org/elasticsearch/action/search/simple-msearch5.json
index b337eae..5f08919 100644
--- a/core/src/test/resources/org/elasticsearch/action/search/simple-msearch5.json
+++ b/core/src/test/resources/org/elasticsearch/action/search/simple-msearch5.json
@@ -1,6 +1,6 @@
 {"index":["test0", "test1"], "request_cache": true}
-{"template": {"query" : {"match_{{template}}" :{}}}, "params": {"template": "all" } } }
+{"template": {"query" : {"match_{{template}}" {}}}, "params": {"template": "all" } } }
 {"index" : "test2,test3", "type" : "type1", "preference": "_local"}
-{"template": {"query" : {"match_{{template}}" :{}}}, "params": {"template": "all" } } }
+{"template": {"query" : {"match_{{template}}" {}}}, "params": {"template": "all" } } }
 {"index" : ["test4", "test1"], "type" :  [ "type2", "type1" ], "routing": "123"}
-{"template": {"query" : {"match_{{template}}" :{}}}, "params": {"template": "all" } } }
+{"template": {"query" : {"match_{{template}}" {}}}, "params": {"template": "all" } } }
diff --git a/core/src/test/resources/org/elasticsearch/index/query/function-score-query-causing-NPE.json b/core/src/test/resources/org/elasticsearch/index/query/function-score-query-causing-NPE.json
deleted file mode 100644
index 283682b..0000000
--- a/core/src/test/resources/org/elasticsearch/index/query/function-score-query-causing-NPE.json
+++ /dev/null
@@ -1,9 +0,0 @@
-{
-    "function_score": {
-      "script_score": {
-        "script": "_index['text']['foo'].tf()"
-      },
-      "weight": 2
-    }
-}
-
diff --git a/docs/reference/migration/migrate_query_refactoring.asciidoc b/docs/reference/migration/migrate_query_refactoring.asciidoc
index c7e005b..520a5fa 100644
--- a/docs/reference/migration/migrate_query_refactoring.asciidoc
+++ b/docs/reference/migration/migrate_query_refactoring.asciidoc
@@ -10,13 +10,22 @@ Plugins implementing custom queries need to implement the `fromXContent(QueryPar
 `QueryParser` subclass rather than `parse`. This method will take care of parsing the query from `XContent` format
 into an intermediate query representation that can be streamed between the nodes in binary format, effectively the
 query object used in the java api. Also, the query parser needs to implement the `getBuilderPrototype` method that
-returns a prototype of the streamable query, which allows to deserialize an incoming query by calling
+returns a prototype of the `NamedWriteable` query, which allows to deserialize an incoming query by calling
 `readFrom(StreamInput)` against it, which will create a new object, see usages of `Writeable`. The `QueryParser`
 also needs to declare the generic type of the query that it supports and it's able to parse.
 The query object can then transform itself into a lucene query through the new `toQuery(QueryShardContext)` method,
-which returns a lucene query to be executed on the data node. The query implementation also needs to implement the
-`validate` method that allows to validate the content of the query, no matter whether it came in through the java api
-directly or through the REST layer.
+which returns a lucene query to be executed on the data node.
+
+Similarly, plugins implementing custom score functions need to implement the `fromXContent(QueryParseContext)`
+method in their `ScoreFunctionParser` subclass rather than `parse`. This method will take care of parsing
+the function from `XContent` format into an intermediate function representation that can be streamed between
+the nodes in binary format, effectively the function object used in the java api. Also, the query parser needs
+to implement the `getBuilderPrototype` method that returns a prototype of the `NamedWriteable` function, which
+allows to deserialize an incoming function by calling `readFrom(StreamInput)` against it, which will create a
+new object, see usages of `Writeable`. The `ScoreFunctionParser` also needs to declare the generic type of the
+function that it supports and it's able to parse. The function object can then transform itself into a lucene
+function through the new `toFunction(QueryShardContext)` method, which returns a lucene function to be executed
+on the data node.
 
 === Java-API
 
@@ -100,8 +109,11 @@ Also reusing new Operator enum.
 Removed `MoreLikeThisQueryBuilder.Item#id(String id)`, `Item#doc(BytesReference doc)`,
 `Item#doc(XContentBuilder doc)`. Use provided constructors instead.
 
-Removed `MoreLikeThisQueryBuilder#addLike` and `addUnlike` in favor to using the `like`
-and `unlike` methods.
+Removed `MoreLikeThisQueryBuilder#addLike` in favor of texts and/or items beeing provided
+at construction time. Using arrays there instead of lists now.
+
+Removed `MoreLikeThisQueryBuilder#addUnlike` in favor to using the `unlike` methods
+which take arrays as arguments now rather than the lists used before. 
 
 The deprecated `docs(Item... docs)`, `ignoreLike(Item... docs)`,
 `ignoreLike(String... likeText)`, `addItem(Item... likeItems)` have been removed.
@@ -145,3 +157,14 @@ individual values at constrution time. Also moving individual settings for the T
 lookupType, lookupId, lookupPath) to the separate TermsLookUp class, using construtor only and moving
 checks for validation there.
 
+==== FunctionScoreQueryBuilder
+
+`add` methods have been removed, all filters and functions must be provided as constructor arguments by
+creating an array of `FunctionScoreQueryBuilder.FilterFunctionBuilder` objects, containing one element
+for each filter/function pair.
+
+`scoreMode` and `boostMode` can only be provided using corresponding enum members instead
+of string values: see `FilterFunctionScoreQuery.ScoreMode` and `CombineFunction`.
+
+`CombineFunction.MULT` has been renamed to `MULTIPLY`.
+
diff --git a/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequest.java b/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequest.java
index 86d224b..4c29e7c 100644
--- a/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequest.java
+++ b/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequest.java
@@ -19,20 +19,27 @@
 
 package org.elasticsearch.action.deletebyquery;
 
+import org.elasticsearch.ElasticsearchGenerationException;
 import org.elasticsearch.action.ActionRequest;
 import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.IndicesRequest;
 import org.elasticsearch.action.support.IndicesOptions;
+import org.elasticsearch.action.support.QuerySourceBuilder;
+import org.elasticsearch.client.Requests;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.bytes.BytesArray;
+import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.search.Scroll;
 
 import java.io.IOException;
 import java.util.Arrays;
+import java.util.Map;
 
 import static org.elasticsearch.action.ValidateActions.addValidationError;
 import static org.elasticsearch.search.Scroll.readScroll;
@@ -70,7 +77,7 @@ public class DeleteByQueryRequest extends ActionRequest<DeleteByQueryRequest> im
 
     private String[] types = Strings.EMPTY_ARRAY;
 
-    private QueryBuilder<?> query;
+    private BytesReference source;
 
     private String routing;
 
@@ -94,7 +101,7 @@ public class DeleteByQueryRequest extends ActionRequest<DeleteByQueryRequest> im
     @Override
     public ActionRequestValidationException validate() {
         ActionRequestValidationException validationException = null;
-        if (query == null) {
+        if (source == null) {
             validationException = addValidationError("source is missing", validationException);
         }
         return validationException;
@@ -133,12 +140,45 @@ public class DeleteByQueryRequest extends ActionRequest<DeleteByQueryRequest> im
         return this;
     }
 
-    public QueryBuilder<?> query() {
-        return query;
+    public BytesReference source() {
+        return source;
     }
 
-    public DeleteByQueryRequest query(QueryBuilder<?> queryBuilder) {
-        this.query = queryBuilder;
+    public DeleteByQueryRequest source(QuerySourceBuilder sourceBuilder) {
+        this.source = sourceBuilder.buildAsBytes(Requests.CONTENT_TYPE);
+        return this;
+    }
+
+    public DeleteByQueryRequest source(Map<String,?> querySource) {
+        try {
+            XContentBuilder builder = XContentFactory.contentBuilder(Requests.CONTENT_TYPE);
+            builder.map(querySource);
+            return source(builder);
+        } catch (IOException e) {
+            throw new ElasticsearchGenerationException("Failed to generate [" + querySource + "]", e);
+        }
+    }
+
+    public DeleteByQueryRequest source(XContentBuilder builder) {
+        this.source = builder.bytes();
+        return this;
+    }
+
+    public DeleteByQueryRequest source(String querySource) {
+        this.source = new BytesArray(querySource);
+        return this;
+    }
+
+    public DeleteByQueryRequest source(byte[] querySource) {
+        return source(querySource, 0, querySource.length);
+    }
+
+    public DeleteByQueryRequest source(byte[] querySource, int offset, int length) {
+        return source(new BytesArray(querySource, offset, length));
+    }
+
+    public DeleteByQueryRequest source(BytesReference querySource) {
+        this.source = querySource;
         return this;
     }
 
@@ -209,7 +249,7 @@ public class DeleteByQueryRequest extends ActionRequest<DeleteByQueryRequest> im
         indices = in.readStringArray();
         indicesOptions = IndicesOptions.readIndicesOptions(in);
         types = in.readStringArray();
-        query = in.readQuery();
+        source = in.readBytesReference();
         routing = in.readOptionalString();
         size = in.readVInt();
         if (in.readBoolean()) {
@@ -226,7 +266,7 @@ public class DeleteByQueryRequest extends ActionRequest<DeleteByQueryRequest> im
         out.writeStringArray(indices);
         indicesOptions.writeIndicesOptions(out);
         out.writeStringArray(types);
-        out.writeQuery(query);
+        out.writeBytesReference(source);
         out.writeOptionalString(routing);
         out.writeVInt(size);
         out.writeOptionalStreamable(scroll);
@@ -237,7 +277,7 @@ public class DeleteByQueryRequest extends ActionRequest<DeleteByQueryRequest> im
     public String toString() {
         String sSource = "_na_";
         try {
-            sSource = XContentHelper.toString(query);
+            sSource = XContentHelper.convertToJson(source, false);
         } catch (Exception e) {
             // ignore
         }
diff --git a/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequestBuilder.java b/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequestBuilder.java
index ccfc741..d30cfaa 100644
--- a/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequestBuilder.java
+++ b/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequestBuilder.java
@@ -22,17 +22,22 @@ package org.elasticsearch.action.deletebyquery;
 import org.elasticsearch.action.ActionRequestBuilder;
 import org.elasticsearch.action.ListenableActionFuture;
 import org.elasticsearch.action.support.IndicesOptions;
+import org.elasticsearch.action.support.QuerySourceBuilder;
 import org.elasticsearch.client.ElasticsearchClient;
+import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
 
+import java.util.Map;
+
 /**
  * Creates a new {@link DeleteByQueryRequestBuilder}
  * @see DeleteByQueryRequest
  */
 public class DeleteByQueryRequestBuilder extends ActionRequestBuilder<DeleteByQueryRequest, DeleteByQueryResponse, DeleteByQueryRequestBuilder> {
 
-    private QueryBuilder<?> queryBuilder;
+    private QuerySourceBuilder sourceBuilder;
 
     public DeleteByQueryRequestBuilder(ElasticsearchClient client, DeleteByQueryAction action) {
         super(client, action, new DeleteByQueryRequest());
@@ -59,11 +64,26 @@ public class DeleteByQueryRequestBuilder extends ActionRequestBuilder<DeleteByQu
      * @see org.elasticsearch.index.query.QueryBuilders
      */
     public DeleteByQueryRequestBuilder setQuery(QueryBuilder<?> queryBuilder) {
-        this.queryBuilder = queryBuilder;
+        sourceBuilder().setQuery(queryBuilder);
+        return this;
+    }
+
+    /**
+     * The query binary used to delete documents.
+     */
+    public DeleteByQueryRequestBuilder setQuery(BytesReference queryBinary) {
+        sourceBuilder().setQuery(queryBinary);
         return this;
     }
 
     /**
+     * Constructs a new builder with a raw search query.
+     */
+    public DeleteByQueryRequestBuilder setQuery(XContentBuilder query) {
+        return setQuery(query.bytes());
+    }
+
+    /**
      * A comma separated list of routing values to control the shards the action will be executed on.
      */
     public DeleteByQueryRequestBuilder setRouting(String routing) {
@@ -80,6 +100,47 @@ public class DeleteByQueryRequestBuilder extends ActionRequestBuilder<DeleteByQu
     }
 
     /**
+     * The source to execute. It is preferable to use either {@link #setSource(byte[])}
+     * or {@link #setQuery(QueryBuilder)}.
+     */
+    public DeleteByQueryRequestBuilder setSource(String source) {
+        request().source(source);
+        return this;
+    }
+
+    /**
+     * The source to execute in the form of a map.
+     */
+    public DeleteByQueryRequestBuilder setSource(Map<String, Object> source) {
+        request().source(source);
+        return this;
+    }
+
+    /**
+     * The source to execute in the form of a builder.
+     */
+    public DeleteByQueryRequestBuilder setSource(XContentBuilder builder) {
+        request().source(builder);
+        return this;
+    }
+
+    /**
+     * The source to execute.
+     */
+    public DeleteByQueryRequestBuilder setSource(byte[] source) {
+        request().source(source);
+        return this;
+    }
+
+    /**
+     * The source to execute.
+     */
+    public DeleteByQueryRequestBuilder setSource(BytesReference source) {
+        request().source(source);
+        return this;
+    }
+
+    /**
      * An optional timeout to control how long the delete by query is allowed to take.
      */
     public DeleteByQueryRequestBuilder setTimeout(TimeValue timeout) {
@@ -105,10 +166,17 @@ public class DeleteByQueryRequestBuilder extends ActionRequestBuilder<DeleteByQu
 
     @Override
     public ListenableActionFuture<DeleteByQueryResponse> execute() {
-        if (queryBuilder != null) {
-            request.query(queryBuilder);
+        if (sourceBuilder != null) {
+            request.source(sourceBuilder);
         }
         return super.execute();
     }
 
+    private QuerySourceBuilder sourceBuilder() {
+        if (sourceBuilder == null) {
+            sourceBuilder = new QuerySourceBuilder();
+        }
+        return sourceBuilder;
+    }
+
 }
diff --git a/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryAction.java b/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryAction.java
index 83a3015..252befd 100644
--- a/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryAction.java
+++ b/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryAction.java
@@ -27,13 +27,7 @@ import org.elasticsearch.action.bulk.BulkRequest;
 import org.elasticsearch.action.bulk.BulkResponse;
 import org.elasticsearch.action.delete.DeleteRequest;
 import org.elasticsearch.action.delete.DeleteResponse;
-import org.elasticsearch.action.search.ClearScrollResponse;
-import org.elasticsearch.action.search.SearchRequest;
-import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.action.search.SearchScrollRequest;
-import org.elasticsearch.action.search.ShardSearchFailure;
-import org.elasticsearch.action.search.TransportSearchAction;
-import org.elasticsearch.action.search.TransportSearchScrollAction;
+import org.elasticsearch.action.search.*;
 import org.elasticsearch.action.support.ActionFilters;
 import org.elasticsearch.action.support.HandledTransportAction;
 import org.elasticsearch.client.Client;
@@ -48,9 +42,7 @@ import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
-import java.util.ArrayList;
 import java.util.HashMap;
-import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicLong;
@@ -115,11 +107,9 @@ public class TransportDeleteByQueryAction extends HandledTransportAction<DeleteB
                     scanRequest.routing(request.routing());
                 }
 
-                List<String> fields = new ArrayList<>();
-                fields.add("_routing");
-                fields.add("_parent");
                 SearchSourceBuilder source = new SearchSourceBuilder()
-.query(request.query()).fields(fields)
+                        .query(request.source())
+                        .fields("_routing", "_parent")
                         .sort("_doc") // important for performance
                         .fetchSource(false)
                         .version(true);
diff --git a/plugins/delete-by-query/src/main/java/org/elasticsearch/rest/action/deletebyquery/RestDeleteByQueryAction.java b/plugins/delete-by-query/src/main/java/org/elasticsearch/rest/action/deletebyquery/RestDeleteByQueryAction.java
index 2d8b950..251953d 100644
--- a/plugins/delete-by-query/src/main/java/org/elasticsearch/rest/action/deletebyquery/RestDeleteByQueryAction.java
+++ b/plugins/delete-by-query/src/main/java/org/elasticsearch/rest/action/deletebyquery/RestDeleteByQueryAction.java
@@ -22,11 +22,11 @@ package org.elasticsearch.rest.action.deletebyquery;
 import org.elasticsearch.action.deletebyquery.DeleteByQueryRequest;
 import org.elasticsearch.action.deletebyquery.DeleteByQueryResponse;
 import org.elasticsearch.action.support.IndicesOptions;
+import org.elasticsearch.action.support.QuerySourceBuilder;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.rest.BaseRestHandler;
 import org.elasticsearch.rest.RestChannel;
 import org.elasticsearch.rest.RestController;
@@ -58,15 +58,15 @@ public class RestDeleteByQueryAction extends BaseRestHandler {
             delete.timeout(request.paramAsTime("timeout", null));
         }
         if (request.hasContent()) {
-//            delete.source(request.content()); NORELEASE parse request.content() into a queryBuilder
+            delete.source(request.content());
         } else {
             String source = request.param("source");
             if (source != null) {
-                // delete.source(source); NORELEASE parse source into a queryBuilder
+                delete.source(source);
             } else {
-                QueryBuilder<?> queryBuilder = RestActions.parseQuerySource(request);
-                if (queryBuilder != null) {
-                    delete.query(queryBuilder);
+                QuerySourceBuilder querySourceBuilder = RestActions.parseQuerySource(request);
+                if (querySourceBuilder != null) {
+                    delete.source(querySourceBuilder);
                 }
             }
         }
diff --git a/plugins/delete-by-query/src/test/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryActionTests.java b/plugins/delete-by-query/src/test/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryActionTests.java
index d5d2e79..c9d3f44 100644
--- a/plugins/delete-by-query/src/test/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryActionTests.java
+++ b/plugins/delete-by-query/src/test/java/org/elasticsearch/action/deletebyquery/TransportDeleteByQueryActionTests.java
@@ -58,20 +58,19 @@ public class TransportDeleteByQueryActionTests extends ESSingleNodeTestCase {
         assertSearchContextsClosed();
     }
 
-    // NORELEASE re-implement this parsing test as a unit test
-//    @Test
-//    public void testExecuteScanFailsOnMalformedQuery() {
-//        createIndex("test");
-//
-//        DeleteByQueryRequest delete = new DeleteByQueryRequest().indices(new String[]{"test"}).query("{...}");
-//        TestActionListener listener = new TestActionListener();
-//
-//        newAsyncAction(delete, listener).executeScan();
-//        waitForCompletion("scan request should fail on malformed query", listener);
-//
-//        assertFailure(listener, "all shards failed");
-//        assertSearchContextsClosed();
-//    }
+    @Test
+    public void testExecuteScanFailsOnMalformedQuery() {
+        createIndex("test");
+
+        DeleteByQueryRequest delete = new DeleteByQueryRequest().indices(new String[]{"test"}).source("{...}");
+        TestActionListener listener = new TestActionListener();
+
+        newAsyncAction(delete, listener).executeScan();
+        waitForCompletion("scan request should fail on malformed query", listener);
+
+        assertFailure(listener, "all shards failed");
+        assertSearchContextsClosed();
+    }
 
     @Test
     public void testExecuteScan() {
@@ -84,7 +83,7 @@ public class TransportDeleteByQueryActionTests extends ESSingleNodeTestCase {
         assertHitCount(client().prepareCount("test").get(), numDocs);
 
         final long limit = randomIntBetween(0, numDocs);
-        DeleteByQueryRequest delete = new DeleteByQueryRequest().indices(new String[]{"test"}).query(boolQuery().must(rangeQuery("num").lte(limit)));
+        DeleteByQueryRequest delete = new DeleteByQueryRequest().indices(new String[]{"test"}).source(boolQuery().must(rangeQuery("num").lte(limit)).buildAsBytes());
         TestActionListener listener = new TestActionListener();
 
         newAsyncAction(delete, listener).executeScan();
@@ -220,7 +219,7 @@ public class TransportDeleteByQueryActionTests extends ESSingleNodeTestCase {
         assertTrue(Strings.hasText(scrollId));
         assertThat(searchResponse.getHits().getTotalHits(), equalTo(limit));
 
-        DeleteByQueryRequest delete = new DeleteByQueryRequest().indices(new String[]{"test"}).size(100).query(boolQuery().must(rangeQuery("num").lte(limit)));
+        DeleteByQueryRequest delete = new DeleteByQueryRequest().indices(new String[]{"test"}).size(100).source(boolQuery().must(rangeQuery("num").lte(limit)).buildAsBytes());
         TestActionListener listener = new TestActionListener();
 
         newAsyncAction(delete, listener).executeScroll(searchResponse.getScrollId());
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/script/30_expressions.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/script/30_expressions.yaml
index 36ff7f5..a0953a25 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/script/30_expressions.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/script/30_expressions.yaml
@@ -22,6 +22,6 @@ setup:
 ---
 "Expressions scripting test":
 
-  - do: { search: { body: { script_fields : { my_field : { script: { lang: expression, inline: 'doc["age"].value + 19' } } } } } }
+  - do: { search: { body: { script_fields : { my_field : { lang: expression, script: 'doc["age"].value + 19' } } } } }
   - match:  { hits.hits.0.fields.my_field.0: 42.0 }
 
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/search/10_source_filtering.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/search/10_source_filtering.yaml
index b49d659..a78a5a2 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/search/10_source_filtering.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/search/10_source_filtering.yaml
@@ -14,12 +14,12 @@
   - do:
       search:
       # stringified for boolean value
-        body: { _source: true, query: { match_all: {} } }
+        body: "{ _source: true, query: { match_all: {} } }"
 
   - length:   { hits.hits: 1  }
   - match: { hits.hits.0._source.count: 1 }
 
-  - do: { search: { body: { _source: false, query: { match_all: {} } } } }
+  - do: { search: { body: "{ _source: false, query: { match_all: {} } }" } }
   - length:   { hits.hits: 1  }
   - is_false: hits.hits.0._source
 
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/template/20_search.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/template/20_search.yaml
index 4da748a..5153f6c 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/template/20_search.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/template/20_search.yaml
@@ -28,11 +28,16 @@
 
   - do:
       search_template:
+        body: { "template": { "id" : "1" }, "params" : { "my_value" : "value1_foo", "my_size" : 1 } }
+  - match: { hits.total: 1 }
+
+  - do:
+      search_template:
         body: {  "id" : "1", "params" : { "my_value" : "value1_foo", "my_size" : 1 } }
   - match: { hits.total: 1 }
 
   - do:
       catch: /Unable.to.find.on.disk.file.script.\[simple1\].using.lang.\[mustache\]/
       search_template:
-        body: { "file" : "simple1"}
+        body: { "template" : "simple1" }
 

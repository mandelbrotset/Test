diff --git a/core/pom.xml b/core/pom.xml
index a96e374..2a5f6de 100644
--- a/core/pom.xml
+++ b/core/pom.xml
@@ -274,7 +274,7 @@
                                 <include>org/elasticsearch/common/cli/CliToolTestCase$*.class</include>
                                 <include>org/elasticsearch/cluster/MockInternalClusterInfoService.class</include>
                                 <include>org/elasticsearch/cluster/MockInternalClusterInfoService$*.class</include>
-                                <include>org/elasticsearch/index/shard/MockEngineFactoryPlugin.class</include>
+                                <include>org/elasticsearch/index/MockEngineFactoryPlugin.class</include>
                                 <include>org/elasticsearch/search/MockSearchService.class</include>
                                 <include>org/elasticsearch/search/MockSearchService$*.class</include>
                                 <include>org/elasticsearch/search/aggregations/bucket/AbstractTermsTestCase.class</include>
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsIndices.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsIndices.java
index be7a3f0..ff754be 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsIndices.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/stats/ClusterStatsIndices.java
@@ -31,7 +31,7 @@ import org.elasticsearch.common.xcontent.XContentBuilderString;
 import org.elasticsearch.index.cache.query.QueryCacheStats;
 import org.elasticsearch.index.engine.SegmentsStats;
 import org.elasticsearch.index.fielddata.FieldDataStats;
-import org.elasticsearch.index.percolator.stats.PercolateStats;
+import org.elasticsearch.index.percolator.PercolateStats;
 import org.elasticsearch.index.shard.DocsStats;
 import org.elasticsearch.index.store.StoreStats;
 import org.elasticsearch.search.suggest.completion.CompletionStats;
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/cache/clear/TransportClearIndicesCacheAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/cache/clear/TransportClearIndicesCacheAction.java
index 0057929..2308d7b 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/cache/clear/TransportClearIndicesCacheAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/cache/clear/TransportClearIndicesCacheAction.java
@@ -83,7 +83,7 @@ public class TransportClearIndicesCacheAction extends TransportBroadcastByNodeAc
     protected EmptyResult shardOperation(ClearIndicesCacheRequest request, ShardRouting shardRouting) {
         IndexService service = indicesService.indexService(shardRouting.getIndex());
         if (service != null) {
-            IndexShard shard = service.shard(shardRouting.id());
+            IndexShard shard = service.getShardOrNull(shardRouting.id());
             boolean clearedAtLeastOne = false;
             if (request.queryCache()) {
                 clearedAtLeastOne = true;
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/flush/TransportShardFlushAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/flush/TransportShardFlushAction.java
index 2bae799..f768cfe 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/flush/TransportShardFlushAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/flush/TransportShardFlushAction.java
@@ -62,7 +62,7 @@ public class TransportShardFlushAction extends TransportReplicationAction<ShardF
 
     @Override
     protected Tuple<ActionWriteResponse, ShardFlushRequest> shardOperationOnPrimary(ClusterState clusterState, PrimaryOperationRequest shardRequest) throws Throwable {
-        IndexShard indexShard = indicesService.indexServiceSafe(shardRequest.shardId.getIndex()).shardSafe(shardRequest.shardId.id());
+        IndexShard indexShard = indicesService.indexServiceSafe(shardRequest.shardId.getIndex()).getShard(shardRequest.shardId.id());
         indexShard.flush(shardRequest.request.getRequest());
         logger.trace("{} flush request executed on primary", indexShard.shardId());
         return new Tuple<>(new ActionWriteResponse(), shardRequest.request);
@@ -70,7 +70,7 @@ public class TransportShardFlushAction extends TransportReplicationAction<ShardF
 
     @Override
     protected void shardOperationOnReplica(ShardId shardId, ShardFlushRequest request) {
-        IndexShard indexShard = indicesService.indexServiceSafe(request.shardId().getIndex()).shardSafe(request.shardId().id());
+        IndexShard indexShard = indicesService.indexServiceSafe(request.shardId().getIndex()).getShard(request.shardId().id());
         indexShard.flush(request.getRequest());
         logger.trace("{} flush request executed on replica", indexShard.shardId());
     }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java
index a7a4830..764022b 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/optimize/TransportOptimizeAction.java
@@ -75,7 +75,7 @@ public class TransportOptimizeAction extends TransportBroadcastByNodeAction<Opti
 
     @Override
     protected EmptyResult shardOperation(OptimizeRequest request, ShardRouting shardRouting) throws IOException {
-        IndexShard indexShard = indicesService.indexServiceSafe(shardRouting.shardId().getIndex()).shardSafe(shardRouting.shardId().id());
+        IndexShard indexShard = indicesService.indexServiceSafe(shardRouting.shardId().getIndex()).getShard(shardRouting.shardId().id());
         indexShard.optimize(request);
         return EmptyResult.INSTANCE;
     }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java
index ca670f7..b003f06 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java
@@ -100,7 +100,7 @@ public class TransportRecoveryAction extends TransportBroadcastByNodeAction<Reco
     @Override
     protected RecoveryState shardOperation(RecoveryRequest request, ShardRouting shardRouting) {
         IndexService indexService = indicesService.indexServiceSafe(shardRouting.shardId().getIndex());
-        IndexShard indexShard = indexService.shardSafe(shardRouting.shardId().id());
+        IndexShard indexShard = indexService.getShard(shardRouting.shardId().id());
         return indexShard.recoveryState();
     }
 
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportShardRefreshAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportShardRefreshAction.java
index 7f4d3fc..a06483a 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportShardRefreshAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/refresh/TransportShardRefreshAction.java
@@ -63,7 +63,7 @@ public class TransportShardRefreshAction extends TransportReplicationAction<Repl
 
     @Override
     protected Tuple<ActionWriteResponse, ReplicationRequest> shardOperationOnPrimary(ClusterState clusterState, PrimaryOperationRequest shardRequest) throws Throwable {
-        IndexShard indexShard = indicesService.indexServiceSafe(shardRequest.shardId.getIndex()).shardSafe(shardRequest.shardId.id());
+        IndexShard indexShard = indicesService.indexServiceSafe(shardRequest.shardId.getIndex()).getShard(shardRequest.shardId.id());
         indexShard.refresh("api");
         logger.trace("{} refresh request executed on primary", indexShard.shardId());
         return new Tuple<>(new ActionWriteResponse(), shardRequest.request);
@@ -71,7 +71,7 @@ public class TransportShardRefreshAction extends TransportReplicationAction<Repl
 
     @Override
     protected void shardOperationOnReplica(ShardId shardId, ReplicationRequest request) {
-        IndexShard indexShard = indicesService.indexServiceSafe(shardId.getIndex()).shardSafe(shardId.id());
+        IndexShard indexShard = indicesService.indexServiceSafe(shardId.getIndex()).getShard(shardId.id());
         indexShard.refresh("api");
         logger.trace("{} refresh request executed on replica", indexShard.shardId());
     }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/segments/TransportIndicesSegmentsAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/segments/TransportIndicesSegmentsAction.java
index e7770a5..4a9f2c3 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/segments/TransportIndicesSegmentsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/segments/TransportIndicesSegmentsAction.java
@@ -94,7 +94,7 @@ public class TransportIndicesSegmentsAction extends TransportBroadcastByNodeActi
     @Override
     protected ShardSegments shardOperation(IndicesSegmentsRequest request, ShardRouting shardRouting) {
         IndexService indexService = indicesService.indexServiceSafe(shardRouting.getIndex());
-        IndexShard indexShard = indexService.shardSafe(shardRouting.id());
-        return new ShardSegments(indexShard.routingEntry(), indexShard.engine().segments(request.verbose()));
+        IndexShard indexShard = indexService.getShard(shardRouting.id());
+        return new ShardSegments(indexShard.routingEntry(), indexShard.segments(request.verbose()));
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStats.java b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStats.java
index b2f0dee..53c0711 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStats.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/CommonStats.java
@@ -34,7 +34,7 @@ import org.elasticsearch.index.flush.FlushStats;
 import org.elasticsearch.index.get.GetStats;
 import org.elasticsearch.index.indexing.IndexingStats;
 import org.elasticsearch.index.merge.MergeStats;
-import org.elasticsearch.index.percolator.stats.PercolateStats;
+import org.elasticsearch.index.percolator.PercolateStats;
 import org.elasticsearch.index.recovery.RecoveryStats;
 import org.elasticsearch.index.refresh.RefreshStats;
 import org.elasticsearch.index.search.stats.SearchStats;
@@ -167,7 +167,7 @@ public class CommonStats implements Streamable, ToXContent {
                     segments = indexShard.segmentStats();
                     break;
                 case Percolate:
-                    percolate = indexShard.shardPercolateService().stats();
+                    percolate = indexShard.percolateStats();
                     break;
                 case Translog:
                     translog = indexShard.translogStats();
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java
index 6275e97..d5de67d 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java
@@ -95,7 +95,7 @@ public class TransportIndicesStatsAction extends TransportBroadcastByNodeAction<
     @Override
     protected ShardStats shardOperation(IndicesStatsRequest request, ShardRouting shardRouting) {
         IndexService indexService = indicesService.indexServiceSafe(shardRouting.shardId().getIndex());
-        IndexShard indexShard = indexService.shardSafe(shardRouting.shardId().id());
+        IndexShard indexShard = indexService.getShard(shardRouting.shardId().id());
         // if we don't have the routing entry yet, we need it stats wise, we treat it as if the shard is not ready yet
         if (indexShard.routingEntry() == null) {
             throw new ShardNotFoundException(indexShard.shardId());
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/TransportUpgradeStatusAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/TransportUpgradeStatusAction.java
index ea2a2ed..6b37f56 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/TransportUpgradeStatusAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/get/TransportUpgradeStatusAction.java
@@ -96,8 +96,8 @@ public class TransportUpgradeStatusAction extends TransportBroadcastByNodeAction
     @Override
     protected ShardUpgradeStatus shardOperation(UpgradeStatusRequest request, ShardRouting shardRouting) {
         IndexService indexService = indicesService.indexServiceSafe(shardRouting.shardId().getIndex());
-        IndexShard indexShard = indexService.shardSafe(shardRouting.shardId().id());
-        List<Segment> segments = indexShard.engine().segments(false);
+        IndexShard indexShard = indexService.getShard(shardRouting.shardId().id());
+        List<Segment> segments = indexShard.segments(false);
         long total_bytes = 0;
         long to_upgrade_bytes = 0;
         long to_upgrade_bytes_ancient = 0;
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
index 38375af..30aff1f 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/upgrade/post/TransportUpgradeAction.java
@@ -119,7 +119,7 @@ public class TransportUpgradeAction extends TransportBroadcastByNodeAction<Upgra
 
     @Override
     protected ShardUpgradeResult shardOperation(UpgradeRequest request, ShardRouting shardRouting) throws IOException {
-        IndexShard indexShard = indicesService.indexServiceSafe(shardRouting.shardId().getIndex()).shardSafe(shardRouting.shardId().id());
+        IndexShard indexShard = indicesService.indexServiceSafe(shardRouting.shardId().getIndex()).getShard(shardRouting.shardId().id());
         org.apache.lucene.util.Version oldestLuceneSegment = indexShard.upgrade(request);
         // We are using the current version of Elasticsearch as upgrade version since we update mapping to match the current version
         return new ShardUpgradeResult(shardRouting.shardId(), indexShard.routingEntry().primary(), Version.CURRENT, oldestLuceneSegment);
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
index c64a594..db54fe4 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/TransportValidateQueryAction.java
@@ -163,7 +163,7 @@ public class TransportValidateQueryAction extends TransportBroadcastAction<Valid
     protected ShardValidateQueryResponse shardOperation(ShardValidateQueryRequest request) {
         IndexService indexService = indicesService.indexServiceSafe(request.shardId().getIndex());
         IndexQueryParserService queryParserService = indexService.queryParserService();
-        IndexShard indexShard = indexService.shardSafe(request.shardId().id());
+        IndexShard indexShard = indexService.getShard(request.shardId().id());
 
         boolean valid;
         String explanation = null;
diff --git a/core/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java b/core/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java
index 7a16839..c071885 100644
--- a/core/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java
+++ b/core/src/main/java/org/elasticsearch/action/bulk/TransportShardBulkAction.java
@@ -116,7 +116,7 @@ public class TransportShardBulkAction extends TransportReplicationAction<BulkSha
     protected Tuple<BulkShardResponse, BulkShardRequest> shardOperationOnPrimary(ClusterState clusterState, PrimaryOperationRequest shardRequest) {
         final BulkShardRequest request = shardRequest.request;
         final IndexService indexService = indicesService.indexServiceSafe(request.index());
-        final IndexShard indexShard = indexService.shardSafe(shardRequest.shardId.id());
+        final IndexShard indexShard = indexService.getShard(shardRequest.shardId.id());
 
         long[] preVersions = new long[request.items().length];
         VersionType[] preVersionTypes = new VersionType[request.items().length];
@@ -447,7 +447,7 @@ public class TransportShardBulkAction extends TransportReplicationAction<BulkSha
     @Override
     protected void shardOperationOnReplica(ShardId shardId, BulkShardRequest request) {
         IndexService indexService = indicesService.indexServiceSafe(shardId.getIndex());
-        IndexShard indexShard = indexService.shardSafe(shardId.id());
+        IndexShard indexShard = indexService.getShard(shardId.id());
         Translog.Location location = null;
         for (int i = 0; i < request.items().length; i++) {
             BulkItemRequest item = request.items()[i];
diff --git a/core/src/main/java/org/elasticsearch/action/delete/TransportDeleteAction.java b/core/src/main/java/org/elasticsearch/action/delete/TransportDeleteAction.java
index 0bbc37f..c20b203 100644
--- a/core/src/main/java/org/elasticsearch/action/delete/TransportDeleteAction.java
+++ b/core/src/main/java/org/elasticsearch/action/delete/TransportDeleteAction.java
@@ -42,7 +42,6 @@ import org.elasticsearch.index.VersionType;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.translog.Translog;
 import org.elasticsearch.indices.IndexAlreadyExistsException;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.threadpool.ThreadPool;
@@ -130,7 +129,7 @@ public class TransportDeleteAction extends TransportReplicationAction<DeleteRequ
     @Override
     protected Tuple<DeleteResponse, DeleteRequest> shardOperationOnPrimary(ClusterState clusterState, PrimaryOperationRequest shardRequest) {
         DeleteRequest request = shardRequest.request;
-        IndexShard indexShard = indicesService.indexServiceSafe(shardRequest.shardId.getIndex()).shardSafe(shardRequest.shardId.id());
+        IndexShard indexShard = indicesService.indexServiceSafe(shardRequest.shardId.getIndex()).getShard(shardRequest.shardId.id());
         Engine.Delete delete = indexShard.prepareDelete(request.type(), request.id(), request.version(), request.versionType(), Engine.Operation.Origin.PRIMARY);
         indexShard.delete(delete);
         // update the request with teh version so it will go to the replicas
@@ -146,7 +145,7 @@ public class TransportDeleteAction extends TransportReplicationAction<DeleteRequ
 
     @Override
     protected void shardOperationOnReplica(ShardId shardId, DeleteRequest request) {
-        IndexShard indexShard = indicesService.indexServiceSafe(shardId.getIndex()).shardSafe(shardId.id());
+        IndexShard indexShard = indicesService.indexServiceSafe(shardId.getIndex()).getShard(shardId.id());
         Engine.Delete delete = indexShard.prepareDelete(request.type(), request.id(), request.version(), request.versionType(), Engine.Operation.Origin.REPLICA);
 
         indexShard.delete(delete);
diff --git a/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java b/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
index b35fe78..3cc6f06 100644
--- a/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/exists/TransportExistsAction.java
@@ -148,7 +148,7 @@ public class TransportExistsAction extends TransportBroadcastAction<ExistsReques
     @Override
     protected ShardExistsResponse shardOperation(ShardExistsRequest request) {
         IndexService indexService = indicesService.indexServiceSafe(request.shardId().getIndex());
-        IndexShard indexShard = indexService.shardSafe(request.shardId().id());
+        IndexShard indexShard = indexService.getShard(request.shardId().id());
 
         SearchShardTarget shardTarget = new SearchShardTarget(clusterService.localNode().id(), request.shardId().getIndex(), request.shardId().id());
         SearchContext context = new DefaultSearchContext(0,
diff --git a/core/src/main/java/org/elasticsearch/action/explain/TransportExplainAction.java b/core/src/main/java/org/elasticsearch/action/explain/TransportExplainAction.java
index 88b3da3..c2e6ddf 100644
--- a/core/src/main/java/org/elasticsearch/action/explain/TransportExplainAction.java
+++ b/core/src/main/java/org/elasticsearch/action/explain/TransportExplainAction.java
@@ -104,7 +104,7 @@ public class TransportExplainAction extends TransportSingleShardAction<ExplainRe
     @Override
     protected ExplainResponse shardOperation(ExplainRequest request, ShardId shardId) {
         IndexService indexService = indicesService.indexServiceSafe(shardId.getIndex());
-        IndexShard indexShard = indexService.shardSafe(shardId.id());
+        IndexShard indexShard = indexService.getShard(shardId.id());
         Term uidTerm = new Term(UidFieldMapper.NAME, Uid.createUidAsBytes(request.type(), request.id()));
         Engine.GetResult result = indexShard.get(new Engine.Get(false, uidTerm));
         if (!result.exists()) {
diff --git a/core/src/main/java/org/elasticsearch/action/fieldstats/TransportFieldStatsTransportAction.java b/core/src/main/java/org/elasticsearch/action/fieldstats/TransportFieldStatsTransportAction.java
index b029cb1..f92571a 100644
--- a/core/src/main/java/org/elasticsearch/action/fieldstats/TransportFieldStatsTransportAction.java
+++ b/core/src/main/java/org/elasticsearch/action/fieldstats/TransportFieldStatsTransportAction.java
@@ -152,7 +152,7 @@ public class TransportFieldStatsTransportAction extends TransportBroadcastAction
         Map<String, FieldStats> fieldStats = new HashMap<>();
         IndexService indexServices = indicesService.indexServiceSafe(shardId.getIndex());
         MapperService mapperService = indexServices.mapperService();
-        IndexShard shard = indexServices.shardSafe(shardId.id());
+        IndexShard shard = indexServices.getShard(shardId.id());
         try (Engine.Searcher searcher = shard.acquireSearcher("fieldstats")) {
             for (String field : request.getFields()) {
                 MappedFieldType fieldType = mapperService.fullName(field);
diff --git a/core/src/main/java/org/elasticsearch/action/get/TransportGetAction.java b/core/src/main/java/org/elasticsearch/action/get/TransportGetAction.java
index cba68bd..0bcadd6 100644
--- a/core/src/main/java/org/elasticsearch/action/get/TransportGetAction.java
+++ b/core/src/main/java/org/elasticsearch/action/get/TransportGetAction.java
@@ -92,7 +92,7 @@ public class TransportGetAction extends TransportSingleShardAction<GetRequest, G
     @Override
     protected GetResponse shardOperation(GetRequest request, ShardId shardId) {
         IndexService indexService = indicesService.indexServiceSafe(shardId.getIndex());
-        IndexShard indexShard = indexService.shardSafe(shardId.id());
+        IndexShard indexShard = indexService.getShard(shardId.id());
 
         if (request.refresh() && !request.realtime()) {
             indexShard.refresh("refresh_flag_get");
diff --git a/core/src/main/java/org/elasticsearch/action/get/TransportShardMultiGetAction.java b/core/src/main/java/org/elasticsearch/action/get/TransportShardMultiGetAction.java
index db72a87..1f07a5e 100644
--- a/core/src/main/java/org/elasticsearch/action/get/TransportShardMultiGetAction.java
+++ b/core/src/main/java/org/elasticsearch/action/get/TransportShardMultiGetAction.java
@@ -87,7 +87,7 @@ public class TransportShardMultiGetAction extends TransportSingleShardAction<Mul
     @Override
     protected MultiGetShardResponse shardOperation(MultiGetShardRequest request, ShardId shardId) {
         IndexService indexService = indicesService.indexServiceSafe(shardId.getIndex());
-        IndexShard indexShard = indexService.shardSafe(shardId.id());
+        IndexShard indexShard = indexService.getShard(shardId.id());
 
         if (request.refresh() && !request.realtime()) {
             indexShard.refresh("refresh_flag_mget");
diff --git a/core/src/main/java/org/elasticsearch/action/index/TransportIndexAction.java b/core/src/main/java/org/elasticsearch/action/index/TransportIndexAction.java
index 44fa4cf..3e98f1a 100644
--- a/core/src/main/java/org/elasticsearch/action/index/TransportIndexAction.java
+++ b/core/src/main/java/org/elasticsearch/action/index/TransportIndexAction.java
@@ -164,7 +164,7 @@ public class TransportIndexAction extends TransportReplicationAction<IndexReques
         }
 
         IndexService indexService = indicesService.indexServiceSafe(shardRequest.shardId.getIndex());
-        IndexShard indexShard = indexService.shardSafe(shardRequest.shardId.id());
+        IndexShard indexShard = indexService.getShard(shardRequest.shardId.id());
 
         final WriteResult<IndexResponse> result = executeIndexRequestOnPrimary(null, request, indexShard);
         final IndexResponse response = result.response;
@@ -176,7 +176,7 @@ public class TransportIndexAction extends TransportReplicationAction<IndexReques
     @Override
     protected void shardOperationOnReplica(ShardId shardId, IndexRequest request) {
         IndexService indexService = indicesService.indexServiceSafe(shardId.getIndex());
-        IndexShard indexShard = indexService.shardSafe(shardId.id());
+        IndexShard indexShard = indexService.getShard(shardId.id());
         SourceToParse sourceToParse = SourceToParse.source(SourceToParse.Origin.REPLICA, request.source()).index(shardId.getIndex()).type(request.type()).id(request.id())
                 .routing(request.routing()).parent(request.parent()).timestamp(request.timestamp()).ttl(request.ttl());
 
diff --git a/core/src/main/java/org/elasticsearch/action/suggest/TransportSuggestAction.java b/core/src/main/java/org/elasticsearch/action/suggest/TransportSuggestAction.java
index b6e6965..f44ed7b 100644
--- a/core/src/main/java/org/elasticsearch/action/suggest/TransportSuggestAction.java
+++ b/core/src/main/java/org/elasticsearch/action/suggest/TransportSuggestAction.java
@@ -130,7 +130,7 @@ public class TransportSuggestAction extends TransportBroadcastAction<SuggestRequ
     @Override
     protected ShardSuggestResponse shardOperation(ShardSuggestRequest request) {
         IndexService indexService = indicesService.indexServiceSafe(request.shardId().getIndex());
-        IndexShard indexShard = indexService.shardSafe(request.shardId().id());
+        IndexShard indexShard = indexService.getShard(request.shardId().id());
         ShardSuggestMetric suggestMetric = indexShard.getSuggestMetric();
         suggestMetric.preSuggest();
         long startTime = System.nanoTime();
diff --git a/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java b/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
index 63f55f2..d7fca31 100644
--- a/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
+++ b/core/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java
@@ -666,7 +666,7 @@ public abstract class TransportReplicationAction<Request extends ReplicationRequ
 
     protected Releasable getIndexShardOperationsCounter(ShardId shardId) {
         IndexService indexService = indicesService.indexServiceSafe(shardId.index().getName());
-        IndexShard indexShard = indexService.shardSafe(shardId.id());
+        IndexShard indexShard = indexService.getShard(shardId.id());
         return new IndexShardReference(indexShard);
     }
 
@@ -678,7 +678,7 @@ public abstract class TransportReplicationAction<Request extends ReplicationRequ
                 logger.debug("ignoring failed replica [{}][{}] because index was already removed.", index, shardId);
                 return;
             }
-            IndexShard indexShard = indexService.shard(shardId);
+            IndexShard indexShard = indexService.getShardOrNull(shardId);
             if (indexShard == null) {
                 logger.debug("ignoring failed replica [{}][{}] because index was already removed.", index, shardId);
                 return;
diff --git a/core/src/main/java/org/elasticsearch/action/termvectors/TransportShardMultiTermsVectorAction.java b/core/src/main/java/org/elasticsearch/action/termvectors/TransportShardMultiTermsVectorAction.java
index 4242e8d..c3a312a 100644
--- a/core/src/main/java/org/elasticsearch/action/termvectors/TransportShardMultiTermsVectorAction.java
+++ b/core/src/main/java/org/elasticsearch/action/termvectors/TransportShardMultiTermsVectorAction.java
@@ -79,7 +79,7 @@ public class TransportShardMultiTermsVectorAction extends TransportSingleShardAc
             TermVectorsRequest termVectorsRequest = request.requests.get(i);
             try {
                 IndexService indexService = indicesService.indexServiceSafe(request.index());
-                IndexShard indexShard = indexService.shardSafe(shardId.id());
+                IndexShard indexShard = indexService.getShard(shardId.id());
                 TermVectorsResponse termVectorsResponse = indexShard.getTermVectors(termVectorsRequest);
                 termVectorsResponse.updateTookInMillis(termVectorsRequest.startTime());
                 response.add(request.locations.get(i), termVectorsResponse);
diff --git a/core/src/main/java/org/elasticsearch/action/termvectors/TransportTermVectorsAction.java b/core/src/main/java/org/elasticsearch/action/termvectors/TransportTermVectorsAction.java
index 80ec12e..b790c21 100644
--- a/core/src/main/java/org/elasticsearch/action/termvectors/TransportTermVectorsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/termvectors/TransportTermVectorsAction.java
@@ -82,7 +82,7 @@ public class TransportTermVectorsAction extends TransportSingleShardAction<TermV
     @Override
     protected TermVectorsResponse shardOperation(TermVectorsRequest request, ShardId shardId) {
         IndexService indexService = indicesService.indexServiceSafe(shardId.getIndex());
-        IndexShard indexShard = indexService.shardSafe(shardId.id());
+        IndexShard indexShard = indexService.getShard(shardId.id());
         TermVectorsResponse response = indexShard.getTermVectors(request);
         response.updateTookInMillis(request.startTime());
         return response;
diff --git a/core/src/main/java/org/elasticsearch/action/update/TransportUpdateAction.java b/core/src/main/java/org/elasticsearch/action/update/TransportUpdateAction.java
index bbd1cbb..7479416 100644
--- a/core/src/main/java/org/elasticsearch/action/update/TransportUpdateAction.java
+++ b/core/src/main/java/org/elasticsearch/action/update/TransportUpdateAction.java
@@ -166,7 +166,7 @@ public class TransportUpdateAction extends TransportInstanceSingleOperationActio
 
     protected void shardOperation(final UpdateRequest request, final ActionListener<UpdateResponse> listener, final int retryCount) {
         IndexService indexService = indicesService.indexServiceSafe(request.concreteIndex());
-        IndexShard indexShard = indexService.shardSafe(request.shardId());
+        IndexShard indexShard = indexService.getShard(request.shardId());
         final UpdateHelper.Result result = updateHelper.prepare(request, indexShard);
         switch (result.operation()) {
             case UPSERT:
@@ -266,7 +266,7 @@ public class TransportUpdateAction extends TransportInstanceSingleOperationActio
                 UpdateResponse update = result.action();
                 IndexService indexServiceOrNull = indicesService.indexService(request.concreteIndex());
                 if (indexServiceOrNull !=  null) {
-                    IndexShard shard = indexService.shard(request.shardId());
+                    IndexShard shard = indexService.getShardOrNull(request.shardId());
                     if (shard != null) {
                         shard.indexingService().noopUpdate(request.type());
                     }
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapInfo.java b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapInfo.java
index 76485bb..f1278af 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/BootstrapInfo.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/BootstrapInfo.java
@@ -45,9 +45,16 @@ public final class BootstrapInfo {
     }
     
     /**
-     * Returns true if secure computing mode is enabled (linux/amd64 only)
+     * Returns true if secure computing mode is enabled (linux/amd64, OS X only)
      */
     public static boolean isSeccompInstalled() {
         return Natives.isSeccompInstalled();
     }
+
+    /**
+     * codebase location for untrusted scripts (provide some additional safety)
+     * <p>
+     * This is not a full URL, just a path.
+     */
+    public static final String UNTRUSTED_CODEBASE = "/untrusted";
 }
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java b/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java
index 9db66ca..ae993f2 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/ESPolicy.java
@@ -26,29 +26,27 @@ import java.net.URL;
 import java.security.CodeSource;
 import java.security.Permission;
 import java.security.PermissionCollection;
-import java.security.Permissions;
 import java.security.Policy;
 import java.security.ProtectionDomain;
 import java.security.URIParameter;
-import java.util.PropertyPermission;
 
 /** custom policy for union of static and dynamic permissions */
 final class ESPolicy extends Policy {
     
     /** template policy file, the one used in tests */
     static final String POLICY_RESOURCE = "security.policy";
-    /** limited policy for groovy scripts */
-    static final String GROOVY_RESOURCE = "groovy.policy";
+    /** limited policy for scripts */
+    static final String UNTRUSTED_RESOURCE = "untrusted.policy";
     
     final Policy template;
-    final Policy groovy;
+    final Policy untrusted;
     final PermissionCollection dynamic;
 
     public ESPolicy(PermissionCollection dynamic) throws Exception {
         URI policyUri = getClass().getResource(POLICY_RESOURCE).toURI();
-        URI groovyUri = getClass().getResource(GROOVY_RESOURCE).toURI();
+        URI untrustedUri = getClass().getResource(UNTRUSTED_RESOURCE).toURI();
         this.template = Policy.getInstance("JavaPolicy", new URIParameter(policyUri));
-        this.groovy = Policy.getInstance("JavaPolicy", new URIParameter(groovyUri));
+        this.untrusted = Policy.getInstance("JavaPolicy", new URIParameter(untrustedUri));
         this.dynamic = dynamic;
     }
 
@@ -56,15 +54,17 @@ final class ESPolicy extends Policy {
     public boolean implies(ProtectionDomain domain, Permission permission) {        
         CodeSource codeSource = domain.getCodeSource();
         // codesource can be null when reducing privileges via doPrivileged()
-        if (codeSource != null) {
-            URL location = codeSource.getLocation();
-            // location can be null... ??? nobody knows
-            // https://bugs.openjdk.java.net/browse/JDK-8129972
-            if (location != null) {
-                // run groovy scripts with no permissions (except logging property)
-                if ("/groovy/script".equals(location.getFile())) {
-                    return groovy.implies(domain, permission);
-                }
+        if (codeSource == null) {
+            return false;
+        }
+
+        URL location = codeSource.getLocation();
+        // location can be null... ??? nobody knows
+        // https://bugs.openjdk.java.net/browse/JDK-8129972
+        if (location != null) {
+            // run scripts with limited permissions
+            if (BootstrapInfo.UNTRUSTED_CODEBASE.equals(location.getFile())) {
+                return untrusted.implies(domain, permission);
             }
         }
 
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java
index 272bf61..99ce095 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java
@@ -203,6 +203,9 @@ public class MetaDataCreateIndexService extends AbstractComponent {
         if (state.metaData().hasAlias(index)) {
             throw new InvalidIndexNameException(new Index(index), index, "already exists as alias");
         }
+        if (index.equals(".") || index.equals("..")) {
+            throw new InvalidIndexNameException(new Index(index), index, "must not be '.' or '..'");
+        }
     }
 
     private void createIndex(final CreateIndexClusterStateUpdateRequest request, final ActionListener<ClusterStateUpdateResponse> listener, final Semaphore mdLock) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
index 9a6353a..e1a0b77 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
@@ -598,12 +598,12 @@ public class DiskThresholdDecider extends AllocationDecider {
             return allocation.decision(Decision.YES, NAME, "disk threshold decider disabled");
         }
 
-        // Allow allocation regardless if only a single node is available
-        if (allocation.nodes().size() <= 1) {
+        // Allow allocation regardless if only a single data node is available
+        if (allocation.nodes().dataNodes().size() <= 1) {
             if (logger.isTraceEnabled()) {
-                logger.trace("only a single node is present, allowing allocation");
+                logger.trace("only a single data node is present, allowing allocation");
             }
-            return allocation.decision(Decision.YES, NAME, "only a single node is present");
+            return allocation.decision(Decision.YES, NAME, "only a single data node is present");
         }
 
         // Fail open there is no info available
diff --git a/core/src/main/java/org/elasticsearch/common/hash/MessageDigests.java b/core/src/main/java/org/elasticsearch/common/hash/MessageDigests.java
new file mode 100644
index 0000000..7b3a108
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/common/hash/MessageDigests.java
@@ -0,0 +1,77 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.common.hash;
+
+import org.elasticsearch.ElasticsearchException;
+
+import java.security.MessageDigest;
+import java.security.NoSuchAlgorithmException;
+
+public class MessageDigests {
+
+    private static final MessageDigest MD5_DIGEST;
+    private static final MessageDigest SHA_1_DIGEST;
+    private static final MessageDigest SHA_256_DIGEST;
+
+    static {
+        try {
+            MD5_DIGEST = MessageDigest.getInstance("MD5");
+            SHA_1_DIGEST = MessageDigest.getInstance("SHA-1");
+            SHA_256_DIGEST = MessageDigest.getInstance("SHA-256");
+        } catch (NoSuchAlgorithmException e) {
+            throw new ElasticsearchException("Unexpected exception creating MessageDigest instance", e);
+        }
+    }
+
+    public static MessageDigest md5() {
+        return clone(MD5_DIGEST);
+    }
+
+    public static MessageDigest sha1() {
+        return clone(SHA_1_DIGEST);
+    }
+
+    public static MessageDigest sha256() {
+        return clone(SHA_256_DIGEST);
+    }
+
+    private static MessageDigest clone(MessageDigest messageDigest) {
+        try {
+            return (MessageDigest) messageDigest.clone();
+        } catch (CloneNotSupportedException e) {
+            throw new ElasticsearchException("Unexpected exception cloning MessageDigest instance", e);
+        }
+    }
+
+    private static final char[] HEX_DIGITS = "0123456789abcdef".toCharArray();
+    public static String toHexString(byte[] bytes) {
+        if (bytes == null) {
+            throw new NullPointerException("bytes");
+        }
+        StringBuilder sb = new StringBuilder(2 * bytes.length);
+
+        for (int i = 0; i < bytes.length; i++) {
+            byte b = bytes[i];
+            sb.append(HEX_DIGITS[b >> 4 & 0xf]).append(HEX_DIGITS[b & 0xf]);
+        }
+
+        return sb.toString();
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java b/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java
index ed2de6e..7fe26ed 100644
--- a/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java
+++ b/core/src/main/java/org/elasticsearch/common/http/client/HttpDownloadHelper.java
@@ -19,19 +19,22 @@
 
 package org.elasticsearch.common.http.client;
 
-import java.nio.charset.StandardCharsets;
-import com.google.common.hash.Hashing;
 import org.apache.lucene.util.IOUtils;
-import org.elasticsearch.*;
+import org.elasticsearch.Build;
+import org.elasticsearch.ElasticsearchCorruptionException;
+import org.elasticsearch.ElasticsearchTimeoutException;
+import org.elasticsearch.Version;
 import org.elasticsearch.common.Base64;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.hash.MessageDigests;
 import org.elasticsearch.common.unit.TimeValue;
 
 import java.io.*;
 import java.net.HttpURLConnection;
 import java.net.URL;
 import java.net.URLConnection;
+import java.nio.charset.StandardCharsets;
 import java.nio.file.Files;
 import java.nio.file.NoSuchFileException;
 import java.nio.file.Path;
@@ -96,7 +99,7 @@ public class HttpDownloadHelper {
     public static Checksummer SHA1_CHECKSUM = new Checksummer() {
         @Override
         public String checksum(byte[] filebytes) {
-            return Hashing.sha1().hashBytes(filebytes).toString();
+            return MessageDigests.toHexString(MessageDigests.sha1().digest(filebytes));
         }
 
         @Override
@@ -109,7 +112,7 @@ public class HttpDownloadHelper {
     public static Checksummer MD5_CHECKSUM = new Checksummer() {
         @Override
         public String checksum(byte[] filebytes) {
-            return Hashing.md5().hashBytes(filebytes).toString();
+            return MessageDigests.toHexString(MessageDigests.md5().digest(filebytes));
         }
 
         @Override
diff --git a/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java b/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java
index 21c4cdd..8f92864 100644
--- a/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java
+++ b/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java
@@ -90,12 +90,14 @@ public class LogConfigurator {
         loaded = true;
         // TODO: this is partly a copy of InternalSettingsPreparer...we should pass in Environment and not do all this...
         Environment environment = new Environment(settings);
-        Settings.Builder settingsBuilder = settingsBuilder().put(settings);
+        Settings.Builder settingsBuilder = settingsBuilder();
         resolveConfig(environment, settingsBuilder);
         settingsBuilder
                 .putProperties("elasticsearch.", System.getProperties())
-                .putProperties("es.", System.getProperties())
-                .replacePropertyPlaceholders();
+                .putProperties("es.", System.getProperties());
+        // add custom settings after config was added so that they are not overwritten by config
+        settingsBuilder.put(settings);
+        settingsBuilder.replacePropertyPlaceholders();
         Properties props = new Properties();
         for (Map.Entry<String, String> entry : settingsBuilder.build().getAsMap().entrySet()) {
             String key = "log4j." + entry.getKey();
diff --git a/core/src/main/java/org/elasticsearch/index/IndexModule.java b/core/src/main/java/org/elasticsearch/index/IndexModule.java
index d94eb4f..1929848 100644
--- a/core/src/main/java/org/elasticsearch/index/IndexModule.java
+++ b/core/src/main/java/org/elasticsearch/index/IndexModule.java
@@ -20,21 +20,37 @@
 package org.elasticsearch.index;
 
 import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.inject.util.Providers;
+import org.elasticsearch.index.aliases.IndexAliasesService;
+import org.elasticsearch.index.engine.EngineFactory;
+import org.elasticsearch.index.engine.InternalEngineFactory;
+import org.elasticsearch.index.fielddata.IndexFieldDataService;
+import org.elasticsearch.index.mapper.MapperService;
+import org.elasticsearch.index.shard.IndexSearcherWrapper;
 
 /**
  *
  */
 public class IndexModule extends AbstractModule {
 
-    private final Settings settings;
-
-    public IndexModule(Settings settings) {
-        this.settings = settings;
-    }
-
+    // pkg private so tests can mock
+    Class<? extends EngineFactory> engineFactoryImpl = InternalEngineFactory.class;
+    Class<? extends IndexSearcherWrapper> indexSearcherWrapper = null;
+    
     @Override
     protected void configure() {
+        bind(EngineFactory.class).to(engineFactoryImpl).asEagerSingleton();
+        if (indexSearcherWrapper == null) {
+            bind(IndexSearcherWrapper.class).toProvider(Providers.of(null));
+        } else {
+            bind(IndexSearcherWrapper.class).to(indexSearcherWrapper).asEagerSingleton();
+        }
         bind(IndexService.class).asEagerSingleton();
+        bind(IndexServicesProvider.class).asEagerSingleton();
+        bind(MapperService.class).asEagerSingleton();
+        bind(IndexAliasesService.class).asEagerSingleton();
+        bind(IndexFieldDataService.class).asEagerSingleton();
     }
+
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/IndexService.java b/core/src/main/java/org/elasticsearch/index/IndexService.java
index 3c40b02..2fc7a24 100644
--- a/core/src/main/java/org/elasticsearch/index/IndexService.java
+++ b/core/src/main/java/org/elasticsearch/index/IndexService.java
@@ -24,16 +24,9 @@ import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.inject.CreationException;
 import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.inject.Injector;
-import org.elasticsearch.common.inject.Injectors;
-import org.elasticsearch.common.inject.Module;
-import org.elasticsearch.common.inject.ModulesBuilder;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.env.NodeEnvironment;
 import org.elasticsearch.env.ShardLock;
@@ -49,20 +42,12 @@ import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.settings.IndexSettingsService;
-import org.elasticsearch.index.shard.IndexShard;
-import org.elasticsearch.index.shard.IndexShardModule;
-import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.shard.ShardNotFoundException;
-import org.elasticsearch.index.shard.ShardPath;
+import org.elasticsearch.index.shard.*;
 import org.elasticsearch.index.similarity.SimilarityService;
 import org.elasticsearch.index.store.IndexStore;
 import org.elasticsearch.index.store.Store;
-import org.elasticsearch.index.store.StoreModule;
-import org.elasticsearch.indices.IndicesLifecycle;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.indices.InternalIndicesLifecycle;
-import org.elasticsearch.indices.cache.query.IndicesQueryCache;
-import org.elasticsearch.plugins.PluginsService;
 
 import java.io.Closeable;
 import java.io.IOException;
@@ -81,86 +66,42 @@ import static org.elasticsearch.common.collect.MapBuilder.newMapBuilder;
  */
 public class IndexService extends AbstractIndexComponent implements IndexComponent, Iterable<IndexShard> {
 
-    private final Injector injector;
-
     private final Settings indexSettings;
-
-    private final PluginsService pluginsService;
-
     private final InternalIndicesLifecycle indicesLifecycle;
-
     private final AnalysisService analysisService;
-
-    private final MapperService mapperService;
-
-    private final IndexQueryParserService queryParserService;
-
-    private final SimilarityService similarityService;
-
-    private final IndexAliasesService aliasesService;
-
-    private final IndexCache indexCache;
-
     private final IndexFieldDataService indexFieldData;
-
     private final BitsetFilterCache bitsetFilterCache;
-
     private final IndexSettingsService settingsService;
-
     private final NodeEnvironment nodeEnv;
     private final IndicesService indicesServices;
-
-    private volatile ImmutableMap<Integer, IndexShardInjectorPair> shards = ImmutableMap.of();
-
-    private static class IndexShardInjectorPair {
-        private final IndexShard indexShard;
-        private final Injector injector;
-
-        public IndexShardInjectorPair(IndexShard indexShard, Injector injector) {
-            this.indexShard = indexShard;
-            this.injector = injector;
-        }
-
-        public IndexShard getIndexShard() {
-            return indexShard;
-        }
-
-        public Injector getInjector() {
-            return injector;
-        }
-    }
-
+    private final IndexServicesProvider indexServicesProvider;
+    private final IndexStore indexStore;
+    private volatile ImmutableMap<Integer, IndexShard> shards = ImmutableMap.of();
     private final AtomicBoolean closed = new AtomicBoolean(false);
     private final AtomicBoolean deleted = new AtomicBoolean(false);
 
     @Inject
-    public IndexService(Injector injector, Index index, @IndexSettings Settings indexSettings, NodeEnvironment nodeEnv,
-                        AnalysisService analysisService, MapperService mapperService, IndexQueryParserService queryParserService,
-                        SimilarityService similarityService, IndexAliasesService aliasesService, IndexCache indexCache,
+    public IndexService(Index index, @IndexSettings Settings indexSettings, NodeEnvironment nodeEnv,
+                        AnalysisService analysisService,
                         IndexSettingsService settingsService,
-                        IndexFieldDataService indexFieldData, BitsetFilterCache bitSetFilterCache, IndicesService indicesServices) {
-
+                        IndexFieldDataService indexFieldData,
+                        BitsetFilterCache bitSetFilterCache,
+                        IndicesService indicesServices,
+                        IndexServicesProvider indexServicesProvider,
+                        IndexStore indexStore) {
         super(index, indexSettings);
-        this.injector = injector;
         this.indexSettings = indexSettings;
         this.analysisService = analysisService;
-        this.mapperService = mapperService;
-        this.queryParserService = queryParserService;
-        this.similarityService = similarityService;
-        this.aliasesService = aliasesService;
-        this.indexCache = indexCache;
         this.indexFieldData = indexFieldData;
         this.settingsService = settingsService;
         this.bitsetFilterCache = bitSetFilterCache;
-
-        this.pluginsService = injector.getInstance(PluginsService.class);
         this.indicesServices = indicesServices;
-        this.indicesLifecycle = (InternalIndicesLifecycle) injector.getInstance(IndicesLifecycle.class);
-
-        // inject workarounds for cyclic dep
+        this.indicesLifecycle = (InternalIndicesLifecycle) indexServicesProvider.getIndicesLifecycle();
+        this.nodeEnv = nodeEnv;
+        this.indexServicesProvider = indexServicesProvider;
+        this.indexStore = indexStore;
         indexFieldData.setListener(new FieldDataCacheListener(this));
         bitSetFilterCache.setListener(new BitsetCacheListener(this));
-        this.nodeEnv = nodeEnv;
     }
 
     public int numberOfShards() {
@@ -173,7 +114,7 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
 
     @Override
     public Iterator<IndexShard> iterator() {
-        return shards.values().stream().map((p) -> p.getIndexShard()).iterator();
+        return shards.values().iterator();
     }
 
     public boolean hasShard(int shardId) {
@@ -184,19 +125,15 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
      * Return the shard with the provided id, or null if there is no such shard.
      */
     @Nullable
-    public IndexShard shard(int shardId) {
-        IndexShardInjectorPair indexShardInjectorPair = shards.get(shardId);
-        if (indexShardInjectorPair != null) {
-            return indexShardInjectorPair.getIndexShard();
-        }
-        return null;
+    public IndexShard getShardOrNull(int shardId) {
+         return shards.get(shardId);
     }
 
     /**
      * Return the shard with the provided id, or throw an exception if it doesn't exist.
      */
-    public IndexShard shardSafe(int shardId) {
-        IndexShard indexShard = shard(shardId);
+    public IndexShard getShard(int shardId) {
+        IndexShard indexShard = getShardOrNull(shardId);
         if (indexShard == null) {
             throw new ShardNotFoundException(new ShardId(index, shardId));
         }
@@ -207,16 +144,12 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
         return shards.keySet();
     }
 
-    public Injector injector() {
-        return injector;
-    }
-
     public IndexSettingsService settingsService() {
         return this.settingsService;
     }
 
     public IndexCache cache() {
-        return indexCache;
+        return indexServicesProvider.getIndexCache();
     }
 
     public IndexFieldDataService fieldData() {
@@ -232,19 +165,19 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
     }
 
     public MapperService mapperService() {
-        return mapperService;
+        return indexServicesProvider.getMapperService();
     }
 
     public IndexQueryParserService queryParserService() {
-        return queryParserService;
+        return indexServicesProvider.getQueryParserService();
     }
 
     public SimilarityService similarityService() {
-        return similarityService;
+        return indexServicesProvider.getSimilarityService();
     }
 
     public IndexAliasesService aliasesService() {
-        return aliasesService;
+        return indexServicesProvider.getIndexAliasesService();
     }
 
     public synchronized void close(final String reason, boolean delete) {
@@ -261,16 +194,6 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
         }
     }
 
-    /**
-     * Return the shard injector for the provided id, or throw an exception if there is no such shard.
-     */
-    public Injector shardInjectorSafe(int shardId)  {
-        IndexShardInjectorPair indexShardInjectorPair = shards.get(shardId);
-        if (indexShardInjectorPair == null) {
-            throw new ShardNotFoundException(new ShardId(index, shardId));
-        }
-        return indexShardInjectorPair.getInjector();
-    }
 
     public String indexUUID() {
         return indexSettings.get(IndexMetaData.SETTING_INDEX_UUID, IndexMetaData.INDEX_UUID_NA_VALUE);
@@ -301,10 +224,14 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
         if (closed.get()) {
             throw new IllegalStateException("Can't create shard [" + index.name() + "][" + sShardId + "], closed");
         }
+        if (indexSettings.get("index.translog.type") != null) { // TODO remove?
+            throw new IllegalStateException("a custom translog type is no longer supported. got [" + indexSettings.get("index.translog.type") + "]");
+        }
         final ShardId shardId = new ShardId(index, sShardId);
         ShardLock lock = null;
         boolean success = false;
-        Injector shardInjector = null;
+        Store store = null;
+        IndexShard indexShard = null;
         try {
             lock = nodeEnv.shardLock(shardId, TimeUnit.SECONDS.toMillis(5));
             indicesLifecycle.beforeIndexShardCreated(shardId, indexSettings);
@@ -325,7 +252,6 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
             if (path == null) {
                 // TODO: we should, instead, hold a "bytes reserved" of how large we anticipate this shard will be, e.g. for a shard
                 // that's being relocated/replicated we know how large it will become once it's done copying:
-
                 // Count up how many shards are currently on each data path:
                 Map<Path,Integer> dataPathToShardCount = new HashMap<>();
                 for(IndexShard shard : this) {
@@ -351,39 +277,17 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
             // if we are on a shared FS we only own the shard (ie. we can safely delete it) if we are the primary.
             final boolean canDeleteShardContent = IndexMetaData.isOnSharedFilesystem(indexSettings) == false ||
                     (primary && IndexMetaData.isOnSharedFilesystem(indexSettings));
-            ModulesBuilder modules = new ModulesBuilder();
-            // plugin modules must be added here, before others or we can get crazy injection errors...
-            for (Module pluginModule : pluginsService.shardModules(indexSettings)) {
-                modules.add(pluginModule);
-            }
-            modules.add(new IndexShardModule(shardId, primary, indexSettings));
-            modules.add(new StoreModule(injector.getInstance(IndexStore.class).shardDirectory(), lock,
-                    new StoreCloseListener(shardId, canDeleteShardContent,  new Closeable() {
-                        @Override
-                        public void close() throws IOException {
-                            injector.getInstance(IndicesQueryCache.class).onClose(shardId);
-                        }
-                    }), path));
-            pluginsService.processModules(modules);
-
-            try {
-                shardInjector = modules.createChildInjector(injector);
-            } catch (CreationException e) {
-                ElasticsearchException ex = new ElasticsearchException("failed to create shard", Injectors.getFirstErrorFailure(e));
-                ex.setShard(shardId);
-                throw ex;
-            } catch (Throwable e) {
-                ElasticsearchException ex = new ElasticsearchException("failed to create shard", e);
-                ex.setShard(shardId);
-                throw ex;
+            store = new Store(shardId, indexSettings, indexStore.newDirectoryService(path), lock, new StoreCloseListener(shardId, canDeleteShardContent, () -> indexServicesProvider.getIndicesQueryCache().onClose(shardId)));
+            if (useShadowEngine(primary, indexSettings)) {
+                indexShard = new ShadowIndexShard(shardId, indexSettings, path, store, indexServicesProvider);
+            } else {
+                indexShard = new IndexShard(shardId, indexSettings, path, store, indexServicesProvider);
             }
 
-            IndexShard indexShard = shardInjector.getInstance(IndexShard.class);
             indicesLifecycle.indexShardStateChanged(indexShard, null, "shard created");
             indicesLifecycle.afterIndexShardCreated(indexShard);
-
-            shards = newMapBuilder(shards).put(shardId.id(), new IndexShardInjectorPair(indexShard, shardInjector)).immutableMap();
             settingsService.addListener(indexShard);
+            shards = newMapBuilder(shards).put(shardId.id(), indexShard).immutableMap();
             success = true;
             return indexShard;
         } catch (IOException e) {
@@ -393,45 +297,35 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
         } finally {
             if (success == false) {
                 IOUtils.closeWhileHandlingException(lock);
-                if (shardInjector != null) {
-                    IndexShard indexShard = shardInjector.getInstance(IndexShard.class);
-                    closeShardInjector("initialization failed", shardId, shardInjector, indexShard);
-                }
+                closeShard("initialization failed", shardId, indexShard, store);
             }
         }
     }
 
+    static boolean useShadowEngine(boolean primary, Settings indexSettings) {
+        return primary == false && IndexMetaData.isIndexUsingShadowReplicas(indexSettings);
+    }
+
     public synchronized void removeShard(int shardId, String reason) {
         final ShardId sId = new ShardId(index, shardId);
-        final Injector shardInjector;
         final IndexShard indexShard;
         if (shards.containsKey(shardId) == false) {
             return;
         }
         logger.debug("[{}] closing... (reason: [{}])", shardId, reason);
-        HashMap<Integer, IndexShardInjectorPair> tmpShardsMap = new HashMap<>(shards);
-        IndexShardInjectorPair indexShardInjectorPair = tmpShardsMap.remove(shardId);
-        indexShard = indexShardInjectorPair.getIndexShard();
-        shardInjector = indexShardInjectorPair.getInjector();
+        HashMap<Integer, IndexShard> tmpShardsMap = new HashMap<>(shards);
+        indexShard = tmpShardsMap.remove(shardId);
         shards = ImmutableMap.copyOf(tmpShardsMap);
-        closeShardInjector(reason, sId, shardInjector, indexShard);
+        closeShard(reason, sId, indexShard, indexShard.store());
         logger.debug("[{}] closed (reason: [{}])", shardId, reason);
     }
 
-    private void closeShardInjector(String reason, ShardId sId, Injector shardInjector, IndexShard indexShard) {
+    private void closeShard(String reason, ShardId sId, IndexShard indexShard, Store store) {
         final int shardId = sId.id();
         try {
             try {
                 indicesLifecycle.beforeIndexShardClosed(sId, indexShard, indexSettings);
             } finally {
-                // close everything else even if the beforeIndexShardClosed threw an exception
-                for (Class<? extends Closeable> closeable : pluginsService.shardServices()) {
-                    try {
-                        shardInjector.getInstance(closeable).close();
-                    } catch (Throwable e) {
-                        logger.debug("[{}] failed to clean plugin shard service [{}]", e, shardId, closeable);
-                    }
-                }
                 // this logic is tricky, we want to close the engine so we rollback the changes done to it
                 // and close the shard so no operations are allowed to it
                 if (indexShard != null) {
@@ -449,30 +343,13 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
             }
         } finally {
             try {
-                shardInjector.getInstance(Store.class).close();
+                store.close();
             } catch (Throwable e) {
                 logger.warn("[{}] failed to close store on shard removal (reason: [{}])", e, shardId, reason);
             }
         }
     }
 
-    /**
-     * Closes an optional resource. Returns true if the resource was found;
-     * NOTE: this method swallows all exceptions thrown from the close method of the injector and logs them as debug log
-     */
-    private boolean closeInjectorOptionalResource(ShardId shardId, Injector shardInjector, Class<? extends Closeable> toClose) {
-        try {
-            final Closeable instance = shardInjector.getInstance(toClose);
-            if (instance == null) {
-                return false;
-            }
-            IOUtils.close(instance);
-        } catch (Throwable t) {
-            logger.debug("{} failed to close {}", t, shardId, Strings.toUnderscoreCase(toClose.getSimpleName()));
-        }
-        return true;
-    }
-
 
     private void onShardClose(ShardLock lock, boolean ownsShard) {
         if (deleted.get()) { // we remove that shards content if this index has been deleted
@@ -492,6 +369,10 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
         }
     }
 
+    public IndexServicesProvider getIndexServices() {
+        return indexServicesProvider;
+    }
+
     private class StoreCloseListener implements Store.OnClose {
         private final ShardId shardId;
         private final boolean ownsShard;
@@ -533,7 +414,7 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
         @Override
         public void onCache(ShardId shardId, Accountable accountable) {
             if (shardId != null) {
-                final IndexShard shard = indexService.shard(shardId.id());
+                final IndexShard shard = indexService.getShardOrNull(shardId.id());
                 if (shard != null) {
                     long ramBytesUsed = accountable != null ? accountable.ramBytesUsed() : 0l;
                     shard.shardBitsetFilterCache().onCached(ramBytesUsed);
@@ -544,7 +425,7 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
         @Override
         public void onRemoval(ShardId shardId, Accountable accountable) {
             if (shardId != null) {
-                final IndexShard shard = indexService.shard(shardId.id());
+                final IndexShard shard = indexService.getShardOrNull(shardId.id());
                 if (shard != null) {
                     long ramBytesUsed = accountable != null ? accountable.ramBytesUsed() : 0l;
                     shard.shardBitsetFilterCache().onRemoval(ramBytesUsed);
@@ -563,7 +444,7 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
         @Override
         public void onCache(ShardId shardId, MappedFieldType.Names fieldNames, FieldDataType fieldDataType, Accountable ramUsage) {
             if (shardId != null) {
-                final IndexShard shard = indexService.shard(shardId.id());
+                final IndexShard shard = indexService.getShardOrNull(shardId.id());
                 if (shard != null) {
                     shard.fieldData().onCache(shardId, fieldNames, fieldDataType, ramUsage);
                 }
@@ -573,7 +454,7 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
         @Override
         public void onRemoval(ShardId shardId, MappedFieldType.Names fieldNames, FieldDataType fieldDataType, boolean wasEvicted, long sizeInBytes) {
             if (shardId != null) {
-                final IndexShard shard = indexService.shard(shardId.id());
+                final IndexShard shard = indexService.getShardOrNull(shardId.id());
                 if (shard != null) {
                     shard.fieldData().onRemoval(shardId, fieldNames, fieldDataType, wasEvicted, sizeInBytes);
                 }
diff --git a/core/src/main/java/org/elasticsearch/index/IndexServicesProvider.java b/core/src/main/java/org/elasticsearch/index/IndexServicesProvider.java
new file mode 100644
index 0000000..fe84284
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/IndexServicesProvider.java
@@ -0,0 +1,138 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.index;
+
+import org.elasticsearch.common.Nullable;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.util.BigArrays;
+import org.elasticsearch.index.aliases.IndexAliasesService;
+import org.elasticsearch.index.cache.IndexCache;
+import org.elasticsearch.index.codec.CodecService;
+import org.elasticsearch.index.engine.EngineFactory;
+import org.elasticsearch.index.fielddata.IndexFieldDataService;
+import org.elasticsearch.index.mapper.MapperService;
+import org.elasticsearch.index.query.IndexQueryParserService;
+import org.elasticsearch.index.shard.IndexSearcherWrapper;
+import org.elasticsearch.index.similarity.SimilarityService;
+import org.elasticsearch.index.termvectors.TermVectorsService;
+import org.elasticsearch.indices.IndicesLifecycle;
+import org.elasticsearch.indices.IndicesWarmer;
+import org.elasticsearch.indices.cache.query.IndicesQueryCache;
+import org.elasticsearch.threadpool.ThreadPool;
+
+/**
+ * Simple provider class that holds the Index and Node level services used by
+ * a shard.
+ * This is just a temporary solution until we cleaned up index creation and removed injectors on that level as well.
+ */
+public final class IndexServicesProvider {
+
+    private final IndicesLifecycle indicesLifecycle;
+    private final ThreadPool threadPool;
+    private final MapperService mapperService;
+    private final IndexQueryParserService queryParserService;
+    private final IndexCache indexCache;
+    private final IndexAliasesService indexAliasesService;
+    private final IndicesQueryCache indicesQueryCache;
+    private final CodecService codecService;
+    private final TermVectorsService termVectorsService;
+    private final IndexFieldDataService indexFieldDataService;
+    private final IndicesWarmer warmer;
+    private final SimilarityService similarityService;
+    private final EngineFactory factory;
+    private final BigArrays bigArrays;
+    private final IndexSearcherWrapper indexSearcherWrapper;
+
+    @Inject
+    public IndexServicesProvider(IndicesLifecycle indicesLifecycle, ThreadPool threadPool, MapperService mapperService, IndexQueryParserService queryParserService, IndexCache indexCache, IndexAliasesService indexAliasesService, IndicesQueryCache indicesQueryCache, CodecService codecService, TermVectorsService termVectorsService, IndexFieldDataService indexFieldDataService, @Nullable IndicesWarmer warmer, SimilarityService similarityService, EngineFactory factory, BigArrays bigArrays, @Nullable IndexSearcherWrapper indexSearcherWrapper) {
+        this.indicesLifecycle = indicesLifecycle;
+        this.threadPool = threadPool;
+        this.mapperService = mapperService;
+        this.queryParserService = queryParserService;
+        this.indexCache = indexCache;
+        this.indexAliasesService = indexAliasesService;
+        this.indicesQueryCache = indicesQueryCache;
+        this.codecService = codecService;
+        this.termVectorsService = termVectorsService;
+        this.indexFieldDataService = indexFieldDataService;
+        this.warmer = warmer;
+        this.similarityService = similarityService;
+        this.factory = factory;
+        this.bigArrays = bigArrays;
+        this.indexSearcherWrapper = indexSearcherWrapper;
+    }
+
+    public IndicesLifecycle getIndicesLifecycle() {
+        return indicesLifecycle;
+    }
+
+    public ThreadPool getThreadPool() {
+        return threadPool;
+    }
+
+    public MapperService getMapperService() {
+        return mapperService;
+    }
+
+    public IndexQueryParserService getQueryParserService() {
+        return queryParserService;
+    }
+
+    public IndexCache getIndexCache() {
+        return indexCache;
+    }
+
+    public IndexAliasesService getIndexAliasesService() {
+        return indexAliasesService;
+    }
+
+    public IndicesQueryCache getIndicesQueryCache() {
+        return indicesQueryCache;
+    }
+
+    public CodecService getCodecService() {
+        return codecService;
+    }
+
+    public TermVectorsService getTermVectorsService() {
+        return termVectorsService;
+    }
+
+    public IndexFieldDataService getIndexFieldDataService() {
+        return indexFieldDataService;
+    }
+
+    public IndicesWarmer getWarmer() {
+        return warmer;
+    }
+
+    public SimilarityService getSimilarityService() {
+        return similarityService;
+    }
+
+    public EngineFactory getFactory() {
+        return factory;
+    }
+
+    public BigArrays getBigArrays() {
+        return bigArrays;
+    }
+
+    public IndexSearcherWrapper getIndexSearcherWrapper() { return indexSearcherWrapper; }
+}
diff --git a/core/src/main/java/org/elasticsearch/index/aliases/IndexAliasesServiceModule.java b/core/src/main/java/org/elasticsearch/index/aliases/IndexAliasesServiceModule.java
deleted file mode 100644
index 1bb9a58..0000000
--- a/core/src/main/java/org/elasticsearch/index/aliases/IndexAliasesServiceModule.java
+++ /dev/null
@@ -1,33 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.aliases;
-
-import org.elasticsearch.common.inject.AbstractModule;
-
-/**
- *
- */
-public class IndexAliasesServiceModule extends AbstractModule {
-
-    @Override
-    protected void configure() {
-        bind(IndexAliasesService.class).asEagerSingleton();
-    }
-}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/engine/Engine.java b/core/src/main/java/org/elasticsearch/index/engine/Engine.java
index 83bc0ae..1330ef0 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/Engine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/Engine.java
@@ -59,6 +59,8 @@ import java.util.concurrent.locks.Condition;
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReentrantLock;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
+import java.util.function.Function;
+import java.util.function.Supplier;
 
 /**
  *
@@ -78,7 +80,6 @@ public abstract class Engine implements Closeable {
     protected final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
     protected final ReleasableLock readLock = new ReleasableLock(rwl.readLock());
     protected final ReleasableLock writeLock = new ReleasableLock(rwl.writeLock());
-
     protected volatile Throwable failedEngine = null;
 
     protected Engine(EngineConfig engineConfig) {
@@ -227,8 +228,8 @@ public abstract class Engine implements Closeable {
         PENDING_OPERATIONS
     }
 
-    final protected GetResult getFromSearcher(Get get) throws EngineException {
-        final Searcher searcher = acquireSearcher("get");
+    final protected GetResult getFromSearcher(Get get, Function<String, Searcher> searcherFactory) throws EngineException {
+        final Searcher searcher = searcherFactory.apply("get");
         final Versions.DocIdAndVersion docIdAndVersion;
         try {
             docIdAndVersion = Versions.loadDocIdAndVersion(searcher.reader(), get.uid());
@@ -256,7 +257,11 @@ public abstract class Engine implements Closeable {
         }
     }
 
-    public abstract GetResult get(Get get) throws EngineException;
+    public final GetResult get(Get get) throws EngineException {
+        return get(get, this::acquireSearcher);
+    }
+
+    public abstract GetResult get(Get get, Function<String, Searcher> searcherFactory) throws EngineException;
 
     /**
      * Returns a new searcher instance. The consumer of this
@@ -279,7 +284,7 @@ public abstract class Engine implements Closeable {
             try {
                 final Searcher retVal = newSearcher(source, searcher, manager);
                 success = true;
-                return config().getWrappingService().wrap(engineConfig, retVal);
+                return retVal;
             } finally {
                 if (!success) {
                     manager.release(searcher);
@@ -361,9 +366,6 @@ public abstract class Engine implements Closeable {
         stats.addIndexWriterMaxMemoryInBytes(0);
     }
 
-    /** How much heap Lucene's IndexWriter is using */
-    abstract public long indexWriterRAMBytesUsed();
-
     protected Segment[] getSegmentInfo(SegmentInfos lastCommittedSegmentInfos, boolean verbose) {
         ensureOpen();
         Map<String, Segment> segments = new HashMap<>();
@@ -621,11 +623,6 @@ public abstract class Engine implements Closeable {
         Type opType();
 
         Origin origin();
-
-        /**
-         * Returns operation start time in nanoseconds.
-         */
-        long startTime();
     }
 
     public static abstract class IndexingOperation implements Operation {
@@ -719,7 +716,9 @@ public abstract class Engine implements Closeable {
             return this.doc.source();
         }
 
-        @Override
+        /**
+         * Returns operation start time in nanoseconds.
+         */
         public long startTime() {
             return this.startTime;
         }
@@ -859,7 +858,9 @@ public abstract class Engine implements Closeable {
             return this.found;
         }
 
-        @Override
+        /**
+         * Returns operation start time in nanoseconds.
+         */
         public long startTime() {
             return this.startTime;
         }
diff --git a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
index c6e6724..a79587e 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
@@ -25,6 +25,7 @@ import org.apache.lucene.index.SnapshotDeletionPolicy;
 import org.apache.lucene.search.QueryCache;
 import org.apache.lucene.search.QueryCachingPolicy;
 import org.apache.lucene.search.similarities.Similarity;
+import org.apache.lucene.util.SetOnce;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.ByteSizeUnit;
@@ -32,6 +33,7 @@ import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.index.codec.CodecService;
 import org.elasticsearch.index.indexing.ShardIndexingService;
+import org.elasticsearch.index.shard.IndexSearcherWrapper;
 import org.elasticsearch.index.shard.MergeSchedulerConfig;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.index.shard.TranslogRecoveryPerformer;
@@ -73,7 +75,7 @@ public final class EngineConfig {
     private final boolean forceNewTranslog;
     private final QueryCache queryCache;
     private final QueryCachingPolicy queryCachingPolicy;
-    private final IndexSearcherWrappingService wrappingService;
+    private final SetOnce<IndexSearcherWrapper> searcherWrapper = new SetOnce<>();
 
     /**
      * Index setting for compound file on flush. This setting is realtime updateable.
@@ -121,7 +123,7 @@ public final class EngineConfig {
                         Settings indexSettings, IndicesWarmer warmer, Store store, SnapshotDeletionPolicy deletionPolicy,
                         MergePolicy mergePolicy, MergeSchedulerConfig mergeSchedulerConfig, Analyzer analyzer,
                         Similarity similarity, CodecService codecService, Engine.FailedEngineListener failedEngineListener,
-                        TranslogRecoveryPerformer translogRecoveryPerformer, QueryCache queryCache, QueryCachingPolicy queryCachingPolicy, IndexSearcherWrappingService wrappingService, TranslogConfig translogConfig) {
+                        TranslogRecoveryPerformer translogRecoveryPerformer, QueryCache queryCache, QueryCachingPolicy queryCachingPolicy, TranslogConfig translogConfig) {
         this.shardId = shardId;
         this.indexSettings = indexSettings;
         this.threadPool = threadPool;
@@ -135,7 +137,6 @@ public final class EngineConfig {
         this.similarity = similarity;
         this.codecService = codecService;
         this.failedEngineListener = failedEngineListener;
-        this.wrappingService = wrappingService;
         this.compoundOnFlush = indexSettings.getAsBoolean(EngineConfig.INDEX_COMPOUND_ON_FLUSH, compoundOnFlush);
         codecName = indexSettings.get(EngineConfig.INDEX_CODEC_SETTING, EngineConfig.DEFAULT_CODEC_NAME);
         indexingBufferSize = DEFAULT_INDEX_BUFFER_SIZE;
@@ -380,10 +381,6 @@ public final class EngineConfig {
         return queryCachingPolicy;
     }
 
-    public IndexSearcherWrappingService getWrappingService() {
-        return wrappingService;
-    }
-
     /**
      * Returns the translog config for this engine
      */
diff --git a/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrapper.java b/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrapper.java
deleted file mode 100644
index 665d17a..0000000
--- a/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrapper.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.engine;
-
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.search.IndexSearcher;
-
-/**
- * Extension point to add custom functionality at request time to the {@link DirectoryReader}
- * and {@link IndexSearcher} managed by the {@link Engine}.
- */
-public interface IndexSearcherWrapper {
-
-    /**
-     * @param reader The provided directory reader to be wrapped to add custom functionality
-     * @return a new directory reader wrapping the provided directory reader or if no wrapping was performed
-     *         the provided directory reader
-     */
-    DirectoryReader wrap(DirectoryReader reader);
-
-    /**
-     * @param engineConfig  The engine config which can be used to get the query cache and query cache policy from
-     *                      when creating a new index searcher
-     * @param searcher      The provided index searcher to be wrapped to add custom functionality
-     * @return a new index searcher wrapping the provided index searcher or if no wrapping was performed
-     *         the provided index searcher
-     */
-    IndexSearcher wrap(EngineConfig engineConfig, IndexSearcher searcher) throws EngineException;
-
-}
diff --git a/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrappingService.java b/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrappingService.java
deleted file mode 100644
index 23d05f0..0000000
--- a/core/src/main/java/org/elasticsearch/index/engine/IndexSearcherWrappingService.java
+++ /dev/null
@@ -1,94 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.engine;
-
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.search.IndexSearcher;
-import org.elasticsearch.ElasticsearchException;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.index.engine.Engine.Searcher;
-
-import java.util.Set;
-
-/**
- * Service responsible for wrapping the {@link DirectoryReader} and {@link IndexSearcher} of a {@link Searcher} via the
- * configured {@link IndexSearcherWrapper} instance. This allows custom functionally to be added the {@link Searcher}
- * before being used to do an operation (search, get, field stats etc.)
- */
-// TODO: This needs extension point is a bit hacky now, because the IndexSearch from the engine can only be wrapped once,
-// if we allowed the IndexSearcher to be wrapped multiple times then a custom IndexSearcherWrapper needs have good
-// control over its location in the wrapping chain
-public final class IndexSearcherWrappingService {
-
-    private final IndexSearcherWrapper wrapper;
-
-    // for unit tests:
-    IndexSearcherWrappingService() {
-        this.wrapper = null;
-    }
-
-    @Inject
-    // Use a Set parameter here, because constructor parameter can't be optional
-    // and I prefer to keep the `wrapper` field final.
-    public IndexSearcherWrappingService(Set<IndexSearcherWrapper> wrappers) {
-        if (wrappers.size() > 1) {
-            throw new IllegalStateException("wrapping of the index searcher by more than one wrappers is forbidden, found the following wrappers [" + wrappers + "]");
-        }
-        if (wrappers.isEmpty()) {
-            this.wrapper = null;
-        } else {
-            this.wrapper = wrappers.iterator().next();
-        }
-    }
-
-    /**
-     * If there are configured {@link IndexSearcherWrapper} instances, the {@link IndexSearcher} of the provided engine searcher
-     * gets wrapped and a new {@link Searcher} instances is returned, otherwise the provided {@link Searcher} is returned.
-     *
-     * This is invoked each time a {@link Searcher} is requested to do an operation. (for example search)
-     */
-    public Searcher wrap(EngineConfig engineConfig, final Searcher engineSearcher) throws EngineException {
-        if (wrapper == null) {
-            return engineSearcher;
-        }
-
-        DirectoryReader reader = wrapper.wrap((DirectoryReader) engineSearcher.reader());
-        IndexSearcher innerIndexSearcher = new IndexSearcher(reader);
-        innerIndexSearcher.setQueryCache(engineConfig.getQueryCache());
-        innerIndexSearcher.setQueryCachingPolicy(engineConfig.getQueryCachingPolicy());
-        innerIndexSearcher.setSimilarity(engineConfig.getSimilarity());
-        // TODO: Right now IndexSearcher isn't wrapper friendly, when it becomes wrapper friendly we should revise this extension point
-        // For example if IndexSearcher#rewrite() is overwritten than also IndexSearcher#createNormalizedWeight needs to be overwritten
-        // This needs to be fixed before we can allow the IndexSearcher from Engine to be wrapped multiple times
-        IndexSearcher indexSearcher = wrapper.wrap(engineConfig, innerIndexSearcher);
-        if (reader == engineSearcher.reader() && indexSearcher == innerIndexSearcher) {
-            return engineSearcher;
-        } else {
-            return new Engine.Searcher(engineSearcher.source(), indexSearcher) {
-
-                @Override
-                public void close() throws ElasticsearchException {
-                    engineSearcher.close();
-                }
-            };
-        }
-    }
-
-}
diff --git a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
index 63e106c..227212d 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
@@ -66,6 +66,8 @@ import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReentrantLock;
+import java.util.function.Function;
+import java.util.function.Supplier;
 
 /**
  *
@@ -303,7 +305,7 @@ public class InternalEngine extends Engine {
     }
 
     @Override
-    public GetResult get(Get get) throws EngineException {
+    public GetResult get(Get get, Function<String, Searcher> searcherFactory) throws EngineException {
         try (ReleasableLock lock = readLock.acquire()) {
             ensureOpen();
             if (get.realtime()) {
@@ -324,7 +326,7 @@ public class InternalEngine extends Engine {
             }
 
             // no version, get the version from the index, we know that we refresh on flush
-            return getFromSearcher(get);
+            return getFromSearcher(get, searcherFactory);
         }
     }
 
@@ -903,11 +905,6 @@ public class InternalEngine extends Engine {
     }
 
     @Override
-    public long indexWriterRAMBytesUsed() {
-        return indexWriter.ramBytesUsed();
-    }
-
-    @Override
     public List<Segment> segments(boolean verbose) {
         try (ReleasableLock lock = readLock.acquire()) {
             Segment[] segmentsArr = getSegmentInfo(lastCommittedSegmentInfos, verbose);
diff --git a/core/src/main/java/org/elasticsearch/index/engine/ShadowEngine.java b/core/src/main/java/org/elasticsearch/index/engine/ShadowEngine.java
index 31a8148..7588ffa 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/ShadowEngine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/ShadowEngine.java
@@ -35,6 +35,7 @@ import org.elasticsearch.index.translog.Translog;
 import java.io.IOException;
 import java.util.Arrays;
 import java.util.List;
+import java.util.function.Function;
 
 /**
  * ShadowEngine is a specialized engine that only allows read-only operations
@@ -168,9 +169,9 @@ public class ShadowEngine extends Engine {
     }
 
     @Override
-    public GetResult get(Get get) throws EngineException {
+    public GetResult get(Get get, Function<String, Searcher> searcherFacotry) throws EngineException {
         // There is no translog, so we can get it directly from the searcher
-        return getFromSearcher(get);
+        return getFromSearcher(get, searcherFacotry);
     }
 
     @Override
@@ -244,9 +245,4 @@ public class ShadowEngine extends Engine {
         return lastCommittedSegmentInfos;
     }
 
-    @Override
-    public long indexWriterRAMBytesUsed() {
-        // No IndexWriter
-        return 0L;
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataModule.java b/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataModule.java
deleted file mode 100644
index e68ff4c..0000000
--- a/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataModule.java
+++ /dev/null
@@ -1,38 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.fielddata;
-
-import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.settings.Settings;
-
-/**
- */
-public class IndexFieldDataModule extends AbstractModule {
-
-    private final Settings settings;
-
-    public IndexFieldDataModule(Settings settings) {
-        this.settings = settings;
-    }
-
-    @Override
-    protected void configure() {
-        bind(IndexFieldDataService.class).asEagerSingleton();
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/MapperServiceModule.java b/core/src/main/java/org/elasticsearch/index/mapper/MapperServiceModule.java
deleted file mode 100644
index e742992..0000000
--- a/core/src/main/java/org/elasticsearch/index/mapper/MapperServiceModule.java
+++ /dev/null
@@ -1,33 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.mapper;
-
-import org.elasticsearch.common.inject.AbstractModule;
-
-/**
- *
- */
-public class MapperServiceModule extends AbstractModule {
-
-    @Override
-    protected void configure() {
-        bind(MapperService.class).asEagerSingleton();
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/percolator/PercolateStats.java b/core/src/main/java/org/elasticsearch/index/percolator/PercolateStats.java
new file mode 100644
index 0000000..f927a42
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/percolator/PercolateStats.java
@@ -0,0 +1,164 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.index.percolator;
+
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.io.stream.Streamable;
+import org.elasticsearch.common.unit.ByteSizeValue;
+import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.xcontent.ToXContent;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentBuilderString;
+
+import java.io.IOException;
+
+/**
+ * Exposes percolator related statistics.
+ */
+public class PercolateStats implements Streamable, ToXContent {
+
+    private long percolateCount;
+    private long percolateTimeInMillis;
+    private long current;
+    private long memorySizeInBytes = -1;
+    private long numQueries;
+
+    /**
+     * Noop constructor for serialazation purposes.
+     */
+    public PercolateStats() {
+    }
+
+    PercolateStats(long percolateCount, long percolateTimeInMillis, long current, long memorySizeInBytes, long numQueries) {
+        this.percolateCount = percolateCount;
+        this.percolateTimeInMillis = percolateTimeInMillis;
+        this.current = current;
+        this.memorySizeInBytes = memorySizeInBytes;
+        this.numQueries = numQueries;
+    }
+
+    /**
+     * @return The number of times the percolate api has been invoked.
+     */
+    public long getCount() {
+        return percolateCount;
+    }
+
+    /**
+     * @return The total amount of time spend in the percolate api
+     */
+    public long getTimeInMillis() {
+        return percolateTimeInMillis;
+    }
+
+    /**
+     * @return The total amount of time spend in the percolate api
+     */
+    public TimeValue getTime() {
+        return new TimeValue(getTimeInMillis());
+    }
+
+    /**
+     * @return The total amount of active percolate api invocations.
+     */
+    public long getCurrent() {
+        return current;
+    }
+
+    /**
+     * @return The total number of loaded percolate queries.
+     */
+    public long getNumQueries() {
+        return numQueries;
+    }
+
+    /**
+     * @return Temporarily returns <code>-1</code>, but this used to return the total size the loaded queries take in
+     * memory, but this is disabled now because the size estimation was too expensive cpu wise. This will be enabled
+     * again when a cheaper size estimation can be found.
+     */
+    public long getMemorySizeInBytes() {
+        return memorySizeInBytes;
+    }
+
+    /**
+     * @return The total size the loaded queries take in memory.
+     */
+    public ByteSizeValue getMemorySize() {
+        return new ByteSizeValue(memorySizeInBytes);
+    }
+
+    @Override
+    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
+        builder.startObject(Fields.PERCOLATE);
+        builder.field(Fields.TOTAL, percolateCount);
+        builder.timeValueField(Fields.TIME_IN_MILLIS, Fields.TIME, percolateTimeInMillis);
+        builder.field(Fields.CURRENT, current);
+        builder.field(Fields.MEMORY_SIZE_IN_BYTES, memorySizeInBytes);
+        builder.field(Fields.MEMORY_SIZE, getMemorySize());
+        builder.field(Fields.QUERIES, getNumQueries());
+        builder.endObject();
+        return builder;
+    }
+
+    public void add(PercolateStats percolate) {
+        if (percolate == null) {
+            return;
+        }
+
+        percolateCount += percolate.getCount();
+        percolateTimeInMillis += percolate.getTimeInMillis();
+        current += percolate.getCurrent();
+        numQueries += percolate.getNumQueries();
+    }
+
+    static final class Fields {
+        static final XContentBuilderString PERCOLATE = new XContentBuilderString("percolate");
+        static final XContentBuilderString TOTAL = new XContentBuilderString("total");
+        static final XContentBuilderString TIME = new XContentBuilderString("time");
+        static final XContentBuilderString TIME_IN_MILLIS = new XContentBuilderString("time_in_millis");
+        static final XContentBuilderString CURRENT = new XContentBuilderString("current");
+        static final XContentBuilderString MEMORY_SIZE_IN_BYTES = new XContentBuilderString("memory_size_in_bytes");
+        static final XContentBuilderString MEMORY_SIZE = new XContentBuilderString("memory_size");
+        static final XContentBuilderString QUERIES = new XContentBuilderString("queries");
+    }
+
+    public static PercolateStats readPercolateStats(StreamInput in) throws IOException {
+        PercolateStats stats = new PercolateStats();
+        stats.readFrom(in);
+        return stats;
+    }
+
+    @Override
+    public void readFrom(StreamInput in) throws IOException {
+        percolateCount = in.readVLong();
+        percolateTimeInMillis = in.readVLong();
+        current = in.readVLong();
+        numQueries = in.readVLong();
+    }
+
+    @Override
+    public void writeTo(StreamOutput out) throws IOException {
+        out.writeVLong(percolateCount);
+        out.writeVLong(percolateTimeInMillis);
+        out.writeVLong(current);
+        out.writeVLong(numQueries);
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java b/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
index 7dd26ec..d811f1f 100644
--- a/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
+++ b/core/src/main/java/org/elasticsearch/index/percolator/PercolatorQueriesRegistry.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.percolator;
 
+import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
@@ -27,6 +28,8 @@ import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.ParsingException;
 import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.common.metrics.CounterMetric;
+import org.elasticsearch.common.metrics.MeanMetric;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.util.concurrent.ConcurrentCollections;
 import org.elasticsearch.common.xcontent.XContentBuilder;
@@ -41,20 +44,18 @@ import org.elasticsearch.index.mapper.DocumentMapper;
 import org.elasticsearch.index.mapper.DocumentTypeListener;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
-import org.elasticsearch.index.percolator.stats.ShardPercolateService;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.shard.AbstractIndexShardComponent;
-import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.indices.IndicesLifecycle;
 import org.elasticsearch.percolator.PercolatorService;
 
 import java.io.Closeable;
 import java.io.IOException;
 import java.util.Map;
 import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 
 /**
@@ -64,39 +65,35 @@ import java.util.concurrent.atomic.AtomicBoolean;
  * Once a document type has been created, the real-time percolator will start to listen to write events and update the
  * this registry with queries in real time.
  */
-public class PercolatorQueriesRegistry extends AbstractIndexShardComponent implements Closeable{
+public final class PercolatorQueriesRegistry extends AbstractIndexShardComponent implements Closeable {
 
     public final String MAP_UNMAPPED_FIELDS_AS_STRING = "index.percolator.map_unmapped_fields_as_string";
 
     // This is a shard level service, but these below are index level service:
     private final IndexQueryParserService queryParserService;
     private final MapperService mapperService;
-    private final IndicesLifecycle indicesLifecycle;
     private final IndexFieldDataService indexFieldDataService;
 
     private final ShardIndexingService indexingService;
-    private final ShardPercolateService shardPercolateService;
 
     private final ConcurrentMap<BytesRef, Query> percolateQueries = ConcurrentCollections.newConcurrentMapWithAggressiveConcurrency();
-    private final ShardLifecycleListener shardLifecycleListener = new ShardLifecycleListener();
     private final RealTimePercolatorOperationListener realTimePercolatorOperationListener = new RealTimePercolatorOperationListener();
     private final PercolateTypeListener percolateTypeListener = new PercolateTypeListener();
     private final AtomicBoolean realTimePercolatorEnabled = new AtomicBoolean(false);
     private boolean mapUnmappedFieldsAsString;
+    private final MeanMetric percolateMetric = new MeanMetric();
+    private final CounterMetric currentMetric = new CounterMetric();
+    private final CounterMetric numberOfQueries = new CounterMetric();
 
     public PercolatorQueriesRegistry(ShardId shardId, @IndexSettings Settings indexSettings, IndexQueryParserService queryParserService,
-                                     ShardIndexingService indexingService, IndicesLifecycle indicesLifecycle, MapperService mapperService,
-                                     IndexFieldDataService indexFieldDataService, ShardPercolateService shardPercolateService) {
+                                     ShardIndexingService indexingService, MapperService mapperService,
+                                     IndexFieldDataService indexFieldDataService) {
         super(shardId, indexSettings);
         this.queryParserService = queryParserService;
         this.mapperService = mapperService;
-        this.indicesLifecycle = indicesLifecycle;
         this.indexingService = indexingService;
         this.indexFieldDataService = indexFieldDataService;
-        this.shardPercolateService = shardPercolateService;
         this.mapUnmappedFieldsAsString = indexSettings.getAsBoolean(MAP_UNMAPPED_FIELDS_AS_STRING, false);
-
-        indicesLifecycle.addListener(shardLifecycleListener);
         mapperService.addTypeListener(percolateTypeListener);
     }
 
@@ -107,7 +104,6 @@ public class PercolatorQueriesRegistry extends AbstractIndexShardComponent imple
     @Override
     public void close() {
         mapperService.removeTypeListener(percolateTypeListener);
-        indicesLifecycle.removeListener(shardLifecycleListener);
         indexingService.removeListener(realTimePercolatorOperationListener);
         clear();
     }
@@ -116,30 +112,25 @@ public class PercolatorQueriesRegistry extends AbstractIndexShardComponent imple
         percolateQueries.clear();
     }
 
-    void enableRealTimePercolator() {
+    public void enableRealTimePercolator() {
         if (realTimePercolatorEnabled.compareAndSet(false, true)) {
             indexingService.addListener(realTimePercolatorOperationListener);
         }
     }
 
-    void disableRealTimePercolator() {
-        if (realTimePercolatorEnabled.compareAndSet(true, false)) {
-            indexingService.removeListener(realTimePercolatorOperationListener);
-        }
-    }
-
     public void addPercolateQuery(String idAsString, BytesReference source) {
         Query newquery = parsePercolatorDocument(idAsString, source);
         BytesRef id = new BytesRef(idAsString);
-        Query previousQuery = percolateQueries.put(id, newquery);
-        shardPercolateService.addedQuery(id, previousQuery, newquery);
+        percolateQueries.put(id, newquery);
+        numberOfQueries.inc();
+
     }
 
     public void removePercolateQuery(String idAsString) {
         BytesRef id = new BytesRef(idAsString);
         Query query = percolateQueries.remove(id);
         if (query != null) {
-            shardPercolateService.removedQuery(id, query);
+            numberOfQueries.dec();
         }
     }
 
@@ -225,55 +216,27 @@ public class PercolatorQueriesRegistry extends AbstractIndexShardComponent imple
                 enableRealTimePercolator();
             }
         }
-
     }
 
-    private class ShardLifecycleListener extends IndicesLifecycle.Listener {
-
-        @Override
-        public void afterIndexShardCreated(IndexShard indexShard) {
-            if (hasPercolatorType(indexShard)) {
-                enableRealTimePercolator();
-            }
-        }
-
-        @Override
-        public void beforeIndexShardPostRecovery(IndexShard indexShard) {
-            if (hasPercolatorType(indexShard)) {
-                // percolator index has started, fetch what we can from it and initialize the indices
-                // we have
-                logger.trace("loading percolator queries for [{}]...", shardId);
-                int loadedQueries = loadQueries(indexShard);
-                logger.debug("done loading [{}] percolator queries for [{}]", loadedQueries, shardId);
-            }
-        }
-
-        private boolean hasPercolatorType(IndexShard indexShard) {
-            ShardId otherShardId = indexShard.shardId();
-            return shardId.equals(otherShardId) && mapperService.hasMapping(PercolatorService.TYPE_NAME);
-        }
-
-        private int loadQueries(IndexShard shard) {
-            shard.refresh("percolator_load_queries");
-            // NOTE: we acquire the searcher via the engine directly here since this is executed right
-            // before the shard is marked as POST_RECOVERY
-            try (Engine.Searcher searcher = shard.engine().acquireSearcher("percolator_load_queries")) {
-                Query query = new TermQuery(new Term(TypeFieldMapper.NAME, PercolatorService.TYPE_NAME));
-                QueriesLoaderCollector queryCollector = new QueriesLoaderCollector(PercolatorQueriesRegistry.this, logger, mapperService, indexFieldDataService);
-                IndexSearcher indexSearcher = new IndexSearcher(searcher.reader());
-                indexSearcher.setQueryCache(null);
-                indexSearcher.search(query, queryCollector);
-                Map<BytesRef, Query> queries = queryCollector.queries();
-                for (Map.Entry<BytesRef, Query> entry : queries.entrySet()) {
-                    Query previousQuery = percolateQueries.put(entry.getKey(), entry.getValue());
-                    shardPercolateService.addedQuery(entry.getKey(), previousQuery, entry.getValue());
-                }
-                return queries.size();
-            } catch (Exception e) {
-                throw new PercolatorException(shardId.index(), "failed to load queries from percolator index", e);
+    public void loadQueries(IndexReader reader) {
+        logger.trace("loading percolator queries...");
+        final int loadedQueries;
+        try {
+            Query query = new TermQuery(new Term(TypeFieldMapper.NAME, PercolatorService.TYPE_NAME));
+            QueriesLoaderCollector queryCollector = new QueriesLoaderCollector(PercolatorQueriesRegistry.this, logger, mapperService, indexFieldDataService);
+            IndexSearcher indexSearcher = new IndexSearcher(reader);
+            indexSearcher.setQueryCache(null);
+            indexSearcher.search(query, queryCollector);
+            Map<BytesRef, Query> queries = queryCollector.queries();
+            for (Map.Entry<BytesRef, Query> entry : queries.entrySet()) {
+                percolateQueries.put(entry.getKey(), entry.getValue());
+                numberOfQueries.inc();
             }
+            loadedQueries = queries.size();
+        } catch (Exception e) {
+            throw new PercolatorException(shardId.index(), "failed to load queries from percolator index", e);
         }
-
+        logger.debug("done loading [{}] percolator queries", loadedQueries);
     }
 
     private class RealTimePercolatorOperationListener extends IndexingOperationListener {
@@ -320,4 +283,35 @@ public class PercolatorQueriesRegistry extends AbstractIndexShardComponent imple
             }
         }
     }
+
+    public void prePercolate() {
+        currentMetric.inc();
+    }
+
+    public void postPercolate(long tookInNanos) {
+        currentMetric.dec();
+        percolateMetric.inc(tookInNanos);
+    }
+
+    /**
+     * @return The current metrics
+     */
+    public PercolateStats stats() {
+        return new PercolateStats(percolateMetric.count(), TimeUnit.NANOSECONDS.toMillis(percolateMetric.sum()), currentMetric.count(), -1, numberOfQueries.count());
+    }
+
+    // Enable when a more efficient manner is found for estimating the size of a Lucene query.
+    /*private static long computeSizeInMemory(HashedBytesRef id, Query query) {
+        long size = (3 * RamUsageEstimator.NUM_BYTES_INT) + RamUsageEstimator.NUM_BYTES_OBJECT_REF + RamUsageEstimator.NUM_BYTES_OBJECT_HEADER + id.bytes.bytes.length;
+        size += RamEstimator.sizeOf(query);
+        return size;
+    }
+
+    private static final class RamEstimator {
+        // we move this into it's own class to exclude it from the forbidden API checks
+        // it's fine to use here!
+        static long sizeOf(Query query) {
+            return RamUsageEstimator.sizeOf(query);
+        }
+    }*/
 }
diff --git a/core/src/main/java/org/elasticsearch/index/percolator/stats/PercolateStats.java b/core/src/main/java/org/elasticsearch/index/percolator/stats/PercolateStats.java
deleted file mode 100644
index 49f2375..0000000
--- a/core/src/main/java/org/elasticsearch/index/percolator/stats/PercolateStats.java
+++ /dev/null
@@ -1,164 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.percolator.stats;
-
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Streamable;
-import org.elasticsearch.common.unit.ByteSizeValue;
-import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentBuilderString;
-
-import java.io.IOException;
-
-/**
- * Exposes percolator related statistics.
- */
-public class PercolateStats implements Streamable, ToXContent {
-
-    private long percolateCount;
-    private long percolateTimeInMillis;
-    private long current;
-    private long memorySizeInBytes = -1;
-    private long numQueries;
-
-    /**
-     * Noop constructor for serialazation purposes.
-     */
-    public PercolateStats() {
-    }
-
-    PercolateStats(long percolateCount, long percolateTimeInMillis, long current, long memorySizeInBytes, long numQueries) {
-        this.percolateCount = percolateCount;
-        this.percolateTimeInMillis = percolateTimeInMillis;
-        this.current = current;
-        this.memorySizeInBytes = memorySizeInBytes;
-        this.numQueries = numQueries;
-    }
-
-    /**
-     * @return The number of times the percolate api has been invoked.
-     */
-    public long getCount() {
-        return percolateCount;
-    }
-
-    /**
-     * @return The total amount of time spend in the percolate api
-     */
-    public long getTimeInMillis() {
-        return percolateTimeInMillis;
-    }
-
-    /**
-     * @return The total amount of time spend in the percolate api
-     */
-    public TimeValue getTime() {
-        return new TimeValue(getTimeInMillis());
-    }
-
-    /**
-     * @return The total amount of active percolate api invocations.
-     */
-    public long getCurrent() {
-        return current;
-    }
-
-    /**
-     * @return The total number of loaded percolate queries.
-     */
-    public long getNumQueries() {
-        return numQueries;
-    }
-
-    /**
-     * @return Temporarily returns <code>-1</code>, but this used to return the total size the loaded queries take in
-     * memory, but this is disabled now because the size estimation was too expensive cpu wise. This will be enabled
-     * again when a cheaper size estimation can be found.
-     */
-    public long getMemorySizeInBytes() {
-        return memorySizeInBytes;
-    }
-
-    /**
-     * @return The total size the loaded queries take in memory.
-     */
-    public ByteSizeValue getMemorySize() {
-        return new ByteSizeValue(memorySizeInBytes);
-    }
-
-    @Override
-    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
-        builder.startObject(Fields.PERCOLATE);
-        builder.field(Fields.TOTAL, percolateCount);
-        builder.timeValueField(Fields.TIME_IN_MILLIS, Fields.TIME, percolateTimeInMillis);
-        builder.field(Fields.CURRENT, current);
-        builder.field(Fields.MEMORY_SIZE_IN_BYTES, memorySizeInBytes);
-        builder.field(Fields.MEMORY_SIZE, getMemorySize());
-        builder.field(Fields.QUERIES, getNumQueries());
-        builder.endObject();
-        return builder;
-    }
-
-    public void add(PercolateStats percolate) {
-        if (percolate == null) {
-            return;
-        }
-
-        percolateCount += percolate.getCount();
-        percolateTimeInMillis += percolate.getTimeInMillis();
-        current += percolate.getCurrent();
-        numQueries += percolate.getNumQueries();
-    }
-
-    static final class Fields {
-        static final XContentBuilderString PERCOLATE = new XContentBuilderString("percolate");
-        static final XContentBuilderString TOTAL = new XContentBuilderString("total");
-        static final XContentBuilderString TIME = new XContentBuilderString("time");
-        static final XContentBuilderString TIME_IN_MILLIS = new XContentBuilderString("time_in_millis");
-        static final XContentBuilderString CURRENT = new XContentBuilderString("current");
-        static final XContentBuilderString MEMORY_SIZE_IN_BYTES = new XContentBuilderString("memory_size_in_bytes");
-        static final XContentBuilderString MEMORY_SIZE = new XContentBuilderString("memory_size");
-        static final XContentBuilderString QUERIES = new XContentBuilderString("queries");
-    }
-
-    public static PercolateStats readPercolateStats(StreamInput in) throws IOException {
-        PercolateStats stats = new PercolateStats();
-        stats.readFrom(in);
-        return stats;
-    }
-
-    @Override
-    public void readFrom(StreamInput in) throws IOException {
-        percolateCount = in.readVLong();
-        percolateTimeInMillis = in.readVLong();
-        current = in.readVLong();
-        numQueries = in.readVLong();
-    }
-
-    @Override
-    public void writeTo(StreamOutput out) throws IOException {
-        out.writeVLong(percolateCount);
-        out.writeVLong(percolateTimeInMillis);
-        out.writeVLong(current);
-        out.writeVLong(numQueries);
-    }
-}
diff --git a/core/src/main/java/org/elasticsearch/index/percolator/stats/ShardPercolateService.java b/core/src/main/java/org/elasticsearch/index/percolator/stats/ShardPercolateService.java
deleted file mode 100644
index 80f6bd9..0000000
--- a/core/src/main/java/org/elasticsearch/index/percolator/stats/ShardPercolateService.java
+++ /dev/null
@@ -1,93 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.percolator.stats;
-
-import org.apache.lucene.search.Query;
-import org.apache.lucene.util.BytesRef;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.metrics.CounterMetric;
-import org.elasticsearch.common.metrics.MeanMetric;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.settings.IndexSettings;
-import org.elasticsearch.index.shard.AbstractIndexShardComponent;
-import org.elasticsearch.index.shard.ShardId;
-
-import java.util.concurrent.TimeUnit;
-
-/**
- * Shard level percolator service that maintains percolator metrics:
- * <ul>
- *     <li> total time spent in percolate api
- *     <li> the current number of percolate requests
- *     <li> number of registered percolate queries
- * </ul>
- */
-public class ShardPercolateService extends AbstractIndexShardComponent {
-
-    @Inject
-    public ShardPercolateService(ShardId shardId, @IndexSettings Settings indexSettings) {
-        super(shardId, indexSettings);
-    }
-
-    private final MeanMetric percolateMetric = new MeanMetric();
-    private final CounterMetric currentMetric = new CounterMetric();
-
-    private final CounterMetric numberOfQueries = new CounterMetric();
-
-    public void prePercolate() {
-        currentMetric.inc();
-    }
-
-    public void postPercolate(long tookInNanos) {
-        currentMetric.dec();
-        percolateMetric.inc(tookInNanos);
-    }
-
-    public void addedQuery(BytesRef id, Query previousQuery, Query newQuery) {
-        numberOfQueries.inc();
-    }
-
-    public void removedQuery(BytesRef id, Query query) {
-        numberOfQueries.dec();
-    }
-
-    /**
-     * @return The current metrics
-     */
-    public PercolateStats stats() {
-        return new PercolateStats(percolateMetric.count(), TimeUnit.NANOSECONDS.toMillis(percolateMetric.sum()), currentMetric.count(), -1, numberOfQueries.count());
-    }
-
-    // Enable when a more efficient manner is found for estimating the size of a Lucene query.
-    /*private static long computeSizeInMemory(HashedBytesRef id, Query query) {
-        long size = (3 * RamUsageEstimator.NUM_BYTES_INT) + RamUsageEstimator.NUM_BYTES_OBJECT_REF + RamUsageEstimator.NUM_BYTES_OBJECT_HEADER + id.bytes.bytes.length;
-        size += RamEstimator.sizeOf(query);
-        return size;
-    }
-
-    private static final class RamEstimator {
-        // we move this into it's own class to exclude it from the forbidden API checks
-        // it's fine to use here!
-        static long sizeOf(Query query) {
-            return RamUsageEstimator.sizeOf(query);
-        }
-    }*/
-
-}
diff --git a/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
index b85db4b..1de8db2 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IdsQueryBuilder.java
@@ -22,7 +22,6 @@ package org.elasticsearch.index.query;
 import org.apache.lucene.queries.TermsQuery;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.lucene.search.Queries;
@@ -47,9 +46,19 @@ public class IdsQueryBuilder extends AbstractQueryBuilder<IdsQueryBuilder> {
     static final IdsQueryBuilder PROTOTYPE = new IdsQueryBuilder();
 
     /**
-     * Creates a new IdsQueryBuilder by optionally providing the types of the documents to look for
+     * Creates a new IdsQueryBuilder without providing the types of the documents to look for
      */
-    public IdsQueryBuilder(@Nullable String... types) {
+    public IdsQueryBuilder() {
+        this.types = new String[0];
+    }
+
+    /**
+     * Creates a new IdsQueryBuilder by providing the types of the documents to look for
+     */
+    public IdsQueryBuilder(String... types) {
+        if (types == null) {
+            throw new IllegalArgumentException("[ids] types cannot be null");
+        }
         this.types = types;
     }
 
@@ -64,33 +73,14 @@ public class IdsQueryBuilder extends AbstractQueryBuilder<IdsQueryBuilder> {
      * Adds ids to the query.
      */
     public IdsQueryBuilder addIds(String... ids) {
+        if (ids == null) {
+            throw new IllegalArgumentException("[ids] ids cannot be null");
+        }
         Collections.addAll(this.ids, ids);
         return this;
     }
 
     /**
-     * Adds ids to the query.
-     */
-    public IdsQueryBuilder addIds(Collection<String> ids) {
-        this.ids.addAll(ids);
-        return this;
-    }
-
-    /**
-     * Adds ids to the filter.
-     */
-    public IdsQueryBuilder ids(String... ids) {
-        return addIds(ids);
-    }
-
-    /**
-     * Adds ids to the filter.
-     */
-    public IdsQueryBuilder ids(Collection<String> ids) {
-        return addIds(ids);
-    }
-
-    /**
      * Returns the ids for the query.
      */
     public Set<String> ids() {
@@ -100,13 +90,7 @@ public class IdsQueryBuilder extends AbstractQueryBuilder<IdsQueryBuilder> {
     @Override
     protected void doXContent(XContentBuilder builder, Params params) throws IOException {
         builder.startObject(NAME);
-        if (types != null) {
-            if (types.length == 1) {
-                builder.field("type", types[0]);
-            } else {
-                builder.array("types", types);
-            }
-        }
+        builder.array("types", types);
         builder.startArray("values");
         for (String value : ids) {
             builder.value(value);
@@ -128,7 +112,7 @@ public class IdsQueryBuilder extends AbstractQueryBuilder<IdsQueryBuilder> {
              query = Queries.newMatchNoDocsQuery();
         } else {
             Collection<String> typesForQuery;
-            if (types == null || types.length == 0) {
+            if (types.length == 0) {
                 typesForQuery = context.queryTypes();
             } else if (types.length == 1 && MetaData.ALL.equals(types[0])) {
                 typesForQuery = context.mapperService().types();
diff --git a/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java b/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
index d4f7491..bbd9f84 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IndexQueryParserService.java
@@ -197,15 +197,6 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         }
     }
 
-    @Nullable
-    public Query parseInnerQuery(QueryShardContext context) throws IOException {
-        Query query = context.parseContext().parseInnerQueryBuilder().toQuery(context);
-        if (query == null) {
-            query = Queries.newMatchNoDocsQuery();
-        }
-        return query;
-    }
-
     public QueryShardContext getShardContext() {
         return cache.get();
     }
@@ -258,16 +249,41 @@ public class IndexQueryParserService extends AbstractIndexComponent {
         context.reset(parser);
         try {
             context.parseFieldMatcher(parseFieldMatcher);
-            Query query = context.parseContext().parseInnerQueryBuilder().toQuery(context);
-            if (query == null) {
-                query = Queries.newMatchNoDocsQuery();
-            }
+            Query query = parseInnerQuery(context);
             return new ParsedQuery(query, context.copyNamedQueries());
         } finally {
             context.reset(null);
         }
     }
 
+    public Query parseInnerQuery(QueryShardContext context) throws IOException {
+        return toQuery(context.parseContext().parseInnerQueryBuilder(), context);
+    }
+
+    public ParsedQuery toQuery(QueryBuilder<?> queryBuilder) {
+        QueryShardContext context = cache.get();
+        context.reset();
+        context.parseFieldMatcher(parseFieldMatcher);
+        try {
+            Query query = toQuery(queryBuilder, context);
+            return new ParsedQuery(query, context.copyNamedQueries());
+        } catch(QueryShardException | ParsingException e ) {
+            throw e;
+        } catch(Exception e) {
+            throw new QueryShardException(context, "failed to create query: {}", e, queryBuilder);
+        } finally {
+            context.reset();
+        }
+    }
+
+    private static Query toQuery(QueryBuilder<?> queryBuilder, QueryShardContext context) throws IOException {
+        Query query = queryBuilder.toQuery(context);
+        if (query == null) {
+            query = Queries.newMatchNoDocsQuery();
+        }
+        return query;
+    }
+
     public ParseFieldMatcher parseFieldMatcher() {
         return parseFieldMatcher;
     }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java b/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
index df823e1..67e654c 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryBuilders.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.index.query;
 
-import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.geo.GeoPoint;
 import org.elasticsearch.common.geo.ShapeRelation;
@@ -110,11 +109,18 @@ public abstract class QueryBuilders {
     }
 
     /**
+     * Constructs a query that will match only specific ids within all types.
+     */
+    public static IdsQueryBuilder idsQuery() {
+        return new IdsQueryBuilder();
+    }
+
+    /**
      * Constructs a query that will match only specific ids within types.
      *
      * @param types The mapping/doc type
      */
-    public static IdsQueryBuilder idsQuery(@Nullable String... types) {
+    public static IdsQueryBuilder idsQuery(String... types) {
         return new IdsQueryBuilder(types);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexSearcherWrapper.java b/core/src/main/java/org/elasticsearch/index/shard/IndexSearcherWrapper.java
new file mode 100644
index 0000000..c75f3c7
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexSearcherWrapper.java
@@ -0,0 +1,81 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index.shard;
+
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.search.IndexSearcher;
+import org.elasticsearch.ElasticsearchException;
+import org.elasticsearch.index.engine.Engine;
+import org.elasticsearch.index.engine.EngineConfig;
+import org.elasticsearch.index.engine.EngineException;
+
+import java.io.IOException;
+
+/**
+ * Extension point to add custom functionality at request time to the {@link DirectoryReader}
+ * and {@link IndexSearcher} managed by the {@link Engine}.
+ */
+public interface IndexSearcherWrapper {
+
+    /**
+     * @param reader The provided directory reader to be wrapped to add custom functionality
+     * @return a new directory reader wrapping the provided directory reader or if no wrapping was performed
+     *         the provided directory reader
+     */
+    DirectoryReader wrap(DirectoryReader reader) throws IOException;
+
+    /**
+     * @param engineConfig  The engine config which can be used to get the query cache and query cache policy from
+     *                      when creating a new index searcher
+     * @param searcher      The provided index searcher to be wrapped to add custom functionality
+     * @return a new index searcher wrapping the provided index searcher or if no wrapping was performed
+     *         the provided index searcher
+     */
+    IndexSearcher wrap(EngineConfig engineConfig, IndexSearcher searcher) throws IOException;
+
+    /**
+     * If there are configured {@link IndexSearcherWrapper} instances, the {@link IndexSearcher} of the provided engine searcher
+     * gets wrapped and a new {@link Engine.Searcher} instances is returned, otherwise the provided {@link Engine.Searcher} is returned.
+     *
+     * This is invoked each time a {@link Engine.Searcher} is requested to do an operation. (for example search)
+     */
+    default Engine.Searcher wrap(EngineConfig engineConfig, Engine.Searcher engineSearcher) throws IOException {
+        DirectoryReader reader = wrap((DirectoryReader) engineSearcher.reader());
+        IndexSearcher innerIndexSearcher = new IndexSearcher(reader);
+        innerIndexSearcher.setQueryCache(engineConfig.getQueryCache());
+        innerIndexSearcher.setQueryCachingPolicy(engineConfig.getQueryCachingPolicy());
+        innerIndexSearcher.setSimilarity(engineConfig.getSimilarity());
+        // TODO: Right now IndexSearcher isn't wrapper friendly, when it becomes wrapper friendly we should revise this extension point
+        // For example if IndexSearcher#rewrite() is overwritten than also IndexSearcher#createNormalizedWeight needs to be overwritten
+        // This needs to be fixed before we can allow the IndexSearcher from Engine to be wrapped multiple times
+        IndexSearcher indexSearcher = wrap(engineConfig, innerIndexSearcher);
+        if (reader == engineSearcher.reader() && indexSearcher == innerIndexSearcher) {
+            return engineSearcher;
+        } else {
+            return new Engine.Searcher(engineSearcher.source(), indexSearcher) {
+                @Override
+                public void close() throws ElasticsearchException {
+                    engineSearcher.close();
+                }
+            };
+        }
+    }
+
+}
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
index 645b970..ea2d555 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
@@ -20,10 +20,7 @@
 package org.elasticsearch.index.shard;
 
 import org.apache.lucene.codecs.PostingsFormat;
-import org.apache.lucene.index.CheckIndex;
-import org.apache.lucene.index.IndexCommit;
-import org.apache.lucene.index.KeepOnlyLastCommitDeletionPolicy;
-import org.apache.lucene.index.SnapshotDeletionPolicy;
+import org.apache.lucene.index.*;
 import org.apache.lucene.search.QueryCachingPolicy;
 import org.apache.lucene.search.UsageTrackingQueryCachingPolicy;
 import org.apache.lucene.store.AlreadyClosedException;
@@ -36,6 +33,7 @@ import org.elasticsearch.action.admin.indices.optimize.OptimizeRequest;
 import org.elasticsearch.action.admin.indices.upgrade.post.UpgradeRequest;
 import org.elasticsearch.action.termvectors.TermVectorsRequest;
 import org.elasticsearch.action.termvectors.TermVectorsResponse;
+import org.elasticsearch.bootstrap.Elasticsearch;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.ShardRouting;
@@ -51,11 +49,11 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.ByteSizeUnit;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.common.util.concurrent.AbstractRefCounted;
 import org.elasticsearch.common.util.concurrent.AbstractRunnable;
 import org.elasticsearch.common.util.concurrent.FutureUtils;
 import org.elasticsearch.gateway.MetaDataStateFormat;
+import org.elasticsearch.index.IndexServicesProvider;
 import org.elasticsearch.index.VersionType;
 import org.elasticsearch.index.aliases.IndexAliasesService;
 import org.elasticsearch.index.cache.IndexCache;
@@ -75,8 +73,8 @@ import org.elasticsearch.index.indexing.IndexingStats;
 import org.elasticsearch.index.indexing.ShardIndexingService;
 import org.elasticsearch.index.mapper.*;
 import org.elasticsearch.index.merge.MergeStats;
+import org.elasticsearch.index.percolator.PercolateStats;
 import org.elasticsearch.index.percolator.PercolatorQueriesRegistry;
-import org.elasticsearch.index.percolator.stats.ShardPercolateService;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.recovery.RecoveryStats;
 import org.elasticsearch.index.refresh.RefreshStats;
@@ -86,8 +84,8 @@ import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.settings.IndexSettingsService;
 import org.elasticsearch.index.similarity.SimilarityService;
 import org.elasticsearch.index.snapshots.IndexShardRepository;
-import org.elasticsearch.index.store.Store.MetadataSnapshot;
 import org.elasticsearch.index.store.Store;
+import org.elasticsearch.index.store.Store.MetadataSnapshot;
 import org.elasticsearch.index.store.StoreFileMetaData;
 import org.elasticsearch.index.store.StoreStats;
 import org.elasticsearch.index.suggest.stats.ShardSuggestMetric;
@@ -99,13 +97,12 @@ import org.elasticsearch.index.translog.TranslogStats;
 import org.elasticsearch.index.translog.TranslogWriter;
 import org.elasticsearch.index.warmer.ShardIndexWarmerService;
 import org.elasticsearch.index.warmer.WarmerStats;
-import org.elasticsearch.indices.IndicesLifecycle;
 import org.elasticsearch.indices.IndicesWarmer;
 import org.elasticsearch.indices.InternalIndicesLifecycle;
 import org.elasticsearch.indices.cache.query.IndicesQueryCache;
-import org.elasticsearch.indices.memory.IndexingMemoryController;
 import org.elasticsearch.indices.recovery.RecoveryFailedException;
 import org.elasticsearch.indices.recovery.RecoveryState;
+import org.elasticsearch.percolator.PercolatorService;
 import org.elasticsearch.search.suggest.completion.Completion090PostingsFormat;
 import org.elasticsearch.search.suggest.completion.CompletionStats;
 import org.elasticsearch.threadpool.ThreadPool;
@@ -121,7 +118,6 @@ import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicReference;
 
-
 public class IndexShard extends AbstractIndexShardComponent implements IndexSettingsService.Listener {
 
     private final ThreadPool threadPool;
@@ -139,7 +135,6 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
     private final ShardRequestCache shardQueryCache;
     private final ShardFieldData shardFieldData;
     private final PercolatorQueriesRegistry percolatorQueriesRegistry;
-    private final ShardPercolateService shardPercolateService;
     private final TermVectorsService termVectorsService;
     private final IndexFieldDataService indexFieldDataService;
     private final ShardSuggestMetric shardSuggestMetric = new ShardSuggestMetric();
@@ -163,7 +158,6 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
     protected volatile IndexShardState state;
     protected final AtomicReference<Engine> currentEngineReference = new AtomicReference<>();
     protected final EngineFactory engineFactory;
-    private final IndexSearcherWrappingService wrappingService;
 
     @Nullable
     private RecoveryState recoveryState;
@@ -192,47 +186,36 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
 
     private final IndexShardOperationCounter indexShardOperationCounter;
 
-    private EnumSet<IndexShardState> readAllowedStates = EnumSet.of(IndexShardState.STARTED, IndexShardState.RELOCATED, IndexShardState.POST_RECOVERY);
+    private final EnumSet<IndexShardState> readAllowedStates = EnumSet.of(IndexShardState.STARTED, IndexShardState.RELOCATED, IndexShardState.POST_RECOVERY);
 
-    private final AtomicBoolean active = new AtomicBoolean();
-    private volatile long lastWriteNS;
-    private final IndexingMemoryController indexingMemoryController;
+    private final IndexSearcherWrapper searcherWrapper;
 
     @Inject
-    public IndexShard(ShardId shardId, @IndexSettings Settings indexSettings, IndicesLifecycle indicesLifecycle, Store store,
-                      ThreadPool threadPool, MapperService mapperService, IndexQueryParserService queryParserService, IndexCache indexCache, IndexAliasesService indexAliasesService,
-                      IndicesQueryCache indicesQueryCache, CodecService codecService,
-                      TermVectorsService termVectorsService, IndexFieldDataService indexFieldDataService,
-                      @Nullable IndicesWarmer warmer, SimilarityService similarityService, EngineFactory factory,
-                      ShardPath path, BigArrays bigArrays, IndexSearcherWrappingService wrappingService,
-                      IndexingMemoryController indexingMemoryController) {
+    public IndexShard(ShardId shardId, @IndexSettings Settings indexSettings, ShardPath path, Store store, IndexServicesProvider provider) {
         super(shardId, indexSettings);
-        this.codecService = codecService;
-        this.warmer = warmer;
+        this.codecService = provider.getCodecService();
+        this.warmer = provider.getWarmer();
         this.deletionPolicy = new SnapshotDeletionPolicy(new KeepOnlyLastCommitDeletionPolicy());
-        this.similarityService = similarityService;
-        this.wrappingService = wrappingService;
+        this.similarityService = provider.getSimilarityService();
         Objects.requireNonNull(store, "Store must be provided to the index shard");
-        this.engineFactory = factory;
-        this.indicesLifecycle = (InternalIndicesLifecycle) indicesLifecycle;
+        this.engineFactory = provider.getFactory();
+        this.indicesLifecycle = (InternalIndicesLifecycle) provider.getIndicesLifecycle();
         this.store = store;
         this.mergeSchedulerConfig = new MergeSchedulerConfig(indexSettings);
-        this.threadPool = threadPool;
-        this.mapperService = mapperService;
-        this.queryParserService = queryParserService;
-        this.indexCache = indexCache;
-        this.indexAliasesService = indexAliasesService;
+        this.threadPool =  provider.getThreadPool();
+        this.mapperService =  provider.getMapperService();
+        this.queryParserService =  provider.getQueryParserService();
+        this.indexCache =  provider.getIndexCache();
+        this.indexAliasesService =  provider.getIndexAliasesService();
         this.indexingService = new ShardIndexingService(shardId, indexSettings);
         this.getService = new ShardGetService(this, mapperService);
-        this.termVectorsService = termVectorsService;
+        this.termVectorsService =  provider.getTermVectorsService();
         this.searchService = new ShardSearchStats(indexSettings);
         this.shardWarmerService = new ShardIndexWarmerService(shardId, indexSettings);
-        this.indicesQueryCache = indicesQueryCache;
+        this.indicesQueryCache =  provider.getIndicesQueryCache();
         this.shardQueryCache = new ShardRequestCache(shardId, indexSettings);
         this.shardFieldData = new ShardFieldData();
-        this.shardPercolateService = new ShardPercolateService(shardId, indexSettings);
-        this.percolatorQueriesRegistry = new PercolatorQueriesRegistry(shardId, indexSettings, queryParserService, indexingService, indicesLifecycle, mapperService, indexFieldDataService, shardPercolateService);
-        this.indexFieldDataService = indexFieldDataService;
+        this.indexFieldDataService =  provider.getIndexFieldDataService();
         this.shardBitsetFilterCache = new ShardBitsetFilterCache(shardId, indexSettings);
         state = IndexShardState.CREATED;
         this.refreshInterval = indexSettings.getAsTime(INDEX_REFRESH_INTERVAL, EngineConfig.DEFAULT_REFRESH_INTERVAL);
@@ -245,7 +228,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
 
         this.checkIndexOnStartup = indexSettings.get("index.shard.check_on_startup", "false");
         this.translogConfig = new TranslogConfig(shardId, shardPath().resolveTranslog(), indexSettings, getFromSettings(logger, indexSettings, Translog.Durabilty.REQUEST),
-                bigArrays, threadPool);
+                provider.getBigArrays(), threadPool);
         final QueryCachingPolicy cachingPolicy;
         // the query cache is a node-level thing, however we want the most popular filters
         // to be computed on a per-shard basis
@@ -259,10 +242,11 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         this.flushThresholdSize = indexSettings.getAsBytesSize(INDEX_TRANSLOG_FLUSH_THRESHOLD_SIZE, new ByteSizeValue(512, ByteSizeUnit.MB));
         this.disableFlush = indexSettings.getAsBoolean(INDEX_TRANSLOG_DISABLE_FLUSH, false);
         this.indexShardOperationCounter = new IndexShardOperationCounter(logger, shardId);
-        this.indexingMemoryController = indexingMemoryController;
-
-        // TODO: can we somehow call IMC.forceCheck here?  Since we just became active, it can divvy up the RAM
-        active.set(true);
+        this.searcherWrapper = provider.getIndexSearcherWrapper();
+        this.percolatorQueriesRegistry = new PercolatorQueriesRegistry(shardId, indexSettings, queryParserService, indexingService, mapperService, indexFieldDataService);
+        if (mapperService.hasMapping(PercolatorService.TYPE_NAME)) {
+            percolatorQueriesRegistry.enableRealTimePercolator();
+        }
     }
 
     public Store store() {
@@ -355,7 +339,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
                 if (newRouting.state() == ShardRoutingState.STARTED || newRouting.state() == ShardRoutingState.RELOCATING) {
                     // we want to refresh *before* we move to internal STARTED state
                     try {
-                        engine().refresh("cluster_state_started");
+                        getEngine().refresh("cluster_state_started");
                     } catch (Throwable t) {
                         logger.debug("failed to refresh due to move to cluster wide started", t);
                     }
@@ -458,13 +442,13 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
     }
 
     public void create(Engine.Create create) {
-        ensureWriteAllowed(create);
+        writeAllowed(create.origin());
         create = indexingService.preCreate(create);
         try {
             if (logger.isTraceEnabled()) {
                 logger.trace("index [{}][{}]{}", create.type(), create.id(), create.docs());
             }
-            engine().create(create);
+            getEngine().create(create);
             create.endTime(System.nanoTime());
         } catch (Throwable ex) {
             indexingService.postCreate(create, ex);
@@ -496,14 +480,14 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
      * updated.
      */
     public boolean index(Engine.Index index) {
-        ensureWriteAllowed(index);
+        writeAllowed(index.origin());
         index = indexingService.preIndex(index);
         final boolean created;
         try {
             if (logger.isTraceEnabled()) {
                 logger.trace("index [{}][{}]{}", index.type(), index.id(), index.docs());
             }
-            created = engine().index(index);
+            created = getEngine().index(index);
             index.endTime(System.nanoTime());
         } catch (Throwable ex) {
             indexingService.postIndex(index, ex);
@@ -520,13 +504,13 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
     }
 
     public void delete(Engine.Delete delete) {
-        ensureWriteAllowed(delete);
+        writeAllowed(delete.origin());
         delete = indexingService.preDelete(delete);
         try {
             if (logger.isTraceEnabled()) {
                 logger.trace("delete [{}]", delete.uid().text());
             }
-            engine().delete(delete);
+            getEngine().delete(delete);
             delete.endTime(System.nanoTime());
         } catch (Throwable ex) {
             indexingService.postDelete(delete, ex);
@@ -537,7 +521,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
 
     public Engine.GetResult get(Engine.Get get) {
         readAllowed();
-        return engine().get(get);
+        return getEngine().get(get, this::acquireSearcher);
     }
 
     public void refresh(String source) {
@@ -546,7 +530,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
             logger.trace("refresh with source: {}", source);
         }
         long time = System.nanoTime();
-        engine().refresh(source);
+        getEngine().refresh(source);
         refreshMetric.inc(System.nanoTime() - time);
     }
 
@@ -572,7 +556,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
      */
     @Nullable
     public CommitStats commitStats() {
-        Engine engine = engineUnsafe();
+        Engine engine = getEngineOrNull();
         return engine == null ? null : engine.commitStats();
     }
 
@@ -599,7 +583,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
     }
 
     public MergeStats mergeStats() {
-        final Engine engine = engineUnsafe();
+        final Engine engine = getEngineOrNull();
         if (engine == null) {
             return new MergeStats();
         }
@@ -607,7 +591,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
     }
 
     public SegmentsStats segmentStats() {
-        SegmentsStats segmentsStats = engine().segmentsStats();
+        SegmentsStats segmentsStats = getEngine().segmentsStats();
         segmentsStats.addBitsetMemoryInBytes(shardBitsetFilterCache.getMemorySizeInBytes());
         return segmentsStats;
     }
@@ -632,12 +616,8 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         return percolatorQueriesRegistry;
     }
 
-    public ShardPercolateService shardPercolateService() {
-        return shardPercolateService;
-    }
-
     public TranslogStats translogStats() {
-        return engine().getTranslog().stats();
+        return getEngine().getTranslog().stats();
     }
 
     public SuggestStats suggestStats() {
@@ -662,7 +642,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
     public Engine.SyncedFlushResult syncFlush(String syncId, Engine.CommitId expectedCommitId) {
         verifyStartedOrRecovering();
         logger.trace("trying to sync flush. sync id [{}]. expected commit id [{}]]", syncId, expectedCommitId);
-        return engine().syncFlush(syncId, expectedCommitId);
+        return getEngine().syncFlush(syncId, expectedCommitId);
     }
 
     public Engine.CommitId flush(FlushRequest request) throws ElasticsearchException {
@@ -677,7 +657,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         verifyStartedOrRecovering();
 
         long time = System.nanoTime();
-        Engine.CommitId commitId = engine().flush(force, waitIfOngoing);
+        Engine.CommitId commitId = getEngine().flush(force, waitIfOngoing);
         flushMetric.inc(System.nanoTime() - time);
         return commitId;
 
@@ -688,7 +668,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         if (logger.isTraceEnabled()) {
             logger.trace("optimize with {}", optimize);
         }
-        engine().forceMerge(optimize.flush(), optimize.maxNumSegments(), optimize.onlyExpungeDeletes(), false, false);
+        getEngine().forceMerge(optimize.flush(), optimize.maxNumSegments(), optimize.onlyExpungeDeletes(), false, false);
     }
 
     /**
@@ -701,7 +681,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         }
         org.apache.lucene.util.Version previousVersion = minimumCompatibleVersion();
         // we just want to upgrade the segments, not actually optimize to a single segment
-        engine().forceMerge(true,  // we need to flush at the end to make sure the upgrade is durable
+        getEngine().forceMerge(true,  // we need to flush at the end to make sure the upgrade is durable
                 Integer.MAX_VALUE, // we just want to upgrade the segments, not actually optimize to a single segment
                 false, true, upgrade.upgradeOnlyAncientSegments());
         org.apache.lucene.util.Version version = minimumCompatibleVersion();
@@ -714,7 +694,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
 
     public org.apache.lucene.util.Version minimumCompatibleVersion() {
         org.apache.lucene.util.Version luceneVersion = null;
-        for (Segment segment : engine().segments(false)) {
+        for (Segment segment : getEngine().segments(false)) {
             if (luceneVersion == null || luceneVersion.onOrAfter(segment.getVersion())) {
                 luceneVersion = segment.getVersion();
             }
@@ -732,7 +712,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         IndexShardState state = this.state; // one time volatile read
         // we allow snapshot on closed index shard, since we want to do one after we close the shard and before we close the engine
         if (state == IndexShardState.STARTED || state == IndexShardState.RELOCATED || state == IndexShardState.CLOSED) {
-            return engine().snapshotIndex(flushFirst);
+            return getEngine().snapshotIndex(flushFirst);
         } else {
             throw new IllegalIndexShardStateException(shardId, state, "snapshot is not allowed");
         }
@@ -753,12 +733,17 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
      */
     public void failShard(String reason, @Nullable Throwable e) {
         // fail the engine. This will cause this shard to also be removed from the node's index service.
-        engine().failEngine(reason, e);
+        getEngine().failEngine(reason, e);
     }
 
     public Engine.Searcher acquireSearcher(String source) {
         readAllowed();
-        return engine().acquireSearcher(source);
+        Engine engine = getEngine();
+        try {
+            return searcherWrapper == null ? engine.acquireSearcher(source) : searcherWrapper.wrap(engineConfig, engine.acquireSearcher(source));
+        } catch (IOException ex) {
+            throw new ElasticsearchException("failed to wrap searcher", ex);
+        }
     }
 
     public void close(String reason, boolean flushEngine) throws IOException {
@@ -785,8 +770,14 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         }
     }
 
+
     public IndexShard postRecovery(String reason) throws IndexShardStartedException, IndexShardRelocatedException, IndexShardClosedException {
-        indicesLifecycle.beforeIndexShardPostRecovery(this);
+        if (mapperService.hasMapping(PercolatorService.TYPE_NAME)) {
+            refresh("percolator_load_queries");
+            try (Engine.Searcher searcher = getEngine().acquireSearcher("percolator_load_queries")) {
+                this.percolatorQueriesRegistry.loadQueries(searcher.reader());
+            }
+        }
         synchronized (mutex) {
             if (state == IndexShardState.CLOSED) {
                 throw new IndexShardClosedException(shardId);
@@ -800,7 +791,6 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
             recoveryState.setStage(RecoveryState.Stage.DONE);
             changeState(IndexShardState.POST_RECOVERY, reason);
         }
-        indicesLifecycle.afterIndexShardPostRecovery(this);
         return this;
     }
 
@@ -824,7 +814,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         if (state != IndexShardState.RECOVERING) {
             throw new IndexShardNotRecoveringException(shardId, state);
         }
-        return engineConfig.getTranslogRecoveryPerformer().performBatchRecovery(engine(), operations);
+        return engineConfig.getTranslogRecoveryPerformer().performBatchRecovery(getEngine(), operations);
     }
 
     /**
@@ -863,7 +853,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
      * a remote peer.
      */
     public void skipTranslogRecovery() throws IOException {
-        assert engineUnsafe() == null : "engine was already created";
+        assert getEngineOrNull() == null : "engine was already created";
         internalPerformTranslogRecovery(true, true);
         assert recoveryState.getTranslog().recoveredOperations() == 0;
     }
@@ -903,7 +893,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
      */
     public void finalizeRecovery() {
         recoveryState().setStage(RecoveryState.Stage.FINALIZE);
-        engine().refresh("recovery_finalization");
+        getEngine().refresh("recovery_finalization");
         startScheduledTasksIfNeeded();
         engineConfig.setEnableGcDeletes(true);
     }
@@ -924,20 +914,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         }
     }
 
-    /** Returns timestamp of last indexing operation */
-    public long getLastWriteNS() {
-        return lastWriteNS;
-    }
-
-    private void ensureWriteAllowed(Engine.Operation op) throws IllegalIndexShardStateException {
-        lastWriteNS = op.startTime();
-        if (active.getAndSet(true) == false) {
-            // We are currently inactive, but a new write operation just showed up, so we now notify IMC
-            // to wake up and fix our indexing buffer.  We could do this async instead, but cost should
-            // be low, and it's rare this happens.
-            indexingMemoryController.forceCheck();
-        }
-        Engine.Operation.Origin origin = op.origin();
+    private void writeAllowed(Engine.Operation.Origin origin) throws IllegalIndexShardStateException {
         IndexShardState state = this.state; // one time volatile read
 
         if (origin == Engine.Operation.Origin.PRIMARY) {
@@ -999,8 +976,6 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         this.failedEngineListener.delegates.add(failedEngineListener);
     }
 
-    /** Change the indexing and translog buffer sizes.  If {@code IndexWriter} is currently using more than
-     *  the new buffering indexing size then we do a refresh to free up the heap. */
     public void updateBufferSize(ByteSizeValue shardIndexingBufferSize, ByteSizeValue shardTranslogBufferSize) {
 
         final EngineConfig config = engineConfig;
@@ -1008,7 +983,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
 
         config.setIndexingBufferSize(shardIndexingBufferSize);
 
-        Engine engine = engineUnsafe();
+        Engine engine = getEngineOrNull();
         if (engine == null) {
             logger.debug("updateBufferSize: engine is closed; skipping");
             return;
@@ -1018,21 +993,19 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         if (preValue.bytes() != shardIndexingBufferSize.bytes()) {
             // so we push changes these changes down to IndexWriter:
             engine.onSettingsChanged();
-            logger.debug("updating index_buffer_size from [{}] to [{}]", preValue, shardIndexingBufferSize);
 
-            long iwBytesUsed = engine.indexWriterRAMBytesUsed();
-            if (shardIndexingBufferSize.bytes() < iwBytesUsed) {
-                // our allowed buffer was changed to less than we are currently using; we ask IW to refresh
-                // so it clears its buffers (otherwise it won't clear until the next indexing/delete op)
-                logger.debug("refresh because index buffer decreased to [{}] and IndexWriter is now using [{}] bytes",
-                             shardIndexingBufferSize, iwBytesUsed);
-
-                // TODO: should IW have an API to move segments to disk, but not refresh?
+            if (shardIndexingBufferSize == EngineConfig.INACTIVE_SHARD_INDEXING_BUFFER) {
+                // it's inactive: make sure we do a refresh / full IW flush in this case, since the memory
+                // changes only after a "data" change has happened to the writer
+                // the index writer lazily allocates memory and a refresh will clean it all up.
+                logger.debug("updating index_buffer_size from [{}] to (inactive) [{}]", preValue, shardIndexingBufferSize);
                 try {
                     refresh("update index buffer");
                 } catch (Throwable e) {
-                    logger.warn("failed to refresh after decreasing index buffer", e);
+                    logger.warn("failed to refresh after setting shard to inactive", e);
                 }
+            } else {
+                logger.debug("updating index_buffer_size from [{}] to [{}]", preValue, shardIndexingBufferSize);
             }
         }
 
@@ -1040,17 +1013,8 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
     }
 
     public void markAsInactive() {
-        if (active.getAndSet(false)) {
-            updateBufferSize(EngineConfig.INACTIVE_SHARD_INDEXING_BUFFER, TranslogConfig.INACTIVE_SHARD_TRANSLOG_BUFFER);
-            logger.debug("shard is now inactive");
-            indicesLifecycle.onShardInactive(this);
-        }
-    }
-
-    /** Returns {@code true} if this shard is active (has seen indexing ops in the last {@link
-     *  IndexingMemoryController#SHARD_INACTIVE_TIME_SETTING} (default 5 minutes), else {@code false}. */
-    public boolean getActive() {
-        return active.get();
+        updateBufferSize(EngineConfig.INACTIVE_SHARD_INDEXING_BUFFER, TranslogConfig.INACTIVE_SHARD_TRANSLOG_BUFFER);
+        indicesLifecycle.onShardInactive(this);
     }
 
     public final boolean isFlushOnClose() {
@@ -1094,7 +1058,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
      */
     boolean shouldFlush() {
         if (disableFlush == false) {
-            Engine engine = engineUnsafe();
+            Engine engine = getEngineOrNull();
             if (engine != null) {
                 try {
                     Translog translog = engine.getTranslog();
@@ -1208,15 +1172,37 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         searchService.onRefreshSettings(settings);
         indexingService.onRefreshSettings(settings);
         if (change) {
-            engine().onSettingsChanged();
+            getEngine().onSettingsChanged();
         }
     }
 
+    public Translog.View acquireTranslogView() {
+        Engine engine = getEngine();
+        assert engine.getTranslog() != null : "translog must not be null";
+        return engine.getTranslog().newView();
+    }
+
+    public List<Segment> segments(boolean verbose) {
+        return getEngine().segments(verbose);
+    }
+
+    public void flushAndCloseEngine() throws IOException {
+        getEngine().flushAndClose();
+    }
+
+    public Translog getTranslog() {
+        return getEngine().getTranslog();
+    }
+
+    public PercolateStats percolateStats() {
+        return percolatorQueriesRegistry.stats();
+    }
+
     class EngineRefresher implements Runnable {
         @Override
         public void run() {
             // we check before if a refresh is needed, if not, we reschedule, otherwise, we fork, refresh, and then reschedule
-            if (!engine().refreshNeeded()) {
+            if (!getEngine().refreshNeeded()) {
                 reschedule();
                 return;
             }
@@ -1224,7 +1210,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
                 @Override
                 public void run() {
                     try {
-                        if (engine().refreshNeeded()) {
+                        if (getEngine().refreshNeeded()) {
                             refresh("schedule");
                         }
                     } catch (EngineClosedException e) {
@@ -1337,8 +1323,8 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         recoveryState.getVerifyIndex().checkIndexTime(Math.max(0, TimeValue.nsecToMSec(System.nanoTime() - timeNS)));
     }
 
-    public Engine engine() {
-        Engine engine = engineUnsafe();
+    Engine getEngine() {
+        Engine engine = getEngineOrNull();
         if (engine == null) {
             throw new EngineClosedException(shardId);
         }
@@ -1347,7 +1333,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
 
     /** NOTE: returns null if engine is not yet started (e.g. recovery phase 1, copying over index files, is still running), or if engine is
      *  closed. */
-    protected Engine engineUnsafe() {
+    protected Engine getEngineOrNull() {
         return this.currentEngineReference.get();
     }
 
@@ -1440,7 +1426,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         };
         return new EngineConfig(shardId,
                 threadPool, indexingService, indexSettings, warmer, store, deletionPolicy, mergePolicyConfig.getMergePolicy(), mergeSchedulerConfig,
-                mapperService.indexAnalyzer(), similarityService.similarity(), codecService, failedEngineListener, translogRecoveryPerformer, indexCache.query(), cachingPolicy, wrappingService, translogConfig);
+                mapperService.indexAnalyzer(), similarityService.similarity(), codecService, failedEngineListener, translogRecoveryPerformer, indexCache.query(), cachingPolicy, translogConfig);
     }
 
     private static class IndexShardOperationCounter extends AbstractRefCounted {
@@ -1481,7 +1467,7 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
      */
     public void sync(Translog.Location location) {
         try {
-            final Engine engine = engine();
+            final Engine engine = getEngine();
             engine.getTranslog().ensureSynced(location);
         } catch (EngineClosedException ex) {
             // that's fine since we already synced everything on engine close - this also is conform with the methods documentation
@@ -1552,4 +1538,5 @@ public class IndexShard extends AbstractIndexShardComponent implements IndexSett
         }
         return false;
     }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardModule.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardModule.java
deleted file mode 100644
index 188669f..0000000
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardModule.java
+++ /dev/null
@@ -1,76 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.shard;
-
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.inject.multibindings.Multibinder;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.engine.IndexSearcherWrapper;
-import org.elasticsearch.index.engine.IndexSearcherWrappingService;
-import org.elasticsearch.index.engine.EngineFactory;
-import org.elasticsearch.index.engine.InternalEngineFactory;
-
-/**
- * The {@code IndexShardModule} module is responsible for binding the correct
- * shard id, index shard, engine factory, and warming service for a newly
- * created shard.
- */
-public class IndexShardModule extends AbstractModule {
-
-    private final ShardId shardId;
-    private final Settings settings;
-    private final boolean primary;
-
-    // pkg private so tests can mock
-    Class<? extends EngineFactory> engineFactoryImpl = InternalEngineFactory.class;
-
-    public IndexShardModule(ShardId shardId, boolean primary, Settings settings) {
-        this.settings = settings;
-        this.shardId = shardId;
-        this.primary = primary;
-        if (settings.get("index.translog.type") != null) {
-            throw new IllegalStateException("a custom translog type is no longer supported. got [" + settings.get("index.translog.type") + "]");
-        }
-    }
-
-    /** Return true if a shadow engine should be used */
-    protected boolean useShadowEngine() {
-        return primary == false && IndexMetaData.isIndexUsingShadowReplicas(settings);
-    }
-
-    @Override
-    protected void configure() {
-        bind(ShardId.class).toInstance(shardId);
-        if (useShadowEngine()) {
-            bind(IndexShard.class).to(ShadowIndexShard.class).asEagerSingleton();
-        } else {
-            bind(IndexShard.class).asEagerSingleton();
-        }
-
-        bind(EngineFactory.class).to(engineFactoryImpl);
-        bind(IndexSearcherWrappingService.class).asEagerSingleton();
-        // this injects an empty set in IndexSearcherWrappingService, otherwise guice can't construct IndexSearcherWrappingService
-        Multibinder<IndexSearcherWrapper> multibinder
-                = Multibinder.newSetBinder(binder(), IndexSearcherWrapper.class);
-    }
-
-
-}
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java
index d66df0b..c81b9e5 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/ShadowIndexShard.java
@@ -18,35 +18,16 @@
  */
 package org.elasticsearch.index.shard;
 
-import java.io.IOException;
-
-import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.util.BigArrays;
-import org.elasticsearch.index.aliases.IndexAliasesService;
-import org.elasticsearch.index.cache.IndexCache;
-import org.elasticsearch.index.codec.CodecService;
+import org.elasticsearch.index.IndexServicesProvider;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.engine.EngineConfig;
-import org.elasticsearch.index.engine.EngineFactory;
-import org.elasticsearch.index.engine.IndexSearcherWrappingService;
-import org.elasticsearch.index.fielddata.IndexFieldDataService;
-import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.merge.MergeStats;
-import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.settings.IndexSettings;
-import org.elasticsearch.index.settings.IndexSettingsService;
-import org.elasticsearch.index.similarity.SimilarityService;
 import org.elasticsearch.index.store.Store;
-import org.elasticsearch.index.termvectors.TermVectorsService;
-import org.elasticsearch.indices.IndicesLifecycle;
-import org.elasticsearch.indices.IndicesWarmer;
-import org.elasticsearch.indices.cache.query.IndicesQueryCache;
-import org.elasticsearch.indices.memory.IndexingMemoryController;
-import org.elasticsearch.threadpool.ThreadPool;
+
+import java.io.IOException;
 
 /**
  * ShadowIndexShard extends {@link IndexShard} to add file synchronization
@@ -56,25 +37,8 @@ import org.elasticsearch.threadpool.ThreadPool;
  */
 public final class ShadowIndexShard extends IndexShard {
 
-    @Inject
-    public ShadowIndexShard(ShardId shardId, @IndexSettings Settings indexSettings,
-                            IndicesLifecycle indicesLifecycle, Store store,
-                            ThreadPool threadPool, MapperService mapperService,
-                            IndexQueryParserService queryParserService, IndexCache indexCache,
-                            IndexAliasesService indexAliasesService, IndicesQueryCache indicesQueryCache,
-                            CodecService codecService, TermVectorsService termVectorsService, IndexFieldDataService indexFieldDataService,
-                            @Nullable IndicesWarmer warmer,
-                            SimilarityService similarityService,
-                            EngineFactory factory,
-                            ShardPath path, BigArrays bigArrays, IndexSearcherWrappingService wrappingService,
-                            IndexingMemoryController indexingMemoryController) throws IOException {
-        super(shardId, indexSettings, indicesLifecycle, store,
-              threadPool, mapperService, queryParserService, indexCache, indexAliasesService,
-              indicesQueryCache, codecService,
-              termVectorsService, indexFieldDataService,
-              warmer, similarityService,
-              factory, path, bigArrays, wrappingService,
-              indexingMemoryController);
+    public ShadowIndexShard(ShardId shardId, @IndexSettings Settings indexSettings, ShardPath path, Store store, IndexServicesProvider provider) throws IOException {
+        super(shardId, indexSettings, path, store, provider);
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
index 991af6d..091985e 100644
--- a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
+++ b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
@@ -26,6 +26,7 @@ import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.store.RateLimiter;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
+import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterService;
@@ -93,6 +94,8 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
 
     private RateLimitingInputStream.Listener snapshotThrottleListener;
 
+    private RateLimitingInputStream.Listener restoreThrottleListener;
+
     private boolean compress;
 
     private final ParseFieldMatcher parseFieldMatcher;
@@ -147,6 +150,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
         this.restoreRateLimiter = restoreRateLimiter;
         this.rateLimiterListener = rateLimiterListener;
         this.snapshotThrottleListener = nanos -> rateLimiterListener.onSnapshotPause(nanos);
+        this.restoreThrottleListener = nanos -> rateLimiterListener.onRestorePause(nanos);
         this.compress = compress;
         indexShardSnapshotFormat = new ChecksumBlobStoreFormat<>(SNAPSHOT_CODEC, SNAPSHOT_NAME_FORMAT, BlobStoreIndexShardSnapshot.PROTO, parseFieldMatcher, isCompress());
         indexShardSnapshotLegacyFormat = new LegacyBlobStoreFormat<>(LEGACY_SNAPSHOT_NAME_FORMAT, BlobStoreIndexShardSnapshot.PROTO, parseFieldMatcher);
@@ -486,7 +490,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
         public SnapshotContext(SnapshotId snapshotId, ShardId shardId, IndexShardSnapshotStatus snapshotStatus) {
             super(snapshotId, Version.CURRENT, shardId);
             IndexService indexService = indicesService.indexServiceSafe(shardId.getIndex());
-            store = indexService.shard(shardId.id()).store();
+            store = indexService.getShardOrNull(shardId.id()).store();
             this.snapshotStatus = snapshotStatus;
 
         }
@@ -770,7 +774,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
          */
         public RestoreContext(SnapshotId snapshotId, Version version, ShardId shardId, ShardId snapshotShardId, RecoveryState recoveryState) {
             super(snapshotId, version, shardId, snapshotShardId);
-            store = indicesService.indexServiceSafe(shardId.getIndex()).shard(shardId.id()).store();
+            store = indicesService.indexServiceSafe(shardId.getIndex()).getShardOrNull(shardId.id()).store();
             this.recoveryState = recoveryState;
         }
 
@@ -891,16 +895,20 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
          */
         private void restoreFile(final FileInfo fileInfo) throws IOException {
             boolean success = false;
-            try (InputStream stream = new PartSliceStream(blobContainer, fileInfo)) {
+
+            try (InputStream partSliceStream = new PartSliceStream(blobContainer, fileInfo)) {
+                final InputStream stream;
+                if (restoreRateLimiter == null) {
+                    stream = partSliceStream;
+                } else {
+                    stream = new RateLimitingInputStream(partSliceStream, restoreRateLimiter, restoreThrottleListener);
+                }
                 try (final IndexOutput indexOutput = store.createVerifyingOutput(fileInfo.physicalName(), fileInfo.metadata(), IOContext.DEFAULT)) {
                     final byte[] buffer = new byte[BUFFER_SIZE];
                     int length;
                     while ((length = stream.read(buffer)) > 0) {
                         indexOutput.writeBytes(buffer, 0, length);
                         recoveryState.getIndex().addRecoveredBytesToFile(fileInfo.name(), length);
-                        if (restoreRateLimiter != null) {
-                            rateLimiterListener.onRestorePause(restoreRateLimiter.pause(length));
-                        }
                     }
                     Store.verify(indexOutput);
                     indexOutput.close();
diff --git a/core/src/main/java/org/elasticsearch/index/store/IndexStore.java b/core/src/main/java/org/elasticsearch/index/store/IndexStore.java
index 4022dd7..3a23a09 100644
--- a/core/src/main/java/org/elasticsearch/index/store/IndexStore.java
+++ b/core/src/main/java/org/elasticsearch/index/store/IndexStore.java
@@ -27,6 +27,7 @@ import org.elasticsearch.index.AbstractIndexComponent;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.settings.IndexSettingsService;
+import org.elasticsearch.index.shard.ShardPath;
 import org.elasticsearch.indices.store.IndicesStore;
 
 import java.io.Closeable;
@@ -112,7 +113,7 @@ public class IndexStore extends AbstractIndexComponent implements Closeable {
     /**
      * The shard store class that should be used for each shard.
      */
-    public Class<? extends DirectoryService> shardDirectory() {
-        return FsDirectoryService.class;
+    public DirectoryService newDirectoryService(ShardPath path) {
+        return new FsDirectoryService(indexSettings, this, path);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/store/Store.java b/core/src/main/java/org/elasticsearch/index/store/Store.java
index b82973d..7fb1b40 100644
--- a/core/src/main/java/org/elasticsearch/index/store/Store.java
+++ b/core/src/main/java/org/elasticsearch/index/store/Store.java
@@ -1286,14 +1286,15 @@ public class Store extends AbstractIndexShardComponent implements Closeable, Ref
         @Override
         public void writeByte(byte b) throws IOException {
             final long writtenBytes = this.writtenBytes++;
-            if (writtenBytes == checksumPosition) {
-                readAndCompareChecksum();
-            } else if (writtenBytes > checksumPosition) { // we are writing parts of the checksum....
+            if (writtenBytes >= checksumPosition) { // we are writing parts of the checksum....
+                if (writtenBytes == checksumPosition) {
+                    readAndCompareChecksum();
+                }
                 final int index = Math.toIntExact(writtenBytes - checksumPosition);
                 if (index < footerChecksum.length) {
                     footerChecksum[index] = b;
                     if (index == footerChecksum.length-1) {
-                        verify();// we have recorded the entire checksum
+                        verify(); // we have recorded the entire checksum
                     }
                 } else {
                     verify(); // fail if we write more than expected
@@ -1315,16 +1316,7 @@ public class Store extends AbstractIndexShardComponent implements Closeable, Ref
         @Override
         public void writeBytes(byte[] b, int offset, int length) throws IOException {
             if (writtenBytes + length > checksumPosition) {
-                if (actualChecksum == null) {
-                    assert writtenBytes <= checksumPosition;
-                    final int bytesToWrite = (int) (checksumPosition - writtenBytes);
-                    out.writeBytes(b, offset, bytesToWrite);
-                    readAndCompareChecksum();
-                    offset += bytesToWrite;
-                    length -= bytesToWrite;
-                    writtenBytes += bytesToWrite;
-                }
-                for (int i = 0; i < length; i++) {
+                for (int i = 0; i < length; i++) { // don't optimze writing the last block of bytes
                     writeByte(b[offset+i]);
                 }
             } else {
@@ -1332,7 +1324,6 @@ public class Store extends AbstractIndexShardComponent implements Closeable, Ref
                 writtenBytes += length;
             }
         }
-
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/index/translog/TranslogConfig.java b/core/src/main/java/org/elasticsearch/index/translog/TranslogConfig.java
index f18da82..4d74961 100644
--- a/core/src/main/java/org/elasticsearch/index/translog/TranslogConfig.java
+++ b/core/src/main/java/org/elasticsearch/index/translog/TranslogConfig.java
@@ -44,8 +44,6 @@ public final class TranslogConfig {
     public static final String INDEX_TRANSLOG_SYNC_INTERVAL = "index.translog.sync_interval";
     public static final ByteSizeValue INACTIVE_SHARD_TRANSLOG_BUFFER = ByteSizeValue.parseBytesSizeValue("1kb", "INACTIVE_SHARD_TRANSLOG_BUFFER");
 
-    public static final ByteSizeValue DEFAULT_SHARD_TRANSLOG_BUFFER_SIZE = ByteSizeValue.parseBytesSizeValue("64k", INDEX_TRANSLOG_BUFFER_SIZE);
-
     private final TimeValue syncInterval;
     private final BigArrays bigArrays;
     private final ThreadPool threadPool;
@@ -75,7 +73,7 @@ public final class TranslogConfig {
         this.threadPool = threadPool;
         this.bigArrays = bigArrays;
         this.type = TranslogWriter.Type.fromString(indexSettings.get(INDEX_TRANSLOG_FS_TYPE, TranslogWriter.Type.BUFFERED.name()));
-        this.bufferSize = (int) indexSettings.getAsBytesSize(INDEX_TRANSLOG_BUFFER_SIZE, DEFAULT_SHARD_TRANSLOG_BUFFER_SIZE).bytes(); // Not really interesting, updated by IndexingMemoryController...
+        this.bufferSize = (int) indexSettings.getAsBytesSize(INDEX_TRANSLOG_BUFFER_SIZE, ByteSizeValue.parseBytesSizeValue("64k", INDEX_TRANSLOG_BUFFER_SIZE)).bytes(); // Not really interesting, updated by IndexingMemoryController...
 
         syncInterval = indexSettings.getAsTime(INDEX_TRANSLOG_SYNC_INTERVAL, TimeValue.timeValueSeconds(5));
         if (syncInterval.millis() > 0 && threadPool != null) {
diff --git a/core/src/main/java/org/elasticsearch/indices/IndicesLifecycle.java b/core/src/main/java/org/elasticsearch/indices/IndicesLifecycle.java
index 211b6d4..8c761df 100644
--- a/core/src/main/java/org/elasticsearch/indices/IndicesLifecycle.java
+++ b/core/src/main/java/org/elasticsearch/indices/IndicesLifecycle.java
@@ -98,17 +98,6 @@ public interface IndicesLifecycle {
         }
 
         /**
-         * Called right after the shard is moved into POST_RECOVERY mode
-         */
-        public void afterIndexShardPostRecovery(IndexShard indexShard) {}
-
-        /**
-         * Called right before the shard is moved into POST_RECOVERY mode.
-         * The shard is ready to be used but not yet marked as POST_RECOVERY.
-         */
-        public void beforeIndexShardPostRecovery(IndexShard indexShard) {}
-
-        /**
          * Called after the index shard has been started.
          */
         public void afterIndexShardStarted(IndexShard indexShard) {
diff --git a/core/src/main/java/org/elasticsearch/indices/IndicesService.java b/core/src/main/java/org/elasticsearch/indices/IndicesService.java
index 3b24544..ae69eee 100644
--- a/core/src/main/java/org/elasticsearch/indices/IndicesService.java
+++ b/core/src/main/java/org/elasticsearch/indices/IndicesService.java
@@ -53,18 +53,15 @@ import org.elasticsearch.index.IndexNameModule;
 import org.elasticsearch.index.IndexNotFoundException;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.LocalNodeIdModule;
-import org.elasticsearch.index.aliases.IndexAliasesServiceModule;
 import org.elasticsearch.index.analysis.AnalysisModule;
 import org.elasticsearch.index.analysis.AnalysisService;
 import org.elasticsearch.index.cache.IndexCache;
 import org.elasticsearch.index.cache.IndexCacheModule;
-import org.elasticsearch.index.fielddata.IndexFieldDataModule;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
 import org.elasticsearch.index.flush.FlushStats;
 import org.elasticsearch.index.get.GetStats;
 import org.elasticsearch.index.indexing.IndexingStats;
 import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.mapper.MapperServiceModule;
 import org.elasticsearch.index.merge.MergeStats;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.recovery.RecoveryStats;
@@ -343,10 +340,7 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
         modules.add(new AnalysisModule(indexSettings, indicesAnalysisService));
         modules.add(new SimilarityModule(indexSettings));
         modules.add(new IndexCacheModule(indexSettings));
-        modules.add(new IndexFieldDataModule(indexSettings));
-        modules.add(new MapperServiceModule());
-        modules.add(new IndexAliasesServiceModule());
-        modules.add(new IndexModule(indexSettings));
+        modules.add(new IndexModule());
         
         pluginsService.processModules(modules);
 
diff --git a/core/src/main/java/org/elasticsearch/indices/IndicesWarmer.java b/core/src/main/java/org/elasticsearch/indices/IndicesWarmer.java
index 9ee45b2..2a82774 100644
--- a/core/src/main/java/org/elasticsearch/indices/IndicesWarmer.java
+++ b/core/src/main/java/org/elasticsearch/indices/IndicesWarmer.java
@@ -87,7 +87,7 @@ public final class IndicesWarmer extends AbstractComponent {
         if (indexService == null) {
             return;
         }
-        final IndexShard indexShard = indexService.shard(context.shardId().id());
+        final IndexShard indexShard = indexService.getShardOrNull(context.shardId().id());
         if (indexShard == null) {
             return;
         }
diff --git a/core/src/main/java/org/elasticsearch/indices/InternalIndicesLifecycle.java b/core/src/main/java/org/elasticsearch/indices/InternalIndicesLifecycle.java
index 7705071..16c0c36 100644
--- a/core/src/main/java/org/elasticsearch/indices/InternalIndicesLifecycle.java
+++ b/core/src/main/java/org/elasticsearch/indices/InternalIndicesLifecycle.java
@@ -121,28 +121,6 @@ public class InternalIndicesLifecycle extends AbstractComponent implements Indic
         }
     }
 
-    public void beforeIndexShardPostRecovery(IndexShard indexShard) {
-        for (Listener listener : listeners) {
-            try {
-                listener.beforeIndexShardPostRecovery(indexShard);
-            } catch (Throwable t) {
-                logger.warn("{} failed to invoke before shard post recovery callback", t, indexShard.shardId());
-                throw t;
-            }
-        }
-    }
-
-
-    public void afterIndexShardPostRecovery(IndexShard indexShard) {
-        for (Listener listener : listeners) {
-            try {
-                listener.afterIndexShardPostRecovery(indexShard);
-            } catch (Throwable t) {
-                logger.warn("{} failed to invoke after shard post recovery callback", t, indexShard.shardId());
-                throw t;
-            }
-        }
-    }
 
     public void afterIndexShardStarted(IndexShard indexShard) {
         for (Listener listener : listeners) {
diff --git a/core/src/main/java/org/elasticsearch/indices/NodeIndicesStats.java b/core/src/main/java/org/elasticsearch/indices/NodeIndicesStats.java
index 747d15a..c8142f3 100644
--- a/core/src/main/java/org/elasticsearch/indices/NodeIndicesStats.java
+++ b/core/src/main/java/org/elasticsearch/indices/NodeIndicesStats.java
@@ -38,7 +38,7 @@ import org.elasticsearch.index.flush.FlushStats;
 import org.elasticsearch.index.get.GetStats;
 import org.elasticsearch.index.indexing.IndexingStats;
 import org.elasticsearch.index.merge.MergeStats;
-import org.elasticsearch.index.percolator.stats.PercolateStats;
+import org.elasticsearch.index.percolator.PercolateStats;
 import org.elasticsearch.index.recovery.RecoveryStats;
 import org.elasticsearch.index.refresh.RefreshStats;
 import org.elasticsearch.index.search.stats.SearchStats;
diff --git a/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java b/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java
index eb2bc24..6bce5bc 100644
--- a/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java
+++ b/core/src/main/java/org/elasticsearch/indices/cluster/IndicesClusterStateService.java
@@ -327,7 +327,7 @@ public class IndicesClusterStateService extends AbstractLifecycleComponent<Indic
                 // already deleted on us, ignore it
                 continue;
             }
-            IndexSettingsService indexSettingsService = indexService.injector().getInstance(IndexSettingsService.class);
+            IndexSettingsService indexSettingsService = indexService.settingsService();
             indexSettingsService.refreshSettings(indexMetaData.settings());
         }
     }
@@ -505,7 +505,7 @@ public class IndicesClusterStateService extends AbstractLifecycleComponent<Indic
                 continue;
             }
 
-            IndexShard indexShard = indexService.shard(shardId);
+            IndexShard indexShard = indexService.getShardOrNull(shardId);
             if (indexShard != null) {
                 ShardRouting currentRoutingEntry = indexShard.routingEntry();
                 // if the current and global routing are initializing, but are still not the same, its a different "shard" being allocated
@@ -591,7 +591,7 @@ public class IndicesClusterStateService extends AbstractLifecycleComponent<Indic
         final int shardId = shardRouting.id();
 
         if (indexService.hasShard(shardId)) {
-            IndexShard indexShard = indexService.shardSafe(shardId);
+            IndexShard indexShard = indexService.getShard(shardId);
             if (indexShard.state() == IndexShardState.STARTED || indexShard.state() == IndexShardState.POST_RECOVERY) {
                 // the master thinks we are initializing, but we are already started or on POST_RECOVERY and waiting
                 // for master to confirm a shard started message (either master failover, or a cluster event before
@@ -647,7 +647,7 @@ public class IndicesClusterStateService extends AbstractLifecycleComponent<Indic
                 return;
             }
         }
-        final IndexShard indexShard = indexService.shardSafe(shardId);
+        final IndexShard indexShard = indexService.getShard(shardId);
 
         if (indexShard.ignoreRecoveryAttempt()) {
             // we are already recovering (we can get to this state since the cluster event can happen several
@@ -835,7 +835,7 @@ public class IndicesClusterStateService extends AbstractLifecycleComponent<Indic
             ShardRouting shardRouting = null;
             final IndexService indexService = indicesService.indexService(shardId.index().name());
             if (indexService != null) {
-                IndexShard indexShard = indexService.shard(shardId.id());
+                IndexShard indexShard = indexService.getShardOrNull(shardId.id());
                 if (indexShard != null) {
                     shardRouting = indexShard.routingEntry();
                 }
diff --git a/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java b/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
index 92a4e93..b6fc3cd 100644
--- a/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
+++ b/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
@@ -398,7 +398,7 @@ public class SyncedFlushService extends AbstractComponent {
     }
 
     private PreSyncedFlushResponse performPreSyncedFlush(PreSyncedFlushRequest request) {
-        IndexShard indexShard = indicesService.indexServiceSafe(request.shardId().getIndex()).shardSafe(request.shardId().id());
+        IndexShard indexShard = indicesService.indexServiceSafe(request.shardId().getIndex()).getShard(request.shardId().id());
         FlushRequest flushRequest = new FlushRequest().force(false).waitIfOngoing(true);
         logger.trace("{} performing pre sync flush", request.shardId());
         Engine.CommitId commitId = indexShard.flush(flushRequest);
@@ -408,7 +408,7 @@ public class SyncedFlushService extends AbstractComponent {
 
     private SyncedFlushResponse performSyncedFlush(SyncedFlushRequest request) {
         IndexService indexService = indicesService.indexServiceSafe(request.shardId().getIndex());
-        IndexShard indexShard = indexService.shardSafe(request.shardId().id());
+        IndexShard indexShard = indexService.getShard(request.shardId().id());
         logger.trace("{} performing sync flush. sync id [{}], expected commit id {}", request.shardId(), request.syncId(), request.expectedCommitId());
         Engine.SyncedFlushResult result = indexShard.syncFlush(request.syncId(), request.expectedCommitId());
         logger.trace("{} sync flush done. sync id [{}], result [{}]", request.shardId(), request.syncId(), result);
@@ -426,7 +426,7 @@ public class SyncedFlushService extends AbstractComponent {
 
     private InFlightOpsResponse performInFlightOps(InFlightOpsRequest request) {
         IndexService indexService = indicesService.indexServiceSafe(request.shardId().getIndex());
-        IndexShard indexShard = indexService.shardSafe(request.shardId().id());
+        IndexShard indexShard = indexService.getShard(request.shardId().id());
         if (indexShard.routingEntry().primary() == false) {
             throw new IllegalStateException("[" + request.shardId() +"] expected a primary shard");
         }
diff --git a/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java b/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java
index 12c1242..a84fff3 100644
--- a/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java
+++ b/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java
@@ -42,6 +42,9 @@ import org.elasticsearch.threadpool.ThreadPool;
 import java.util.*;
 import java.util.concurrent.ScheduledFuture;
 
+/**
+ *
+ */
 public class IndexingMemoryController extends AbstractLifecycleComponent<IndexingMemoryController> {
 
     /** How much heap (% or bytes) we will share across all actively indexing shards on this node (default: 10%). */
@@ -161,6 +164,7 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
 
         this.statusChecker = new ShardsIndicesStatusChecker();
 
+
         logger.debug("using indexing buffer size [{}], with {} [{}], {} [{}], {} [{}], {} [{}]",
                 this.indexingBuffer,
                 MIN_SHARD_INDEX_BUFFER_SIZE_SETTING, this.minShardIndexBufferSize,
@@ -171,7 +175,7 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
 
     @Override
     protected void doStart() {
-        // it's fine to run it on the scheduler thread, no busy work
+        // its fine to run it on the scheduler thread, no busy work
         this.scheduler = threadPool.scheduleWithFixedDelay(statusChecker, interval);
     }
 
@@ -230,7 +234,8 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
     protected IndexShard getShard(ShardId shardId) {
         IndexService indexService = indicesService.indexService(shardId.index().name());
         if (indexService != null) {
-            return indexService.shard(shardId.id());
+            IndexShard indexShard = indexService.getShardOrNull(shardId.id());
+            return indexShard;
         }
         return null;
     }
@@ -250,43 +255,49 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
         }
     }
 
-    protected boolean isShardIdle(ShardId shardId, long inactiveTimeNS) {
-        final IndexShard shard = getShard(shardId);
-        if (shard == null) {
-            return false;
-        }
-        return currentTimeInNanos() - shard.getLastWriteNS() >= inactiveTimeNS;
-    }
-
 
-    /** returns {@link IndexShard#getActive} if the shard exists, else null */
-    protected Boolean getShardActive(ShardId shardId) {
+    /** returns the current translog status (generation id + ops) for the given shard id. Returns null if unavailable. */
+    protected ShardIndexingStatus getTranslogStatus(ShardId shardId) {
         final IndexShard indexShard = getShard(shardId);
         if (indexShard == null) {
             return null;
         }
-        return indexShard.getActive();
+        final Translog translog;
+        try {
+            translog = indexShard.getTranslog();
+        } catch (EngineClosedException e) {
+            // not ready yet to be checked for activity
+            return null;
+        }
+
+        ShardIndexingStatus status = new ShardIndexingStatus();
+        status.translogId = translog.currentFileGeneration();
+        status.translogNumberOfOperations = translog.totalOperations();
+        return status;
     }
 
-    /** Check if any shards active status changed, now. */
-    public void forceCheck() {
+    // used for tests
+    void forceCheck() {
         statusChecker.run();
     }
 
     class ShardsIndicesStatusChecker implements Runnable {
 
-        // True if the shard was active last time we checked
-        private final Map<ShardId,Boolean> shardWasActive = new HashMap<>();
+        private final Map<ShardId, ShardIndexingStatus> shardsIndicesStatus = new HashMap<>();
 
         @Override
-        public synchronized void run() {
+        public void run() {
             EnumSet<ShardStatusChangeType> changes = purgeDeletedAndClosedShards();
 
-            final int activeShardCount = updateShardStatuses(changes);
+            final List<ShardId> activeToInactiveIndexingShards = new ArrayList<>();
+            final int activeShards = updateShardStatuses(changes, activeToInactiveIndexingShards);
+            for (ShardId indexShard : activeToInactiveIndexingShards) {
+                markShardAsInactive(indexShard);
+            }
 
             if (changes.isEmpty() == false) {
                 // Something changed: recompute indexing buffers:
-                calcAndSetShardBuffers(activeShardCount, "[" + changes + "]");
+                calcAndSetShardBuffers(activeShards, "[" + changes + "]");
             }
         }
 
@@ -295,48 +306,43 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
          *
          * @return the current count of active shards
          */
-        private int updateShardStatuses(EnumSet<ShardStatusChangeType> changes) {
-            int activeShardCount = 0;
+        private int updateShardStatuses(EnumSet<ShardStatusChangeType> changes, List<ShardId> activeToInactiveIndexingShards) {
+            int activeShards = 0;
             for (ShardId shardId : availableShards()) {
 
-                // Is the shard active now?
-                Boolean isActive = getShardActive(shardId);
+                final ShardIndexingStatus currentStatus = getTranslogStatus(shardId);
 
-                if (isActive == null) {
+                if (currentStatus == null) {
                     // shard was closed..
                     continue;
-                } else if (isActive) {
-                    activeShardCount++;
                 }
 
-                // Was the shard active last time we checked?
-                Boolean wasActive = shardWasActive.get(shardId);
-
-                if (wasActive == null) {
-                    // First time we are seeing this shard
-                    shardWasActive.put(shardId, isActive);
+                ShardIndexingStatus status = shardsIndicesStatus.get(shardId);
+                if (status == null) {
+                    status = currentStatus;
+                    shardsIndicesStatus.put(shardId, status);
                     changes.add(ShardStatusChangeType.ADDED);
-                } else if (isActive) {
-                    // Shard is active now
-                    if (wasActive == false) {
-                        // Shard became active itself, since we last checked (due to new indexing op arriving)
+                } else {
+                    final boolean lastActiveIndexing = status.activeIndexing;
+                    status.updateWith(currentTimeInNanos(), currentStatus, inactiveTime.nanos());
+                    if (lastActiveIndexing && (status.activeIndexing == false)) {
+                        activeToInactiveIndexingShards.add(shardId);
+                        changes.add(ShardStatusChangeType.BECAME_INACTIVE);
+                        logger.debug("marking shard {} as inactive (inactive_time[{}]) indexing wise, setting size to [{}]",
+                                shardId,
+                                inactiveTime, EngineConfig.INACTIVE_SHARD_INDEXING_BUFFER);
+                    } else if ((lastActiveIndexing == false) && status.activeIndexing) {
                         changes.add(ShardStatusChangeType.BECAME_ACTIVE);
                         logger.debug("marking shard {} as active indexing wise", shardId);
-                        shardWasActive.put(shardId, true);
-
-                    } else if (isShardIdle(shardId, inactiveTime.nanos())) {
-                        // Make shard inactive now
-                        changes.add(ShardStatusChangeType.BECAME_INACTIVE);
-                        logger.debug("marking shard {} as inactive (inactive_time[{}]) indexing wise",
-                                     shardId,
-                                     inactiveTime);
-                        markShardAsInactive(shardId);
-                        shardWasActive.put(shardId, false);
                     }
                 }
+
+                if (status.activeIndexing) {
+                    activeShards++;
+                }
             }
 
-            return activeShardCount;
+            return activeShards;
         }
 
         /**
@@ -347,7 +353,7 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
         private EnumSet<ShardStatusChangeType> purgeDeletedAndClosedShards() {
             EnumSet<ShardStatusChangeType> changes = EnumSet.noneOf(ShardStatusChangeType.class);
 
-            Iterator<ShardId> statusShardIdIterator = shardWasActive.keySet().iterator();
+            Iterator<ShardId> statusShardIdIterator = shardsIndicesStatus.keySet().iterator();
             while (statusShardIdIterator.hasNext()) {
                 ShardId shardId = statusShardIdIterator.next();
                 if (shardAvailable(shardId) == false) {
@@ -358,15 +364,12 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
             return changes;
         }
 
-        private void calcAndSetShardBuffers(int activeShardCount, String reason) {
-            // TODO: we could be smarter here by taking into account how RAM the IndexWriter on each shard
-            // is actually using (using IW.ramBytesUsed), so that small indices (e.g. Marvel) would not
-            // get the same indexing buffer as large indices.  But it quickly gets tricky...
-            if (activeShardCount == 0) {
+        private void calcAndSetShardBuffers(int activeShards, String reason) {
+            if (activeShards == 0) {
                 logger.debug("no active shards (reason={})", reason);
                 return;
             }
-            ByteSizeValue shardIndexingBufferSize = new ByteSizeValue(indexingBuffer.bytes() / activeShardCount);
+            ByteSizeValue shardIndexingBufferSize = new ByteSizeValue(indexingBuffer.bytes() / activeShards);
             if (shardIndexingBufferSize.bytes() < minShardIndexBufferSize.bytes()) {
                 shardIndexingBufferSize = minShardIndexBufferSize;
             }
@@ -374,7 +377,7 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
                 shardIndexingBufferSize = maxShardIndexBufferSize;
             }
 
-            ByteSizeValue shardTranslogBufferSize = new ByteSizeValue(translogBuffer.bytes() / activeShardCount);
+            ByteSizeValue shardTranslogBufferSize = new ByteSizeValue(translogBuffer.bytes() / activeShards);
             if (shardTranslogBufferSize.bytes() < minShardTranslogBufferSize.bytes()) {
                 shardTranslogBufferSize = minShardTranslogBufferSize;
             }
@@ -382,10 +385,10 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
                 shardTranslogBufferSize = maxShardTranslogBufferSize;
             }
 
-            logger.debug("recalculating shard indexing buffer (reason={}), total is [{}] with [{}] active shards, each shard set to indexing=[{}], translog=[{}]", reason, indexingBuffer, activeShardCount, shardIndexingBufferSize, shardTranslogBufferSize);
-
+            logger.debug("recalculating shard indexing buffer (reason={}), total is [{}] with [{}] active shards, each shard set to indexing=[{}], translog=[{}]", reason, indexingBuffer, activeShards, shardIndexingBufferSize, shardTranslogBufferSize);
             for (ShardId shardId : availableShards()) {
-                if (shardWasActive.get(shardId) == Boolean.TRUE) {
+                ShardIndexingStatus status = shardsIndicesStatus.get(shardId);
+                if (status == null || status.activeIndexing) {
                     updateShardBuffers(shardId, shardIndexingBufferSize, shardTranslogBufferSize);
                 }
             }
@@ -421,4 +424,42 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
     private static enum ShardStatusChangeType {
         ADDED, DELETED, BECAME_ACTIVE, BECAME_INACTIVE
     }
+
+    static class ShardIndexingStatus {
+        long translogId = -1;
+        long translogNumberOfOperations = -1;
+        boolean activeIndexing = true;
+        long idleSinceNanoTime = -1; // contains the first time we saw this shard with no operations done on it
+
+
+        /** update status based on a new sample. updates all internal variables */
+        public void updateWith(long currentNanoTime, ShardIndexingStatus current, long inactiveNanoInterval) {
+            final boolean idle = (translogId == current.translogId && translogNumberOfOperations == current.translogNumberOfOperations);
+            if (activeIndexing && idle) {
+                // no indexing activity detected.
+                if (idleSinceNanoTime < 0) {
+                    // first time we see this, start the clock.
+                    idleSinceNanoTime = currentNanoTime;
+                } else if ((currentNanoTime - idleSinceNanoTime) > inactiveNanoInterval) {
+                    // shard is inactive. mark it as such.
+                    activeIndexing = false;
+                }
+            } else if (activeIndexing == false  // we weren't indexing before
+                    && idle == false // but we do now
+                    && current.translogNumberOfOperations > 0 // but only if we're really sure - see note bellow
+                    ) {
+                // since we sync flush once a shard becomes inactive, the translog id can change, however that
+                // doesn't mean the an indexing operation has happened. Note that if we're really unlucky and a flush happens
+                // immediately after an indexing operation we may not become active immediately. The following
+                // indexing operation will mark the shard as active, so it's OK. If that one doesn't come, we might as well stay
+                // inactive
+
+                activeIndexing = true;
+                idleSinceNanoTime = -1;
+            }
+
+            translogId = current.translogId;
+            translogNumberOfOperations = current.translogNumberOfOperations;
+        }
+    }
 }
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java
index d79e5e5..6ea4189 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySource.java
@@ -89,7 +89,7 @@ public class RecoverySource extends AbstractComponent {
 
     private RecoveryResponse recover(final StartRecoveryRequest request) {
         final IndexService indexService = indicesService.indexServiceSafe(request.shardId().index().name());
-        final IndexShard shard = indexService.shardSafe(request.shardId().id());
+        final IndexShard shard = indexService.getShard(request.shardId().id());
 
         // starting recovery from that our (the source) shard state is marking the shard to be in recovery mode as well, otherwise
         // the index operations will not be routed to it properly
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
index 854546f..6ace3c6 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
@@ -120,9 +120,7 @@ public class RecoverySourceHandler {
      * performs the recovery from the local engine to the target
      */
     public RecoveryResponse recoverToTarget() {
-        final Engine engine = shard.engine();
-        assert engine.getTranslog() != null : "translog must not be null";
-        try (Translog.View translogView = engine.getTranslog().newView()) {
+        try (Translog.View translogView = shard.acquireTranslogView()) {
             logger.trace("captured translog id [{}] for recovery", translogView.minTranslogGeneration());
             final IndexCommit phase1Snapshot;
             try {
@@ -179,7 +177,7 @@ public class RecoverySourceHandler {
             try {
                 recoverySourceMetadata = store.getMetadata(snapshot);
             } catch (CorruptIndexException | IndexFormatTooOldException | IndexFormatTooNewException ex) {
-                shard.engine().failEngine("recovery", ex);
+                shard.failShard("recovery", ex);
                 throw ex;
             }
             for (String name : snapshot.getFileNames()) {
@@ -287,7 +285,7 @@ public class RecoverySourceHandler {
                                 for (StoreFileMetaData md : metadata) {
                                     logger.debug("{} checking integrity for file {} after remove corruption exception", shard.shardId(), md);
                                     if (store.checkIntegrityNoException(md) == false) { // we are corrupted on the primary -- fail!
-                                        shard.engine().failEngine("recovery", corruptIndexException);
+                                        shard.failShard("recovery", corruptIndexException);
                                         logger.warn("{} Corrupted file detected {} checksum mismatch", shard.shardId(), md);
                                         throw corruptIndexException;
                                     }
@@ -641,7 +639,7 @@ public class RecoverySourceHandler {
     }
 
     protected void failEngine(IOException cause) {
-        shard.engine().failEngine("recovery", cause);
+        shard.failShard("recovery", cause);
     }
 
     Future<Void>[] asyncSendFiles(Store store, StoreFileMetaData[] files, Function<StoreFileMetaData, OutputStream> outputStreamFactory) {
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/SharedFSRecoverySourceHandler.java b/core/src/main/java/org/elasticsearch/indices/recovery/SharedFSRecoverySourceHandler.java
index a466147..123480e 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/SharedFSRecoverySourceHandler.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/SharedFSRecoverySourceHandler.java
@@ -52,7 +52,7 @@ public class SharedFSRecoverySourceHandler extends RecoverySourceHandler {
                     // if we relocate we need to close the engine in order to open a new
                     // IndexWriter on the other end of the relocation
                     engineClosed = true;
-                    shard.engine().flushAndClose();
+                    shard.flushAndCloseEngine();
                 } catch (IOException e) {
                     logger.warn("close engine failed", e);
                     shard.failShard("failed to close engine (phase1)", e);
diff --git a/core/src/main/java/org/elasticsearch/indices/store/IndicesStore.java b/core/src/main/java/org/elasticsearch/indices/store/IndicesStore.java
index 45b19ae..b1cb507 100644
--- a/core/src/main/java/org/elasticsearch/indices/store/IndicesStore.java
+++ b/core/src/main/java/org/elasticsearch/indices/store/IndicesStore.java
@@ -395,7 +395,7 @@ public class IndicesStore extends AbstractComponent implements ClusterStateListe
             ShardId shardId = request.shardId;
             IndexService indexService = indicesService.indexService(shardId.index().getName());
             if (indexService != null && indexService.indexUUID().equals(request.indexUUID)) {
-                return indexService.shard(shardId.id());
+                return indexService.getShardOrNull(shardId.id());
             }
             return null;
         }
diff --git a/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java b/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java
index 48ef0aa..ec5cc18 100644
--- a/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java
+++ b/core/src/main/java/org/elasticsearch/indices/store/TransportNodesListShardStoreMetaData.java
@@ -152,7 +152,7 @@ public class TransportNodesListShardStoreMetaData extends TransportNodesAction<T
         try {
             IndexService indexService = indicesService.indexService(shardId.index().name());
             if (indexService != null) {
-                IndexShard indexShard = indexService.shard(shardId.id());
+                IndexShard indexShard = indexService.getShardOrNull(shardId.id());
                 if (indexShard != null) {
                     final Store store = indexShard.store();
                     store.incRef();
diff --git a/core/src/main/java/org/elasticsearch/percolator/PercolateContext.java b/core/src/main/java/org/elasticsearch/percolator/PercolateContext.java
index 190ffc9..8cb797c 100644
--- a/core/src/main/java/org/elasticsearch/percolator/PercolateContext.java
+++ b/core/src/main/java/org/elasticsearch/percolator/PercolateContext.java
@@ -50,6 +50,7 @@ import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.ParsedDocument;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
+import org.elasticsearch.index.percolator.PercolatorQueriesRegistry;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.query.ParsedQuery;
 import org.elasticsearch.index.shard.IndexShard;
@@ -89,6 +90,7 @@ import java.util.concurrent.ConcurrentMap;
  */
 public class PercolateContext extends SearchContext {
 
+    private final PercolatorQueriesRegistry percolateQueryRegistry;
     public boolean limit;
     private int size;
     public boolean doSort;
@@ -102,7 +104,6 @@ public class PercolateContext extends SearchContext {
     private final PageCacheRecycler pageCacheRecycler;
     private final BigArrays bigArrays;
     private final ScriptService scriptService;
-    private final ConcurrentMap<BytesRef, Query> percolateQueries;
     private final int numberOfShards;
     private final Query aliasFilter;
     private final long originNanoTime = System.nanoTime();
@@ -133,7 +134,7 @@ public class PercolateContext extends SearchContext {
         this.indexService = indexService;
         this.fieldDataService = indexService.fieldData();
         this.searchShardTarget = searchShardTarget;
-        this.percolateQueries = indexShard.percolateRegistry().percolateQueries();
+        this.percolateQueryRegistry = indexShard.percolateRegistry();
         this.types = new String[]{request.documentType()};
         this.pageCacheRecycler = pageCacheRecycler;
         this.bigArrays = bigArrays.withCircuitBreaking();
@@ -179,7 +180,7 @@ public class PercolateContext extends SearchContext {
     }
 
     public ConcurrentMap<BytesRef, Query> percolateQueries() {
-        return percolateQueries;
+        return percolateQueryRegistry.percolateQueries();
     }
 
     public Query percolateQuery() {
diff --git a/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java b/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java
index ba4ccae..b20a54f 100644
--- a/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java
+++ b/core/src/main/java/org/elasticsearch/percolator/PercolatorService.java
@@ -71,7 +71,7 @@ import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.ParsedDocument;
 import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
-import org.elasticsearch.index.percolator.stats.ShardPercolateService;
+import org.elasticsearch.index.percolator.PercolatorQueriesRegistry;
 import org.elasticsearch.index.query.ParsedQuery;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.indices.IndicesService;
@@ -86,7 +86,6 @@ import org.elasticsearch.search.aggregations.AggregationPhase;
 import org.elasticsearch.search.aggregations.InternalAggregation;
 import org.elasticsearch.search.aggregations.InternalAggregation.ReduceContext;
 import org.elasticsearch.search.aggregations.InternalAggregations;
-import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;
 import org.elasticsearch.search.aggregations.pipeline.SiblingPipelineAggregator;
 import org.elasticsearch.search.highlight.HighlightField;
 import org.elasticsearch.search.highlight.HighlightPhase;
@@ -177,11 +176,10 @@ public class PercolatorService extends AbstractComponent {
 
     public PercolateShardResponse percolate(PercolateShardRequest request) {
         IndexService percolateIndexService = indicesService.indexServiceSafe(request.shardId().getIndex());
-        IndexShard indexShard = percolateIndexService.shardSafe(request.shardId().id());
+        IndexShard indexShard = percolateIndexService.getShard(request.shardId().id());
         indexShard.readAllowed(); // check if we can read the shard...
-
-        ShardPercolateService shardPercolateService = indexShard.shardPercolateService();
-        shardPercolateService.prePercolate();
+        PercolatorQueriesRegistry percolateQueryRegistry = indexShard.percolateRegistry();
+        percolateQueryRegistry.prePercolate();
         long startTime = System.nanoTime();
 
         // TODO: The filteringAliases should be looked up at the coordinating node and serialized with all shard request,
@@ -255,7 +253,7 @@ public class PercolatorService extends AbstractComponent {
         } finally {
             SearchContext.removeCurrent();
             context.close();
-            shardPercolateService.postPercolate(System.nanoTime() - startTime);
+            percolateQueryRegistry.postPercolate(System.nanoTime() - startTime);
         }
     }
 
diff --git a/core/src/main/java/org/elasticsearch/plugins/Plugin.java b/core/src/main/java/org/elasticsearch/plugins/Plugin.java
index 7207795..4229c54 100644
--- a/core/src/main/java/org/elasticsearch/plugins/Plugin.java
+++ b/core/src/main/java/org/elasticsearch/plugins/Plugin.java
@@ -74,20 +74,6 @@ public abstract class Plugin {
     }
 
     /**
-     * Per index shard module.
-     */
-    public Collection<Module> shardModules(Settings indexSettings) {
-        return Collections.emptyList();
-    }
-
-    /**
-     * Per index shard service that will be automatically closed.
-     */
-    public Collection<Class<? extends Closeable>> shardServices() {
-        return Collections.emptyList();
-    }
-
-    /**
      * Additional node settings loaded by the plugin. Note that settings that are explicit in the nodes settings can't be
      * overwritten with the additional settings. These settings added if they don't exist.
      */
diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
index 5834efc..9582d3f 100644
--- a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
+++ b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java
@@ -250,22 +250,6 @@ public class PluginsService extends AbstractComponent {
         return services;
     }
 
-    public Collection<Module> shardModules(Settings indexSettings) {
-        List<Module> modules = new ArrayList<>();
-        for (Tuple<PluginInfo, Plugin> plugin : plugins) {
-            modules.addAll(plugin.v2().shardModules(indexSettings));
-        }
-        return modules;
-    }
-
-    public Collection<Class<? extends Closeable>> shardServices() {
-        List<Class<? extends Closeable>> services = new ArrayList<>();
-        for (Tuple<PluginInfo, Plugin> plugin : plugins) {
-            services.addAll(plugin.v2().shardServices());
-        }
-        return services;
-    }
-
     /**
      * Get information about plugins (jvm and site plugins).
      */
diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java
index 8ccf201..337dd41 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodesAction.java
@@ -43,7 +43,7 @@ import org.elasticsearch.index.flush.FlushStats;
 import org.elasticsearch.index.get.GetStats;
 import org.elasticsearch.index.indexing.IndexingStats;
 import org.elasticsearch.index.merge.MergeStats;
-import org.elasticsearch.index.percolator.stats.PercolateStats;
+import org.elasticsearch.index.percolator.PercolateStats;
 import org.elasticsearch.index.refresh.RefreshStats;
 import org.elasticsearch.index.search.stats.SearchStats;
 import org.elasticsearch.index.suggest.stats.SuggestStats;
diff --git a/core/src/main/java/org/elasticsearch/search/SearchService.java b/core/src/main/java/org/elasticsearch/search/SearchService.java
index 59ec671..403f4a5 100644
--- a/core/src/main/java/org/elasticsearch/search/SearchService.java
+++ b/core/src/main/java/org/elasticsearch/search/SearchService.java
@@ -559,7 +559,7 @@ public class SearchService extends AbstractLifecycleComponent<SearchService> {
 
     final SearchContext createContext(ShardSearchRequest request, @Nullable Engine.Searcher searcher) {
         IndexService indexService = indicesService.indexServiceSafe(request.index());
-        IndexShard indexShard = indexService.shardSafe(request.shardId());
+        IndexShard indexShard = indexService.getShard(request.shardId());
 
         SearchShardTarget shardTarget = new SearchShardTarget(clusterService.localNode().id(), request.index(), request.shardId());
 
diff --git a/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java b/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
index 3850888..c751895 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
@@ -289,7 +289,7 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
                 for (final Map.Entry<ShardId, IndexShardSnapshotStatus> shardEntry : entry.getValue().entrySet()) {
                     final ShardId shardId = shardEntry.getKey();
                     try {
-                        final IndexShard indexShard = indicesService.indexServiceSafe(shardId.getIndex()).shard(shardId.id());
+                        final IndexShard indexShard = indicesService.indexServiceSafe(shardId.getIndex()).getShardOrNull(shardId.id());
                         executor.execute(new AbstractRunnable() {
                             @Override
                             public void doRun() {
diff --git a/core/src/main/resources/org/elasticsearch/bootstrap/groovy.policy b/core/src/main/resources/org/elasticsearch/bootstrap/groovy.policy
deleted file mode 100644
index 4e12758..0000000
--- a/core/src/main/resources/org/elasticsearch/bootstrap/groovy.policy
+++ /dev/null
@@ -1,31 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
- 
-/*
- * Limited security policy for groovy scripts.
- * This is what is needed for its invokeDynamic functionality to work.
- */
-grant {
-  
-  // groovy IndyInterface bootstrap requires this property for indy logging
-  permission java.util.PropertyPermission "groovy.indy.logging", "read";
-  
-  // needed IndyInterface selectMethod (setCallSiteTarget)
-  permission java.lang.RuntimePermission "getClassLoader";
-};
diff --git a/core/src/main/resources/org/elasticsearch/bootstrap/security.policy b/core/src/main/resources/org/elasticsearch/bootstrap/security.policy
index ae2320f..1126824 100644
--- a/core/src/main/resources/org/elasticsearch/bootstrap/security.policy
+++ b/core/src/main/resources/org/elasticsearch/bootstrap/security.policy
@@ -69,8 +69,8 @@ grant codeBase "${es.security.plugin.lang-groovy}" {
   permission java.lang.RuntimePermission "accessClassInPackage.sun.reflect";
   // needed by GroovyScriptEngineService to close its classloader (why?)
   permission java.lang.RuntimePermission "closeClassLoader";
-  // Allow executing groovy scripts with codesource of /groovy/script
-  permission groovy.security.GroovyCodeSourcePermission "/groovy/script";
+  // Allow executing groovy scripts with codesource of /untrusted
+  permission groovy.security.GroovyCodeSourcePermission "/untrusted";
 };
 
 grant codeBase "${es.security.plugin.lang-javascript}" {
diff --git a/core/src/main/resources/org/elasticsearch/bootstrap/untrusted.policy b/core/src/main/resources/org/elasticsearch/bootstrap/untrusted.policy
new file mode 100644
index 0000000..2475c56
--- /dev/null
+++ b/core/src/main/resources/org/elasticsearch/bootstrap/untrusted.policy
@@ -0,0 +1,31 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+ 
+/*
+ * Limited security policy for scripts.
+ * This is what is needed for invokeDynamic functionality to work.
+ */
+grant {
+  
+  // groovy IndyInterface bootstrap requires this property for indy logging
+  permission java.util.PropertyPermission "groovy.indy.logging", "read";
+  
+  // needed IndyInterface selectMethod (setCallSiteTarget)
+  permission java.lang.RuntimePermission "getClassLoader";
+};
diff --git a/core/src/test/java/org/elasticsearch/action/admin/indices/shards/IndicesShardStoreRequestIT.java b/core/src/test/java/org/elasticsearch/action/admin/indices/shards/IndicesShardStoreRequestIT.java
index f040ca2..de9eada 100644
--- a/core/src/test/java/org/elasticsearch/action/admin/indices/shards/IndicesShardStoreRequestIT.java
+++ b/core/src/test/java/org/elasticsearch/action/admin/indices/shards/IndicesShardStoreRequestIT.java
@@ -158,7 +158,7 @@ public class IndicesShardStoreRequestIT extends ESIntegTestCase {
             IndicesService indexServices = internalCluster().getInstance(IndicesService.class, node);
             IndexService indexShards = indexServices.indexServiceSafe(index);
             for (Integer shardId : indexShards.shardIds()) {
-                IndexShard shard = indexShards.shardSafe(shardId);
+                IndexShard shard = indexShards.getShard(shardId);
                 if (randomBoolean()) {
                     shard.failShard("test", new CorruptIndexException("test corrupted", ""));
                     Set<String> nodes = corruptedShardIDMap.get(shardId);
diff --git a/core/src/test/java/org/elasticsearch/action/admin/indices/upgrade/UpgradeReallyOldIndexIT.java b/core/src/test/java/org/elasticsearch/action/admin/indices/upgrade/UpgradeReallyOldIndexIT.java
index 4ada599..d365f5b 100644
--- a/core/src/test/java/org/elasticsearch/action/admin/indices/upgrade/UpgradeReallyOldIndexIT.java
+++ b/core/src/test/java/org/elasticsearch/action/admin/indices/upgrade/UpgradeReallyOldIndexIT.java
@@ -65,7 +65,7 @@ public class UpgradeReallyOldIndexIT extends StaticIndexBackwardCompatibilityIT
         for (IndicesService services : internalCluster().getInstances(IndicesService.class)) {
             IndexService indexService = services.indexService(index);
             if (indexService != null) {
-                assertEquals(version, indexService.shard(0).minimumCompatibleVersion());
+                assertEquals(version, indexService.getShardOrNull(0).minimumCompatibleVersion());
             }
         }
 
diff --git a/core/src/test/java/org/elasticsearch/bootstrap/ESPolicyTests.java b/core/src/test/java/org/elasticsearch/bootstrap/ESPolicyTests.java
index 5423e68..b7ed195 100644
--- a/core/src/test/java/org/elasticsearch/bootstrap/ESPolicyTests.java
+++ b/core/src/test/java/org/elasticsearch/bootstrap/ESPolicyTests.java
@@ -24,7 +24,9 @@ import org.elasticsearch.test.ESTestCase;
 import java.io.FilePermission;
 import java.security.AccessControlContext;
 import java.security.AccessController;
+import java.security.AllPermission;
 import java.security.CodeSource;
+import java.security.Permission;
 import java.security.PermissionCollection;
 import java.security.Permissions;
 import java.security.PrivilegedAction;
@@ -48,8 +50,13 @@ public class ESPolicyTests extends ESTestCase {
      */
     public void testNullCodeSource() throws Exception {
         assumeTrue("test cannot run with security manager", System.getSecurityManager() == null);
+        // create a policy with AllPermission
+        Permission all = new AllPermission();
+        PermissionCollection allCollection = all.newPermissionCollection();
+        allCollection.add(all);
+        ESPolicy policy = new ESPolicy(allCollection);
+        // restrict ourselves to NoPermission
         PermissionCollection noPermissions = new Permissions();
-        ESPolicy policy = new ESPolicy(noPermissions);
         assertFalse(policy.implies(new ProtectionDomain(null, noPermissions), new FilePermission("foo", "read")));
     }
 
diff --git a/core/src/test/java/org/elasticsearch/bootstrap/MockPluginPolicy.java b/core/src/test/java/org/elasticsearch/bootstrap/MockPluginPolicy.java
index bd366a2..c301ec7 100644
--- a/core/src/test/java/org/elasticsearch/bootstrap/MockPluginPolicy.java
+++ b/core/src/test/java/org/elasticsearch/bootstrap/MockPluginPolicy.java
@@ -35,7 +35,6 @@ import java.security.ProtectionDomain;
 import java.security.cert.Certificate;
 import java.util.Collections;
 import java.util.HashSet;
-import java.util.Objects;
 import java.util.Set;
 
 /**
@@ -99,18 +98,24 @@ final class MockPluginPolicy extends Policy {
         excludedSources.add(RandomizedRunner.class.getProtectionDomain().getCodeSource());
         // junit library
         excludedSources.add(Assert.class.getProtectionDomain().getCodeSource());
-        // groovy scripts
-        excludedSources.add(new CodeSource(new URL("file:/groovy/script"), (Certificate[])null));
+        // scripts
+        excludedSources.add(new CodeSource(new URL("file:" + BootstrapInfo.UNTRUSTED_CODEBASE), (Certificate[])null));
 
         Loggers.getLogger(getClass()).debug("Apply permissions [{}] excluding codebases [{}]", extraPermissions, excludedSources);
     }
 
     @Override
     public boolean implies(ProtectionDomain domain, Permission permission) {
+        CodeSource codeSource = domain.getCodeSource();
+        // codesource can be null when reducing privileges via doPrivileged()
+        if (codeSource == null) {
+            return false;
+        }
+
         if (standardPolicy.implies(domain, permission)) {
             return true;
-        } else if (excludedSources.contains(domain.getCodeSource()) == false && 
-                   Objects.toString(domain.getCodeSource()).contains("test-classes") == false) {
+        } else if (excludedSources.contains(codeSource) == false &&
+                   codeSource.toString().contains("test-classes") == false) {
             return extraPermissions.implies(permission);
         } else {
             return false;
diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
index 606911f..f672b26 100644
--- a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
@@ -179,7 +179,7 @@ public class ClusterInfoServiceIT extends ESIntegTestCase {
             DiscoveryNode discoveryNode = state.getNodes().get(nodeId);
             IndicesService indicesService = internalTestCluster.getInstance(IndicesService.class, discoveryNode.getName());
             IndexService indexService = indicesService.indexService(shard.index());
-            IndexShard indexShard = indexService.shard(shard.id());
+            IndexShard indexShard = indexService.getShardOrNull(shard.id());
             assertEquals(indexShard.shardPath().getRootDataPath().toString(), dataPath);
         }
 
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java
index dfdd9ba..5852faf 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java
@@ -50,13 +50,11 @@ import org.elasticsearch.test.ESAllocationTestCase;
 import org.elasticsearch.test.gateway.NoopGatewayAllocator;
 import org.junit.Test;
 
-import java.util.AbstractMap;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
-import java.util.Set;
 
 import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
 import static org.elasticsearch.cluster.routing.ShardRoutingState.RELOCATING;
@@ -912,6 +910,137 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
         assertThat(result.routingTable().index("test").getShards().get(1).primaryShard().relocatingNodeId(), equalTo("node2"));
     }
 
+    public void testForSingleDataNode() {
+        Settings diskSettings = settingsBuilder()
+                .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_DISK_THRESHOLD_ENABLED, true)
+                .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_INCLUDE_RELOCATIONS, true)
+                .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK, "60%")
+                .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK, "70%").build();
+
+        Map<String, DiskUsage> usages = new HashMap<>();
+        usages.put("node1", new DiskUsage("node1", "n1", "/dev/null", 100, 100)); // 0% used
+        usages.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 20));  // 80% used
+        usages.put("node3", new DiskUsage("node3", "n3", "/dev/null", 100, 100)); // 0% used
+
+        // We have an index with 1 primary shards each taking 40 bytes. Each node has 100 bytes available
+        Map<String, Long> shardSizes = new HashMap<>();
+        shardSizes.put("[test][0][p]", 40L);
+        shardSizes.put("[test][1][p]", 40L);
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
+
+        DiskThresholdDecider diskThresholdDecider = new DiskThresholdDecider(diskSettings);
+        MetaData metaData = MetaData.builder()
+                .put(IndexMetaData.builder("test").settings(settings(Version.CURRENT)).numberOfShards(2).numberOfReplicas(0))
+                .build();
+
+        RoutingTable routingTable = RoutingTable.builder()
+                .addAsNew(metaData.index("test"))
+                .build();
+
+        logger.info("--> adding one master node, one data node");
+        Map<String, String> masterNodeAttributes = new HashMap<>();
+        masterNodeAttributes.put("master", "true");
+        masterNodeAttributes.put("data", "false");
+        Map<String, String> dataNodeAttributes = new HashMap<>();
+        dataNodeAttributes.put("master", "false");
+        dataNodeAttributes.put("data", "true");
+        DiscoveryNode discoveryNode1 = new DiscoveryNode("", "node1", new LocalTransportAddress("1"), masterNodeAttributes, Version.CURRENT);
+        DiscoveryNode discoveryNode2 = new DiscoveryNode("", "node2", new LocalTransportAddress("2"), dataNodeAttributes, Version.CURRENT);
+
+        DiscoveryNodes discoveryNodes = DiscoveryNodes.builder().put(discoveryNode1).put(discoveryNode2).build();
+        ClusterState baseClusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT)
+                .metaData(metaData)
+                .routingTable(routingTable)
+                .nodes(discoveryNodes)
+                .build();
+
+        // Two shards consumes 80% of disk space in data node, but we have only one data node, shards should remain.
+        ShardRouting firstRouting = TestShardRouting.newShardRouting("test", 0, "node2", null, null, true, ShardRoutingState.STARTED, 1);
+        ShardRouting secondRouting = TestShardRouting.newShardRouting("test", 1, "node2", null, null, true, ShardRoutingState.STARTED, 1);
+        RoutingNode firstRoutingNode = new RoutingNode("node2", discoveryNode2, Arrays.asList(firstRouting, secondRouting));
+
+        RoutingTable.Builder builder = RoutingTable.builder().add(
+                IndexRoutingTable.builder("test")
+                        .addIndexShard(new IndexShardRoutingTable.Builder(new ShardId("test", 0))
+                                        .addShard(firstRouting)
+                                        .build()
+                        )
+                        .addIndexShard(new IndexShardRoutingTable.Builder(new ShardId("test", 1))
+                                        .addShard(secondRouting)
+                                        .build()
+                        )
+        );
+        ClusterState clusterState = ClusterState.builder(baseClusterState).routingTable(builder).build();
+        RoutingAllocation routingAllocation = new RoutingAllocation(null, new RoutingNodes(clusterState), discoveryNodes, clusterInfo);
+        Decision decision = diskThresholdDecider.canRemain(firstRouting, firstRoutingNode, routingAllocation);
+
+        // Two shards should start happily
+        assertThat(decision.type(), equalTo(Decision.Type.YES));
+        ClusterInfoService cis = new ClusterInfoService() {
+            @Override
+            public ClusterInfo getClusterInfo() {
+                logger.info("--> calling fake getClusterInfo");
+                return clusterInfo;
+            }
+
+            @Override
+            public void addListener(Listener listener) {
+            }
+        };
+
+        AllocationDeciders deciders = new AllocationDeciders(Settings.EMPTY, new HashSet<>(Arrays.asList(
+                new SameShardAllocationDecider(Settings.EMPTY), diskThresholdDecider
+        )));
+
+        AllocationService strategy = new AllocationService(settingsBuilder()
+                .put("cluster.routing.allocation.concurrent_recoveries", 10)
+                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE, "always")
+                .put("cluster.routing.allocation.cluster_concurrent_rebalance", -1)
+                .build(), deciders, makeShardsAllocators(), cis);
+        RoutingAllocation.Result result = strategy.reroute(clusterState);
+
+        assertThat(result.routingTable().index("test").getShards().get(0).primaryShard().state(), equalTo(STARTED));
+        assertThat(result.routingTable().index("test").getShards().get(0).primaryShard().currentNodeId(), equalTo("node2"));
+        assertThat(result.routingTable().index("test").getShards().get(0).primaryShard().relocatingNodeId(), nullValue());
+        assertThat(result.routingTable().index("test").getShards().get(1).primaryShard().state(), equalTo(STARTED));
+        assertThat(result.routingTable().index("test").getShards().get(1).primaryShard().currentNodeId(), equalTo("node2"));
+        assertThat(result.routingTable().index("test").getShards().get(1).primaryShard().relocatingNodeId(), nullValue());
+
+        // Add another datanode, it should relocate.
+        logger.info("--> adding node3");
+        DiscoveryNode discoveryNode3 = new DiscoveryNode("", "node3", new LocalTransportAddress("3"), dataNodeAttributes, Version.CURRENT);
+        ClusterState updateClusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
+                .put(discoveryNode3)).build();
+
+        firstRouting = TestShardRouting.newShardRouting("test", 0, "node2", null, null, true, ShardRoutingState.STARTED, 1);
+        secondRouting = TestShardRouting.newShardRouting("test", 1, "node2", "node3", null, true, ShardRoutingState.RELOCATING, 1);
+        firstRoutingNode = new RoutingNode("node2", discoveryNode2, Arrays.asList(firstRouting, secondRouting));
+        builder = RoutingTable.builder().add(
+                IndexRoutingTable.builder("test")
+                        .addIndexShard(new IndexShardRoutingTable.Builder(new ShardId("test", 0))
+                                        .addShard(firstRouting)
+                                        .build()
+                        )
+                        .addIndexShard(new IndexShardRoutingTable.Builder(new ShardId("test", 1))
+                                        .addShard(secondRouting)
+                                        .build()
+                        )
+        );
+
+        clusterState = ClusterState.builder(updateClusterState).routingTable(builder).build();
+        routingAllocation = new RoutingAllocation(null, new RoutingNodes(clusterState), discoveryNodes, clusterInfo);
+        decision = diskThresholdDecider.canRemain(firstRouting, firstRoutingNode, routingAllocation);
+        assertThat(decision.type(), equalTo(Decision.Type.YES));
+
+        result = strategy.reroute(clusterState);
+        assertThat(result.routingTable().index("test").getShards().get(0).primaryShard().state(), equalTo(STARTED));
+        assertThat(result.routingTable().index("test").getShards().get(0).primaryShard().currentNodeId(), equalTo("node2"));
+        assertThat(result.routingTable().index("test").getShards().get(0).primaryShard().relocatingNodeId(), nullValue());
+        assertThat(result.routingTable().index("test").getShards().get(1).primaryShard().state(), equalTo(RELOCATING));
+        assertThat(result.routingTable().index("test").getShards().get(1).primaryShard().currentNodeId(), equalTo("node2"));
+        assertThat(result.routingTable().index("test").getShards().get(1).primaryShard().relocatingNodeId(), equalTo("node3"));
+    }
+
     public void logShardStates(ClusterState state) {
         RoutingNodes rn = state.getRoutingNodes();
         logger.info("--> counts: total: {}, unassigned: {}, initializing: {}, relocating: {}, started: {}",
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/operation/hash/murmur3/Murmur3HashFunctionTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/operation/hash/murmur3/Murmur3HashFunctionTests.java
index 23b928d..ed454ae 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/operation/hash/murmur3/Murmur3HashFunctionTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/operation/hash/murmur3/Murmur3HashFunctionTests.java
@@ -19,26 +19,24 @@
 
 package org.elasticsearch.cluster.routing.operation.hash.murmur3;
 
-import com.carrotsearch.randomizedtesting.generators.RandomInts;
-import com.carrotsearch.randomizedtesting.generators.RandomStrings;
-import com.google.common.hash.HashFunction;
-import com.google.common.hash.Hashing;
 import org.elasticsearch.cluster.routing.Murmur3HashFunction;
 import org.elasticsearch.test.ESTestCase;
 
 public class Murmur3HashFunctionTests extends ESTestCase {
 
-    public void test() {
-        // Make sure that we agree with guava
-        Murmur3HashFunction murmur3 = new Murmur3HashFunction();
-        HashFunction guavaMurmur3 = Hashing.murmur3_32();
-        for (int i = 0; i < 100; ++i) {
-            final String id = RandomStrings.randomRealisticUnicodeOfCodepointLength(getRandom(), RandomInts.randomIntBetween(getRandom(), 1, 20));
-            //final String id = "0";
-            final int hash1 = guavaMurmur3.newHasher().putUnencodedChars(id).hash().asInt();
-            final int hash2 = murmur3.hash(id);
-            assertEquals(hash1, hash2);
-        }
+    private static Murmur3HashFunction HASH = new Murmur3HashFunction();
+
+    public void testKnownValues() {
+        assertHash(0x5a0cb7c3, "hell");
+        assertHash(0xd7c31989, "hello");
+        assertHash(0x22ab2984, "hello w");
+        assertHash(0xdf0ca123, "hello wo");
+        assertHash(0xe7744d61, "hello wor");
+        assertHash(0xe07db09c, "The quick brown fox jumps over the lazy dog");
+        assertHash(0x4e63d2ad, "The quick brown fox jumps over the lazy cog");
     }
 
+    private static void assertHash(int expected, String stringInput) {
+        assertEquals(expected, HASH.hash(stringInput));
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/common/hash/MessageDigestsTests.java b/core/src/test/java/org/elasticsearch/common/hash/MessageDigestsTests.java
new file mode 100644
index 0000000..dbc174b
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/common/hash/MessageDigestsTests.java
@@ -0,0 +1,81 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.common.hash;
+
+import org.elasticsearch.test.ESTestCase;
+import org.junit.Test;
+
+import java.math.BigInteger;
+import java.nio.charset.StandardCharsets;
+import java.security.MessageDigest;
+
+import static org.junit.Assert.*;
+
+public class MessageDigestsTests extends ESTestCase {
+    private void assertHash(String expected, String test, MessageDigest messageDigest) {
+        String actual = MessageDigests.toHexString(messageDigest.digest(test.getBytes(StandardCharsets.UTF_8)));
+        assertEquals(expected, actual);
+    }
+
+    @Test
+    public void testMd5() throws Exception {
+        assertHash("d41d8cd98f00b204e9800998ecf8427e", "", MessageDigests.md5());
+        assertHash("900150983cd24fb0d6963f7d28e17f72", "abc", MessageDigests.md5());
+        assertHash("8215ef0796a20bcaaae116d3876c664a", "abcdbcdecdefdefgefghfghighijhijkijkljklmklmnlmnomnopnopq", MessageDigests.md5());
+        assertHash("7707d6ae4e027c70eea2a935c2296f21", new String(new char[1000000]).replace("\0", "a"), MessageDigests.md5());
+        assertHash("9e107d9d372bb6826bd81d3542a419d6", "The quick brown fox jumps over the lazy dog", MessageDigests.md5());
+        assertHash("1055d3e698d289f2af8663725127bd4b", "The quick brown fox jumps over the lazy cog", MessageDigests.md5());
+    }
+
+    @Test
+    public void testSha1() throws Exception {
+        assertHash("da39a3ee5e6b4b0d3255bfef95601890afd80709", "", MessageDigests.sha1());
+        assertHash("a9993e364706816aba3e25717850c26c9cd0d89d", "abc", MessageDigests.sha1());
+        assertHash("84983e441c3bd26ebaae4aa1f95129e5e54670f1", "abcdbcdecdefdefgefghfghighijhijkijkljklmklmnlmnomnopnopq", MessageDigests.sha1());
+        assertHash("34aa973cd4c4daa4f61eeb2bdbad27316534016f", new String(new char[1000000]).replace("\0", "a"), MessageDigests.sha1());
+        assertHash("2fd4e1c67a2d28fced849ee1bb76e7391b93eb12", "The quick brown fox jumps over the lazy dog", MessageDigests.sha1());
+        assertHash("de9f2c7fd25e1b3afad3e85a0bd17d9b100db4b3", "The quick brown fox jumps over the lazy cog", MessageDigests.sha1());
+    }
+
+    @Test
+    public void testSha256() throws Exception {
+        assertHash("e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855", "", MessageDigests.sha256());
+        assertHash("ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad", "abc", MessageDigests.sha256());
+        assertHash("248d6a61d20638b8e5c026930c3e6039a33ce45964ff2167f6ecedd419db06c1", "abcdbcdecdefdefgefghfghighijhijkijkljklmklmnlmnomnopnopq", MessageDigests.sha256());
+        assertHash("cdc76e5c9914fb9281a1c7e284d73e67f1809a48a497200e046d39ccc7112cd0", new String(new char[1000000]).replace("\0", "a"), MessageDigests.sha256());
+        assertHash("d7a8fbb307d7809469ca9abcb0082e4f8d5651e46d3cdb762d02d0bf37c9e592", "The quick brown fox jumps over the lazy dog", MessageDigests.sha256());
+        assertHash("e4c4d8f3bf76b692de791a173e05321150f7a345b46484fe427f6acc7ecc81be", "The quick brown fox jumps over the lazy cog", MessageDigests.sha256());
+    }
+
+    @Test
+    public void testToHexString() throws Exception {
+        for (int i = 0; i < 1024; i++) {
+            BigInteger expected = BigInteger.probablePrime(256, random());
+            byte[] bytes = expected.toByteArray();
+            String hex = MessageDigests.toHexString(bytes);
+            String zeros = new String(new char[2 * bytes.length]).replace("\0", "0");
+            String expectedAsString = expected.toString(16);
+            String expectedHex = zeros.substring(expectedAsString.length()) + expectedAsString;
+            assertEquals(expectedHex, hex);
+            BigInteger actual = new BigInteger(hex, 16);
+            assertEquals(expected, actual);
+        }
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/common/hashing/MurmurHash3Tests.java b/core/src/test/java/org/elasticsearch/common/hashing/MurmurHash3Tests.java
index d9d4057..cbdfe9c 100644
--- a/core/src/test/java/org/elasticsearch/common/hashing/MurmurHash3Tests.java
+++ b/core/src/test/java/org/elasticsearch/common/hashing/MurmurHash3Tests.java
@@ -19,37 +19,34 @@
 
 package org.elasticsearch.common.hashing;
 
-import com.google.common.hash.HashCode;
-import com.google.common.hash.Hashing;
 import org.elasticsearch.common.hash.MurmurHash3;
 import org.elasticsearch.test.ESTestCase;
 
-import java.nio.ByteBuffer;
-import java.nio.ByteOrder;
-import java.nio.LongBuffer;
+import java.io.UnsupportedEncodingException;
+import java.nio.charset.StandardCharsets;
 
 public class MurmurHash3Tests extends ESTestCase {
-
-    public void testHash128() {
-        final int iters = scaledRandomIntBetween(100, 5000);
-        for (int i = 0; i < iters; ++i) {
-            final int seed = randomInt();
-            final int offset = randomInt(20);
-            final int len = randomInt(randomBoolean() ? 20 : 200);
-            final byte[] bytes = new byte[len + offset + randomInt(3)];
-            getRandom().nextBytes(bytes);
-            HashCode h1 = Hashing.murmur3_128(seed).hashBytes(bytes, offset, len);
-            MurmurHash3.Hash128 h2 = MurmurHash3.hash128(bytes, offset, len, seed, new MurmurHash3.Hash128());
-            assertEquals(h1, h2);
-        }
+    public void testKnownValues() throws UnsupportedEncodingException {
+        assertHash(0x629942693e10f867L, 0x92db0b82baeb5347L, "hell", 0);
+        assertHash(0xa78ddff5adae8d10L, 0x128900ef20900135L, "hello", 1);
+        assertHash(0x8a486b23f422e826L, 0xf962a2c58947765fL, "hello ", 2);
+        assertHash(0x2ea59f466f6bed8cL, 0xc610990acc428a17L, "hello w", 3);
+        assertHash(0x79f6305a386c572cL, 0x46305aed3483b94eL, "hello wo", 4);
+        assertHash(0xc2219d213ec1f1b5L, 0xa1d8e2e0a52785bdL, "hello wor", 5);
+        assertHash(0xe34bbc7bbc071b6cL, 0x7a433ca9c49a9347L, "The quick brown fox jumps over the lazy dog", 0);
+        assertHash(0x658ca970ff85269aL, 0x43fee3eaa68e5c3eL, "The quick brown fox jumps over the lazy cog", 0);
     }
 
-    private void assertEquals(HashCode h1, MurmurHash3.Hash128 h2) {
-        final LongBuffer longs = ByteBuffer.wrap(h1.asBytes()).order(ByteOrder.LITTLE_ENDIAN).asLongBuffer();
-        assertEquals(2, longs.limit());
-        assertEquals(h1.asLong(), h2.h1);
-        assertEquals(longs.get(), h2.h1);
-        assertEquals(longs.get(), h2.h2);
+    private static void assertHash(long lower, long upper, String inputString, long seed) {
+        byte[] bytes = inputString.getBytes(StandardCharsets.UTF_8);
+        MurmurHash3.Hash128 expected = new MurmurHash3.Hash128();
+        expected.h1 = lower;
+        expected.h2 = upper;
+        assertHash(expected, MurmurHash3.hash128(bytes, 0, bytes.length, seed, new MurmurHash3.Hash128()));
     }
 
+    private static void assertHash(MurmurHash3.Hash128 expected, MurmurHash3.Hash128 actual) {
+        assertEquals(expected.h1, actual.h1);
+        assertEquals(expected.h2, actual.h2);
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java b/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java
index eeac546..255def7 100644
--- a/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java
+++ b/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java
@@ -60,6 +60,22 @@ public abstract class ModuleTestCase extends ESTestCase {
         fail("Did not find any binding to " + to.getName() + ". Found these bindings:\n" + s);
     }
 
+//    /** Configures the module and asserts "instance" is bound to "to". */
+//    public void assertInstanceBinding(Module module, Class to, Object instance) {
+//        List<Element> elements = Elements.getElements(module);
+//        for (Element element : elements) {
+//            if (element instanceof ProviderInstanceBinding) {
+//                assertEquals(instance, ((ProviderInstanceBinding) element).getProviderInstance().get());
+//                return;
+//            }
+//        }
+//        StringBuilder s = new StringBuilder();
+//        for (Element element : elements) {
+//            s.append(element + "\n");
+//        }
+//        fail("Did not find any binding to " + to.getName() + ". Found these bindings:\n" + s);
+//    }
+
     /**
      * Attempts to configure the module, and asserts an {@link IllegalArgumentException} is
      * caught, containing the given messages
@@ -164,6 +180,10 @@ public abstract class ModuleTestCase extends ESTestCase {
                         return;
                     }
                 }
+            } else  if (element instanceof ProviderInstanceBinding) {
+                ProviderInstanceBinding binding = (ProviderInstanceBinding) element;
+                assertTrue(tester.test(to.cast(binding.getProviderInstance().get())));
+                return;
             }
         }
         StringBuilder s = new StringBuilder();
diff --git a/core/src/test/java/org/elasticsearch/common/logging/log4j/LoggingConfigurationTests.java b/core/src/test/java/org/elasticsearch/common/logging/log4j/LoggingConfigurationTests.java
index 6515432..199f94c 100644
--- a/core/src/test/java/org/elasticsearch/common/logging/log4j/LoggingConfigurationTests.java
+++ b/core/src/test/java/org/elasticsearch/common/logging/log4j/LoggingConfigurationTests.java
@@ -21,20 +21,21 @@ package org.elasticsearch.common.logging.log4j;
 
 import org.apache.log4j.Appender;
 import org.apache.log4j.Logger;
+import org.elasticsearch.common.cli.CliToolTestCase;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.env.Environment;
+import org.elasticsearch.node.internal.InternalSettingsPreparer;
 import org.elasticsearch.test.ESTestCase;
-import org.hamcrest.Matchers;
 import org.junit.Before;
 import org.junit.Test;
 
 import java.nio.charset.StandardCharsets;
 import java.nio.file.Files;
 import java.nio.file.Path;
+import java.nio.file.StandardOpenOption;
 
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.notNullValue;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -148,7 +149,34 @@ public class LoggingConfigurationTests extends ESTestCase {
         LogConfigurator.resolveConfig(environment, builder);
 
         Settings logSettings = builder.build();
-        assertThat(logSettings.get("yml"), Matchers.nullValue());
+        assertThat(logSettings.get("yml"), nullValue());
+    }
+
+    // tests that custom settings are not overwritten by settings in the config file
+    @Test
+    public void testResolveOrder() throws Exception {
+        Path tmpDir = createTempDir();
+        Path loggingConf = tmpDir.resolve(loggingConfiguration("yaml"));
+        Files.write(loggingConf, "logger.test: INFO, file\n".getBytes(StandardCharsets.UTF_8));
+        Files.write(loggingConf, "appender.file.type: file\n".getBytes(StandardCharsets.UTF_8), StandardOpenOption.APPEND);
+        Environment environment = InternalSettingsPreparer.prepareEnvironment(
+                Settings.builder()
+                        .put("path.conf", tmpDir.toAbsolutePath())
+                        .put("path.home", createTempDir().toString())
+                        .put("logger.test", "TRACE, console")
+                        .put("appender.console.type", "console")
+                        .put("appender.console.layout.type", "consolePattern")
+                        .put("appender.console.layout.conversionPattern", "[%d{ISO8601}][%-5p][%-25c] %m%n")
+                        .build(), new CliToolTestCase.MockTerminal());
+        LogConfigurator.configure(environment.settings());
+        // args should overwrite whatever is in the config
+        ESLogger esLogger = Log4jESLoggerFactory.getLogger("test");
+        Logger logger = ((Log4jESLogger) esLogger).logger();
+        Appender appender = logger.getAppender("console");
+        assertThat(appender, notNullValue());
+        assertTrue(logger.isTraceEnabled());
+        appender = logger.getAppender("file");
+        assertThat(appender, nullValue());
     }
 
     private static String loggingConfiguration(String suffix) {
diff --git a/core/src/test/java/org/elasticsearch/index/IndexModuleTests.java b/core/src/test/java/org/elasticsearch/index/IndexModuleTests.java
new file mode 100644
index 0000000..13957b7
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/IndexModuleTests.java
@@ -0,0 +1,66 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.index;
+
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.search.IndexSearcher;
+import org.elasticsearch.common.inject.ModuleTestCase;
+import org.elasticsearch.index.engine.EngineConfig;
+import org.elasticsearch.index.engine.EngineException;
+import org.elasticsearch.index.engine.EngineFactory;
+import org.elasticsearch.index.engine.InternalEngineFactory;
+import org.elasticsearch.index.shard.IndexSearcherWrapper;
+import org.elasticsearch.test.engine.MockEngineFactory;
+
+public class IndexModuleTests extends ModuleTestCase {
+
+    public void testWrapperIsBound() {
+        IndexModule module = new IndexModule();
+        assertInstanceBinding(module, IndexSearcherWrapper.class,(x) -> x == null);
+        module.indexSearcherWrapper = Wrapper.class;
+        assertBinding(module, IndexSearcherWrapper.class, Wrapper.class);
+    }
+
+    public void testEngineFactoryBound() {
+        IndexModule module = new IndexModule();
+        assertBinding(module, EngineFactory.class, InternalEngineFactory.class);
+        module.engineFactoryImpl = MockEngineFactory.class;
+        assertBinding(module, EngineFactory.class, MockEngineFactory.class);
+    }
+
+    public void testOtherServiceBound() {
+        IndexModule module = new IndexModule();
+        assertBinding(module, IndexService.class, IndexService.class);
+        assertBinding(module, IndexServicesProvider.class, IndexServicesProvider.class);
+    }
+
+    public static final class Wrapper implements IndexSearcherWrapper {
+
+        @Override
+        public DirectoryReader wrap(DirectoryReader reader) {
+            return null;
+        }
+
+        @Override
+        public IndexSearcher wrap(EngineConfig engineConfig, IndexSearcher searcher) throws EngineException {
+            return null;
+        }
+    }
+
+}
diff --git a/core/src/test/java/org/elasticsearch/index/IndexServiceTests.java b/core/src/test/java/org/elasticsearch/index/IndexServiceTests.java
new file mode 100644
index 0000000..7d66382
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/IndexServiceTests.java
@@ -0,0 +1,49 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.index;
+
+import org.elasticsearch.cluster.metadata.IndexMetaData;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.index.shard.ShardId;
+import org.elasticsearch.test.ESTestCase;
+import org.junit.Test;
+
+/** Unit test(s) for IndexService */
+public class IndexServiceTests extends ESTestCase {
+
+    @Test
+    public void testDetermineShadowEngineShouldBeUsed() {
+        Settings regularSettings = Settings.builder()
+                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 2)
+                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
+                .build();
+
+        Settings shadowSettings = Settings.builder()
+                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 2)
+                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
+                .put(IndexMetaData.SETTING_SHADOW_REPLICAS, true)
+                .build();
+
+        assertFalse("no shadow replicas for normal settings", IndexService.useShadowEngine(true, regularSettings));
+        assertFalse("no shadow replicas for normal settings", IndexService.useShadowEngine(false, regularSettings));
+        assertFalse("no shadow replicas for primary shard with shadow settings", IndexService.useShadowEngine(true, shadowSettings));
+        assertTrue("shadow replicas for replica shards with shadow settings",IndexService.useShadowEngine(false, shadowSettings));
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java b/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java
index 0cbcaf9..a54be17 100644
--- a/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java
+++ b/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java
@@ -150,7 +150,7 @@ public class IndexWithShadowReplicasIT extends ESIntegTestCase {
 
         for (IndicesService service : internalCluster().getDataNodeInstances(IndicesService.class)) {
             if (service.hasIndex("foo-copy")) {
-                IndexShard shard = service.indexServiceSafe("foo-copy").shard(0);
+                IndexShard shard = service.indexServiceSafe("foo-copy").getShardOrNull(0);
                 if (shard.routingEntry().primary()) {
                     assertFalse(shard instanceof ShadowIndexShard);
                 } else {
diff --git a/core/src/test/java/org/elasticsearch/index/MockEngineFactoryPlugin.java b/core/src/test/java/org/elasticsearch/index/MockEngineFactoryPlugin.java
new file mode 100644
index 0000000..94ddde0
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/MockEngineFactoryPlugin.java
@@ -0,0 +1,48 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.index;
+
+import org.elasticsearch.common.inject.Module;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.index.IndexModule;
+import org.elasticsearch.plugins.Plugin;
+import org.elasticsearch.test.engine.MockEngineFactory;
+import org.elasticsearch.test.engine.MockEngineSupportModule;
+
+import java.util.Collection;
+import java.util.Collections;
+
+// this must exist in the same package as IndexModule to allow access to setting the impl
+public class MockEngineFactoryPlugin extends Plugin {
+    @Override
+    public String name() {
+        return "mock-engine-factory";
+    }
+    @Override
+    public String description() {
+        return "a mock engine factory for testing";
+    }
+    @Override
+    public Collection<Module> indexModules(Settings indexSettings) {
+        return Collections.<Module>singletonList(new MockEngineSupportModule());
+    }
+    public void onModule(IndexModule module) {
+        module.engineFactoryImpl = MockEngineFactory.class;
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/codec/CodecTests.java b/core/src/test/java/org/elasticsearch/index/codec/CodecTests.java
index e45f1c4..30a8e33 100644
--- a/core/src/test/java/org/elasticsearch/index/codec/CodecTests.java
+++ b/core/src/test/java/org/elasticsearch/index/codec/CodecTests.java
@@ -97,7 +97,7 @@ public class CodecTests extends ESSingleNodeTestCase {
 
     private static CodecService createCodecService(Settings settings) {
         IndexService indexService = createIndex("test", settings);
-        return indexService.injector().getInstance(CodecService.class);
+        return indexService.getIndexServices().getCodecService();
     }
 
 }
diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineSettingsTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineSettingsTests.java
index fa5db4c..1ed022d 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineSettingsTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineSettingsTests.java
@@ -21,6 +21,7 @@ package org.elasticsearch.index.engine;
 import org.apache.lucene.index.LiveIndexWriterConfig;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.IndexService;
+import org.elasticsearch.index.shard.EngineAccess;
 import org.elasticsearch.test.ESSingleNodeTestCase;
 
 import java.util.concurrent.TimeUnit;
@@ -33,7 +34,7 @@ public class InternalEngineSettingsTests extends ESSingleNodeTestCase {
     public void testSettingsUpdate() {
         final IndexService service = createIndex("foo");
         // INDEX_COMPOUND_ON_FLUSH
-        InternalEngine engine = ((InternalEngine)engine(service));
+        InternalEngine engine = ((InternalEngine) EngineAccess.engine(service.getShardOrNull(0)));
         assertThat(engine.getCurrentIndexWriterConfig().getUseCompoundFile(), is(true));
         client().admin().indices().prepareUpdateSettings("foo").setSettings(Settings.builder().put(EngineConfig.INDEX_COMPOUND_ON_FLUSH, false).build()).get();
         assertThat(engine.getCurrentIndexWriterConfig().getUseCompoundFile(), is(false));
diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
index 01197fb..4b7de9b 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
@@ -67,10 +67,7 @@ import org.elasticsearch.index.mapper.ParseContext.Document;
 import org.elasticsearch.index.mapper.internal.SourceFieldMapper;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.mapper.object.RootObjectMapper;
-import org.elasticsearch.index.shard.MergeSchedulerConfig;
-import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.shard.ShardUtils;
-import org.elasticsearch.index.shard.TranslogRecoveryPerformer;
+import org.elasticsearch.index.shard.*;
 import org.elasticsearch.index.similarity.SimilarityLookupService;
 import org.elasticsearch.index.store.DirectoryService;
 import org.elasticsearch.index.store.DirectoryUtils;
@@ -232,15 +229,15 @@ public class InternalEngineTests extends ESTestCase {
         return new SnapshotDeletionPolicy(new KeepOnlyLastCommitDeletionPolicy());
     }
 
-    protected InternalEngine createEngine(Store store, Path translogPath, IndexSearcherWrapper... wrappers) {
-        return createEngine(defaultSettings, store, translogPath, new MergeSchedulerConfig(defaultSettings), newMergePolicy(), wrappers);
+    protected InternalEngine createEngine(Store store, Path translogPath) {
+        return createEngine(defaultSettings, store, translogPath, new MergeSchedulerConfig(defaultSettings), newMergePolicy());
     }
 
-    protected InternalEngine createEngine(Settings indexSettings, Store store, Path translogPath, MergeSchedulerConfig mergeSchedulerConfig,  MergePolicy mergePolicy, IndexSearcherWrapper... wrappers) {
-        return new InternalEngine(config(indexSettings, store, translogPath, mergeSchedulerConfig, mergePolicy, wrappers), false);
+    protected InternalEngine createEngine(Settings indexSettings, Store store, Path translogPath, MergeSchedulerConfig mergeSchedulerConfig,  MergePolicy mergePolicy) {
+        return new InternalEngine(config(indexSettings, store, translogPath, mergeSchedulerConfig, mergePolicy), false);
     }
 
-    public EngineConfig config(Settings indexSettings, Store store, Path translogPath, MergeSchedulerConfig mergeSchedulerConfig, MergePolicy mergePolicy, IndexSearcherWrapper... wrappers) {
+    public EngineConfig config(Settings indexSettings, Store store, Path translogPath, MergeSchedulerConfig mergeSchedulerConfig, MergePolicy mergePolicy) {
         IndexWriterConfig iwc = newIndexWriterConfig();
         TranslogConfig translogConfig = new TranslogConfig(shardId, translogPath, indexSettings, Translog.Durabilty.REQUEST, BigArrays.NON_RECYCLING_INSTANCE, threadPool);
 
@@ -251,7 +248,7 @@ public class InternalEngineTests extends ESTestCase {
             public void onFailedEngine(ShardId shardId, String reason, @Nullable Throwable t) {
                 // we don't need to notify anybody in this test
             }
-        }, new TranslogHandler(shardId.index().getName(), logger), IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), new IndexSearcherWrappingService(new HashSet<>(Arrays.asList(wrappers))), translogConfig);
+        }, new TranslogHandler(shardId.index().getName(), logger), IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), translogConfig);
         try {
             config.setCreate(Lucene.indexExists(store.directory()) == false);
         } catch (IOException e) {
@@ -491,8 +488,7 @@ public class InternalEngineTests extends ESTestCase {
         assertThat(stats2.getUserData(), hasKey(Translog.TRANSLOG_GENERATION_KEY));
         assertThat(stats2.getUserData(), hasKey(Translog.TRANSLOG_UUID_KEY));
         assertThat(stats2.getUserData().get(Translog.TRANSLOG_GENERATION_KEY), not(equalTo(stats1.getUserData().get(Translog.TRANSLOG_GENERATION_KEY))));
-        assertThat(stats2.getUserData().get(Translog.TRANSLOG_UUID_KEY), equalTo(stats1.getUserData().get(Translog.TRANSLOG_UUID_KEY)))
-        ;
+        assertThat(stats2.getUserData().get(Translog.TRANSLOG_UUID_KEY), equalTo(stats1.getUserData().get(Translog.TRANSLOG_UUID_KEY)));
     }
 
     @Test
@@ -514,8 +510,11 @@ public class InternalEngineTests extends ESTestCase {
         };
         Store store = createStore();
         Path translog = createTempDir("translog-test");
-        InternalEngine engine = createEngine(store, translog, wrapper);
-        Engine.Searcher searcher = engine.acquireSearcher("test");
+        InternalEngine engine = createEngine(store, translog);
+        engine.close();
+
+        engine = new InternalEngine(engine.config(), false);
+        Engine.Searcher searcher = wrapper.wrap(engine.config(), engine.acquireSearcher("test"));
         assertThat(counter.get(), equalTo(2));
         searcher.close();
         IOUtils.close(store, engine);
@@ -1951,7 +1950,7 @@ public class InternalEngineTests extends ESTestCase {
         EngineConfig brokenConfig = new EngineConfig(shardId, threadPool, config.getIndexingService(), config.getIndexSettings()
                 , null, store, createSnapshotDeletionPolicy(), newMergePolicy(), config.getMergeSchedulerConfig(),
                 config.getAnalyzer(), config.getSimilarity(), new CodecService(shardId.index()), config.getFailedEngineListener()
-        , config.getTranslogRecoveryPerformer(), IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), new IndexSearcherWrappingService(), translogConfig);
+        , config.getTranslogRecoveryPerformer(), IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), translogConfig);
 
         try {
             new InternalEngine(brokenConfig, false);
diff --git a/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
index a6ca90a..b5987a9 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
@@ -216,7 +216,7 @@ public class ShadowEngineTests extends ESTestCase {
             @Override
             public void onFailedEngine(ShardId shardId, String reason, @Nullable Throwable t) {
                 // we don't need to notify anybody in this test
-        }}, null, IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), new IndexSearcherWrappingService(), translogConfig);
+        }}, null, IndexSearcher.getDefaultQueryCache(), IndexSearcher.getDefaultQueryCachingPolicy(), translogConfig);
         try {
             config.setCreate(Lucene.indexExists(store.directory()) == false);
         } catch (IOException e) {
diff --git a/core/src/test/java/org/elasticsearch/index/fielddata/AbstractFieldDataTestCase.java b/core/src/test/java/org/elasticsearch/index/fielddata/AbstractFieldDataTestCase.java
index 5980688..94178f9 100644
--- a/core/src/test/java/org/elasticsearch/index/fielddata/AbstractFieldDataTestCase.java
+++ b/core/src/test/java/org/elasticsearch/index/fielddata/AbstractFieldDataTestCase.java
@@ -102,7 +102,7 @@ public abstract class AbstractFieldDataTestCase extends ESSingleNodeTestCase {
         Settings settings = Settings.builder().put("index.fielddata.cache", "none").build();
         indexService = createIndex("test", settings);
         mapperService = indexService.mapperService();
-        indicesFieldDataCache = indexService.injector().getInstance(IndicesFieldDataCache.class);
+        indicesFieldDataCache = getInstanceFromNode(IndicesFieldDataCache.class);
         ifdService = indexService.fieldData();
         // LogByteSizeMP to preserve doc ID order
         writer = new IndexWriter(new RAMDirectory(), new IndexWriterConfig(new StandardAnalyzer()).setMergePolicy(new LogByteSizeMergePolicy()));
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java b/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java
index 009bb4c..a7314c2 100644
--- a/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java
+++ b/core/src/test/java/org/elasticsearch/index/mapper/all/SimpleAllMapperTests.java
@@ -433,7 +433,7 @@ public class SimpleAllMapperTests extends ESSingleNodeTestCase {
             client().prepareIndex(index, "type").setSource("foo", "bar").get();
             client().admin().indices().prepareRefresh(index).get();
             Query query = indexService.mapperService().documentMapper("type").allFieldMapper().fieldType().termQuery("bar", null);
-            try (Searcher searcher = indexService.shard(0).acquireSearcher("tests")) {
+            try (Searcher searcher = indexService.getShardOrNull(0).acquireSearcher("tests")) {
                 query = searcher.searcher().rewrite(query);
                 final Class<?> expected = boost ? AllTermQuery.class : TermQuery.class;
                 assertThat(query, Matchers.instanceOf(expected));
diff --git a/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java
index b697582..c567ba3 100644
--- a/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java
@@ -190,7 +190,36 @@ public class HasChildQueryBuilderTests extends AbstractQueryTestCase<HasChildQue
     }
 
     public void testParseFromJSON() throws IOException {
-        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/has-child-with-inner-hits.json");
+        String query = "{\n" +
+                "  \"has_child\" : {\n" +
+                "    \"query\" : {\n" +
+                "      \"range\" : {\n" +
+                "        \"mapped_string\" : {\n" +
+                "          \"from\" : \"agJhRET\",\n" +
+                "          \"to\" : \"zvqIq\",\n" +
+                "          \"include_lower\" : true,\n" +
+                "          \"include_upper\" : true,\n" +
+                "          \"boost\" : 1.0\n" +
+                "        }\n" +
+                "      }\n" +
+                "    },\n" +
+                "    \"child_type\" : \"child\",\n" +
+                "    \"score_mode\" : \"avg\",\n" +
+                "    \"min_children\" : 883170873,\n" +
+                "    \"max_children\" : 1217235442,\n" +
+                "    \"boost\" : 2.0,\n" +
+                "    \"_name\" : \"WNzYMJKRwePuRBh\",\n" +
+                "    \"inner_hits\" : {\n" +
+                "      \"name\" : \"inner_hits_name\",\n" +
+                "      \"size\" : 100,\n" +
+                "      \"sort\" : [ {\n" +
+                "        \"mapped_string\" : {\n" +
+                "          \"order\" : \"asc\"\n" +
+                "        }\n" +
+                "      } ]\n" +
+                "    }\n" +
+                "  }\n" +
+                "}";
         HasChildQueryBuilder queryBuilder = (HasChildQueryBuilder) parseQuery(query);
         assertEquals(query, queryBuilder.maxChildren(), 1217235442);
         assertEquals(query, queryBuilder.minChildren(), 883170873);
diff --git a/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTests.java
index 7ec3e3f..177caf0 100644
--- a/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/IdsQueryBuilderTests.java
@@ -121,4 +121,20 @@ public class IdsQueryBuilderTests extends AbstractQueryTestCase<IdsQueryBuilder>
 
         return alternateVersions;
     }
+
+    public void testIllegalArguments() {
+        try {
+            new IdsQueryBuilder((String[])null);
+            fail("must be not null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+
+        try {
+            new IdsQueryBuilder().addIds((String[])null);
+            fail("must be not null");
+        } catch(IllegalArgumentException e) {
+            //all good
+        }
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/index/search/MultiMatchQueryTests.java b/core/src/test/java/org/elasticsearch/index/search/MultiMatchQueryTests.java
index 831dc6c..3c3f1b4 100644
--- a/core/src/test/java/org/elasticsearch/index/search/MultiMatchQueryTests.java
+++ b/core/src/test/java/org/elasticsearch/index/search/MultiMatchQueryTests.java
@@ -71,7 +71,7 @@ public class MultiMatchQueryTests extends ESSingleNodeTestCase {
         QueryShardContext queryShardContext = new QueryShardContext(new Index("test"), queryParser);
         queryShardContext.setAllowUnmappedFields(true);
         Query parsedQuery = multiMatchQuery("banon").field("name.first", 2).field("name.last", 3).field("foobar").type(MultiMatchQueryBuilder.Type.CROSS_FIELDS).toQuery(queryShardContext);
-        try (Engine.Searcher searcher = indexService.shardSafe(0).acquireSearcher("test")) {
+        try (Engine.Searcher searcher = indexService.getShard(0).acquireSearcher("test")) {
             Query rewrittenQuery = searcher.searcher().rewrite(parsedQuery);
 
             BooleanQuery.Builder expected = new BooleanQuery.Builder();
diff --git a/core/src/test/java/org/elasticsearch/index/shard/EngineAccess.java b/core/src/test/java/org/elasticsearch/index/shard/EngineAccess.java
new file mode 100644
index 0000000..9e5eb6c
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/index/shard/EngineAccess.java
@@ -0,0 +1,31 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.elasticsearch.index.shard;
+
+import org.elasticsearch.index.engine.Engine;
+
+/**
+ * Test utility to access the engine of a shard
+ */
+public final class EngineAccess {
+
+    public static Engine engine(IndexShard shard) {
+        return shard.getEngine();
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/index/shard/IndexShardModuleTests.java b/core/src/test/java/org/elasticsearch/index/shard/IndexShardModuleTests.java
deleted file mode 100644
index e488905..0000000
--- a/core/src/test/java/org/elasticsearch/index/shard/IndexShardModuleTests.java
+++ /dev/null
@@ -1,54 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.index.shard;
-
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.test.ESTestCase;
-import org.junit.Test;
-
-/** Unit test(s) for IndexShardModule */
-public class IndexShardModuleTests extends ESTestCase {
-
-    @Test
-    public void testDetermineShadowEngineShouldBeUsed() {
-        ShardId shardId = new ShardId("myindex", 0);
-        Settings regularSettings = Settings.builder()
-                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 2)
-                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
-                .build();
-
-        Settings shadowSettings = Settings.builder()
-                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 2)
-                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1)
-                .put(IndexMetaData.SETTING_SHADOW_REPLICAS, true)
-                .build();
-
-        IndexShardModule ism1 = new IndexShardModule(shardId, true, regularSettings);
-        IndexShardModule ism2 = new IndexShardModule(shardId, false, regularSettings);
-        IndexShardModule ism3 = new IndexShardModule(shardId, true, shadowSettings);
-        IndexShardModule ism4 = new IndexShardModule(shardId, false, shadowSettings);
-
-        assertFalse("no shadow replicas for normal settings", ism1.useShadowEngine());
-        assertFalse("no shadow replicas for normal settings", ism2.useShadowEngine());
-        assertFalse("no shadow replicas for primary shard with shadow settings", ism3.useShadowEngine());
-        assertTrue("shadow replicas for replica shards with shadow settings", ism4.useShadowEngine());
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
index 25a8bf2..c1bdd9d 100644
--- a/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
+++ b/core/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
@@ -20,9 +20,8 @@ package org.elasticsearch.index.shard;
 
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.NumericDocValuesField;
-import org.apache.lucene.index.CorruptIndexException;
-import org.apache.lucene.index.IndexCommit;
-import org.apache.lucene.index.Term;
+import org.apache.lucene.index.*;
+import org.apache.lucene.search.*;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.LockObtainFailedException;
 import org.apache.lucene.util.Constants;
@@ -58,13 +57,17 @@ import org.elasticsearch.env.Environment;
 import org.elasticsearch.env.NodeEnvironment;
 import org.elasticsearch.env.ShardLock;
 import org.elasticsearch.index.IndexService;
+import org.elasticsearch.index.IndexServicesProvider;
 import org.elasticsearch.index.engine.Engine;
+import org.elasticsearch.index.engine.EngineConfig;
+import org.elasticsearch.index.engine.EngineException;
 import org.elasticsearch.index.flush.FlushStats;
 import org.elasticsearch.index.indexing.IndexingOperationListener;
 import org.elasticsearch.index.indexing.ShardIndexingService;
 import org.elasticsearch.index.mapper.Mapping;
 import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.ParsedDocument;
+import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.common.ParsingException;
 import org.elasticsearch.index.settings.IndexSettingsService;
@@ -112,7 +115,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         ensureGreen();
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         assertEquals(initValue, shard.isFlushOnClose());
         final boolean newValue = !initValue;
         assertAcked(client().admin().indices().prepareUpdateSettings("test").setSettings(settingsBuilder().put(IndexShard.INDEX_FLUSH_ON_CLOSE, newValue).build()));
@@ -183,7 +186,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         NodeEnvironment env = getInstanceFromNode(NodeEnvironment.class);
         IndexService test = indicesService.indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         ShardStateMetaData shardStateMetaData = load(logger, env.availableShardPaths(shard.shardId));
         assertEquals(getShardStateMetadata(shard), shardStateMetaData);
         ShardRouting routing = new ShardRouting(shard.shardRouting, shard.shardRouting.version() + 1);
@@ -232,7 +235,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         NodeEnvironment env = getInstanceFromNode(NodeEnvironment.class);
         IndexService test = indicesService.indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         try {
             shard.deleteShardState();
             fail("shard is active metadata delete must fail");
@@ -259,7 +262,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         NodeEnvironment env = getInstanceFromNode(NodeEnvironment.class);
         IndexService test = indicesService.indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         // fail shard
         shard.failShard("test shard fail", new CorruptIndexException("", ""));
         // check state file still exists
@@ -304,7 +307,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         ensureGreen("test");
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService indexService = indicesService.indexServiceSafe("test");
-        IndexShard indexShard = indexService.shard(0);
+        IndexShard indexShard = indexService.getShardOrNull(0);
         client().admin().indices().prepareDelete("test").get();
         assertThat(indexShard.getOperationsCount(), equalTo(0));
         try {
@@ -321,7 +324,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         ensureGreen("test");
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService indexService = indicesService.indexServiceSafe("test");
-        IndexShard indexShard = indexService.shard(0);
+        IndexShard indexShard = indexService.getShardOrNull(0);
         assertEquals(0, indexShard.getOperationsCount());
         indexShard.incrementOperationCounter();
         assertEquals(1, indexShard.getOperationsCount());
@@ -339,7 +342,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         client().prepareIndex("test", "test").setSource("{}").get();
         ensureGreen("test");
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
-        indicesService.indexService("test").shard(0).markAsInactive();
+        indicesService.indexService("test").getShardOrNull(0).markAsInactive();
         assertBusy(new Runnable() { // should be very very quick
             @Override
             public void run() {
@@ -366,31 +369,31 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         client().prepareIndex("test", "bar", "1").setSource("{}").get();
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         setDurability(shard, Translog.Durabilty.REQUEST);
-        assertFalse(shard.engine().getTranslog().syncNeeded());
+        assertFalse(shard.getEngine().getTranslog().syncNeeded());
         setDurability(shard, Translog.Durabilty.ASYNC);
         client().prepareIndex("test", "bar", "2").setSource("{}").get();
-        assertTrue(shard.engine().getTranslog().syncNeeded());
+        assertTrue(shard.getEngine().getTranslog().syncNeeded());
         setDurability(shard, Translog.Durabilty.REQUEST);
         client().prepareDelete("test", "bar", "1").get();
-        assertFalse(shard.engine().getTranslog().syncNeeded());
+        assertFalse(shard.getEngine().getTranslog().syncNeeded());
 
         setDurability(shard, Translog.Durabilty.ASYNC);
         client().prepareDelete("test", "bar", "2").get();
-        assertTrue(shard.engine().getTranslog().syncNeeded());
+        assertTrue(shard.getEngine().getTranslog().syncNeeded());
         setDurability(shard, Translog.Durabilty.REQUEST);
         assertNoFailures(client().prepareBulk()
                 .add(client().prepareIndex("test", "bar", "3").setSource("{}"))
                 .add(client().prepareDelete("test", "bar", "1")).get());
-        assertFalse(shard.engine().getTranslog().syncNeeded());
+        assertFalse(shard.getEngine().getTranslog().syncNeeded());
 
         setDurability(shard, Translog.Durabilty.ASYNC);
         assertNoFailures(client().prepareBulk()
                 .add(client().prepareIndex("test", "bar", "4").setSource("{}"))
                 .add(client().prepareDelete("test", "bar", "3")).get());
         setDurability(shard, Translog.Durabilty.REQUEST);
-        assertTrue(shard.engine().getTranslog().syncNeeded());
+        assertTrue(shard.getEngine().getTranslog().syncNeeded());
     }
 
     private void setDurability(IndexShard shard, Translog.Durabilty durabilty) {
@@ -407,12 +410,12 @@ public class IndexShardTests extends ESSingleNodeTestCase {
 
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         int numDocs = 1;
         shard.state = IndexShardState.RECOVERING;
         try {
             shard.recoveryState().getTranslog().totalOperations(1);
-            shard.engine().config().getTranslogRecoveryPerformer().performRecoveryOperation(shard.engine(), new Translog.DeleteByQuery(new Engine.DeleteByQuery(null, new BytesArray("{\"term\" : { \"user\" : \"kimchy\" }}"), null, null, null, Engine.Operation.Origin.RECOVERY, 0, "person")), false);
+            shard.getEngine().config().getTranslogRecoveryPerformer().performRecoveryOperation(shard.getEngine(), new Translog.DeleteByQuery(new Engine.DeleteByQuery(null, new BytesArray("{\"term\" : { \"user\" : \"kimchy\" }}"), null, null, null, Engine.Operation.Origin.RECOVERY, 0, "person")), false);
             assertTrue(version.onOrBefore(Version.V_1_0_0_Beta2));
             numDocs = 0;
         } catch (ParsingException ex) {
@@ -420,9 +423,9 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         } finally {
             shard.state = IndexShardState.STARTED;
         }
-        shard.engine().refresh("foo");
+        shard.getEngine().refresh("foo");
 
-        try (Engine.Searcher searcher = shard.engine().acquireSearcher("foo")) {
+        try (Engine.Searcher searcher = shard.getEngine().acquireSearcher("foo")) {
             assertEquals(numDocs, searcher.reader().numDocs());
         }
     }
@@ -434,11 +437,11 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         client().prepareIndex("test", "test").setSource("{}").get();
         ensureGreen("test");
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
-        IndexShard test = indicesService.indexService("test").shard(0);
+        IndexShard test = indicesService.indexService("test").getShardOrNull(0);
         assertEquals(versionCreated.luceneVersion, test.minimumCompatibleVersion());
         client().prepareIndex("test", "test").setSource("{}").get();
         assertEquals(versionCreated.luceneVersion, test.minimumCompatibleVersion());
-        test.engine().flush();
+        test.getEngine().flush();
         assertEquals(Version.CURRENT.luceneVersion, test.minimumCompatibleVersion());
     }
 
@@ -460,7 +463,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         assertHitCount(response, 1l);
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         ShardPath shardPath = shard.shardPath();
         Path dataPath = shardPath.getDataPath();
         client().admin().indices().prepareClose("test").get();
@@ -580,7 +583,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         ensureGreen();
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         ShardStats stats = new ShardStats(shard.routingEntry(), shard.shardPath(), new CommonStats(shard, new CommonStatsFlags()), shard.commitStats());
         assertEquals(shard.shardPath().getRootDataPath().toString(), stats.getDataPath());
         assertEquals(shard.shardPath().getRootStatePath().toString(), stats.getStatePath());
@@ -619,7 +622,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         ensureGreen();
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("testpreindex");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         ShardIndexingService shardIndexingService = shard.indexingService();
         final AtomicBoolean preIndexCalled = new AtomicBoolean(false);
 
@@ -642,7 +645,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         ensureGreen();
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("testpostindex");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         ShardIndexingService shardIndexingService = shard.indexingService();
         final AtomicBoolean postIndexCalled = new AtomicBoolean(false);
 
@@ -665,7 +668,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         ensureGreen();
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("testpostindexwithexception");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         ShardIndexingService shardIndexingService = shard.indexingService();
 
         shard.close("Unexpected close", true);
@@ -700,7 +703,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         ensureGreen();
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
         assertFalse(shard.shouldFlush());
         client().admin().indices().prepareUpdateSettings("test").setSettings(settingsBuilder().put(IndexShard.INDEX_TRANSLOG_FLUSH_THRESHOLD_OPS, 1).build()).get();
         client().prepareIndex("test", "test", "0").setSource("{}").setRefresh(randomBoolean()).get();
@@ -709,25 +712,25 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         Engine.Index index = new Engine.Index(new Term("_uid", "1"), doc);
         shard.index(index);
         assertTrue(shard.shouldFlush());
-        assertEquals(2, shard.engine().getTranslog().totalOperations());
+        assertEquals(2, shard.getEngine().getTranslog().totalOperations());
         client().prepareIndex("test", "test", "2").setSource("{}").setRefresh(randomBoolean()).get();
         assertBusy(() -> { // this is async
             assertFalse(shard.shouldFlush());
         });
-        assertEquals(0, shard.engine().getTranslog().totalOperations());
-        shard.engine().getTranslog().sync();
-        long size = shard.engine().getTranslog().sizeInBytes();
-        logger.info("--> current translog size: [{}] num_ops [{}] generation [{}]", shard.engine().getTranslog().sizeInBytes(), shard.engine().getTranslog().totalOperations(), shard.engine().getTranslog().getGeneration());
+        assertEquals(0, shard.getEngine().getTranslog().totalOperations());
+        shard.getEngine().getTranslog().sync();
+        long size = shard.getEngine().getTranslog().sizeInBytes();
+        logger.info("--> current translog size: [{}] num_ops [{}] generation [{}]", shard.getEngine().getTranslog().sizeInBytes(), shard.getEngine().getTranslog().totalOperations(), shard.getEngine().getTranslog().getGeneration());
         client().admin().indices().prepareUpdateSettings("test").setSettings(settingsBuilder().put(IndexShard.INDEX_TRANSLOG_FLUSH_THRESHOLD_OPS, 1000)
                 .put(IndexShard.INDEX_TRANSLOG_FLUSH_THRESHOLD_SIZE, new ByteSizeValue(size, ByteSizeUnit.BYTES))
                 .build()).get();
         client().prepareDelete("test", "test", "2").get();
-        logger.info("--> translog size after delete: [{}] num_ops [{}] generation [{}]", shard.engine().getTranslog().sizeInBytes(), shard.engine().getTranslog().totalOperations(), shard.engine().getTranslog().getGeneration());
+        logger.info("--> translog size after delete: [{}] num_ops [{}] generation [{}]", shard.getEngine().getTranslog().sizeInBytes(), shard.getEngine().getTranslog().totalOperations(), shard.getEngine().getTranslog().getGeneration());
         assertBusy(() -> { // this is async
-            logger.info("--> translog size on iter  : [{}] num_ops [{}] generation [{}]", shard.engine().getTranslog().sizeInBytes(), shard.engine().getTranslog().totalOperations(), shard.engine().getTranslog().getGeneration());
+            logger.info("--> translog size on iter  : [{}] num_ops [{}] generation [{}]", shard.getEngine().getTranslog().sizeInBytes(), shard.getEngine().getTranslog().totalOperations(), shard.getEngine().getTranslog().getGeneration());
             assertFalse(shard.shouldFlush());
         });
-        assertEquals(0, shard.engine().getTranslog().totalOperations());
+        assertEquals(0, shard.getEngine().getTranslog().totalOperations());
     }
 
     public void testStressMaybeFlush() throws Exception {
@@ -735,7 +738,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         ensureGreen();
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("test");
-        final IndexShard shard = test.shard(0);
+        final IndexShard shard = test.getShardOrNull(0);
         assertFalse(shard.shouldFlush());
         client().admin().indices().prepareUpdateSettings("test").setSettings(settingsBuilder().put(IndexShard.INDEX_TRANSLOG_FLUSH_THRESHOLD_OPS, 1).build()).get();
         client().prepareIndex("test", "test", "0").setSource("{}").setRefresh(randomBoolean()).get();
@@ -778,7 +781,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         ensureGreen();
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("test");
-        final IndexShard shard = test.shard(0);
+        final IndexShard shard = test.getShardOrNull(0);
 
         client().prepareIndex("test", "test", "0").setSource("{}").setRefresh(randomBoolean()).get();
         if (randomBoolean()) {
@@ -804,7 +807,7 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         DiscoveryNode localNode = new DiscoveryNode("foo", DummyTransportAddress.INSTANCE, Version.CURRENT);
         IndexService test = indicesService.indexService("test");
-        final IndexShard shard = test.shard(0);
+        final IndexShard shard = test.getShardOrNull(0);
 
         client().prepareIndex("test", "test", "0").setSource("{}").setRefresh(randomBoolean()).get();
         if (randomBoolean()) {
@@ -852,14 +855,14 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService test = indicesService.indexService("test");
         IndexService test_target = indicesService.indexService("test_target");
-        final IndexShard test_shard = test.shard(0);
+        final IndexShard test_shard = test.getShardOrNull(0);
 
         client().prepareIndex("test", "test", "0").setSource("{}").setRefresh(randomBoolean()).get();
         client().prepareIndex("test_target", "test", "1").setSource("{}").setRefresh(true).get();
         assertHitCount(client().prepareSearch("test_target").get(), 1);
         assertSearchHits(client().prepareSearch("test_target").get(), "1");
         client().admin().indices().prepareFlush("test").get(); // only flush test
-        final ShardRouting origRouting = test_target.shard(0).routingEntry();
+        final ShardRouting origRouting = test_target.getShardOrNull(0).routingEntry();
         ShardRouting routing = new ShardRouting(origRouting);
         ShardRoutingHelper.reinit(routing);
         routing = ShardRoutingHelper.newWithRestoreSource(routing, new RestoreSource(new SnapshotId("foo", "bar"), Version.CURRENT, "test"));
@@ -912,10 +915,100 @@ public class IndexShardTests extends ESSingleNodeTestCase {
         ensureGreen();
         IndicesService indicesService = getInstanceFromNode(IndicesService.class);
         IndexService indexService = indicesService.indexService("test");
-        IndexShard shard = indexService.shard(0);
+        IndexShard shard = indexService.getShardOrNull(0);
         IndexSettingsService settingsService = indexService.settingsService();
         assertTrue(settingsService.isRegistered(shard));
         indexService.removeShard(0, "simon says so");
         assertFalse(settingsService.isRegistered(shard));
     }
+
+    public void testSearcherWrapperIsUsed() throws IOException {
+        createIndex("test");
+        ensureGreen();
+        IndicesService indicesService = getInstanceFromNode(IndicesService.class);
+        IndexService indexService = indicesService.indexService("test");
+        IndexShard shard = indexService.getShardOrNull(0);
+        client().prepareIndex("test", "test", "0").setSource("{\"foo\" : \"bar\"}").setRefresh(randomBoolean()).get();
+        client().prepareIndex("test", "test", "1").setSource("{\"foobar\" : \"bar\"}").setRefresh(true).get();
+
+        Engine.GetResult getResult = shard.get(new Engine.Get(false, new Term(UidFieldMapper.NAME, Uid.createUid("test", "1"))));
+        assertTrue(getResult.exists());
+        assertNotNull(getResult.searcher());
+        getResult.release();
+        try (Engine.Searcher searcher = shard.acquireSearcher("test")) {
+            TopDocs search = searcher.searcher().search(new TermQuery(new Term("foo", "bar")), 10);
+            assertEquals(search.totalHits, 1);
+            search = searcher.searcher().search(new TermQuery(new Term("foobar", "bar")), 10);
+            assertEquals(search.totalHits, 1);
+        }
+
+        ShardRouting routing = new ShardRouting(shard.routingEntry());
+        shard.close("simon says", true);
+        IndexServicesProvider indexServices = indexService.getIndexServices();
+        IndexSearcherWrapper wrapper = new IndexSearcherWrapper() {
+            @Override
+            public DirectoryReader wrap(DirectoryReader reader) throws IOException {
+                return new FieldMaskingReader("foo", reader);
+            }
+
+            @Override
+            public IndexSearcher wrap(EngineConfig engineConfig, IndexSearcher searcher) throws EngineException {
+                return searcher;
+            }
+        };
+
+        IndexServicesProvider newProvider = new IndexServicesProvider(indexServices.getIndicesLifecycle(), indexServices.getThreadPool(), indexServices.getMapperService(), indexServices.getQueryParserService(), indexServices.getIndexCache(), indexServices.getIndexAliasesService(), indexServices.getIndicesQueryCache(), indexServices.getCodecService(), indexServices.getTermVectorsService(), indexServices.getIndexFieldDataService(), indexServices.getWarmer(), indexServices.getSimilarityService(), indexServices.getFactory(), indexServices.getBigArrays(), wrapper);
+        IndexShard newShard = new IndexShard(shard.shardId(), shard.indexSettings, shard.shardPath(), shard.store(), newProvider);
+
+        ShardRoutingHelper.reinit(routing);
+        newShard.updateRoutingEntry(routing, false);
+        DiscoveryNode localNode = new DiscoveryNode("foo", DummyTransportAddress.INSTANCE, Version.CURRENT);
+        assertTrue(newShard.recoverFromStore(routing, localNode));
+        routing = new ShardRouting(routing);
+        ShardRoutingHelper.moveToStarted(routing);
+        newShard.updateRoutingEntry(routing, true);
+        try (Engine.Searcher searcher = newShard.acquireSearcher("test")) {
+            TopDocs search = searcher.searcher().search(new TermQuery(new Term("foo", "bar")), 10);
+            assertEquals(search.totalHits, 0);
+            search = searcher.searcher().search(new TermQuery(new Term("foobar", "bar")), 10);
+            assertEquals(search.totalHits, 1);
+        }
+        getResult = newShard.get(new Engine.Get(false, new Term(UidFieldMapper.NAME, Uid.createUid("test", "1"))));
+        assertTrue(getResult.exists());
+        assertNotNull(getResult.searcher()); // make sure get uses the wrapped reader
+        assertTrue(getResult.searcher().reader() instanceof FieldMaskingReader);
+        getResult.release();
+        newShard.close("just do it", randomBoolean());
+    }
+
+    private static class FieldMaskingReader extends FilterDirectoryReader {
+
+        private final String field;
+        public FieldMaskingReader(String field, DirectoryReader in) throws IOException {
+            super(in, new SubReaderWrapper() {
+                private final String filteredField = field;
+                @Override
+                public LeafReader wrap(LeafReader reader) {
+                    return new FilterLeafReader(reader) {
+                        @Override
+                        public Fields fields() throws IOException {
+                            return new FilterFields(super.fields()) {
+                                @Override
+                                public Terms terms(String field) throws IOException {
+                                    return filteredField.equals(field) ? null : super.terms(field);
+                                }
+                            };
+                        }
+                    };
+                }
+            });
+            this.field = field;
+
+        }
+
+        @Override
+        protected DirectoryReader doWrapDirectoryReader(DirectoryReader in) throws IOException {
+            return new FieldMaskingReader(field, in);
+        }
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/index/shard/MockEngineFactoryPlugin.java b/core/src/test/java/org/elasticsearch/index/shard/MockEngineFactoryPlugin.java
deleted file mode 100644
index d1b5048..0000000
--- a/core/src/test/java/org/elasticsearch/index/shard/MockEngineFactoryPlugin.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.index.shard;
-
-import org.elasticsearch.common.inject.Module;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.plugins.Plugin;
-import org.elasticsearch.test.engine.MockEngineFactory;
-import org.elasticsearch.test.engine.MockEngineSupportModule;
-
-import java.util.Collection;
-import java.util.Collections;
-
-// this must exist in the same package as IndexShardModule to allow access to setting the impl
-public class MockEngineFactoryPlugin extends Plugin {
-    @Override
-    public String name() {
-        return "mock-engine-factory";
-    }
-    @Override
-    public String description() {
-        return "a mock engine factory for testing";
-    }
-    @Override
-    public Collection<Module> indexModules(Settings indexSettings) {
-        return Collections.<Module>singletonList(new MockEngineSupportModule());
-    }
-    public void onModule(IndexShardModule module) {
-        module.engineFactoryImpl = MockEngineFactory.class;
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/index/store/StoreTests.java b/core/src/test/java/org/elasticsearch/index/store/StoreTests.java
index 144dedd..11d01c9 100644
--- a/core/src/test/java/org/elasticsearch/index/store/StoreTests.java
+++ b/core/src/test/java/org/elasticsearch/index/store/StoreTests.java
@@ -208,11 +208,6 @@ public class StoreTests extends ESTestCase {
                     verifyingOutput.writeByte(checksumBytes.bytes[i]);
                 }
             }
-            if (randomBoolean()) {
-               appendRandomData(verifyingOutput);
-            } else {
-                Store.verify(verifyingOutput);
-            }
             fail("should be a corrupted index");
         } catch (CorruptIndexException | IndexFormatTooOldException | IndexFormatTooNewException ex) {
             // ok
diff --git a/core/src/test/java/org/elasticsearch/indexing/IndexActionIT.java b/core/src/test/java/org/elasticsearch/indexing/IndexActionIT.java
index 9700841..1c914c1 100644
--- a/core/src/test/java/org/elasticsearch/indexing/IndexActionIT.java
+++ b/core/src/test/java/org/elasticsearch/indexing/IndexActionIT.java
@@ -203,7 +203,7 @@ public class IndexActionIT extends ESIntegTestCase {
 
         try {
             // Catch chars that are more than a single byte
-            client().prepareIndex(randomAsciiOfLength(MetaDataCreateIndexService.MAX_INDEX_NAME_BYTES -1).toLowerCase(Locale.ROOT) +
+            client().prepareIndex(randomAsciiOfLength(MetaDataCreateIndexService.MAX_INDEX_NAME_BYTES - 1).toLowerCase(Locale.ROOT) +
                             "Ϟ".toLowerCase(Locale.ROOT),
                     "mytype").setSource("foo", "bar").get();
             fail("exception should have been thrown on too-long index name");
@@ -215,4 +215,22 @@ public class IndexActionIT extends ESIntegTestCase {
         // we can create an index of max length
         createIndex(randomAsciiOfLength(MetaDataCreateIndexService.MAX_INDEX_NAME_BYTES).toLowerCase(Locale.ROOT));
     }
+
+    public void testInvalidIndexName() {
+        try {
+            createIndex(".");
+            fail("exception should have been thrown on dot index name");
+        } catch (InvalidIndexNameException e) {
+            assertThat("exception contains message about index name is dot " + e.getMessage(),
+                    e.getMessage().contains("Invalid index name [.], must not be \'.\' or '..'"), equalTo(true));
+        }
+
+        try {
+            createIndex("..");
+            fail("exception should have been thrown on dot index name");
+        } catch (InvalidIndexNameException e) {
+            assertThat("exception contains message about index name is dot " + e.getMessage(),
+                    e.getMessage().contains("Invalid index name [..], must not be \'.\' or '..'"), equalTo(true));
+        }
+    }
 }
diff --git a/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java b/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java
index b1ed006..995deac 100644
--- a/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java
+++ b/core/src/test/java/org/elasticsearch/indices/IndicesServiceTests.java
@@ -137,8 +137,8 @@ public class IndicesServiceTests extends ESSingleNodeTestCase {
         IndexService test = createIndex("test");
 
         assertTrue(test.hasShard(0));
-        ShardPath path = test.shard(0).shardPath();
-        assertTrue(test.shard(0).routingEntry().started());
+        ShardPath path = test.getShardOrNull(0).shardPath();
+        assertTrue(test.getShardOrNull(0).routingEntry().started());
         ShardPath shardPath = ShardPath.loadShardPath(logger, getNodeEnvironment(), new ShardId(test.index(), 0), test.getIndexSettings());
         assertEquals(shardPath, path);
         try {
diff --git a/core/src/test/java/org/elasticsearch/indices/flush/SyncedFlushSingleNodeTests.java b/core/src/test/java/org/elasticsearch/indices/flush/SyncedFlushSingleNodeTests.java
index 06c2566..1a4bf8f 100644
--- a/core/src/test/java/org/elasticsearch/indices/flush/SyncedFlushSingleNodeTests.java
+++ b/core/src/test/java/org/elasticsearch/indices/flush/SyncedFlushSingleNodeTests.java
@@ -42,7 +42,7 @@ public class SyncedFlushSingleNodeTests extends ESSingleNodeTestCase {
         createIndex("test");
         client().prepareIndex("test", "test", "1").setSource("{}").get();
         IndexService test = getInstanceFromNode(IndicesService.class).indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
 
         SyncedFlushService flushService = getInstanceFromNode(SyncedFlushService.class);
         final ShardId shardId = shard.shardId();
@@ -86,7 +86,7 @@ public class SyncedFlushSingleNodeTests extends ESSingleNodeTestCase {
         createIndex("test");
         client().prepareIndex("test", "test", "1").setSource("{}").get();
         IndexService test = getInstanceFromNode(IndicesService.class).indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
 
         SyncedFlushService flushService = getInstanceFromNode(SyncedFlushService.class);
         final ShardId shardId = shard.shardId();
@@ -106,7 +106,7 @@ public class SyncedFlushSingleNodeTests extends ESSingleNodeTestCase {
         createIndex("test");
         client().prepareIndex("test", "test", "1").setSource("{}").get();
         IndexService test = getInstanceFromNode(IndicesService.class).indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
 
         SyncedFlushService flushService = getInstanceFromNode(SyncedFlushService.class);
         final ShardId shardId = shard.shardId();
@@ -129,7 +129,7 @@ public class SyncedFlushSingleNodeTests extends ESSingleNodeTestCase {
     public void testSyncFailsOnIndexClosedOrMissing() throws InterruptedException {
         createIndex("test");
         IndexService test = getInstanceFromNode(IndicesService.class).indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
 
         SyncedFlushService flushService = getInstanceFromNode(SyncedFlushService.class);
         SyncedFlushUtil.LatchedListener listener = new SyncedFlushUtil.LatchedListener();
@@ -162,7 +162,7 @@ public class SyncedFlushSingleNodeTests extends ESSingleNodeTestCase {
         createIndex("test");
         client().prepareIndex("test", "test", "1").setSource("{}").get();
         IndexService test = getInstanceFromNode(IndicesService.class).indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
 
         SyncedFlushService flushService = getInstanceFromNode(SyncedFlushService.class);
         final ShardId shardId = shard.shardId();
@@ -195,7 +195,7 @@ public class SyncedFlushSingleNodeTests extends ESSingleNodeTestCase {
         createIndex("test");
         client().prepareIndex("test", "test", "1").setSource("{}").get();
         IndexService test = getInstanceFromNode(IndicesService.class).indexService("test");
-        IndexShard shard = test.shard(0);
+        IndexShard shard = test.getShardOrNull(0);
 
         SyncedFlushService flushService = getInstanceFromNode(SyncedFlushService.class);
         final ShardId shardId = shard.shardId();
diff --git a/core/src/test/java/org/elasticsearch/indices/leaks/IndicesLeaksIT.java b/core/src/test/java/org/elasticsearch/indices/leaks/IndicesLeaksIT.java
deleted file mode 100644
index 422fee6..0000000
--- a/core/src/test/java/org/elasticsearch/indices/leaks/IndicesLeaksIT.java
+++ /dev/null
@@ -1,131 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.elasticsearch.indices.leaks;
-
-import org.elasticsearch.common.inject.Injector;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.IndexService;
-import org.elasticsearch.index.shard.IndexShard;
-import org.elasticsearch.indices.IndicesService;
-import org.elasticsearch.test.ESIntegTestCase;
-import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
-import org.junit.Test;
-
-import java.lang.ref.WeakReference;
-import java.util.ArrayList;
-import java.util.List;
-
-import static org.elasticsearch.test.ESIntegTestCase.Scope;
-import static org.hamcrest.Matchers.nullValue;
-
-/**
- */
-@ClusterScope(scope= Scope.TEST, numDataNodes =1)
-public class IndicesLeaksIT extends ESIntegTestCase {
-
-
-    @SuppressWarnings({"ConstantConditions", "unchecked"})
-    @Test
-    @BadApple(bugUrl = "https://github.com/elasticsearch/elasticsearch/issues/3232")
-    public void testIndexShardLifecycleLeak() throws Exception {
-
-        client().admin().indices().prepareCreate("test")
-                .setSettings(Settings.builder().put("index.number_of_shards", 1).put("index.number_of_replicas", 0))
-                .execute().actionGet();
-
-        client().admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();
-
-        IndicesService indicesService = internalCluster().getDataNodeInstance(IndicesService.class);
-        IndexService indexService = indicesService.indexServiceSafe("test");
-        Injector indexInjector = indexService.injector();
-        IndexShard shard = indexService.shardSafe(0);
-        Injector shardInjector = indexService.shardInjectorSafe(0);
-
-        performCommonOperations();
-
-        List<WeakReference> indexReferences = new ArrayList<>();
-        List<WeakReference> shardReferences = new ArrayList<>();
-
-        // TODO if we could iterate over the already created classes on the injector, we can just add them here to the list
-        // for now, we simple add some classes that make sense
-
-        // add index references
-        indexReferences.add(new WeakReference(indexService));
-        indexReferences.add(new WeakReference(indexInjector));
-        indexReferences.add(new WeakReference(indexService.mapperService()));
-        for (DocumentMapper documentMapper : indexService.mapperService().docMappers(true)) {
-            indexReferences.add(new WeakReference(documentMapper));
-        }
-        indexReferences.add(new WeakReference(indexService.aliasesService()));
-        indexReferences.add(new WeakReference(indexService.analysisService()));
-        indexReferences.add(new WeakReference(indexService.fieldData()));
-        indexReferences.add(new WeakReference(indexService.queryParserService()));
-
-
-        // add shard references
-        shardReferences.add(new WeakReference(shard));
-        shardReferences.add(new WeakReference(shardInjector));
-
-        indexService = null;
-        indexInjector = null;
-        shard = null;
-        shardInjector = null;
-
-        cluster().wipeIndices("test");
-
-        for (int i = 0; i < 100; i++) {
-            System.gc();
-            int indexNotCleared = 0;
-            for (WeakReference indexReference : indexReferences) {
-                if (indexReference.get() != null) {
-                    indexNotCleared++;
-                }
-            }
-            int shardNotCleared = 0;
-            for (WeakReference shardReference : shardReferences) {
-                if (shardReference.get() != null) {
-                    shardNotCleared++;
-                }
-            }
-            logger.info("round {}, indices {}/{}, shards {}/{}", i, indexNotCleared, indexReferences.size(), shardNotCleared, shardReferences.size());
-            if (indexNotCleared == 0 && shardNotCleared == 0) {
-                break;
-            }
-        }
-
-        //System.out.println("sleeping");Thread.sleep(1000000);
-
-        for (WeakReference indexReference : indexReferences) {
-            assertThat("dangling index reference: " + indexReference.get(), indexReference.get(), nullValue());
-        }
-
-        for (WeakReference shardReference : shardReferences) {
-            assertThat("dangling shard reference: " + shardReference.get(), shardReference.get(), nullValue());
-        }
-    }
-
-    private void performCommonOperations() {
-        client().prepareIndex("test", "type", "1").setSource("field1", "value", "field2", 2, "field3", 3.0f).execute().actionGet();
-        client().admin().indices().prepareRefresh().execute().actionGet();
-        client().prepareSearch("test").setQuery(QueryBuilders.queryStringQuery("field1:value")).execute().actionGet();
-        client().prepareSearch("test").setQuery(QueryBuilders.termQuery("field1", "value")).execute().actionGet();
-    }
-}
diff --git a/core/src/test/java/org/elasticsearch/indices/memory/IndexingMemoryControllerTests.java b/core/src/test/java/org/elasticsearch/indices/memory/IndexingMemoryControllerTests.java
index 4a6f29e..f6e21db 100644
--- a/core/src/test/java/org/elasticsearch/indices/memory/IndexingMemoryControllerTests.java
+++ b/core/src/test/java/org/elasticsearch/indices/memory/IndexingMemoryControllerTests.java
@@ -22,17 +22,13 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.ByteSizeUnit;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.index.engine.EngineConfig;
 import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.translog.TranslogConfig;
 import org.elasticsearch.test.ESTestCase;
 
 import java.util.ArrayList;
 import java.util.HashMap;
-import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
-import java.util.Set;
 
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.not;
@@ -43,28 +39,44 @@ public class IndexingMemoryControllerTests extends ESTestCase {
 
         final static ByteSizeValue INACTIVE = new ByteSizeValue(-1);
 
+        final Map<ShardId, Long> translogIds = new HashMap<>();
+        final Map<ShardId, Long> translogOps = new HashMap<>();
+
         final Map<ShardId, ByteSizeValue> indexingBuffers = new HashMap<>();
         final Map<ShardId, ByteSizeValue> translogBuffers = new HashMap<>();
 
-        final Map<ShardId, Long> lastIndexTimeNanos = new HashMap<>();
-        final Set<ShardId> activeShards = new HashSet<>();
-
         long currentTimeSec = TimeValue.timeValueNanos(System.nanoTime()).seconds();
 
         public MockController(Settings settings) {
             super(Settings.builder()
                             .put(SHARD_INACTIVE_INTERVAL_TIME_SETTING, "200h") // disable it
-                            .put(SHARD_INACTIVE_TIME_SETTING, "1ms") // nearly immediate
+                            .put(SHARD_INACTIVE_TIME_SETTING, "0s") // immediate
                             .put(settings)
                             .build(),
                     null, null, 100 * 1024 * 1024); // fix jvm mem size to 100mb
         }
 
+        public void incTranslog(ShardId shard1, int id, int ops) {
+            setTranslog(shard1, translogIds.get(shard1) + id, translogOps.get(shard1) + ops);
+        }
+
+        public void setTranslog(ShardId id, long translogId, long ops) {
+            translogIds.put(id, translogId);
+            translogOps.put(id, ops);
+        }
+
         public void deleteShard(ShardId id) {
+            translogIds.remove(id);
+            translogOps.remove(id);
             indexingBuffers.remove(id);
             translogBuffers.remove(id);
         }
 
+        public void assertActive(ShardId id) {
+            assertThat(indexingBuffers.get(id), not(equalTo(INACTIVE)));
+            assertThat(translogBuffers.get(id), not(equalTo(INACTIVE)));
+        }
+
         public void assertBuffers(ShardId id, ByteSizeValue indexing, ByteSizeValue translog) {
             assertThat(indexingBuffers.get(id), equalTo(indexing));
             assertThat(translogBuffers.get(id), equalTo(translog));
@@ -82,24 +94,29 @@ public class IndexingMemoryControllerTests extends ESTestCase {
 
         @Override
         protected List<ShardId> availableShards() {
-            return new ArrayList<>(indexingBuffers.keySet());
+            return new ArrayList<>(translogIds.keySet());
         }
 
         @Override
         protected boolean shardAvailable(ShardId shardId) {
-            return indexingBuffers.containsKey(shardId);
+            return translogIds.containsKey(shardId);
         }
 
         @Override
         protected void markShardAsInactive(ShardId shardId) {
             indexingBuffers.put(shardId, INACTIVE);
             translogBuffers.put(shardId, INACTIVE);
-            activeShards.remove(shardId);
         }
 
         @Override
-        protected Boolean getShardActive(ShardId shardId) {
-            return activeShards.contains(shardId);
+        protected ShardIndexingStatus getTranslogStatus(ShardId shardId) {
+            if (!shardAvailable(shardId)) {
+                return null;
+            }
+            ShardIndexingStatus status = new ShardIndexingStatus();
+            status.translogId = translogIds.get(shardId);
+            status.translogNumberOfOperations = translogOps.get(shardId);
+            return status;
         }
 
         @Override
@@ -108,23 +125,12 @@ public class IndexingMemoryControllerTests extends ESTestCase {
             translogBuffers.put(shardId, shardTranslogBufferSize);
         }
 
-        @Override
-        protected boolean isShardIdle(ShardId shardId, long inactiveTimeNS) {
-            return currentTimeInNanos() - lastIndexTimeNanos.get(shardId) >= inactiveTimeNS;
-        }
-
         public void incrementTimeSec(int sec) {
             currentTimeSec += sec;
         }
 
-        public void simulateIndexing(ShardId shardId) {
-            lastIndexTimeNanos.put(shardId, currentTimeInNanos());
-            if (indexingBuffers.containsKey(shardId) == false) {
-                // First time we are indexing into this shard; start it off with default indexing buffer:
-                indexingBuffers.put(shardId, EngineConfig.DEFAULT_INDEX_BUFFER_SIZE);
-                translogBuffers.put(shardId, TranslogConfig.DEFAULT_SHARD_TRANSLOG_BUFFER_SIZE);
-            }
-            activeShards.add(shardId);
+        public void simulateFlush(ShardId shard) {
+            setTranslog(shard, translogIds.get(shard) + 1, 0);
         }
     }
 
@@ -133,13 +139,13 @@ public class IndexingMemoryControllerTests extends ESTestCase {
                 .put(IndexingMemoryController.INDEX_BUFFER_SIZE_SETTING, "10mb")
                 .put(IndexingMemoryController.TRANSLOG_BUFFER_SIZE_SETTING, "100kb").build());
         final ShardId shard1 = new ShardId("test", 1);
-        controller.simulateIndexing(shard1);
+        controller.setTranslog(shard1, randomInt(10), randomInt(10));
         controller.forceCheck();
         controller.assertBuffers(shard1, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB)); // translog is maxed at 64K
 
         // add another shard
         final ShardId shard2 = new ShardId("test", 2);
-        controller.simulateIndexing(shard2);
+        controller.setTranslog(shard2, randomInt(10), randomInt(10));
         controller.forceCheck();
         controller.assertBuffers(shard1, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));
         controller.assertBuffers(shard2, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));
@@ -155,7 +161,7 @@ public class IndexingMemoryControllerTests extends ESTestCase {
 
         // add a new one
         final ShardId shard3 = new ShardId("test", 3);
-        controller.simulateIndexing(shard3);
+        controller.setTranslog(shard3, randomInt(10), randomInt(10));
         controller.forceCheck();
         controller.assertBuffers(shard3, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB)); // translog is maxed at 64K
     }
@@ -168,45 +174,48 @@ public class IndexingMemoryControllerTests extends ESTestCase {
                 .build());
 
         final ShardId shard1 = new ShardId("test", 1);
-        controller.simulateIndexing(shard1);
+        controller.setTranslog(shard1, 0, 0);
         final ShardId shard2 = new ShardId("test", 2);
-        controller.simulateIndexing(shard2);
+        controller.setTranslog(shard2, 0, 0);
         controller.forceCheck();
         controller.assertBuffers(shard1, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));
         controller.assertBuffers(shard2, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));
 
         // index into both shards, move the clock and see that they are still active
-        controller.simulateIndexing(shard1);
-        controller.simulateIndexing(shard2);
-
+        controller.setTranslog(shard1, randomInt(2), randomInt(2) + 1);
+        controller.setTranslog(shard2, randomInt(2) + 1, randomInt(2));
+        // the controller doesn't know when the ops happened, so even if this is more
+        // than the inactive time the shard is still marked as active
         controller.incrementTimeSec(10);
         controller.forceCheck();
+        controller.assertBuffers(shard1, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));
+        controller.assertBuffers(shard2, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));
 
-        // both shards now inactive
-        controller.assertInActive(shard1);
-        controller.assertInActive(shard2);
-
-        // index into one shard only, see it becomes active
-        controller.simulateIndexing(shard1);
+        // index into one shard only, see other shard is made inactive correctly
+        controller.incTranslog(shard1, randomInt(2), randomInt(2) + 1);
         controller.forceCheck(); // register what happened with the controller (shard is still active)
-        controller.assertBuffers(shard1, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB));
-        controller.assertInActive(shard2);
-
-        controller.incrementTimeSec(3); // increment but not enough to become inactive
+        controller.incrementTimeSec(3); // increment but not enough
         controller.forceCheck();
-        controller.assertBuffers(shard1, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB));
-        controller.assertInActive(shard2);
+        controller.assertBuffers(shard1, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));
+        controller.assertBuffers(shard2, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));
 
         controller.incrementTimeSec(3); // increment some more
         controller.forceCheck();
-        controller.assertInActive(shard1);
+        controller.assertBuffers(shard1, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB));
         controller.assertInActive(shard2);
 
+        if (randomBoolean()) {
+            // once a shard gets inactive it will be synced flushed and a new translog generation will be made
+            controller.simulateFlush(shard2);
+            controller.forceCheck();
+            controller.assertInActive(shard2);
+        }
+
         // index some and shard becomes immediately active
-        controller.simulateIndexing(shard2);
+        controller.incTranslog(shard2, randomInt(2), 1 + randomInt(2)); // we must make sure translog ops is never 0
         controller.forceCheck();
-        controller.assertInActive(shard1);
-        controller.assertBuffers(shard2, new ByteSizeValue(10, ByteSizeUnit.MB), new ByteSizeValue(64, ByteSizeUnit.KB));
+        controller.assertBuffers(shard1, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));
+        controller.assertBuffers(shard2, new ByteSizeValue(5, ByteSizeUnit.MB), new ByteSizeValue(50, ByteSizeUnit.KB));
     }
 
     public void testMinShardBufferSizes() {
@@ -264,9 +273,9 @@ public class IndexingMemoryControllerTests extends ESTestCase {
 
     protected void assertTwoActiveShards(MockController controller, ByteSizeValue indexBufferSize, ByteSizeValue translogBufferSize) {
         final ShardId shard1 = new ShardId("test", 1);
-        controller.simulateIndexing(shard1);
+        controller.setTranslog(shard1, 0, 0);
         final ShardId shard2 = new ShardId("test", 2);
-        controller.simulateIndexing(shard2);
+        controller.setTranslog(shard2, 0, 0);
         controller.forceCheck();
         controller.assertBuffers(shard1, indexBufferSize, translogBufferSize);
         controller.assertBuffers(shard2, indexBufferSize, translogBufferSize);
diff --git a/core/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryIT.java b/core/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryIT.java
index 6609ce8..2eedcef 100644
--- a/core/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/recovery/IndexRecoveryIT.java
@@ -270,10 +270,10 @@ public class IndexRecoveryIT extends ESIntegTestCase {
             @Override
             public void run() {
                 IndicesService indicesService = internalCluster().getInstance(IndicesService.class, nodeA);
-                assertThat(indicesService.indexServiceSafe(INDEX_NAME).shardSafe(0).recoveryStats().currentAsSource(),
+                assertThat(indicesService.indexServiceSafe(INDEX_NAME).getShard(0).recoveryStats().currentAsSource(),
                         equalTo(1));
                 indicesService = internalCluster().getInstance(IndicesService.class, nodeB);
-                assertThat(indicesService.indexServiceSafe(INDEX_NAME).shardSafe(0).recoveryStats().currentAsTarget(),
+                assertThat(indicesService.indexServiceSafe(INDEX_NAME).getShard(0).recoveryStats().currentAsTarget(),
                         equalTo(1));
             }
         });
diff --git a/core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStatusTests.java b/core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStatusTests.java
index ed73a44..edb0f7b 100644
--- a/core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStatusTests.java
+++ b/core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStatusTests.java
@@ -39,7 +39,7 @@ public class RecoveryStatusTests extends ESSingleNodeTestCase {
     public void testRenameTempFiles() throws IOException {
         IndexService service = createIndex("foo");
 
-        IndexShard indexShard = service.shard(0);
+        IndexShard indexShard = service.getShardOrNull(0);
         DiscoveryNode node = new DiscoveryNode("foo", new LocalTransportAddress("bar"), Version.CURRENT);
         RecoveryStatus status = new RecoveryStatus(indexShard, node, new RecoveryTarget.RecoveryListener() {
             @Override
diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java b/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java
index c76bef5..1ffce8d 100644
--- a/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java
+++ b/core/src/test/java/org/elasticsearch/plugins/PluginManagerIT.java
@@ -18,9 +18,6 @@
  */
 package org.elasticsearch.plugins;
 
-import java.nio.charset.StandardCharsets;
-import com.google.common.hash.Hashing;
-
 import org.apache.http.impl.client.HttpClients;
 import org.apache.lucene.util.LuceneTestCase;
 import org.elasticsearch.Version;
@@ -28,6 +25,7 @@ import org.elasticsearch.common.Base64;
 import org.elasticsearch.common.cli.CliTool;
 import org.elasticsearch.common.cli.CliTool.ExitStatus;
 import org.elasticsearch.common.cli.CliToolTestCase.CaptureOutputTerminal;
+import org.elasticsearch.common.hash.MessageDigests;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.env.Environment;
 import org.elasticsearch.node.internal.InternalSettingsPreparer;
@@ -46,16 +44,15 @@ import org.jboss.netty.handler.ssl.util.InsecureTrustManagerFactory;
 import org.jboss.netty.handler.ssl.util.SelfSignedCertificate;
 import org.junit.After;
 import org.junit.Before;
-import org.junit.Test;
 
 import javax.net.ssl.HttpsURLConnection;
 import javax.net.ssl.SSLContext;
 import javax.net.ssl.SSLSocketFactory;
-
 import java.io.BufferedWriter;
 import java.io.IOException;
 import java.net.InetAddress;
 import java.net.InetSocketAddress;
+import java.nio.charset.StandardCharsets;
 import java.nio.file.FileVisitResult;
 import java.nio.file.Files;
 import java.nio.file.Path;
@@ -109,7 +106,7 @@ public class PluginManagerIT extends ESIntegTestCase {
     }
 
     private void writeSha1(Path file, boolean corrupt) throws IOException {
-        String sha1Hex = Hashing.sha1().hashBytes(Files.readAllBytes(file)).toString();
+        String sha1Hex = MessageDigests.toHexString(MessageDigests.sha1().digest(Files.readAllBytes(file)));
         try (BufferedWriter out = Files.newBufferedWriter(file.resolveSibling(file.getFileName() + ".sha1"), StandardCharsets.UTF_8)) {
             out.write(sha1Hex);
             if (corrupt) {
@@ -119,7 +116,7 @@ public class PluginManagerIT extends ESIntegTestCase {
     }
 
     private void writeMd5(Path file, boolean corrupt) throws IOException {
-        String md5Hex = Hashing.md5().hashBytes(Files.readAllBytes(file)).toString();
+        String md5Hex = MessageDigests.toHexString(MessageDigests.md5().digest(Files.readAllBytes(file)));
         try (BufferedWriter out = Files.newBufferedWriter(file.resolveSibling(file.getFileName() + ".md5"), StandardCharsets.UTF_8)) {
             out.write(md5Hex);
             if (corrupt) {
diff --git a/core/src/test/java/org/elasticsearch/recovery/RecoveriesCollectionTests.java b/core/src/test/java/org/elasticsearch/recovery/RecoveriesCollectionTests.java
index b1d97b8..5a5f316 100644
--- a/core/src/test/java/org/elasticsearch/recovery/RecoveriesCollectionTests.java
+++ b/core/src/test/java/org/elasticsearch/recovery/RecoveriesCollectionTests.java
@@ -171,7 +171,7 @@ public class RecoveriesCollectionTests extends ESSingleNodeTestCase {
 
     long startRecovery(RecoveriesCollection collection, RecoveryTarget.RecoveryListener listener, TimeValue timeValue) {
         IndicesService indexServices = getInstanceFromNode(IndicesService.class);
-        IndexShard indexShard = indexServices.indexServiceSafe("test").shard(0);
+        IndexShard indexShard = indexServices.indexServiceSafe("test").getShardOrNull(0);
         final DiscoveryNode sourceNode = new DiscoveryNode("id", DummyTransportAddress.INSTANCE, Version.CURRENT);
         return collection.startRecovery(indexShard, sourceNode, listener, timeValue);
     }
diff --git a/core/src/test/java/org/elasticsearch/routing/AliasRoutingIT.java b/core/src/test/java/org/elasticsearch/routing/AliasRoutingIT.java
new file mode 100644
index 0000000..c418f68
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/routing/AliasRoutingIT.java
@@ -0,0 +1,354 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.routing;
+
+import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.action.search.SearchType;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.index.query.QueryBuilders;
+import org.elasticsearch.test.ESIntegTestCase;
+import org.junit.Test;
+
+import static org.elasticsearch.cluster.metadata.AliasAction.newAddAliasAction;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.hamcrest.Matchers.equalTo;
+
+/**
+ *
+ */
+public class AliasRoutingIT extends ESIntegTestCase {
+
+    @Override
+    protected int minimumNumberOfShards() {
+        return 2;
+    }
+
+    @Test
+    public void testAliasCrudRouting() throws Exception {
+        createIndex("test");
+        ensureGreen();
+        assertAcked(admin().indices().prepareAliases().addAliasAction(newAddAliasAction("test", "alias0").routing("0")));
+
+        logger.info("--> indexing with id [1], and routing [0] using alias");
+        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+        logger.info("--> verifying get with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
+        }
+
+        logger.info("--> verifying get with routing alias, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+
+        logger.info("--> updating with id [1] and routing through alias");
+        client().prepareUpdate("alias0", "type1", "1")
+                .setUpsert(XContentFactory.jsonBuilder().startObject().field("field", 1).endObject())
+                .setDoc("field", "value2")
+                .execute().actionGet();
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().getSourceAsMap().get("field").toString(), equalTo("value2"));
+        }
+
+
+        logger.info("--> deleting with no routing, should not delete anything");
+        client().prepareDelete("test", "type1", "1").setRefresh(true).execute().actionGet();
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+
+        logger.info("--> deleting with routing alias, should delete");
+        client().prepareDelete("alias0", "type1", "1").setRefresh(true).execute().actionGet();
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(false));
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+
+        logger.info("--> indexing with id [1], and routing [0] using alias");
+        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+        logger.info("--> verifying get with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+    }
+
+    @Test
+    public void testAliasSearchRouting() throws Exception {
+        createIndex("test");
+        ensureGreen();
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("test", "alias"))
+                .addAliasAction(newAddAliasAction("test", "alias0").routing("0"))
+                .addAliasAction(newAddAliasAction("test", "alias1").routing("1"))
+                .addAliasAction(newAddAliasAction("test", "alias01").searchRouting("0,1")));
+
+        logger.info("--> indexing with id [1], and routing [0] using alias");
+        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+        logger.info("--> verifying get with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+
+        logger.info("--> search with no routing, should fine one");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+        }
+
+        logger.info("--> search with wrong routing, should not find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
+            assertThat(client().prepareCount().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
+            assertThat(client().prepareSearch("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
+            assertThat(client().prepareCount("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
+        }
+
+        logger.info("--> search with correct routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+            assertThat(client().prepareSearch("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+        }
+
+        logger.info("--> indexing with id [2], and routing [1] using alias");
+        client().prepareIndex("alias1", "type1", "2").setSource("field", "value1").setRefresh(true).execute().actionGet();
+
+        logger.info("--> search with no routing, should fine two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+        logger.info("--> search with 0 routing, should find one");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+            assertThat(client().prepareSearch("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+        }
+
+        logger.info("--> search with 1 routing, should find one");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+            assertThat(client().prepareSearch("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+        }
+
+        logger.info("--> search with 0,1 routings , should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setRouting("0", "1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount().setRouting("0", "1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+            assertThat(client().prepareSearch("alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+        logger.info("--> search with two routing aliases , should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+        logger.info("--> search with alias0, alias1 and alias01, should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias0", "alias1", "alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias0", "alias1", "alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+        logger.info("--> search with test, alias0 and alias1, should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("test", "alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("test", "alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+    }
+
+    @Test
+    public void testAliasSearchRoutingWithTwoIndices() throws Exception {
+        createIndex("test-a");
+        createIndex("test-b");
+        ensureGreen();
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("test-a", "alias-a0").routing("0"))
+                .addAliasAction(newAddAliasAction("test-a", "alias-a1").routing("1"))
+                .addAliasAction(newAddAliasAction("test-b", "alias-b0").routing("0"))
+                .addAliasAction(newAddAliasAction("test-b", "alias-b1").routing("1"))
+                .addAliasAction(newAddAliasAction("test-a", "alias-ab").searchRouting("0"))
+                .addAliasAction(newAddAliasAction("test-b", "alias-ab").searchRouting("1")));
+        ensureGreen(); // wait for events again to make sure we got the aliases on all nodes
+        logger.info("--> indexing with id [1], and routing [0] using alias to test-a");
+        client().prepareIndex("alias-a0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test-a", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+        logger.info("--> verifying get with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("alias-a0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+
+        logger.info("--> indexing with id [0], and routing [1] using alias to test-b");
+        client().prepareIndex("alias-b1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test-a", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+        logger.info("--> verifying get with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("alias-b1", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+
+
+        logger.info("--> search with alias-a1,alias-b0, should not find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias-a1", "alias-b0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
+            assertThat(client().prepareCount("alias-a1", "alias-b0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
+        }
+
+        logger.info("--> search with alias-ab, should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias-ab").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias-ab").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+        logger.info("--> search with alias-a0,alias-b1 should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias-a0", "alias-b1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias-a0", "alias-b1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+    }
+
+    /*
+    See https://github.com/elasticsearch/elasticsearch/issues/2682
+    Searching on more than one index, if one of those is an alias with configured routing, the shards that belonged
+    to the other indices (without routing) were not taken into account in PlainOperationRouting#searchShards.
+    That affected the number of shards that we executed the search on, thus some documents were missing in the search results.
+     */
+    @Test
+    public void testAliasSearchRoutingWithConcreteAndAliasedIndices_issue2682() throws Exception {
+        createIndex("index", "index_2");
+        ensureGreen();
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("index", "index_1").routing("1")));
+
+        logger.info("--> indexing on index_1 which is an alias for index with routing [1]");
+        client().prepareIndex("index_1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> indexing on index_2 which is a concrete index");
+        client().prepareIndex("index_2", "type2", "2").setSource("field", "value2").setRefresh(true).execute().actionGet();
+
+
+        logger.info("--> search all on index_* should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("index_*").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+        }
+    }
+
+    /*
+    See https://github.com/elasticsearch/elasticsearch/pull/3268
+    Searching on more than one index, if one of those is an alias with configured routing, the shards that belonged
+    to the other indices (without routing) were not taken into account in PlainOperationRouting#searchShardsCount.
+    That could cause returning 1, which led to forcing the QUERY_AND_FETCH mode.
+    As a result, (size * number of hit shards) results were returned and no reduce phase was taking place.
+     */
+    @Test
+    public void testAliasSearchRoutingWithConcreteAndAliasedIndices_issue3268() throws Exception {
+        createIndex("index", "index_2");
+        ensureGreen();
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("index", "index_1").routing("1")));
+
+        logger.info("--> indexing on index_1 which is an alias for index with routing [1]");
+        client().prepareIndex("index_1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> indexing on index_2 which is a concrete index");
+        client().prepareIndex("index_2", "type2", "2").setSource("field", "value2").setRefresh(true).execute().actionGet();
+
+        SearchResponse searchResponse = client().prepareSearch("index_*").setSearchType(SearchType.QUERY_THEN_FETCH).setSize(1).setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();
+
+        logger.info("--> search all on index_* should find two");
+        assertThat(searchResponse.getHits().totalHits(), equalTo(2L));
+        //Let's make sure that, even though 2 docs are available, only one is returned according to the size we set in the request
+        //Therefore the reduce phase has taken place, which proves that the QUERY_AND_FETCH search type wasn't erroneously forced.
+        assertThat(searchResponse.getHits().getHits().length, equalTo(1));
+    }
+
+    @Test
+    public void testIndexingAliasesOverTime() throws Exception {
+        createIndex("test");
+        ensureGreen();
+        logger.info("--> creating alias with routing [3]");
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("test", "alias").routing("3")));
+
+        logger.info("--> indexing with id [0], and routing [3]");
+        client().prepareIndex("alias", "type1", "0").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+
+        logger.info("--> verifying get and search with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "0").setRouting("3").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+        }
+
+        logger.info("--> creating alias with routing [4]");
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("test", "alias").routing("4")));
+
+        logger.info("--> verifying search with wrong routing should not find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
+            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
+        }
+
+        logger.info("--> creating alias with search routing [3,4] and index routing 4");
+        assertAcked(client().admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("test", "alias").searchRouting("3,4").indexRouting("4")));
+
+        logger.info("--> indexing with id [1], and routing [4]");
+        client().prepareIndex("alias", "type1", "1").setSource("field", "value2").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+
+        logger.info("--> verifying get and search with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "0").setRouting("3").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareGet("test", "type1", "1").setRouting("4").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+    }
+
+}
diff --git a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java b/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
index 335b584..09f33f6 100644
--- a/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/child/ChildQuerySearchIT.java
@@ -181,7 +181,7 @@ public class ChildQuerySearchIT extends ESIntegTestCase {
         refresh();
 
         // TEST FETCHING _parent from child
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(idsQuery("child").ids("c1")).addFields("_parent").execute()
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(idsQuery("child").addIds("c1")).addFields("_parent").execute()
                 .actionGet();
         assertNoFailures(searchResponse);
         assertThat(searchResponse.getHits().totalHits(), equalTo(1l));
diff --git a/core/src/test/java/org/elasticsearch/search/compress/SearchSourceCompressTests.java b/core/src/test/java/org/elasticsearch/search/compress/SearchSourceCompressTests.java
index b6d3353..d3b5160 100644
--- a/core/src/test/java/org/elasticsearch/search/compress/SearchSourceCompressTests.java
+++ b/core/src/test/java/org/elasticsearch/search/compress/SearchSourceCompressTests.java
@@ -84,7 +84,7 @@ public class SearchSourceCompressTests  extends ESSingleNodeTestCase {
         assertThat(getResponse.getSourceAsBytes(), equalTo(buildSource(10000).bytes().toBytes()));
 
         for (int i = 1; i < 100; i++) {
-            SearchResponse searchResponse = client().prepareSearch().setQuery(QueryBuilders.idsQuery("type1").ids(Integer.toString(i))).execute().actionGet();
+            SearchResponse searchResponse = client().prepareSearch().setQuery(QueryBuilders.idsQuery("type1").addIds(Integer.toString(i))).execute().actionGet();
             assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));
             assertThat(searchResponse.getHits().getAt(0).source(), equalTo(buildSource(i).bytes().toBytes()));
         }
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/QueryRescorerIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/QueryRescorerIT.java
new file mode 100644
index 0000000..e906ac6
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/QueryRescorerIT.java
@@ -0,0 +1,753 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.search.functionscore;
+
+
+
+import org.apache.lucene.search.Explanation;
+import org.apache.lucene.util.English;
+import org.elasticsearch.action.index.IndexRequestBuilder;
+import org.elasticsearch.action.search.SearchRequestBuilder;
+import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.action.search.SearchType;
+import org.elasticsearch.common.lucene.search.function.CombineFunction;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.settings.Settings.Builder;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.index.query.Operator;
+import org.elasticsearch.index.query.QueryBuilders;
+import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
+import org.elasticsearch.search.SearchHit;
+import org.elasticsearch.search.SearchHits;
+import org.elasticsearch.search.rescore.RescoreBuilder;
+import org.elasticsearch.search.rescore.RescoreBuilder.QueryRescorer;
+import org.elasticsearch.test.ESIntegTestCase;
+import org.junit.Test;
+
+import java.util.Arrays;
+import java.util.Comparator;
+
+import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
+import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
+
+/**
+ *
+ */
+public class QueryRescorerIT extends ESIntegTestCase {
+
+    @Test
+    public void testEnforceWindowSize() {
+        createIndex("test");
+        // this
+        int iters = scaledRandomIntBetween(10, 20);
+        for (int i = 0; i < iters; i ++) {
+            client().prepareIndex("test", "type", Integer.toString(i)).setSource("f", Integer.toString(i)).execute().actionGet();
+        }
+        ensureYellow();
+        refresh();
+
+        int numShards = getNumShards("test").numPrimaries;
+        for (int j = 0 ; j < iters; j++) {
+            SearchResponse searchResponse = client().prepareSearch()
+                    .setQuery(QueryBuilders.matchAllQuery())
+                    .setRescorer(RescoreBuilder.queryRescorer(
+                            QueryBuilders.functionScoreQuery(QueryBuilders.matchAllQuery(),
+                                    ScoreFunctionBuilders.weightFactorFunction(100)).boostMode(CombineFunction.REPLACE)).setQueryWeight(0.0f).setRescoreQueryWeight(1.0f))
+                    .setRescoreWindow(1).setSize(randomIntBetween(2, 10)).execute().actionGet();
+            assertSearchResponse(searchResponse);
+            assertFirstHit(searchResponse, hasScore(100.f));
+            int numDocsWith100AsAScore = 0;
+            for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
+                float score = searchResponse.getHits().hits()[i].getScore();
+                if  (score == 100f) {
+                    numDocsWith100AsAScore += 1;
+                }
+            }
+            // we cannot assert that they are equal since some shards might not have docs at all
+            assertThat(numDocsWith100AsAScore, lessThanOrEqualTo(numShards));
+        }
+    }
+
+    @Test
+    public void testRescorePhrase() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping(
+                        "type1",
+                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
+                                .field("analyzer", "whitespace").field("type", "string").endObject().endObject().endObject().endObject())
+                .setSettings(Settings.settingsBuilder().put(indexSettings()).put("index.number_of_shards", 1)));
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox").execute().actionGet();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree ").get();
+        client().prepareIndex("test", "type1", "3")
+                .setSource("field1", "quick huge brown", "field2", "the quick lazy huge brown fox jumps over the tree").get();
+        ensureYellow();
+        refresh();
+        SearchResponse searchResponse = client().prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "quick brown").slop(2).boost(4.0f)).setRescoreQueryWeight(2))
+                .setRescoreWindow(5).execute().actionGet();
+
+        assertThat(searchResponse.getHits().totalHits(), equalTo(3l));
+        assertThat(searchResponse.getHits().getHits()[0].getId(), equalTo("1"));
+        assertThat(searchResponse.getHits().getHits()[1].getId(), equalTo("3"));
+        assertThat(searchResponse.getHits().getHits()[2].getId(), equalTo("2"));
+
+        searchResponse = client().prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(3)))
+                .setRescoreWindow(5).execute().actionGet();
+
+        assertHitCount(searchResponse, 3);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client().prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setRescorer(RescoreBuilder.queryRescorer((QueryBuilders.matchPhraseQuery("field1", "the quick brown"))))
+                .setRescoreWindow(5).execute().actionGet();
+
+        assertHitCount(searchResponse, 3);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+    }
+
+    @Test
+    public void testMoreDocs() throws Exception {
+        Builder builder = Settings.builder();
+        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
+        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
+        builder.put("index.analysis.filter.synonym.type", "synonym");
+        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
+
+        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
+                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
+                .endObject().endObject().endObject().endObject();
+
+        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "massachusetts avenue boston massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "3").setSource("field1", "boston avenue lexington massachusetts").execute().actionGet();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        client().prepareIndex("test", "type1", "4").setSource("field1", "boston road lexington massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "5").setSource("field1", "lexington street lexington massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "7").setSource("field1", "bosten street san franciso california").execute().actionGet();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        client().prepareIndex("test", "type1", "8").setSource("field1", "hollywood boulevard los angeles california").execute().actionGet();
+        client().prepareIndex("test", "type1", "9").setSource("field1", "1st street boston massachussetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "10").setSource("field1", "1st street boston massachusetts").execute().actionGet();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        client().prepareIndex("test", "type1", "11").setSource("field1", "2st street boston massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "12").setSource("field1", "3st street boston massachusetts").execute().actionGet();
+        ensureYellow();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        SearchResponse searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setFrom(0)
+                .setSize(5)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
+
+        assertThat(searchResponse.getHits().hits().length, equalTo(5));
+        assertHitCount(searchResponse, 9);
+        assertFirstHit(searchResponse, hasId("2"));
+        assertSecondHit(searchResponse, hasId("6"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setFrom(0)
+                .setSize(5)
+                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
+
+        assertThat(searchResponse.getHits().hits().length, equalTo(5));
+        assertHitCount(searchResponse, 9);
+        assertFirstHit(searchResponse, hasId("2"));
+        assertSecondHit(searchResponse, hasId("6"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        // Make sure non-zero from works:
+        searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setFrom(2)
+                .setSize(5)
+                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
+
+        assertThat(searchResponse.getHits().hits().length, equalTo(5));
+        assertHitCount(searchResponse, 9);
+        assertFirstHit(searchResponse, hasId("3"));
+    }
+
+    // Tests a rescore window smaller than number of hits:
+    @Test
+    public void testSmallRescoreWindow() throws Exception {
+        Builder builder = Settings.builder();
+        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
+        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
+        builder.put("index.analysis.filter.synonym.type", "synonym");
+        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
+
+        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
+                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
+                .endObject().endObject().endObject().endObject();
+
+        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
+
+        client().prepareIndex("test", "type1", "3").setSource("field1", "massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        client().prepareIndex("test", "type1", "1").setSource("field1", "lexington massachusetts avenue").execute().actionGet();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts road").execute().actionGet();
+        ensureYellow();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+
+        SearchResponse searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
+                .setFrom(0)
+            .setSize(5).execute().actionGet();
+        assertThat(searchResponse.getHits().hits().length, equalTo(4));
+        assertHitCount(searchResponse, 4);
+        assertFirstHit(searchResponse, hasId("3"));
+        assertSecondHit(searchResponse, hasId("6"));
+        assertThirdHit(searchResponse, hasId("1"));
+        assertFourthHit(searchResponse, hasId("2"));
+
+        // Now, rescore only top 2 hits w/ proximity:
+        searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
+                .setFrom(0)
+                .setSize(5)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(2).execute().actionGet();
+        // Only top 2 hits were re-ordered:
+        assertThat(searchResponse.getHits().hits().length, equalTo(4));
+        assertHitCount(searchResponse, 4);
+        assertFirstHit(searchResponse, hasId("6"));
+        assertSecondHit(searchResponse, hasId("3"));
+        assertThirdHit(searchResponse, hasId("1"));
+        assertFourthHit(searchResponse, hasId("2"));
+
+        // Now, rescore only top 3 hits w/ proximity:
+        searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
+                .setFrom(0)
+                .setSize(5)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(3).execute().actionGet();
+
+        // Only top 3 hits were re-ordered:
+        assertThat(searchResponse.getHits().hits().length, equalTo(4));
+        assertHitCount(searchResponse, 4);
+        assertFirstHit(searchResponse, hasId("6"));
+        assertSecondHit(searchResponse, hasId("1"));
+        assertThirdHit(searchResponse, hasId("3"));
+        assertFourthHit(searchResponse, hasId("2"));
+    }
+
+    // Tests a rescorer that penalizes the scores:
+    @Test
+    public void testRescorerMadeScoresWorse() throws Exception {
+        Builder builder = Settings.builder();
+        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
+        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
+        builder.put("index.analysis.filter.synonym.type", "synonym");
+        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
+
+        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
+                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
+                .endObject().endObject().endObject().endObject();
+
+        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
+
+        client().prepareIndex("test", "type1", "3").setSource("field1", "massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        client().prepareIndex("test", "type1", "1").setSource("field1", "lexington massachusetts avenue").execute().actionGet();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts road").execute().actionGet();
+        ensureYellow();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+
+        SearchResponse searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
+                .setFrom(0)
+            .setSize(5).execute().actionGet();
+        assertThat(searchResponse.getHits().hits().length, equalTo(4));
+        assertHitCount(searchResponse, 4);
+        assertFirstHit(searchResponse, hasId("3"));
+        assertSecondHit(searchResponse, hasId("6"));
+        assertThirdHit(searchResponse, hasId("1"));
+        assertFourthHit(searchResponse, hasId("2"));
+
+        // Now, penalizing rescore (nothing matches the rescore query):
+        searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
+                .setFrom(0)
+                .setSize(5)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(1.0f).setRescoreQueryWeight(-1f)).setRescoreWindow(3).execute().actionGet();
+
+        // 6 and 1 got worse, and then the hit (2) outside the rescore window were sorted ahead:
+        assertFirstHit(searchResponse, hasId("3"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("6"));
+        assertFourthHit(searchResponse, hasId("1"));
+    }
+
+    // Comparator that sorts hits and rescored hits in the same way.
+    // The rescore uses the docId as tie, while regular search uses the slot the hit is in as a tie if score
+    // and shard id are equal during merging shard results.
+    // This comparator uses a custom tie in case the scores are equal, so that both regular hits and rescored hits
+    // are sorted equally. This is fine since tests only care about the fact the scores should be equal, not ordering.
+    private final static Comparator<SearchHit> searchHitsComparator = new Comparator<SearchHit>() {
+        @Override
+        public int compare(SearchHit hit1, SearchHit hit2) {
+            int cmp = Float.compare(hit2.getScore(), hit1.getScore());
+            if (cmp == 0) {
+                return hit1.id().compareTo(hit2.id());
+            } else {
+                return cmp;
+            }
+        }
+    };
+
+    private static void assertEquivalent(String query, SearchResponse plain, SearchResponse rescored) {
+        assertNoFailures(plain);
+        assertNoFailures(rescored);
+        SearchHits leftHits = plain.getHits();
+        SearchHits rightHits = rescored.getHits();
+        assertThat(leftHits.getTotalHits(), equalTo(rightHits.getTotalHits()));
+        assertThat(leftHits.getHits().length, equalTo(rightHits.getHits().length));
+        SearchHit[] hits = leftHits.getHits();
+        SearchHit[] rHits = rightHits.getHits();
+        Arrays.sort(hits, searchHitsComparator);
+        Arrays.sort(rHits, searchHitsComparator);
+        for (int i = 0; i < hits.length; i++) {
+            assertThat("query: " + query, hits[i].getScore(), equalTo(rHits[i].getScore()));
+        }
+        for (int i = 0; i < hits.length; i++) {
+            if (hits[i].getScore() == hits[hits.length-1].getScore()) {
+                return; // we need to cut off here since this is the tail of the queue and we might not have fetched enough docs
+            }
+            assertThat("query: " + query,hits[i].getId(), equalTo(rHits[i].getId()));
+        }
+    }
+
+    private static void assertEquivalentOrSubstringMatch(String query, SearchResponse plain, SearchResponse rescored) {
+        assertNoFailures(plain);
+        assertNoFailures(rescored);
+        SearchHits leftHits = plain.getHits();
+        SearchHits rightHits = rescored.getHits();
+        assertThat(leftHits.getTotalHits(), equalTo(rightHits.getTotalHits()));
+        assertThat(leftHits.getHits().length, equalTo(rightHits.getHits().length));
+        SearchHit[] hits = leftHits.getHits();
+        SearchHit[] otherHits = rightHits.getHits();
+        if (!hits[0].getId().equals(otherHits[0].getId())) {
+            assertThat(((String) otherHits[0].sourceAsMap().get("field1")).contains(query), equalTo(true));
+        } else {
+            Arrays.sort(hits, searchHitsComparator);
+            Arrays.sort(otherHits, searchHitsComparator);
+            for (int i = 0; i < hits.length; i++) {
+                if (hits[i].getScore() == hits[hits.length-1].getScore()) {
+                    return; // we need to cut off here since this is the tail of the queue and we might not have fetched enough docs
+                }
+                assertThat(query, hits[i].getId(), equalTo(rightHits.getHits()[i].getId()));
+            }
+        }
+    }
+
+    @Test
+    // forces QUERY_THEN_FETCH because of https://github.com/elasticsearch/elasticsearch/issues/4829
+    public void testEquivalence() throws Exception {
+        // no dummy docs since merges can change scores while we run queries.
+        int numDocs = indexRandomNumbers("whitespace", -1, false);
+
+        final int iters = scaledRandomIntBetween(50, 100);
+        for (int i = 0; i < iters; i++) {
+            int resultSize = numDocs;
+            int rescoreWindow = between(1, 3) * resultSize;
+            String intToEnglish = English.intToEnglish(between(0, numDocs-1));
+            String query = intToEnglish.split(" ")[0];
+            SearchResponse rescored = client()
+                    .prepareSearch()
+                    .setSearchType(SearchType.QUERY_THEN_FETCH)
+                    .setPreference("test") // ensure we hit the same shards for tie-breaking
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setFrom(0)
+                    .setSize(resultSize)
+                    .setRescorer(
+                            RescoreBuilder
+                                    .queryRescorer(
+                                            QueryBuilders
+                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery("field1", intToEnglish).slop(3)))
+                                    .setQueryWeight(1.0f)
+                                    .setRescoreQueryWeight(0.0f)) // no weight - so we basically use the same score as the actual query
+                    .setRescoreWindow(rescoreWindow).execute().actionGet();
+
+            SearchResponse plain = client().prepareSearch()
+                    .setSearchType(SearchType.QUERY_THEN_FETCH)
+                    .setPreference("test") // ensure we hit the same shards for tie-breaking
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR)).setFrom(0).setSize(resultSize)
+                    .execute().actionGet();
+            
+            // check equivalence
+            assertEquivalent(query, plain, rescored);
+
+            rescored = client()
+                    .prepareSearch()
+                    .setSearchType(SearchType.QUERY_THEN_FETCH)
+                    .setPreference("test") // ensure we hit the same shards for tie-breaking
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setFrom(0)
+                    .setSize(resultSize)
+                    .setRescorer(
+                            RescoreBuilder
+                                    .queryRescorer(
+                                            QueryBuilders
+                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery("field1", "not in the index").slop(3)))
+                                    .setQueryWeight(1.0f)
+                                    .setRescoreQueryWeight(1.0f))
+                    .setRescoreWindow(rescoreWindow).execute().actionGet();
+            // check equivalence
+            assertEquivalent(query, plain, rescored);
+
+            rescored = client()
+                    .prepareSearch()
+                    .setSearchType(SearchType.QUERY_THEN_FETCH)
+                    .setPreference("test") // ensure we hit the same shards for tie-breaking
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setFrom(0)
+                    .setSize(resultSize)
+                    .setRescorer(
+                            RescoreBuilder
+                                    .queryRescorer(
+                                            QueryBuilders.matchPhraseQuery("field1", intToEnglish).slop(0))
+                                    .setQueryWeight(1.0f).setRescoreQueryWeight(1.0f)).setRescoreWindow(2 * rescoreWindow).execute().actionGet();
+            // check equivalence or if the first match differs we check if the phrase is a substring of the top doc
+            assertEquivalentOrSubstringMatch(intToEnglish, plain, rescored);
+        }
+    }
+
+    @Test
+    public void testExplain() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping(
+                        "type1",
+                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
+                                .field("analyzer", "whitespace").field("type", "string").endObject().endObject().endObject().endObject())
+        );
+        ensureGreen();
+        client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox").execute().actionGet();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree").execute()
+                .actionGet();
+        client().prepareIndex("test", "type1", "3")
+                .setSource("field1", "quick huge brown", "field2", "the quick lazy huge brown fox jumps over the tree").execute()
+                .actionGet();
+        ensureYellow();
+        refresh();
+
+        {
+            SearchResponse searchResponse = client()
+                    .prepareSearch()
+                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                    .setRescorer(
+                            RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(2).boost(4.0f))
+                                    .setQueryWeight(0.5f).setRescoreQueryWeight(0.4f)).setRescoreWindow(5).setExplain(true).execute()
+                    .actionGet();
+            assertHitCount(searchResponse, 3);
+            assertFirstHit(searchResponse, hasId("1"));
+            assertSecondHit(searchResponse, hasId("2"));
+            assertThirdHit(searchResponse, hasId("3"));
+
+            for (int i = 0; i < 3; i++) {
+                assertThat(searchResponse.getHits().getAt(i).explanation(), notNullValue());
+                assertThat(searchResponse.getHits().getAt(i).explanation().isMatch(), equalTo(true));
+                assertThat(searchResponse.getHits().getAt(i).explanation().getDetails().length, equalTo(2));
+                assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[0].isMatch(), equalTo(true));
+                if (i == 2) {
+                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[1].getValue(), equalTo(0.5f));
+                } else {
+                    assertThat(searchResponse.getHits().getAt(i).explanation().getDescription(), equalTo("sum of:"));
+                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[0].getDetails()[1].getValue(), equalTo(0.5f));
+                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[1].getDetails()[1].getValue(), equalTo(0.4f));
+                }
+            }
+        }
+
+        String[] scoreModes = new String[]{ "max", "min", "avg", "total", "multiply", "" };
+        String[] descriptionModes = new String[]{ "max of:", "min of:", "avg of:", "sum of:", "product of:", "sum of:" };
+        for (int innerMode = 0; innerMode < scoreModes.length; innerMode++) {
+            QueryRescorer innerRescoreQuery = RescoreBuilder.queryRescorer(QueryBuilders.matchQuery("field1", "the quick brown").boost(4.0f))
+                .setQueryWeight(0.5f).setRescoreQueryWeight(0.4f);
+
+            if (!"".equals(scoreModes[innerMode])) {
+                innerRescoreQuery.setScoreMode(scoreModes[innerMode]);
+            }
+
+            SearchResponse searchResponse = client()
+                    .prepareSearch()
+                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                    .setRescorer(innerRescoreQuery).setRescoreWindow(5).setExplain(true).execute()
+                    .actionGet();
+            assertHitCount(searchResponse, 3);
+            assertFirstHit(searchResponse, hasId("1"));
+            assertSecondHit(searchResponse, hasId("2"));
+            assertThirdHit(searchResponse, hasId("3"));
+
+            for (int j = 0; j < 3; j++) {
+                assertThat(searchResponse.getHits().getAt(j).explanation().getDescription(), equalTo(descriptionModes[innerMode]));
+            }
+
+            for (int outerMode = 0; outerMode < scoreModes.length; outerMode++) {
+                QueryRescorer outerRescoreQuery = RescoreBuilder.queryRescorer(QueryBuilders.matchQuery("field1", "the quick brown")
+                        .boost(4.0f)).setQueryWeight(0.5f).setRescoreQueryWeight(0.4f);
+
+                if (!"".equals(scoreModes[outerMode])) {
+                    outerRescoreQuery.setScoreMode(scoreModes[outerMode]);
+                }
+
+                searchResponse = client()
+                        .prepareSearch()
+                        .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                        .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                        .addRescorer(innerRescoreQuery).setRescoreWindow(5)
+                        .addRescorer(outerRescoreQuery).setRescoreWindow(10)
+                        .setExplain(true).get();
+                assertHitCount(searchResponse, 3);
+                assertFirstHit(searchResponse, hasId("1"));
+                assertSecondHit(searchResponse, hasId("2"));
+                assertThirdHit(searchResponse, hasId("3"));
+
+                for (int j = 0; j < 3; j++) {
+                    Explanation explanation = searchResponse.getHits().getAt(j).explanation();
+                    assertThat(explanation.getDescription(), equalTo(descriptionModes[outerMode]));
+                    assertThat(explanation.getDetails()[0].getDetails()[0].getDescription(), equalTo(descriptionModes[innerMode]));
+                }
+            }
+        }
+    }
+
+    @Test
+    public void testScoring() throws Exception {
+        int numDocs = indexRandomNumbers("keyword");
+
+        String[] scoreModes = new String[]{ "max", "min", "avg", "total", "multiply", "" };
+        float primaryWeight = 1.1f;
+        float secondaryWeight = 1.6f;
+
+        for (String scoreMode : scoreModes) {
+            for (int i = 0; i < numDocs - 4; i++) {
+                String[] intToEnglish = new String[] { English.intToEnglish(i), English.intToEnglish(i + 1), English.intToEnglish(i + 2), English.intToEnglish(i + 3) };
+
+                QueryRescorer rescoreQuery = RescoreBuilder
+                        .queryRescorer(
+                                QueryBuilders.boolQuery()
+                                        .disableCoord(true)
+                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]),
+                                                ScoreFunctionBuilders.weightFactorFunction(5.0f)).boostMode(CombineFunction.REPLACE))
+                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]),
+                                                ScoreFunctionBuilders.weightFactorFunction(7.0f)).boostMode(CombineFunction.REPLACE))
+                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]),
+                                                ScoreFunctionBuilders.weightFactorFunction(0.0f)).boostMode(CombineFunction.REPLACE)))
+                        .setQueryWeight(primaryWeight)
+                        .setRescoreQueryWeight(secondaryWeight);
+
+                if (!"".equals(scoreMode)) {
+                    rescoreQuery.setScoreMode(scoreMode);
+                }
+
+                SearchResponse rescored = client()
+                        .prepareSearch()
+                        .setPreference("test") // ensure we hit the same shards for tie-breaking
+                        .setQuery(QueryBuilders.boolQuery()
+                                .disableCoord(true)
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]),
+                                        ScoreFunctionBuilders.weightFactorFunction(2.0f)).boostMode(CombineFunction.REPLACE))
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]),
+                                        ScoreFunctionBuilders.weightFactorFunction(3.0f)).boostMode(CombineFunction.REPLACE))
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[2]),
+                                        ScoreFunctionBuilders.weightFactorFunction(5.0f)).boostMode(CombineFunction.REPLACE))
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]),
+                                        ScoreFunctionBuilders.weightFactorFunction(0.2f)).boostMode(CombineFunction.REPLACE)))
+                                .setFrom(0)
+                                .setSize(10)
+                                .setRescorer(rescoreQuery)
+                                .setRescoreWindow(50).execute().actionGet();
+
+                assertHitCount(rescored, 4);
+
+                if ("total".equals(scoreMode) || "".equals(scoreMode)) {
+                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
+                    assertSecondHit(rescored, hasId(String.valueOf(i)));
+                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
+                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight + 7.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight + 5.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight + 0.0f * secondaryWeight));
+                } else if ("max".equals(scoreMode)) {
+                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
+                    assertSecondHit(rescored, hasId(String.valueOf(i)));
+                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
+                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(7.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight));
+                } else if ("min".equals(scoreMode)) {
+                    assertFirstHit(rescored, hasId(String.valueOf(i + 2)));
+                    assertSecondHit(rescored, hasId(String.valueOf(i + 1)));
+                    assertThirdHit(rescored, hasId(String.valueOf(i)));
+                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(5.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(3.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(2.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.0f * secondaryWeight));
+                } else if ("avg".equals(scoreMode)) {
+                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
+                    assertSecondHit(rescored, hasId(String.valueOf(i + 2)));
+                    assertThirdHit(rescored, hasId(String.valueOf(i)));
+                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo((3.0f * primaryWeight + 7.0f * secondaryWeight) / 2.0f));
+                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo((2.0f * primaryWeight + 5.0f * secondaryWeight) / 2.0f));
+                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo((0.2f * primaryWeight) / 2.0f));
+                } else if ("multiply".equals(scoreMode)) {
+                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
+                    assertSecondHit(rescored, hasId(String.valueOf(i)));
+                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
+                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight * 7.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight * 5.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight * 0.0f * secondaryWeight));
+                }
+            }
+        }
+    }
+
+    @Test
+    public void testMultipleRescores() throws Exception {
+        int numDocs = indexRandomNumbers("keyword", 1, true);
+        QueryRescorer eightIsGreat = RescoreBuilder.queryRescorer(
+                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(8)),
+                        ScoreFunctionBuilders.weightFactorFunction(1000.0f)).boostMode(CombineFunction.REPLACE)).setScoreMode("total");
+        QueryRescorer sevenIsBetter = RescoreBuilder.queryRescorer(
+                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(7)),
+                        ScoreFunctionBuilders.weightFactorFunction(10000.0f)).boostMode(CombineFunction.REPLACE))
+                .setScoreMode("total");
+
+        // First set the rescore window large enough that both rescores take effect
+        SearchRequestBuilder request = client().prepareSearch().setRescoreWindow(numDocs);
+        request.addRescorer(eightIsGreat).addRescorer(sevenIsBetter);
+        SearchResponse response = request.get();
+        assertFirstHit(response, hasId("7"));
+        assertSecondHit(response, hasId("8"));
+
+        // Now squash the second rescore window so it never gets to see a seven
+        response = request.setSize(1).clearRescorers().addRescorer(eightIsGreat).addRescorer(sevenIsBetter, 1).get();
+        assertFirstHit(response, hasId("8"));
+        // We have no idea what the second hit will be because we didn't get a chance to look for seven
+
+        // Now use one rescore to drag the number we're looking for into the window of another
+        QueryRescorer ninetyIsGood = RescoreBuilder.queryRescorer(
+                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*ninety*"), ScoreFunctionBuilders.weightFactorFunction(1000.0f))
+                        .boostMode(CombineFunction.REPLACE)).setScoreMode("total");
+        QueryRescorer oneToo = RescoreBuilder.queryRescorer(
+                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*one*"), ScoreFunctionBuilders.weightFactorFunction(1000.0f))
+                        .boostMode(CombineFunction.REPLACE)).setScoreMode("total");
+        request.clearRescorers().addRescorer(ninetyIsGood).addRescorer(oneToo, 10);
+        response = request.setSize(2).get();
+        assertFirstHit(response, hasId("91"));
+        assertFirstHit(response, hasScore(2001.0f));
+        assertSecondHit(response, hasScore(1001.0f)); // Not sure which one it is but it is ninety something
+    }
+
+    private int indexRandomNumbers(String analyzer) throws Exception {
+        return indexRandomNumbers(analyzer, -1, true);
+    }
+
+    private int indexRandomNumbers(String analyzer, int shards, boolean dummyDocs) throws Exception {
+        Builder builder = Settings.settingsBuilder().put(indexSettings());
+
+        if (shards > 0) {
+            builder.put(SETTING_NUMBER_OF_SHARDS, shards);
+        }
+
+        assertAcked(prepareCreate("test")
+                .addMapping(
+                        "type1",
+                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
+                                .field("analyzer", analyzer).field("type", "string").endObject().endObject().endObject().endObject())
+                .setSettings(builder));
+        int numDocs = randomIntBetween(100, 150);
+        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
+        for (int i = 0; i < numDocs; i++) {
+            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource("field1", English.intToEnglish(i));
+        }
+
+        indexRandom(true, dummyDocs, docs);
+        ensureGreen();
+        return numDocs;
+    }
+
+    // #11277
+    public void testFromSize() throws Exception {
+        Builder settings = Settings.builder();
+        settings.put(SETTING_NUMBER_OF_SHARDS, 1);
+        settings.put(SETTING_NUMBER_OF_REPLICAS, 0);
+        assertAcked(prepareCreate("test").setSettings(settings));
+        for(int i=0;i<5;i++) {
+            client().prepareIndex("test", "type", ""+i).setSource("text", "hello world").get();
+        }
+        refresh();
+
+        SearchRequestBuilder request = client().prepareSearch();
+        request.setQuery(QueryBuilders.termQuery("text", "hello"));
+        request.setFrom(1);
+        request.setSize(4);
+        request.addRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchAllQuery()));
+        request.setRescoreWindow(50);
+
+        assertEquals(4, request.get().getHits().hits().length);
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java b/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java
index 76602a1..c877da8 100644
--- a/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java
+++ b/core/src/test/java/org/elasticsearch/test/ESSingleNodeTestCase.java
@@ -41,6 +41,7 @@ import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.node.Node;
 import org.elasticsearch.node.NodeBuilder;
 import org.elasticsearch.node.internal.InternalSettingsPreparer;
+import org.elasticsearch.script.ScriptService;
 import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.junit.After;
@@ -215,18 +216,15 @@ public abstract class ESSingleNodeTestCase extends ESTestCase {
         return instanceFromNode.indexServiceSafe(index);
     }
 
-    protected static org.elasticsearch.index.engine.Engine engine(IndexService service) {
-        return service.shard(0).engine();
-    }
-
     /**
      * Create a new search context.
      */
     protected static SearchContext createSearchContext(IndexService indexService) {
-        BigArrays bigArrays = indexService.injector().getInstance(BigArrays.class);
-        ThreadPool threadPool = indexService.injector().getInstance(ThreadPool.class);
-        PageCacheRecycler pageCacheRecycler = indexService.injector().getInstance(PageCacheRecycler.class);
-        return new TestSearchContext(threadPool, pageCacheRecycler, bigArrays, indexService);
+        BigArrays bigArrays = indexService.getIndexServices().getBigArrays();
+        ThreadPool threadPool = indexService.getIndexServices().getThreadPool();
+        PageCacheRecycler pageCacheRecycler = node().injector().getInstance(PageCacheRecycler.class);
+        ScriptService scriptService = node().injector().getInstance(ScriptService.class);
+        return new TestSearchContext(threadPool, pageCacheRecycler, bigArrays, scriptService, indexService);
     }
 
     /**
diff --git a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
index 53733bc..f7c44a5 100644
--- a/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
+++ b/core/src/test/java/org/elasticsearch/test/InternalTestCluster.java
@@ -68,7 +68,7 @@ import org.elasticsearch.index.engine.CommitStats;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.engine.EngineClosedException;
 import org.elasticsearch.index.shard.IndexShard;
-import org.elasticsearch.index.shard.MockEngineFactoryPlugin;
+import org.elasticsearch.index.MockEngineFactoryPlugin;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.indices.breaker.CircuitBreakerService;
@@ -1047,8 +1047,8 @@ public final class InternalTestCluster extends TestCluster {
             IndicesService indexServices = getInstance(IndicesService.class, nodeAndClient.name);
             for (IndexService indexService : indexServices) {
                 for (IndexShard indexShard : indexService) {
-                    try {
-                        CommitStats commitStats = indexShard.engine().commitStats();
+                    CommitStats commitStats = indexShard.commitStats();
+                    if (commitStats != null) { // null if the engine is closed or if the shard is recovering
                         String syncId = commitStats.getUserData().get(Engine.SYNC_COMMIT_ID);
                         if (syncId != null) {
                             long liveDocsOnShard = commitStats.getNumDocs();
@@ -1058,8 +1058,6 @@ public final class InternalTestCluster extends TestCluster {
                                 docsOnShards.put(syncId, liveDocsOnShard);
                             }
                         }
-                    } catch (EngineClosedException e) {
-                        // nothing to do, shard is closed
                     }
                 }
             }
@@ -1741,7 +1739,7 @@ public final class InternalTestCluster extends TestCluster {
             IndexService indexService = indicesService.indexService(index);
             if (indexService != null) {
                 assertThat(indexService.settingsService().getSettings().getAsInt(IndexMetaData.SETTING_NUMBER_OF_SHARDS, -1), greaterThan(shard));
-                OperationRouting operationRouting = indexService.injector().getInstance(OperationRouting.class);
+                OperationRouting operationRouting = getInstanceFromNode(OperationRouting.class, node);
                 while (true) {
                     String routing = RandomStrings.randomAsciiOfLength(random, 10);
                     final int targetShard = operationRouting.indexShards(clusterService.state(), index, type, null, routing).shardId().getId();
diff --git a/core/src/test/java/org/elasticsearch/test/TestSearchContext.java b/core/src/test/java/org/elasticsearch/test/TestSearchContext.java
index 4ee8ac6..35b6ab2 100644
--- a/core/src/test/java/org/elasticsearch/test/TestSearchContext.java
+++ b/core/src/test/java/org/elasticsearch/test/TestSearchContext.java
@@ -85,6 +85,7 @@ public class TestSearchContext extends SearchContext {
     final IndexShard indexShard;
     final Counter timeEstimateCounter = Counter.newCounter();
     final QuerySearchResult queryResult = new QuerySearchResult();
+    ScriptService scriptService;
     ParsedQuery originalQuery;
     ParsedQuery postFilter;
     Query query;
@@ -99,7 +100,7 @@ public class TestSearchContext extends SearchContext {
     private final long originNanoTime = System.nanoTime();
     private final Map<String, FetchSubPhaseContext> subPhaseContexts = new HashMap<>();
 
-    public TestSearchContext(ThreadPool threadPool,PageCacheRecycler pageCacheRecycler, BigArrays bigArrays, IndexService indexService) {
+    public TestSearchContext(ThreadPool threadPool,PageCacheRecycler pageCacheRecycler, BigArrays bigArrays, ScriptService scriptService, IndexService indexService) {
         super(ParseFieldMatcher.STRICT, null);
         this.pageCacheRecycler = pageCacheRecycler;
         this.bigArrays = bigArrays.withCircuitBreaking();
@@ -107,7 +108,8 @@ public class TestSearchContext extends SearchContext {
         this.indexFieldDataService = indexService.fieldData();
         this.fixedBitSetFilterCache = indexService.bitsetFilterCache();
         this.threadPool = threadPool;
-        this.indexShard = indexService.shard(0);
+        this.indexShard = indexService.getShardOrNull(0);
+        this.scriptService = scriptService;
     }
 
     public TestSearchContext() {
@@ -119,6 +121,7 @@ public class TestSearchContext extends SearchContext {
         this.threadPool = null;
         this.fixedBitSetFilterCache = null;
         this.indexShard = null;
+        scriptService = null;
     }
 
     public void setTypes(String... types) {
@@ -325,7 +328,7 @@ public class TestSearchContext extends SearchContext {
 
     @Override
     public ScriptService scriptService() {
-        return indexService.injector().getInstance(ScriptService.class);
+        return scriptService;
     }
 
     @Override
diff --git a/core/src/test/java/org/elasticsearch/test/store/MockFSIndexStore.java b/core/src/test/java/org/elasticsearch/test/store/MockFSIndexStore.java
index c5b5ac3..11a791c 100644
--- a/core/src/test/java/org/elasticsearch/test/store/MockFSIndexStore.java
+++ b/core/src/test/java/org/elasticsearch/test/store/MockFSIndexStore.java
@@ -24,14 +24,19 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.settings.IndexSettingsService;
+import org.elasticsearch.index.shard.ShardPath;
 import org.elasticsearch.index.store.DirectoryService;
+import org.elasticsearch.index.store.FsDirectoryService;
 import org.elasticsearch.index.store.IndexStore;
 import org.elasticsearch.index.store.IndexStoreModule;
+import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.indices.store.IndicesStore;
 import org.elasticsearch.plugins.Plugin;
 
 public class MockFSIndexStore extends IndexStore {
 
+    private final IndicesService indicesService;
+
     public static class TestPlugin extends Plugin {
         @Override
         public String name() {
@@ -52,13 +57,13 @@ public class MockFSIndexStore extends IndexStore {
 
     @Inject
     public MockFSIndexStore(Index index, @IndexSettings Settings indexSettings, IndexSettingsService indexSettingsService,
-                            IndicesStore indicesStore) {
+                            IndicesStore indicesStore, IndicesService indicesService) {
         super(index, indexSettings, indexSettingsService, indicesStore);
+        this.indicesService = indicesService;
     }
 
-    @Override
-    public Class<? extends DirectoryService> shardDirectory() {
-        return MockFSDirectoryService.class;
+    public DirectoryService newDirectoryService(ShardPath path) {
+        return new MockFSDirectoryService(indexSettings, this, indicesService, path);
     }
 
 }
diff --git a/core/src/test/resources/org/elasticsearch/index/query/has-child-with-inner-hits.json b/core/src/test/resources/org/elasticsearch/index/query/has-child-with-inner-hits.json
deleted file mode 100644
index 8efd4ba..0000000
--- a/core/src/test/resources/org/elasticsearch/index/query/has-child-with-inner-hits.json
+++ /dev/null
@@ -1,30 +0,0 @@
-{
-  "has_child" : {
-    "query" : {
-      "range" : {
-        "mapped_string" : {
-          "from" : "agJhRET",
-          "to" : "zvqIq",
-          "include_lower" : true,
-          "include_upper" : true,
-          "boost" : 1.0
-        }
-      }
-    },
-    "child_type" : "child",
-    "score_mode" : "avg",
-    "min_children" : 883170873,
-    "max_children" : 1217235442,
-    "boost" : 2.0,
-    "_name" : "WNzYMJKRwePuRBh",
-    "inner_hits" : {
-      "name" : "inner_hits_name",
-      "size" : 100,
-      "sort" : [ {
-        "mapped_string" : {
-          "order" : "asc"
-        }
-      } ]
-    }
-  }
-}
\ No newline at end of file
diff --git a/dev-tools/src/main/resources/forbidden/all-signatures.txt b/dev-tools/src/main/resources/forbidden/all-signatures.txt
index 68c6ea7..e57a862 100644
--- a/dev-tools/src/main/resources/forbidden/all-signatures.txt
+++ b/dev-tools/src/main/resources/forbidden/all-signatures.txt
@@ -130,6 +130,9 @@ com.google.common.primitives.Ints
 com.google.common.collect.ImmutableSet
 com.google.common.collect.ImmutableSet$Builder
 com.google.common.io.Resources
+com.google.common.hash.HashCode
+com.google.common.hash.HashFunction
+com.google.common.hash.Hashing
 
 @defaultMessage Do not violate java's access system
 java.lang.reflect.AccessibleObject#setAccessible(boolean)
diff --git a/docs/reference/migration/migrate_3_0.asciidoc b/docs/reference/migration/migrate_3_0.asciidoc
index 6607a98..897098f 100644
--- a/docs/reference/migration/migrate_3_0.asciidoc
+++ b/docs/reference/migration/migrate_3_0.asciidoc
@@ -262,3 +262,7 @@ of string values: see `FilterFunctionScoreQuery.ScoreMode` and `CombineFunction`
 
 `CombineFunction.MULT` has been renamed to `MULTIPLY`.
 
+==== IdsQueryBuilder
+
+For simplicity, only one way of adding the ids to the existing list (empty by default)  is left: `addIds(String...)`
+
diff --git a/plugins/jvm-example/src/main/java/org/elasticsearch/plugin/example/JvmExamplePlugin.java b/plugins/jvm-example/src/main/java/org/elasticsearch/plugin/example/JvmExamplePlugin.java
index fc9de89..9c4ec73 100644
--- a/plugins/jvm-example/src/main/java/org/elasticsearch/plugin/example/JvmExamplePlugin.java
+++ b/plugins/jvm-example/src/main/java/org/elasticsearch/plugin/example/JvmExamplePlugin.java
@@ -66,24 +66,10 @@ public class JvmExamplePlugin extends Plugin {
     }
 
     @Override
-    public Collection<Module> indexModules(Settings indexSettings) {
-        return Collections.emptyList();
-    }
-
-    @Override
-    public Collection<Class<? extends Closeable>> indexServices() {
-        return Collections.emptyList();
-    }
+    public Collection<Module> indexModules(Settings indexSettings) { return Collections.emptyList();}
 
     @Override
-    public Collection<Module> shardModules(Settings indexSettings) {
-        return Collections.emptyList();
-    }
-
-    @Override
-    public Collection<Class<? extends Closeable>> shardServices() {
-        return Collections.emptyList();
-    }
+    public Collection<Class<? extends Closeable>> indexServices() { return Collections.emptyList();}
 
     @Override
     public Settings additionalSettings() {
diff --git a/plugins/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java b/plugins/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java
index 9359161..1644eff 100644
--- a/plugins/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java
+++ b/plugins/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java
@@ -19,14 +19,10 @@
 
 package org.elasticsearch.script.groovy;
 
-import java.nio.charset.StandardCharsets;
-
-import com.google.common.hash.Hashing;
-
 import groovy.lang.Binding;
 import groovy.lang.GroovyClassLoader;
+import groovy.lang.GroovyCodeSource;
 import groovy.lang.Script;
-
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.Scorer;
 import org.codehaus.groovy.ast.ClassCodeExpressionTransformer;
@@ -41,9 +37,11 @@ import org.codehaus.groovy.control.SourceUnit;
 import org.codehaus.groovy.control.customizers.CompilationCustomizer;
 import org.codehaus.groovy.control.customizers.ImportCustomizer;
 import org.elasticsearch.SpecialPermission;
+import org.elasticsearch.bootstrap.BootstrapInfo;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.component.AbstractComponent;
+import org.elasticsearch.common.hash.MessageDigests;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.settings.Settings;
@@ -53,6 +51,7 @@ import org.elasticsearch.search.lookup.SearchLookup;
 
 import java.io.IOException;
 import java.math.BigDecimal;
+import java.nio.charset.StandardCharsets;
 import java.security.AccessController;
 import java.security.PrivilegedAction;
 import java.util.HashMap;
@@ -172,7 +171,15 @@ public class GroovyScriptEngineService extends AbstractComponent implements Scri
             if (sm != null) {
                 sm.checkPermission(new SpecialPermission());
             }
-            return loader.parseClass(script, Hashing.sha1().hashString(script, StandardCharsets.UTF_8).toString());
+            String fake = MessageDigests.toHexString(MessageDigests.sha1().digest(script.getBytes(StandardCharsets.UTF_8)));
+            // same logic as GroovyClassLoader.parseClass() but with a different codesource string:
+            GroovyCodeSource gcs = AccessController.doPrivileged(new PrivilegedAction<GroovyCodeSource>() {
+                public GroovyCodeSource run() {
+                    return new GroovyCodeSource(script, fake, BootstrapInfo.UNTRUSTED_CODEBASE);
+                }
+            });
+            gcs.setCachable(false);
+            return loader.parseClass(gcs);
         } catch (Throwable e) {
             if (logger.isTraceEnabled()) {
                 logger.trace("exception compiling Groovy script:", e);
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/AliasRoutingTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/AliasRoutingTests.java
deleted file mode 100644
index 347d3c7..0000000
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/AliasRoutingTests.java
+++ /dev/null
@@ -1,366 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.messy.tests;
-
-import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.action.search.SearchType;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.plugins.Plugin;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.script.ScriptService;
-import org.elasticsearch.script.groovy.GroovyPlugin;
-import org.elasticsearch.test.ESIntegTestCase;
-import org.junit.Test;
-
-import java.util.Collection;
-import java.util.Collections;
-
-import static org.elasticsearch.cluster.metadata.AliasAction.newAddAliasAction;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.hamcrest.Matchers.equalTo;
-
-/**
- *
- */
-public class AliasRoutingTests extends ESIntegTestCase {
-
-    @Override
-    protected Collection<Class<? extends Plugin>> nodePlugins() {
-        return Collections.singleton(GroovyPlugin.class);
-    }
-    
-    @Override
-    protected int minimumNumberOfShards() {
-        return 2;
-    }
-
-    @Test
-    public void testAliasCrudRouting() throws Exception {
-        createIndex("test");
-        ensureGreen();
-        assertAcked(admin().indices().prepareAliases().addAliasAction(newAddAliasAction("test", "alias0").routing("0")));
-
-        logger.info("--> indexing with id [1], and routing [0] using alias");
-        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-        logger.info("--> verifying get with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
-        }
-
-        logger.info("--> verifying get with routing alias, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-
-        logger.info("--> updating with id [1] and routing through alias");
-        client().prepareUpdate("alias0", "type1", "1")
-                .setUpsert(XContentFactory.jsonBuilder().startObject().field("field", 1).endObject())
-                .setScript(new Script("ctx._source.field = 'value2'", ScriptService.ScriptType.INLINE, null, null))
-                .execute().actionGet();
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().getSourceAsMap().get("field").toString(), equalTo("value2"));
-        }
-
-
-        logger.info("--> deleting with no routing, should not delete anything");
-        client().prepareDelete("test", "type1", "1").setRefresh(true).execute().actionGet();
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-
-        logger.info("--> deleting with routing alias, should delete");
-        client().prepareDelete("alias0", "type1", "1").setRefresh(true).execute().actionGet();
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(false));
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-
-        logger.info("--> indexing with id [1], and routing [0] using alias");
-        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-        logger.info("--> verifying get with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-    }
-
-    @Test
-    public void testAliasSearchRouting() throws Exception {
-        createIndex("test");
-        ensureGreen();
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("test", "alias"))
-                .addAliasAction(newAddAliasAction("test", "alias0").routing("0"))
-                .addAliasAction(newAddAliasAction("test", "alias1").routing("1"))
-                .addAliasAction(newAddAliasAction("test", "alias01").searchRouting("0,1")));
-
-        logger.info("--> indexing with id [1], and routing [0] using alias");
-        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-        logger.info("--> verifying get with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-
-        logger.info("--> search with no routing, should fine one");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-        }
-
-        logger.info("--> search with wrong routing, should not find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
-            assertThat(client().prepareCount().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
-            assertThat(client().prepareSearch("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
-            assertThat(client().prepareCount("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
-        }
-
-        logger.info("--> search with correct routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-            assertThat(client().prepareSearch("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-        }
-
-        logger.info("--> indexing with id [2], and routing [1] using alias");
-        client().prepareIndex("alias1", "type1", "2").setSource("field", "value1").setRefresh(true).execute().actionGet();
-
-        logger.info("--> search with no routing, should fine two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-        logger.info("--> search with 0 routing, should find one");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-            assertThat(client().prepareSearch("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-        }
-
-        logger.info("--> search with 1 routing, should find one");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-            assertThat(client().prepareSearch("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-        }
-
-        logger.info("--> search with 0,1 routings , should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setRouting("0", "1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount().setRouting("0", "1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-            assertThat(client().prepareSearch("alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-        logger.info("--> search with two routing aliases , should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-        logger.info("--> search with alias0, alias1 and alias01, should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias0", "alias1", "alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias0", "alias1", "alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-        logger.info("--> search with test, alias0 and alias1, should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("test", "alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("test", "alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-    }
-
-    @Test
-    public void testAliasSearchRoutingWithTwoIndices() throws Exception {
-        createIndex("test-a");
-        createIndex("test-b");
-        ensureGreen();
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("test-a", "alias-a0").routing("0"))
-                .addAliasAction(newAddAliasAction("test-a", "alias-a1").routing("1"))
-                .addAliasAction(newAddAliasAction("test-b", "alias-b0").routing("0"))
-                .addAliasAction(newAddAliasAction("test-b", "alias-b1").routing("1"))
-                .addAliasAction(newAddAliasAction("test-a", "alias-ab").searchRouting("0"))
-                .addAliasAction(newAddAliasAction("test-b", "alias-ab").searchRouting("1")));
-        ensureGreen(); // wait for events again to make sure we got the aliases on all nodes
-        logger.info("--> indexing with id [1], and routing [0] using alias to test-a");
-        client().prepareIndex("alias-a0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test-a", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-        logger.info("--> verifying get with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("alias-a0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-
-        logger.info("--> indexing with id [0], and routing [1] using alias to test-b");
-        client().prepareIndex("alias-b1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test-a", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-        logger.info("--> verifying get with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("alias-b1", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-
-
-        logger.info("--> search with alias-a1,alias-b0, should not find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias-a1", "alias-b0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
-            assertThat(client().prepareCount("alias-a1", "alias-b0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
-        }
-
-        logger.info("--> search with alias-ab, should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias-ab").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias-ab").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-        logger.info("--> search with alias-a0,alias-b1 should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias-a0", "alias-b1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias-a0", "alias-b1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-    }
-
-    /*
-    See https://github.com/elasticsearch/elasticsearch/issues/2682
-    Searching on more than one index, if one of those is an alias with configured routing, the shards that belonged
-    to the other indices (without routing) were not taken into account in PlainOperationRouting#searchShards.
-    That affected the number of shards that we executed the search on, thus some documents were missing in the search results.
-     */
-    @Test
-    public void testAliasSearchRoutingWithConcreteAndAliasedIndices_issue2682() throws Exception {
-        createIndex("index", "index_2");
-        ensureGreen();
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("index", "index_1").routing("1")));
-
-        logger.info("--> indexing on index_1 which is an alias for index with routing [1]");
-        client().prepareIndex("index_1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> indexing on index_2 which is a concrete index");
-        client().prepareIndex("index_2", "type2", "2").setSource("field", "value2").setRefresh(true).execute().actionGet();
-
-
-        logger.info("--> search all on index_* should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("index_*").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-        }
-    }
-
-    /*
-    See https://github.com/elasticsearch/elasticsearch/pull/3268
-    Searching on more than one index, if one of those is an alias with configured routing, the shards that belonged
-    to the other indices (without routing) were not taken into account in PlainOperationRouting#searchShardsCount.
-    That could cause returning 1, which led to forcing the QUERY_AND_FETCH mode.
-    As a result, (size * number of hit shards) results were returned and no reduce phase was taking place.
-     */
-    @Test
-    public void testAliasSearchRoutingWithConcreteAndAliasedIndices_issue3268() throws Exception {
-        createIndex("index", "index_2");
-        ensureGreen();
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("index", "index_1").routing("1")));
-
-        logger.info("--> indexing on index_1 which is an alias for index with routing [1]");
-        client().prepareIndex("index_1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> indexing on index_2 which is a concrete index");
-        client().prepareIndex("index_2", "type2", "2").setSource("field", "value2").setRefresh(true).execute().actionGet();
-
-        SearchResponse searchResponse = client().prepareSearch("index_*").setSearchType(SearchType.QUERY_THEN_FETCH).setSize(1).setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();
-
-        logger.info("--> search all on index_* should find two");
-        assertThat(searchResponse.getHits().totalHits(), equalTo(2L));
-        //Let's make sure that, even though 2 docs are available, only one is returned according to the size we set in the request
-        //Therefore the reduce phase has taken place, which proves that the QUERY_AND_FETCH search type wasn't erroneously forced.
-        assertThat(searchResponse.getHits().getHits().length, equalTo(1));
-    }
-
-    @Test
-    public void testIndexingAliasesOverTime() throws Exception {
-        createIndex("test");
-        ensureGreen();
-        logger.info("--> creating alias with routing [3]");
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("test", "alias").routing("3")));
-
-        logger.info("--> indexing with id [0], and routing [3]");
-        client().prepareIndex("alias", "type1", "0").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-
-        logger.info("--> verifying get and search with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "0").setRouting("3").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-        }
-
-        logger.info("--> creating alias with routing [4]");
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("test", "alias").routing("4")));
-
-        logger.info("--> verifying search with wrong routing should not find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
-            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
-        }
-
-        logger.info("--> creating alias with search routing [3,4] and index routing 4");
-        assertAcked(client().admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("test", "alias").searchRouting("3,4").indexRouting("4")));
-
-        logger.info("--> indexing with id [1], and routing [4]");
-        client().prepareIndex("alias", "type1", "1").setSource("field", "value2").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-
-        logger.info("--> verifying get and search with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "0").setRouting("3").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareGet("test", "type1", "1").setRouting("4").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-    }
-
-}
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/QueryRescorerTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/QueryRescorerTests.java
deleted file mode 100644
index f437009..0000000
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/QueryRescorerTests.java
+++ /dev/null
@@ -1,763 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.messy.tests;
-
-
-
-import org.apache.lucene.search.Explanation;
-import org.apache.lucene.util.English;
-import org.elasticsearch.action.index.IndexRequestBuilder;
-import org.elasticsearch.action.search.SearchRequestBuilder;
-import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.action.search.SearchType;
-import org.elasticsearch.common.lucene.search.function.CombineFunction;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.settings.Settings.Builder;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.Operator;
-import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
-import org.elasticsearch.plugins.Plugin;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.script.groovy.GroovyPlugin;
-import org.elasticsearch.search.SearchHit;
-import org.elasticsearch.search.SearchHits;
-import org.elasticsearch.search.rescore.RescoreBuilder;
-import org.elasticsearch.search.rescore.RescoreBuilder.QueryRescorer;
-import org.elasticsearch.test.ESIntegTestCase;
-import org.junit.Test;
-
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
-import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
-import static org.hamcrest.Matchers.*;
-
-/**
- *
- */
-public class QueryRescorerTests extends ESIntegTestCase {
-
-    @Override
-    protected Collection<Class<? extends Plugin>> nodePlugins() {
-        return Collections.singleton(GroovyPlugin.class);
-    }
-
-    @Test
-    public void testEnforceWindowSize() {
-        createIndex("test");
-        // this
-        int iters = scaledRandomIntBetween(10, 20);
-        for (int i = 0; i < iters; i ++) {
-            client().prepareIndex("test", "type", Integer.toString(i)).setSource("f", Integer.toString(i)).execute().actionGet();
-        }
-        ensureYellow();
-        refresh();
-
-        int numShards = getNumShards("test").numPrimaries;
-        for (int j = 0 ; j < iters; j++) {
-            SearchResponse searchResponse = client().prepareSearch()
-                    .setQuery(QueryBuilders.matchAllQuery())
-                    .setRescorer(RescoreBuilder.queryRescorer(
-                            QueryBuilders.functionScoreQuery(QueryBuilders.matchAllQuery(),
-                                    ScoreFunctionBuilders.weightFactorFunction(100)).boostMode(CombineFunction.REPLACE)).setQueryWeight(0.0f).setRescoreQueryWeight(1.0f))
-                    .setRescoreWindow(1).setSize(randomIntBetween(2, 10)).execute().actionGet();
-            assertSearchResponse(searchResponse);
-            assertFirstHit(searchResponse, hasScore(100.f));
-            int numDocsWith100AsAScore = 0;
-            for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
-                float score = searchResponse.getHits().hits()[i].getScore();
-                if  (score == 100f) {
-                    numDocsWith100AsAScore += 1;
-                }
-            }
-            // we cannot assert that they are equal since some shards might not have docs at all
-            assertThat(numDocsWith100AsAScore, lessThanOrEqualTo(numShards));
-        }
-    }
-
-    @Test
-    public void testRescorePhrase() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping(
-                        "type1",
-                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
-                                .field("analyzer", "whitespace").field("type", "string").endObject().endObject().endObject().endObject())
-                .setSettings(Settings.settingsBuilder().put(indexSettings()).put("index.number_of_shards", 1)));
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox").execute().actionGet();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree ").get();
-        client().prepareIndex("test", "type1", "3")
-                .setSource("field1", "quick huge brown", "field2", "the quick lazy huge brown fox jumps over the tree").get();
-        ensureYellow();
-        refresh();
-        SearchResponse searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "quick brown").slop(2).boost(4.0f)).setRescoreQueryWeight(2))
-                .setRescoreWindow(5).execute().actionGet();
-
-        assertThat(searchResponse.getHits().totalHits(), equalTo(3l));
-        assertThat(searchResponse.getHits().getHits()[0].getId(), equalTo("1"));
-        assertThat(searchResponse.getHits().getHits()[1].getId(), equalTo("3"));
-        assertThat(searchResponse.getHits().getHits()[2].getId(), equalTo("2"));
-
-        searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(3)))
-                .setRescoreWindow(5).execute().actionGet();
-
-        assertHitCount(searchResponse, 3);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                .setRescorer(RescoreBuilder.queryRescorer((QueryBuilders.matchPhraseQuery("field1", "the quick brown"))))
-                .setRescoreWindow(5).execute().actionGet();
-
-        assertHitCount(searchResponse, 3);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-    }
-
-    @Test
-    public void testMoreDocs() throws Exception {
-        Builder builder = Settings.builder();
-        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
-        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
-        builder.put("index.analysis.filter.synonym.type", "synonym");
-        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
-
-        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
-                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
-                .endObject().endObject().endObject().endObject();
-
-        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "massachusetts avenue boston massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "3").setSource("field1", "boston avenue lexington massachusetts").execute().actionGet();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        client().prepareIndex("test", "type1", "4").setSource("field1", "boston road lexington massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "5").setSource("field1", "lexington street lexington massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "7").setSource("field1", "bosten street san franciso california").execute().actionGet();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        client().prepareIndex("test", "type1", "8").setSource("field1", "hollywood boulevard los angeles california").execute().actionGet();
-        client().prepareIndex("test", "type1", "9").setSource("field1", "1st street boston massachussetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "10").setSource("field1", "1st street boston massachusetts").execute().actionGet();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        client().prepareIndex("test", "type1", "11").setSource("field1", "2st street boston massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "12").setSource("field1", "3st street boston massachusetts").execute().actionGet();
-        ensureYellow();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        SearchResponse searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
-                .setFrom(0)
-                .setSize(5)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
-
-        assertThat(searchResponse.getHits().hits().length, equalTo(5));
-        assertHitCount(searchResponse, 9);
-        assertFirstHit(searchResponse, hasId("2"));
-        assertSecondHit(searchResponse, hasId("6"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
-                .setFrom(0)
-                .setSize(5)
-                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
-
-        assertThat(searchResponse.getHits().hits().length, equalTo(5));
-        assertHitCount(searchResponse, 9);
-        assertFirstHit(searchResponse, hasId("2"));
-        assertSecondHit(searchResponse, hasId("6"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        // Make sure non-zero from works:
-        searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
-                .setFrom(2)
-                .setSize(5)
-                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
-
-        assertThat(searchResponse.getHits().hits().length, equalTo(5));
-        assertHitCount(searchResponse, 9);
-        assertFirstHit(searchResponse, hasId("3"));
-    }
-
-    // Tests a rescore window smaller than number of hits:
-    @Test
-    public void testSmallRescoreWindow() throws Exception {
-        Builder builder = Settings.builder();
-        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
-        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
-        builder.put("index.analysis.filter.synonym.type", "synonym");
-        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
-
-        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
-                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
-                .endObject().endObject().endObject().endObject();
-
-        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
-
-        client().prepareIndex("test", "type1", "3").setSource("field1", "massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        client().prepareIndex("test", "type1", "1").setSource("field1", "lexington massachusetts avenue").execute().actionGet();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts road").execute().actionGet();
-        ensureYellow();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-
-        SearchResponse searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
-                .setFrom(0)
-            .setSize(5).execute().actionGet();
-        assertThat(searchResponse.getHits().hits().length, equalTo(4));
-        assertHitCount(searchResponse, 4);
-        assertFirstHit(searchResponse, hasId("3"));
-        assertSecondHit(searchResponse, hasId("6"));
-        assertThirdHit(searchResponse, hasId("1"));
-        assertFourthHit(searchResponse, hasId("2"));
-
-        // Now, rescore only top 2 hits w/ proximity:
-        searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
-                .setFrom(0)
-                .setSize(5)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(2).execute().actionGet();
-        // Only top 2 hits were re-ordered:
-        assertThat(searchResponse.getHits().hits().length, equalTo(4));
-        assertHitCount(searchResponse, 4);
-        assertFirstHit(searchResponse, hasId("6"));
-        assertSecondHit(searchResponse, hasId("3"));
-        assertThirdHit(searchResponse, hasId("1"));
-        assertFourthHit(searchResponse, hasId("2"));
-
-        // Now, rescore only top 3 hits w/ proximity:
-        searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
-                .setFrom(0)
-                .setSize(5)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(3).execute().actionGet();
-
-        // Only top 3 hits were re-ordered:
-        assertThat(searchResponse.getHits().hits().length, equalTo(4));
-        assertHitCount(searchResponse, 4);
-        assertFirstHit(searchResponse, hasId("6"));
-        assertSecondHit(searchResponse, hasId("1"));
-        assertThirdHit(searchResponse, hasId("3"));
-        assertFourthHit(searchResponse, hasId("2"));
-    }
-
-    // Tests a rescorer that penalizes the scores:
-    @Test
-    public void testRescorerMadeScoresWorse() throws Exception {
-        Builder builder = Settings.builder();
-        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
-        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
-        builder.put("index.analysis.filter.synonym.type", "synonym");
-        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
-
-        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
-                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
-                .endObject().endObject().endObject().endObject();
-
-        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
-
-        client().prepareIndex("test", "type1", "3").setSource("field1", "massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        client().prepareIndex("test", "type1", "1").setSource("field1", "lexington massachusetts avenue").execute().actionGet();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts road").execute().actionGet();
-        ensureYellow();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-
-        SearchResponse searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
-                .setFrom(0)
-            .setSize(5).execute().actionGet();
-        assertThat(searchResponse.getHits().hits().length, equalTo(4));
-        assertHitCount(searchResponse, 4);
-        assertFirstHit(searchResponse, hasId("3"));
-        assertSecondHit(searchResponse, hasId("6"));
-        assertThirdHit(searchResponse, hasId("1"));
-        assertFourthHit(searchResponse, hasId("2"));
-
-        // Now, penalizing rescore (nothing matches the rescore query):
-        searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
-                .setFrom(0)
-                .setSize(5)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(1.0f).setRescoreQueryWeight(-1f)).setRescoreWindow(3).execute().actionGet();
-
-        // 6 and 1 got worse, and then the hit (2) outside the rescore window were sorted ahead:
-        assertFirstHit(searchResponse, hasId("3"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("6"));
-        assertFourthHit(searchResponse, hasId("1"));
-    }
-
-    // Comparator that sorts hits and rescored hits in the same way.
-    // The rescore uses the docId as tie, while regular search uses the slot the hit is in as a tie if score
-    // and shard id are equal during merging shard results.
-    // This comparator uses a custom tie in case the scores are equal, so that both regular hits and rescored hits
-    // are sorted equally. This is fine since tests only care about the fact the scores should be equal, not ordering.
-    private final static Comparator<SearchHit> searchHitsComparator = new Comparator<SearchHit>() {
-        @Override
-        public int compare(SearchHit hit1, SearchHit hit2) {
-            int cmp = Float.compare(hit2.getScore(), hit1.getScore());
-            if (cmp == 0) {
-                return hit1.id().compareTo(hit2.id());
-            } else {
-                return cmp;
-            }
-        }
-    };
-
-    private static void assertEquivalent(String query, SearchResponse plain, SearchResponse rescored) {
-        assertNoFailures(plain);
-        assertNoFailures(rescored);
-        SearchHits leftHits = plain.getHits();
-        SearchHits rightHits = rescored.getHits();
-        assertThat(leftHits.getTotalHits(), equalTo(rightHits.getTotalHits()));
-        assertThat(leftHits.getHits().length, equalTo(rightHits.getHits().length));
-        SearchHit[] hits = leftHits.getHits();
-        SearchHit[] rHits = rightHits.getHits();
-        Arrays.sort(hits, searchHitsComparator);
-        Arrays.sort(rHits, searchHitsComparator);
-        for (int i = 0; i < hits.length; i++) {
-            assertThat("query: " + query, hits[i].getScore(), equalTo(rHits[i].getScore()));
-        }
-        for (int i = 0; i < hits.length; i++) {
-            if (hits[i].getScore() == hits[hits.length-1].getScore()) {
-                return; // we need to cut off here since this is the tail of the queue and we might not have fetched enough docs
-            }
-            assertThat("query: " + query,hits[i].getId(), equalTo(rHits[i].getId()));
-        }
-    }
-
-    private static void assertEquivalentOrSubstringMatch(String query, SearchResponse plain, SearchResponse rescored) {
-        assertNoFailures(plain);
-        assertNoFailures(rescored);
-        SearchHits leftHits = plain.getHits();
-        SearchHits rightHits = rescored.getHits();
-        assertThat(leftHits.getTotalHits(), equalTo(rightHits.getTotalHits()));
-        assertThat(leftHits.getHits().length, equalTo(rightHits.getHits().length));
-        SearchHit[] hits = leftHits.getHits();
-        SearchHit[] otherHits = rightHits.getHits();
-        if (!hits[0].getId().equals(otherHits[0].getId())) {
-            assertThat(((String) otherHits[0].sourceAsMap().get("field1")).contains(query), equalTo(true));
-        } else {
-            Arrays.sort(hits, searchHitsComparator);
-            Arrays.sort(otherHits, searchHitsComparator);
-            for (int i = 0; i < hits.length; i++) {
-                if (hits[i].getScore() == hits[hits.length-1].getScore()) {
-                    return; // we need to cut off here since this is the tail of the queue and we might not have fetched enough docs
-                }
-                assertThat(query, hits[i].getId(), equalTo(rightHits.getHits()[i].getId()));
-            }
-        }
-    }
-
-    @Test
-    // forces QUERY_THEN_FETCH because of https://github.com/elasticsearch/elasticsearch/issues/4829
-    public void testEquivalence() throws Exception {
-        // no dummy docs since merges can change scores while we run queries.
-        int numDocs = indexRandomNumbers("whitespace", -1, false);
-
-        final int iters = scaledRandomIntBetween(50, 100);
-        for (int i = 0; i < iters; i++) {
-            int resultSize = numDocs;
-            int rescoreWindow = between(1, 3) * resultSize;
-            String intToEnglish = English.intToEnglish(between(0, numDocs-1));
-            String query = intToEnglish.split(" ")[0];
-            SearchResponse rescored = client()
-                    .prepareSearch()
-                    .setSearchType(SearchType.QUERY_THEN_FETCH)
-                    .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
-                    .setFrom(0)
-                    .setSize(resultSize)
-                    .setRescorer(
-                            RescoreBuilder
-                                    .queryRescorer(
-                                            QueryBuilders
-                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery("field1", intToEnglish).slop(3)))
-                                    .setQueryWeight(1.0f)
-                                    .setRescoreQueryWeight(0.0f)) // no weight - so we basically use the same score as the actual query
-                    .setRescoreWindow(rescoreWindow).execute().actionGet();
-
-            SearchResponse plain = client().prepareSearch()
-                    .setSearchType(SearchType.QUERY_THEN_FETCH)
-                    .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR)).setFrom(0).setSize(resultSize)
-                    .execute().actionGet();
-            
-            // check equivalence
-            assertEquivalent(query, plain, rescored);
-
-            rescored = client()
-                    .prepareSearch()
-                    .setSearchType(SearchType.QUERY_THEN_FETCH)
-                    .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
-                    .setFrom(0)
-                    .setSize(resultSize)
-                    .setRescorer(
-                            RescoreBuilder
-                                    .queryRescorer(
-                                            QueryBuilders
-                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery("field1", "not in the index").slop(3)))
-                                    .setQueryWeight(1.0f)
-                                    .setRescoreQueryWeight(1.0f))
-                    .setRescoreWindow(rescoreWindow).execute().actionGet();
-            // check equivalence
-            assertEquivalent(query, plain, rescored);
-
-            rescored = client()
-                    .prepareSearch()
-                    .setSearchType(SearchType.QUERY_THEN_FETCH)
-                    .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
-                    .setFrom(0)
-                    .setSize(resultSize)
-                    .setRescorer(
-                            RescoreBuilder
-                                    .queryRescorer(
-                                            QueryBuilders.matchPhraseQuery("field1", intToEnglish).slop(0))
-                                    .setQueryWeight(1.0f).setRescoreQueryWeight(1.0f)).setRescoreWindow(2 * rescoreWindow).execute().actionGet();
-            // check equivalence or if the first match differs we check if the phrase is a substring of the top doc
-            assertEquivalentOrSubstringMatch(intToEnglish, plain, rescored);
-        }
-    }
-
-    @Test
-    public void testExplain() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping(
-                        "type1",
-                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
-                                .field("analyzer", "whitespace").field("type", "string").endObject().endObject().endObject().endObject())
-        );
-        ensureGreen();
-        client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox").execute().actionGet();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree").execute()
-                .actionGet();
-        client().prepareIndex("test", "type1", "3")
-                .setSource("field1", "quick huge brown", "field2", "the quick lazy huge brown fox jumps over the tree").execute()
-                .actionGet();
-        ensureYellow();
-        refresh();
-
-        {
-            SearchResponse searchResponse = client()
-                    .prepareSearch()
-                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                    .setRescorer(
-                            RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(2).boost(4.0f))
-                                    .setQueryWeight(0.5f).setRescoreQueryWeight(0.4f)).setRescoreWindow(5).setExplain(true).execute()
-                    .actionGet();
-            assertHitCount(searchResponse, 3);
-            assertFirstHit(searchResponse, hasId("1"));
-            assertSecondHit(searchResponse, hasId("2"));
-            assertThirdHit(searchResponse, hasId("3"));
-
-            for (int i = 0; i < 3; i++) {
-                assertThat(searchResponse.getHits().getAt(i).explanation(), notNullValue());
-                assertThat(searchResponse.getHits().getAt(i).explanation().isMatch(), equalTo(true));
-                assertThat(searchResponse.getHits().getAt(i).explanation().getDetails().length, equalTo(2));
-                assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[0].isMatch(), equalTo(true));
-                if (i == 2) {
-                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[1].getValue(), equalTo(0.5f));
-                } else {
-                    assertThat(searchResponse.getHits().getAt(i).explanation().getDescription(), equalTo("sum of:"));
-                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[0].getDetails()[1].getValue(), equalTo(0.5f));
-                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[1].getDetails()[1].getValue(), equalTo(0.4f));
-                }
-            }
-        }
-
-        String[] scoreModes = new String[]{ "max", "min", "avg", "total", "multiply", "" };
-        String[] descriptionModes = new String[]{ "max of:", "min of:", "avg of:", "sum of:", "product of:", "sum of:" };
-        for (int innerMode = 0; innerMode < scoreModes.length; innerMode++) {
-            QueryRescorer innerRescoreQuery = RescoreBuilder.queryRescorer(QueryBuilders.matchQuery("field1", "the quick brown").boost(4.0f))
-                .setQueryWeight(0.5f).setRescoreQueryWeight(0.4f);
-
-            if (!"".equals(scoreModes[innerMode])) {
-                innerRescoreQuery.setScoreMode(scoreModes[innerMode]);
-            }
-
-            SearchResponse searchResponse = client()
-                    .prepareSearch()
-                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                    .setRescorer(innerRescoreQuery).setRescoreWindow(5).setExplain(true).execute()
-                    .actionGet();
-            assertHitCount(searchResponse, 3);
-            assertFirstHit(searchResponse, hasId("1"));
-            assertSecondHit(searchResponse, hasId("2"));
-            assertThirdHit(searchResponse, hasId("3"));
-
-            for (int j = 0; j < 3; j++) {
-                assertThat(searchResponse.getHits().getAt(j).explanation().getDescription(), equalTo(descriptionModes[innerMode]));
-            }
-
-            for (int outerMode = 0; outerMode < scoreModes.length; outerMode++) {
-                QueryRescorer outerRescoreQuery = RescoreBuilder.queryRescorer(QueryBuilders.matchQuery("field1", "the quick brown")
-                        .boost(4.0f)).setQueryWeight(0.5f).setRescoreQueryWeight(0.4f);
-
-                if (!"".equals(scoreModes[outerMode])) {
-                    outerRescoreQuery.setScoreMode(scoreModes[outerMode]);
-                }
-
-                searchResponse = client()
-                        .prepareSearch()
-                        .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                        .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                        .addRescorer(innerRescoreQuery).setRescoreWindow(5)
-                        .addRescorer(outerRescoreQuery).setRescoreWindow(10)
-                        .setExplain(true).get();
-                assertHitCount(searchResponse, 3);
-                assertFirstHit(searchResponse, hasId("1"));
-                assertSecondHit(searchResponse, hasId("2"));
-                assertThirdHit(searchResponse, hasId("3"));
-
-                for (int j = 0; j < 3; j++) {
-                    Explanation explanation = searchResponse.getHits().getAt(j).explanation();
-                    assertThat(explanation.getDescription(), equalTo(descriptionModes[outerMode]));
-                    assertThat(explanation.getDetails()[0].getDetails()[0].getDescription(), equalTo(descriptionModes[innerMode]));
-                }
-            }
-        }
-    }
-
-    @Test
-    public void testScoring() throws Exception {
-        int numDocs = indexRandomNumbers("keyword");
-
-        String[] scoreModes = new String[]{ "max", "min", "avg", "total", "multiply", "" };
-        float primaryWeight = 1.1f;
-        float secondaryWeight = 1.6f;
-
-        for (String scoreMode : scoreModes) {
-            for (int i = 0; i < numDocs - 4; i++) {
-                String[] intToEnglish = new String[] { English.intToEnglish(i), English.intToEnglish(i + 1), English.intToEnglish(i + 2), English.intToEnglish(i + 3) };
-
-                QueryRescorer rescoreQuery = RescoreBuilder
-                        .queryRescorer(
-                                QueryBuilders.boolQuery()
-                                        .disableCoord(true)
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]),
-                                                ScoreFunctionBuilders.scriptFunction(new Script("5.0f"))).boostMode(CombineFunction.REPLACE))
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]),
-                                                ScoreFunctionBuilders.scriptFunction(new Script("7.0f"))).boostMode(CombineFunction.REPLACE))
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]),
-                                                ScoreFunctionBuilders.scriptFunction(new Script("0.0f"))).boostMode(CombineFunction.REPLACE)))
-                        .setQueryWeight(primaryWeight)
-                        .setRescoreQueryWeight(secondaryWeight);
-
-                if (!"".equals(scoreMode)) {
-                    rescoreQuery.setScoreMode(scoreMode);
-                }
-
-                SearchResponse rescored = client()
-                        .prepareSearch()
-                        .setPreference("test") // ensure we hit the same shards for tie-breaking
-                        .setQuery(QueryBuilders.boolQuery()
-                                .disableCoord(true)
-                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]),
-                                        ScoreFunctionBuilders.scriptFunction(new Script("2.0f"))).boostMode(CombineFunction.REPLACE))
-                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]),
-                                        ScoreFunctionBuilders.scriptFunction(new Script("3.0f"))).boostMode(CombineFunction.REPLACE))
-                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[2]),
-                                        ScoreFunctionBuilders.scriptFunction(new Script("5.0f"))).boostMode(CombineFunction.REPLACE))
-                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]),
-                                        ScoreFunctionBuilders.scriptFunction(new Script("0.2f"))).boostMode(CombineFunction.REPLACE)))
-                                .setFrom(0)
-                                .setSize(10)
-                                .setRescorer(rescoreQuery)
-                                .setRescoreWindow(50).execute().actionGet();
-
-                assertHitCount(rescored, 4);
-
-                if ("total".equals(scoreMode) || "".equals(scoreMode)) {
-                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
-                    assertSecondHit(rescored, hasId(String.valueOf(i)));
-                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
-                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight + 7.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight + 5.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight + 0.0f * secondaryWeight));
-                } else if ("max".equals(scoreMode)) {
-                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
-                    assertSecondHit(rescored, hasId(String.valueOf(i)));
-                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
-                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(7.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight));
-                } else if ("min".equals(scoreMode)) {
-                    assertFirstHit(rescored, hasId(String.valueOf(i + 2)));
-                    assertSecondHit(rescored, hasId(String.valueOf(i + 1)));
-                    assertThirdHit(rescored, hasId(String.valueOf(i)));
-                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(5.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(3.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(2.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.0f * secondaryWeight));
-                } else if ("avg".equals(scoreMode)) {
-                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
-                    assertSecondHit(rescored, hasId(String.valueOf(i + 2)));
-                    assertThirdHit(rescored, hasId(String.valueOf(i)));
-                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo((3.0f * primaryWeight + 7.0f * secondaryWeight) / 2.0f));
-                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo((2.0f * primaryWeight + 5.0f * secondaryWeight) / 2.0f));
-                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo((0.2f * primaryWeight) / 2.0f));
-                } else if ("multiply".equals(scoreMode)) {
-                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
-                    assertSecondHit(rescored, hasId(String.valueOf(i)));
-                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
-                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight * 7.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight * 5.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight * 0.0f * secondaryWeight));
-                }
-            }
-        }
-    }
-
-    @Test
-    public void testMultipleRescores() throws Exception {
-        int numDocs = indexRandomNumbers("keyword", 1, true);
-        QueryRescorer eightIsGreat = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(8)),
-                        ScoreFunctionBuilders.scriptFunction(new Script("1000.0f"))).boostMode(CombineFunction.REPLACE)).setScoreMode("total");
-        QueryRescorer sevenIsBetter = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(7)),
-                        ScoreFunctionBuilders.scriptFunction(new Script("10000.0f"))).boostMode(CombineFunction.REPLACE))
-                .setScoreMode("total");
-
-        // First set the rescore window large enough that both rescores take effect
-        SearchRequestBuilder request = client().prepareSearch().setRescoreWindow(numDocs);
-        request.addRescorer(eightIsGreat).addRescorer(sevenIsBetter);
-        SearchResponse response = request.get();
-        assertFirstHit(response, hasId("7"));
-        assertSecondHit(response, hasId("8"));
-
-        // Now squash the second rescore window so it never gets to see a seven
-        response = request.setSize(1).clearRescorers().addRescorer(eightIsGreat).addRescorer(sevenIsBetter, 1).get();
-        assertFirstHit(response, hasId("8"));
-        // We have no idea what the second hit will be because we didn't get a chance to look for seven
-
-        // Now use one rescore to drag the number we're looking for into the window of another
-        QueryRescorer ninetyIsGood = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*ninety*"), ScoreFunctionBuilders.scriptFunction(new Script("1000.0f")))
-                        .boostMode(CombineFunction.REPLACE)).setScoreMode("total");
-        QueryRescorer oneToo = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*one*"), ScoreFunctionBuilders.scriptFunction(new Script("1000.0f")))
-                        .boostMode(CombineFunction.REPLACE)).setScoreMode("total");
-        request.clearRescorers().addRescorer(ninetyIsGood).addRescorer(oneToo, 10);
-        response = request.setSize(2).get();
-        assertFirstHit(response, hasId("91"));
-        assertFirstHit(response, hasScore(2001.0f));
-        assertSecondHit(response, hasScore(1001.0f)); // Not sure which one it is but it is ninety something
-    }
-
-    private int indexRandomNumbers(String analyzer) throws Exception {
-        return indexRandomNumbers(analyzer, -1, true);
-    }
-
-    private int indexRandomNumbers(String analyzer, int shards, boolean dummyDocs) throws Exception {
-        Builder builder = Settings.settingsBuilder().put(indexSettings());
-
-        if (shards > 0) {
-            builder.put(SETTING_NUMBER_OF_SHARDS, shards);
-        }
-
-        assertAcked(prepareCreate("test")
-                .addMapping(
-                        "type1",
-                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
-                                .field("analyzer", analyzer).field("type", "string").endObject().endObject().endObject().endObject())
-                .setSettings(builder));
-        int numDocs = randomIntBetween(100, 150);
-        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
-        for (int i = 0; i < numDocs; i++) {
-            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource("field1", English.intToEnglish(i));
-        }
-
-        indexRandom(true, dummyDocs, docs);
-        ensureGreen();
-        return numDocs;
-    }
-
-    // #11277
-    public void testFromSize() throws Exception {
-        Builder settings = Settings.builder();
-        settings.put(SETTING_NUMBER_OF_SHARDS, 1);
-        settings.put(SETTING_NUMBER_OF_REPLICAS, 0);
-        assertAcked(prepareCreate("test").setSettings(settings));
-        for(int i=0;i<5;i++) {
-            client().prepareIndex("test", "type", ""+i).setSource("text", "hello world").get();
-        }
-        refresh();
-
-        SearchRequestBuilder request = client().prepareSearch();
-        request.setQuery(QueryBuilders.termQuery("text", "hello"));
-        request.setFrom(1);
-        request.setSize(4);
-        request.addRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchAllQuery()));
-        request.setRescoreWindow(50);
-
-        assertEquals(4, request.get().getHits().hits().length);
-    }
-}
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchQueryTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchQueryTests.java
deleted file mode 100644
index 89f0778..0000000
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchQueryTests.java
+++ /dev/null
@@ -1,2268 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.messy.tests;
-
-import org.apache.lucene.util.English;
-import org.elasticsearch.Version;
-import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
-import org.elasticsearch.action.index.IndexRequestBuilder;
-import org.elasticsearch.action.search.SearchPhaseExecutionException;
-import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.action.search.SearchType;
-import org.elasticsearch.action.search.ShardSearchFailure;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.mapper.MapperParsingException;
-import org.elasticsearch.index.query.*;
-import org.elasticsearch.index.search.MatchQuery.Type;
-import org.elasticsearch.index.search.MatchQuery;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
-import org.elasticsearch.plugins.Plugin;
-import org.elasticsearch.rest.RestStatus;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.script.groovy.GroovyPlugin;
-import org.elasticsearch.search.SearchHit;
-import org.elasticsearch.search.SearchHits;
-import org.elasticsearch.search.aggregations.AggregationBuilders;
-import org.elasticsearch.test.ESIntegTestCase;
-import org.joda.time.DateTime;
-import org.joda.time.DateTimeZone;
-import org.joda.time.format.ISODateTimeFormat;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Random;
-import java.util.concurrent.ExecutionException;
-
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
-import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.*;
-import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
-import static org.elasticsearch.test.VersionUtils.randomVersion;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
-import static org.hamcrest.Matchers.*;
-
-public class SearchQueryTests extends ESIntegTestCase {
-
-    @Override
-    protected Collection<Class<? extends Plugin>> nodePlugins() {
-        return Collections.singleton(GroovyPlugin.class);
-    }
-    
-    @Override
-    protected int maximumNumberOfShards() {
-        return 7;
-    }
-
-    @Override
-    protected int maximumNumberOfReplicas() {
-        return Math.min(2, cluster().numDataNodes() - 1);
-    }
-
-    @Test
-    public void testOmitNormsOnAll() throws ExecutionException, InterruptedException, IOException {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
-                        .startObject("_all").field("omit_norms", true).endObject()
-                        .endObject().endObject())
-                .setSettings(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)); // only one shard otherwise IDF might be different for comparing scores
-
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
-                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
-
-        assertHitCount(client().prepareSearch().setQuery(matchQuery("_all", "quick")).get(), 3l);
-        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("_all", "quick")).setExplain(true).get();
-        SearchHit[] hits = searchResponse.getHits().hits();
-        assertThat(hits.length, equalTo(3));
-        assertThat(hits[0].score(), allOf(equalTo(hits[1].getScore()), equalTo(hits[2].getScore())));
-        cluster().wipeIndices("test");
-
-        createIndex("test");
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
-                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
-
-        assertHitCount(client().prepareSearch().setQuery(matchQuery("_all", "quick")).get(), 3l);
-        searchResponse = client().prepareSearch().setQuery(matchQuery("_all", "quick")).get();
-        hits = searchResponse.getHits().hits();
-        assertThat(hits.length, equalTo(3));
-        assertThat(hits[0].score(), allOf(greaterThan(hits[1].getScore()), greaterThan(hits[2].getScore())));
-
-    }
-    @Test // see #3952
-    public void testEmptyQueryString() throws ExecutionException, InterruptedException, IOException {
-        createIndex("test");
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
-                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
-
-        assertHitCount(client().prepareSearch().setQuery(queryStringQuery("quick")).get(), 3l);
-        assertHitCount(client().prepareSearch().setQuery(queryStringQuery("")).get(), 0l); // return no docs
-    }
-
-    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3177
-    public void testIssue3177() {
-        createIndex("test");
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "value2").get();
-        client().prepareIndex("test", "type1", "3").setSource("field1", "value3").get();
-        ensureGreen();
-        waitForRelocation();
-        optimize();
-        refresh();
-        assertHitCount(
-                client().prepareSearch()
-                        .setQuery(matchAllQuery())
-                        .setPostFilter(
-                                boolQuery().must(
-                                        matchAllQuery()).must(
-                                        notQuery(boolQuery().must(termQuery("field1", "value1")).must(
-                                                termQuery("field1", "value2"))))).get(),
-                3l);
-        assertHitCount(
-                client().prepareSearch()
-                        .setQuery(
-                                boolQuery().must(
-                                        boolQuery().should(termQuery("field1", "value1")).should(termQuery("field1", "value2"))
-                                                .should(termQuery("field1", "value3"))).filter(
-                                        notQuery(boolQuery().must(termQuery("field1", "value1")).must(
-                                                termQuery("field1", "value2"))))).get(),
-                3l);
-        assertHitCount(
-                client().prepareSearch().setQuery(matchAllQuery()).setPostFilter(notQuery(termQuery("field1", "value3"))).get(),
-                2l);
-    }
-
-    @Test
-    public void passQueryAsStringTest() throws Exception {
-        createIndex("test");
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1_1", "field2", "value2_1").setRefresh(true).get();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery("{ \"term\" : { \"field1\" : \"value1_1\" }}").get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testIndexOptions() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1", "field1", "type=string,index_options=docs"));
-        indexRandom(true,
-                client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(Type.PHRASE).slop(0)).get();
-        assertHitCount(searchResponse, 1l);
-
-        assertFailures(client().prepareSearch().setQuery(matchQuery("field1", "quick brown").type(Type.PHRASE).slop(0)),
-                    RestStatus.INTERNAL_SERVER_ERROR,
-                    containsString("field \"field1\" was indexed without position data; cannot run PhraseQuery"));
-    }
-
-    @Test // see #3521
-    public void testConstantScoreQuery() throws Exception {
-        Random random = getRandom();
-        createIndex("test");
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"), client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("field1", "quick"))).get();
-        assertHitCount(searchResponse, 2l);
-        for (SearchHit searchHit : searchResponse.getHits().hits()) {
-            assertSearchHit(searchHit, hasScore(1.0f));
-        }
-
-        searchResponse = client().prepareSearch("test").setQuery(
-                boolQuery().must(matchAllQuery()).must(
-                constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + getRandom().nextFloat()))).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
-
-        client().prepareSearch("test").setQuery(constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + getRandom().nextFloat())).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
-
-        searchResponse = client().prepareSearch("test").setQuery(
-                constantScoreQuery(boolQuery().must(matchAllQuery()).must(
-                constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + (random.nextBoolean()? 0.0f : random.nextFloat()))))).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
-        for (SearchHit searchHit : searchResponse.getHits().hits()) {
-            assertSearchHit(searchHit, hasScore(1.0f));
-        }
-
-        int num = scaledRandomIntBetween(100, 200);
-        IndexRequestBuilder[] builders = new IndexRequestBuilder[num];
-        for (int i = 0; i < builders.length; i++) {
-            builders[i] = client().prepareIndex("test", "type", "" + i).setSource("f", English.intToEnglish(i));
-        }
-        createIndex("test_1");
-        indexRandom(true, builders);
-
-        int queryRounds = scaledRandomIntBetween(10, 20);
-        for (int i = 0; i < queryRounds; i++) {
-            MatchQueryBuilder matchQuery = matchQuery("f", English.intToEnglish(between(0, num)));
-            searchResponse = client().prepareSearch("test_1").setQuery(matchQuery).setSize(num).get();
-            long totalHits = searchResponse.getHits().totalHits();
-            SearchHits hits = searchResponse.getHits();
-            for (SearchHit searchHit : hits) {
-                assertSearchHit(searchHit, hasScore(1.0f));
-            }
-            searchResponse = client().prepareSearch("test_1").setQuery(
-                    boolQuery().must(matchAllQuery()).must(
-                    constantScoreQuery(matchQuery).boost(1.0f + (random.nextBoolean()? 0.0f : random.nextFloat())))).setSize(num).get();
-            hits = searchResponse.getHits();
-            assertThat(hits.totalHits(), equalTo(totalHits));
-            if (totalHits > 1) {
-                float expected = hits.getAt(0).score();
-                for (SearchHit searchHit : hits) {
-                    assertSearchHit(searchHit, hasScore(expected));
-                }
-            }
-        }
-    }
-
-    @Test // see #3521
-    public void testAllDocsQueryString() throws InterruptedException, ExecutionException {
-        createIndex("test");
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("foo", "bar"),
-                client().prepareIndex("test", "type1", "2").setSource("foo", "bar")
-        );
-
-        int iters = scaledRandomIntBetween(100, 200);
-        for (int i = 0; i < iters; i++) {
-            SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("*:*^10.0").boost(10.0f)).get();
-            assertHitCount(searchResponse, 2l);
-
-            searchResponse = client().prepareSearch("test").setQuery(
-                    boolQuery().must(matchAllQuery()).must(constantScoreQuery(matchAllQuery()))).get();
-            assertHitCount(searchResponse, 2l);
-            assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(Math.sqrt(2), 0.1));
-            assertThat((double)searchResponse.getHits().getAt(1).score(),closeTo(Math.sqrt(2), 0.1));
-        }
-    }
-
-    @Test
-    public void testCommonTermsQueryOnAllField() throws Exception {
-        client().admin().indices().prepareCreate("test")
-                .addMapping("type1", "message", "type=string", "comment", "type=string,boost=5.0")
-                .setSettings(SETTING_NUMBER_OF_SHARDS, 1).get();
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("message", "test message", "comment", "whatever"),
-                client().prepareIndex("test", "type1", "2").setSource("message", "hello world", "comment", "test comment"));
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("_all", "test")).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("2"));
-        assertSecondHit(searchResponse, hasId("1"));
-        assertThat(searchResponse.getHits().getHits()[0].getScore(), greaterThan(searchResponse.getHits().getHits()[1].getScore()));
-    }
-
-    @Test
-    public void testCommonTermsQuery() throws Exception {
-        client().admin().indices().prepareCreate("test")
-                .addMapping("type1", "field1", "type=string,analyzer=whitespace")
-                .setSettings(SETTING_NUMBER_OF_SHARDS, 1).get();
-        indexRandom(true, client().prepareIndex("test", "type1", "3").setSource("field1", "quick lazy huge brown pidgin", "field2", "the quick lazy huge brown fox jumps over the tree"),
-                client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree") );
-
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).lowFreqOperator(Operator.OR)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).lowFreqOperator(Operator.AND)).get();
-        assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        // Default
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the huge fox").lowFreqMinimumShouldMatch("2")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("3")).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("4")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 4 } } } }").get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        // Default
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).analyzer("stop")).get();
-        assertHitCount(searchResponse, 3l);
-        // stop drops "the" since its a stopword
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("3"));
-        assertThirdHit(searchResponse, hasId("2"));
-
-        // try the same with match query
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.OR)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
-        assertHitCount(searchResponse, 3l);
-        // stop drops "the" since its a stopword
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("3"));
-        assertThirdHit(searchResponse, hasId("2"));
-
-        // try the same with multi match query
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the quick brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
-        assertSecondHit(searchResponse, hasId("1"));
-        assertThirdHit(searchResponse, hasId("2"));
-    }
-
-    @Test
-    public void testCommonTermsQueryStackedTokens() throws Exception {
-        assertAcked(prepareCreate("test")
-                .setSettings(settingsBuilder()
-                        .put(indexSettings())
-                        .put(SETTING_NUMBER_OF_SHARDS,1)
-                        .put("index.analysis.filter.syns.type","synonym")
-                        .putArray("index.analysis.filter.syns.synonyms","quick,fast")
-                        .put("index.analysis.analyzer.syns.tokenizer","whitespace")
-                        .put("index.analysis.analyzer.syns.filter","syns")
-                        )
-                .addMapping("type1", "field1", "type=string,analyzer=syns", "field2", "type=string,analyzer=syns"));
-
-        indexRandom(true, client().prepareIndex("test", "type1", "3").setSource("field1", "quick lazy huge brown pidgin", "field2", "the quick lazy huge brown fox jumps over the tree"),
-                client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree") );
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3).lowFreqOperator(Operator.OR)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3).lowFreqOperator(Operator.AND)).get();
-        assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        // Default
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast huge fox").lowFreqMinimumShouldMatch("3")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("5")).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("6")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the fast lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 6 } } } }").get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        // Default
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).analyzer("stop")).get();
-        assertHitCount(searchResponse, 3l);
-        // stop drops "the" since its a stopword
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("3"));
-        assertThirdHit(searchResponse, hasId("2"));
-
-        // try the same with match query
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.OR)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
-        assertHitCount(searchResponse, 3l);
-        // stop drops "the" since its a stopword
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("3"));
-        assertThirdHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).minimumShouldMatch("3")).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        // try the same with multi match query
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the fast brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
-        assertSecondHit(searchResponse, hasId("1"));
-        assertThirdHit(searchResponse, hasId("2"));
-    }
-
-    @Test
-    public void testOmitTermFreqsAndPositions() throws Exception {
-        cluster().wipeTemplates(); // no randomized template for this test -- we are testing bwc compat and set version explicitly this might cause failures if an unsupported feature
-                                   // is added randomly via an index template.
-        Version version = Version.CURRENT;
-        int iters = scaledRandomIntBetween(10, 20);
-        for (int i = 0; i < iters; i++) {
-            try {
-                // backwards compat test!
-                assertAcked(client().admin().indices().prepareCreate("test")
-                        .addMapping("type1", "field1", "type=string,omit_term_freq_and_positions=true")
-                        .setSettings(settings(version).put(SETTING_NUMBER_OF_SHARDS, 1)));
-                assertThat(version.onOrAfter(Version.V_1_0_0_RC2), equalTo(false));
-                indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"),
-                        client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
-
-
-                SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(Type.PHRASE).slop(0)).get();
-                assertHitCount(searchResponse, 1l);
-                try {
-                    client().prepareSearch().setQuery(matchQuery("field1", "quick brown").type(Type.PHRASE).slop(0)).get();
-                    fail("SearchPhaseExecutionException should have been thrown");
-                } catch (SearchPhaseExecutionException e) {
-                    assertTrue(e.toString().contains("IllegalStateException[field \"field1\" was indexed without position data; cannot run PhraseQuery"));
-                }
-                cluster().wipeIndices("test");
-            } catch (MapperParsingException ex) {
-                assertThat(version.toString(), version.onOrAfter(Version.V_1_0_0_RC2), equalTo(true));
-                assertThat(ex.getCause().getMessage(), equalTo("'omit_term_freq_and_positions' is not supported anymore - use ['index_options' : 'docs']  instead"));
-            }
-            version = randomVersion(random());
-        }
-    }
-
-    @Test
-    public void queryStringAnalyzedWildcard() throws Exception {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value_1", "field2", "value_2").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("value*").analyzeWildcard(true)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("*ue*").analyzeWildcard(true)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("*ue_1").analyzeWildcard(true)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("val*e_1").analyzeWildcard(true)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("v?l*e?1").analyzeWildcard(true)).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testLowercaseExpandedTerms() {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value_1", "field2", "value_2").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("VALUE_3~1").lowercaseExpandedTerms(true)).get();
-        assertHitCount(searchResponse, 1l);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("VALUE_3~1").lowercaseExpandedTerms(false)).get();
-        assertHitCount(searchResponse, 0l);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("ValUE_*").lowercaseExpandedTerms(true)).get();
-        assertHitCount(searchResponse, 1l);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("vAl*E_1")).get();
-        assertHitCount(searchResponse, 1l);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("[VALUE_1 TO VALUE_3]")).get();
-        assertHitCount(searchResponse, 1l);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("[VALUE_1 TO VALUE_3]").lowercaseExpandedTerms(false)).get();
-        assertHitCount(searchResponse, 0l);
-    }
-
-    @Test //https://github.com/elasticsearch/elasticsearch/issues/3540
-    public void testDateRangeInQueryString() {
-        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
-        //as with dynamic mappings some shards might be lacking behind and parse a different query
-        assertAcked(prepareCreate("test").addMapping(
-                "type", "past", "type=date", "future", "type=date"
-        ));
-
-        String aMonthAgo = ISODateTimeFormat.yearMonthDay().print(new DateTime(DateTimeZone.UTC).minusMonths(1));
-        String aMonthFromNow = ISODateTimeFormat.yearMonthDay().print(new DateTime(DateTimeZone.UTC).plusMonths(1));
-        client().prepareIndex("test", "type", "1").setSource("past", aMonthAgo, "future", aMonthFromNow).get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("past:[now-2M/d TO now/d]")).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("future:[now/d TO now+2M/d]").lowercaseExpandedTerms(false)).get();
-        assertHitCount(searchResponse, 1l);
-
-        try {
-            client().prepareSearch().setQuery(queryStringQuery("future:[now/D TO now+2M/d]").lowercaseExpandedTerms(false)).get();
-            fail("expected SearchPhaseExecutionException (total failure)");
-        } catch (SearchPhaseExecutionException e) {
-            assertThat(e.status(), equalTo(RestStatus.BAD_REQUEST));
-            assertThat(e.toString(), containsString("unit [D] not supported for date math"));
-        }
-    }
-
-    @Test // https://github.com/elasticsearch/elasticsearch/issues/7880
-    public void testDateRangeInQueryStringWithTimeZone_7880() {
-        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
-        //as with dynamic mappings some shards might be lacking behind and parse a different query
-        assertAcked(prepareCreate("test").addMapping(
-                "type", "past", "type=date"
-        ));
-
-        DateTimeZone timeZone = randomDateTimeZone();
-        String now = ISODateTimeFormat.dateTime().print(new DateTime(timeZone));
-        logger.info(" --> Using time_zone [{}], now is [{}]", timeZone.getID(), now);
-        client().prepareIndex("test", "type", "1").setSource("past", now).get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("past:[now-1m/m TO now+1m/m]")
-                .timeZone(timeZone.getID())).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test // https://github.com/elasticsearch/elasticsearch/issues/10477
-    public void testDateRangeInQueryStringWithTimeZone_10477() {
-        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
-        //as with dynamic mappings some shards might be lacking behind and parse a different query
-        assertAcked(prepareCreate("test").addMapping(
-                "type", "past", "type=date"
-        ));
-
-        client().prepareIndex("test", "type", "1").setSource("past", "2015-04-05T23:00:00+0000").get();
-        client().prepareIndex("test", "type", "2").setSource("past", "2015-04-06T00:00:00+0000").get();
-        refresh();
-
-        // Timezone set with dates
-        SearchResponse searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00+0200 TO 2015-04-06T23:00:00+0200]"))
-                .get();
-        assertHitCount(searchResponse, 2l);
-
-        // Same timezone set with time_zone
-        searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00 TO 2015-04-06T23:00:00]").timeZone("+0200"))
-                .get();
-        assertHitCount(searchResponse, 2l);
-
-        // We set a timezone which will give no result
-        searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00-0200 TO 2015-04-06T23:00:00-0200]"))
-                .get();
-        assertHitCount(searchResponse, 0l);
-
-        // Same timezone set with time_zone but another timezone is set directly within dates which has the precedence
-        searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00-0200 TO 2015-04-06T23:00:00-0200]").timeZone("+0200"))
-                .get();
-        assertHitCount(searchResponse, 0l);
-    }
-
-    @Test
-    public void typeFilterTypeIndexedTests() throws Exception {
-        typeFilterTests("not_analyzed");
-    }
-
-    @Test
-    public void typeFilterTypeNotIndexedTests() throws Exception {
-        typeFilterTests("no");
-    }
-
-    private void typeFilterTests(String index) throws Exception {
-        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
-        assertAcked(prepareCreate("test").setSettings(indexSettings)
-                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
-                        .startObject("_type").field("index", index).endObject()
-                        .endObject().endObject())
-                .addMapping("type2", jsonBuilder().startObject().startObject("type2")
-                        .startObject("_type").field("index", index).endObject()
-                        .endObject().endObject())
-                .setUpdateAllTypes(true));
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "value1"),
-                client().prepareIndex("test", "type2", "1").setSource("field1", "value1"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "value1"),
-                client().prepareIndex("test", "type2", "2").setSource("field1", "value1"),
-                client().prepareIndex("test", "type2", "3").setSource("field1", "value1"));
-
-        assertHitCount(client().prepareSearch().setQuery(typeQuery("type1")).get(), 2l);
-        assertHitCount(client().prepareSearch().setQuery(typeQuery("type2")).get(), 3l);
-
-        assertHitCount(client().prepareSearch().setTypes("type1").setQuery(matchAllQuery()).get(), 2l);
-        assertHitCount(client().prepareSearch().setTypes("type2").setQuery(matchAllQuery()).get(), 3l);
-
-        assertHitCount(client().prepareSearch().setTypes("type1", "type2").setQuery(matchAllQuery()).get(), 5l);
-    }
-
-    @Test
-    public void idsQueryTestsIdIndexed() throws Exception {
-        idsQueryTests("not_analyzed");
-    }
-
-    @Test
-    public void idsQueryTestsIdNotIndexed() throws Exception {
-        idsQueryTests("no");
-    }
-
-    private void idsQueryTests(String index) throws Exception {
-        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
-        assertAcked(client().admin().indices().prepareCreate("test").setSettings(indexSettings)
-                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
-                        .startObject("_id").field("index", index).endObject()
-                        .endObject().endObject()));
-
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "value1"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "value2"),
-                client().prepareIndex("test", "type1", "3").setSource("field1", "value3"));
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery("type1").ids("1", "3"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        // no type
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery().ids("1", "3"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").ids("1", "3")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        // no type
-        searchResponse = client().prepareSearch().setQuery(idsQuery().ids("1", "3")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").ids("7", "10")).get();
-        assertHitCount(searchResponse, 0l);
-
-        // repeat..., with terms
-        searchResponse = client().prepareSearch().setTypes("type1").setQuery(constantScoreQuery(termsQuery("_id", "1", "3"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-    }
-
-    @Test
-    public void term_indexQueryTestsIndexed() throws Exception {
-        term_indexQueryTests("not_analyzed");
-    }
-
-    @Test
-    public void term_indexQueryTestsNotIndexed() throws Exception {
-        term_indexQueryTests("no");
-    }
-
-    private void term_indexQueryTests(String index) throws Exception {
-        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
-        String[] indexNames = { "test1", "test2" };
-        for (String indexName : indexNames) {
-            assertAcked(client()
-                    .admin()
-                    .indices()
-                    .prepareCreate(indexName)
-                    .setSettings(indexSettings)
-                    .addMapping(
-                            "type1",
-                            jsonBuilder().startObject().startObject("type1").startObject("_index").field("index", index).endObject()
-                                    .endObject().endObject()));
-
-            indexRandom(true, client().prepareIndex(indexName, "type1", indexName + "1").setSource("field1", "value1"));
-
-        }
-
-        for (String indexName : indexNames) {
-            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termQuery("_index", indexName))).get();
-            SearchResponse searchResponse = assertSearchResponse(request);
-            assertHitCount(searchResponse, 1l);
-            assertSearchHits(searchResponse, indexName + "1");
-        }
-        for (String indexName : indexNames) {
-            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termsQuery("_index", indexName))).get();
-            SearchResponse searchResponse = assertSearchResponse(request);
-            assertHitCount(searchResponse, 1l);
-            assertSearchHits(searchResponse, indexName + "1");
-        }
-        for (String indexName : indexNames) {
-            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("_index", indexName))).get();
-            SearchResponse searchResponse = assertSearchResponse(request);
-            assertHitCount(searchResponse, 1l);
-            assertSearchHits(searchResponse, indexName + "1");
-        }
-        {
-            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termsQuery("_index", indexNames))).get();
-            SearchResponse searchResponse = assertSearchResponse(request);
-            assertHitCount(searchResponse, indexNames.length);
-        }
-    }
-
-    @Test
-    public void filterExistsMissingTests() throws Exception {
-        createIndex("test");
-
-        indexRandom(true,
-                client().prepareIndex("test", "type1", "1").setSource(jsonBuilder().startObject().startObject("obj1").field("obj1_val", "1").endObject().field("x1", "x_1").field("field1", "value1_1").field("field2", "value2_1").endObject()),
-                client().prepareIndex("test", "type1", "2").setSource(jsonBuilder().startObject().startObject("obj1").field("obj1_val", "1").endObject().field("x2", "x_2").field("field1", "value1_2").endObject()),
-                client().prepareIndex("test", "type1", "3").setSource(jsonBuilder().startObject().startObject("obj2").field("obj2_val", "1").endObject().field("y1", "y_1").field("field2", "value2_3").endObject()),
-                client().prepareIndex("test", "type1", "4").setSource(jsonBuilder().startObject().startObject("obj2").field("obj2_val", "1").endObject().field("y2", "y_2").field("field3", "value3_4").endObject()) );
-
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(existsQuery("field1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(existsQuery("field1"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("_exists_:field1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        searchResponse = client().prepareSearch().setQuery(existsQuery("field2")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch().setQuery(existsQuery("field3")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("4"));
-
-        // wildcard check
-        searchResponse = client().prepareSearch().setQuery(existsQuery("x*")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        // object check
-        searchResponse = client().prepareSearch().setQuery(existsQuery("obj1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        searchResponse = client().prepareSearch().setQuery(missingQuery("field1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-
-        searchResponse = client().prepareSearch().setQuery(missingQuery("field1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(missingQuery("field1"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("_missing_:field1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-
-        // wildcard check
-        searchResponse = client().prepareSearch().setQuery(missingQuery("x*")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-
-        // object check
-        searchResponse = client().prepareSearch().setQuery(missingQuery("obj1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-    }
-
-    @Test
-    public void passQueryOrFilterAsJSONStringTest() throws Exception {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1_1", "field2", "value2_1").setRefresh(true).get();
-
-        WrapperQueryBuilder wrapper = new WrapperQueryBuilder("{ \"term\" : { \"field1\" : \"value1_1\" } }");
-        assertHitCount(client().prepareSearch().setQuery(wrapper).get(), 1l);
-
-        BoolQueryBuilder bool = boolQuery().must(wrapper).must(new TermQueryBuilder("field2", "value2_1"));
-        assertHitCount(client().prepareSearch().setQuery(bool).get(), 1l);
-
-        WrapperQueryBuilder wrapperFilter = wrapperQuery("{ \"term\" : { \"field1\" : \"value1_1\" } }");
-        assertHitCount(client().prepareSearch().setPostFilter(wrapperFilter).get(), 1l);
-    }
-
-    @Test
-    public void testFiltersWithCustomCacheKey() throws Exception {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
-        refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testMatchQueryNumeric() throws Exception {
-        assertAcked(prepareCreate("test").addMapping("type1", "long", "type=long", "double", "type=double"));
-
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("long", 1l, "double", 1.0d),
-                client().prepareIndex("test", "type1", "2").setSource("long", 2l, "double", 2.0d),
-                client().prepareIndex("test", "type1", "3").setSource("long", 3l, "double", 3.0d));
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("long", "1")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("double", "2")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-        try {
-            client().prepareSearch().setQuery(matchQuery("double", "2 3 4")).get();
-            fail("SearchPhaseExecutionException should have been thrown");
-        } catch (SearchPhaseExecutionException ex) {
-            // number format exception
-        }
-    }
-
-    @Test
-    public void testMultiMatchQuery() throws Exception {
-        createIndex("test");
-
-        indexRandom(true,
-                client().prepareIndex("test", "type1", "1").setSource("field1", "value1", "field2", "value4", "field3", "value3"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "value2", "field2", "value5", "field3", "value2"),
-                client().prepareIndex("test", "type1", "3").setSource("field1", "value3", "field2", "value6", "field3", "value1") );
-
-        MultiMatchQueryBuilder builder = multiMatchQuery("value1 value2 value4", "field1", "field2");
-        SearchResponse searchResponse = client().prepareSearch().setQuery(builder)
-                .addAggregation(AggregationBuilders.terms("field1").field("field1")).get();
-
-        assertHitCount(searchResponse, 2l);
-        // this uses dismax so scores are equal and the order can be arbitrary
-        assertSearchHits(searchResponse, "1", "2");
-
-        builder.useDisMax(false);
-        searchResponse = client().prepareSearch()
-                .setQuery(builder)
-                .get();
-
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        client().admin().indices().prepareRefresh("test").get();
-        builder = multiMatchQuery("value1", "field1", "field2")
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
-        searchResponse = client().prepareSearch()
-                .setQuery(builder)
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        refresh();
-        builder = multiMatchQuery("value1", "field1").field("field3", 1.5f)
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
-        searchResponse = client().prepareSearch().setQuery(builder).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "1");
-
-        client().admin().indices().prepareRefresh("test").get();
-        builder = multiMatchQuery("value1").field("field1").field("field3", 1.5f)
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
-        searchResponse = client().prepareSearch().setQuery(builder).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "1");
-
-        // Test lenient
-        client().prepareIndex("test", "type1", "3").setSource("field1", "value7", "field2", "value8", "field4", 5).get();
-        refresh();
-
-        builder = multiMatchQuery("value1", "field1", "field2", "field4");
-
-        assertFailures(client().prepareSearch().setQuery(builder),
-                RestStatus.BAD_REQUEST,
-                containsString("NumberFormatException[For input string: \"value1\"]"));
-
-        builder.lenient(true);
-        searchResponse = client().prepareSearch().setQuery(builder).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-    }
-
-    @Test
-    public void testMatchQueryZeroTermsQuery() {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1", "field1", "type=string,analyzer=classic", "field2", "type=string,analyzer=classic"));
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "value2").get();
-        refresh();
-
-        BoolQueryBuilder boolQuery = boolQuery()
-                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE))
-                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE));
-        SearchResponse searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 0l);
-
-        boolQuery = boolQuery()
-                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL))
-                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
-        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 1l);
-
-        boolQuery = boolQuery().must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
-        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 2l);
-    }
-
-    public void testMultiMatchQueryZeroTermsQuery() {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1", "field1", "type=string,analyzer=classic", "field2", "type=string,analyzer=classic"));
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1", "field2", "value2").get();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "value3", "field2", "value4").get();
-        refresh();
-
-
-        BoolQueryBuilder boolQuery = boolQuery()
-                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE))
-                .must(multiMatchQuery("value1", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE)); // Fields are ORed together
-        SearchResponse searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 0l);
-
-        boolQuery = boolQuery()
-                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL))
-                .must(multiMatchQuery("value4", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
-        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 1l);
-
-        boolQuery = boolQuery().must(multiMatchQuery("a", "field1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
-        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 2l);
-    }
-
-    @Test
-    public void testMultiMatchQueryMinShouldMatch() {
-        createIndex("test");
-        client().prepareIndex("test", "type1", "1").setSource("field1", new String[]{"value1", "value2", "value3"}).get();
-        client().prepareIndex("test", "type1", "2").setSource("field2", "value1").get();
-        refresh();
-
-        MultiMatchQueryBuilder multiMatchQuery = multiMatchQuery("value1 value2 foo", "field1", "field2");
-
-        multiMatchQuery.useDisMax(true);
-        multiMatchQuery.minimumShouldMatch("70%");
-        SearchResponse searchResponse = client().prepareSearch()
-                .setQuery(multiMatchQuery)
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        multiMatchQuery.minimumShouldMatch("30%");
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        multiMatchQuery.useDisMax(false);
-        multiMatchQuery.minimumShouldMatch("70%");
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        multiMatchQuery.minimumShouldMatch("30%");
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        multiMatchQuery = multiMatchQuery("value1 value2 bar", "field1");
-        multiMatchQuery.minimumShouldMatch("100%");
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
-        assertHitCount(searchResponse, 0l);
-
-        multiMatchQuery.minimumShouldMatch("70%");
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-    }
-
-    @Test
-    public void testFuzzyQueryString() {
-        createIndex("test");
-        client().prepareIndex("test", "type1", "1").setSource("str", "kimchy", "date", "2012-02-01", "num", 12).get();
-        client().prepareIndex("test", "type1", "2").setSource("str", "shay", "date", "2012-02-05", "num", 20).get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("str:kimcy~1")).get();
-        assertNoFailures(searchResponse);
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:11~1")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("date:2012-02-02~1d")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-    }
-
-    @Test
-    public void testQuotedQueryStringWithBoost() throws InterruptedException, ExecutionException {
-        float boost = 10.0f;
-        assertAcked(prepareCreate("test").setSettings(SETTING_NUMBER_OF_SHARDS, 1));
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("important", "phrase match", "less_important", "nothing important"),
-                client().prepareIndex("test", "type1", "2").setSource("important", "nothing important", "less_important", "phrase match")
-        );
-
-
-        SearchResponse searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("\"phrase match\"").field("important", boost).field("less_important")).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(boost * searchResponse.getHits().getAt(1).score(), .1));
-
-        searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("\"phrase match\"").field("important", boost).field("less_important").useDisMax(false)).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(boost * searchResponse.getHits().getAt(1).score(), .1));
-    }
-
-    @Test
-    public void testSpecialRangeSyntaxInQueryString() {
-        createIndex("test");
-        client().prepareIndex("test", "type1", "1").setSource("str", "kimchy", "date", "2012-02-01", "num", 12).get();
-        client().prepareIndex("test", "type1", "2").setSource("str", "shay", "date", "2012-02-05", "num", 20).get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>19")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>20")).get();
-        assertHitCount(searchResponse, 0l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>=20")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>11")).get();
-        assertHitCount(searchResponse, 2l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:<20")).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:<=20")).get();
-        assertHitCount(searchResponse, 2l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("+num:>11 +num:<20")).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testEmptytermsQuery() throws Exception {
-        assertAcked(prepareCreate("test").addMapping("type", "term", "type=string"));
-
-        indexRandom(true, client().prepareIndex("test", "type", "1").setSource("term", "1"),
-                client().prepareIndex("test", "type", "2").setSource("term", "2"),
-                client().prepareIndex("test", "type", "3").setSource("term", "3"),
-                client().prepareIndex("test", "type", "4").setSource("term", "4") );
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("term", new String[0]))).get();
-        assertHitCount(searchResponse, 0l);
-
-        searchResponse = client().prepareSearch("test").setQuery(idsQuery()).get();
-        assertHitCount(searchResponse, 0l);
-    }
-
-    @Test
-    public void testTermsQuery() throws Exception {
-        assertAcked(prepareCreate("test").addMapping("type", "str", "type=string", "lng", "type=long", "dbl", "type=double"));
-
-        indexRandom(true,
-                client().prepareIndex("test", "type", "1").setSource("str", "1", "lng", 1l, "dbl", 1.0d),
-                client().prepareIndex("test", "type", "2").setSource("str", "2", "lng", 2l, "dbl", 2.0d),
-                client().prepareIndex("test", "type", "3").setSource("str", "3", "lng", 3l, "dbl", 3.0d),
-                client().prepareIndex("test", "type", "4").setSource("str", "4", "lng", 4l, "dbl", 4.0d));
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("str", "1", "4"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "4");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {2, 3}))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "2", "3");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("dbl", new double[]{2, 3}))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "2", "3");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("lng", new int[] {1, 3}))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("dbl", new float[] {2, 4}))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "2", "4");
-
-        // test partial matching
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("str", "2", "5"))).get();
-        assertNoFailures(searchResponse);
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("dbl", new double[] {2, 5}))).get();
-        assertNoFailures(searchResponse);
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {2, 5}))).get();
-        assertNoFailures(searchResponse);
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        // test valid type, but no matching terms
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("str", "5", "6"))).get();
-        assertHitCount(searchResponse, 0l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("dbl", new double[] {5, 6}))).get();
-        assertHitCount(searchResponse, 0l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {5, 6}))).get();
-        assertHitCount(searchResponse, 0l);
-    }
-
-    @Test
-    public void testTermsLookupFilter() throws Exception {
-        assertAcked(prepareCreate("lookup").addMapping("type", "terms","type=string", "other", "type=string"));
-        assertAcked(prepareCreate("lookup2").addMapping("type",
-                jsonBuilder().startObject().startObject("type").startObject("properties")
-                        .startObject("arr").startObject("properties").startObject("term").field("type", "string")
-                        .endObject().endObject().endObject().endObject().endObject().endObject()));
-        assertAcked(prepareCreate("test").addMapping("type", "term", "type=string"));
-
-        indexRandom(true,
-                client().prepareIndex("lookup", "type", "1").setSource("terms", new String[]{"1", "3"}),
-                client().prepareIndex("lookup", "type", "2").setSource("terms", new String[]{"2"}),
-                client().prepareIndex("lookup", "type", "3").setSource("terms", new String[]{"2", "4"}),
-                client().prepareIndex("lookup", "type", "4").setSource("other", "value"),
-                client().prepareIndex("lookup2", "type", "1").setSource(XContentFactory.jsonBuilder().startObject()
-                        .startArray("arr")
-                        .startObject().field("term", "1").endObject()
-                        .startObject().field("term", "3").endObject()
-                        .endArray()
-                        .endObject()),
-                client().prepareIndex("lookup2", "type", "2").setSource(XContentFactory.jsonBuilder().startObject()
-                        .startArray("arr")
-                        .startObject().field("term", "2").endObject()
-                        .endArray()
-                        .endObject()),
-                client().prepareIndex("lookup2", "type", "3").setSource(XContentFactory.jsonBuilder().startObject()
-                        .startArray("arr")
-                        .startObject().field("term", "2").endObject()
-                        .startObject().field("term", "4").endObject()
-                        .endArray()
-                        .endObject()),
-                client().prepareIndex("test", "type", "1").setSource("term", "1"),
-                client().prepareIndex("test", "type", "2").setSource("term", "2"),
-                client().prepareIndex("test", "type", "3").setSource("term", "3"),
-                client().prepareIndex("test", "type", "4").setSource("term", "4") );
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term" , new TermsLookup("lookup", "type", "1", "terms"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        // same as above, just on the _id...
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("_id", new TermsLookup("lookup", "type", "1", "terms"))
-                ).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        // another search with same parameters...
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "1", "terms"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "2", "terms"))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "3", "terms"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "2", "4");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "4", "terms"))).get();
-        assertHitCount(searchResponse, 0l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "1", "arr.term"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "2", "arr.term"))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "3", "arr.term"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "2", "4");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("not_exists", new TermsLookup("lookup2", "type", "3", "arr.term"))).get();
-        assertHitCount(searchResponse, 0l);
-    }
-
-    @Test
-    public void testBasicFilterById() throws Exception {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
-        client().prepareIndex("test", "type2", "2").setSource("field1", "value2").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setPostFilter(idsQuery("type1").ids("1")).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery("type1", "type2").ids("1", "2"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(2));
-
-        searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setPostFilter(idsQuery().ids("1")).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        searchResponse = client().prepareSearch().setQuery(matchAllQuery()).setPostFilter(idsQuery().ids("1", "2")).get();
-        assertHitCount(searchResponse, 2l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(2));
-
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery().ids("1", "2"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(2));
-
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery("type1").ids("1", "2"))).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery().ids("1"))).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        // TODO: why do we even support passing null??
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery((String[])null).ids("1"))).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery("type1", "type2", "type3").ids("1", "2", "3", "4"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(2));
-    }
-
-    @Test
-    public void testBasicQueryById() throws Exception {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
-        client().prepareIndex("test", "type2", "2").setSource("field1", "value2").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(idsQuery("type1", "type2").ids("1", "2")).get();
-        assertHitCount(searchResponse, 2l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(2));
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery().ids("1")).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery().ids("1", "2")).get();
-        assertHitCount(searchResponse, 2l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(2));
-
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").ids("1", "2")).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery().ids("1")).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery((String[])null).ids("1")).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery("type1", "type2", "type3").ids("1", "2", "3", "4")).get();
-        assertHitCount(searchResponse, 2l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(2));
-    }
-
-    @Test
-    public void testNumericTermsAndRanges() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1",
-                        "num_byte", "type=byte", "num_short", "type=short",
-                        "num_integer", "type=integer", "num_long", "type=long",
-                        "num_float", "type=float", "num_double", "type=double"));
-
-        client().prepareIndex("test", "type1", "1").setSource("num_byte", 1, "num_short", 1, "num_integer", 1,
-                "num_long", 1, "num_float", 1, "num_double", 1).get();
-
-        client().prepareIndex("test", "type1", "2").setSource("num_byte", 2, "num_short", 2, "num_integer", 2,
-                "num_long", 2, "num_float", 2, "num_double", 2).get();
-
-        client().prepareIndex("test", "type1", "17").setSource("num_byte", 17, "num_short", 17, "num_integer", 17,
-                "num_long", 17, "num_float", 17, "num_double", 17).get();
-        refresh();
-
-        SearchResponse searchResponse;
-        logger.info("--> term query on 1");
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_byte", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_short", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_integer", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_long", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_float", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_double", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        logger.info("--> terms query on 1");
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_byte", new int[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_short", new int[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_integer", new int[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_long", new int[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_float", new double[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_double", new double[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        logger.info("--> term filter on 1");
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_byte", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_short", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_integer", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_long", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_float", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_double", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        logger.info("--> terms filter on 1");
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_byte", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_short", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_integer", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_long", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_float", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_double", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-    }
-
-    @Test
-    public void testNumericRangeFilter_2826() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1",
-                        "num_byte", "type=byte", "num_short", "type=short",
-                        "num_integer", "type=integer", "num_long", "type=long",
-                        "num_float", "type=float", "num_double", "type=double"));
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "test1", "num_long", 1).get();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "test1", "num_long", 2).get();
-        client().prepareIndex("test", "type1", "3").setSource("field1", "test2", "num_long", 3).get();
-        client().prepareIndex("test", "type1", "4").setSource("field1", "test2", "num_long", 4).get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch("test").setPostFilter(
-                boolQuery()
-                        .should(rangeQuery("num_long").from(1).to(2))
-                        .should(rangeQuery("num_long").from(3).to(4))
-        ).get();
-        assertHitCount(searchResponse, 4l);
-
-        // This made 2826 fail! (only with bit based filters)
-        searchResponse = client().prepareSearch("test").setPostFilter(
-                boolQuery()
-                        .should(rangeQuery("num_long").from(1).to(2))
-                        .should(rangeQuery("num_long").from(3).to(4))
-        ).get();
-        assertHitCount(searchResponse, 4l);
-
-        // This made #2979 fail!
-        searchResponse = client().prepareSearch("test").setPostFilter(
-                boolQuery()
-                        .must(termQuery("field1", "test1"))
-                        .should(rangeQuery("num_long").from(1).to(2))
-                        .should(rangeQuery("num_long").from(3).to(4))
-        ).get();
-        assertHitCount(searchResponse, 2l);
-    }
-
-    @Test
-    public void testEmptyTopLevelFilter() {
-        client().prepareIndex("test", "type", "1").setSource("field", "value").setRefresh(true).get();
-
-        SearchResponse searchResponse = client().prepareSearch().setPostFilter("{}").get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test // see #2926
-    public void testMustNot() throws IOException, ExecutionException, InterruptedException {
-        assertAcked(prepareCreate("test")
-                //issue manifested only with shards>=2
-                .setSettings(SETTING_NUMBER_OF_SHARDS, between(2, DEFAULT_MAX_NUM_SHARDS)));
-
-
-        indexRandom(true, client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar"),
-                client().prepareIndex("test", "test", "2").setSource("description", "foo other anything"),
-                client().prepareIndex("test", "test", "3").setSource("description", "foo other"),
-                client().prepareIndex("test", "test", "4").setSource("description", "foo"));
-
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchAllQuery())
-                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH).get();
-        assertHitCount(searchResponse, 4l);
-
-        searchResponse = client().prepareSearch("test").setQuery(
-                boolQuery()
-                        .mustNot(matchQuery("description", "anything").type(Type.BOOLEAN))
-        ).setSearchType(SearchType.DFS_QUERY_THEN_FETCH).get();
-        assertHitCount(searchResponse, 2l);
-    }
-
-    @Test // see #2994
-    public void testSimpleSpan() throws IOException, ExecutionException, InterruptedException {
-        createIndex("test");
-
-
-        indexRandom(true, client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar"),
-                client().prepareIndex("test", "test", "2").setSource("description", "foo other anything"),
-                client().prepareIndex("test", "test", "3").setSource("description", "foo other"),
-                client().prepareIndex("test", "test", "4").setSource("description", "foo"));
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanTermQuery("description", "bar"))).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test").setQuery(
-                spanNearQuery(spanTermQuery("description", "foo"), 3)
-                        .clause(spanTermQuery("description", "other"))).get();
-        assertHitCount(searchResponse, 3l);
-    }
-
-    @Test
-    public void testSpanMultiTermQuery() throws IOException {
-        createIndex("test");
-
-        client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar", "count", 1).get();
-        client().prepareIndex("test", "test", "2").setSource("description", "foo other anything", "count", 2).get();
-        client().prepareIndex("test", "test", "3").setSource("description", "foo other", "count", 3).get();
-        client().prepareIndex("test", "test", "4").setSource("description", "fop", "count", 4).get();
-        refresh();
-
-        SearchResponse response = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(fuzzyQuery("description", "fop")))).get();
-        assertHitCount(response, 4);
-
-        response = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(prefixQuery("description", "fo")))).get();
-        assertHitCount(response, 4);
-
-        response = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(wildcardQuery("description", "oth*")))).get();
-        assertHitCount(response, 3);
-
-        response = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(QueryBuilders.rangeQuery("description").from("ffa").to("foo"))))
-                .execute().actionGet();
-        assertHitCount(response, 3);
-
-        response = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(regexpQuery("description", "fo{2}")))).get();
-        assertHitCount(response, 3);
-    }
-
-    @Test
-    public void testSpanNot() throws IOException, ExecutionException, InterruptedException {
-        createIndex("test");
-
-        client().prepareIndex("test", "test", "1").setSource("description", "the quick brown fox jumped over the lazy dog").get();
-        client().prepareIndex("test", "test", "2").setSource("description", "the quick black fox leaped over the sleeping dog").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "brown"))).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "sleeping")).dist(5)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "jumped")).pre(1).post(1)).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testSimpleDFSQuery() throws IOException {
-        assertAcked(prepareCreate("test")
-            .addMapping("s", jsonBuilder()
-                .startObject()
-                .startObject("s")
-                .startObject("_routing")
-                .field("required", true)
-                .endObject()
-                .startObject("properties")
-                .startObject("online")
-                .field("type", "boolean")
-                .endObject()
-                .startObject("ts")
-                .field("type", "date")
-                .field("ignore_malformed", false)
-                .field("format", "epoch_millis")
-                .endObject()
-                .startObject("bs")
-                .field("type", "string")
-                .field("index", "not_analyzed")
-                .endObject()
-                .endObject()
-                .endObject()
-                .endObject())
-            .addMapping("bs", "online", "type=boolean", "ts", "type=date,ignore_malformed=false,format=epoch_millis"));
-
-
-        client().prepareIndex("test", "s", "1").setRouting("Y").setSource("online", false, "bs", "Y", "ts", System.currentTimeMillis() - 100).get();
-        client().prepareIndex("test", "s", "2").setRouting("X").setSource("online", true, "bs", "X", "ts", System.currentTimeMillis() - 10000000).get();
-        client().prepareIndex("test", "bs", "3").setSource("online", false, "ts", System.currentTimeMillis() - 100).get();
-        client().prepareIndex("test", "bs", "4").setSource("online", true, "ts", System.currentTimeMillis() - 123123).get();
-        refresh();
-
-        SearchResponse response = client().prepareSearch("test")
-                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                .setQuery(
-                        boolQuery()
-                                .must(termQuery("online", true))
-                                .must(boolQuery()
-                                        .should(boolQuery()
-                                                .must(rangeQuery("ts").lt(System.currentTimeMillis() - (15 * 1000)))
-                                                .must(termQuery("_type", "bs"))
-                                        )
-                                        .should(boolQuery()
-                                                .must(rangeQuery("ts").lt(System.currentTimeMillis() - (15 * 1000)))
-                                                .must(termQuery("_type", "s"))
-                                        )
-                                )
-                )
-                .setVersion(true)
-                .setFrom(0).setSize(100).setExplain(true).get();
-        assertNoFailures(response);
-    }
-
-    @Test
-    public void testMultiFieldQueryString() {
-        client().prepareIndex("test", "s", "1").setSource("field1", "value1", "field2", "value2").setRefresh(true).get();
-
-        logger.info("regular");
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value1").field("field1").field("field2")).get(), 1);
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value1")).get(), 1);
-        logger.info("prefix");
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value*").field("field1").field("field2")).get(), 1);
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value*")).get(), 1);
-        logger.info("wildcard");
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("v?lue*").field("field1").field("field2")).get(), 1);
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:v?lue*")).get(), 1);
-        logger.info("fuzzy");
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value~").field("field1").field("field2")).get(), 1);
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value~")).get(), 1);
-        logger.info("regexp");
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("/value[01]/").field("field1").field("field2")).get(), 1);
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:/value[01]/")).get(), 1);
-    }
-
-    // see #3881 - for extensive description of the issue
-    @Test
-    public void testMatchQueryWithSynonyms() throws IOException {
-        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
-                .put(indexSettings())
-                .put("index.analysis.analyzer.index.type", "custom")
-                .put("index.analysis.analyzer.index.tokenizer", "standard")
-                .put("index.analysis.analyzer.index.filter", "lowercase")
-                .put("index.analysis.analyzer.search.type", "custom")
-                .put("index.analysis.analyzer.search.tokenizer", "standard")
-                .putArray("index.analysis.analyzer.search.filter", "lowercase", "synonym")
-                .put("index.analysis.filter.synonym.type", "synonym")
-                .putArray("index.analysis.filter.synonym.synonyms", "fast, quick"));
-        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
-
-        client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
-        refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fast").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-
-        client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
-        refresh();
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2);
-    }
-
-    @Test
-    public void testMatchQueryWithStackedStems() throws IOException {
-        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
-                .put(indexSettings())
-                .put("index.analysis.analyzer.index.type", "custom")
-                .put("index.analysis.analyzer.index.tokenizer", "standard")
-                .put("index.analysis.analyzer.index.filter", "lowercase")
-                .put("index.analysis.analyzer.search.type", "custom")
-                .put("index.analysis.analyzer.search.tokenizer", "standard")
-                .putArray("index.analysis.analyzer.search.filter", "lowercase", "keyword_repeat", "porterStem", "unique_stem")
-                .put("index.analysis.filter.unique_stem.type", "unique")
-                .put("index.analysis.filter.unique_stem.only_on_same_position", true));
-        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
-
-        client().prepareIndex("test", "test", "1").setSource("text", "the fox runs across the street").get();
-        refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-
-        client().prepareIndex("test", "test", "2").setSource("text", "run fox run").get();
-        refresh();
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2);
-    }
-
-    @Test
-    public void testQueryStringWithSynonyms() throws IOException {
-        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
-                .put(indexSettings())
-                .put("index.analysis.analyzer.index.type", "custom")
-                .put("index.analysis.analyzer.index.tokenizer", "standard")
-                .put("index.analysis.analyzer.index.filter", "lowercase")
-                .put("index.analysis.analyzer.search.type", "custom")
-                .put("index.analysis.analyzer.search.tokenizer", "standard")
-                .putArray("index.analysis.analyzer.search.filter", "lowercase", "synonym")
-                .put("index.analysis.filter.synonym.type", "synonym")
-                .putArray("index.analysis.filter.synonym.synonyms", "fast, quick"));
-        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
-
-        client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("fast").defaultField("text").defaultOperator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-
-        client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
-        refresh();
-
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2);
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2);
-    }
-
-    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3898
-    public void testCustomWordDelimiterQueryString() {
-        assertAcked(client().admin().indices().prepareCreate("test")
-                .setSettings("analysis.analyzer.my_analyzer.type", "custom",
-                        "analysis.analyzer.my_analyzer.tokenizer", "whitespace",
-                        "analysis.analyzer.my_analyzer.filter", "custom_word_delimiter",
-                        "analysis.filter.custom_word_delimiter.type", "word_delimiter",
-                        "analysis.filter.custom_word_delimiter.generate_word_parts", "true",
-                        "analysis.filter.custom_word_delimiter.generate_number_parts", "false",
-                        "analysis.filter.custom_word_delimiter.catenate_numbers", "true",
-                        "analysis.filter.custom_word_delimiter.catenate_words", "false",
-                        "analysis.filter.custom_word_delimiter.split_on_case_change", "false",
-                        "analysis.filter.custom_word_delimiter.split_on_numerics", "false",
-                        "analysis.filter.custom_word_delimiter.stem_english_possessive", "false")
-                .addMapping("type1", "field1", "type=string,analyzer=my_analyzer", "field2", "type=string,analyzer=my_analyzer"));
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "foo bar baz", "field2", "not needed").get();
-        refresh();
-
-        SearchResponse response = client()
-                .prepareSearch("test")
-                .setQuery(
-                        queryStringQuery("foo.baz").useDisMax(false).defaultOperator(Operator.AND)
-                                .field("field1").field("field2")).get();
-        assertHitCount(response, 1l);
-    }
-
-    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3797
-    public void testMultiMatchLenientIssue3797() {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", 123, "field2", "value2").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(multiMatchQuery("value2", "field2").field("field1", 2).lenient(true).useDisMax(false)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(multiMatchQuery("value2", "field2").field("field1", 2).lenient(true).useDisMax(true)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(multiMatchQuery("value2").field("field2", 2).lenient(true)).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testAllFieldEmptyMapping() throws Exception {
-        client().prepareIndex("myindex", "mytype").setId("1").setSource("{}").setRefresh(true).get();
-        SearchResponse response = client().prepareSearch("myindex").setQuery(matchQuery("_all", "foo")).get();
-        assertNoFailures(response);
-    }
-
-    @Test
-    public void testAllDisabledButQueried() throws Exception {
-        createIndex("myindex");
-        assertAcked(client().admin().indices().preparePutMapping("myindex").setType("mytype").setSource(
-                jsonBuilder().startObject().startObject("mytype").startObject("_all").field("enabled", false)));
-        client().prepareIndex("myindex", "mytype").setId("1").setSource("bar", "foo").setRefresh(true).get();
-        SearchResponse response = client().prepareSearch("myindex").setQuery(matchQuery("_all", "foo")).get();
-        assertNoFailures(response);
-        assertHitCount(response, 0);
-    }
-
-    @Test
-    public void testIndicesQuery() throws Exception {
-        createIndex("index1", "index2", "index3");
-
-
-        client().prepareIndex("index1", "type1").setId("1").setSource("text", "value1").get();
-        client().prepareIndex("index2", "type2").setId("2").setSource("text", "value2").get();
-        client().prepareIndex("index3", "type3").setId("3").setSource("text", "value3").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch("index1", "index2", "index3")
-                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
-                        .noMatchQuery(matchQuery("text", "value2"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        //default no match query is match_all
-        searchResponse = client().prepareSearch("index1", "index2", "index3")
-                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")).get();
-        assertHitCount(searchResponse, 3l);
-        assertSearchHits(searchResponse, "1", "2", "3");
-        searchResponse = client().prepareSearch("index1", "index2", "index3")
-                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
-                        .noMatchQuery(QueryBuilders.matchAllQuery())).get();
-        assertHitCount(searchResponse, 3l);
-        assertSearchHits(searchResponse, "1", "2", "3");
-
-        searchResponse = client().prepareSearch("index1", "index2", "index3")
-                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
-                        .noMatchQuery("none")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-    }
-
-    @Test // https://github.com/elasticsearch/elasticsearch/issues/2416
-    public void testIndicesQuerySkipParsing() throws Exception {
-        createIndex("simple");
-        assertAcked(prepareCreate("related")
-                .addMapping("child", jsonBuilder().startObject().startObject("child").startObject("_parent").field("type", "parent")
-                        .endObject().endObject().endObject()));
-
-        client().prepareIndex("simple", "lone").setId("1").setSource("text", "value1").get();
-        client().prepareIndex("related", "parent").setId("2").setSource("text", "parent").get();
-        client().prepareIndex("related", "child").setId("3").setParent("2").setSource("text", "value2").get();
-        refresh();
-
-        //has_child fails if executed on "simple" index
-        try {
-            client().prepareSearch("simple")
-                    .setQuery(hasChildQuery("child", matchQuery("text", "value"))).get();
-            fail("Should have failed as has_child query can only be executed against parent-child types");
-        } catch (SearchPhaseExecutionException e) {
-            assertThat(e.shardFailures().length, greaterThan(0));
-            for (ShardSearchFailure shardSearchFailure : e.shardFailures()) {
-                assertThat(shardSearchFailure.reason(), containsString("no mapping found for type [child]"));
-            }
-        }
-
-        //has_child doesn't get parsed for "simple" index
-        SearchResponse searchResponse = client().prepareSearch("related", "simple")
-                .setQuery(indicesQuery(hasChildQuery("child", matchQuery("text", "value2")), "related")
-                        .noMatchQuery(matchQuery("text", "value1"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-    }
-
-    @Test
-    public void testIndicesQueryMissingIndices() throws IOException, ExecutionException, InterruptedException {
-        createIndex("index1");
-        createIndex("index2");
-
-        indexRandom(true,
-                client().prepareIndex("index1", "type1", "1").setSource("field", "match"),
-                client().prepareIndex("index1", "type1", "2").setSource("field", "no_match"),
-                client().prepareIndex("index2", "type1", "10").setSource("field", "match"),
-                client().prepareIndex("index2", "type1", "20").setSource("field", "no_match"),
-                client().prepareIndex("index3", "type1", "100").setSource("field", "match"),
-                client().prepareIndex("index3", "type1", "200").setSource("field", "no_match"));
-
-        //all indices are missing
-        SearchResponse searchResponse = client().prepareSearch().setQuery(
-                indicesQuery(termQuery("field", "missing"), "test1", "test2", "test3")
-                        .noMatchQuery(termQuery("field", "match"))).get();
-
-        assertHitCount(searchResponse, 3l);
-
-        for (SearchHit hit : searchResponse.getHits().getHits()) {
-            if ("index1".equals(hit.index())) {
-                assertThat(hit, hasId("1"));
-            } else if ("index2".equals(hit.index())) {
-                assertThat(hit, hasId("10"));
-            } else if ("index3".equals(hit.index())) {
-                assertThat(hit, hasId("100"));
-            } else {
-                fail("Returned documents should belong to either index1, index2 or index3");
-            }
-        }
-
-        //only one index specified, which is missing
-        searchResponse = client().prepareSearch().setQuery(
-                indicesQuery(termQuery("field", "missing"), "test1")
-                        .noMatchQuery(termQuery("field", "match"))).get();
-
-        assertHitCount(searchResponse, 3l);
-
-        for (SearchHit hit : searchResponse.getHits().getHits()) {
-            if ("index1".equals(hit.index())) {
-                assertThat(hit, hasId("1"));
-            } else if ("index2".equals(hit.index())) {
-                assertThat(hit, hasId("10"));
-            } else if ("index3".equals(hit.index())) {
-                assertThat(hit, hasId("100"));
-            } else {
-                fail("Returned documents should belong to either index1, index2 or index3");
-            }
-        }
-
-        //more than one index specified, one of them is missing
-        searchResponse = client().prepareSearch().setQuery(
-                indicesQuery(termQuery("field", "missing"), "index1", "test1")
-                        .noMatchQuery(termQuery("field", "match"))).get();
-
-        assertHitCount(searchResponse, 2l);
-
-        for (SearchHit hit : searchResponse.getHits().getHits()) {
-            if ("index2".equals(hit.index())) {
-                assertThat(hit, hasId("10"));
-            } else if ("index3".equals(hit.index())) {
-                assertThat(hit, hasId("100"));
-            } else {
-                fail("Returned documents should belong to either index2 or index3");
-            }
-        }
-    }
-
-    @Test
-    public void testMinScore() throws ExecutionException, InterruptedException {
-        createIndex("test");
-
-        indexRandom(true,
-                client().prepareIndex("test", "test", "1").setSource("score", 1.5),
-                client().prepareIndex("test", "test", "2").setSource("score", 1.0),
-                client().prepareIndex("test", "test", "3").setSource("score", 2.0),
-                client().prepareIndex("test", "test", "4").setSource("score", 0.5));
-
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(
-functionScoreQuery(scriptFunction(new Script("_doc['score'].value")))).setMinScore(1.5f).get();
-        assertHitCount(searchResponse, 2);
-        assertFirstHit(searchResponse, hasId("3"));
-        assertSecondHit(searchResponse, hasId("1"));
-    }
-
-    @Test
-    public void testQueryStringWithSlopAndFields() {
-        createIndex("test");
-
-        client().prepareIndex("test", "customer", "1").setSource("desc", "one two three").get();
-        client().prepareIndex("test", "product", "2").setSource("desc", "one two three").get();
-        refresh();
-        {
-            SearchResponse searchResponse = client().prepareSearch("test").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
-            assertHitCount(searchResponse, 2);
-        }
-        {
-            SearchResponse searchResponse = client().prepareSearch("test").setTypes("product").setQuery(QueryBuilders.queryStringQuery("\"one two\"").field("desc")).get();
-            assertHitCount(searchResponse, 1);
-        }
-        {
-            SearchResponse searchResponse = client().prepareSearch("test").setTypes("product").setQuery(QueryBuilders.queryStringQuery("\"one three\"~5").field("desc")).get();
-            assertHitCount(searchResponse, 1);
-        }
-        {
-            SearchResponse searchResponse = client().prepareSearch("test").setTypes("customer").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
-            assertHitCount(searchResponse, 1);
-        }
-        {
-            SearchResponse searchResponse = client().prepareSearch("test").setTypes("customer").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
-            assertHitCount(searchResponse, 1);
-        }
-    }
-
-    @Test
-    public void testDateProvidedAsNumber() throws ExecutionException, InterruptedException {
-        createIndex("test");
-        assertAcked(client().admin().indices().preparePutMapping("test").setType("type").setSource("field", "type=date,format=epoch_millis").get());
-        indexRandom(true, client().prepareIndex("test", "type", "1").setSource("field", -1000000000001L),
-                client().prepareIndex("test", "type", "2").setSource("field", -1000000000000L),
-                client().prepareIndex("test", "type", "3").setSource("field", -999999999999L));
-
-
-        assertHitCount(client().prepareCount("test").setQuery(rangeQuery("field").lte(-1000000000000L)).get(), 2);
-        assertHitCount(client().prepareCount("test").setQuery(rangeQuery("field").lte(-999999999999L)).get(), 3);
-    }
-
-    @Test
-    public void testRangeQueryWithTimeZone() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1", "date", "type=date", "num", "type=integer"));
-
-        indexRandom(true,
-                client().prepareIndex("test", "type1", "1").setSource("date", "2014-01-01", "num", 1),
-                client().prepareIndex("test", "type1", "2").setSource("date", "2013-12-31T23:00:00", "num", 2),
-                client().prepareIndex("test", "type1", "3").setSource("date", "2014-01-01T01:00:00", "num", 3),
-                // Now in UTC+1
-                client().prepareIndex("test", "type1", "4").setSource("date", DateTime.now(DateTimeZone.forOffsetHours(1)).getMillis(), "num", 4));
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T00:00:00").to("2014-01-01T00:59:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2013-12-31T23:00:00").to("2013-12-31T23:59:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T01:00:00").to("2014-01-01T01:59:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
-
-        // We explicitly define a time zone in the from/to dates so whatever the time zone is, it won't be used
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T00:00:00Z").to("2014-01-01T00:59:00Z").timeZone("+10:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2013-12-31T23:00:00Z").to("2013-12-31T23:59:00Z").timeZone("+10:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T01:00:00Z").to("2014-01-01T01:59:00Z").timeZone("+10:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
-
-        // We define a time zone to be applied to the filter and from/to have no time zone
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T03:00:00").to("2014-01-01T03:59:00").timeZone("+03:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T02:00:00").to("2014-01-01T02:59:00").timeZone("+03:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T04:00:00").to("2014-01-01T04:59:00").timeZone("+03:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
-
-        // When we use long values, it means we have ms since epoch UTC based so we don't apply any transformation
-        try {
-            client().prepareSearch("test")
-                    .setQuery(QueryBuilders.rangeQuery("date").from(1388534400000L).to(1388537940999L).timeZone("+01:00"))
-                    .get();
-            fail("A Range Filter using ms since epoch with a TimeZone should raise a ParsingException");
-        } catch (SearchPhaseExecutionException e) {
-            // We expect it
-        }
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01").to("2014-01-01T00:59:00").timeZone("-01:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("now/d-1d").timeZone("+01:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("4"));
-
-        // A Range Filter on a numeric field with a TimeZone should raise an exception
-        try {
-            client().prepareSearch("test")
-                    .setQuery(QueryBuilders.rangeQuery("num").from("0").to("4").timeZone("-01:00"))
-                    .get();
-            fail("A Range Filter on a numeric field with a TimeZone should raise a ParsingException");
-        } catch (SearchPhaseExecutionException e) {
-            // We expect it
-        }
-    }
-
-    @Test
-    public void testSearchEmptyDoc() {
-        assertAcked(prepareCreate("test").setSettings("{\"index.analysis.analyzer.default.type\":\"keyword\"}"));
-        client().prepareIndex("test", "type1", "1").setSource("{}").get();
-
-        refresh();
-        assertHitCount(client().prepareSearch().setQuery(matchAllQuery()).get(), 1l);
-    }
-
-    @Test  // see #5120
-    public void testNGramCopyField() {
-        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
-                .put(indexSettings())
-                .put("index.analysis.analyzer.my_ngram_analyzer.type", "custom")
-                .put("index.analysis.analyzer.my_ngram_analyzer.tokenizer", "my_ngram_tokenizer")
-                .put("index.analysis.tokenizer.my_ngram_tokenizer.type", "nGram")
-                .put("index.analysis.tokenizer.my_ngram_tokenizer.min_gram", "1")
-                .put("index.analysis.tokenizer.my_ngram_tokenizer.max_gram", "10")
-                .putArray("index.analysis.tokenizer.my_ngram_tokenizer.token_chars", new String[0]));
-        assertAcked(builder.addMapping("test", "origin", "type=string,copy_to=meta", "meta", "type=string,analyzer=my_ngram_analyzer"));
-        // we only have ngrams as the index analyzer so searches will get standard analyzer
-
-
-        client().prepareIndex("test", "test", "1").setSource("origin", "C.A1234.5678")
-                .setRefresh(true)
-                .get();
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(matchQuery("meta", "1234"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(matchQuery("meta", "1234.56"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termQuery("meta", "A1234"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termQuery("meta", "a1234"))
-                .get();
-        assertHitCount(searchResponse, 0l); // it's upper case
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(matchQuery("meta", "A1234").analyzer("my_ngram_analyzer"))
-                .get(); // force ngram analyzer
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(matchQuery("meta", "a1234").analyzer("my_ngram_analyzer"))
-                .get(); // this one returns a hit since it's default operator is OR
-        assertHitCount(searchResponse, 1l);
-    }
-
-    public void testMatchPhrasePrefixQuery() throws ExecutionException, InterruptedException {
-        createIndex("test1");
-        indexRandom(true, client().prepareIndex("test1", "type1", "1").setSource("field", "Johnnie Walker Black Label"),
-        client().prepareIndex("test1", "type1", "2").setSource("field", "trying out Elasticsearch"));
-
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field", "Johnnie la").slop(between(2,5)).type(Type.PHRASE_PREFIX)).get();
-        assertHitCount(searchResponse, 1l);
-        assertSearchHits(searchResponse, "1");
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field", "trying").type(Type.PHRASE_PREFIX)).get();
-        assertHitCount(searchResponse, 1l);
-        assertSearchHits(searchResponse, "2");
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field", "try").type(Type.PHRASE_PREFIX)).get();
-        assertHitCount(searchResponse, 1l);
-        assertSearchHits(searchResponse, "2");
-    }
-
-    @Test
-    public void testQueryStringParserCache() throws Exception {
-        createIndex("test");
-        indexRandom(true, false, client().prepareIndex("test", "type", "1").setSource("nameTokens", "xyz"));
-
-
-        SearchResponse response = client().prepareSearch("test")
-                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                .setQuery(QueryBuilders.queryStringQuery("xyz").boost(100))
-                .get();
-        assertThat(response.getHits().totalHits(), equalTo(1l));
-        assertThat(response.getHits().getAt(0).id(), equalTo("1"));
-
-        float first = response.getHits().getAt(0).getScore();
-        for (int i = 0; i < 100; i++) {
-            response = client().prepareSearch("test")
-                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.queryStringQuery("xyz").boost(100))
-                    .get();
-
-            assertThat(response.getHits().totalHits(), equalTo(1l));
-            assertThat(response.getHits().getAt(0).id(), equalTo("1"));
-            float actual = response.getHits().getAt(0).getScore();
-            assertThat(i + " expected: " + first + " actual: " + actual, Float.compare(first, actual), equalTo(0));
-        }
-    }
-
-    @Test // see #7686.
-    public void testIdsQueryWithInvalidValues() throws Exception {
-        createIndex("test");
-        indexRandom(true, false, client().prepareIndex("test", "type", "1").setSource("body", "foo"));
-
-        try {
-            client().prepareSearch("test")
-                    .setTypes("type")
-                    .setQuery("{\n" +
-                            "  \"ids\": {\n" +
-                            "    \"values\": [[\"1\"]]\n" +
-                            "  }\n" +
-                            "}")
-                    .get();
-            fail("query is invalid and should have produced a parse exception");
-        } catch (Exception e) {
-            assertThat("query could not be parsed due to bad format: " + e.toString(),
-                    e.toString().contains("Illegal value for id, expecting a string or number, got: START_ARRAY"),
-                    equalTo(true));
-        }
-    }
-}
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java
index ca3a9df..47bfb49 100644
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java
+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java
@@ -46,56 +46,23 @@ import org.elasticsearch.script.Script;
 import org.elasticsearch.script.groovy.GroovyPlugin;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHitField;
-import org.elasticsearch.search.sort.FieldSortBuilder;
-import org.elasticsearch.search.sort.GeoDistanceSortBuilder;
-import org.elasticsearch.search.sort.ScriptSortBuilder;
-import org.elasticsearch.search.sort.SortBuilders;
-import org.elasticsearch.search.sort.SortOrder;
+import org.elasticsearch.search.sort.*;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.junit.annotations.TestLogging;
 import org.hamcrest.Matchers;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Locale;
+import java.util.*;
 import java.util.Map.Entry;
-import java.util.Random;
-import java.util.Set;
-import java.util.TreeMap;
 import java.util.concurrent.ExecutionException;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
+import static org.elasticsearch.index.query.QueryBuilders.*;
+import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.fieldValueFactorFunction;
 import static org.elasticsearch.search.sort.SortBuilders.fieldSort;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFirstHit;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertOrderedSearchHits;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSecondHit;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSortValues;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasId;
-import static org.hamcrest.Matchers.closeTo;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.lessThan;
-import static org.hamcrest.Matchers.lessThanOrEqualTo;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
 
 
 /**
@@ -107,7 +74,7 @@ public class SimpleSortTests extends ESIntegTestCase {
     protected Collection<Class<? extends Plugin>> nodePlugins() {
         return Collections.singleton(GroovyPlugin.class);
     }
-    
+
     @TestLogging("action.search.type:TRACE")
     @LuceneTestCase.AwaitsFix(bugUrl = "https://github.com/elasticsearch/elasticsearch/issues/9421")
     public void testIssue8226() {
@@ -391,7 +358,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         SearchResponse searchResponse = client()
                 .prepareSearch("test")
                 .setQuery(
-                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.scriptFunction(new Script("_source.field"))))
+                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.fieldValueFactorFunction("field")))
                 .execute().actionGet();
         assertThat(searchResponse.getHits().getAt(0).getId(), equalTo("1"));
         assertThat(searchResponse.getHits().getAt(1).score(), Matchers.lessThan(searchResponse.getHits().getAt(0).score()));
@@ -402,7 +369,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         searchResponse = client()
                 .prepareSearch("test")
                 .setQuery(
-                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.scriptFunction(new Script("_source.field"))))
+                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.fieldValueFactorFunction("field")))
                 .addSort("_score", SortOrder.DESC).execute().actionGet();
         assertThat(searchResponse.getHits().getAt(0).getId(), equalTo("1"));
         assertThat(searchResponse.getHits().getAt(1).score(), Matchers.lessThan(searchResponse.getHits().getAt(0).score()));
@@ -413,7 +380,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         searchResponse = client()
                 .prepareSearch("test")
                 .setQuery(
-                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.scriptFunction(new Script("_source.field"))))
+                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.fieldValueFactorFunction("field")))
                 .addSort("_score", SortOrder.DESC).execute().actionGet();
         assertThat(searchResponse.getHits().getAt(2).getId(), equalTo("3"));
         assertThat(searchResponse.getHits().getAt(1).getId(), equalTo("2"));
@@ -433,7 +400,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         refresh();
 
         SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(functionScoreQuery(matchAllQuery(), scriptFunction(new Script("_source.field")))).execute().actionGet();
+                .setQuery(functionScoreQuery(matchAllQuery(), fieldValueFactorFunction("field"))).execute().actionGet();
         assertThat(searchResponse.getHits().getAt(0).getId(), equalTo("1"));
         assertThat(searchResponse.getHits().getAt(1).score(), Matchers.lessThan(searchResponse.getHits().getAt(0).score()));
         assertThat(searchResponse.getHits().getAt(1).getId(), equalTo("2"));
@@ -441,7 +408,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertThat(searchResponse.getHits().getAt(2).getId(), equalTo("3"));
 
         searchResponse = client().prepareSearch("test")
-                .setQuery(functionScoreQuery(matchAllQuery(), scriptFunction(new Script("_source.field"))))
+                .setQuery(functionScoreQuery(matchAllQuery(), fieldValueFactorFunction("field")))
                 .addSort("_score", SortOrder.DESC).execute().actionGet();
         assertThat(searchResponse.getHits().getAt(0).getId(), equalTo("1"));
         assertThat(searchResponse.getHits().getAt(1).score(), Matchers.lessThan(searchResponse.getHits().getAt(0).score()));
@@ -450,7 +417,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertThat(searchResponse.getHits().getAt(2).getId(), equalTo("3"));
 
         searchResponse = client().prepareSearch("test")
-                .setQuery(functionScoreQuery(matchAllQuery(), scriptFunction(new Script("_source.field"))))
+                .setQuery(functionScoreQuery(matchAllQuery(), fieldValueFactorFunction("field")))
                 .addSort("_score", SortOrder.DESC).execute().actionGet();
         assertThat(searchResponse.getHits().getAt(2).getId(), equalTo("3"));
         assertThat(searchResponse.getHits().getAt(1).getId(), equalTo("2"));
@@ -907,9 +874,9 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertNoFailures(searchResponse);
 
         assertThat(searchResponse.getHits().getTotalHits(), equalTo(3l));
-        assertThat((String) searchResponse.getHits().getAt(0).field("id").value(), equalTo("1"));
-        assertThat((String) searchResponse.getHits().getAt(1).field("id").value(), equalTo("3"));
-        assertThat((String) searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
+        assertThat(searchResponse.getHits().getAt(0).field("id").value(), equalTo("1"));
+        assertThat(searchResponse.getHits().getAt(1).field("id").value(), equalTo("3"));
+        assertThat(searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
 
         searchResponse = client().prepareSearch()
                 .setQuery(matchAllQuery())
@@ -920,9 +887,9 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertNoFailures(searchResponse);
 
         assertThat(searchResponse.getHits().getTotalHits(), equalTo(3l));
-        assertThat((String) searchResponse.getHits().getAt(0).field("id").value(), equalTo("1"));
-        assertThat((String) searchResponse.getHits().getAt(1).field("id").value(), equalTo("3"));
-        assertThat((String) searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
+        assertThat(searchResponse.getHits().getAt(0).field("id").value(), equalTo("1"));
+        assertThat(searchResponse.getHits().getAt(1).field("id").value(), equalTo("3"));
+        assertThat(searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
 
         searchResponse = client().prepareSearch()
                 .setQuery(matchAllQuery())
@@ -939,9 +906,9 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertThat(searchResponse.getFailedShards(), equalTo(0));
 
         assertThat(searchResponse.getHits().getTotalHits(), equalTo(3l));
-        assertThat((String) searchResponse.getHits().getAt(0).field("id").value(), equalTo("3"));
-        assertThat((String) searchResponse.getHits().getAt(1).field("id").value(), equalTo("1"));
-        assertThat((String) searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
+        assertThat(searchResponse.getHits().getAt(0).field("id").value(), equalTo("3"));
+        assertThat(searchResponse.getHits().getAt(1).field("id").value(), equalTo("1"));
+        assertThat(searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
 
         // a query with docs just with null values
         searchResponse = client().prepareSearch()
@@ -959,7 +926,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertThat(searchResponse.getFailedShards(), equalTo(0));
 
         assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));
-        assertThat((String) searchResponse.getHits().getAt(0).field("id").value(), equalTo("2"));
+        assertThat(searchResponse.getHits().getAt(0).field("id").value(), equalTo("2"));
     }
 
     @Test
@@ -1782,32 +1749,32 @@ public class SimpleSortTests extends ESIntegTestCase {
                 .addSort(new GeoDistanceSortBuilder("location").points(q).sortMode("min").order(SortOrder.ASC).geoDistance(GeoDistance.PLANE).unit(DistanceUnit.KILOMETERS))
                 .execute().actionGet();
         assertOrderedSearchHits(searchResponse, "d1", "d2");
-        assertThat((Double) searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 3, 2, DistanceUnit.KILOMETERS)));
-        assertThat((Double) searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 5, 1, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 3, 2, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 5, 1, DistanceUnit.KILOMETERS)));
 
         searchResponse = client().prepareSearch()
                 .setQuery(matchAllQuery())
                 .addSort(new GeoDistanceSortBuilder("location").points(q).sortMode("min").order(SortOrder.DESC).geoDistance(GeoDistance.PLANE).unit(DistanceUnit.KILOMETERS))
                 .execute().actionGet();
         assertOrderedSearchHits(searchResponse, "d2", "d1");
-        assertThat((Double) searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 5, 1, DistanceUnit.KILOMETERS)));
-        assertThat((Double) searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 3, 2, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 5, 1, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 3, 2, DistanceUnit.KILOMETERS)));
 
         searchResponse = client().prepareSearch()
                 .setQuery(matchAllQuery())
                 .addSort(new GeoDistanceSortBuilder("location").points(q).sortMode("max").order(SortOrder.ASC).geoDistance(GeoDistance.PLANE).unit(DistanceUnit.KILOMETERS))
                 .execute().actionGet();
         assertOrderedSearchHits(searchResponse, "d1", "d2");
-        assertThat((Double) searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 4, 1, DistanceUnit.KILOMETERS)));
-        assertThat((Double) searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 6, 2, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 4, 1, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 6, 2, DistanceUnit.KILOMETERS)));
 
         searchResponse = client().prepareSearch()
                 .setQuery(matchAllQuery())
                 .addSort(new GeoDistanceSortBuilder("location").points(q).sortMode("max").order(SortOrder.DESC).geoDistance(GeoDistance.PLANE).unit(DistanceUnit.KILOMETERS))
                 .execute().actionGet();
         assertOrderedSearchHits(searchResponse, "d2", "d1");
-        assertThat((Double) searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 6, 2, DistanceUnit.KILOMETERS)));
-        assertThat((Double) searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 4, 1, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 6, 2, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 4, 1, DistanceUnit.KILOMETERS)));
     }
 
     protected void createShuffeldJSONArray(XContentBuilder builder, GeoPoint[] pointsArray) throws IOException {
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/package-info.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/package-info.java
index 4767ada..c4d9366 100644
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/package-info.java
+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/package-info.java
@@ -35,7 +35,6 @@
  * </ul>
  */
 /* List of renames that took place:
-  renamed:    core/src/test/java/org/elasticsearch/routing/AliasRoutingIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/AliasRoutingTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/metrics/AvgIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/AvgTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/BucketScriptTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketSelectorIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/BucketSelectorTests.java
@@ -63,14 +62,12 @@
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/bucket/MinDocCountIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinDocCountTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/metrics/MinIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java
   renamed:    core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/PercolatorTests.java
-  renamed:    core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/QueryRescorerTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/RandomScoreFunctionTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/bucket/RangeIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/RangeTests.java
   renamed:    core/src/test/java/org/elasticsearch/script/ScriptIndexSettingsIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptIndexSettingsTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/scriptfilter/ScriptQuerySearchIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptQuerySearchTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/metrics/ScriptedMetricIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptedMetricTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/fields/SearchFieldsIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchFieldsTests.java
-  renamed:    core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchQueryTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/stats/SearchStatsIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchStatsTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/timeout/SearchTimeoutIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchTimeoutTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SignificantTermsSignificanceScoreTests.java
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
new file mode 100644
index 0000000..7e8e26c
--- /dev/null
+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
@@ -0,0 +1,2209 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.search.query;
+
+import org.apache.lucene.util.English;
+import org.elasticsearch.Version;
+import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
+import org.elasticsearch.action.index.IndexRequestBuilder;
+import org.elasticsearch.action.search.SearchPhaseExecutionException;
+import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.action.search.SearchType;
+import org.elasticsearch.action.search.ShardSearchFailure;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
+import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.index.mapper.MapperParsingException;
+import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
+import org.elasticsearch.index.search.MatchQuery;
+import org.elasticsearch.index.search.MatchQuery.Type;
+import org.elasticsearch.indices.cache.query.terms.TermsLookup;
+import org.elasticsearch.rest.RestStatus;
+import org.elasticsearch.search.SearchHit;
+import org.elasticsearch.search.SearchHits;
+import org.elasticsearch.search.aggregations.AggregationBuilders;
+import org.elasticsearch.test.ESIntegTestCase;
+import org.joda.time.DateTime;
+import org.joda.time.DateTimeZone;
+import org.joda.time.format.ISODateTimeFormat;
+import org.junit.Test;
+
+import java.io.IOException;
+import java.util.Random;
+import java.util.concurrent.ExecutionException;
+
+import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
+import static org.elasticsearch.common.settings.Settings.settingsBuilder;
+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
+import static org.elasticsearch.index.query.QueryBuilders.*;
+import static org.elasticsearch.test.VersionUtils.randomVersion;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
+
+public class SearchQueryIT extends ESIntegTestCase {
+
+    @Override
+    protected int maximumNumberOfShards() {
+        return 7;
+    }
+
+    @Override
+    protected int maximumNumberOfReplicas() {
+        return Math.min(2, cluster().numDataNodes() - 1);
+    }
+
+    @Test
+    public void testOmitNormsOnAll() throws ExecutionException, InterruptedException, IOException {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
+                        .startObject("_all").field("omit_norms", true).endObject()
+                        .endObject().endObject())
+                .setSettings(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)); // only one shard otherwise IDF might be different for comparing scores
+
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
+                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
+
+        assertHitCount(client().prepareSearch().setQuery(matchQuery("_all", "quick")).get(), 3l);
+        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("_all", "quick")).setExplain(true).get();
+        SearchHit[] hits = searchResponse.getHits().hits();
+        assertThat(hits.length, equalTo(3));
+        assertThat(hits[0].score(), allOf(equalTo(hits[1].getScore()), equalTo(hits[2].getScore())));
+        cluster().wipeIndices("test");
+
+        createIndex("test");
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
+                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
+
+        assertHitCount(client().prepareSearch().setQuery(matchQuery("_all", "quick")).get(), 3l);
+        searchResponse = client().prepareSearch().setQuery(matchQuery("_all", "quick")).get();
+        hits = searchResponse.getHits().hits();
+        assertThat(hits.length, equalTo(3));
+        assertThat(hits[0].score(), allOf(greaterThan(hits[1].getScore()), greaterThan(hits[2].getScore())));
+
+    }
+
+    @Test // see #3952
+    public void testEmptyQueryString() throws ExecutionException, InterruptedException, IOException {
+        createIndex("test");
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
+                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
+
+        assertHitCount(client().prepareSearch().setQuery(queryStringQuery("quick")).get(), 3l);
+        assertHitCount(client().prepareSearch().setQuery(queryStringQuery("")).get(), 0l); // return no docs
+    }
+
+    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3177
+    public void testIssue3177() {
+        createIndex("test");
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "value2").get();
+        client().prepareIndex("test", "type1", "3").setSource("field1", "value3").get();
+        ensureGreen();
+        waitForRelocation();
+        optimize();
+        refresh();
+        assertHitCount(
+                client().prepareSearch()
+                        .setQuery(matchAllQuery())
+                        .setPostFilter(
+                                boolQuery().must(
+                                        matchAllQuery()).must(
+                                        notQuery(boolQuery().must(termQuery("field1", "value1")).must(
+                                                termQuery("field1", "value2"))))).get(),
+                3l);
+        assertHitCount(
+                client().prepareSearch()
+                        .setQuery(
+                                boolQuery().must(
+                                        boolQuery().should(termQuery("field1", "value1")).should(termQuery("field1", "value2"))
+                                                .should(termQuery("field1", "value3"))).filter(
+                                        notQuery(boolQuery().must(termQuery("field1", "value1")).must(
+                                                termQuery("field1", "value2"))))).get(),
+                3l);
+        assertHitCount(
+                client().prepareSearch().setQuery(matchAllQuery()).setPostFilter(notQuery(termQuery("field1", "value3"))).get(),
+                2l);
+    }
+
+    @Test
+    public void passQueryAsStringTest() throws Exception {
+        createIndex("test");
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1_1", "field2", "value2_1").setRefresh(true).get();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery("{ \"term\" : { \"field1\" : \"value1_1\" }}").get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testIndexOptions() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1", "field1", "type=string,index_options=docs"));
+        indexRandom(true,
+                client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(Type.PHRASE).slop(0)).get();
+        assertHitCount(searchResponse, 1l);
+
+        assertFailures(client().prepareSearch().setQuery(matchQuery("field1", "quick brown").type(Type.PHRASE).slop(0)),
+                    RestStatus.INTERNAL_SERVER_ERROR,
+                    containsString("field \"field1\" was indexed without position data; cannot run PhraseQuery"));
+    }
+
+    @Test // see #3521
+    public void testConstantScoreQuery() throws Exception {
+        Random random = getRandom();
+        createIndex("test");
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"), client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("field1", "quick"))).get();
+        assertHitCount(searchResponse, 2l);
+        for (SearchHit searchHit : searchResponse.getHits().hits()) {
+            assertSearchHit(searchHit, hasScore(1.0f));
+        }
+
+        searchResponse = client().prepareSearch("test").setQuery(
+                boolQuery().must(matchAllQuery()).must(
+                constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + getRandom().nextFloat()))).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
+
+        client().prepareSearch("test").setQuery(constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + getRandom().nextFloat())).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
+
+        searchResponse = client().prepareSearch("test").setQuery(
+                constantScoreQuery(boolQuery().must(matchAllQuery()).must(
+                constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + (random.nextBoolean()? 0.0f : random.nextFloat()))))).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
+        for (SearchHit searchHit : searchResponse.getHits().hits()) {
+            assertSearchHit(searchHit, hasScore(1.0f));
+        }
+
+        int num = scaledRandomIntBetween(100, 200);
+        IndexRequestBuilder[] builders = new IndexRequestBuilder[num];
+        for (int i = 0; i < builders.length; i++) {
+            builders[i] = client().prepareIndex("test", "type", "" + i).setSource("f", English.intToEnglish(i));
+        }
+        createIndex("test_1");
+        indexRandom(true, builders);
+
+        int queryRounds = scaledRandomIntBetween(10, 20);
+        for (int i = 0; i < queryRounds; i++) {
+            MatchQueryBuilder matchQuery = matchQuery("f", English.intToEnglish(between(0, num)));
+            searchResponse = client().prepareSearch("test_1").setQuery(matchQuery).setSize(num).get();
+            long totalHits = searchResponse.getHits().totalHits();
+            SearchHits hits = searchResponse.getHits();
+            for (SearchHit searchHit : hits) {
+                assertSearchHit(searchHit, hasScore(1.0f));
+            }
+            searchResponse = client().prepareSearch("test_1").setQuery(
+                    boolQuery().must(matchAllQuery()).must(
+                    constantScoreQuery(matchQuery).boost(1.0f + (random.nextBoolean()? 0.0f : random.nextFloat())))).setSize(num).get();
+            hits = searchResponse.getHits();
+            assertThat(hits.totalHits(), equalTo(totalHits));
+            if (totalHits > 1) {
+                float expected = hits.getAt(0).score();
+                for (SearchHit searchHit : hits) {
+                    assertSearchHit(searchHit, hasScore(expected));
+                }
+            }
+        }
+    }
+
+    @Test // see #3521
+    public void testAllDocsQueryString() throws InterruptedException, ExecutionException {
+        createIndex("test");
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("foo", "bar"),
+                client().prepareIndex("test", "type1", "2").setSource("foo", "bar")
+        );
+
+        int iters = scaledRandomIntBetween(100, 200);
+        for (int i = 0; i < iters; i++) {
+            SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("*:*^10.0").boost(10.0f)).get();
+            assertHitCount(searchResponse, 2l);
+
+            searchResponse = client().prepareSearch("test").setQuery(
+                    boolQuery().must(matchAllQuery()).must(constantScoreQuery(matchAllQuery()))).get();
+            assertHitCount(searchResponse, 2l);
+            assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(Math.sqrt(2), 0.1));
+            assertThat((double)searchResponse.getHits().getAt(1).score(),closeTo(Math.sqrt(2), 0.1));
+        }
+    }
+
+    @Test
+    public void testCommonTermsQueryOnAllField() throws Exception {
+        client().admin().indices().prepareCreate("test")
+                .addMapping("type1", "message", "type=string", "comment", "type=string,boost=5.0")
+                .setSettings(SETTING_NUMBER_OF_SHARDS, 1).get();
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("message", "test message", "comment", "whatever"),
+                client().prepareIndex("test", "type1", "2").setSource("message", "hello world", "comment", "test comment"));
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("_all", "test")).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("2"));
+        assertSecondHit(searchResponse, hasId("1"));
+        assertThat(searchResponse.getHits().getHits()[0].getScore(), greaterThan(searchResponse.getHits().getHits()[1].getScore()));
+    }
+
+    @Test
+    public void testCommonTermsQuery() throws Exception {
+        client().admin().indices().prepareCreate("test")
+                .addMapping("type1", "field1", "type=string,analyzer=whitespace")
+                .setSettings(SETTING_NUMBER_OF_SHARDS, 1).get();
+        indexRandom(true, client().prepareIndex("test", "type1", "3").setSource("field1", "quick lazy huge brown pidgin", "field2", "the quick lazy huge brown fox jumps over the tree"),
+                client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree") );
+
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).lowFreqOperator(Operator.OR)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).lowFreqOperator(Operator.AND)).get();
+        assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        // Default
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the huge fox").lowFreqMinimumShouldMatch("2")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("3")).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("4")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 4 } } } }").get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        // Default
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).analyzer("stop")).get();
+        assertHitCount(searchResponse, 3l);
+        // stop drops "the" since its a stopword
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("3"));
+        assertThirdHit(searchResponse, hasId("2"));
+
+        // try the same with match query
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.OR)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
+        assertHitCount(searchResponse, 3l);
+        // stop drops "the" since its a stopword
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("3"));
+        assertThirdHit(searchResponse, hasId("2"));
+
+        // try the same with multi match query
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the quick brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
+        assertSecondHit(searchResponse, hasId("1"));
+        assertThirdHit(searchResponse, hasId("2"));
+    }
+
+    @Test
+    public void testCommonTermsQueryStackedTokens() throws Exception {
+        assertAcked(prepareCreate("test")
+                .setSettings(settingsBuilder()
+                        .put(indexSettings())
+                        .put(SETTING_NUMBER_OF_SHARDS,1)
+                        .put("index.analysis.filter.syns.type","synonym")
+                        .putArray("index.analysis.filter.syns.synonyms","quick,fast")
+                        .put("index.analysis.analyzer.syns.tokenizer","whitespace")
+                        .put("index.analysis.analyzer.syns.filter","syns")
+                        )
+                .addMapping("type1", "field1", "type=string,analyzer=syns", "field2", "type=string,analyzer=syns"));
+
+        indexRandom(true, client().prepareIndex("test", "type1", "3").setSource("field1", "quick lazy huge brown pidgin", "field2", "the quick lazy huge brown fox jumps over the tree"),
+                client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree") );
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3).lowFreqOperator(Operator.OR)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3).lowFreqOperator(Operator.AND)).get();
+        assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        // Default
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast huge fox").lowFreqMinimumShouldMatch("3")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("5")).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("6")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the fast lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 6 } } } }").get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        // Default
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).analyzer("stop")).get();
+        assertHitCount(searchResponse, 3l);
+        // stop drops "the" since its a stopword
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("3"));
+        assertThirdHit(searchResponse, hasId("2"));
+
+        // try the same with match query
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.OR)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
+        assertHitCount(searchResponse, 3l);
+        // stop drops "the" since its a stopword
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("3"));
+        assertThirdHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).minimumShouldMatch("3")).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        // try the same with multi match query
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the fast brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
+        assertSecondHit(searchResponse, hasId("1"));
+        assertThirdHit(searchResponse, hasId("2"));
+    }
+
+    @Test
+    public void testOmitTermFreqsAndPositions() throws Exception {
+        cluster().wipeTemplates(); // no randomized template for this test -- we are testing bwc compat and set version explicitly this might cause failures if an unsupported feature
+                                   // is added randomly via an index template.
+        Version version = Version.CURRENT;
+        int iters = scaledRandomIntBetween(10, 20);
+        for (int i = 0; i < iters; i++) {
+            try {
+                // backwards compat test!
+                assertAcked(client().admin().indices().prepareCreate("test")
+                        .addMapping("type1", "field1", "type=string,omit_term_freq_and_positions=true")
+                        .setSettings(settings(version).put(SETTING_NUMBER_OF_SHARDS, 1)));
+                assertThat(version.onOrAfter(Version.V_1_0_0_RC2), equalTo(false));
+                indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"),
+                        client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
+
+
+                SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(Type.PHRASE).slop(0)).get();
+                assertHitCount(searchResponse, 1l);
+                try {
+                    client().prepareSearch().setQuery(matchQuery("field1", "quick brown").type(Type.PHRASE).slop(0)).get();
+                    fail("SearchPhaseExecutionException should have been thrown");
+                } catch (SearchPhaseExecutionException e) {
+                    assertTrue(e.toString().contains("IllegalStateException[field \"field1\" was indexed without position data; cannot run PhraseQuery"));
+                }
+                cluster().wipeIndices("test");
+            } catch (MapperParsingException ex) {
+                assertThat(version.toString(), version.onOrAfter(Version.V_1_0_0_RC2), equalTo(true));
+                assertThat(ex.getCause().getMessage(), equalTo("'omit_term_freq_and_positions' is not supported anymore - use ['index_options' : 'docs']  instead"));
+            }
+            version = randomVersion(random());
+        }
+    }
+
+    @Test
+    public void queryStringAnalyzedWildcard() throws Exception {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value_1", "field2", "value_2").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("value*").analyzeWildcard(true)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("*ue*").analyzeWildcard(true)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("*ue_1").analyzeWildcard(true)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("val*e_1").analyzeWildcard(true)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("v?l*e?1").analyzeWildcard(true)).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testLowercaseExpandedTerms() {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value_1", "field2", "value_2").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("VALUE_3~1").lowercaseExpandedTerms(true)).get();
+        assertHitCount(searchResponse, 1l);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("VALUE_3~1").lowercaseExpandedTerms(false)).get();
+        assertHitCount(searchResponse, 0l);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("ValUE_*").lowercaseExpandedTerms(true)).get();
+        assertHitCount(searchResponse, 1l);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("vAl*E_1")).get();
+        assertHitCount(searchResponse, 1l);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("[VALUE_1 TO VALUE_3]")).get();
+        assertHitCount(searchResponse, 1l);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("[VALUE_1 TO VALUE_3]").lowercaseExpandedTerms(false)).get();
+        assertHitCount(searchResponse, 0l);
+    }
+
+    @Test //https://github.com/elasticsearch/elasticsearch/issues/3540
+    public void testDateRangeInQueryString() {
+        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
+        //as with dynamic mappings some shards might be lacking behind and parse a different query
+        assertAcked(prepareCreate("test").addMapping(
+                "type", "past", "type=date", "future", "type=date"
+        ));
+
+        String aMonthAgo = ISODateTimeFormat.yearMonthDay().print(new DateTime(DateTimeZone.UTC).minusMonths(1));
+        String aMonthFromNow = ISODateTimeFormat.yearMonthDay().print(new DateTime(DateTimeZone.UTC).plusMonths(1));
+        client().prepareIndex("test", "type", "1").setSource("past", aMonthAgo, "future", aMonthFromNow).get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("past:[now-2M/d TO now/d]")).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("future:[now/d TO now+2M/d]").lowercaseExpandedTerms(false)).get();
+        assertHitCount(searchResponse, 1l);
+
+        try {
+            client().prepareSearch().setQuery(queryStringQuery("future:[now/D TO now+2M/d]").lowercaseExpandedTerms(false)).get();
+            fail("expected SearchPhaseExecutionException (total failure)");
+        } catch (SearchPhaseExecutionException e) {
+            assertThat(e.status(), equalTo(RestStatus.BAD_REQUEST));
+            assertThat(e.toString(), containsString("unit [D] not supported for date math"));
+        }
+    }
+
+    @Test // https://github.com/elasticsearch/elasticsearch/issues/7880
+    public void testDateRangeInQueryStringWithTimeZone_7880() {
+        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
+        //as with dynamic mappings some shards might be lacking behind and parse a different query
+        assertAcked(prepareCreate("test").addMapping(
+                "type", "past", "type=date"
+        ));
+
+        DateTimeZone timeZone = randomDateTimeZone();
+        String now = ISODateTimeFormat.dateTime().print(new DateTime(timeZone));
+        logger.info(" --> Using time_zone [{}], now is [{}]", timeZone.getID(), now);
+        client().prepareIndex("test", "type", "1").setSource("past", now).get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("past:[now-1m/m TO now+1m/m]")
+                .timeZone(timeZone.getID())).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test // https://github.com/elasticsearch/elasticsearch/issues/10477
+    public void testDateRangeInQueryStringWithTimeZone_10477() {
+        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
+        //as with dynamic mappings some shards might be lacking behind and parse a different query
+        assertAcked(prepareCreate("test").addMapping(
+                "type", "past", "type=date"
+        ));
+
+        client().prepareIndex("test", "type", "1").setSource("past", "2015-04-05T23:00:00+0000").get();
+        client().prepareIndex("test", "type", "2").setSource("past", "2015-04-06T00:00:00+0000").get();
+        refresh();
+
+        // Timezone set with dates
+        SearchResponse searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00+0200 TO 2015-04-06T23:00:00+0200]"))
+                .get();
+        assertHitCount(searchResponse, 2l);
+
+        // Same timezone set with time_zone
+        searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00 TO 2015-04-06T23:00:00]").timeZone("+0200"))
+                .get();
+        assertHitCount(searchResponse, 2l);
+
+        // We set a timezone which will give no result
+        searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00-0200 TO 2015-04-06T23:00:00-0200]"))
+                .get();
+        assertHitCount(searchResponse, 0l);
+
+        // Same timezone set with time_zone but another timezone is set directly within dates which has the precedence
+        searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00-0200 TO 2015-04-06T23:00:00-0200]").timeZone("+0200"))
+                .get();
+        assertHitCount(searchResponse, 0l);
+    }
+
+    @Test
+    public void typeFilterTypeIndexedTests() throws Exception {
+        typeFilterTests("not_analyzed");
+    }
+
+    @Test
+    public void typeFilterTypeNotIndexedTests() throws Exception {
+        typeFilterTests("no");
+    }
+
+    private void typeFilterTests(String index) throws Exception {
+        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
+        assertAcked(prepareCreate("test").setSettings(indexSettings)
+                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
+                        .startObject("_type").field("index", index).endObject()
+                        .endObject().endObject())
+                .addMapping("type2", jsonBuilder().startObject().startObject("type2")
+                        .startObject("_type").field("index", index).endObject()
+                        .endObject().endObject())
+                .setUpdateAllTypes(true));
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "value1"),
+                client().prepareIndex("test", "type2", "1").setSource("field1", "value1"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "value1"),
+                client().prepareIndex("test", "type2", "2").setSource("field1", "value1"),
+                client().prepareIndex("test", "type2", "3").setSource("field1", "value1"));
+
+        assertHitCount(client().prepareSearch().setQuery(typeQuery("type1")).get(), 2l);
+        assertHitCount(client().prepareSearch().setQuery(typeQuery("type2")).get(), 3l);
+
+        assertHitCount(client().prepareSearch().setTypes("type1").setQuery(matchAllQuery()).get(), 2l);
+        assertHitCount(client().prepareSearch().setTypes("type2").setQuery(matchAllQuery()).get(), 3l);
+
+        assertHitCount(client().prepareSearch().setTypes("type1", "type2").setQuery(matchAllQuery()).get(), 5l);
+    }
+
+    @Test
+    public void idsQueryTestsIdIndexed() throws Exception {
+        idsQueryTests("not_analyzed");
+    }
+
+    @Test
+    public void idsQueryTestsIdNotIndexed() throws Exception {
+        idsQueryTests("no");
+    }
+
+    private void idsQueryTests(String index) throws Exception {
+        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
+        assertAcked(client().admin().indices().prepareCreate("test").setSettings(indexSettings)
+                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
+                        .startObject("_id").field("index", index).endObject()
+                        .endObject().endObject()));
+
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "value1"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "value2"),
+                client().prepareIndex("test", "type1", "3").setSource("field1", "value3"));
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery("type1").addIds("1", "3"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        // no type
+        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery().addIds("1", "3"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").addIds("1", "3")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        // no type
+        searchResponse = client().prepareSearch().setQuery(idsQuery().addIds("1", "3")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").addIds("7", "10")).get();
+        assertHitCount(searchResponse, 0l);
+
+        // repeat..., with terms
+        searchResponse = client().prepareSearch().setTypes("type1").setQuery(constantScoreQuery(termsQuery("_id", "1", "3"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+    }
+
+    @Test
+    public void term_indexQueryTestsIndexed() throws Exception {
+        term_indexQueryTests("not_analyzed");
+    }
+
+    @Test
+    public void term_indexQueryTestsNotIndexed() throws Exception {
+        term_indexQueryTests("no");
+    }
+
+    private void term_indexQueryTests(String index) throws Exception {
+        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
+        String[] indexNames = { "test1", "test2" };
+        for (String indexName : indexNames) {
+            assertAcked(client()
+                    .admin()
+                    .indices()
+                    .prepareCreate(indexName)
+                    .setSettings(indexSettings)
+                    .addMapping(
+                            "type1",
+                            jsonBuilder().startObject().startObject("type1").startObject("_index").field("index", index).endObject()
+                                    .endObject().endObject()));
+
+            indexRandom(true, client().prepareIndex(indexName, "type1", indexName + "1").setSource("field1", "value1"));
+
+        }
+
+        for (String indexName : indexNames) {
+            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termQuery("_index", indexName))).get();
+            SearchResponse searchResponse = assertSearchResponse(request);
+            assertHitCount(searchResponse, 1l);
+            assertSearchHits(searchResponse, indexName + "1");
+        }
+        for (String indexName : indexNames) {
+            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termsQuery("_index", indexName))).get();
+            SearchResponse searchResponse = assertSearchResponse(request);
+            assertHitCount(searchResponse, 1l);
+            assertSearchHits(searchResponse, indexName + "1");
+        }
+        for (String indexName : indexNames) {
+            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("_index", indexName))).get();
+            SearchResponse searchResponse = assertSearchResponse(request);
+            assertHitCount(searchResponse, 1l);
+            assertSearchHits(searchResponse, indexName + "1");
+        }
+        {
+            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termsQuery("_index", indexNames))).get();
+            SearchResponse searchResponse = assertSearchResponse(request);
+            assertHitCount(searchResponse, indexNames.length);
+        }
+    }
+
+    @Test
+    public void filterExistsMissingTests() throws Exception {
+        createIndex("test");
+
+        indexRandom(true,
+                client().prepareIndex("test", "type1", "1").setSource(jsonBuilder().startObject().startObject("obj1").field("obj1_val", "1").endObject().field("x1", "x_1").field("field1", "value1_1").field("field2", "value2_1").endObject()),
+                client().prepareIndex("test", "type1", "2").setSource(jsonBuilder().startObject().startObject("obj1").field("obj1_val", "1").endObject().field("x2", "x_2").field("field1", "value1_2").endObject()),
+                client().prepareIndex("test", "type1", "3").setSource(jsonBuilder().startObject().startObject("obj2").field("obj2_val", "1").endObject().field("y1", "y_1").field("field2", "value2_3").endObject()),
+                client().prepareIndex("test", "type1", "4").setSource(jsonBuilder().startObject().startObject("obj2").field("obj2_val", "1").endObject().field("y2", "y_2").field("field3", "value3_4").endObject()) );
+
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(existsQuery("field1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(existsQuery("field1"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("_exists_:field1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        searchResponse = client().prepareSearch().setQuery(existsQuery("field2")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch().setQuery(existsQuery("field3")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("4"));
+
+        // wildcard check
+        searchResponse = client().prepareSearch().setQuery(existsQuery("x*")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        // object check
+        searchResponse = client().prepareSearch().setQuery(existsQuery("obj1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        searchResponse = client().prepareSearch().setQuery(missingQuery("field1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+
+        searchResponse = client().prepareSearch().setQuery(missingQuery("field1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+
+        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(missingQuery("field1"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("_missing_:field1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+
+        // wildcard check
+        searchResponse = client().prepareSearch().setQuery(missingQuery("x*")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+
+        // object check
+        searchResponse = client().prepareSearch().setQuery(missingQuery("obj1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+    }
+
+    @Test
+    public void passQueryOrFilterAsJSONStringTest() throws Exception {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1_1", "field2", "value2_1").setRefresh(true).get();
+
+        WrapperQueryBuilder wrapper = new WrapperQueryBuilder("{ \"term\" : { \"field1\" : \"value1_1\" } }");
+        assertHitCount(client().prepareSearch().setQuery(wrapper).get(), 1l);
+
+        BoolQueryBuilder bool = boolQuery().must(wrapper).must(new TermQueryBuilder("field2", "value2_1"));
+        assertHitCount(client().prepareSearch().setQuery(bool).get(), 1l);
+
+        WrapperQueryBuilder wrapperFilter = wrapperQuery("{ \"term\" : { \"field1\" : \"value1_1\" } }");
+        assertHitCount(client().prepareSearch().setPostFilter(wrapperFilter).get(), 1l);
+    }
+
+    @Test
+    public void testFiltersWithCustomCacheKey() throws Exception {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
+        refresh();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testMatchQueryNumeric() throws Exception {
+        assertAcked(prepareCreate("test").addMapping("type1", "long", "type=long", "double", "type=double"));
+
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("long", 1l, "double", 1.0d),
+                client().prepareIndex("test", "type1", "2").setSource("long", 2l, "double", 2.0d),
+                client().prepareIndex("test", "type1", "3").setSource("long", 3l, "double", 3.0d));
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("long", "1")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("double", "2")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+        try {
+            client().prepareSearch().setQuery(matchQuery("double", "2 3 4")).get();
+            fail("SearchPhaseExecutionException should have been thrown");
+        } catch (SearchPhaseExecutionException ex) {
+            // number format exception
+        }
+    }
+
+    @Test
+    public void testMultiMatchQuery() throws Exception {
+        createIndex("test");
+
+        indexRandom(true,
+                client().prepareIndex("test", "type1", "1").setSource("field1", "value1", "field2", "value4", "field3", "value3"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "value2", "field2", "value5", "field3", "value2"),
+                client().prepareIndex("test", "type1", "3").setSource("field1", "value3", "field2", "value6", "field3", "value1") );
+
+        MultiMatchQueryBuilder builder = multiMatchQuery("value1 value2 value4", "field1", "field2");
+        SearchResponse searchResponse = client().prepareSearch().setQuery(builder)
+                .addAggregation(AggregationBuilders.terms("field1").field("field1")).get();
+
+        assertHitCount(searchResponse, 2l);
+        // this uses dismax so scores are equal and the order can be arbitrary
+        assertSearchHits(searchResponse, "1", "2");
+
+        builder.useDisMax(false);
+        searchResponse = client().prepareSearch()
+                .setQuery(builder)
+                .get();
+
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        client().admin().indices().prepareRefresh("test").get();
+        builder = multiMatchQuery("value1", "field1", "field2")
+                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+        searchResponse = client().prepareSearch()
+                .setQuery(builder)
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        refresh();
+        builder = multiMatchQuery("value1", "field1").field("field3", 1.5f)
+                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+        searchResponse = client().prepareSearch().setQuery(builder).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "1");
+
+        client().admin().indices().prepareRefresh("test").get();
+        builder = multiMatchQuery("value1").field("field1").field("field3", 1.5f)
+                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+        searchResponse = client().prepareSearch().setQuery(builder).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "1");
+
+        // Test lenient
+        client().prepareIndex("test", "type1", "3").setSource("field1", "value7", "field2", "value8", "field4", 5).get();
+        refresh();
+
+        builder = multiMatchQuery("value1", "field1", "field2", "field4");
+
+        assertFailures(client().prepareSearch().setQuery(builder),
+                RestStatus.BAD_REQUEST,
+                containsString("NumberFormatException[For input string: \"value1\"]"));
+
+        builder.lenient(true);
+        searchResponse = client().prepareSearch().setQuery(builder).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+    }
+
+    @Test
+    public void testMatchQueryZeroTermsQuery() {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1", "field1", "type=string,analyzer=classic", "field2", "type=string,analyzer=classic"));
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "value2").get();
+        refresh();
+
+        BoolQueryBuilder boolQuery = boolQuery()
+                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE))
+                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE));
+        SearchResponse searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 0l);
+
+        boolQuery = boolQuery()
+                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL))
+                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 1l);
+
+        boolQuery = boolQuery().must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 2l);
+    }
+
+    public void testMultiMatchQueryZeroTermsQuery() {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1", "field1", "type=string,analyzer=classic", "field2", "type=string,analyzer=classic"));
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1", "field2", "value2").get();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "value3", "field2", "value4").get();
+        refresh();
+
+
+        BoolQueryBuilder boolQuery = boolQuery()
+                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE))
+                .must(multiMatchQuery("value1", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE)); // Fields are ORed together
+        SearchResponse searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 0l);
+
+        boolQuery = boolQuery()
+                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL))
+                .must(multiMatchQuery("value4", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 1l);
+
+        boolQuery = boolQuery().must(multiMatchQuery("a", "field1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 2l);
+    }
+
+    @Test
+    public void testMultiMatchQueryMinShouldMatch() {
+        createIndex("test");
+        client().prepareIndex("test", "type1", "1").setSource("field1", new String[]{"value1", "value2", "value3"}).get();
+        client().prepareIndex("test", "type1", "2").setSource("field2", "value1").get();
+        refresh();
+
+        MultiMatchQueryBuilder multiMatchQuery = multiMatchQuery("value1 value2 foo", "field1", "field2");
+
+        multiMatchQuery.useDisMax(true);
+        multiMatchQuery.minimumShouldMatch("70%");
+        SearchResponse searchResponse = client().prepareSearch()
+                .setQuery(multiMatchQuery)
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        multiMatchQuery.minimumShouldMatch("30%");
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        multiMatchQuery.useDisMax(false);
+        multiMatchQuery.minimumShouldMatch("70%");
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        multiMatchQuery.minimumShouldMatch("30%");
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        multiMatchQuery = multiMatchQuery("value1 value2 bar", "field1");
+        multiMatchQuery.minimumShouldMatch("100%");
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
+        assertHitCount(searchResponse, 0l);
+
+        multiMatchQuery.minimumShouldMatch("70%");
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+    }
+
+    @Test
+    public void testFuzzyQueryString() {
+        createIndex("test");
+        client().prepareIndex("test", "type1", "1").setSource("str", "kimchy", "date", "2012-02-01", "num", 12).get();
+        client().prepareIndex("test", "type1", "2").setSource("str", "shay", "date", "2012-02-05", "num", 20).get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("str:kimcy~1")).get();
+        assertNoFailures(searchResponse);
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:11~1")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("date:2012-02-02~1d")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+    }
+
+    @Test
+    public void testQuotedQueryStringWithBoost() throws InterruptedException, ExecutionException {
+        float boost = 10.0f;
+        assertAcked(prepareCreate("test").setSettings(SETTING_NUMBER_OF_SHARDS, 1));
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("important", "phrase match", "less_important", "nothing important"),
+                client().prepareIndex("test", "type1", "2").setSource("important", "nothing important", "less_important", "phrase match")
+        );
+
+
+        SearchResponse searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("\"phrase match\"").field("important", boost).field("less_important")).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(boost * searchResponse.getHits().getAt(1).score(), .1));
+
+        searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("\"phrase match\"").field("important", boost).field("less_important").useDisMax(false)).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(boost * searchResponse.getHits().getAt(1).score(), .1));
+    }
+
+    @Test
+    public void testSpecialRangeSyntaxInQueryString() {
+        createIndex("test");
+        client().prepareIndex("test", "type1", "1").setSource("str", "kimchy", "date", "2012-02-01", "num", 12).get();
+        client().prepareIndex("test", "type1", "2").setSource("str", "shay", "date", "2012-02-05", "num", 20).get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>19")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>20")).get();
+        assertHitCount(searchResponse, 0l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>=20")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>11")).get();
+        assertHitCount(searchResponse, 2l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:<20")).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:<=20")).get();
+        assertHitCount(searchResponse, 2l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("+num:>11 +num:<20")).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testEmptytermsQuery() throws Exception {
+        assertAcked(prepareCreate("test").addMapping("type", "term", "type=string"));
+
+        indexRandom(true, client().prepareIndex("test", "type", "1").setSource("term", "1"),
+                client().prepareIndex("test", "type", "2").setSource("term", "2"),
+                client().prepareIndex("test", "type", "3").setSource("term", "3"),
+                client().prepareIndex("test", "type", "4").setSource("term", "4") );
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("term", new String[0]))).get();
+        assertHitCount(searchResponse, 0l);
+
+        searchResponse = client().prepareSearch("test").setQuery(idsQuery()).get();
+        assertHitCount(searchResponse, 0l);
+    }
+
+    @Test
+    public void testTermsQuery() throws Exception {
+        assertAcked(prepareCreate("test").addMapping("type", "str", "type=string", "lng", "type=long", "dbl", "type=double"));
+
+        indexRandom(true,
+                client().prepareIndex("test", "type", "1").setSource("str", "1", "lng", 1l, "dbl", 1.0d),
+                client().prepareIndex("test", "type", "2").setSource("str", "2", "lng", 2l, "dbl", 2.0d),
+                client().prepareIndex("test", "type", "3").setSource("str", "3", "lng", 3l, "dbl", 3.0d),
+                client().prepareIndex("test", "type", "4").setSource("str", "4", "lng", 4l, "dbl", 4.0d));
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("str", "1", "4"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "4");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {2, 3}))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "2", "3");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("dbl", new double[]{2, 3}))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "2", "3");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("lng", new int[] {1, 3}))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("dbl", new float[] {2, 4}))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "2", "4");
+
+        // test partial matching
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("str", "2", "5"))).get();
+        assertNoFailures(searchResponse);
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("dbl", new double[] {2, 5}))).get();
+        assertNoFailures(searchResponse);
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {2, 5}))).get();
+        assertNoFailures(searchResponse);
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        // test valid type, but no matching terms
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("str", "5", "6"))).get();
+        assertHitCount(searchResponse, 0l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("dbl", new double[] {5, 6}))).get();
+        assertHitCount(searchResponse, 0l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {5, 6}))).get();
+        assertHitCount(searchResponse, 0l);
+    }
+
+    @Test
+    public void testTermsLookupFilter() throws Exception {
+        assertAcked(prepareCreate("lookup").addMapping("type", "terms","type=string", "other", "type=string"));
+        assertAcked(prepareCreate("lookup2").addMapping("type",
+                jsonBuilder().startObject().startObject("type").startObject("properties")
+                        .startObject("arr").startObject("properties").startObject("term").field("type", "string")
+                        .endObject().endObject().endObject().endObject().endObject().endObject()));
+        assertAcked(prepareCreate("test").addMapping("type", "term", "type=string"));
+
+        indexRandom(true,
+                client().prepareIndex("lookup", "type", "1").setSource("terms", new String[]{"1", "3"}),
+                client().prepareIndex("lookup", "type", "2").setSource("terms", new String[]{"2"}),
+                client().prepareIndex("lookup", "type", "3").setSource("terms", new String[]{"2", "4"}),
+                client().prepareIndex("lookup", "type", "4").setSource("other", "value"),
+                client().prepareIndex("lookup2", "type", "1").setSource(XContentFactory.jsonBuilder().startObject()
+                        .startArray("arr")
+                        .startObject().field("term", "1").endObject()
+                        .startObject().field("term", "3").endObject()
+                        .endArray()
+                        .endObject()),
+                client().prepareIndex("lookup2", "type", "2").setSource(XContentFactory.jsonBuilder().startObject()
+                        .startArray("arr")
+                        .startObject().field("term", "2").endObject()
+                        .endArray()
+                        .endObject()),
+                client().prepareIndex("lookup2", "type", "3").setSource(XContentFactory.jsonBuilder().startObject()
+                        .startArray("arr")
+                        .startObject().field("term", "2").endObject()
+                        .startObject().field("term", "4").endObject()
+                        .endArray()
+                        .endObject()),
+                client().prepareIndex("test", "type", "1").setSource("term", "1"),
+                client().prepareIndex("test", "type", "2").setSource("term", "2"),
+                client().prepareIndex("test", "type", "3").setSource("term", "3"),
+                client().prepareIndex("test", "type", "4").setSource("term", "4") );
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term" , new TermsLookup("lookup", "type", "1", "terms"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        // same as above, just on the _id...
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("_id", new TermsLookup("lookup", "type", "1", "terms"))
+                ).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        // another search with same parameters...
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "1", "terms"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "2", "terms"))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "3", "terms"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "2", "4");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "4", "terms"))).get();
+        assertHitCount(searchResponse, 0l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "1", "arr.term"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "2", "arr.term"))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "3", "arr.term"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "2", "4");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("not_exists", new TermsLookup("lookup2", "type", "3", "arr.term"))).get();
+        assertHitCount(searchResponse, 0l);
+    }
+
+    @Test
+    public void testBasicQueryById() throws Exception {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
+        client().prepareIndex("test", "type2", "2").setSource("field1", "value2").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(idsQuery("type1", "type2").addIds("1", "2")).get();
+        assertHitCount(searchResponse, 2l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(2));
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery().addIds("1")).get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(1));
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery().addIds("1", "2")).get();
+        assertHitCount(searchResponse, 2l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(2));
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").addIds("1", "2")).get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(1));
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery(Strings.EMPTY_ARRAY).addIds("1")).get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(1));
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery("type1", "type2", "type3").addIds("1", "2", "3", "4")).get();
+        assertHitCount(searchResponse, 2l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(2));
+    }
+
+    @Test
+    public void testNumericTermsAndRanges() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1",
+                        "num_byte", "type=byte", "num_short", "type=short",
+                        "num_integer", "type=integer", "num_long", "type=long",
+                        "num_float", "type=float", "num_double", "type=double"));
+
+        client().prepareIndex("test", "type1", "1").setSource("num_byte", 1, "num_short", 1, "num_integer", 1,
+                "num_long", 1, "num_float", 1, "num_double", 1).get();
+
+        client().prepareIndex("test", "type1", "2").setSource("num_byte", 2, "num_short", 2, "num_integer", 2,
+                "num_long", 2, "num_float", 2, "num_double", 2).get();
+
+        client().prepareIndex("test", "type1", "17").setSource("num_byte", 17, "num_short", 17, "num_integer", 17,
+                "num_long", 17, "num_float", 17, "num_double", 17).get();
+        refresh();
+
+        SearchResponse searchResponse;
+        logger.info("--> term query on 1");
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_byte", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_short", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_integer", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_long", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_float", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_double", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        logger.info("--> terms query on 1");
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_byte", new int[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_short", new int[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_integer", new int[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_long", new int[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_float", new double[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_double", new double[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        logger.info("--> term filter on 1");
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_byte", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_short", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_integer", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_long", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_float", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_double", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        logger.info("--> terms filter on 1");
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_byte", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_short", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_integer", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_long", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_float", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_double", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+    }
+
+    @Test
+    public void testNumericRangeFilter_2826() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1",
+                        "num_byte", "type=byte", "num_short", "type=short",
+                        "num_integer", "type=integer", "num_long", "type=long",
+                        "num_float", "type=float", "num_double", "type=double"));
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "test1", "num_long", 1).get();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "test1", "num_long", 2).get();
+        client().prepareIndex("test", "type1", "3").setSource("field1", "test2", "num_long", 3).get();
+        client().prepareIndex("test", "type1", "4").setSource("field1", "test2", "num_long", 4).get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch("test").setPostFilter(
+                boolQuery()
+                        .should(rangeQuery("num_long").from(1).to(2))
+                        .should(rangeQuery("num_long").from(3).to(4))
+        ).get();
+        assertHitCount(searchResponse, 4l);
+
+        // This made 2826 fail! (only with bit based filters)
+        searchResponse = client().prepareSearch("test").setPostFilter(
+                boolQuery()
+                        .should(rangeQuery("num_long").from(1).to(2))
+                        .should(rangeQuery("num_long").from(3).to(4))
+        ).get();
+        assertHitCount(searchResponse, 4l);
+
+        // This made #2979 fail!
+        searchResponse = client().prepareSearch("test").setPostFilter(
+                boolQuery()
+                        .must(termQuery("field1", "test1"))
+                        .should(rangeQuery("num_long").from(1).to(2))
+                        .should(rangeQuery("num_long").from(3).to(4))
+        ).get();
+        assertHitCount(searchResponse, 2l);
+    }
+
+    @Test
+    public void testEmptyTopLevelFilter() {
+        client().prepareIndex("test", "type", "1").setSource("field", "value").setRefresh(true).get();
+
+        SearchResponse searchResponse = client().prepareSearch().setPostFilter("{}").get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test // see #2926
+    public void testMustNot() throws IOException, ExecutionException, InterruptedException {
+        assertAcked(prepareCreate("test")
+                //issue manifested only with shards>=2
+                .setSettings(SETTING_NUMBER_OF_SHARDS, between(2, DEFAULT_MAX_NUM_SHARDS)));
+
+
+        indexRandom(true, client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar"),
+                client().prepareIndex("test", "test", "2").setSource("description", "foo other anything"),
+                client().prepareIndex("test", "test", "3").setSource("description", "foo other"),
+                client().prepareIndex("test", "test", "4").setSource("description", "foo"));
+
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchAllQuery())
+                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH).get();
+        assertHitCount(searchResponse, 4l);
+
+        searchResponse = client().prepareSearch("test").setQuery(
+                boolQuery()
+                        .mustNot(matchQuery("description", "anything").type(Type.BOOLEAN))
+        ).setSearchType(SearchType.DFS_QUERY_THEN_FETCH).get();
+        assertHitCount(searchResponse, 2l);
+    }
+
+    @Test // see #2994
+    public void testSimpleSpan() throws IOException, ExecutionException, InterruptedException {
+        createIndex("test");
+
+
+        indexRandom(true, client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar"),
+                client().prepareIndex("test", "test", "2").setSource("description", "foo other anything"),
+                client().prepareIndex("test", "test", "3").setSource("description", "foo other"),
+                client().prepareIndex("test", "test", "4").setSource("description", "foo"));
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanTermQuery("description", "bar"))).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test").setQuery(
+                spanNearQuery(spanTermQuery("description", "foo"), 3)
+                        .clause(spanTermQuery("description", "other"))).get();
+        assertHitCount(searchResponse, 3l);
+    }
+
+    @Test
+    public void testSpanMultiTermQuery() throws IOException {
+        createIndex("test");
+
+        client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar", "count", 1).get();
+        client().prepareIndex("test", "test", "2").setSource("description", "foo other anything", "count", 2).get();
+        client().prepareIndex("test", "test", "3").setSource("description", "foo other", "count", 3).get();
+        client().prepareIndex("test", "test", "4").setSource("description", "fop", "count", 4).get();
+        refresh();
+
+        SearchResponse response = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(fuzzyQuery("description", "fop")))).get();
+        assertHitCount(response, 4);
+
+        response = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(prefixQuery("description", "fo")))).get();
+        assertHitCount(response, 4);
+
+        response = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(wildcardQuery("description", "oth*")))).get();
+        assertHitCount(response, 3);
+
+        response = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(QueryBuilders.rangeQuery("description").from("ffa").to("foo"))))
+                .execute().actionGet();
+        assertHitCount(response, 3);
+
+        response = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(regexpQuery("description", "fo{2}")))).get();
+        assertHitCount(response, 3);
+    }
+
+    @Test
+    public void testSpanNot() throws IOException, ExecutionException, InterruptedException {
+        createIndex("test");
+
+        client().prepareIndex("test", "test", "1").setSource("description", "the quick brown fox jumped over the lazy dog").get();
+        client().prepareIndex("test", "test", "2").setSource("description", "the quick black fox leaped over the sleeping dog").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "brown"))).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "sleeping")).dist(5)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "jumped")).pre(1).post(1)).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testSimpleDFSQuery() throws IOException {
+        assertAcked(prepareCreate("test")
+            .addMapping("s", jsonBuilder()
+                .startObject()
+                .startObject("s")
+                .startObject("_routing")
+                .field("required", true)
+                .endObject()
+                .startObject("properties")
+                .startObject("online")
+                .field("type", "boolean")
+                .endObject()
+                .startObject("ts")
+                .field("type", "date")
+                .field("ignore_malformed", false)
+                .field("format", "epoch_millis")
+                .endObject()
+                .startObject("bs")
+                .field("type", "string")
+                .field("index", "not_analyzed")
+                .endObject()
+                .endObject()
+                .endObject()
+                .endObject())
+            .addMapping("bs", "online", "type=boolean", "ts", "type=date,ignore_malformed=false,format=epoch_millis"));
+
+
+        client().prepareIndex("test", "s", "1").setRouting("Y").setSource("online", false, "bs", "Y", "ts", System.currentTimeMillis() - 100).get();
+        client().prepareIndex("test", "s", "2").setRouting("X").setSource("online", true, "bs", "X", "ts", System.currentTimeMillis() - 10000000).get();
+        client().prepareIndex("test", "bs", "3").setSource("online", false, "ts", System.currentTimeMillis() - 100).get();
+        client().prepareIndex("test", "bs", "4").setSource("online", true, "ts", System.currentTimeMillis() - 123123).get();
+        refresh();
+
+        SearchResponse response = client().prepareSearch("test")
+                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                .setQuery(
+                        boolQuery()
+                                .must(termQuery("online", true))
+                                .must(boolQuery()
+                                        .should(boolQuery()
+                                                .must(rangeQuery("ts").lt(System.currentTimeMillis() - (15 * 1000)))
+                                                .must(termQuery("_type", "bs"))
+                                        )
+                                        .should(boolQuery()
+                                                .must(rangeQuery("ts").lt(System.currentTimeMillis() - (15 * 1000)))
+                                                .must(termQuery("_type", "s"))
+                                        )
+                                )
+                )
+                .setVersion(true)
+                .setFrom(0).setSize(100).setExplain(true).get();
+        assertNoFailures(response);
+    }
+
+    @Test
+    public void testMultiFieldQueryString() {
+        client().prepareIndex("test", "s", "1").setSource("field1", "value1", "field2", "value2").setRefresh(true).get();
+
+        logger.info("regular");
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value1").field("field1").field("field2")).get(), 1);
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value1")).get(), 1);
+        logger.info("prefix");
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value*").field("field1").field("field2")).get(), 1);
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value*")).get(), 1);
+        logger.info("wildcard");
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("v?lue*").field("field1").field("field2")).get(), 1);
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:v?lue*")).get(), 1);
+        logger.info("fuzzy");
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value~").field("field1").field("field2")).get(), 1);
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value~")).get(), 1);
+        logger.info("regexp");
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("/value[01]/").field("field1").field("field2")).get(), 1);
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:/value[01]/")).get(), 1);
+    }
+
+    // see #3881 - for extensive description of the issue
+    @Test
+    public void testMatchQueryWithSynonyms() throws IOException {
+        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
+                .put(indexSettings())
+                .put("index.analysis.analyzer.index.type", "custom")
+                .put("index.analysis.analyzer.index.tokenizer", "standard")
+                .put("index.analysis.analyzer.index.filter", "lowercase")
+                .put("index.analysis.analyzer.search.type", "custom")
+                .put("index.analysis.analyzer.search.tokenizer", "standard")
+                .putArray("index.analysis.analyzer.search.filter", "lowercase", "synonym")
+                .put("index.analysis.filter.synonym.type", "synonym")
+                .putArray("index.analysis.filter.synonym.synonyms", "fast, quick"));
+        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
+
+        client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
+        refresh();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fast").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+
+        client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
+        refresh();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2);
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2);
+    }
+
+    @Test
+    public void testMatchQueryWithStackedStems() throws IOException {
+        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
+                .put(indexSettings())
+                .put("index.analysis.analyzer.index.type", "custom")
+                .put("index.analysis.analyzer.index.tokenizer", "standard")
+                .put("index.analysis.analyzer.index.filter", "lowercase")
+                .put("index.analysis.analyzer.search.type", "custom")
+                .put("index.analysis.analyzer.search.tokenizer", "standard")
+                .putArray("index.analysis.analyzer.search.filter", "lowercase", "keyword_repeat", "porterStem", "unique_stem")
+                .put("index.analysis.filter.unique_stem.type", "unique")
+                .put("index.analysis.filter.unique_stem.only_on_same_position", true));
+        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
+
+        client().prepareIndex("test", "test", "1").setSource("text", "the fox runs across the street").get();
+        refresh();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+
+        client().prepareIndex("test", "test", "2").setSource("text", "run fox run").get();
+        refresh();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2);
+    }
+
+    @Test
+    public void testQueryStringWithSynonyms() throws IOException {
+        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
+                .put(indexSettings())
+                .put("index.analysis.analyzer.index.type", "custom")
+                .put("index.analysis.analyzer.index.tokenizer", "standard")
+                .put("index.analysis.analyzer.index.filter", "lowercase")
+                .put("index.analysis.analyzer.search.type", "custom")
+                .put("index.analysis.analyzer.search.tokenizer", "standard")
+                .putArray("index.analysis.analyzer.search.filter", "lowercase", "synonym")
+                .put("index.analysis.filter.synonym.type", "synonym")
+                .putArray("index.analysis.filter.synonym.synonyms", "fast, quick"));
+        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
+
+        client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("fast").defaultField("text").defaultOperator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+
+        client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
+        refresh();
+
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2);
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2);
+    }
+
+    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3898
+    public void testCustomWordDelimiterQueryString() {
+        assertAcked(client().admin().indices().prepareCreate("test")
+                .setSettings("analysis.analyzer.my_analyzer.type", "custom",
+                        "analysis.analyzer.my_analyzer.tokenizer", "whitespace",
+                        "analysis.analyzer.my_analyzer.filter", "custom_word_delimiter",
+                        "analysis.filter.custom_word_delimiter.type", "word_delimiter",
+                        "analysis.filter.custom_word_delimiter.generate_word_parts", "true",
+                        "analysis.filter.custom_word_delimiter.generate_number_parts", "false",
+                        "analysis.filter.custom_word_delimiter.catenate_numbers", "true",
+                        "analysis.filter.custom_word_delimiter.catenate_words", "false",
+                        "analysis.filter.custom_word_delimiter.split_on_case_change", "false",
+                        "analysis.filter.custom_word_delimiter.split_on_numerics", "false",
+                        "analysis.filter.custom_word_delimiter.stem_english_possessive", "false")
+                .addMapping("type1", "field1", "type=string,analyzer=my_analyzer", "field2", "type=string,analyzer=my_analyzer"));
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "foo bar baz", "field2", "not needed").get();
+        refresh();
+
+        SearchResponse response = client()
+                .prepareSearch("test")
+                .setQuery(
+                        queryStringQuery("foo.baz").useDisMax(false).defaultOperator(Operator.AND)
+                                .field("field1").field("field2")).get();
+        assertHitCount(response, 1l);
+    }
+
+    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3797
+    public void testMultiMatchLenientIssue3797() {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", 123, "field2", "value2").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(multiMatchQuery("value2", "field2").field("field1", 2).lenient(true).useDisMax(false)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(multiMatchQuery("value2", "field2").field("field1", 2).lenient(true).useDisMax(true)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(multiMatchQuery("value2").field("field2", 2).lenient(true)).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testAllFieldEmptyMapping() throws Exception {
+        client().prepareIndex("myindex", "mytype").setId("1").setSource("{}").setRefresh(true).get();
+        SearchResponse response = client().prepareSearch("myindex").setQuery(matchQuery("_all", "foo")).get();
+        assertNoFailures(response);
+    }
+
+    @Test
+    public void testAllDisabledButQueried() throws Exception {
+        createIndex("myindex");
+        assertAcked(client().admin().indices().preparePutMapping("myindex").setType("mytype").setSource(
+                jsonBuilder().startObject().startObject("mytype").startObject("_all").field("enabled", false)));
+        client().prepareIndex("myindex", "mytype").setId("1").setSource("bar", "foo").setRefresh(true).get();
+        SearchResponse response = client().prepareSearch("myindex").setQuery(matchQuery("_all", "foo")).get();
+        assertNoFailures(response);
+        assertHitCount(response, 0);
+    }
+
+    @Test
+    public void testIndicesQuery() throws Exception {
+        createIndex("index1", "index2", "index3");
+
+
+        client().prepareIndex("index1", "type1").setId("1").setSource("text", "value1").get();
+        client().prepareIndex("index2", "type2").setId("2").setSource("text", "value2").get();
+        client().prepareIndex("index3", "type3").setId("3").setSource("text", "value3").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch("index1", "index2", "index3")
+                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
+                        .noMatchQuery(matchQuery("text", "value2"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        //default no match query is match_all
+        searchResponse = client().prepareSearch("index1", "index2", "index3")
+                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")).get();
+        assertHitCount(searchResponse, 3l);
+        assertSearchHits(searchResponse, "1", "2", "3");
+        searchResponse = client().prepareSearch("index1", "index2", "index3")
+                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
+                        .noMatchQuery(QueryBuilders.matchAllQuery())).get();
+        assertHitCount(searchResponse, 3l);
+        assertSearchHits(searchResponse, "1", "2", "3");
+
+        searchResponse = client().prepareSearch("index1", "index2", "index3")
+                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
+                        .noMatchQuery("none")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+    }
+
+    @Test // https://github.com/elasticsearch/elasticsearch/issues/2416
+    public void testIndicesQuerySkipParsing() throws Exception {
+        createIndex("simple");
+        assertAcked(prepareCreate("related")
+                .addMapping("child", jsonBuilder().startObject().startObject("child").startObject("_parent").field("type", "parent")
+                        .endObject().endObject().endObject()));
+
+        client().prepareIndex("simple", "lone").setId("1").setSource("text", "value1").get();
+        client().prepareIndex("related", "parent").setId("2").setSource("text", "parent").get();
+        client().prepareIndex("related", "child").setId("3").setParent("2").setSource("text", "value2").get();
+        refresh();
+
+        //has_child fails if executed on "simple" index
+        try {
+            client().prepareSearch("simple")
+                    .setQuery(hasChildQuery("child", matchQuery("text", "value"))).get();
+            fail("Should have failed as has_child query can only be executed against parent-child types");
+        } catch (SearchPhaseExecutionException e) {
+            assertThat(e.shardFailures().length, greaterThan(0));
+            for (ShardSearchFailure shardSearchFailure : e.shardFailures()) {
+                assertThat(shardSearchFailure.reason(), containsString("no mapping found for type [child]"));
+            }
+        }
+
+        //has_child doesn't get parsed for "simple" index
+        SearchResponse searchResponse = client().prepareSearch("related", "simple")
+                .setQuery(indicesQuery(hasChildQuery("child", matchQuery("text", "value2")), "related")
+                        .noMatchQuery(matchQuery("text", "value1"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+    }
+
+    @Test
+    public void testIndicesQueryMissingIndices() throws IOException, ExecutionException, InterruptedException {
+        createIndex("index1");
+        createIndex("index2");
+
+        indexRandom(true,
+                client().prepareIndex("index1", "type1", "1").setSource("field", "match"),
+                client().prepareIndex("index1", "type1", "2").setSource("field", "no_match"),
+                client().prepareIndex("index2", "type1", "10").setSource("field", "match"),
+                client().prepareIndex("index2", "type1", "20").setSource("field", "no_match"),
+                client().prepareIndex("index3", "type1", "100").setSource("field", "match"),
+                client().prepareIndex("index3", "type1", "200").setSource("field", "no_match"));
+
+        //all indices are missing
+        SearchResponse searchResponse = client().prepareSearch().setQuery(
+                indicesQuery(termQuery("field", "missing"), "test1", "test2", "test3")
+                        .noMatchQuery(termQuery("field", "match"))).get();
+
+        assertHitCount(searchResponse, 3l);
+
+        for (SearchHit hit : searchResponse.getHits().getHits()) {
+            if ("index1".equals(hit.index())) {
+                assertThat(hit, hasId("1"));
+            } else if ("index2".equals(hit.index())) {
+                assertThat(hit, hasId("10"));
+            } else if ("index3".equals(hit.index())) {
+                assertThat(hit, hasId("100"));
+            } else {
+                fail("Returned documents should belong to either index1, index2 or index3");
+            }
+        }
+
+        //only one index specified, which is missing
+        searchResponse = client().prepareSearch().setQuery(
+                indicesQuery(termQuery("field", "missing"), "test1")
+                        .noMatchQuery(termQuery("field", "match"))).get();
+
+        assertHitCount(searchResponse, 3l);
+
+        for (SearchHit hit : searchResponse.getHits().getHits()) {
+            if ("index1".equals(hit.index())) {
+                assertThat(hit, hasId("1"));
+            } else if ("index2".equals(hit.index())) {
+                assertThat(hit, hasId("10"));
+            } else if ("index3".equals(hit.index())) {
+                assertThat(hit, hasId("100"));
+            } else {
+                fail("Returned documents should belong to either index1, index2 or index3");
+            }
+        }
+
+        //more than one index specified, one of them is missing
+        searchResponse = client().prepareSearch().setQuery(
+                indicesQuery(termQuery("field", "missing"), "index1", "test1")
+                        .noMatchQuery(termQuery("field", "match"))).get();
+
+        assertHitCount(searchResponse, 2l);
+
+        for (SearchHit hit : searchResponse.getHits().getHits()) {
+            if ("index2".equals(hit.index())) {
+                assertThat(hit, hasId("10"));
+            } else if ("index3".equals(hit.index())) {
+                assertThat(hit, hasId("100"));
+            } else {
+                fail("Returned documents should belong to either index2 or index3");
+            }
+        }
+    }
+
+    @Test
+    public void testMinScore() throws ExecutionException, InterruptedException {
+        createIndex("test");
+
+        indexRandom(true,
+                client().prepareIndex("test", "test", "1").setSource("score", 1.5),
+                client().prepareIndex("test", "test", "2").setSource("score", 1.0),
+                client().prepareIndex("test", "test", "3").setSource("score", 2.0),
+                client().prepareIndex("test", "test", "4").setSource("score", 0.5));
+
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(
+                functionScoreQuery(ScoreFunctionBuilders.fieldValueFactorFunction("score")).setMinScore(1.5f)).get();
+        assertHitCount(searchResponse, 2);
+        assertFirstHit(searchResponse, hasId("3"));
+        assertSecondHit(searchResponse, hasId("1"));
+    }
+
+    @Test
+    public void testQueryStringWithSlopAndFields() {
+        createIndex("test");
+
+        client().prepareIndex("test", "customer", "1").setSource("desc", "one two three").get();
+        client().prepareIndex("test", "product", "2").setSource("desc", "one two three").get();
+        refresh();
+        {
+            SearchResponse searchResponse = client().prepareSearch("test").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
+            assertHitCount(searchResponse, 2);
+        }
+        {
+            SearchResponse searchResponse = client().prepareSearch("test").setTypes("product").setQuery(QueryBuilders.queryStringQuery("\"one two\"").field("desc")).get();
+            assertHitCount(searchResponse, 1);
+        }
+        {
+            SearchResponse searchResponse = client().prepareSearch("test").setTypes("product").setQuery(QueryBuilders.queryStringQuery("\"one three\"~5").field("desc")).get();
+            assertHitCount(searchResponse, 1);
+        }
+        {
+            SearchResponse searchResponse = client().prepareSearch("test").setTypes("customer").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
+            assertHitCount(searchResponse, 1);
+        }
+        {
+            SearchResponse searchResponse = client().prepareSearch("test").setTypes("customer").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
+            assertHitCount(searchResponse, 1);
+        }
+    }
+
+    @Test
+    public void testDateProvidedAsNumber() throws ExecutionException, InterruptedException {
+        createIndex("test");
+        assertAcked(client().admin().indices().preparePutMapping("test").setType("type").setSource("field", "type=date,format=epoch_millis").get());
+        indexRandom(true, client().prepareIndex("test", "type", "1").setSource("field", -1000000000001L),
+                client().prepareIndex("test", "type", "2").setSource("field", -1000000000000L),
+                client().prepareIndex("test", "type", "3").setSource("field", -999999999999L));
+
+
+        assertHitCount(client().prepareCount("test").setQuery(rangeQuery("field").lte(-1000000000000L)).get(), 2);
+        assertHitCount(client().prepareCount("test").setQuery(rangeQuery("field").lte(-999999999999L)).get(), 3);
+    }
+
+    @Test
+    public void testRangeQueryWithTimeZone() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1", "date", "type=date", "num", "type=integer"));
+
+        indexRandom(true,
+                client().prepareIndex("test", "type1", "1").setSource("date", "2014-01-01", "num", 1),
+                client().prepareIndex("test", "type1", "2").setSource("date", "2013-12-31T23:00:00", "num", 2),
+                client().prepareIndex("test", "type1", "3").setSource("date", "2014-01-01T01:00:00", "num", 3),
+                // Now in UTC+1
+                client().prepareIndex("test", "type1", "4").setSource("date", DateTime.now(DateTimeZone.forOffsetHours(1)).getMillis(), "num", 4));
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T00:00:00").to("2014-01-01T00:59:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2013-12-31T23:00:00").to("2013-12-31T23:59:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T01:00:00").to("2014-01-01T01:59:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
+
+        // We explicitly define a time zone in the from/to dates so whatever the time zone is, it won't be used
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T00:00:00Z").to("2014-01-01T00:59:00Z").timeZone("+10:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2013-12-31T23:00:00Z").to("2013-12-31T23:59:00Z").timeZone("+10:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T01:00:00Z").to("2014-01-01T01:59:00Z").timeZone("+10:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
+
+        // We define a time zone to be applied to the filter and from/to have no time zone
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T03:00:00").to("2014-01-01T03:59:00").timeZone("+03:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T02:00:00").to("2014-01-01T02:59:00").timeZone("+03:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T04:00:00").to("2014-01-01T04:59:00").timeZone("+03:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
+
+        // When we use long values, it means we have ms since epoch UTC based so we don't apply any transformation
+        try {
+            client().prepareSearch("test")
+                    .setQuery(QueryBuilders.rangeQuery("date").from(1388534400000L).to(1388537940999L).timeZone("+01:00"))
+                    .get();
+            fail("A Range Filter using ms since epoch with a TimeZone should raise a ParsingException");
+        } catch (SearchPhaseExecutionException e) {
+            // We expect it
+        }
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01").to("2014-01-01T00:59:00").timeZone("-01:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("now/d-1d").timeZone("+01:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("4"));
+
+        // A Range Filter on a numeric field with a TimeZone should raise an exception
+        try {
+            client().prepareSearch("test")
+                    .setQuery(QueryBuilders.rangeQuery("num").from("0").to("4").timeZone("-01:00"))
+                    .get();
+            fail("A Range Filter on a numeric field with a TimeZone should raise a ParsingException");
+        } catch (SearchPhaseExecutionException e) {
+            // We expect it
+        }
+    }
+
+    @Test
+    public void testSearchEmptyDoc() {
+        assertAcked(prepareCreate("test").setSettings("{\"index.analysis.analyzer.default.type\":\"keyword\"}"));
+        client().prepareIndex("test", "type1", "1").setSource("{}").get();
+
+        refresh();
+        assertHitCount(client().prepareSearch().setQuery(matchAllQuery()).get(), 1l);
+    }
+
+    @Test  // see #5120
+    public void testNGramCopyField() {
+        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
+                .put(indexSettings())
+                .put("index.analysis.analyzer.my_ngram_analyzer.type", "custom")
+                .put("index.analysis.analyzer.my_ngram_analyzer.tokenizer", "my_ngram_tokenizer")
+                .put("index.analysis.tokenizer.my_ngram_tokenizer.type", "nGram")
+                .put("index.analysis.tokenizer.my_ngram_tokenizer.min_gram", "1")
+                .put("index.analysis.tokenizer.my_ngram_tokenizer.max_gram", "10")
+                .putArray("index.analysis.tokenizer.my_ngram_tokenizer.token_chars", new String[0]));
+        assertAcked(builder.addMapping("test", "origin", "type=string,copy_to=meta", "meta", "type=string,analyzer=my_ngram_analyzer"));
+        // we only have ngrams as the index analyzer so searches will get standard analyzer
+
+
+        client().prepareIndex("test", "test", "1").setSource("origin", "C.A1234.5678")
+                .setRefresh(true)
+                .get();
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(matchQuery("meta", "1234"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(matchQuery("meta", "1234.56"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termQuery("meta", "A1234"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termQuery("meta", "a1234"))
+                .get();
+        assertHitCount(searchResponse, 0l); // it's upper case
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(matchQuery("meta", "A1234").analyzer("my_ngram_analyzer"))
+                .get(); // force ngram analyzer
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(matchQuery("meta", "a1234").analyzer("my_ngram_analyzer"))
+                .get(); // this one returns a hit since it's default operator is OR
+        assertHitCount(searchResponse, 1l);
+    }
+
+    public void testMatchPhrasePrefixQuery() throws ExecutionException, InterruptedException {
+        createIndex("test1");
+        indexRandom(true, client().prepareIndex("test1", "type1", "1").setSource("field", "Johnnie Walker Black Label"),
+        client().prepareIndex("test1", "type1", "2").setSource("field", "trying out Elasticsearch"));
+
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field", "Johnnie la").slop(between(2,5)).type(Type.PHRASE_PREFIX)).get();
+        assertHitCount(searchResponse, 1l);
+        assertSearchHits(searchResponse, "1");
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field", "trying").type(Type.PHRASE_PREFIX)).get();
+        assertHitCount(searchResponse, 1l);
+        assertSearchHits(searchResponse, "2");
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field", "try").type(Type.PHRASE_PREFIX)).get();
+        assertHitCount(searchResponse, 1l);
+        assertSearchHits(searchResponse, "2");
+    }
+
+    @Test
+    public void testQueryStringParserCache() throws Exception {
+        createIndex("test");
+        indexRandom(true, false, client().prepareIndex("test", "type", "1").setSource("nameTokens", "xyz"));
+
+
+        SearchResponse response = client().prepareSearch("test")
+                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                .setQuery(QueryBuilders.queryStringQuery("xyz").boost(100))
+                .get();
+        assertThat(response.getHits().totalHits(), equalTo(1l));
+        assertThat(response.getHits().getAt(0).id(), equalTo("1"));
+
+        float first = response.getHits().getAt(0).getScore();
+        for (int i = 0; i < 100; i++) {
+            response = client().prepareSearch("test")
+                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                    .setQuery(QueryBuilders.queryStringQuery("xyz").boost(100))
+                    .get();
+
+            assertThat(response.getHits().totalHits(), equalTo(1l));
+            assertThat(response.getHits().getAt(0).id(), equalTo("1"));
+            float actual = response.getHits().getAt(0).getScore();
+            assertThat(i + " expected: " + first + " actual: " + actual, Float.compare(first, actual), equalTo(0));
+        }
+    }
+
+    @Test // see #7686.
+    public void testIdsQueryWithInvalidValues() throws Exception {
+        createIndex("test");
+        indexRandom(true, false, client().prepareIndex("test", "type", "1").setSource("body", "foo"));
+
+        try {
+            client().prepareSearch("test")
+                    .setTypes("type")
+                    .setQuery("{\n" +
+                            "  \"ids\": {\n" +
+                            "    \"values\": [[\"1\"]]\n" +
+                            "  }\n" +
+                            "}")
+                    .get();
+            fail("query is invalid and should have produced a parse exception");
+        } catch (Exception e) {
+            assertThat("query could not be parsed due to bad format: " + e.toString(),
+                    e.toString().contains("Illegal value for id, expecting a string or number, got: START_ARRAY"),
+                    equalTo(true));
+        }
+    }
+}
diff --git a/plugins/lang-javascript/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java b/plugins/lang-javascript/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java
index f207897..0adf9ca 100644
--- a/plugins/lang-javascript/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java
+++ b/plugins/lang-javascript/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java
@@ -22,6 +22,7 @@ package org.elasticsearch.script.javascript;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.Scorer;
 import org.elasticsearch.SpecialPermission;
+import org.elasticsearch.bootstrap.BootstrapInfo;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
@@ -36,6 +37,10 @@ import org.mozilla.javascript.*;
 import org.mozilla.javascript.Script;
 
 import java.io.IOException;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.security.CodeSource;
+import java.security.cert.Certificate;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicLong;
@@ -105,7 +110,11 @@ public class JavaScriptScriptEngineService extends AbstractComponent implements
         try {
             ctx.setWrapFactory(wrapFactory);
             ctx.setOptimizationLevel(optimizationLevel);
-            return ctx.compileString(script, generateScriptName(), 1, null);
+            ctx.setSecurityController(new PolicySecurityController());
+            return ctx.compileString(script, generateScriptName(), 1, 
+                      new CodeSource(new URL("file:" + BootstrapInfo.UNTRUSTED_CODEBASE), (Certificate[]) null));
+        } catch (MalformedURLException e) {
+            throw new RuntimeException(e);
         } finally {
             Context.exit();
         }
diff --git a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptSecurityTests.java b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptSecurityTests.java
new file mode 100644
index 0000000..36636eb
--- /dev/null
+++ b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptSecurityTests.java
@@ -0,0 +1,89 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.script.javascript;
+
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.script.CompiledScript;
+import org.elasticsearch.script.ScriptService;
+import org.elasticsearch.test.ESTestCase;
+import org.junit.After;
+import org.junit.Before;
+import org.mozilla.javascript.WrappedException;
+
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ * Tests for the Javascript security permissions
+ */
+public class JavaScriptSecurityTests extends ESTestCase {
+    
+    private JavaScriptScriptEngineService se;
+
+    @Before
+    public void setup() {
+        se = new JavaScriptScriptEngineService(Settings.Builder.EMPTY_SETTINGS);
+    }
+
+    @After
+    public void close() {
+        se.close();
+    }
+
+    /** runs a script */
+    private void doTest(String script) {
+        Map<String, Object> vars = new HashMap<String, Object>();
+        se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "test", "js", se.compile(script)), vars);
+    }
+    
+    /** asserts that a script runs without exception */
+    private void assertSuccess(String script) {
+        doTest(script);
+    }
+    
+    /** assert that a security exception is hit */
+    private void assertFailure(String script) {
+        try {
+            doTest(script);
+            fail("did not get expected exception");
+        } catch (WrappedException expected) {
+            Throwable cause = expected.getCause();
+            assertNotNull(cause);
+            assertTrue("unexpected exception: " + cause, cause instanceof SecurityException);
+        }
+    }
+    
+    /** Test some javascripts that are ok */
+    public void testOK() {
+        assertSuccess("1 + 2");
+        assertSuccess("Math.cos(Math.PI)");
+    }
+    
+    /** Test some javascripts that should hit security exception */
+    public void testNotOK() {
+        // sanity check :)
+        assertFailure("java.lang.Runtime.getRuntime().halt(0)");
+        // check a few things more restrictive than the ordinary policy
+        // no network
+        assertFailure("new java.net.Socket(\"localhost\", 1024)");
+        // no files
+        assertFailure("java.io.File.createTempFile(\"test\", \"tmp\")");
+    }
+}
diff --git a/plugins/lang-python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java b/plugins/lang-python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java
index f4d83cf..87bfbb5 100644
--- a/plugins/lang-python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java
+++ b/plugins/lang-python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java
@@ -20,8 +20,11 @@
 package org.elasticsearch.script.python;
 
 import java.io.IOException;
+import java.security.AccessControlContext;
 import java.security.AccessController;
+import java.security.Permissions;
 import java.security.PrivilegedAction;
+import java.security.ProtectionDomain;
 import java.util.Map;
 
 import org.apache.lucene.index.LeafReaderContext;
@@ -125,7 +128,8 @@ public class PythonScriptEngineService extends AbstractComponent implements Scri
     public Object execute(CompiledScript compiledScript, Map<String, Object> vars) {
         PyObject pyVars = Py.java2py(vars);
         interp.setLocals(pyVars);
-        PyObject ret = interp.eval((PyCode) compiledScript.compiled());
+        // eval the script with reduced privileges
+        PyObject ret = evalRestricted((PyCode) compiledScript.compiled());
         if (ret == null) {
             return null;
         }
@@ -171,7 +175,8 @@ public class PythonScriptEngineService extends AbstractComponent implements Scri
         @Override
         public Object run() {
             interp.setLocals(pyVars);
-            PyObject ret = interp.eval(code);
+            // eval the script with reduced privileges
+            PyObject ret = evalRestricted(code);
             if (ret == null) {
                 return null;
             }
@@ -229,7 +234,8 @@ public class PythonScriptEngineService extends AbstractComponent implements Scri
         @Override
         public Object run() {
             interp.setLocals(pyVars);
-            PyObject ret = interp.eval(code);
+            // eval the script with reduced privileges
+            PyObject ret = evalRestricted(code);
             if (ret == null) {
                 return null;
             }
@@ -257,6 +263,27 @@ public class PythonScriptEngineService extends AbstractComponent implements Scri
         }
     }
 
+    // we don't have a way to specify codesource for generated jython classes,
+    // so we just run them with a special context to reduce privileges
+    private static final AccessControlContext PY_CONTEXT;
+    static {
+        Permissions none = new Permissions();
+        none.setReadOnly();
+        PY_CONTEXT = new AccessControlContext(new ProtectionDomain[] {
+                new ProtectionDomain(null, none)
+        });
+    }
+
+    /** Evaluates with reduced privileges */
+    private final PyObject evalRestricted(final PyCode code) {
+        // eval the script with reduced privileges
+        return AccessController.doPrivileged(new PrivilegedAction<PyObject>() {
+            @Override
+            public PyObject run() {
+                return interp.eval(code);
+            }
+        }, PY_CONTEXT);
+    }
 
     public static Object unwrapValue(Object value) {
         if (value == null) {
diff --git a/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonSecurityTests.java b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonSecurityTests.java
new file mode 100644
index 0000000..745a109
--- /dev/null
+++ b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonSecurityTests.java
@@ -0,0 +1,92 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.script.python;
+
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.script.CompiledScript;
+import org.elasticsearch.script.ScriptService;
+import org.elasticsearch.test.ESTestCase;
+import org.junit.After;
+import org.junit.Before;
+import org.python.core.PyException;
+
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ * Tests for Python security permissions
+ */
+public class PythonSecurityTests extends ESTestCase {
+    
+    private PythonScriptEngineService se;
+
+    @Before
+    public void setup() {
+        se = new PythonScriptEngineService(Settings.Builder.EMPTY_SETTINGS);
+    }
+
+    @After
+    public void close() {
+        // We need to clear some system properties
+        System.clearProperty("python.cachedir.skip");
+        System.clearProperty("python.console.encoding");
+        se.close();
+    }
+
+    /** runs a script */
+    private void doTest(String script) {
+        Map<String, Object> vars = new HashMap<String, Object>();
+        se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "test", "python", se.compile(script)), vars);
+    }
+    
+    /** asserts that a script runs without exception */
+    private void assertSuccess(String script) {
+        doTest(script);
+    }
+    
+    /** assert that a security exception is hit */
+    private void assertFailure(String script) {
+        try {
+            doTest(script);
+            fail("did not get expected exception");
+        } catch (PyException expected) {
+            Throwable cause = expected.getCause();
+            assertNotNull("null cause for exception: " + expected, cause);
+            assertTrue("unexpected exception: " + cause, cause instanceof SecurityException);
+        }
+    }
+    
+    /** Test some py scripts that are ok */
+    public void testOK() {
+        assertSuccess("1 + 2");
+        assertSuccess("from java.lang import Math\nMath.cos(0)");
+    }
+    
+    /** Test some py scripts that should hit security exception */
+    public void testNotOK() {
+        // sanity check :)
+        assertFailure("from java.lang import Runtime\nRuntime.getRuntime().halt(0)");
+        // check a few things more restrictive than the ordinary policy
+        // no network
+        assertFailure("from java.net import Socket\nSocket(\"localhost\", 1024)");
+        // no files
+        assertFailure("from java.io import File\nFile.createTempFile(\"test\", \"tmp\")");
+    }
+}
diff --git a/plugins/store-smb/src/main/java/org/elasticsearch/index/store/smbmmapfs/SmbMmapFsIndexStore.java b/plugins/store-smb/src/main/java/org/elasticsearch/index/store/smbmmapfs/SmbMmapFsIndexStore.java
index 0422975..1d1592d 100644
--- a/plugins/store-smb/src/main/java/org/elasticsearch/index/store/smbmmapfs/SmbMmapFsIndexStore.java
+++ b/plugins/store-smb/src/main/java/org/elasticsearch/index/store/smbmmapfs/SmbMmapFsIndexStore.java
@@ -24,6 +24,7 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.settings.IndexSettingsService;
+import org.elasticsearch.index.shard.ShardPath;
 import org.elasticsearch.index.store.DirectoryService;
 import org.elasticsearch.index.store.IndexStore;
 import org.elasticsearch.indices.store.IndicesStore;
@@ -37,7 +38,7 @@ public class SmbMmapFsIndexStore extends IndexStore {
     }
 
     @Override
-    public Class<? extends DirectoryService> shardDirectory() {
-        return SmbMmapFsDirectoryService.class;
+    public DirectoryService newDirectoryService(ShardPath path) {
+        return new SmbMmapFsDirectoryService(indexSettings(), this, path);
     }
 }
diff --git a/plugins/store-smb/src/main/java/org/elasticsearch/index/store/smbsimplefs/SmbSimpleFsIndexStore.java b/plugins/store-smb/src/main/java/org/elasticsearch/index/store/smbsimplefs/SmbSimpleFsIndexStore.java
index 4813344..67d396a 100644
--- a/plugins/store-smb/src/main/java/org/elasticsearch/index/store/smbsimplefs/SmbSimpleFsIndexStore.java
+++ b/plugins/store-smb/src/main/java/org/elasticsearch/index/store/smbsimplefs/SmbSimpleFsIndexStore.java
@@ -24,6 +24,7 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.settings.IndexSettingsService;
+import org.elasticsearch.index.shard.ShardPath;
 import org.elasticsearch.index.store.DirectoryService;
 import org.elasticsearch.index.store.IndexStore;
 import org.elasticsearch.indices.store.IndicesStore;
@@ -36,9 +37,13 @@ public class SmbSimpleFsIndexStore extends IndexStore {
         super(index, indexSettings, indexSettingsService, indicesStore);
     }
 
-    @Override
     public Class<? extends DirectoryService> shardDirectory() {
         return SmbSimpleFsDirectoryService.class;
     }
+
+    @Override
+    public DirectoryService newDirectoryService(ShardPath path) {
+        return new SmbSimpleFsDirectoryService(indexSettings(), this, path);
+    }
 }
 
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/search/80_date_math_index_names.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/search/80_date_math_index_names.yaml
index 233b41c..2f2cf6a 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/search/80_date_math_index_names.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/search/80_date_math_index_names.yaml
@@ -2,6 +2,6 @@
 "Missing index with catch":
 
   - do:
-      catch:   /index=logstash-\d{4}\.\d{2}\.\d{2}/
+      catch:   /logstash-\d{4}\.\d{2}\.\d{2}/
       search:
         index: <logstash-{now/M}>

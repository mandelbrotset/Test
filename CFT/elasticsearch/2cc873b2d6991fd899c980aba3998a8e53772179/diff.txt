diff --git a/core/src/main/java/org/apache/lucene/queries/BlendedTermQuery.java b/core/src/main/java/org/apache/lucene/queries/BlendedTermQuery.java
index 7d3c47f..e411139 100644
--- a/core/src/main/java/org/apache/lucene/queries/BlendedTermQuery.java
+++ b/core/src/main/java/org/apache/lucene/queries/BlendedTermQuery.java
@@ -18,8 +18,6 @@
  */
 package org.apache.lucene.queries;
 
-import com.google.common.primitives.Ints;
-
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexReaderContext;
 import org.apache.lucene.index.LeafReaderContext;
@@ -141,7 +139,7 @@ public abstract class BlendedTermQuery extends Query {
             }
             @Override
             protected int compare(int i, int j) {
-                return Ints.compare(contexts[tieBreak[j]].docFreq(), contexts[tieBreak[i]].docFreq());
+                return Integer.compare(contexts[tieBreak[j]].docFreq(), contexts[tieBreak[i]].docFreq());
             }
         }.sort(0, tieBreak.length);
         int prev = contexts[tieBreak[0]].docFreq();
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/repositories/get/GetRepositoriesRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/repositories/get/GetRepositoriesRequestBuilder.java
index 320794c..e21aa19 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/repositories/get/GetRepositoriesRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/repositories/get/GetRepositoriesRequestBuilder.java
@@ -19,9 +19,9 @@
 
 package org.elasticsearch.action.admin.cluster.repositories.get;
 
-import com.google.common.collect.ObjectArrays;
 import org.elasticsearch.action.support.master.MasterNodeReadOperationRequestBuilder;
 import org.elasticsearch.client.ElasticsearchClient;
+import org.elasticsearch.common.util.ArrayUtils;
 
 /**
  * Get repository request builder
@@ -60,7 +60,7 @@ public class GetRepositoriesRequestBuilder extends MasterNodeReadOperationReques
      * @return builder
      */
     public GetRepositoriesRequestBuilder addRepositories(String... repositories) {
-        request.repositories(ObjectArrays.concat(request.repositories(), repositories, String.class));
+        request.repositories(ArrayUtils.concat(request.repositories(), repositories));
         return this;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/get/GetSnapshotsRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/get/GetSnapshotsRequestBuilder.java
index 79472d4..d989ac3 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/get/GetSnapshotsRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/get/GetSnapshotsRequestBuilder.java
@@ -19,9 +19,9 @@
 
 package org.elasticsearch.action.admin.cluster.snapshots.get;
 
-import com.google.common.collect.ObjectArrays;
 import org.elasticsearch.action.support.master.MasterNodeOperationRequestBuilder;
 import org.elasticsearch.client.ElasticsearchClient;
+import org.elasticsearch.common.util.ArrayUtils;
 
 /**
  * Get snapshots request builder
@@ -81,7 +81,7 @@ public class GetSnapshotsRequestBuilder extends MasterNodeOperationRequestBuilde
      * @return this builder
      */
     public GetSnapshotsRequestBuilder addSnapshots(String... snapshots) {
-        request.snapshots(ObjectArrays.concat(request.snapshots(), snapshots, String.class));
+        request.snapshots(ArrayUtils.concat(request.snapshots(), snapshots));
         return this;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotsStatusRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotsStatusRequestBuilder.java
index c8a7829..3ec1733 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotsStatusRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotsStatusRequestBuilder.java
@@ -19,10 +19,9 @@
 
 package org.elasticsearch.action.admin.cluster.snapshots.status;
 
-import com.google.common.collect.ObjectArrays;
-import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.master.MasterNodeOperationRequestBuilder;
 import org.elasticsearch.client.ElasticsearchClient;
+import org.elasticsearch.common.util.ArrayUtils;
 
 /**
  * Snapshots status request builder
@@ -72,7 +71,7 @@ public class SnapshotsStatusRequestBuilder extends MasterNodeOperationRequestBui
      * @return this builder
      */
     public SnapshotsStatusRequestBuilder addSnapshots(String... snapshots) {
-        request.snapshots(ObjectArrays.concat(request.snapshots(), snapshots, String.class));
+        request.snapshots(ArrayUtils.concat(request.snapshots(), snapshots));
         return this;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/BaseAliasesRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/BaseAliasesRequestBuilder.java
index da7c505..bcfdb0e 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/BaseAliasesRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/alias/get/BaseAliasesRequestBuilder.java
@@ -19,13 +19,12 @@
 
 package org.elasticsearch.action.admin.indices.alias.get;
 
-import com.google.common.collect.ObjectArrays;
 import org.elasticsearch.action.Action;
 import org.elasticsearch.action.ActionResponse;
 import org.elasticsearch.action.support.IndicesOptions;
 import org.elasticsearch.action.support.master.MasterNodeReadOperationRequestBuilder;
 import org.elasticsearch.client.ElasticsearchClient;
-import org.elasticsearch.client.IndicesAdminClient;
+import org.elasticsearch.common.util.ArrayUtils;
 
 /**
  */
@@ -43,7 +42,7 @@ public abstract class BaseAliasesRequestBuilder<Response extends ActionResponse,
 
     @SuppressWarnings("unchecked")
     public Builder addAliases(String... aliases) {
-        request.aliases(ObjectArrays.concat(request.aliases(), aliases, String.class));
+        request.aliases(ArrayUtils.concat(request.aliases(), aliases));
         return (Builder) this;
     }
 
@@ -55,7 +54,7 @@ public abstract class BaseAliasesRequestBuilder<Response extends ActionResponse,
 
     @SuppressWarnings("unchecked")
     public Builder addIndices(String... indices) {
-        request.indices(ObjectArrays.concat(request.indices(), indices, String.class));
+        request.indices(ArrayUtils.concat(request.indices(), indices));
         return (Builder) this;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/get/GetIndexRequest.java b/core/src/main/java/org/elasticsearch/action/admin/indices/get/GetIndexRequest.java
index bd392ea..4c85cd8 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/get/GetIndexRequest.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/get/GetIndexRequest.java
@@ -19,12 +19,11 @@
 
 package org.elasticsearch.action.admin.indices.get;
 
-import com.google.common.collect.ObjectArrays;
-
 import org.elasticsearch.action.ActionRequestValidationException;
 import org.elasticsearch.action.support.master.info.ClusterInfoRequest;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.util.ArrayUtils;
 
 import java.io.IOException;
 import java.util.Arrays;
@@ -115,7 +114,7 @@ public class GetIndexRequest extends ClusterInfoRequest<GetIndexRequest> {
         if (this.features == DEFAULT_FEATURES) {
             return features(features);
         } else {
-            return features(ObjectArrays.concat(featuresAsEnums(), features, Feature.class));
+            return features(ArrayUtils.concat(features(), features, Feature.class));
         }
     }
 
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/GetFieldMappingsRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/GetFieldMappingsRequestBuilder.java
index 158e2db..84b16ac 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/GetFieldMappingsRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/GetFieldMappingsRequestBuilder.java
@@ -19,12 +19,10 @@
 
 package org.elasticsearch.action.admin.indices.mapping.get;
 
-import com.google.common.collect.ObjectArrays;
-import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.ActionRequestBuilder;
 import org.elasticsearch.action.support.IndicesOptions;
 import org.elasticsearch.client.ElasticsearchClient;
-import org.elasticsearch.client.IndicesAdminClient;
+import org.elasticsearch.common.util.ArrayUtils;
 
 /** A helper class to build {@link GetFieldMappingsRequest} objects */
 public class GetFieldMappingsRequestBuilder extends ActionRequestBuilder<GetFieldMappingsRequest, GetFieldMappingsResponse, GetFieldMappingsRequestBuilder> {
@@ -39,7 +37,7 @@ public class GetFieldMappingsRequestBuilder extends ActionRequestBuilder<GetFiel
     }
 
     public GetFieldMappingsRequestBuilder addIndices(String... indices) {
-        request.indices(ObjectArrays.concat(request.indices(), indices, String.class));
+        request.indices(ArrayUtils.concat(request.indices(), indices));
         return this;
     }
 
@@ -49,7 +47,7 @@ public class GetFieldMappingsRequestBuilder extends ActionRequestBuilder<GetFiel
     }
 
     public GetFieldMappingsRequestBuilder addTypes(String... types) {
-        request.types(ObjectArrays.concat(request.types(), types, String.class));
+        request.types(ArrayUtils.concat(request.types(), types));
         return this;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/settings/get/GetSettingsRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/admin/indices/settings/get/GetSettingsRequestBuilder.java
index 910141b..4047d0a 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/settings/get/GetSettingsRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/settings/get/GetSettingsRequestBuilder.java
@@ -19,10 +19,10 @@
 
 package org.elasticsearch.action.admin.indices.settings.get;
 
-import com.google.common.collect.ObjectArrays;
 import org.elasticsearch.action.support.IndicesOptions;
 import org.elasticsearch.action.support.master.MasterNodeReadOperationRequestBuilder;
 import org.elasticsearch.client.ElasticsearchClient;
+import org.elasticsearch.common.util.ArrayUtils;
 
 /**
  */
@@ -38,7 +38,7 @@ public class GetSettingsRequestBuilder extends MasterNodeReadOperationRequestBui
     }
 
     public GetSettingsRequestBuilder addIndices(String... indices) {
-        request.indices(ObjectArrays.concat(request.indices(), indices, String.class));
+        request.indices(ArrayUtils.concat(request.indices(), indices));
         return this;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/get/GetWarmersRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/get/GetWarmersRequestBuilder.java
index 1ed635d..de67d38 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/get/GetWarmersRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/warmer/get/GetWarmersRequestBuilder.java
@@ -19,9 +19,9 @@
 
 package org.elasticsearch.action.admin.indices.warmer.get;
 
-import com.google.common.collect.ObjectArrays;
 import org.elasticsearch.action.support.master.info.ClusterInfoRequestBuilder;
 import org.elasticsearch.client.ElasticsearchClient;
+import org.elasticsearch.common.util.ArrayUtils;
 
 /**
  * Builder for {@link GetWarmersRequest}
@@ -40,7 +40,7 @@ public class GetWarmersRequestBuilder extends ClusterInfoRequestBuilder<GetWarme
     }
 
     public GetWarmersRequestBuilder addWarmers(String... warmers) {
-        request.warmers(ObjectArrays.concat(request.warmers(), warmers, String.class));
+        request.warmers(ArrayUtils.concat(request.warmers(), warmers));
         return this;
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/action/support/master/info/ClusterInfoRequestBuilder.java b/core/src/main/java/org/elasticsearch/action/support/master/info/ClusterInfoRequestBuilder.java
index cc12e28..1e871a4 100644
--- a/core/src/main/java/org/elasticsearch/action/support/master/info/ClusterInfoRequestBuilder.java
+++ b/core/src/main/java/org/elasticsearch/action/support/master/info/ClusterInfoRequestBuilder.java
@@ -18,14 +18,12 @@
  */
 package org.elasticsearch.action.support.master.info;
 
-import com.google.common.collect.ObjectArrays;
 import org.elasticsearch.action.Action;
 import org.elasticsearch.action.ActionResponse;
 import org.elasticsearch.action.support.IndicesOptions;
 import org.elasticsearch.action.support.master.MasterNodeReadOperationRequestBuilder;
-import org.elasticsearch.client.ClusterAdminClient;
 import org.elasticsearch.client.ElasticsearchClient;
-import org.elasticsearch.client.IndicesAdminClient;
+import org.elasticsearch.common.util.ArrayUtils;
 
 /**
  */
@@ -44,7 +42,7 @@ public abstract class ClusterInfoRequestBuilder<Request extends ClusterInfoReque
 
     @SuppressWarnings("unchecked")
     public Builder addIndices(String... indices) {
-        request.indices(ObjectArrays.concat(request.indices(), indices, String.class));
+        request.indices(ArrayUtils.concat(request.indices(), indices));
         return (Builder) this;
     }
 
@@ -56,7 +54,7 @@ public abstract class ClusterInfoRequestBuilder<Request extends ClusterInfoReque
 
     @SuppressWarnings("unchecked")
     public Builder addTypes(String... types) {
-        request.types(ObjectArrays.concat(request.types(), types, String.class));
+        request.types(ArrayUtils.concat(request.types(), types));
         return (Builder) this;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsFilter.java b/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsFilter.java
index 373893f..a33e8e2 100644
--- a/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsFilter.java
+++ b/core/src/main/java/org/elasticsearch/action/termvectors/TermVectorsFilter.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.action.termvectors;
 
-import com.google.common.util.concurrent.AtomicLongMap;
 import org.apache.lucene.index.*;
 import org.apache.lucene.search.TermStatistics;
 import org.apache.lucene.search.similarities.DefaultSimilarity;
@@ -54,7 +53,7 @@ public class TermVectorsFilter {
     private final Set<String> selectedFields;
     private AggregatedDfs dfs;
     private Map<Term, ScoreTerm> scoreTerms;
-    private AtomicLongMap<String> sizes;
+    private Map<String, Integer> sizes = new HashMap<>();
     private TFIDFSimilarity similarity;
 
     public TermVectorsFilter(Fields termVectorsByField, Fields topLevelFields, Set<String> selectedFields, @Nullable AggregatedDfs dfs) {
@@ -64,7 +63,6 @@ public class TermVectorsFilter {
 
         this.dfs = dfs;
         this.scoreTerms = new HashMap<>();
-        this.sizes = AtomicLongMap.create();
         this.similarity = new DefaultSimilarity();
     }
 
@@ -228,10 +226,12 @@ public class TermVectorsFilter {
 
             // retain the best terms for quick lookups
             ScoreTerm scoreTerm;
+            int count = 0;
             while ((scoreTerm = queue.pop()) != null) {
                 scoreTerms.put(new Term(scoreTerm.field, scoreTerm.word), scoreTerm);
-                sizes.incrementAndGet(scoreTerm.field);
+                count++;
             }
+            sizes.put(fieldName, count);
         }
     }
 
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasOrIndex.java b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasOrIndex.java
index e98a046..b8de2ea 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/AliasOrIndex.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/AliasOrIndex.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.cluster.metadata;
 
-import com.google.common.collect.UnmodifiableIterator;
 import org.elasticsearch.common.collect.Tuple;
 
 import java.util.ArrayList;
@@ -106,7 +105,7 @@ public interface AliasOrIndex {
             return new Iterable<Tuple<String, AliasMetaData>>() {
                 @Override
                 public Iterator<Tuple<String, AliasMetaData>> iterator() {
-                    return new UnmodifiableIterator<Tuple<String,AliasMetaData>>() {
+                    return new Iterator<Tuple<String,AliasMetaData>>() {
 
                         int index = 0;
 
@@ -121,6 +120,11 @@ public interface AliasOrIndex {
                             return new Tuple<>(indexMetaData.getIndex(), indexMetaData.getAliases().get(aliasName));
                         }
 
+                        @Override
+                        public final void remove() {
+                            throw new UnsupportedOperationException();
+                        }
+
                     };
                 }
             };
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java
index dc4691e..2e2458c 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexMetaData.java
@@ -21,7 +21,6 @@ package org.elasticsearch.cluster.metadata;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-import com.google.common.base.Preconditions;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.Diff;
@@ -205,8 +204,12 @@ public class IndexMetaData implements Diffable<IndexMetaData>, FromXContentBuild
     private final boolean useTypeForRouting;
 
     private IndexMetaData(String index, long version, State state, Settings settings, ImmutableOpenMap<String, MappingMetaData> mappings, ImmutableOpenMap<String, AliasMetaData> aliases, ImmutableOpenMap<String, Custom> customs) {
-        Preconditions.checkArgument(settings.getAsInt(SETTING_NUMBER_OF_SHARDS, null) != null, "must specify numberOfShards for index [" + index + "]");
-        Preconditions.checkArgument(settings.getAsInt(SETTING_NUMBER_OF_REPLICAS, null) != null, "must specify numberOfReplicas for index [" + index + "]");
+        if (settings.getAsInt(SETTING_NUMBER_OF_SHARDS, null) == null) {
+            throw new IllegalArgumentException("must specify numberOfShards for index [" + index + "]");
+        }
+        if (settings.getAsInt(SETTING_NUMBER_OF_REPLICAS, null) == null) {
+            throw new IllegalArgumentException("must specify numberOfReplicas for index [" + index + "]");
+        }
         this.index = index;
         this.version = version;
         this.state = state;
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
index 8ce7f82..3ca3ec3 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java
@@ -23,7 +23,6 @@ import com.carrotsearch.hppc.ObjectHashSet;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.UnmodifiableIterator;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.cluster.Diff;
 import org.elasticsearch.cluster.Diffable;
@@ -60,18 +59,7 @@ import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.search.warmer.IndexWarmersMetaData;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.EnumSet;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.SortedMap;
-import java.util.TreeMap;
+import java.util.*;
 import java.util.stream.Collectors;
 
 import static org.elasticsearch.common.settings.Settings.readSettingsFromStream;
@@ -569,7 +557,7 @@ public class MetaData implements Iterable<IndexMetaData>, Diffable<MetaData>, Fr
     }
 
     @Override
-    public UnmodifiableIterator<IndexMetaData> iterator() {
+    public Iterator<IndexMetaData> iterator() {
         return indices.valuesIt();
     }
 
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java
index bc033fc..2d26ebf 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java
@@ -26,6 +26,7 @@ import org.elasticsearch.cluster.routing.DjbHashFunction;
 import org.elasticsearch.cluster.routing.HashFunction;
 import org.elasticsearch.cluster.routing.SimpleHashFunction;
 import org.elasticsearch.cluster.routing.UnassignedInfo;
+import org.elasticsearch.common.Classes;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
@@ -218,6 +219,7 @@ public class MetaDataIndexUpgradeService extends AbstractComponent {
 
     /** All known byte-sized settings for an index. */
     public static final Set<String> INDEX_BYTES_SIZE_SETTINGS = ImmutableSet.of(
+                                    "index.buffer_size",
                                     "index.merge.policy.floor_segment",
                                     "index.merge.policy.max_merged_segment",
                                     "index.merge.policy.max_merge_size",
diff --git a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
index 847173e..13b6471 100644
--- a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
+++ b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
@@ -22,7 +22,6 @@ package org.elasticsearch.cluster.node;
 import com.carrotsearch.hppc.ObjectHashSet;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-import com.google.common.collect.UnmodifiableIterator;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.common.Booleans;
@@ -34,11 +33,7 @@ import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.transport.TransportAddress;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 
 /**
  * This class holds all {@link DiscoveryNode} in the cluster and provides convenience methods to
@@ -69,7 +64,7 @@ public class DiscoveryNodes extends AbstractDiffable<DiscoveryNodes> implements
     }
 
     @Override
-    public UnmodifiableIterator<DiscoveryNode> iterator() {
+    public Iterator<DiscoveryNode> iterator() {
         return nodes.valuesIt();
     }
 
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java b/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
index a909b55..062c7b4 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java
@@ -22,7 +22,6 @@ package org.elasticsearch.cluster.routing;
 import com.carrotsearch.hppc.IntSet;
 import com.carrotsearch.hppc.cursors.IntCursor;
 import com.carrotsearch.hppc.cursors.IntObjectCursor;
-import com.google.common.collect.UnmodifiableIterator;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -33,12 +32,7 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.index.shard.ShardId;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.ThreadLocalRandom;
 
 /**
@@ -163,7 +157,7 @@ public class IndexRoutingTable extends AbstractDiffable<IndexRoutingTable> imple
     }
 
     @Override
-    public UnmodifiableIterator<IndexShardRoutingTable> iterator() {
+    public Iterator<IndexShardRoutingTable> iterator() {
         return shards.valuesIt();
     }
 
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
index 0a2a5c9..9c9cfaa 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
@@ -21,7 +21,6 @@ package org.elasticsearch.cluster.routing;
 
 import com.carrotsearch.hppc.ObjectIntHashMap;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.google.common.collect.Iterables;
 import com.google.common.collect.Iterators;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.cluster.ClusterState;
@@ -31,15 +30,7 @@ import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.index.shard.ShardId;
 
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 import java.util.function.Predicate;
 
 /**
@@ -308,7 +299,7 @@ public class RoutingNodes implements Iterable<RoutingNode> {
         }
         for (ShardRoutingState s : state) {
             if (s == ShardRoutingState.UNASSIGNED) {
-                Iterables.addAll(shards, unassigned());
+                unassigned().forEach(shards::add);
                 break;
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
index 8f6b05b..32c50b3 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
@@ -21,8 +21,6 @@ package org.elasticsearch.cluster.routing;
 
 import com.carrotsearch.hppc.IntSet;
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Iterables;
-import com.google.common.collect.UnmodifiableIterator;
 import org.elasticsearch.cluster.Diff;
 import org.elasticsearch.cluster.Diffable;
 import org.elasticsearch.cluster.DiffableUtils;
@@ -30,14 +28,11 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.index.IndexNotFoundException;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 import java.util.function.Predicate;
 
 /**
@@ -72,7 +67,7 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
     }
 
     @Override
-    public UnmodifiableIterator<IndexRoutingTable> iterator() {
+    public Iterator<IndexRoutingTable> iterator() {
         return indicesRouting.values().iterator();
     }
 
@@ -379,7 +374,10 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
                     indexBuilder.addShard(refData, shardRoutingEntry);
                 }
             }
-            for (ShardRouting shardRoutingEntry : Iterables.concat(routingNodes.unassigned(), routingNodes.unassigned().ignored())) {
+
+            Iterable<ShardRouting> shardRoutingEntries = Iterables.concat(routingNodes.unassigned(), routingNodes.unassigned().ignored());
+
+            for (ShardRouting shardRoutingEntry : shardRoutingEntries) {
                 String index = shardRoutingEntry.index();
                 IndexRoutingTable.Builder indexBuilder = indexRoutingTableBuilders.get(index);
                 if (indexBuilder == null) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java
index 08cdbbb..2b8a180 100644
--- a/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.cluster.service;
 
-import com.google.common.collect.Iterables;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.*;
 import org.elasticsearch.cluster.ClusterState.Builder;
@@ -42,6 +41,7 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.text.StringText;
 import org.elasticsearch.common.transport.TransportAddress;
 import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.common.util.concurrent.*;
 import org.elasticsearch.discovery.Discovery;
 import org.elasticsearch.discovery.DiscoveryService;
@@ -89,10 +89,7 @@ public class InternalClusterService extends AbstractLifecycleComponent<ClusterSe
     private final Collection<ClusterStateListener> lastClusterStateListeners = new CopyOnWriteArrayList<>();
     // TODO this is rather frequently changing I guess a Synced Set would be better here and a dedicated remove API
     private final Collection<ClusterStateListener> postAppliedListeners = new CopyOnWriteArrayList<>();
-    private final Iterable<ClusterStateListener> preAppliedListeners = Iterables.concat(
-            priorityClusterStateListeners,
-            clusterStateListeners,
-            lastClusterStateListeners);
+    private final Iterable<ClusterStateListener> preAppliedListeners = Iterables.concat(priorityClusterStateListeners, clusterStateListeners, lastClusterStateListeners);
 
     private final LocalNodeMasterListeners localNodeMasterListeners;
 
diff --git a/core/src/main/java/org/elasticsearch/common/Strings.java b/core/src/main/java/org/elasticsearch/common/Strings.java
index dafaa61..40d9602 100644
--- a/core/src/main/java/org/elasticsearch/common/Strings.java
+++ b/core/src/main/java/org/elasticsearch/common/Strings.java
@@ -20,8 +20,6 @@
 package org.elasticsearch.common;
 
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Iterables;
-
 import org.apache.lucene.util.BytesRefBuilder;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.FastStringReader;
@@ -32,18 +30,7 @@ import org.elasticsearch.common.xcontent.json.JsonXContent;
 
 import java.io.BufferedReader;
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Properties;
-import java.util.Random;
-import java.util.Set;
-import java.util.StringTokenizer;
-import java.util.TreeSet;
+import java.util.*;
 
 /**
  *
@@ -840,9 +827,6 @@ public class Strings {
     }
 
     public static String collectionToDelimitedString(Iterable<?> coll, String delim, String prefix, String suffix, StringBuilder sb) {
-        if (Iterables.isEmpty(coll)) {
-            return "";
-        }
         Iterator<?> it = coll.iterator();
         while (it.hasNext()) {
             sb.append(prefix).append(it.next()).append(suffix);
diff --git a/core/src/main/java/org/elasticsearch/common/cli/CliTool.java b/core/src/main/java/org/elasticsearch/common/cli/CliTool.java
index d264232..0d32b6e 100644
--- a/core/src/main/java/org/elasticsearch/common/cli/CliTool.java
+++ b/core/src/main/java/org/elasticsearch/common/cli/CliTool.java
@@ -19,11 +19,9 @@
 
 package org.elasticsearch.common.cli;
 
-import com.google.common.base.Preconditions;
 import org.apache.commons.cli.CommandLine;
 import org.apache.commons.cli.CommandLineParser;
 import org.apache.commons.cli.DefaultParser;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.env.Environment;
 import org.elasticsearch.node.internal.InternalSettingsPreparer;
@@ -101,7 +99,9 @@ public abstract class CliTool {
     }
 
     protected CliTool(CliToolConfig config, Terminal terminal) {
-        Preconditions.checkArgument(config.cmds().size() != 0, "At least one command must be configured");
+        if (config.cmds().size() == 0) {
+            throw new IllegalArgumentException("At least one command must be configured");
+        }
         this.config = config;
         this.terminal = terminal;
         env = InternalSettingsPreparer.prepareEnvironment(EMPTY_SETTINGS, terminal);
diff --git a/core/src/main/java/org/elasticsearch/common/cli/CliToolConfig.java b/core/src/main/java/org/elasticsearch/common/cli/CliToolConfig.java
index 2e3d755..d0ba897 100644
--- a/core/src/main/java/org/elasticsearch/common/cli/CliToolConfig.java
+++ b/core/src/main/java/org/elasticsearch/common/cli/CliToolConfig.java
@@ -19,13 +19,14 @@
 
 package org.elasticsearch.common.cli;
 
-import com.google.common.collect.ImmutableMap;
-import org.apache.commons.cli.CommandLine;
 import org.apache.commons.cli.Option;
 import org.apache.commons.cli.OptionGroup;
 import org.apache.commons.cli.Options;
 
 import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
 
 /**
  *
@@ -38,18 +39,18 @@ public class CliToolConfig {
 
     private final Class<? extends CliTool> toolType;
     private final String name;
-    private final ImmutableMap<String, Cmd> cmds;
+    private final Map<String, Cmd> cmds;
 
     private static final HelpPrinter helpPrinter = new HelpPrinter();
 
     private CliToolConfig(String name, Class<? extends CliTool> toolType, Cmd[] cmds) {
         this.name = name;
         this.toolType = toolType;
-        ImmutableMap.Builder<String, Cmd> cmdsBuilder = ImmutableMap.builder();
+        final Map<String, Cmd> cmdsMapping = new HashMap<>();
         for (int i = 0; i < cmds.length; i++) {
-            cmdsBuilder.put(cmds[i].name, cmds[i]);
+            cmdsMapping.put(cmds[i].name, cmds[i]);
         }
-        this.cmds = cmdsBuilder.build();
+        this.cmds = Collections.unmodifiableMap(cmdsMapping);
     }
 
     public boolean isSingle() {
diff --git a/core/src/main/java/org/elasticsearch/common/collect/CopyOnWriteHashMap.java b/core/src/main/java/org/elasticsearch/common/collect/CopyOnWriteHashMap.java
index 8ec1a13..c011448 100644
--- a/core/src/main/java/org/elasticsearch/common/collect/CopyOnWriteHashMap.java
+++ b/core/src/main/java/org/elasticsearch/common/collect/CopyOnWriteHashMap.java
@@ -18,26 +18,10 @@
  */
 
 package org.elasticsearch.common.collect;
-
-import com.google.common.base.Preconditions;
-import com.google.common.base.Supplier;
-import com.google.common.base.Suppliers;
-import com.google.common.collect.UnmodifiableIterator;
 import org.apache.lucene.util.mutable.MutableValueInt;
 
 import java.lang.reflect.Array;
-import java.util.AbstractMap;
-import java.util.AbstractSet;
-import java.util.ArrayDeque;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Deque;
-import java.util.Iterator;
-import java.util.Map;
-import java.util.NoSuchElementException;
-import java.util.Set;
-import java.util.function.Consumer;
-import java.util.stream.Collectors;
+import java.util.*;
 import java.util.stream.Stream;
 
 /**
@@ -434,7 +418,7 @@ public final class CopyOnWriteHashMap<K, V> extends AbstractMap<K, V> {
 
     }
 
-    private static class EntryIterator<K, V> extends UnmodifiableIterator<Map.Entry<K, V>> {
+    private static class EntryIterator<K, V> implements Iterator<Map.Entry<K, V>> {
 
         private final Deque<Map.Entry<K, V>> entries;
         private final Deque<Node<K, V>> nodes;
@@ -462,6 +446,11 @@ public final class CopyOnWriteHashMap<K, V> extends AbstractMap<K, V> {
             return entries.pop();
         }
 
+        @Override
+        public final void remove() {
+            throw new UnsupportedOperationException();
+        }
+
     }
 
     private final InnerNode<K, V> root;
@@ -487,7 +476,9 @@ public final class CopyOnWriteHashMap<K, V> extends AbstractMap<K, V> {
 
     @Override
     public V get(Object key) {
-        Preconditions.checkArgument(key != null, "Null keys are not supported");
+        if (key == null) {
+            throw new IllegalArgumentException("null keys are not supported");
+        }
         final int hash = key.hashCode();
         return root.get(key, hash);
     }
@@ -503,8 +494,12 @@ public final class CopyOnWriteHashMap<K, V> extends AbstractMap<K, V> {
      * of the hash table. The current hash table is not modified.
      */
     public CopyOnWriteHashMap<K, V> copyAndPut(K key, V value) {
-        Preconditions.checkArgument(key != null, "null keys are not supported");
-        Preconditions.checkArgument(value != null, "null values are not supported");
+        if (key == null) {
+            throw new IllegalArgumentException("null keys are not supported");
+        }
+        if (value == null) {
+            throw new IllegalArgumentException("null values are not supported");
+        }
         final int hash = key.hashCode();
         final MutableValueInt newValue = new MutableValueInt();
         final InnerNode<K, V> newRoot = root.put(key, hash, TOTAL_HASH_BITS, value, newValue);
@@ -535,7 +530,9 @@ public final class CopyOnWriteHashMap<K, V> extends AbstractMap<K, V> {
      * Remove the given key from this map. The current hash table is not modified.
      */
     public CopyOnWriteHashMap<K, V> copyAndRemove(Object key) {
-        Preconditions.checkArgument(key != null, "Null keys are not supported");
+        if (key == null) {
+            throw new IllegalArgumentException("null keys are not supported");
+        }
         final int hash = key.hashCode();
         final InnerNode<K, V> newRoot = root.remove(key, hash);
         if (root == newRoot) {
diff --git a/core/src/main/java/org/elasticsearch/common/collect/ImmutableOpenIntMap.java b/core/src/main/java/org/elasticsearch/common/collect/ImmutableOpenIntMap.java
index eda83a1..ccadbcf 100644
--- a/core/src/main/java/org/elasticsearch/common/collect/ImmutableOpenIntMap.java
+++ b/core/src/main/java/org/elasticsearch/common/collect/ImmutableOpenIntMap.java
@@ -26,7 +26,6 @@ import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.predicates.IntObjectPredicate;
 import com.carrotsearch.hppc.predicates.IntPredicate;
 import com.carrotsearch.hppc.procedures.IntObjectProcedure;
-import com.google.common.collect.UnmodifiableIterator;
 
 import java.util.Iterator;
 import java.util.Map;
@@ -113,9 +112,9 @@ public final class ImmutableOpenIntMap<VType> implements Iterable<IntObjectCurso
     /**
      * Returns a direct iterator over the keys.
      */
-    public UnmodifiableIterator<Integer> keysIt() {
+    public Iterator<Integer> keysIt() {
         final Iterator<IntCursor> iterator = map.keys().iterator();
-        return new UnmodifiableIterator<Integer>() {
+        return new Iterator<Integer>() {
             @Override
             public boolean hasNext() {
                 return iterator.hasNext();
@@ -125,6 +124,11 @@ public final class ImmutableOpenIntMap<VType> implements Iterable<IntObjectCurso
             public Integer next() {
                 return iterator.next().value;
             }
+
+            @Override
+            public final void remove() {
+                throw new UnsupportedOperationException();
+            }
         };
     }
 
@@ -138,9 +142,9 @@ public final class ImmutableOpenIntMap<VType> implements Iterable<IntObjectCurso
     /**
      * Returns a direct iterator over the keys.
      */
-    public UnmodifiableIterator<VType> valuesIt() {
+    public Iterator<VType> valuesIt() {
         final Iterator<ObjectCursor<VType>> iterator = map.values().iterator();
-        return new UnmodifiableIterator<VType>() {
+        return new Iterator<VType>() {
             @Override
             public boolean hasNext() {
                 return iterator.hasNext();
@@ -150,6 +154,11 @@ public final class ImmutableOpenIntMap<VType> implements Iterable<IntObjectCurso
             public VType next() {
                 return iterator.next().value;
             }
+
+            @Override
+            public final void remove() {
+                throw new UnsupportedOperationException();
+            }
         };
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java b/core/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java
index 0effca3..814df93 100644
--- a/core/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java
+++ b/core/src/main/java/org/elasticsearch/common/collect/ImmutableOpenMap.java
@@ -25,7 +25,6 @@ import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
 import com.carrotsearch.hppc.predicates.ObjectObjectPredicate;
 import com.carrotsearch.hppc.predicates.ObjectPredicate;
 import com.carrotsearch.hppc.procedures.ObjectObjectProcedure;
-import com.google.common.collect.UnmodifiableIterator;
 
 import java.util.Iterator;
 import java.util.Map;
@@ -120,18 +119,21 @@ public final class ImmutableOpenMap<KType, VType> implements Iterable<ObjectObje
     /**
      * Returns a direct iterator over the keys.
      */
-    public UnmodifiableIterator<KType> keysIt() {
+    public Iterator<KType> keysIt() {
         final Iterator<ObjectCursor<KType>> iterator = map.keys().iterator();
-        return new UnmodifiableIterator<KType>() {
+        return new Iterator<KType>() {
             @Override
-            public boolean hasNext() {
-                return iterator.hasNext();
-            }
+            public boolean hasNext() { return iterator.hasNext(); }
 
             @Override
             public KType next() {
                 return iterator.next().value;
             }
+
+            @Override
+            public final void remove() {
+                throw new UnsupportedOperationException();
+            }
         };
     }
 
@@ -145,18 +147,21 @@ public final class ImmutableOpenMap<KType, VType> implements Iterable<ObjectObje
     /**
      * Returns a direct iterator over the keys.
      */
-    public UnmodifiableIterator<VType> valuesIt() {
+    public Iterator<VType> valuesIt() {
         final Iterator<ObjectCursor<VType>> iterator = map.values().iterator();
-        return new UnmodifiableIterator<VType>() {
+        return new Iterator<VType>() {
             @Override
-            public boolean hasNext() {
-                return iterator.hasNext();
-            }
+            public boolean hasNext() { return iterator.hasNext(); }
 
             @Override
             public VType next() {
                 return iterator.next().value;
             }
+
+            @Override
+            public final void remove() {
+                throw new UnsupportedOperationException();
+            }
         };
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/AbstractModule.java b/core/src/main/java/org/elasticsearch/common/inject/AbstractModule.java
index af90884..86ef158 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/AbstractModule.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/AbstractModule.java
@@ -27,8 +27,6 @@ import org.elasticsearch.common.inject.spi.TypeListener;
 import java.lang.annotation.Annotation;
 import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkState;
-
 /**
  * A support class for {@link Module}s which reduces repetition and results in
  * a more readable configuration. Simply extend this class, implement {@link
@@ -54,8 +52,9 @@ public abstract class AbstractModule implements Module {
 
     @Override
     public final synchronized void configure(Binder builder) {
-        checkState(this.binder == null, "Re-entry is not allowed.");
-
+        if (this.binder != null) {
+            throw new IllegalStateException("Re-entry is not allowed.");
+        }
         this.binder = Objects.requireNonNull(builder, "builder");
         try {
             configure();
diff --git a/core/src/main/java/org/elasticsearch/common/inject/ConfigurationException.java b/core/src/main/java/org/elasticsearch/common/inject/ConfigurationException.java
index db7f250..4afc653 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/ConfigurationException.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/ConfigurationException.java
@@ -21,8 +21,7 @@ import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.spi.Message;
 
 import java.util.Collection;
-
-import static com.google.common.base.Preconditions.checkState;
+import java.util.Locale;
 
 /**
  * Thrown when a programming error such as a misplaced annotation, illegal binding, or unsupported
@@ -48,8 +47,10 @@ public final class ConfigurationException extends RuntimeException {
      * Returns a copy of this configuration exception with the specified partial value.
      */
     public ConfigurationException withPartialValue(Object partialValue) {
-        checkState(this.partialValue == null,
-                "Can't clobber existing partial value %s with %s", this.partialValue, partialValue);
+        if (this.partialValue != null) {
+            String message = String.format(Locale.ROOT, "Can't clobber existing partial value %s with %s", this.partialValue, partialValue);
+            throw new IllegalStateException(message);
+        }
         ConfigurationException result = new ConfigurationException(messages);
         result.partialValue = partialValue;
         return result;
diff --git a/core/src/main/java/org/elasticsearch/common/inject/ConstructorBindingImpl.java b/core/src/main/java/org/elasticsearch/common/inject/ConstructorBindingImpl.java
index 221b19b..0b5cec8 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/ConstructorBindingImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/ConstructorBindingImpl.java
@@ -25,8 +25,6 @@ import org.elasticsearch.common.inject.spi.InjectionPoint;
 
 import java.util.Set;
 
-import static com.google.common.base.Preconditions.checkState;
-
 class ConstructorBindingImpl<T> extends BindingImpl<T> implements ConstructorBinding<T> {
 
     private final Factory<T> factory;
@@ -52,19 +50,25 @@ class ConstructorBindingImpl<T> extends BindingImpl<T> implements ConstructorBin
 
     @Override
     public <V> V acceptTargetVisitor(BindingTargetVisitor<? super T, V> visitor) {
-        checkState(factory.constructorInjector != null, "not initialized");
+        if (factory.constructorInjector == null) {
+            throw new IllegalStateException("not initialized");
+        }
         return visitor.visit(this);
     }
 
     @Override
     public InjectionPoint getConstructor() {
-        checkState(factory.constructorInjector != null, "Binding is not ready");
+        if (factory.constructorInjector == null) {
+            throw new IllegalStateException("Binding is not ready");
+        }
         return factory.constructorInjector.getConstructionProxy().getInjectionPoint();
     }
 
     @Override
     public Set<InjectionPoint> getInjectableMembers() {
-        checkState(factory.constructorInjector != null, "Binding is not ready");
+        if (factory.constructorInjector == null) {
+            throw new IllegalStateException("Binding is not ready");
+        }
         return factory.constructorInjector.getInjectableMembers();
     }
 
@@ -97,7 +101,9 @@ class ConstructorBindingImpl<T> extends BindingImpl<T> implements ConstructorBin
         @SuppressWarnings("unchecked")
         public T get(Errors errors, InternalContext context, Dependency<?> dependency)
                 throws ErrorsException {
-            checkState(constructorInjector != null, "Constructor not ready");
+            if (constructorInjector == null) {
+                throw new IllegalStateException("Constructor not ready");
+            }
 
             // This may not actually be safe because it could return a super type of T (if that's all the
             // client needs), but it should be OK in practice thanks to the wonders of erasure.
diff --git a/core/src/main/java/org/elasticsearch/common/inject/CreationException.java b/core/src/main/java/org/elasticsearch/common/inject/CreationException.java
index 4553bc2..5c44111 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/CreationException.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/CreationException.java
@@ -22,8 +22,6 @@ import org.elasticsearch.common.inject.spi.Message;
 
 import java.util.Collection;
 
-import static com.google.common.base.Preconditions.checkArgument;
-
 /**
  * Thrown when errors occur while creating a {@link Injector}. Includes a list of encountered
  * errors. Clients should catch this exception, log it, and stop execution.
@@ -39,7 +37,9 @@ public class CreationException extends RuntimeException {
      */
     public CreationException(Collection<Message> messages) {
         this.messages = ImmutableSet.copyOf(messages);
-        checkArgument(!this.messages.isEmpty());
+        if (this.messages.isEmpty()) {
+            throw new IllegalArgumentException();
+        }
         initCause(Errors.getOnlyCause(this.messages));
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/EncounterImpl.java b/core/src/main/java/org/elasticsearch/common/inject/EncounterImpl.java
index 83b8e44..fc2bd48 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/EncounterImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/EncounterImpl.java
@@ -25,8 +25,6 @@ import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
 
-import static com.google.common.base.Preconditions.checkState;
-
 /**
  * @author jessewilson@google.com (Jesse Wilson)
  */
@@ -61,7 +59,9 @@ final class EncounterImpl<T> implements TypeEncounter<T> {
 
     @Override
     public void register(MembersInjector<? super T> membersInjector) {
-        checkState(valid, "Encounters may not be used after hear() returns.");
+        if (!valid) {
+            throw new IllegalStateException("Encounters may not be used after hear() returns.");
+        }
 
         if (membersInjectors == null) {
             membersInjectors = new ArrayList<>();
@@ -72,7 +72,9 @@ final class EncounterImpl<T> implements TypeEncounter<T> {
 
     @Override
     public void register(InjectionListener<? super T> injectionListener) {
-        checkState(valid, "Encounters may not be used after hear() returns.");
+        if (!valid) {
+            throw new IllegalStateException("Encounters may not be used after hear() returns.");
+        }
 
         if (injectionListeners == null) {
             injectionListeners = new ArrayList<>();
@@ -83,25 +85,33 @@ final class EncounterImpl<T> implements TypeEncounter<T> {
 
     @Override
     public void addError(String message, Object... arguments) {
-        checkState(valid, "Encounters may not be used after hear() returns.");
+        if (!valid) {
+            throw new IllegalStateException("Encounters may not be used after hear() returns.");
+        }
         errors.addMessage(message, arguments);
     }
 
     @Override
     public void addError(Throwable t) {
-        checkState(valid, "Encounters may not be used after hear() returns.");
+        if (!valid) {
+            throw new IllegalStateException("Encounters may not be used after hear() returns.");
+        }
         errors.errorInUserCode(t, "An exception was caught and reported. Message: %s", t.getMessage());
     }
 
     @Override
     public void addError(Message message) {
-        checkState(valid, "Encounters may not be used after hear() returns.");
+        if (!valid) {
+            throw new IllegalStateException("Encounters may not be used after hear() returns.");
+        }
         errors.addMessage(message);
     }
 
     @Override
     public <T> Provider<T> getProvider(Key<T> key) {
-        checkState(valid, "Encounters may not be used after hear() returns.");
+        if (!valid) {
+            throw new IllegalStateException("Encounters may not be used after hear() returns.");
+        }
         return lookups.getProvider(key);
     }
 
@@ -112,7 +122,9 @@ final class EncounterImpl<T> implements TypeEncounter<T> {
 
     @Override
     public <T> MembersInjector<T> getMembersInjector(TypeLiteral<T> typeLiteral) {
-        checkState(valid, "Encounters may not be used after hear() returns.");
+        if (!valid) {
+            throw new IllegalStateException("Encounters may not be used after hear() returns.");
+        }
         return lookups.getMembersInjector(typeLiteral);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InjectorBuilder.java b/core/src/main/java/org/elasticsearch/common/inject/InjectorBuilder.java
index 32d7477..5f7175d 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InjectorBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InjectorBuilder.java
@@ -17,9 +17,9 @@
 package org.elasticsearch.common.inject;
 
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Iterables;
 import org.elasticsearch.common.inject.internal.*;
 import org.elasticsearch.common.inject.spi.Dependency;
+import org.elasticsearch.common.util.iterable.Iterables;
 
 import java.util.Collection;
 import java.util.List;
diff --git a/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java b/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
index 510d9b5..8acc7d7 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/InjectorShell.java
@@ -17,28 +17,14 @@
 package org.elasticsearch.common.inject;
 
 import com.google.common.collect.ImmutableSet;
-import org.elasticsearch.common.inject.internal.Errors;
-import org.elasticsearch.common.inject.internal.ErrorsException;
-import org.elasticsearch.common.inject.internal.InternalContext;
-import org.elasticsearch.common.inject.internal.InternalFactory;
-import org.elasticsearch.common.inject.internal.PrivateElementsImpl;
-import org.elasticsearch.common.inject.internal.ProviderInstanceBindingImpl;
-import org.elasticsearch.common.inject.internal.Scoping;
-import org.elasticsearch.common.inject.internal.SourceProvider;
-import org.elasticsearch.common.inject.internal.Stopwatch;
-import org.elasticsearch.common.inject.spi.Dependency;
-import org.elasticsearch.common.inject.spi.Element;
-import org.elasticsearch.common.inject.spi.Elements;
-import org.elasticsearch.common.inject.spi.InjectionPoint;
-import org.elasticsearch.common.inject.spi.PrivateElements;
-import org.elasticsearch.common.inject.spi.TypeListenerBinding;
+import org.elasticsearch.common.inject.internal.*;
+import org.elasticsearch.common.inject.spi.*;
 
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Objects;
 import java.util.logging.Logger;
 
-import static com.google.common.base.Preconditions.checkState;
 import static org.elasticsearch.common.inject.Scopes.SINGLETON;
 
 /**
@@ -125,9 +111,15 @@ class InjectorShell {
          */
         List<InjectorShell> build(Initializer initializer, BindingProcessor bindingProcessor,
                                   Stopwatch stopwatch, Errors errors) {
-            checkState(stage != null, "Stage not initialized");
-            checkState(privateElements == null || parent != null, "PrivateElements with no parent");
-            checkState(state != null, "no state. Did you remember to lock() ?");
+            if (stage == null) {
+                throw new IllegalStateException("Stage not initialized");
+            }
+            if (privateElements != null && parent == null) {
+                throw new IllegalStateException("PrivateElements with no parent");
+            }
+            if (state == null) {
+                throw new IllegalStateException("no state. Did you remember to lock() ?");
+            }
 
             InjectorImpl injector = new InjectorImpl(parent, state, initializer);
             if (privateElements != null) {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/Key.java b/core/src/main/java/org/elasticsearch/common/inject/Key.java
index e2bbcf8..92925c6 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/Key.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/Key.java
@@ -24,8 +24,6 @@ import java.lang.annotation.Annotation;
 import java.lang.reflect.Type;
 import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkArgument;
-
 /**
  * Binding key consisting of an injection type and an optional annotation.
  * Matches the type and annotation at a point of injection.
@@ -367,16 +365,20 @@ public class Key<T> {
 
     private static void ensureRetainedAtRuntime(
             Class<? extends Annotation> annotationType) {
-        checkArgument(Annotations.isRetainedAtRuntime(annotationType),
-                "%s is not retained at runtime. Please annotate it with @Retention(RUNTIME).",
-                annotationType.getName());
+        if (!Annotations.isRetainedAtRuntime(annotationType)) {
+            throw new IllegalArgumentException(
+                    annotationType.getName() + " is not retained at runtime. Please annotate it with @Retention(RUNTIME)."
+            );
+        }
     }
 
     private static void ensureIsBindingAnnotation(
             Class<? extends Annotation> annotationType) {
-        checkArgument(isBindingAnnotation(annotationType),
-                "%s is not a binding annotation. Please annotate it with @BindingAnnotation.",
-                annotationType.getName());
+        if (!isBindingAnnotation(annotationType)) {
+            throw new IllegalArgumentException(
+                    annotationType.getName() + " is not a binding annotation. Please annotate it with @BindingAnnotation."
+            );
+        }
     }
 
     static enum NullAnnotationStrategy implements AnnotationStrategy {
diff --git a/core/src/main/java/org/elasticsearch/common/inject/PrivateModule.java b/core/src/main/java/org/elasticsearch/common/inject/PrivateModule.java
index caf6a23..a69ba75 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/PrivateModule.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/PrivateModule.java
@@ -27,8 +27,6 @@ import org.elasticsearch.common.inject.spi.TypeListener;
 
 import java.lang.annotation.Annotation;
 
-import static com.google.common.base.Preconditions.checkState;
-
 /**
  * A module whose configuration information is hidden from its environment by default. Only bindings
  * that are explicitly exposed will be available to other modules and to the users of the injector.
@@ -93,7 +91,9 @@ public abstract class PrivateModule implements Module {
 
     @Override
     public final synchronized void configure(Binder binder) {
-        checkState(this.binder == null, "Re-entry is not allowed.");
+        if (this.binder != null) {
+            throw new IllegalStateException("Re-entry is not allowed.");
+        }
 
         // Guice treats PrivateModules specially and passes in a PrivateBinder automatically.
         this.binder = (PrivateBinder) binder.skipSources(PrivateModule.class);
diff --git a/core/src/main/java/org/elasticsearch/common/inject/ProvisionException.java b/core/src/main/java/org/elasticsearch/common/inject/ProvisionException.java
index b124dfc..9497169 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/ProvisionException.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/ProvisionException.java
@@ -23,8 +23,6 @@ import org.elasticsearch.common.inject.spi.Message;
 import java.util.Collection;
 import java.util.Collections;
 
-import static com.google.common.base.Preconditions.checkArgument;
-
 /**
  * Indicates that there was a runtime failure while providing an instance.
  *
@@ -41,7 +39,9 @@ public final class ProvisionException extends RuntimeException {
      */
     public ProvisionException(Iterable<Message> messages) {
         this.messages = ImmutableSet.copyOf(messages);
-        checkArgument(!this.messages.isEmpty());
+        if (this.messages.isEmpty()) {
+            throw new IllegalArgumentException();
+        }
         initCause(Errors.getOnlyCause(this.messages));
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/TypeLiteral.java b/core/src/main/java/org/elasticsearch/common/inject/TypeLiteral.java
index de9101d..ee50b12 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/TypeLiteral.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/TypeLiteral.java
@@ -24,7 +24,6 @@ import java.util.Arrays;
 import java.util.List;
 import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkArgument;
 import static org.elasticsearch.common.inject.internal.MoreTypes.canonicalize;
 
 /**
@@ -257,8 +256,9 @@ public class TypeLiteral<T> {
      * @since 2.0
      */
     public TypeLiteral<?> getSupertype(Class<?> supertype) {
-        checkArgument(supertype.isAssignableFrom(rawType),
-                "%s is not a supertype of %s", supertype, this.type);
+        if (!supertype.isAssignableFrom(rawType)) {
+            throw new IllegalArgumentException(supertype + " is not a supertype of " + type);
+        }
         return resolve(MoreTypes.getGenericSupertype(type, rawType, supertype));
     }
 
@@ -269,8 +269,9 @@ public class TypeLiteral<T> {
      * @since 2.0
      */
     public TypeLiteral<?> getFieldType(Field field) {
-        checkArgument(field.getDeclaringClass().isAssignableFrom(rawType),
-                "%s is not defined by a supertype of %s", field, type);
+        if (!field.getDeclaringClass().isAssignableFrom(rawType)) {
+            throw new IllegalArgumentException(field + " is not defined by a supertype of " + type);
+        }
         return resolve(field.getGenericType());
     }
 
@@ -285,14 +286,17 @@ public class TypeLiteral<T> {
 
         if (methodOrConstructor instanceof Method) {
             Method method = (Method) methodOrConstructor;
-            checkArgument(method.getDeclaringClass().isAssignableFrom(rawType),
-                    "%s is not defined by a supertype of %s", method, type);
+            if (!method.getDeclaringClass().isAssignableFrom(rawType)) {
+                throw new IllegalArgumentException(method + " is not defined by a supertype of " + type);
+            }
             genericParameterTypes = method.getGenericParameterTypes();
 
         } else if (methodOrConstructor instanceof Constructor) {
             Constructor constructor = (Constructor) methodOrConstructor;
-            checkArgument(constructor.getDeclaringClass().isAssignableFrom(rawType),
-                    "%s does not construct a supertype of %s", constructor, type);
+            if (!constructor.getDeclaringClass().isAssignableFrom(rawType)) {
+                throw new IllegalArgumentException(constructor + " does not construct a supertype of " + type);
+            }
+
             genericParameterTypes = constructor.getGenericParameterTypes();
 
         } else {
@@ -313,14 +317,17 @@ public class TypeLiteral<T> {
 
         if (methodOrConstructor instanceof Method) {
             Method method = (Method) methodOrConstructor;
-            checkArgument(method.getDeclaringClass().isAssignableFrom(rawType),
-                    "%s is not defined by a supertype of %s", method, type);
+            if (!method.getDeclaringClass().isAssignableFrom(rawType)) {
+                throw new IllegalArgumentException(method + " is not defined by a supertype of " + type);
+            }
+
             genericExceptionTypes = method.getGenericExceptionTypes();
 
         } else if (methodOrConstructor instanceof Constructor) {
             Constructor<?> constructor = (Constructor<?>) methodOrConstructor;
-            checkArgument(constructor.getDeclaringClass().isAssignableFrom(rawType),
-                    "%s does not construct a supertype of %s", constructor, type);
+            if (!constructor.getDeclaringClass().isAssignableFrom(rawType)) {
+                throw new IllegalArgumentException(constructor + " does not construct a supertype of " + type);
+            }
             genericExceptionTypes = constructor.getGenericExceptionTypes();
 
         } else {
@@ -337,8 +344,10 @@ public class TypeLiteral<T> {
      * @since 2.0
      */
     public TypeLiteral<?> getReturnType(Method method) {
-        checkArgument(method.getDeclaringClass().isAssignableFrom(rawType),
-                "%s is not defined by a supertype of %s", method, type);
+        if (!method.getDeclaringClass().isAssignableFrom(rawType)) {
+            throw new IllegalArgumentException(method + " is not defined by a supertype of " + type);
+        }
+
         return resolve(method.getGenericReturnType());
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
index 821d729..bedd796 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
@@ -17,18 +17,7 @@
 package org.elasticsearch.common.inject.assistedinject;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Iterables;
-import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.inject.Binder;
-import org.elasticsearch.common.inject.Binding;
-import org.elasticsearch.common.inject.ConfigurationException;
-import org.elasticsearch.common.inject.Inject;
-import org.elasticsearch.common.inject.Injector;
-import org.elasticsearch.common.inject.Key;
-import org.elasticsearch.common.inject.Module;
-import org.elasticsearch.common.inject.Provider;
-import org.elasticsearch.common.inject.ProvisionException;
-import org.elasticsearch.common.inject.TypeLiteral;
+import org.elasticsearch.common.inject.*;
 import org.elasticsearch.common.inject.internal.Errors;
 import org.elasticsearch.common.inject.internal.ErrorsException;
 import org.elasticsearch.common.inject.spi.Message;
@@ -43,7 +32,6 @@ import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
 
-import static com.google.common.base.Preconditions.checkState;
 import static org.elasticsearch.common.inject.internal.Annotations.getKey;
 
 /**
@@ -192,8 +180,9 @@ public final class FactoryProvider2<F> implements InvocationHandler, Provider<F>
      * Creates a child injector that binds the args, and returns the binding for the method's result.
      */
     public Binding<?> getBindingFromNewInjector(final Method method, final Object[] args) {
-        checkState(injector != null,
-                "Factories.create() factories cannot be used until they're initialized by Guice.");
+        if (injector == null) {
+            throw new IllegalStateException("Factories.create() factories cannot be used until they're initialized by Guice.");
+        }
 
         final Key<?> returnType = returnTypesByMethod.get(method);
 
@@ -237,7 +226,7 @@ public final class FactoryProvider2<F> implements InvocationHandler, Provider<F>
         } catch (ProvisionException e) {
             // if this is an exception declared by the factory method, throw it as-is
             if (e.getErrorMessages().size() == 1) {
-                Message onlyError = Iterables.getOnlyElement(e.getErrorMessages());
+                Message onlyError = e.getErrorMessages().iterator().next();
                 Throwable cause = onlyError.getCause();
                 if (cause != null && canRethrow(method, cause)) {
                     throw cause;
diff --git a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/Parameter.java b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/Parameter.java
index a882b9f..16e4deb 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/Parameter.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/Parameter.java
@@ -22,8 +22,6 @@ import java.lang.annotation.Annotation;
 import java.lang.reflect.ParameterizedType;
 import java.lang.reflect.Type;
 
-import static com.google.common.base.Preconditions.checkArgument;
-
 /**
  * Models a method or constructor parameter.
  *
@@ -144,8 +142,9 @@ class Parameter {
         Annotation bindingAnnotation = null;
         for (Annotation a : annotations) {
             if (a.annotationType().getAnnotation(BindingAnnotation.class) != null) {
-                checkArgument(bindingAnnotation == null,
-                        "Parameter has multiple binding annotations: %s and %s", bindingAnnotation, a);
+                if (bindingAnnotation != null) {
+                    throw new IllegalArgumentException("Parameter has multiple binding annotations: " + bindingAnnotation + " and " + a);
+                }
                 bindingAnnotation = a;
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java b/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
index 6eb6f40..2a61116 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
@@ -30,8 +30,6 @@ import java.util.Map;
 import java.util.NoSuchElementException;
 import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkArgument;
-
 /**
  * Static methods for working with types that we aren't publishing in the
  * public {@code Types} API.
@@ -152,8 +150,11 @@ public class MoreTypes {
             // Neal isn't either but suspects some pathological case related
             // to nested classes exists.
             Type rawType = parameterizedType.getRawType();
-            checkArgument(rawType instanceof Class,
-                    "Expected a Class, but <%s> is of type %s", type, type.getClass().getName());
+            if (!(rawType instanceof Class)) {
+                throw new IllegalArgumentException(
+                        "Expected a Class, but <" + type +"> is of type " + type.getClass().getName()
+                );
+            }
             return (Class<?>) rawType;
 
         } else if (type instanceof GenericArrayType) {
@@ -445,10 +446,13 @@ public class MoreTypes {
             // require an owner type if the raw type needs it
             if (rawType instanceof Class<?>) {
                 Class rawTypeAsClass = (Class) rawType;
-                checkArgument(ownerType != null || rawTypeAsClass.getEnclosingClass() == null,
-                        "No owner type for enclosed %s", rawType);
-                checkArgument(ownerType == null || rawTypeAsClass.getEnclosingClass() != null,
-                        "Owner type for unenclosed %s", rawType);
+                if (ownerType == null && rawTypeAsClass.getEnclosingClass() != null) {
+                    throw new IllegalArgumentException("No owner type for enclosed " + rawType);
+                }
+                if (ownerType != null && rawTypeAsClass.getEnclosingClass() == null) {
+                    throw new IllegalArgumentException("Owner type for unenclosed " + rawType);
+                }
+
             }
 
             this.ownerType = ownerType == null ? null : canonicalize(ownerType);
@@ -561,13 +565,18 @@ public class MoreTypes {
         private final Type lowerBound;
 
         public WildcardTypeImpl(Type[] upperBounds, Type[] lowerBounds) {
-            checkArgument(lowerBounds.length <= 1, "Must have at most one lower bound.");
-            checkArgument(upperBounds.length == 1, "Must have exactly one upper bound.");
-
+            if (lowerBounds.length > 1) {
+                throw new IllegalArgumentException("Must have at most one lower bound.");
+            }
+            if (upperBounds.length != 1) {
+                throw new IllegalArgumentException("Must have exactly one upper bound.");
+            }
             if (lowerBounds.length == 1) {
                 Objects.requireNonNull(lowerBounds[0], "lowerBound");
                 checkNotPrimitive(lowerBounds[0], "wildcard bounds");
-                checkArgument(upperBounds[0] == Object.class, "bounded both ways");
+                if (upperBounds[0] != Object.class) {
+                    throw new IllegalArgumentException("bounded both ways");
+                }
                 this.lowerBound = canonicalize(lowerBounds[0]);
                 this.upperBound = Object.class;
 
@@ -615,8 +624,9 @@ public class MoreTypes {
     }
 
     private static void checkNotPrimitive(Type type, String use) {
-        checkArgument(!(type instanceof Class<?>) || !((Class) type).isPrimitive(),
-                "Primitive types are not allowed in %s: %s", use, type);
+        if (type instanceof Class<?> && ((Class) type).isPrimitive()) {
+            throw new IllegalArgumentException("Primitive types are not allowed in " + use + ": " + type);
+        }
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java b/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
index 5d2bbad..6ab5454 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
@@ -25,16 +25,7 @@ import org.elasticsearch.common.inject.spi.Element;
 import org.elasticsearch.common.inject.spi.ElementVisitor;
 import org.elasticsearch.common.inject.spi.PrivateElements;
 
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Objects;
-import java.util.Set;
-
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkState;
+import java.util.*;
 
 /**
  * @author jessewilson@google.com (Jesse Wilson)
@@ -88,7 +79,9 @@ public final class PrivateElementsImpl implements PrivateElements {
     }
 
     public void initInjector(Injector injector) {
-        checkState(this.injector == null, "injector already initialized");
+        if (this.injector != null) {
+            throw new IllegalStateException("injector already initialized");
+        }
         this.injector = Objects.requireNonNull(injector, "injector");
     }
 
@@ -137,7 +130,9 @@ public final class PrivateElementsImpl implements PrivateElements {
     public Object getExposedSource(Key<?> key) {
         getExposedKeys(); // ensure exposedKeysToSources is populated
         Object source = exposedKeysToSources.get(key);
-        checkArgument(source != null, "%s not exposed by %s.", key, this);
+        if (source == null) {
+            throw new IllegalArgumentException(key + " not exposed by " + ".");
+        }
         return source;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java b/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java
index f0fa05c..a149c57 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/SourceProvider.java
@@ -17,7 +17,7 @@
 package org.elasticsearch.common.inject.internal;
 
 import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Iterables;
+import org.elasticsearch.common.util.iterable.Iterables;
 
 import java.util.ArrayList;
 import java.util.List;
diff --git a/core/src/main/java/org/elasticsearch/common/inject/matcher/Matchers.java b/core/src/main/java/org/elasticsearch/common/inject/matcher/Matchers.java
index 7e663db..c29a48d 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/matcher/Matchers.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/matcher/Matchers.java
@@ -24,8 +24,6 @@ import java.lang.reflect.AnnotatedElement;
 import java.lang.reflect.Method;
 import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkArgument;
-
 /**
  * Matcher implementations. Supports matching classes and methods.
  *
@@ -103,8 +101,9 @@ public class Matchers {
     private static void checkForRuntimeRetention(
             Class<? extends Annotation> annotationType) {
         Retention retention = annotationType.getAnnotation(Retention.class);
-        checkArgument(retention != null && retention.value() == RetentionPolicy.RUNTIME,
-                "Annotation " + annotationType.getSimpleName() + " is missing RUNTIME retention");
+        if (retention == null || retention.value() != RetentionPolicy.RUNTIME) {
+            throw new IllegalArgumentException("Annotation " + annotationType.getSimpleName() + " is missing RUNTIME retention");
+        }
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java b/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java
index 9c50a1a..afc8545 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/Elements.java
@@ -16,43 +16,17 @@
 
 package org.elasticsearch.common.inject.spi;
 
-import org.elasticsearch.common.inject.AbstractModule;
-import org.elasticsearch.common.inject.Binder;
-import org.elasticsearch.common.inject.Binding;
-import org.elasticsearch.common.inject.Key;
-import org.elasticsearch.common.inject.MembersInjector;
-import org.elasticsearch.common.inject.Module;
-import org.elasticsearch.common.inject.PrivateBinder;
-import org.elasticsearch.common.inject.PrivateModule;
-import org.elasticsearch.common.inject.Provider;
-import org.elasticsearch.common.inject.Scope;
-import org.elasticsearch.common.inject.Stage;
-import org.elasticsearch.common.inject.TypeLiteral;
+import org.elasticsearch.common.inject.*;
 import org.elasticsearch.common.inject.binder.AnnotatedBindingBuilder;
 import org.elasticsearch.common.inject.binder.AnnotatedConstantBindingBuilder;
 import org.elasticsearch.common.inject.binder.AnnotatedElementBuilder;
-import org.elasticsearch.common.inject.internal.AbstractBindingBuilder;
-import org.elasticsearch.common.inject.internal.BindingBuilder;
-import org.elasticsearch.common.inject.internal.ConstantBindingBuilderImpl;
-import org.elasticsearch.common.inject.internal.Errors;
-import org.elasticsearch.common.inject.internal.ExposureBuilder;
-import org.elasticsearch.common.inject.internal.PrivateElementsImpl;
-import org.elasticsearch.common.inject.internal.ProviderMethodsModule;
-import org.elasticsearch.common.inject.internal.SourceProvider;
+import org.elasticsearch.common.inject.internal.*;
 import org.elasticsearch.common.inject.matcher.Matcher;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 
 import java.lang.annotation.Annotation;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-import static com.google.common.base.Preconditions.checkArgument;
+import java.util.*;
 
 /**
  * Exposes elements of a module so they can be inspected, validated or {@link
@@ -156,7 +130,9 @@ public final class Elements {
          */
         private RecordingBinder(
                 RecordingBinder prototype, Object source, SourceProvider sourceProvider) {
-            checkArgument(source == null ^ sourceProvider == null);
+            if (!(source == null ^ sourceProvider == null)) {
+                throw new IllegalArgumentException();
+            }
 
             this.stage = prototype.stage;
             this.modules = prototype.modules;
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/MembersInjectorLookup.java b/core/src/main/java/org/elasticsearch/common/inject/spi/MembersInjectorLookup.java
index f53d662..9bde624 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/MembersInjectorLookup.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/MembersInjectorLookup.java
@@ -22,8 +22,6 @@ import org.elasticsearch.common.inject.TypeLiteral;
 
 import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkState;
-
 /**
  * A lookup of the members injector for a type. Lookups are created explicitly in a module using
  * {@link org.elasticsearch.common.inject.Binder#getMembersInjector(Class) getMembersInjector()} statements:
@@ -68,7 +66,9 @@ public final class MembersInjectorLookup<T> implements Element {
      * @throws IllegalStateException if the delegate is already set
      */
     public void initializeDelegate(MembersInjector<T> delegate) {
-        checkState(this.delegate == null, "delegate already initialized");
+        if (this.delegate != null) {
+            throw new IllegalStateException("delegate already initialized");
+        }
         this.delegate = Objects.requireNonNull(delegate, "delegate");
     }
 
@@ -95,8 +95,9 @@ public final class MembersInjectorLookup<T> implements Element {
         return new MembersInjector<T>() {
             @Override
             public void injectMembers(T instance) {
-                checkState(delegate != null,
-                        "This MembersInjector cannot be used until the Injector has been created.");
+                if (delegate == null) {
+                    throw new IllegalStateException("This MembersInjector cannot be used until the Injector has been created.");
+                }
                 delegate.injectMembers(instance);
             }
 
diff --git a/core/src/main/java/org/elasticsearch/common/inject/spi/ProviderLookup.java b/core/src/main/java/org/elasticsearch/common/inject/spi/ProviderLookup.java
index 61ae67a..464b850 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/spi/ProviderLookup.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/spi/ProviderLookup.java
@@ -22,8 +22,6 @@ import org.elasticsearch.common.inject.Provider;
 
 import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkState;
-
 /**
  * A lookup of the provider for a type. Lookups are created explicitly in a module using
  * {@link org.elasticsearch.common.inject.Binder#getProvider(Class) getProvider()} statements:
@@ -46,8 +44,9 @@ public final class ProviderLookup<T> implements Element {
 
         @Override
         public T get() {
-            checkState(lookup.delegate != null,
-                "This Provider cannot be used until the Injector has been created.");
+            if (lookup.delegate == null) {
+                throw new IllegalStateException( "This Provider cannot be used until the Injector has been created.");
+            }
             return lookup.delegate.get();
         }
 
@@ -89,7 +88,9 @@ public final class ProviderLookup<T> implements Element {
      * @throws IllegalStateException if the delegate is already set
      */
     public void initializeDelegate(Provider<T> delegate) {
-        checkState(this.delegate == null, "delegate already initialized");
+        if (this.delegate != null) {
+            throw new IllegalStateException("delegate already initialized");
+        }
         this.delegate = Objects.requireNonNull(delegate, "delegate");
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java
index 0d0db20..db2bb12 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/Lucene.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.common.lucene;
 
-import com.google.common.collect.Iterables;
 import org.apache.lucene.analysis.core.KeywordAnalyzer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.codecs.CodecUtil;
@@ -27,7 +26,10 @@ import org.apache.lucene.codecs.DocValuesFormat;
 import org.apache.lucene.codecs.PostingsFormat;
 import org.apache.lucene.index.*;
 import org.apache.lucene.search.*;
-import org.apache.lucene.store.*;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.IOContext;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.store.Lock;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.Counter;
@@ -40,6 +42,7 @@ import org.elasticsearch.common.SuppressForbidden;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.logging.ESLogger;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.index.analysis.AnalyzerScope;
 import org.elasticsearch.index.analysis.NamedAnalyzer;
 import org.elasticsearch.index.fielddata.IndexFieldData;
@@ -107,7 +110,7 @@ public class Lucene {
         for (SegmentCommitInfo info : infos) {
             list.add(info.files());
         }
-        return Iterables.concat(list);
+        return Iterables.flatten(list);
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/lucene/ShardCoreKeyMap.java b/core/src/main/java/org/elasticsearch/common/lucene/ShardCoreKeyMap.java
index 0d9270e..c405de1 100644
--- a/core/src/main/java/org/elasticsearch/common/lucene/ShardCoreKeyMap.java
+++ b/core/src/main/java/org/elasticsearch/common/lucene/ShardCoreKeyMap.java
@@ -19,19 +19,11 @@
 
 package org.elasticsearch.common.lucene;
 
-import com.google.common.collect.HashMultimap;
-import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Multimap;
-
 import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.LeafReader.CoreClosedListener;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.index.shard.ShardUtils;
 
-import java.io.IOException;
-import java.util.IdentityHashMap;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 
 /**
  * A map between segment core cache keys and the shard that these segments
@@ -47,16 +39,16 @@ import java.util.Set;
 public final class ShardCoreKeyMap {
 
     private final Map<Object, ShardId> coreKeyToShard;
-    private final Multimap<String, Object> indexToCoreKey;
+    private final Map<String, Set<Object>> indexToCoreKey;
 
     public ShardCoreKeyMap() {
         coreKeyToShard = new IdentityHashMap<>();
-        indexToCoreKey = HashMultimap.create();
+        indexToCoreKey = new HashMap<>();
     }
 
     /**
      * Register a {@link LeafReader}. This is necessary so that the core cache
-     * key of this reader can be found later using {@link #getCoreCacheKeys(ShardId)}.
+     * key of this reader can be found later using {@link #getCoreKeysForIndex(String)}.
      */
     public void add(LeafReader reader) {
         final ShardId shardId = ShardUtils.extractShardId(reader);
@@ -67,15 +59,22 @@ public final class ShardCoreKeyMap {
         final String index = shardId.getIndex();
         synchronized (this) {
             if (coreKeyToShard.put(coreKey, shardId) == null) {
-                final boolean added = indexToCoreKey.put(index, coreKey);
+                Set<Object> objects = indexToCoreKey.get(index);
+                if (objects == null) {
+                    objects = new HashSet<>();
+                    indexToCoreKey.put(index, objects);
+                }
+                final boolean added = objects.add(coreKey);
                 assert added;
-                reader.addCoreClosedListener(new CoreClosedListener() {
-                    @Override
-                    public void onClose(Object ownerCoreCacheKey) throws IOException {
-                        assert coreKey == ownerCoreCacheKey;
-                        synchronized (ShardCoreKeyMap.this) {
-                            coreKeyToShard.remove(ownerCoreCacheKey);
-                            indexToCoreKey.remove(index, coreKey);
+                reader.addCoreClosedListener(ownerCoreCacheKey -> {
+                    assert coreKey == ownerCoreCacheKey;
+                    synchronized (ShardCoreKeyMap.this) {
+                        coreKeyToShard.remove(ownerCoreCacheKey);
+                        final Set<Object> coreKeys = indexToCoreKey.get(index);
+                        final boolean removed = coreKeys.remove(coreKey);
+                        assert removed;
+                        if (coreKeys.isEmpty()) {
+                            indexToCoreKey.remove(index);
                         }
                     }
                 });
@@ -95,15 +94,35 @@ public final class ShardCoreKeyMap {
      * Get the set of core cache keys associated with the given index.
      */
     public synchronized Set<Object> getCoreKeysForIndex(String index) {
-        return ImmutableSet.copyOf(indexToCoreKey.get(index));
+        final Set<Object> objects = indexToCoreKey.get(index);
+        if (objects == null) {
+            return Collections.emptySet();
+        }
+        // we have to copy otherwise we risk ConcurrentModificationException
+        return Collections.unmodifiableSet(new HashSet<>(objects));
     }
 
     /**
      * Return the number of tracked segments.
      */
     public synchronized int size() {
-        assert indexToCoreKey.size() == coreKeyToShard.size();
+        assert assertSize();
         return coreKeyToShard.size();
     }
 
+    private synchronized boolean assertSize() {
+        // this is heavy and should only used in assertions
+        boolean assertionsEnabled = false;
+        assert assertionsEnabled = true;
+        if (assertionsEnabled == false) {
+            throw new AssertionError("only run this if assertions are enabled");
+        }
+        Collection<Set<Object>> values = indexToCoreKey.values();
+        int size = 0;
+        for (Set<Object> value : values) {
+            size += value.size();
+        }
+        return size == coreKeyToShard.size();
+    }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java b/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
index cfcd209..3b4a073 100644
--- a/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
+++ b/core/src/main/java/org/elasticsearch/common/unit/Fuzziness.java
@@ -18,9 +18,6 @@
  */
 package org.elasticsearch.common.unit;
 
-import com.google.common.base.Preconditions;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.util.automaton.LevenshteinAutomata;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
@@ -46,7 +43,9 @@ public final class Fuzziness implements ToXContent {
     private final String fuzziness;
 
     private Fuzziness(int fuzziness) {
-        Preconditions.checkArgument(fuzziness >= 0 && fuzziness <= 2, "Valid edit distances are [0, 1, 2] but was [" + fuzziness + "]");
+        if (fuzziness != 0 && fuzziness != 1 && fuzziness != 2) {
+            throw new IllegalArgumentException("Valid edit distances are [0, 1, 2] but was [" + fuzziness + "]");
+        }
         this.fuzziness = Integer.toString(fuzziness);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/unit/SizeValue.java b/core/src/main/java/org/elasticsearch/common/unit/SizeValue.java
index 586f305..fcbcff3 100644
--- a/core/src/main/java/org/elasticsearch/common/unit/SizeValue.java
+++ b/core/src/main/java/org/elasticsearch/common/unit/SizeValue.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.common.unit;
 
-import com.google.common.base.Preconditions;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.io.stream.StreamInput;
@@ -46,7 +45,9 @@ public class SizeValue implements Streamable {
     }
 
     public SizeValue(long size, SizeUnit sizeUnit) {
-        Preconditions.checkArgument(size >= 0, "size in SizeValue may not be negative");
+        if (size < 0) {
+            throw new IllegalArgumentException("size in SizeValue may not be negative");
+        }
         this.size = size;
         this.sizeUnit = sizeUnit;
     }
diff --git a/core/src/main/java/org/elasticsearch/common/util/AbstractBigArray.java b/core/src/main/java/org/elasticsearch/common/util/AbstractBigArray.java
index 1523b80..29beee9 100644
--- a/core/src/main/java/org/elasticsearch/common/util/AbstractBigArray.java
+++ b/core/src/main/java/org/elasticsearch/common/util/AbstractBigArray.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.common.util;
 
-import com.google.common.base.Preconditions;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.elasticsearch.cache.recycler.PageCacheRecycler;
@@ -42,8 +41,12 @@ abstract class AbstractBigArray extends AbstractArray {
     protected AbstractBigArray(int pageSize, BigArrays bigArrays, boolean clearOnResize) {
         super(bigArrays, clearOnResize);
         this.recycler = bigArrays.recycler;
-        Preconditions.checkArgument(pageSize >= 128, "pageSize must be >= 128");
-        Preconditions.checkArgument((pageSize & (pageSize - 1)) == 0, "pageSize must be a power of two");
+        if (pageSize < 128) {
+            throw new IllegalArgumentException("pageSize must be >= 128");
+        }
+        if ((pageSize & (pageSize - 1)) != 0) {
+            throw new IllegalArgumentException("pageSize must be a power of two");
+        }
         this.pageShift = Integer.numberOfTrailingZeros(pageSize);
         this.pageMask = pageSize - 1;
         size = 0;
@@ -56,7 +59,9 @@ abstract class AbstractBigArray extends AbstractArray {
 
     final int numPages(long capacity) {
         final long numPages = (capacity + pageMask) >>> pageShift;
-        Preconditions.checkArgument(numPages <= Integer.MAX_VALUE, "pageSize=" + (pageMask + 1) + " is too small for such as capacity: " + capacity);
+        if (numPages > Integer.MAX_VALUE) {
+            throw new IllegalArgumentException("pageSize=" + (pageMask + 1) + " is too small for such as capacity: " + capacity);
+        }
         return (int) numPages;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/util/AbstractPagedHashMap.java b/core/src/main/java/org/elasticsearch/common/util/AbstractPagedHashMap.java
index b481557..2368a5d 100644
--- a/core/src/main/java/org/elasticsearch/common/util/AbstractPagedHashMap.java
+++ b/core/src/main/java/org/elasticsearch/common/util/AbstractPagedHashMap.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.common.util;
 
 import com.carrotsearch.hppc.BitMixer;
-import com.google.common.base.Preconditions;
 import org.elasticsearch.common.lease.Releasable;
 
 /**
@@ -48,8 +47,12 @@ abstract class AbstractPagedHashMap implements Releasable {
     long mask;
 
     AbstractPagedHashMap(long capacity, float maxLoadFactor, BigArrays bigArrays) {
-        Preconditions.checkArgument(capacity >= 0, "capacity must be >= 0");
-        Preconditions.checkArgument(maxLoadFactor > 0 && maxLoadFactor < 1, "maxLoadFactor must be > 0 and < 1");
+        if (capacity < 0) {
+            throw new IllegalArgumentException("capacity must be >= 0");
+        }
+        if (maxLoadFactor <= 0 || maxLoadFactor >= 1) {
+            throw new IllegalArgumentException("maxLoadFactor must be > 0 and < 1");
+        }
         this.bigArrays = bigArrays;
         this.maxLoadFactor = maxLoadFactor;
         long buckets = 1L + (long) (capacity / maxLoadFactor);
diff --git a/core/src/main/java/org/elasticsearch/common/util/ArrayUtils.java b/core/src/main/java/org/elasticsearch/common/util/ArrayUtils.java
index 053c9b5..bb8442e 100644
--- a/core/src/main/java/org/elasticsearch/common/util/ArrayUtils.java
+++ b/core/src/main/java/org/elasticsearch/common/util/ArrayUtils.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.common.util;
 
+import java.lang.reflect.Array;
 import java.util.Arrays;
 
 /**
@@ -69,4 +70,22 @@ public class ArrayUtils {
         }
         return index;
     }
+
+    /**
+     * Concatenates 2 arrays
+     */
+    public static String[] concat(String[] one, String[] other) {
+        return concat(one, other, String.class);
+    }
+
+    /**
+     * Concatenates 2 arrays
+     */
+    public static <T> T[] concat(T[] one, T[] other, Class<T> clazz) {
+        T[] target = (T[]) Array.newInstance(clazz, one.length + other.length);
+        System.arraycopy(one, 0, target, 0, one.length);
+        System.arraycopy(other, 0, target, one.length, other.length);
+        return target;
+    }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/common/util/BigArrays.java b/core/src/main/java/org/elasticsearch/common/util/BigArrays.java
index 90db1bd..0f0bced 100644
--- a/core/src/main/java/org/elasticsearch/common/util/BigArrays.java
+++ b/core/src/main/java/org/elasticsearch/common/util/BigArrays.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.common.util;
 
-import com.google.common.base.Preconditions;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.RamUsageEstimator;
@@ -55,9 +54,15 @@ public class BigArrays {
     /** Return the next size to grow to that is &gt;= <code>minTargetSize</code>.
      *  Inspired from {@link ArrayUtil#oversize(int, int)} and adapted to play nicely with paging. */
     public static long overSize(long minTargetSize, int pageSize, int bytesPerElement) {
-        Preconditions.checkArgument(minTargetSize >= 0, "minTargetSize must be >= 0");
-        Preconditions.checkArgument(pageSize >= 0, "pageSize must be > 0");
-        Preconditions.checkArgument(bytesPerElement > 0, "bytesPerElement must be > 0");
+        if (minTargetSize < 0) {
+            throw new IllegalArgumentException("minTargetSize must be >= 0");
+        }
+        if (pageSize < 0) {
+            throw new IllegalArgumentException("pageSize must be > 0");
+        }
+        if (bytesPerElement <= 0) {
+            throw new IllegalArgumentException("bytesPerElement must be > 0");
+        }
 
         long newSize;
         if (minTargetSize < pageSize) {
diff --git a/core/src/main/java/org/elasticsearch/common/util/BigByteArray.java b/core/src/main/java/org/elasticsearch/common/util/BigByteArray.java
index 2a445cc..da4bc28 100644
--- a/core/src/main/java/org/elasticsearch/common/util/BigByteArray.java
+++ b/core/src/main/java/org/elasticsearch/common/util/BigByteArray.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.common.util;
 
-import com.google.common.base.Preconditions;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.RamUsageEstimator;
@@ -110,7 +109,9 @@ final class BigByteArray extends AbstractBigArray implements ByteArray {
 
     @Override
     public void fill(long fromIndex, long toIndex, byte value) {
-        Preconditions.checkArgument(fromIndex <= toIndex);
+        if (fromIndex > toIndex) {
+            throw new IllegalArgumentException();
+        }
         final int fromPage = pageIndex(fromIndex);
         final int toPage = pageIndex(toIndex - 1);
         if (fromPage == toPage) {
diff --git a/core/src/main/java/org/elasticsearch/common/util/BigDoubleArray.java b/core/src/main/java/org/elasticsearch/common/util/BigDoubleArray.java
index 38df32c..1f73918 100644
--- a/core/src/main/java/org/elasticsearch/common/util/BigDoubleArray.java
+++ b/core/src/main/java/org/elasticsearch/common/util/BigDoubleArray.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.common.util;
 
-import com.google.common.base.Preconditions;
-
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.RamUsageEstimator;
 
@@ -95,7 +93,9 @@ final class BigDoubleArray extends AbstractBigArray implements DoubleArray {
 
     @Override
     public void fill(long fromIndex, long toIndex, double value) {
-        Preconditions.checkArgument(fromIndex <= toIndex);
+        if (fromIndex > toIndex) {
+            throw new IllegalArgumentException();
+        }
         final long longBits = Double.doubleToRawLongBits(value);
         final int fromPage = pageIndex(fromIndex);
         final int toPage = pageIndex(toIndex - 1);
diff --git a/core/src/main/java/org/elasticsearch/common/util/BigFloatArray.java b/core/src/main/java/org/elasticsearch/common/util/BigFloatArray.java
index fc73c72..f6fc2d8 100644
--- a/core/src/main/java/org/elasticsearch/common/util/BigFloatArray.java
+++ b/core/src/main/java/org/elasticsearch/common/util/BigFloatArray.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.common.util;
 
-import com.google.common.base.Preconditions;
-
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.RamUsageEstimator;
 
@@ -95,7 +93,9 @@ final class BigFloatArray extends AbstractBigArray implements FloatArray {
 
     @Override
     public void fill(long fromIndex, long toIndex, float value) {
-        Preconditions.checkArgument(fromIndex <= toIndex);
+        if (fromIndex > toIndex) {
+            throw new IllegalArgumentException();
+        }
         final int intBits = Float.floatToRawIntBits(value);
         final int fromPage = pageIndex(fromIndex);
         final int toPage = pageIndex(toIndex - 1);
diff --git a/core/src/main/java/org/elasticsearch/common/util/BigIntArray.java b/core/src/main/java/org/elasticsearch/common/util/BigIntArray.java
index c07280b..1c0e9fe 100644
--- a/core/src/main/java/org/elasticsearch/common/util/BigIntArray.java
+++ b/core/src/main/java/org/elasticsearch/common/util/BigIntArray.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.common.util;
 
-import com.google.common.base.Preconditions;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.RamUsageEstimator;
 
@@ -71,7 +70,9 @@ final class BigIntArray extends AbstractBigArray implements IntArray {
 
     @Override
     public void fill(long fromIndex, long toIndex, int value) {
-        Preconditions.checkArgument(fromIndex <= toIndex);
+        if (fromIndex > toIndex) {
+            throw new IllegalArgumentException();
+        }
         final int fromPage = pageIndex(fromIndex);
         final int toPage = pageIndex(toIndex - 1);
         if (fromPage == toPage) {
diff --git a/core/src/main/java/org/elasticsearch/common/util/BigLongArray.java b/core/src/main/java/org/elasticsearch/common/util/BigLongArray.java
index 286dc53..fe0323b 100644
--- a/core/src/main/java/org/elasticsearch/common/util/BigLongArray.java
+++ b/core/src/main/java/org/elasticsearch/common/util/BigLongArray.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.common.util;
 
-import com.google.common.base.Preconditions;
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.RamUsageEstimator;
 
@@ -93,7 +92,9 @@ final class BigLongArray extends AbstractBigArray implements LongArray {
 
     @Override
     public void fill(long fromIndex, long toIndex, long value) {
-        Preconditions.checkArgument(fromIndex <= toIndex);
+        if (fromIndex > toIndex) {
+            throw new IllegalArgumentException();
+        }
         if (fromIndex == toIndex) {
             return; // empty range
         }
diff --git a/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java b/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java
index 8a2acba..0f72d6d 100644
--- a/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java
+++ b/core/src/main/java/org/elasticsearch/common/util/BloomFilter.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.common.util;
 
-import com.google.common.math.LongMath;
 import com.google.common.primitives.Ints;
 import org.apache.lucene.store.DataInput;
 import org.apache.lucene.store.DataOutput;
@@ -33,7 +32,6 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.unit.SizeValue;
 
 import java.io.IOException;
-import java.math.RoundingMode;
 import java.util.Arrays;
 import java.util.Comparator;
 
@@ -321,7 +319,13 @@ public class BloomFilter {
         long bitCount;
 
         BitArray(long bits) {
-            this(new long[Ints.checkedCast(LongMath.divide(bits, 64, RoundingMode.CEILING))]);
+            this(new long[size(bits)]);
+        }
+
+        private static int size(long bits) {
+            long quotient = bits / 64;
+            long remainder = bits - quotient * 64;
+            return Ints.checkedCast(remainder == 0 ? quotient : 1 + quotient);
         }
 
         // Used by serialization
diff --git a/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java b/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java
index 2791ea6..ec37fb2 100644
--- a/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java
+++ b/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java
@@ -23,24 +23,10 @@ import com.carrotsearch.hppc.DoubleArrayList;
 import com.carrotsearch.hppc.FloatArrayList;
 import com.carrotsearch.hppc.LongArrayList;
 import com.carrotsearch.hppc.ObjectArrayList;
-import com.google.common.base.Preconditions;
 import com.google.common.collect.Iterators;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BytesRefArray;
-import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.InPlaceMergeSorter;
-import org.apache.lucene.util.IntroSorter;
-
-import java.util.AbstractList;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.RandomAccess;
+import org.apache.lucene.util.*;
+
+import java.util.*;
 
 /** Collections-related utility methods. */
 public enum CollectionUtils {
@@ -297,8 +283,12 @@ public enum CollectionUtils {
         private final int distance;
 
         public RotatedList(List<T> list, int distance) {
-            Preconditions.checkArgument(distance >= 0 && distance < list.size());
-            Preconditions.checkArgument(list instanceof RandomAccess);
+            if (distance < 0 || distance >= list.size()) {
+                throw new IllegalArgumentException();
+            }
+            if (!(list instanceof RandomAccess)) {
+                throw new IllegalArgumentException();
+            }
             this.in = list;
             this.distance = distance;
         }
@@ -462,4 +452,5 @@ public enum CollectionUtils {
 
         return result;
     }
+
 }
diff --git a/core/src/main/java/org/elasticsearch/common/util/LongObjectPagedHashMap.java b/core/src/main/java/org/elasticsearch/common/util/LongObjectPagedHashMap.java
index 7949989..63b7b23 100644
--- a/core/src/main/java/org/elasticsearch/common/util/LongObjectPagedHashMap.java
+++ b/core/src/main/java/org/elasticsearch/common/util/LongObjectPagedHashMap.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.common.util;
 
 
-import com.google.common.collect.UnmodifiableIterator;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.lease.Releasables;
 
@@ -125,7 +124,7 @@ public class LongObjectPagedHashMap<T> extends AbstractPagedHashMap implements I
 
     @Override
     public Iterator<Cursor<T>> iterator() {
-        return new UnmodifiableIterator<Cursor<T>>() {
+        return new Iterator<Cursor<T>>() {
 
             boolean cached;
             final Cursor<T> cursor;
@@ -162,6 +161,11 @@ public class LongObjectPagedHashMap<T> extends AbstractPagedHashMap implements I
                 return cursor;
             }
 
+            @Override
+            public final void remove() {
+                throw new UnsupportedOperationException();
+            }
+
         };
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/util/concurrent/EsExecutors.java b/core/src/main/java/org/elasticsearch/common/util/concurrent/EsExecutors.java
index c7cc07c..46fd750 100644
--- a/core/src/main/java/org/elasticsearch/common/util/concurrent/EsExecutors.java
+++ b/core/src/main/java/org/elasticsearch/common/util/concurrent/EsExecutors.java
@@ -19,11 +19,12 @@
 
 package org.elasticsearch.common.util.concurrent;
 
-import com.google.common.base.Joiner;
 import org.elasticsearch.common.settings.Settings;
 
+import java.util.Arrays;
 import java.util.concurrent.*;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.stream.Collectors;
 
 /**
  *
@@ -81,7 +82,12 @@ public class EsExecutors {
     }
 
     public static String threadName(Settings settings, String ... names) {
-        return threadName(settings, "[" +  Joiner.on(".").skipNulls().join(names) + "]");
+        String namePrefix =
+                Arrays
+                        .stream(names)
+                        .filter(name -> name != null)
+                        .collect(Collectors.joining(".", "[", "]"));
+        return threadName(settings, namePrefix);
     }
 
     public static String threadName(Settings settings, String namePrefix) {
diff --git a/core/src/main/java/org/elasticsearch/common/util/iterable/Iterables.java b/core/src/main/java/org/elasticsearch/common/util/iterable/Iterables.java
new file mode 100644
index 0000000..f6b891c
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/common/util/iterable/Iterables.java
@@ -0,0 +1,142 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.common.util.iterable;
+
+import org.elasticsearch.common.lucene.store.IndexOutputOutputStream;
+
+import java.util.*;
+import java.util.stream.Stream;
+import java.util.stream.StreamSupport;
+
+public class Iterables {
+    public Iterables() {
+    }
+
+    public static <T> Iterable<T> concat(Iterable<T>... inputs) {
+        Objects.requireNonNull(inputs);
+        return new ConcatenatedIterable(inputs);
+    }
+
+    static class ConcatenatedIterable<T> implements Iterable<T> {
+        private final Iterable<T>[] inputs;
+
+        ConcatenatedIterable(Iterable<T>[] inputs) {
+            this.inputs = Arrays.copyOf(inputs, inputs.length);
+        }
+
+        @Override
+        public Iterator<T> iterator() {
+            return Stream
+                    .of(inputs)
+                    .map(it -> StreamSupport.stream(it.spliterator(), false))
+                    .reduce(Stream::concat)
+                    .orElseGet(Stream::empty).iterator();
+        }
+    }
+
+    public static <T> Iterable<T> flatten(Iterable<? extends Iterable<T>> inputs) {
+        Objects.requireNonNull(inputs);
+        return new FlattenedIterables<>(inputs);
+    }
+
+    static class FlattenedIterables<T> implements Iterable<T> {
+        private final Iterable<? extends Iterable<T>> inputs;
+
+        FlattenedIterables(Iterable<? extends Iterable<T>> inputs) {
+            List<Iterable<T>> list = new ArrayList<>();
+            for (Iterable<T> iterable : inputs) {
+                list.add(iterable);
+            }
+            this.inputs = list;
+        }
+
+        @Override
+        public Iterator<T> iterator() {
+            return StreamSupport
+                    .stream(inputs.spliterator(), false)
+                    .flatMap(s -> StreamSupport.stream(s.spliterator(), false)).iterator();
+        }
+    }
+
+    public static boolean allElementsAreEqual(Iterable<?> left, Iterable<?> right) {
+        Objects.requireNonNull(left);
+        Objects.requireNonNull(right);
+        if (left instanceof Collection && right instanceof Collection) {
+            Collection collection1 = (Collection) left;
+            Collection collection2 = (Collection) right;
+            if (collection1.size() != collection2.size()) {
+                return false;
+            }
+        }
+
+        Iterator<?> leftIt = left.iterator();
+        Iterator<?> rightIt = right.iterator();
+
+        while (true) {
+            if (leftIt.hasNext()) {
+                if (!rightIt.hasNext()) {
+                    return false;
+                }
+
+                Object o1 = leftIt.next();
+                Object o2 = rightIt.next();
+                if (Objects.equals(o1, o2)) {
+                    continue;
+                }
+
+                return false;
+            }
+
+            return !rightIt.hasNext();
+        }
+    }
+
+    public static <T> T getFirst(Iterable<T> collection, T defaultValue) {
+        Objects.requireNonNull(collection);
+        Iterator<T> iterator = collection.iterator();
+        return iterator.hasNext() ? iterator.next() : defaultValue;
+    }
+
+    public static <T> T get(Iterable<T> iterable, int position) {
+        Objects.requireNonNull(iterable);
+        if (position < 0) {
+            throw new IllegalArgumentException("position >= 0");
+        }
+        if (iterable instanceof List) {
+            List<T> list = (List<T>)iterable;
+            if (position >= list.size()) {
+                throw new IndexOutOfBoundsException(Integer.toString(position));
+            }
+            return list.get(position);
+        } else {
+            Iterator<T> it = iterable.iterator();
+            for (int index = 0; index < position; index++) {
+                if (!it.hasNext()) {
+                    throw new IndexOutOfBoundsException(Integer.toString(position));
+                }
+                it.next();
+            }
+            if (!it.hasNext()) {
+                throw new IndexOutOfBoundsException(Integer.toString(position));
+            }
+            return it.next();
+        }
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/gateway/MetaDataStateFormat.java b/core/src/main/java/org/elasticsearch/gateway/MetaDataStateFormat.java
index b15a327..9ac1768 100644
--- a/core/src/main/java/org/elasticsearch/gateway/MetaDataStateFormat.java
+++ b/core/src/main/java/org/elasticsearch/gateway/MetaDataStateFormat.java
@@ -18,28 +18,18 @@
  */
 package org.elasticsearch.gateway;
 
-import com.google.common.base.Preconditions;
-
 import org.apache.lucene.codecs.CodecUtil;
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.IndexFormatTooNewException;
 import org.apache.lucene.index.IndexFormatTooOldException;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.IOContext;
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.store.OutputStreamIndexOutput;
-import org.apache.lucene.store.SimpleFSDirectory;
+import org.apache.lucene.store.*;
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.lucene.store.IndexOutputOutputStream;
 import org.elasticsearch.common.lucene.store.InputStreamIndexInput;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentHelper;
-import org.elasticsearch.common.xcontent.XContentParser;
-import org.elasticsearch.common.xcontent.XContentType;
+import org.elasticsearch.common.xcontent.*;
 
 import java.io.FileNotFoundException;
 import java.io.IOException;
@@ -99,8 +89,12 @@ public abstract class MetaDataStateFormat<T> {
      * @throws IOException if an IOException occurs
      */
     public final void write(final T state, final long version, final Path... locations) throws IOException {
-        Preconditions.checkArgument(locations != null, "Locations must not be null");
-        Preconditions.checkArgument(locations.length > 0, "One or more locations required");
+        if (locations == null) {
+            throw new IllegalArgumentException("Locations must not be null");
+        }
+        if (locations.length <= 0) {
+            throw new IllegalArgumentException("One or more locations required");
+        }
         final long maxStateId = findMaxStateId(prefix, locations)+1;
         assert maxStateId >= 0 : "maxStateId must be positive but was: [" + maxStateId + "]";
         final String fileName = prefix + maxStateId + STATE_FILE_EXTENSION;
diff --git a/core/src/main/java/org/elasticsearch/http/HttpServer.java b/core/src/main/java/org/elasticsearch/http/HttpServer.java
index 0fab142..168ed06 100644
--- a/core/src/main/java/org/elasticsearch/http/HttpServer.java
+++ b/core/src/main/java/org/elasticsearch/http/HttpServer.java
@@ -20,16 +20,17 @@
 package org.elasticsearch.http;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.io.ByteStreams;
 
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.io.FileSystemUtils;
+import org.elasticsearch.common.io.Streams;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.env.Environment;
 import org.elasticsearch.node.service.NodeService;
 import org.elasticsearch.rest.*;
 
+import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.nio.file.*;
@@ -141,8 +142,9 @@ public class HttpServer extends AbstractLifecycleComponent<HttpServer> {
         if (request.method() == RestRequest.Method.GET) {
             try {
                 try (InputStream stream = getClass().getResourceAsStream("/config/favicon.ico")) {
-                    byte[] content = ByteStreams.toByteArray(stream);
-                    BytesRestResponse restResponse = new BytesRestResponse(RestStatus.OK, "image/x-icon", content);
+                    ByteArrayOutputStream out = new ByteArrayOutputStream();
+                    Streams.copy(stream, out);
+                    BytesRestResponse restResponse = new BytesRestResponse(RestStatus.OK, "image/x-icon", out.toByteArray());
                     channel.sendResponse(restResponse);
                 }
             } catch (IOException e) {
diff --git a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
index d180979..899fa5f 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/EngineConfig.java
@@ -94,6 +94,15 @@ public final class EngineConfig {
     public static final String INDEX_GC_DELETES_SETTING = "index.gc_deletes";
 
     /**
+     * Index setting to control the initial index buffer size.  NOTE: this setting is somewhat
+     * useless, since IndexingMemoryController will take over quickly and partition the
+     * indices.memory.index_buffer_size for this node across all shards.
+     *
+     * <p>This setting is <b>not</b> realtime updateable.
+     */
+    public static final String INDEX_BUFFER_SIZE_SETTING = "index.buffer_size";
+
+    /**
      * Index setting to change the low level lucene codec used for writing new segments.
      * This setting is <b>not</b> realtime updateable.
      */
@@ -146,7 +155,7 @@ public final class EngineConfig {
         this.optimizeAutoGenerateId = indexSettings.getAsBoolean(EngineConfig.INDEX_OPTIMIZE_AUTOGENERATED_ID_SETTING, false);
         this.compoundOnFlush = indexSettings.getAsBoolean(EngineConfig.INDEX_COMPOUND_ON_FLUSH, compoundOnFlush);
         codecName = indexSettings.get(EngineConfig.INDEX_CODEC_SETTING, EngineConfig.DEFAULT_CODEC_NAME);
-        indexingBufferSize = DEFAULT_INDEX_BUFFER_SIZE;
+        indexingBufferSize = indexSettings.getAsBytesSize(INDEX_BUFFER_SIZE_SETTING, DEFAULT_INDEX_BUFFER_SIZE);
         gcDeletesInMillis = indexSettings.getAsTime(INDEX_GC_DELETES_SETTING, EngineConfig.DEFAULT_GC_DELETES).millis();
         versionMapSizeSetting = indexSettings.get(INDEX_VERSION_MAP_SIZE, DEFAULT_VERSION_MAP_SIZE);
         updateVersionMapSize();
@@ -161,7 +170,7 @@ public final class EngineConfig {
     private void updateVersionMapSize() {
         if (versionMapSizeSetting.endsWith("%")) {
             double percent = Double.parseDouble(versionMapSizeSetting.substring(0, versionMapSizeSetting.length() - 1));
-            versionMapSize = new ByteSizeValue((long) ((double) indexingBufferSize.bytes() * (percent / 100)));
+            versionMapSize = new ByteSizeValue((long) (((double) indexingBufferSize.bytes() * (percent / 100))));
         } else {
             versionMapSize = ByteSizeValue.parseBytesSizeValue(versionMapSizeSetting, INDEX_VERSION_MAP_SIZE);
         }
diff --git a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
index 45f7801..f4a77cf 100644
--- a/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
+++ b/core/src/main/java/org/elasticsearch/index/engine/InternalEngine.java
@@ -666,7 +666,6 @@ public class InternalEngine extends Engine {
         // since it flushes the index as well (though, in terms of concurrency, we are allowed to do it)
         try (ReleasableLock lock = readLock.acquire()) {
             ensureOpen();
-            updateIndexWriterSettings();
             searcherManager.maybeRefreshBlocking();
         } catch (AlreadyClosedException e) {
             ensureOpen();
@@ -736,7 +735,6 @@ public class InternalEngine extends Engine {
          */
         try (ReleasableLock lock = readLock.acquire()) {
             ensureOpen();
-            updateIndexWriterSettings();
             if (flushLock.tryLock() == false) {
                 // if we can't get the lock right away we block if needed otherwise barf
                 if (waitIfOngoing) {
@@ -954,7 +952,6 @@ public class InternalEngine extends Engine {
         }
     }
 
-
     /**
      * Closes the engine without acquiring the write lock. This should only be
      * called while the write lock is hold or in a disaster condition ie. if the engine
@@ -1168,8 +1165,6 @@ public class InternalEngine extends Engine {
         return indexWriter.getConfig();
     }
 
-
-
     private final class EngineMergeScheduler extends ElasticsearchConcurrentMergeScheduler {
         private final AtomicInteger numMergesInFlight = new AtomicInteger(0);
         private final AtomicBoolean isThrottling = new AtomicBoolean();
@@ -1245,11 +1240,14 @@ public class InternalEngine extends Engine {
 
     public void onSettingsChanged() {
         mergeScheduler.refreshConfig();
+        updateIndexWriterSettings();
+        // config().getVersionMapSize() may have changed:
+        checkVersionMapRefresh();
+        // config().isEnableGcDeletes() or config.getGcDeletesInMillis() may have changed:
+        maybePruneDeletedTombstones();
     }
 
     public MergeStats getMergeStats() {
         return mergeScheduler.stats();
     }
-
-
 }
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/plain/BinaryDVNumericIndexFieldData.java b/core/src/main/java/org/elasticsearch/index/fielddata/plain/BinaryDVNumericIndexFieldData.java
index c78da7c..86966617 100644
--- a/core/src/main/java/org/elasticsearch/index/fielddata/plain/BinaryDVNumericIndexFieldData.java
+++ b/core/src/main/java/org/elasticsearch/index/fielddata/plain/BinaryDVNumericIndexFieldData.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.index.fielddata.plain;
 
-import com.google.common.base.Preconditions;
-
 import org.apache.lucene.index.BinaryDocValues;
 import org.apache.lucene.index.DocValues;
 import org.apache.lucene.index.LeafReaderContext;
@@ -52,7 +50,9 @@ public class BinaryDVNumericIndexFieldData extends DocValuesIndexFieldData imple
 
     public BinaryDVNumericIndexFieldData(Index index, Names fieldNames, NumericType numericType, FieldDataType fieldDataType) {
         super(index, fieldNames, fieldDataType);
-        Preconditions.checkArgument(numericType != null, "numericType must be non-null");
+        if (numericType == null) {
+            throw new IllegalArgumentException("numericType must be non-null");
+        }
         this.numericType = numericType;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/plain/PackedArrayIndexFieldData.java b/core/src/main/java/org/elasticsearch/index/fielddata/plain/PackedArrayIndexFieldData.java
index 8996209..1b54e38 100644
--- a/core/src/main/java/org/elasticsearch/index/fielddata/plain/PackedArrayIndexFieldData.java
+++ b/core/src/main/java/org/elasticsearch/index/fielddata/plain/PackedArrayIndexFieldData.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.index.fielddata.plain;
 
-import com.google.common.base.Preconditions;
 import org.apache.lucene.index.*;
 import org.apache.lucene.util.*;
 import org.apache.lucene.util.BitSet;
@@ -73,7 +72,9 @@ public class PackedArrayIndexFieldData extends AbstractIndexFieldData<AtomicNume
                                      CircuitBreakerService breakerService) {
         super(index, indexSettings, fieldNames, fieldDataType, cache);
         Objects.requireNonNull(numericType);
-        Preconditions.checkArgument(EnumSet.of(NumericType.BOOLEAN, NumericType.BYTE, NumericType.SHORT, NumericType.INT, NumericType.LONG).contains(numericType), getClass().getSimpleName() + " only supports integer types, not " + numericType);
+        if (!EnumSet.of(NumericType.BOOLEAN, NumericType.BYTE, NumericType.SHORT, NumericType.INT, NumericType.LONG).contains(numericType)) {
+            throw new IllegalArgumentException(getClass().getSimpleName() + " only supports integer types, not " + numericType);
+        }
         this.numericType = numericType;
         this.breakerService = breakerService;
     }
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/plain/SortedNumericDVIndexFieldData.java b/core/src/main/java/org/elasticsearch/index/fielddata/plain/SortedNumericDVIndexFieldData.java
index 52686af..354ad43 100644
--- a/core/src/main/java/org/elasticsearch/index/fielddata/plain/SortedNumericDVIndexFieldData.java
+++ b/core/src/main/java/org/elasticsearch/index/fielddata/plain/SortedNumericDVIndexFieldData.java
@@ -19,24 +19,12 @@
 
 package org.elasticsearch.index.fielddata.plain;
 
-import com.google.common.base.Preconditions;
-
-import org.apache.lucene.index.DocValues;
-import org.apache.lucene.index.FieldInfo;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.NumericDocValues;
-import org.apache.lucene.index.SortedNumericDocValues;
+import org.apache.lucene.index.*;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.NumericUtils;
 import org.elasticsearch.index.Index;
-import org.elasticsearch.index.fielddata.AtomicNumericFieldData;
-import org.elasticsearch.index.fielddata.FieldData;
-import org.elasticsearch.index.fielddata.FieldDataType;
+import org.elasticsearch.index.fielddata.*;
 import org.elasticsearch.index.fielddata.IndexFieldData.XFieldComparatorSource.Nested;
-import org.elasticsearch.index.fielddata.IndexNumericFieldData;
-import org.elasticsearch.index.fielddata.NumericDoubleValues;
-import org.elasticsearch.index.fielddata.SortedNumericDoubleValues;
 import org.elasticsearch.index.fielddata.fieldcomparator.DoubleValuesComparatorSource;
 import org.elasticsearch.index.fielddata.fieldcomparator.FloatValuesComparatorSource;
 import org.elasticsearch.index.fielddata.fieldcomparator.LongValuesComparatorSource;
@@ -56,7 +44,9 @@ public class SortedNumericDVIndexFieldData extends DocValuesIndexFieldData imple
     
     public SortedNumericDVIndexFieldData(Index index, Names fieldNames, NumericType numericType, FieldDataType fieldDataType) {
         super(index, fieldNames, fieldDataType);
-        Preconditions.checkArgument(numericType != null, "numericType must be non-null");
+        if (numericType == null) {
+            throw new IllegalArgumentException("numericType must be non-null");
+        }
         this.numericType = numericType;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/FieldNamesFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/FieldNamesFieldMapper.java
index ac2ef99..500f973 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/FieldNamesFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/FieldNamesFieldMapper.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.index.mapper.internal;
 
-import com.google.common.collect.UnmodifiableIterator;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexableField;
@@ -240,7 +239,7 @@ public class FieldNamesFieldMapper extends MetadataFieldMapper {
         return new Iterable<String>() {
             @Override
             public Iterator<String> iterator() {
-                return new UnmodifiableIterator<String>() {
+                return new Iterator<String>() {
 
                     int endIndex = nextEndIndex(0);
 
@@ -263,6 +262,11 @@ public class FieldNamesFieldMapper extends MetadataFieldMapper {
                         return result;
                     }
 
+                    @Override
+                    public final void remove() {
+                        throw new UnsupportedOperationException();
+                    }
+
                 };
             }
         };
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
index 96810ec..c21e07c 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/internal/IdFieldMapper.java
@@ -19,18 +19,12 @@
 
 package org.elasticsearch.index.mapper.internal;
 
-import com.google.common.collect.Iterables;
 import org.apache.lucene.document.BinaryDocValuesField;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.TermsQuery;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.RegexpQuery;
+import org.apache.lucene.search.*;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.Nullable;
@@ -38,17 +32,11 @@ import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.lucene.BytesRefs;
 import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.fielddata.FieldDataType;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.Mapper;
-import org.elasticsearch.index.mapper.MapperParsingException;
-import org.elasticsearch.index.mapper.MergeMappingException;
-import org.elasticsearch.index.mapper.MergeResult;
-import org.elasticsearch.index.mapper.MetadataFieldMapper;
-import org.elasticsearch.index.mapper.ParseContext;
-import org.elasticsearch.index.mapper.Uid;
+import org.elasticsearch.index.mapper.*;
 import org.elasticsearch.index.query.QueryParseContext;
 
 import java.io.IOException;
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/object/ObjectMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/object/ObjectMapper.java
index 3ff0611..24be42c 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/object/ObjectMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/object/ObjectMapper.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.index.mapper.object;
 
-import com.google.common.collect.Iterables;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.QueryWrapperFilter;
@@ -33,30 +32,13 @@ import org.elasticsearch.common.collect.CopyOnWriteHashMap;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.mapper.ContentPath;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.DocumentMapperParser;
-import org.elasticsearch.index.mapper.FieldMapper;
-import org.elasticsearch.index.mapper.Mapper;
-import org.elasticsearch.index.mapper.MapperParsingException;
-import org.elasticsearch.index.mapper.MapperUtils;
-import org.elasticsearch.index.mapper.MergeMappingException;
-import org.elasticsearch.index.mapper.MergeResult;
-import org.elasticsearch.index.mapper.MetadataFieldMapper;
+import org.elasticsearch.index.mapper.*;
 import org.elasticsearch.index.mapper.internal.AllFieldMapper;
 import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
 import org.elasticsearch.index.settings.IndexSettings;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
+import java.util.*;
 
 import static org.elasticsearch.common.xcontent.support.XContentMapValues.nodeBooleanValue;
 import static org.elasticsearch.index.mapper.MapperBuilders.object;
@@ -583,7 +565,7 @@ public class ObjectMapper extends Mapper implements AllFieldMapper.IncludeInAll,
         doXContent(builder, params);
 
         // sort the mappers so we get consistent serialization format
-        Mapper[] sortedMappers = Iterables.toArray(mappers.values(), Mapper.class);
+        Mapper[] sortedMappers = mappers.values().stream().toArray(size -> new Mapper[size]);
         Arrays.sort(sortedMappers, new Comparator<Mapper>() {
             @Override
             public int compare(Mapper o1, Mapper o2) {
diff --git a/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java b/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
index dcbb19f..62c2224 100644
--- a/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/IdsQueryParser.java
@@ -19,13 +19,12 @@
 
 package org.elasticsearch.index.query;
 
-import com.google.common.collect.Iterables;
-
 import org.apache.lucene.queries.TermsQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.Queries;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.mapper.Uid;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
diff --git a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
index 124336c..6d8f729 100644
--- a/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
+++ b/core/src/main/java/org/elasticsearch/index/query/functionscore/random/RandomScoreFunctionParser.java
@@ -20,14 +20,12 @@
 
 package org.elasticsearch.index.query.functionscore.random;
 
-import com.google.common.primitives.Longs;
 
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.search.function.RandomScoreFunction;
 import org.elasticsearch.common.lucene.search.function.ScoreFunction;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.fielddata.IndexFieldData;
-import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.query.QueryParseContext;
 import org.elasticsearch.index.query.QueryParsingException;
@@ -66,7 +64,7 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
                         if (parser.numberType() == XContentParser.NumberType.INT) {
                             seed = parser.intValue();
                         } else if (parser.numberType() == XContentParser.NumberType.LONG) {
-                            seed = Longs.hashCode(parser.longValue());
+                            seed = hash(parser.longValue());
                         } else {
                             throw new QueryParsingException(parseContext, "random_score seed must be an int, long or string, not '"
                                     + token.toString() + "'");
@@ -90,7 +88,7 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
         }
 
         if (seed == -1) {
-            seed = Longs.hashCode(parseContext.nowInMillis());
+            seed = hash(parseContext.nowInMillis());
         }
         final ShardId shardId = SearchContext.current().indexShard().shardId();
         final int salt = (shardId.index().name().hashCode() << 10) | shardId.id();
@@ -98,4 +96,8 @@ public class RandomScoreFunctionParser implements ScoreFunctionParser {
 
         return new RandomScoreFunction(seed, salt, uidFieldData);
     }
+
+    private static final int hash(long value) {
+        return (int) (value ^ (value >>> 32));
+    }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
index 706bf37..abf9839 100644
--- a/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
+++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShard.java
@@ -115,9 +115,6 @@ import java.util.concurrent.ScheduledFuture;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicReference;
 
-/**
- *
- */
 public class IndexShard extends AbstractIndexShardComponent {
 
     private final ThreadPool threadPool;
@@ -985,15 +982,27 @@ public class IndexShard extends AbstractIndexShardComponent {
     }
 
     public void updateBufferSize(ByteSizeValue shardIndexingBufferSize, ByteSizeValue shardTranslogBufferSize) {
+
         final EngineConfig config = engineConfig;
         final ByteSizeValue preValue = config.getIndexingBufferSize();
+
         config.setIndexingBufferSize(shardIndexingBufferSize);
+
+        Engine engine = engineUnsafe();
+        if (engine == null) {
+            logger.debug("updateBufferSize: engine is closed; skipping");
+            return;
+        }
+
         // update engine if it is already started.
-        if (preValue.bytes() != shardIndexingBufferSize.bytes() && engineUnsafe() != null) {
-            // its inactive, make sure we do a refresh / full IW flush in this case, since the memory
-            // changes only after a "data" change has happened to the writer
-            // the index writer lazily allocates memory and a refresh will clean it all up.
-            if (shardIndexingBufferSize == EngineConfig.INACTIVE_SHARD_INDEXING_BUFFER && preValue != EngineConfig.INACTIVE_SHARD_INDEXING_BUFFER) {
+        if (preValue.bytes() != shardIndexingBufferSize.bytes()) {
+            // so we push changes these changes down to IndexWriter:
+            engine.onSettingsChanged();
+
+            if (shardIndexingBufferSize == EngineConfig.INACTIVE_SHARD_INDEXING_BUFFER) {
+                // it's inactive: make sure we do a refresh / full IW flush in this case, since the memory
+                // changes only after a "data" change has happened to the writer
+                // the index writer lazily allocates memory and a refresh will clean it all up.
                 logger.debug("updating index_buffer_size from [{}] to (inactive) [{}]", preValue, shardIndexingBufferSize);
                 try {
                     refresh("update index buffer");
@@ -1004,10 +1013,8 @@ public class IndexShard extends AbstractIndexShardComponent {
                 logger.debug("updating index_buffer_size from [{}] to [{}]", preValue, shardIndexingBufferSize);
             }
         }
-        Engine engine = engineUnsafe();
-        if (engine != null) {
-            engine.getTranslog().updateBuffer(shardTranslogBufferSize);
-        }
+
+        engine.getTranslog().updateBuffer(shardTranslogBufferSize);
     }
 
     public void markAsInactive() {
@@ -1129,7 +1136,7 @@ public class IndexShard extends AbstractIndexShardComponent {
             searchService.onRefreshSettings(settings);
             indexingService.onRefreshSettings(settings);
             if (change) {
-                refresh("apply settings");
+                engine().onSettingsChanged();
             }
         }
     }
@@ -1267,6 +1274,8 @@ public class IndexShard extends AbstractIndexShardComponent {
         return engine;
     }
 
+    /** NOTE: returns null if engine is not yet started (e.g. recovery phase 1, copying over index files, is still running), or if engine is
+     *  closed. */
     protected Engine engineUnsafe() {
         return this.currentEngineReference.get();
     }
diff --git a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
index ed42e2f..947a36a 100644
--- a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
+++ b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.index.snapshots.blobstore;
 
-import com.google.common.collect.Iterables;
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.IndexFormatTooNewException;
 import org.apache.lucene.index.IndexFormatTooOldException;
@@ -48,14 +47,11 @@ import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.lucene.store.InputStreamIndexInput;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.ByteSizeValue;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.snapshots.IndexShardRepository;
-import org.elasticsearch.index.snapshots.IndexShardRestoreFailedException;
-import org.elasticsearch.index.snapshots.IndexShardSnapshotException;
-import org.elasticsearch.index.snapshots.IndexShardSnapshotFailedException;
-import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;
+import org.elasticsearch.index.snapshots.*;
 import org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardSnapshot.FileInfo;
 import org.elasticsearch.index.store.Store;
 import org.elasticsearch.index.store.StoreFileMetaData;
@@ -71,11 +67,7 @@ import org.elasticsearch.repositories.blobstore.LegacyBlobStoreFormat;
 import java.io.FilterInputStream;
 import java.io.IOException;
 import java.io.InputStream;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 
 import static org.elasticsearch.repositories.blobstore.BlobStoreRepository.testBlobPrefix;
 
diff --git a/core/src/main/java/org/elasticsearch/index/store/Store.java b/core/src/main/java/org/elasticsearch/index/store/Store.java
index 39a0f53..147cf77 100644
--- a/core/src/main/java/org/elasticsearch/index/store/Store.java
+++ b/core/src/main/java/org/elasticsearch/index/store/Store.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.index.store;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Iterables;
 import org.apache.lucene.codecs.CodecUtil;
 import org.apache.lucene.index.*;
 import org.apache.lucene.store.*;
@@ -42,6 +41,7 @@ import org.elasticsearch.common.lucene.store.InputStreamIndexInput;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.Callback;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.common.util.SingleObjectCache;
 import org.elasticsearch.common.util.concurrent.AbstractRefCounted;
 import org.elasticsearch.common.util.concurrent.RefCounted;
diff --git a/core/src/main/java/org/elasticsearch/indices/flush/IndicesSyncedFlushResult.java b/core/src/main/java/org/elasticsearch/indices/flush/IndicesSyncedFlushResult.java
index f625f04..54ec76e 100644
--- a/core/src/main/java/org/elasticsearch/indices/flush/IndicesSyncedFlushResult.java
+++ b/core/src/main/java/org/elasticsearch/indices/flush/IndicesSyncedFlushResult.java
@@ -19,8 +19,8 @@
 package org.elasticsearch.indices.flush;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.Iterables;
 import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentBuilderString;
@@ -41,7 +41,7 @@ public class IndicesSyncedFlushResult implements ToXContent {
 
     public IndicesSyncedFlushResult(Map<String, List<ShardsSyncedFlushResult>> shardsResultPerIndex) {
         this.shardsResultPerIndex = ImmutableMap.copyOf(shardsResultPerIndex);
-        this.shardCounts = calculateShardCounts(Iterables.concat(shardsResultPerIndex.values()));
+        this.shardCounts = calculateShardCounts(Iterables.flatten(shardsResultPerIndex.values()));
     }
 
     /** total number shards, including replicas, both assigned and unassigned */
diff --git a/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java b/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java
index 67d3e8e..2bf6946 100644
--- a/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java
+++ b/core/src/main/java/org/elasticsearch/indices/memory/IndexingMemoryController.java
@@ -51,6 +51,42 @@ import java.util.concurrent.ScheduledFuture;
  */
 public class IndexingMemoryController extends AbstractLifecycleComponent<IndexingMemoryController> {
 
+    /** How much heap (% or bytes) we will share across all actively indexing shards on this node (default: 10%). */
+    public static final String INDEX_BUFFER_SIZE_SETTING = "indices.memory.index_buffer_size";
+    
+    /** Only applies when <code>indices.memory.index_buffer_size</code> is a %, to set a floor on the actual size in bytes (default: 48 MB). */
+    public static final String MIN_INDEX_BUFFER_SIZE_SETTING = "indices.memory.min_index_buffer_size";
+
+    /** Only applies when <code>indices.memory.index_buffer_size</code> is a %, to set a ceiling on the actual size in bytes (default: not set). */
+    public static final String MAX_INDEX_BUFFER_SIZE_SETTING = "indices.memory.max_index_buffer_size";
+
+    /** Sets a floor on the per-shard index buffer size (default: 4 MB). */
+    public static final String MIN_SHARD_INDEX_BUFFER_SIZE_SETTING = "indices.memory.min_shard_index_buffer_size";
+
+    /** Sets a ceiling on the per-shard index buffer size (default: 512 MB). */
+    public static final String MAX_SHARD_INDEX_BUFFER_SIZE_SETTING = "indices.memory.max_shard_index_buffer_size";
+
+    /** How much heap (% or bytes) we will share across all actively indexing shards for the translog buffer (default: 1%). */
+    public static final String TRANSLOG_BUFFER_SIZE_SETTING = "indices.memory.translog_buffer_size";
+
+    /** Only applies when <code>indices.memory.translog_buffer_size</code> is a %, to set a floor on the actual size in bytes (default: 256 KB). */
+    public static final String MIN_TRANSLOG_BUFFER_SIZE_SETTING = "indices.memory.min_translog_buffer_size";
+
+    /** Only applies when <code>indices.memory.translog_buffer_size</code> is a %, to set a ceiling on the actual size in bytes (default: not set). */
+    public static final String MAX_TRANSLOG_BUFFER_SIZE_SETTING = "indices.memory.max_translog_buffer_size";
+
+    /** Sets a floor on the per-shard translog buffer size (default: 2 KB). */
+    public static final String MIN_SHARD_TRANSLOG_BUFFER_SIZE_SETTING = "indices.memory.min_shard_translog_buffer_size";
+
+    /** Sets a ceiling on the per-shard translog buffer size (default: 64 KB). */
+    public static final String MAX_SHARD_TRANSLOG_BUFFER_SIZE_SETTING = "indices.memory.max_shard_translog_buffer_size";
+
+    /** If we see no indexing operations after this much time for a given shard, we consider that shard inactive (default: 5 minutes). */
+    public static final String SHARD_INACTIVE_TIME_SETTING = "indices.memory.shard_inactive_time";
+
+    /** How frequently we check shards to find inactive ones (default: 30 seconds). */
+    public static final String SHARD_INACTIVE_INTERVAL_TIME_SETTING = "indices.memory.interval";
+
     private final ThreadPool threadPool;
     private final IndicesService indicesService;
 
@@ -77,12 +113,12 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
         this.indicesService = indicesService;
 
         ByteSizeValue indexingBuffer;
-        String indexingBufferSetting = this.settings.get("indices.memory.index_buffer_size", "10%");
+        String indexingBufferSetting = this.settings.get(INDEX_BUFFER_SIZE_SETTING, "10%");
         if (indexingBufferSetting.endsWith("%")) {
             double percent = Double.parseDouble(indexingBufferSetting.substring(0, indexingBufferSetting.length() - 1));
             indexingBuffer = new ByteSizeValue((long) (((double) JvmInfo.jvmInfo().getMem().getHeapMax().bytes()) * (percent / 100)));
-            ByteSizeValue minIndexingBuffer = this.settings.getAsBytesSize("indices.memory.min_index_buffer_size", new ByteSizeValue(48, ByteSizeUnit.MB));
-            ByteSizeValue maxIndexingBuffer = this.settings.getAsBytesSize("indices.memory.max_index_buffer_size", null);
+            ByteSizeValue minIndexingBuffer = this.settings.getAsBytesSize(MIN_INDEX_BUFFER_SIZE_SETTING, new ByteSizeValue(48, ByteSizeUnit.MB));
+            ByteSizeValue maxIndexingBuffer = this.settings.getAsBytesSize(MAX_INDEX_BUFFER_SIZE_SETTING, null);
 
             if (indexingBuffer.bytes() < minIndexingBuffer.bytes()) {
                 indexingBuffer = minIndexingBuffer;
@@ -91,20 +127,20 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
                 indexingBuffer = maxIndexingBuffer;
             }
         } else {
-            indexingBuffer = ByteSizeValue.parseBytesSizeValue(indexingBufferSetting, null);
+            indexingBuffer = ByteSizeValue.parseBytesSizeValue(indexingBufferSetting, INDEX_BUFFER_SIZE_SETTING);
         }
         this.indexingBuffer = indexingBuffer;
-        this.minShardIndexBufferSize = this.settings.getAsBytesSize("indices.memory.min_shard_index_buffer_size", new ByteSizeValue(4, ByteSizeUnit.MB));
+        this.minShardIndexBufferSize = this.settings.getAsBytesSize(MIN_SHARD_INDEX_BUFFER_SIZE_SETTING, new ByteSizeValue(4, ByteSizeUnit.MB));
         // LUCENE MONITOR: Based on this thread, currently (based on Mike), having a large buffer does not make a lot of sense: https://issues.apache.org/jira/browse/LUCENE-2324?focusedCommentId=13005155&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13005155
-        this.maxShardIndexBufferSize = this.settings.getAsBytesSize("indices.memory.max_shard_index_buffer_size", new ByteSizeValue(512, ByteSizeUnit.MB));
+        this.maxShardIndexBufferSize = this.settings.getAsBytesSize(MAX_SHARD_INDEX_BUFFER_SIZE_SETTING, new ByteSizeValue(512, ByteSizeUnit.MB));
 
         ByteSizeValue translogBuffer;
-        String translogBufferSetting = this.settings.get("indices.memory.translog_buffer_size", "1%");
+        String translogBufferSetting = this.settings.get(TRANSLOG_BUFFER_SIZE_SETTING, "1%");
         if (translogBufferSetting.endsWith("%")) {
             double percent = Double.parseDouble(translogBufferSetting.substring(0, translogBufferSetting.length() - 1));
             translogBuffer = new ByteSizeValue((long) (((double) JvmInfo.jvmInfo().getMem().getHeapMax().bytes()) * (percent / 100)));
-            ByteSizeValue minTranslogBuffer = this.settings.getAsBytesSize("indices.memory.min_translog_buffer_size", new ByteSizeValue(256, ByteSizeUnit.KB));
-            ByteSizeValue maxTranslogBuffer = this.settings.getAsBytesSize("indices.memory.max_translog_buffer_size", null);
+            ByteSizeValue minTranslogBuffer = this.settings.getAsBytesSize(MIN_TRANSLOG_BUFFER_SIZE_SETTING, new ByteSizeValue(256, ByteSizeUnit.KB));
+            ByteSizeValue maxTranslogBuffer = this.settings.getAsBytesSize(MAX_TRANSLOG_BUFFER_SIZE_SETTING, null);
 
             if (translogBuffer.bytes() < minTranslogBuffer.bytes()) {
                 translogBuffer = minTranslogBuffer;
@@ -116,15 +152,19 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
             translogBuffer = ByteSizeValue.parseBytesSizeValue(translogBufferSetting, null);
         }
         this.translogBuffer = translogBuffer;
-        this.minShardTranslogBufferSize = this.settings.getAsBytesSize("indices.memory.min_shard_translog_buffer_size", new ByteSizeValue(2, ByteSizeUnit.KB));
-        this.maxShardTranslogBufferSize = this.settings.getAsBytesSize("indices.memory.max_shard_translog_buffer_size", new ByteSizeValue(64, ByteSizeUnit.KB));
+        this.minShardTranslogBufferSize = this.settings.getAsBytesSize(MIN_SHARD_TRANSLOG_BUFFER_SIZE_SETTING, new ByteSizeValue(2, ByteSizeUnit.KB));
+        this.maxShardTranslogBufferSize = this.settings.getAsBytesSize(MAX_SHARD_TRANSLOG_BUFFER_SIZE_SETTING, new ByteSizeValue(64, ByteSizeUnit.KB));
 
-        this.inactiveTime = this.settings.getAsTime("indices.memory.shard_inactive_time", TimeValue.timeValueMinutes(5));
+        this.inactiveTime = this.settings.getAsTime(SHARD_INACTIVE_TIME_SETTING, TimeValue.timeValueMinutes(5));
         // we need to have this relatively small to move a shard from inactive to active fast (enough)
-        this.interval = this.settings.getAsTime("indices.memory.interval", TimeValue.timeValueSeconds(30));
-
-        logger.debug("using index_buffer_size [{}], with min_shard_index_buffer_size [{}], max_shard_index_buffer_size [{}], shard_inactive_time [{}]", this.indexingBuffer, this.minShardIndexBufferSize, this.maxShardIndexBufferSize, this.inactiveTime);
-
+        this.interval = this.settings.getAsTime(SHARD_INACTIVE_INTERVAL_TIME_SETTING, TimeValue.timeValueSeconds(30));
+
+        logger.debug("using indexing buffer size [{}], with {} [{}], {} [{}], {} [{}], {} [{}]",
+                     this.indexingBuffer,
+                     MIN_SHARD_INDEX_BUFFER_SIZE_SETTING, this.minShardIndexBufferSize,
+                     MAX_SHARD_INDEX_BUFFER_SIZE_SETTING, this.maxShardIndexBufferSize,
+                     SHARD_INACTIVE_TIME_SETTING, this.inactiveTime,
+                     SHARD_INACTIVE_INTERVAL_TIME_SETTING, this.interval);
     }
 
     @Override
@@ -155,12 +195,9 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
 
         private final Map<ShardId, ShardIndexingStatus> shardsIndicesStatus = new HashMap<>();
 
-
         @Override
         public void run() {
-            EnumSet<ShardStatusChangeType> changes = EnumSet.noneOf(ShardStatusChangeType.class);
-
-            changes.addAll(purgeDeletedAndClosedShards());
+            EnumSet<ShardStatusChangeType> changes = purgeDeletedAndClosedShards();
 
             final List<IndexShard> activeToInactiveIndexingShards = new ArrayList<>();
             final int activeShards = updateShardStatuses(changes, activeToInactiveIndexingShards);
@@ -170,11 +207,15 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
                     indexShard.markAsInactive();
                 } catch (EngineClosedException e) {
                     // ignore
+                    logger.trace("ignore EngineClosedException while marking shard [{}][{}] as inactive", indexShard.shardId().index().name(), indexShard.shardId().id());
                 } catch (FlushNotAllowedEngineException e) {
                     // ignore
+                    logger.trace("ignore FlushNotAllowedException while marking shard [{}][{}] as inactive", indexShard.shardId().index().name(), indexShard.shardId().id());
                 }
             }
-            if (!changes.isEmpty()) {
+
+            if (changes.isEmpty() == false) {
+                // Something changed: recompute indexing buffers:
                 calcAndSetShardBuffers(activeShards, "[" + changes + "]");
             }
         }
@@ -190,23 +231,24 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
                 for (IndexShard indexShard : indexService) {
 
                     if (!CAN_UPDATE_INDEX_BUFFER_STATES.contains(indexShard.state())) {
-                        // not ready to be updated yet.
+                        // not ready to be updated yet
                         continue;
                     }
 
                     if (indexShard.canIndex() == false) {
-                        // not relevant for memory related issues.
+                        // shadow replica doesn't have an indexing buffer
                         continue;
                     }
+
                     final Translog translog;
                     try {
                         translog = indexShard.engine().getTranslog();
                     } catch (EngineClosedException e) {
-                        // not ready yet to be checked for in activity
+                        // not ready yet to be checked for activity
                         continue;
                     }
 
-                    final long time = threadPool.estimatedTimeInMillis();
+                    final long timeMS = threadPool.estimatedTimeInMillis();
 
                     ShardIndexingStatus status = shardsIndicesStatus.get(indexShard.shardId());
                     if (status == null) {
@@ -214,21 +256,22 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
                         shardsIndicesStatus.put(indexShard.shardId(), status);
                         changes.add(ShardStatusChangeType.ADDED);
                     }
-                    // check if it is deemed to be inactive (sam translogFileGeneration and numberOfOperations over a long period of time)
+
+                    // consider shard inactive if it has same translogFileGeneration and no operations for a long time
                     if (status.translogId == translog.currentFileGeneration() && translog.totalOperations() == 0) {
-                        if (status.time == -1) { // first time
-                            status.time = time;
+                        if (status.timeMS == -1) {
+                            // first time we noticed the shard become idle
+                            status.timeMS = timeMS;
                         }
-                        // inactive?
-                        if (status.activeIndexing) {
-                            // mark it as inactive only if enough time has passed and there are no ongoing merges going on...
-                            if ((time - status.time) > inactiveTime.millis() && indexShard.mergeStats().getCurrent() == 0) {
-                                // inactive for this amount of time, mark it
-                                activeToInactiveIndexingShards.add(indexShard);
-                                status.activeIndexing = false;
-                                changes.add(ShardStatusChangeType.BECAME_INACTIVE);
-                                logger.debug("marking shard [{}][{}] as inactive (inactive_time[{}]) indexing wise, setting size to [{}]", indexShard.shardId().index().name(), indexShard.shardId().id(), inactiveTime, EngineConfig.INACTIVE_SHARD_INDEXING_BUFFER);
-                            }
+                        // mark it as inactive only if enough time has passed
+                        if (status.activeIndexing && (timeMS - status.timeMS) > inactiveTime.millis()) {
+                            // inactive for this amount of time, mark it
+                            activeToInactiveIndexingShards.add(indexShard);
+                            status.activeIndexing = false;
+                            changes.add(ShardStatusChangeType.BECAME_INACTIVE);
+                            logger.debug("marking shard [{}][{}] as inactive (inactive_time[{}]) indexing wise, setting size to [{}]",
+                                         indexShard.shardId().index().name(), indexShard.shardId().id(),
+                                         inactiveTime, EngineConfig.INACTIVE_SHARD_INDEXING_BUFFER);
                         }
                     } else {
                         if (!status.activeIndexing) {
@@ -236,10 +279,9 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
                             changes.add(ShardStatusChangeType.BECAME_ACTIVE);
                             logger.debug("marking shard [{}][{}] as active indexing wise", indexShard.shardId().index().name(), indexShard.shardId().id());
                         }
-                        status.time = -1;
+                        status.timeMS = -1;
                     }
                     status.translogId = translog.currentFileGeneration();
-                    status.translogNumberOfOperations = translog.totalOperations();
 
                     if (status.activeIndexing) {
                         activeShards++;
@@ -261,31 +303,28 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
             while (statusShardIdIterator.hasNext()) {
                 ShardId statusShardId = statusShardIdIterator.next();
                 IndexService indexService = indicesService.indexService(statusShardId.getIndex());
-                boolean remove = false;
-                try {
-                    if (indexService == null) {
-                        remove = true;
-                        continue;
-                    }
+                boolean remove;
+                if (indexService == null) {
+                    remove = true;
+                } else {
                     IndexShard indexShard = indexService.shard(statusShardId.id());
                     if (indexShard == null) {
                         remove = true;
-                        continue;
-                    }
-                    remove = !CAN_UPDATE_INDEX_BUFFER_STATES.contains(indexShard.state());
-
-                } finally {
-                    if (remove) {
-                        changes.add(ShardStatusChangeType.DELETED);
-                        statusShardIdIterator.remove();
+                    } else {
+                        remove = !CAN_UPDATE_INDEX_BUFFER_STATES.contains(indexShard.state());
                     }
                 }
+                if (remove) {
+                    changes.add(ShardStatusChangeType.DELETED);
+                    statusShardIdIterator.remove();
+                }
             }
             return changes;
         }
 
         private void calcAndSetShardBuffers(int activeShards, String reason) {
             if (activeShards == 0) {
+                logger.debug("no active shards (reason={})", reason);
                 return;
             }
             ByteSizeValue shardIndexingBufferSize = new ByteSizeValue(indexingBuffer.bytes() / activeShards);
@@ -335,11 +374,9 @@ public class IndexingMemoryController extends AbstractLifecycleComponent<Indexin
         ADDED, DELETED, BECAME_ACTIVE, BECAME_INACTIVE
     }
 
-
-    static class ShardIndexingStatus {
+    private static class ShardIndexingStatus {
         long translogId = -1;
-        int translogNumberOfOperations = -1;
         boolean activeIndexing = true;
-        long time = -1; // contains the first time we saw this shard with no operations done on it
+        long timeMS = -1; // contains the first time we saw this shard with no operations done on it
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
index 8d913c6..b987b4a 100644
--- a/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
+++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.indices.recovery;
 
-import com.google.common.collect.Iterables;
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.IndexFormatTooNewException;
 import org.apache.lucene.index.IndexFormatTooOldException;
@@ -39,6 +38,7 @@ import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.util.CancellableThreads;
 import org.elasticsearch.common.util.CancellableThreads.Interruptable;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.common.util.concurrent.AbstractRunnable;
 import org.elasticsearch.index.deletionpolicy.SnapshotIndexCommit;
 import org.elasticsearch.index.engine.Engine;
@@ -64,6 +64,7 @@ import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.concurrent.atomic.AtomicReference;
+import java.util.stream.StreamSupport;
 
 /**
  * RecoverySourceHandler handles the three phases of shard recovery, which is
@@ -411,7 +412,8 @@ public class RecoverySourceHandler {
                             if ((corruptIndexException = ExceptionsHelper.unwrapCorruption(remoteException)) != null) {
                                 try {
                                     final Store.MetadataSnapshot recoverySourceMetadata = store.getMetadata(snapshot);
-                                    StoreFileMetaData[] metadata = Iterables.toArray(recoverySourceMetadata, StoreFileMetaData.class);
+                                    StoreFileMetaData[] metadata =
+                                            StreamSupport.stream(recoverySourceMetadata.spliterator(), false).toArray(size -> new StoreFileMetaData[size]);
                                     ArrayUtil.timSort(metadata, new Comparator<StoreFileMetaData>() {
                                         @Override
                                         public int compare(StoreFileMetaData o1, StoreFileMetaData o2) {
diff --git a/core/src/main/java/org/elasticsearch/repositories/RepositoriesService.java b/core/src/main/java/org/elasticsearch/repositories/RepositoriesService.java
index 0a129bd..b11f91f 100644
--- a/core/src/main/java/org/elasticsearch/repositories/RepositoriesService.java
+++ b/core/src/main/java/org/elasticsearch/repositories/RepositoriesService.java
@@ -19,14 +19,9 @@
 
 package org.elasticsearch.repositories;
 
-import com.google.common.base.Joiner;
 import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.action.ActionListener;
-import org.elasticsearch.cluster.AckedClusterStateUpdateTask;
-import org.elasticsearch.cluster.ClusterChangedEvent;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.ClusterStateListener;
+import org.elasticsearch.cluster.*;
 import org.elasticsearch.cluster.ack.ClusterStateUpdateRequest;
 import org.elasticsearch.cluster.ack.ClusterStateUpdateResponse;
 import org.elasticsearch.cluster.metadata.MetaData;
@@ -45,10 +40,8 @@ import org.elasticsearch.snapshots.SnapshotsService;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
+import java.util.stream.Collectors;
 
 import static org.elasticsearch.common.settings.Settings.Builder.EMPTY_SETTINGS;
 
@@ -571,9 +564,10 @@ public class RepositoriesService extends AbstractComponent implements ClusterSta
         }
 
         public String failureDescription() {
-            StringBuilder builder = new StringBuilder('[');
-            Joiner.on(", ").appendTo(builder, failures);
-            return builder.append(']').toString();
+            return Arrays
+                    .stream(failures)
+                    .map(failure -> failure.toString())
+                    .collect(Collectors.joining(", ", "[", "]"));
         }
 
     }
diff --git a/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java b/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
index 4b2c608..4564578 100644
--- a/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
+++ b/core/src/main/java/org/elasticsearch/repositories/blobstore/BlobStoreRepository.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.repositories.blobstore;
 
-import com.google.common.io.ByteStreams;
 import org.apache.lucene.store.RateLimiter;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.Version;
@@ -36,6 +35,7 @@ import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.compress.NotXContentException;
+import org.elasticsearch.common.io.Streams;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.io.stream.OutputStreamStreamOutput;
 import org.elasticsearch.common.io.stream.StreamOutput;
@@ -66,6 +66,7 @@ import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.OutputStream;
+import java.nio.file.Files;
 import java.nio.file.NoSuchFileException;
 import java.util.ArrayList;
 import java.util.Collections;
@@ -590,9 +591,10 @@ public abstract class BlobStoreRepository extends AbstractLifecycleComponent<Rep
      */
     protected List<SnapshotId> readSnapshotList() throws IOException {
         try (InputStream blob = snapshotsBlobContainer.readBlob(SNAPSHOTS_FILE)) {
-            final byte[] data = ByteStreams.toByteArray(blob);
+            BytesStreamOutput out = new BytesStreamOutput();
+            Streams.copy(blob, out);
             ArrayList<SnapshotId> snapshots = new ArrayList<>();
-            try (XContentParser parser = XContentHelper.createParser(new BytesArray(data))) {
+            try (XContentParser parser = XContentHelper.createParser(out.bytes())) {
                 if (parser.nextToken() == XContentParser.Token.START_OBJECT) {
                     if (parser.nextToken() == XContentParser.Token.FIELD_NAME) {
                         String currentFieldName = parser.currentName();
diff --git a/core/src/main/java/org/elasticsearch/repositories/blobstore/ChecksumBlobStoreFormat.java b/core/src/main/java/org/elasticsearch/repositories/blobstore/ChecksumBlobStoreFormat.java
index 718e9da..9109dcd 100644
--- a/core/src/main/java/org/elasticsearch/repositories/blobstore/ChecksumBlobStoreFormat.java
+++ b/core/src/main/java/org/elasticsearch/repositories/blobstore/ChecksumBlobStoreFormat.java
@@ -18,7 +18,6 @@
  */
 package org.elasticsearch.repositories.blobstore;
 
-import com.google.common.io.ByteStreams;
 import org.apache.lucene.codecs.CodecUtil;
 import org.apache.lucene.index.CorruptIndexException;
 import org.apache.lucene.index.IndexFormatTooNewException;
@@ -29,6 +28,7 @@ import org.elasticsearch.common.blobstore.BlobContainer;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.compress.CompressorFactory;
+import org.elasticsearch.common.io.Streams;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.lucene.store.ByteArrayIndexInput;
@@ -93,7 +93,9 @@ public class ChecksumBlobStoreFormat<T extends ToXContent> extends BlobStoreForm
      */
     public T readBlob(BlobContainer blobContainer, String blobName) throws IOException {
         try (InputStream inputStream = blobContainer.readBlob(blobName)) {
-            byte[] bytes = ByteStreams.toByteArray(inputStream);
+            ByteArrayOutputStream out = new ByteArrayOutputStream();
+            Streams.copy(inputStream, out);
+            final byte[] bytes = out.toByteArray();
             final String resourceDesc = "ChecksumBlobStoreFormat.readBlob(blob=\"" + blobName + "\")";
             try (ByteArrayIndexInput indexInput = new ByteArrayIndexInput(resourceDesc, bytes)) {
                 CodecUtil.checksumEntireFile(indexInput);
diff --git a/core/src/main/java/org/elasticsearch/repositories/blobstore/LegacyBlobStoreFormat.java b/core/src/main/java/org/elasticsearch/repositories/blobstore/LegacyBlobStoreFormat.java
index f9d5c98..a0c956d 100644
--- a/core/src/main/java/org/elasticsearch/repositories/blobstore/LegacyBlobStoreFormat.java
+++ b/core/src/main/java/org/elasticsearch/repositories/blobstore/LegacyBlobStoreFormat.java
@@ -18,10 +18,10 @@
  */
 package org.elasticsearch.repositories.blobstore;
 
-import com.google.common.io.ByteStreams;
 import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.blobstore.BlobContainer;
-import org.elasticsearch.common.bytes.BytesArray;
+import org.elasticsearch.common.io.Streams;
+import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.xcontent.FromXContentBuilder;
 import org.elasticsearch.common.xcontent.ToXContent;
 
@@ -53,7 +53,9 @@ public class LegacyBlobStoreFormat<T extends ToXContent> extends BlobStoreFormat
      */
     public T readBlob(BlobContainer blobContainer, String blobName) throws IOException {
         try (InputStream inputStream = blobContainer.readBlob(blobName)) {
-            return read(new BytesArray(ByteStreams.toByteArray(inputStream)));
+            BytesStreamOutput out = new BytesStreamOutput();
+            Streams.copy(inputStream, out);
+            return read(out.bytes());
         }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/BucketCollector.java b/core/src/main/java/org/elasticsearch/search/aggregations/BucketCollector.java
index f862da6..ee38e2b 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/BucketCollector.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/BucketCollector.java
@@ -20,14 +20,13 @@
 package org.elasticsearch.search.aggregations;
 
 
-import com.google.common.collect.Iterables;
-
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.Collector;
 
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
+import java.util.stream.StreamSupport;
 
 /**
  * A Collector that can collect data in separate buckets.
@@ -58,7 +57,8 @@ public abstract class BucketCollector implements Collector {
      * Wrap the given collectors into a single instance.
      */
     public static BucketCollector wrap(Iterable<? extends BucketCollector> collectorList) {
-        final BucketCollector[] collectors = Iterables.toArray(collectorList, BucketCollector.class);
+        final BucketCollector[] collectors =
+                StreamSupport.stream(collectorList.spliterator(), false).toArray(size -> new BucketCollector[size]);
         switch (collectors.length) {
             case 0:
                 return NO_OP_COLLECTOR;
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/LeafBucketCollector.java b/core/src/main/java/org/elasticsearch/search/aggregations/LeafBucketCollector.java
index eb51ba2..f5b7f15 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/LeafBucketCollector.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/LeafBucketCollector.java
@@ -19,12 +19,11 @@
 
 package org.elasticsearch.search.aggregations;
 
-import com.google.common.collect.Iterables;
-
 import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.Scorer;
 
 import java.io.IOException;
+import java.util.stream.Stream;
 import java.util.stream.StreamSupport;
 
 /**
@@ -44,9 +43,9 @@ public abstract class LeafBucketCollector implements LeafCollector {
     };
 
     public static LeafBucketCollector wrap(Iterable<LeafBucketCollector> collectors) {
-        final Iterable<LeafBucketCollector> actualCollectors =
-                StreamSupport.stream(collectors.spliterator(), false).filter(c -> c != NO_OP_COLLECTOR)::iterator;
-        final LeafBucketCollector[] colls = Iterables.toArray(actualCollectors, LeafBucketCollector.class);
+        final Stream<LeafBucketCollector> actualCollectors =
+                StreamSupport.stream(collectors.spliterator(), false).filter(c -> c != NO_OP_COLLECTOR);
+        final LeafBucketCollector[] colls = actualCollectors.toArray(size -> new LeafBucketCollector[size]);
         switch (colls.length) {
         case 0:
             return NO_OP_COLLECTOR;
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/InternalTerms.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/InternalTerms.java
index 681d186..31285d2 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/InternalTerms.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/InternalTerms.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.search.aggregations.bucket.terms;
 
-import com.google.common.collect.ArrayListMultimap;
-import com.google.common.collect.Multimap;
 import org.elasticsearch.common.io.stream.Streamable;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.search.aggregations.AggregationExecutionException;
@@ -33,7 +31,6 @@ import org.elasticsearch.search.aggregations.support.format.ValueFormatter;
 
 import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.Collection;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
@@ -167,7 +164,7 @@ public abstract class InternalTerms<A extends InternalTerms, B extends InternalT
     @Override
     public InternalAggregation doReduce(List<InternalAggregation> aggregations, ReduceContext reduceContext) {
 
-        Multimap<Object, InternalTerms.Bucket> buckets = ArrayListMultimap.create();
+        Map<Object, List<InternalTerms.Bucket>> buckets = new HashMap<>();
         long sumDocCountError = 0;
         long otherDocCount = 0;
         InternalTerms<A, B> referenceTerms = null;
@@ -208,14 +205,18 @@ public abstract class InternalTerms<A extends InternalTerms, B extends InternalT
             terms.docCountError = thisAggDocCountError;
             for (Bucket bucket : terms.buckets) {
                 bucket.docCountError = thisAggDocCountError;
-                buckets.put(bucket.getKey(), bucket);
+                List<Bucket> bucketList = buckets.get(bucket.getKey());
+                if (bucketList == null) {
+                    bucketList = new ArrayList<>();
+                    buckets.put(bucket.getKey(), bucketList);
+                }
+                bucketList.add(bucket);
             }
         }
 
         final int size = Math.min(requiredSize, buckets.size());
         BucketPriorityQueue ordered = new BucketPriorityQueue(size, order.comparator(null));
-        for (Collection<Bucket> l : buckets.asMap().values()) {
-            List<Bucket> sameTermBuckets = (List<Bucket>) l; // cast is ok according to javadocs
+        for (List<Bucket> sameTermBuckets : buckets.values()) {
             final Bucket b = sameTermBuckets.get(0).reduce(sameTermBuckets, reduceContext);
             if (b.docCountError != -1) {
                 if (sumDocCountError == -1) {
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/CardinalityAggregator.java b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/CardinalityAggregator.java
index 0a3918d..93fe7ff 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/CardinalityAggregator.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/CardinalityAggregator.java
@@ -20,8 +20,6 @@
 package org.elasticsearch.search.aggregations.metrics.cardinality;
 
 import com.carrotsearch.hppc.BitMixer;
-import com.google.common.base.Preconditions;
-
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.RandomAccessOrds;
 import org.apache.lucene.index.SortedNumericDocValues;
@@ -234,7 +232,9 @@ public class CardinalityAggregator extends NumericMetricsAggregator.SingleValue
         private ObjectArray<FixedBitSet> visitedOrds;
 
         OrdinalsCollector(HyperLogLogPlusPlus counts, RandomAccessOrds values, BigArrays bigArrays) {
-            Preconditions.checkArgument(values.getValueCount() <= Integer.MAX_VALUE);
+            if (values.getValueCount() > Integer.MAX_VALUE) {
+                throw new IllegalArgumentException();
+            }
             maxOrd = (int) values.getValueCount();
             this.bigArrays = bigArrays;
             this.counts = counts;
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/HyperLogLogPlusPlus.java b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/HyperLogLogPlusPlus.java
index 6eb5153..6b38918 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/HyperLogLogPlusPlus.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/cardinality/HyperLogLogPlusPlus.java
@@ -19,12 +19,10 @@
 
 package org.elasticsearch.search.aggregations.metrics.cardinality;
 
-import com.google.common.base.Preconditions;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LongBitSet;
 import org.apache.lucene.util.RamUsageEstimator;
 import org.apache.lucene.util.packed.PackedInts;
-import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.lease.Releasable;
@@ -37,7 +35,6 @@ import org.elasticsearch.common.util.IntArray;
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.nio.ByteOrder;
-import java.util.Arrays;
 
 /**
  * Hyperloglog++ counter, implemented based on pseudo code from
@@ -162,8 +159,12 @@ public final class HyperLogLogPlusPlus implements Releasable {
     private final double alphaMM;
 
     public HyperLogLogPlusPlus(int precision, BigArrays bigArrays, long initialBucketCount) {
-        Preconditions.checkArgument(precision >= 4, "precision must be >= 4");
-        Preconditions.checkArgument(precision <= 18, "precision must be <= 18");
+        if (precision < 4) {
+            throw new IllegalArgumentException("precision must be >= 4");
+        }
+        if (precision > 18) {
+            throw new IllegalArgumentException("precision must be <= 18");
+        }
         p = precision;
         m = 1 << p;
         this.bigArrays = bigArrays;
@@ -198,7 +199,9 @@ public final class HyperLogLogPlusPlus implements Releasable {
     }
 
     public void merge(long thisBucket, HyperLogLogPlusPlus other, long otherBucket) {
-        Preconditions.checkArgument(p == other.p);
+        if (p != other.p) {
+            throw new IllegalArgumentException();
+        }
         ensureCapacity(thisBucket + 1);
         if (other.algorithm.get(otherBucket) == LINEAR_COUNTING) {
             final IntArray values = other.hashSet.values(otherBucket);
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/hdr/InternalHDRPercentileRanks.java b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/hdr/InternalHDRPercentileRanks.java
index 37acb53..baa2325 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/hdr/InternalHDRPercentileRanks.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/hdr/InternalHDRPercentileRanks.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.search.aggregations.metrics.percentiles.hdr;
 
-import com.google.common.collect.UnmodifiableIterator;
-
 import org.HdrHistogram.DoubleHistogram;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.search.aggregations.AggregationStreams;
@@ -106,7 +104,7 @@ public class InternalHDRPercentileRanks extends AbstractInternalHDRPercentiles i
         return percentileRank;
     }
 
-    public static class Iter extends UnmodifiableIterator<Percentile> {
+    public static class Iter implements Iterator<Percentile> {
 
         private final double[] values;
         private final DoubleHistogram state;
@@ -129,5 +127,10 @@ public class InternalHDRPercentileRanks extends AbstractInternalHDRPercentiles i
             ++i;
             return next;
         }
+
+        @Override
+        public final void remove() {
+            throw new UnsupportedOperationException();
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/hdr/InternalHDRPercentiles.java b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/hdr/InternalHDRPercentiles.java
index 4c475ed..b7b126f 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/hdr/InternalHDRPercentiles.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/hdr/InternalHDRPercentiles.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.search.aggregations.metrics.percentiles.hdr;
 
-import com.google.common.collect.UnmodifiableIterator;
-
 import org.HdrHistogram.DoubleHistogram;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.search.aggregations.AggregationStreams;
@@ -96,7 +94,7 @@ public class InternalHDRPercentiles extends AbstractInternalHDRPercentiles imple
         return TYPE;
     }
 
-    public static class Iter extends UnmodifiableIterator<Percentile> {
+    public static class Iter implements Iterator<Percentile> {
 
         private final double[] percents;
         private final DoubleHistogram state;
@@ -119,5 +117,10 @@ public class InternalHDRPercentiles extends AbstractInternalHDRPercentiles imple
             ++i;
             return next;
         }
+
+        @Override
+        public final void remove() {
+            throw new UnsupportedOperationException();
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/tdigest/InternalTDigestPercentileRanks.java b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/tdigest/InternalTDigestPercentileRanks.java
index bff0dcf..61deecb 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/tdigest/InternalTDigestPercentileRanks.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/tdigest/InternalTDigestPercentileRanks.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.search.aggregations.metrics.percentiles.tdigest;
 
-import com.google.common.collect.UnmodifiableIterator;
-
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.search.aggregations.AggregationStreams;
 import org.elasticsearch.search.aggregations.metrics.percentiles.InternalPercentile;
@@ -102,7 +100,7 @@ public class InternalTDigestPercentileRanks extends AbstractInternalTDigestPerce
         return percentileRank * 100;
     }
 
-    public static class Iter extends UnmodifiableIterator<Percentile> {
+    public static class Iter implements Iterator<Percentile> {
 
         private final double[] values;
         private final TDigestState state;
@@ -125,5 +123,10 @@ public class InternalTDigestPercentileRanks extends AbstractInternalTDigestPerce
             ++i;
             return next;
         }
+
+        @Override
+        public final void remove() {
+            throw new UnsupportedOperationException();
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/tdigest/InternalTDigestPercentiles.java b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/tdigest/InternalTDigestPercentiles.java
index 564e9d5..878ef55 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/tdigest/InternalTDigestPercentiles.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/tdigest/InternalTDigestPercentiles.java
@@ -18,8 +18,6 @@
  */
 package org.elasticsearch.search.aggregations.metrics.percentiles.tdigest;
 
-import com.google.common.collect.UnmodifiableIterator;
-
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.search.aggregations.AggregationStreams;
 import org.elasticsearch.search.aggregations.metrics.percentiles.InternalPercentile;
@@ -92,7 +90,7 @@ public class InternalTDigestPercentiles extends AbstractInternalTDigestPercentil
         return TYPE;
     }
 
-    public static class Iter extends UnmodifiableIterator<Percentile> {
+    public static class Iter implements Iterator<Percentile> {
 
         private final double[] percents;
         private final TDigestState state;
@@ -115,5 +113,10 @@ public class InternalTDigestPercentiles extends AbstractInternalTDigestPercentil
             ++i;
             return next;
         }
+
+        @Override
+        public final void remove() {
+            throw new UnsupportedOperationException();
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketmetrics/percentile/InternalPercentilesBucket.java b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketmetrics/percentile/InternalPercentilesBucket.java
index 10b1481..6a11c6f 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketmetrics/percentile/InternalPercentilesBucket.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketmetrics/percentile/InternalPercentilesBucket.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.search.aggregations.pipeline.bucketmetrics.percentile;
 
-import com.google.common.collect.UnmodifiableIterator;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
@@ -136,7 +135,7 @@ public class InternalPercentilesBucket extends InternalNumericMetricsAggregation
         return builder;
     }
 
-    public static class Iter extends UnmodifiableIterator<Percentile> {
+    public static class Iter implements Iterator<Percentile> {
 
         private final double[] percents;
         private final double[] percentiles;
@@ -159,5 +158,10 @@ public class InternalPercentilesBucket extends InternalNumericMetricsAggregation
             ++i;
             return next;
         }
+
+        @Override
+        public final void remove() {
+            throw new UnsupportedOperationException();
+        }
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java b/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
index 234a841..6402d5e 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/SearchContext.java
@@ -18,9 +18,6 @@
  */
 package org.elasticsearch.search.internal;
 
-import com.google.common.collect.Iterables;
-import com.google.common.collect.Multimap;
-import com.google.common.collect.MultimapBuilder;
 
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.Query;
@@ -35,6 +32,7 @@ import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.lease.Releasable;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.util.BigArrays;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.index.analysis.AnalysisService;
 import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
@@ -62,10 +60,7 @@ import org.elasticsearch.search.query.QuerySearchResult;
 import org.elasticsearch.search.rescore.RescoreSearchContext;
 import org.elasticsearch.search.suggest.SuggestionSearchContext;
 
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 import java.util.concurrent.atomic.AtomicBoolean;
 
 public abstract class SearchContext extends DelegatingHasContextAndHeaders implements Releasable {
@@ -87,7 +82,7 @@ public abstract class SearchContext extends DelegatingHasContextAndHeaders imple
         return current.get();
     }
 
-    private Multimap<Lifetime, Releasable> clearables = null;
+    private Map<Lifetime, List<Releasable>> clearables = null;
     private final AtomicBoolean closed = new AtomicBoolean(false);
 
     protected final ParseFieldMatcher parseFieldMatcher;
@@ -316,21 +311,29 @@ public abstract class SearchContext extends DelegatingHasContextAndHeaders imple
      */
     public void addReleasable(Releasable releasable, Lifetime lifetime) {
         if (clearables == null) {
-            clearables = MultimapBuilder.enumKeys(Lifetime.class).arrayListValues().build();
+            clearables = new HashMap<>();
         }
-        clearables.put(lifetime, releasable);
+        List<Releasable> releasables = clearables.get(lifetime);
+        if (releasables == null) {
+            releasables = new ArrayList<>();
+            clearables.put(lifetime, releasables);
+        }
+        releasables.add(releasable);
     }
 
     public void clearReleasables(Lifetime lifetime) {
         if (clearables != null) {
-            List<Collection<Releasable>> releasables = new ArrayList<>();
+            List<List<Releasable>>releasables = new ArrayList<>();
             for (Lifetime lc : Lifetime.values()) {
                 if (lc.compareTo(lifetime) > 0) {
                     break;
                 }
-                releasables.add(clearables.removeAll(lc));
+                List<Releasable> remove = clearables.remove(lc);
+                if (remove != null) {
+                    releasables.add(remove);
+                }
             }
-            Releasables.close(Iterables.concat(releasables));
+            Releasables.close(Iterables.flatten(releasables));
         }
     }
 
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/context/CategoryContextMapping.java b/core/src/main/java/org/elasticsearch/search/suggest/context/CategoryContextMapping.java
index ad075ac..ce807d8 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/context/CategoryContextMapping.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/context/CategoryContextMapping.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.search.suggest.context;
 
-import com.google.common.base.Joiner;
-import com.google.common.collect.Iterables;
 import org.apache.lucene.analysis.PrefixAnalyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.index.IndexableField;
@@ -28,6 +26,7 @@ import org.apache.lucene.util.automaton.Automata;
 import org.apache.lucene.util.automaton.Automaton;
 import org.apache.lucene.util.automaton.Operations;
 import org.elasticsearch.ElasticsearchParseException;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.common.xcontent.XContentParser.Token;
@@ -35,11 +34,9 @@ import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.ParseContext.Document;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
+import java.util.stream.Collectors;
+import java.util.stream.StreamSupport;
 
 /**
  * The {@link CategoryContextMapping} is used to define a {@link ContextMapping} that
@@ -213,7 +210,7 @@ public class CategoryContextMapping extends ContextMapping {
         if (obj instanceof CategoryContextMapping) {
             CategoryContextMapping other = (CategoryContextMapping) obj;
             if (this.fieldName.equals(other.fieldName)) {
-                return Iterables.elementsEqual(this.defaultValues, other.defaultValues);
+                return Iterables.allElementsAreEqual(this.defaultValues, other.defaultValues);
             }
         }
         return false;
@@ -262,14 +259,18 @@ public class CategoryContextMapping extends ContextMapping {
         public String toString() {
             StringBuilder sb = new StringBuilder("FieldConfig(" + fieldname + " = [");
             if (this.values != null && this.values.iterator().hasNext()) {
-                sb.append("(").append(Joiner.on(", ").join(this.values.iterator())).append(")");
+                sb.append(delimitValues(this.values));
             }
             if (this.defaultValues != null && this.defaultValues.iterator().hasNext()) {
-                sb.append(" default(").append(Joiner.on(", ").join(this.defaultValues.iterator())).append(")");
+                sb.append(" default").append(delimitValues(this.defaultValues));
             }
             return sb.append("])").toString();
         }
 
+        private String delimitValues(Iterable<? extends CharSequence> values) {
+            return StreamSupport.stream(values.spliterator(), false).collect(Collectors.joining(", ", "(", ")"));
+        }
+
     }
 
     private static class FieldQuery extends ContextQuery {
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/context/ContextMapping.java b/core/src/main/java/org/elasticsearch/search/suggest/context/ContextMapping.java
index 849a6e5..65232ca 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/context/ContextMapping.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/context/ContextMapping.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.search.suggest.context;
 
-import com.google.common.collect.Iterables;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.search.suggest.analyzing.XAnalyzingSuggester;
 import org.apache.lucene.util.automaton.Automata;
@@ -36,13 +35,7 @@ import org.elasticsearch.index.mapper.ParseContext;
 import org.elasticsearch.index.mapper.ParseContext.Document;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.SortedMap;
-import java.util.TreeMap;
+import java.util.*;
 
 /**
  * A {@link ContextMapping} is used t define a context that may used
@@ -157,7 +150,7 @@ public abstract class ContextMapping implements ToXContent {
      * @return true if both arguments are equal
      */
     public static boolean mappingsAreEqual(SortedMap<String, ? extends ContextMapping> thisMappings, SortedMap<String, ? extends ContextMapping> otherMappings) {
-        return Iterables.elementsEqual(thisMappings.entrySet(), otherMappings.entrySet());
+        return thisMappings.entrySet().equals(otherMappings.entrySet());
     }
 
     @Override
diff --git a/core/src/test/java/org/elasticsearch/NamingConventionTests.java b/core/src/test/java/org/elasticsearch/NamingConventionTests.java
index 051edd5..40868fc 100644
--- a/core/src/test/java/org/elasticsearch/NamingConventionTests.java
+++ b/core/src/test/java/org/elasticsearch/NamingConventionTests.java
@@ -19,9 +19,6 @@
 package org.elasticsearch;
 
 import junit.framework.TestCase;
-
-import com.google.common.base.Joiner;
-
 import org.apache.lucene.util.LuceneTestCase;
 import org.elasticsearch.common.io.PathUtils;
 import org.elasticsearch.test.ESIntegTestCase;
@@ -40,6 +37,7 @@ import java.nio.file.Path;
 import java.nio.file.attribute.BasicFileAttributes;
 import java.util.HashSet;
 import java.util.Set;
+import java.util.stream.Collectors;
 
 /**
  * Simple class that ensures that all subclasses concrete of ESTestCase end with either Test | Tests
@@ -149,24 +147,27 @@ public class NamingConventionTests extends ESTestCase {
         assertTrue(pureUnitTest.remove(PlainUnit.class));
         assertTrue(pureUnitTest.remove(PlainUnitTheSecond.class));
 
-        String classesToSubclass = Joiner.on(',').join(
-            ESTestCase.class.getSimpleName(),
-            ESTestCase.class.getSimpleName(),
-            ESTokenStreamTestCase.class.getSimpleName(),
-            LuceneTestCase.class.getSimpleName());
-        assertTrue("Not all subclasses of " + ESTestCase.class.getSimpleName() +
- " match the naming convention. Concrete classes must end with [Tests]:\n" + Joiner.on('\n').join(missingSuffix),
-            missingSuffix.isEmpty());
-        assertTrue("Classes ending with [Tests] are abstract or interfaces:\n" + Joiner.on('\n').join(notRunnable),
-            notRunnable.isEmpty());
-        assertTrue("Found inner classes that are tests, which are excluded from the test runner:\n" + Joiner.on('\n').join(innerClasses),
-            innerClasses.isEmpty());
-        assertTrue("Pure Unit-Test found must subclass one of [" + classesToSubclass +"]:\n" + Joiner.on('\n').join(pureUnitTest),
-            pureUnitTest.isEmpty());
-        assertTrue("Classes ending with [Tests] must subclass [" + classesToSubclass + "]:\n" + Joiner.on('\n').join(notImplementing),
-            notImplementing.isEmpty());
-        assertTrue("Subclasses of ESIntegTestCase should end with IT as they are integration tests:\n" + Joiner.on('\n').join(integTestsInDisguise),
-            integTestsInDisguise.isEmpty());
+        String classesToSubclass = String.join(
+                ",",
+                ESTestCase.class.getSimpleName(),
+                ESTestCase.class.getSimpleName(),
+                ESTokenStreamTestCase.class.getSimpleName(),
+                LuceneTestCase.class.getSimpleName()
+        );
+        assertNoViolations("Not all subclasses of " + ESTestCase.class.getSimpleName() + " match the naming convention. Concrete classes must end with [Tests]:\n", missingSuffix);
+        assertNoViolations("Classes ending with [Tests] are abstract or interfaces:\n", notRunnable);
+        assertNoViolations("Found inner classes that are tests, which are excluded from the test runner:\n", innerClasses);
+        assertNoViolations("Pure Unit-Test found must subclass one of [" + classesToSubclass + "]:\n", pureUnitTest);
+        assertNoViolations("Classes ending with [Tests] must subclass [" + classesToSubclass + "]:\n", notImplementing);
+        assertNoViolations("Subclasses of ESIntegTestCase should end with IT as they are integration tests:\n", integTestsInDisguise);
+    }
+
+    private String join(Set<Class> set) {
+        return set.stream().map(Object::toString).collect(Collectors.joining("\n"));
+    }
+
+    private void assertNoViolations(String message, Set<Class> set) {
+        assertTrue(message + join(set), set.isEmpty());
     }
 
     /*
diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
index ef6aa63..d985ada 100644
--- a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
@@ -161,7 +161,7 @@ public class ClusterInfoServiceIT extends ESIntegTestCase {
         }
         for (DiskUsage usage : mostUsages.values()) {
             logger.info("--> usage: {}", usage);
-            assertThat("usage has be retrieved", usage.getFreeBytes(), greaterThan(0L));
+            assertThat("usage has be retrieved", usage.getFreeBytes(), greaterThanOrEqualTo(0L));
         }
         for (Long size : shardSizes.values()) {
             logger.info("--> shard size: {}", size);
diff --git a/core/src/test/java/org/elasticsearch/common/util/ArrayUtilsTests.java b/core/src/test/java/org/elasticsearch/common/util/ArrayUtilsTests.java
index 0c7038e..735fda1 100644
--- a/core/src/test/java/org/elasticsearch/common/util/ArrayUtilsTests.java
+++ b/core/src/test/java/org/elasticsearch/common/util/ArrayUtilsTests.java
@@ -19,9 +19,12 @@
 
 package org.elasticsearch.common.util;
 
+import org.apache.lucene.util.ArrayUtil;
 import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
+import java.lang.reflect.Array;
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.BitSet;
 
@@ -90,4 +93,22 @@ public class ArrayUtilsTests extends ESTestCase {
         return min + delta;
     }
 
+    public void testConcat() {
+        assertArrayEquals(new String[]{"a", "b", "c", "d"}, ArrayUtils.concat(new String[]{"a", "b"}, new String[]{"c", "d"}));
+        int firstSize = randomIntBetween(0, 10);
+        String[] first = new String[firstSize];
+        ArrayList<String> sourceOfTruth = new ArrayList<>();
+        for (int i = 0; i < firstSize; i++) {
+            first[i] = randomRealisticUnicodeOfCodepointLengthBetween(0,10);
+            sourceOfTruth.add(first[i]);
+        }
+        int secondSize = randomIntBetween(0, 10);
+        String[] second = new String[secondSize];
+        for (int i = 0; i < secondSize; i++) {
+            second[i] = randomRealisticUnicodeOfCodepointLengthBetween(0, 10);
+            sourceOfTruth.add(second[i]);
+        }
+        assertArrayEquals(sourceOfTruth.toArray(new String[0]), ArrayUtils.concat(first, second));
+    }
+
 }
diff --git a/core/src/test/java/org/elasticsearch/common/util/CollectionUtilsTests.java b/core/src/test/java/org/elasticsearch/common/util/CollectionUtilsTests.java
index b85c42c..73611c8 100644
--- a/core/src/test/java/org/elasticsearch/common/util/CollectionUtilsTests.java
+++ b/core/src/test/java/org/elasticsearch/common/util/CollectionUtilsTests.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.common.util;
 
-import com.google.common.collect.Iterables;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefArray;
 import org.apache.lucene.util.BytesRefBuilder;
@@ -27,14 +26,7 @@ import org.apache.lucene.util.Counter;
 import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.SortedSet;
-import java.util.TreeSet;
+import java.util.*;
 
 import static org.elasticsearch.common.util.CollectionUtils.eagerPartition;
 import static org.hamcrest.Matchers.equalTo;
@@ -60,7 +52,7 @@ public class CollectionUtilsTests extends ESTestCase {
             final List<Object> rotated = CollectionUtils.rotate(list, distance);
             // check content is the same
             assertEquals(rotated.size(), list.size());
-            assertEquals(Iterables.size(rotated), list.size());
+            assertEquals(rotated.size(), list.size());
             assertEquals(new HashSet<>(rotated), new HashSet<>(list));
             // check stability
             for (int j = randomInt(4); j >= 0; --j) {
diff --git a/core/src/test/java/org/elasticsearch/common/util/iterable/IterablesTests.java b/core/src/test/java/org/elasticsearch/common/util/iterable/IterablesTests.java
new file mode 100644
index 0000000..76fc51d
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/common/util/iterable/IterablesTests.java
@@ -0,0 +1,81 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.common.util.iterable;
+
+import org.elasticsearch.test.ESTestCase;
+import org.hamcrest.Matchers;
+
+import java.util.Arrays;
+import java.util.Iterator;
+import java.util.List;
+import java.util.NoSuchElementException;
+
+import static org.hamcrest.Matchers.contains;
+import static org.hamcrest.Matchers.containsString;
+import static org.hamcrest.object.HasToString.hasToString;
+import static org.junit.Assert.*;
+
+public class IterablesTests extends ESTestCase {
+    public void testGetOverList() {
+        test(Arrays.asList("a", "b", "c"));
+    }
+
+    public void testGetOverIterable() {
+        Iterable<String> iterable = () ->
+                new Iterator<String>() {
+                    private int position = 0;
+
+                    @Override
+                    public boolean hasNext() {
+                        return position < 3;
+                    }
+
+                    @Override
+                    public String next() {
+                        if (position < 3) {
+                            String s = position == 0 ? "a" : position == 1 ? "b" : "c";
+                            position++;
+                            return s;
+                        } else {
+                            throw new NoSuchElementException();
+                        }
+                    }
+                };
+        test(iterable);
+    }
+
+    private void test(Iterable<String> iterable) {
+        try {
+            Iterables.get(iterable, -1);
+            fail("expected IllegalArgumentException");
+        } catch (IllegalArgumentException e) {
+            assertThat(e, hasToString("java.lang.IllegalArgumentException: position >= 0"));
+        }
+        assertEquals("a", Iterables.get(iterable, 0));
+        assertEquals("b", Iterables.get(iterable, 1));
+        assertEquals("c", Iterables.get(iterable, 2));
+        try {
+            Iterables.get(iterable, 3);
+            fail("expected IndexOutOfBoundsException");
+        } catch (IndexOutOfBoundsException e) {
+            assertThat(e, hasToString("java.lang.IndexOutOfBoundsException: 3"));
+        }
+    }
+}
\ No newline at end of file
diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
index a1b577e..2a76a05 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.index.engine;
 
 import com.google.common.collect.ImmutableMap;
-
 import org.apache.log4j.AppenderSkeleton;
 import org.apache.log4j.Level;
 import org.apache.log4j.LogManager;
@@ -53,8 +52,6 @@ import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.lucene.uid.Versions;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.unit.ByteSizeUnit;
-import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.VersionType;
@@ -318,6 +315,7 @@ public class InternalEngineTests extends ESTestCase {
             assertThat(segments.get(0).isCompound(), equalTo(defaultCompound));
 
             engine.config().setCompoundOnFlush(false);
+            engine.onSettingsChanged();
 
             ParsedDocument doc3 = testParsedDocument("3", "3", "test", null, -1, -1, testDocumentWithTextField(), B_3, null);
             engine.create(new Engine.Create(newUid("3"), doc3));
@@ -366,6 +364,7 @@ public class InternalEngineTests extends ESTestCase {
             assertThat(segments.get(1).isCompound(), equalTo(false));
 
             engine.config().setCompoundOnFlush(true);
+            engine.onSettingsChanged();
             ParsedDocument doc4 = testParsedDocument("4", "4", "test", null, -1, -1, testDocumentWithTextField(), B_3, null);
             engine.create(new Engine.Create(newUid("4"), doc4));
             engine.refresh("test");
@@ -1638,10 +1637,12 @@ public class InternalEngineTests extends ESTestCase {
     // #10312
     @Test
     public void testDeletesAloneCanTriggerRefresh() throws Exception {
+        // Tiny indexing buffer:
+        Settings indexSettings = Settings.builder().put(defaultSettings)
+                .put(EngineConfig.INDEX_BUFFER_SIZE_SETTING, "1kb").build();
         try (Store store = createStore();
-            Engine engine = new InternalEngine(config(defaultSettings, store, createTempDir(), new MergeSchedulerConfig(defaultSettings), newMergePolicy()),
+             Engine engine = new InternalEngine(config(indexSettings, store, createTempDir(), new MergeSchedulerConfig(defaultSettings), newMergePolicy()),
                      false)) {
-            engine.config().setIndexingBufferSize(new ByteSizeValue(1, ByteSizeUnit.KB));
             for (int i = 0; i < 100; i++) {
                 String id = Integer.toString(i);
                 ParsedDocument doc = testParsedDocument(id, id, "test", null, -1, -1, testDocument(), B_1, null);
diff --git a/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
index 5d431c5..79f5e07 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/ShadowEngineTests.java
@@ -338,6 +338,7 @@ public class ShadowEngineTests extends ESTestCase {
 
 
         primaryEngine.config().setCompoundOnFlush(false);
+        primaryEngine.onSettingsChanged();
 
         ParsedDocument doc3 = testParsedDocument("3", "3", "test", null, -1, -1, testDocumentWithTextField(), B_3, null);
         primaryEngine.create(new Engine.Create(newUid("3"), doc3));
@@ -410,6 +411,8 @@ public class ShadowEngineTests extends ESTestCase {
         replicaEngine.refresh("test");
 
         primaryEngine.config().setCompoundOnFlush(true);
+        primaryEngine.onSettingsChanged();
+
         ParsedDocument doc4 = testParsedDocument("4", "4", "test", null, -1, -1, testDocumentWithTextField(), B_3, null);
         primaryEngine.create(new Engine.Create(newUid("4"), doc4));
         primaryEngine.refresh("test");
diff --git a/core/src/test/java/org/elasticsearch/indices/memory/IndexingMemoryControllerIT.java b/core/src/test/java/org/elasticsearch/indices/memory/IndexingMemoryControllerIT.java
index f3b8eb3..36ad646 100644
--- a/core/src/test/java/org/elasticsearch/indices/memory/IndexingMemoryControllerIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/memory/IndexingMemoryControllerIT.java
@@ -24,6 +24,7 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.util.concurrent.EsExecutors;
 import org.elasticsearch.index.engine.EngineConfig;
+import org.elasticsearch.index.engine.SegmentsStats;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.node.internal.InternalSettingsPreparer;
@@ -78,7 +79,7 @@ public class IndexingMemoryControllerIT extends ESIntegTestCase {
     @Test
     public void testIndexBufferSizeUpdateInactiveShard() throws InterruptedException {
 
-        createNode(Settings.builder().put("indices.memory.shard_inactive_time", "100ms").build());
+        createNode(Settings.builder().put(IndexingMemoryController.SHARD_INACTIVE_TIME_SETTING, "100ms").build());
 
         prepareCreate("test1").setSettings(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1, IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0).get();
 
@@ -109,6 +110,45 @@ public class IndexingMemoryControllerIT extends ESIntegTestCase {
                             shard1.engine().config().getIndexingBufferSize().bytes() + "]"
             );
         }
+
+        // Make sure we also pushed the tiny indexing buffer down to the underlying IndexWriter:
+        assertEquals(EngineConfig.INACTIVE_SHARD_INDEXING_BUFFER.bytes(), getIWBufferSize("test1"));
+    }
+
+    private long getIWBufferSize(String indexName) {
+        return client().admin().indices().prepareStats(indexName).get().getTotal().getSegments().getIndexWriterMaxMemoryInBytes();
+    }
+
+    @Test
+    public void testIndexBufferSizeTwoShards() throws InterruptedException {
+        createNode(Settings.builder().put(IndexingMemoryController.SHARD_INACTIVE_TIME_SETTING, "100000h",
+                                          IndexingMemoryController.INDEX_BUFFER_SIZE_SETTING, "32mb",
+                                          IndexShard.INDEX_REFRESH_INTERVAL, "-1").build());
+
+        // Create two active indices, sharing 32 MB indexing buffer:
+        prepareCreate("test3").setSettings(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1, IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0).get();
+        prepareCreate("test4").setSettings(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1, IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0).get();
+
+        ensureGreen();
+
+        index("test3", "type", "1", "f", 1);
+        index("test4", "type", "1", "f", 1);
+
+        // .. then make sure we really pushed the update (16 MB for each) down to the IndexWriter, even if refresh nor flush occurs:
+        if (awaitBusy(() -> getIWBufferSize("test3") == 16*1024*1024) == false) {
+            fail("failed to update shard indexing buffer size for test3 index to 16 MB; got: " + getIWBufferSize("test3"));
+        }
+        if (awaitBusy(() -> getIWBufferSize("test4") == 16*1024*1024) == false) {
+            fail("failed to update shard indexing buffer size for test4 index to 16 MB; got: " + getIWBufferSize("test4"));
+        }
+    }
+
+    @Test
+    public void testIndexBufferNotPercent() throws InterruptedException {
+        // #13487: Make sure you can specify non-percent sized index buffer and not hit NPE
+        createNode(Settings.builder().put(IndexingMemoryController.INDEX_BUFFER_SIZE_SETTING, "32mb").build());
+        // ... and that it took:
+        assertEquals(32*1024*1024, internalCluster().getInstance(IndexingMemoryController.class).indexingBufferSize().bytes());
     }
 
     private void createNode(Settings settings) {
@@ -120,7 +160,7 @@ public class IndexingMemoryControllerIT extends ESIntegTestCase {
                         .put(EsExecutors.PROCESSORS, 1) // limit the number of threads created
                         .put("http.enabled", false)
                         .put(InternalSettingsPreparer.IGNORE_SYSTEM_PROPERTIES_SETTING, true) // make sure we get what we set :)
-                        .put("indices.memory.interval", "100ms")
+                        .put(IndexingMemoryController.SHARD_INACTIVE_INTERVAL_TIME_SETTING, "100ms")
                         .put(settings)
         );
     }
diff --git a/core/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java b/core/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java
index cf44a76..c1ae4c2 100644
--- a/core/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java
+++ b/core/src/test/java/org/elasticsearch/plugins/PluginManagerUnitTests.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.plugins;
 
-import com.google.common.io.Files;
 import org.elasticsearch.Build;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.http.client.HttpDownloadHelper;
@@ -63,10 +62,9 @@ public class PluginManagerUnitTests extends ESTestCase {
         Environment environment = new Environment(settings);
 
         PluginManager.PluginHandle pluginHandle = new PluginManager.PluginHandle(pluginName, "version", "user");
-        String configDirPath = Files.simplifyPath(pluginHandle.configDir(environment).normalize().toString());
-        String expectedDirPath = Files.simplifyPath(genericConfigFolder.resolve(pluginName).normalize().toString());
-
-        assertThat(configDirPath, is(expectedDirPath));
+        Path configDirPath = pluginHandle.configDir(environment).normalize();
+        Path expectedDirPath = genericConfigFolder.resolve(pluginName).normalize();
+        assertEquals(configDirPath, expectedDirPath);
     }
 
     @Test
diff --git a/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java b/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
index 9993137..93449c9 100644
--- a/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
+++ b/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchIT.java
@@ -19,22 +19,15 @@
 package org.elasticsearch.search.highlight;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-import com.google.common.base.Joiner;
-import com.google.common.collect.Iterables;
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.common.settings.Settings.Builder;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.BoostableQueryBuilder;
-import org.elasticsearch.index.query.IdsQueryBuilder;
-import org.elasticsearch.index.query.MatchQueryBuilder;
+import org.elasticsearch.index.query.*;
 import org.elasticsearch.index.query.MatchQueryBuilder.Operator;
 import org.elasticsearch.index.query.MatchQueryBuilder.Type;
-import org.elasticsearch.index.query.MultiMatchQueryBuilder;
-import org.elasticsearch.index.query.QueryBuilder;
-import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.rest.RestStatus;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.builder.SearchSourceBuilder;
@@ -51,38 +44,12 @@ import java.util.Map;
 import static org.elasticsearch.client.Requests.searchRequest;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.boolQuery;
-import static org.elasticsearch.index.query.QueryBuilders.boostingQuery;
-import static org.elasticsearch.index.query.QueryBuilders.commonTermsQuery;
-import static org.elasticsearch.index.query.QueryBuilders.constantScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.fuzzyQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchPhrasePrefixQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchPhraseQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
-import static org.elasticsearch.index.query.QueryBuilders.missingQuery;
-import static org.elasticsearch.index.query.QueryBuilders.multiMatchQuery;
-import static org.elasticsearch.index.query.QueryBuilders.prefixQuery;
-import static org.elasticsearch.index.query.QueryBuilders.queryStringQuery;
-import static org.elasticsearch.index.query.QueryBuilders.rangeQuery;
-import static org.elasticsearch.index.query.QueryBuilders.regexpQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.index.query.QueryBuilders.typeQuery;
-import static org.elasticsearch.index.query.QueryBuilders.wildcardQuery;
+import static org.elasticsearch.index.query.QueryBuilders.*;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.highlight;
 import static org.elasticsearch.search.builder.SearchSourceBuilder.searchSource;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHighlight;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNotHighlighted;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
 import static org.elasticsearch.test.hamcrest.RegexMatcher.matches;
-import static org.hamcrest.Matchers.anyOf;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.hasKey;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.startsWith;
+import static org.hamcrest.Matchers.*;
 
 public class HighlighterSearchIT extends ESIntegTestCase {
 
@@ -845,8 +812,10 @@ public class HighlighterSearchIT extends ESIntegTestCase {
         ensureGreen();
 
         // Index one megabyte of "t   " over and over and over again
+        String pattern = "t   ";
+        String value = new String(new char[1024 * 256 / pattern.length()]).replace("\0", pattern);
         client().prepareIndex("test", "type1")
-                .setSource("field1", Joiner.on("").join(Iterables.limit(Iterables.cycle("t   "), 1024*256))).get();
+                .setSource("field1", value).get();
         refresh();
 
         logger.info("--> highlighting and searching on field1");
diff --git a/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java b/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java
index 95c48e8..592f65e 100644
--- a/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java
+++ b/core/src/test/java/org/elasticsearch/test/ESIntegTestCase.java
@@ -24,7 +24,6 @@ import com.carrotsearch.randomizedtesting.Randomness;
 import com.carrotsearch.randomizedtesting.annotations.TestGroup;
 import com.carrotsearch.randomizedtesting.generators.RandomInts;
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-import com.google.common.base.Joiner;
 import org.apache.http.impl.client.HttpClients;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
@@ -793,7 +792,7 @@ public abstract class ESIntegTestCase extends ESTestCase {
     }
 
     private Settings.Builder getExcludeSettings(String index, int num, Settings.Builder builder) {
-        String exclude = Joiner.on(',').join(internalCluster().allDataNodesButN(num));
+        String exclude = String.join(",", internalCluster().allDataNodesButN(num));
         builder.put("index.routing.allocation.exclude._name", exclude);
         return builder;
     }
diff --git a/core/src/test/java/org/elasticsearch/test/rest/client/http/HttpRequestBuilder.java b/core/src/test/java/org/elasticsearch/test/rest/client/http/HttpRequestBuilder.java
index 3fa592b..2f42488 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/client/http/HttpRequestBuilder.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/client/http/HttpRequestBuilder.java
@@ -18,14 +18,7 @@
  */
 package org.elasticsearch.test.rest.client.http;
 
-import com.google.common.base.Joiner;
-import org.apache.http.client.methods.CloseableHttpResponse;
-import org.apache.http.client.methods.HttpEntityEnclosingRequestBase;
-import org.apache.http.client.methods.HttpHead;
-import org.apache.http.client.methods.HttpOptions;
-import org.apache.http.client.methods.HttpPost;
-import org.apache.http.client.methods.HttpPut;
-import org.apache.http.client.methods.HttpUriRequest;
+import org.apache.http.client.methods.*;
 import org.apache.http.entity.StringEntity;
 import org.apache.http.impl.client.CloseableHttpClient;
 import org.elasticsearch.client.support.Headers;
@@ -44,6 +37,7 @@ import java.net.URLEncoder;
 import java.nio.charset.Charset;
 import java.util.HashMap;
 import java.util.Map;
+import java.util.stream.Collectors;
 
 /**
  * Executable builder for an http request
@@ -194,7 +188,7 @@ public class HttpRequestBuilder {
             //(e.g. '+' will stay as is) hence when trying to properly encode params manually they will end up double encoded (+ becomes %252B instead of %2B).
             StringBuilder uriBuilder = new StringBuilder(protocol).append("://").append(host).append(":").append(port).append(uri.getRawPath());
             if (params.size() > 0) {
-                uriBuilder.append("?").append(Joiner.on('&').withKeyValueSeparator("=").join(params));
+                uriBuilder.append("?").append(params.entrySet().stream().map(e -> e.getKey() + "=" + e.getValue()).collect(Collectors.joining("&")));
             }
             return URI.create(uriBuilder.toString());
         } catch(URISyntaxException e) {
diff --git a/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java b/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java
index 29f83d1..852d71c 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java
@@ -18,14 +18,9 @@
  */
 package org.elasticsearch.test.rest.section;
 
-import com.google.common.base.Joiner;
 import com.google.common.collect.ImmutableMap;
 
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 
 /**
  * Represents a test fragment that contains the information needed to call an api
@@ -52,7 +47,7 @@ public class ApiCallSection {
     public void addParam(String key, String value) {
         String existingValue = params.get(key);
         if (existingValue != null) {
-            value = Joiner.on(",").join(existingValue, value);
+            value = existingValue + "," + value;
         }
         this.params.put(key, value);
     }
diff --git a/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java b/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java
index 359ebdd..562adaa 100644
--- a/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java
+++ b/core/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java
@@ -19,7 +19,6 @@
 
 package org.elasticsearch.threadpool;
 
-import com.google.common.util.concurrent.MoreExecutors;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor;
 import org.elasticsearch.test.ESTestCase;
diff --git a/dev-tools/prepare_release_candidate.py b/dev-tools/prepare_release_candidate.py
index 51387cc..5f83893 100644
--- a/dev-tools/prepare_release_candidate.py
+++ b/dev-tools/prepare_release_candidate.py
@@ -63,7 +63,7 @@ To install the deb from an APT repo:
 
 APT line sources.list line:
 
-deb http://download.elasticsearch.org/elasticsearch/staging/%(version)s-%(hash)s/repos/%(major_minor_version)s/debian/ stable main
+deb http://%(bucket)s/elasticsearch/staging/%(version)s-%(hash)s/repos/%(major_minor_version)s/debian/ stable main
 
 To install the RPM, create a YUM file like:
 
@@ -73,30 +73,34 @@ containing:
 
 [elasticsearch-2.0]
 name=Elasticsearch repository for packages
-baseurl=http://download.elasticsearch.org/elasticsearch/staging/%(version)s-%(hash)s/repos/%(major_minor_version)s/centos
+baseurl=http://%(bucket)s/elasticsearch/staging/%(version)s-%(hash)s/repos/%(major_minor_version)s/centos
 gpgcheck=1
 gpgkey=http://packages.elastic.co/GPG-KEY-elasticsearch
 enabled=1
 
 To smoke-test the release please run:
 
- python3 -B ./dev-tools/smoke_tests_rc.py --version %(version)s --hash %(hash)s --plugins license,shield,watcher
+ python3 -B ./dev-tools/smoke_test_rc.py --version %(version)s --hash %(hash)s --plugins license,shield,watcher
 
 NOTE: this script requires JAVA_HOME to point to a Java 7 Runtime 
 
 [1] https://github.com/elastic/elasticsearch/commit/%(hash)s
-[2] http://download.elasticsearch.org/elasticsearch/staging/%(version)s-%(hash)s/org/elasticsearch/distribution/zip/elasticsearch/%(version)s/elasticsearch-%(version)s.zip
-[3] http://download.elasticsearch.org/elasticsearch/staging/%(version)s-%(hash)s/org/elasticsearch/distribution/tar/elasticsearch/%(version)s/elasticsearch-%(version)s.tar.gz
-[4] http://download.elasticsearch.org/elasticsearch/staging/%(version)s-%(hash)s/org/elasticsearch/distribution/rpm/elasticsearch/%(version)s/elasticsearch-%(version)s.rpm
-[5] http://download.elasticsearch.org/elasticsearch/staging/%(version)s-%(hash)s/org/elasticsearch/distribution/deb/elasticsearch/%(version)s/elasticsearch-%(version)s.deb
+[2] http://%(bucket)s/elasticsearch/staging/%(version)s-%(hash)s/org/elasticsearch/distribution/zip/elasticsearch/%(version)s/elasticsearch-%(version)s.zip
+[3] http://%(bucket)s/elasticsearch/staging/%(version)s-%(hash)s/org/elasticsearch/distribution/tar/elasticsearch/%(version)s/elasticsearch-%(version)s.tar.gz
+[4] http://%(bucket)s/elasticsearch/staging/%(version)s-%(hash)s/org/elasticsearch/distribution/rpm/elasticsearch/%(version)s/elasticsearch-%(version)s.rpm
+[5] http://%(bucket)s/elasticsearch/staging/%(version)s-%(hash)s/org/elasticsearch/distribution/deb/elasticsearch/%(version)s/elasticsearch-%(version)s.deb
 """
-VERBOSE=True
-def run(command, env_vars=None, verbose=VERBOSE):
+
+# console colors
+COLOR_OK = '\033[92m'
+COLOR_END = '\033[0m'
+COLOR_FAIL = '\033[91m'
+
+def run(command, env_vars=None):
   if env_vars:
     for key, value in env_vars.items():
       os.putenv(key, value)
-  if not verbose:
-    command = '%s >> /dev/null 2>&1' % (command)
+  print('*** Running: %s%s%s' % (COLOR_OK, command, COLOR_END))
   if os.system(command):
     raise RuntimeError('    FAILED: %s' % (command))
 
@@ -192,10 +196,6 @@ def check_command_exists(name, cmd):
   except subprocess.CalledProcessError:
     raise RuntimeError('Could not run command %s - please make sure it is installed and in $PATH' % (name))
 
-# console colors
-COLOR_OK = '\033[92m'
-COLOR_END = '\033[0m'
-COLOR_FAIL = '\033[91m'
 def run_and_print(text, run_function):
   try:
     print(text, end='')
@@ -218,8 +218,8 @@ def check_env_var(text, env_var):
 
 def check_environment_and_commandline_tools(check_only):
   checks = list()
-  checks.append(check_env_var('Checking for AWS env configuration AWS_SECRET_ACCESS_KEY_ID...     ', 'AWS_SECRET_ACCESS_KEY'))
-  checks.append(check_env_var('Checking for AWS env configuration AWS_ACCESS_KEY_ID...            ', 'AWS_ACCESS_KEY_ID'))
+  checks.append(check_env_var('Checking for AWS env configuration AWS_SECRET_KEY... ', 'AWS_SECRET_KEY'))
+  checks.append(check_env_var('Checking for AWS env configuration AWS_ACCESS_KEY... ', 'AWS_ACCESS_KEY'))
   checks.append(run_and_print('Checking command: rpm...            ', partial(check_command_exists, 'rpm', 'rpm --version')))
   checks.append(run_and_print('Checking command: dpkg...           ', partial(check_command_exists, 'dpkg', 'dpkg --version')))
   checks.append(run_and_print('Checking command: gpg...            ', partial(check_command_exists, 'gpg', 'gpg --version')))
@@ -238,37 +238,66 @@ def check_environment_and_commandline_tools(check_only):
 
 if __name__ == "__main__":
   parser = argparse.ArgumentParser(description='Builds and publishes a Elasticsearch Release')
-  parser.add_argument('--deploy', '-d', dest='deploy', action='store_true',
-                      help='Installs and Deploys the release on a sonartype staging repository.')
-  parser.add_argument('--skipDocCheck', '-c', dest='skip_doc_check', action='store_false',
-                      help='Skips any checks for pending documentation changes')
-  parser.add_argument('--push-s3', '-p', dest='push', action='store_true',
+  parser.add_argument('--deploy-sonatype', dest='deploy_sonatype', action='store_true',
+                      help='Installs and Deploys the release on a sonatype staging repository.')
+  parser.add_argument('--deploy-s3', dest='deploy_s3', action='store_true',
                       help='Pushes artifacts to the S3 staging area')
-  parser.add_argument('--install_only', '-i', dest='install_only', action='store_true',
-                      help='Only runs a maven install to skip the remove deployment step')
-  parser.add_argument('--gpg-key', '-k', dest='gpg_key', default="D88E42B4",
+  parser.add_argument('--deploy-s3-repos', dest='deploy_s3_repos', action='store_true',
+                      help='Creates package repositories in S3 repo')
+  parser.add_argument('--no-install', dest='no_install', action='store_true',
+                      help='Does not run "mvn install", expects this to be run already and reuses artifacts from local repo, only useful with --deploy-s3/--deploy-s3-repos, after sonatype deplomeny to ensure same artifacts')
+  parser.add_argument('--skip-doc-check', dest='skip_doc_check', action='store_false',
+                      help='Skips any checks for pending documentation changes')
+  parser.add_argument('--skip-tests', dest='skip_tests', action='store_true',
+                      help='Skips any test runs')
+  parser.add_argument('--gpg-key', dest='gpg_key', default="D88E42B4",
                       help='Allows you to specify a different gpg_key to be used instead of the default release key')
-  parser.add_argument('--verbose', '-b', dest='verbose',
-                      help='Runs the script in verbose mode')
-  parser.add_argument('--check-only', dest='check_only', action='store_true',
+  parser.add_argument('--bucket', '-b', dest='bucket', default="download.elasticsearch.org",
+                      help='Allows you to specify a different s3 bucket to upload the artifacts to')
+  parser.add_argument('--quiet', dest='quiet', action='store_true',
+                      help='Runs the script in quiet mode')
+  parser.add_argument('--check', dest='check', action='store_true',
                       help='Checks and reports for all requirements and then exits')
-  parser.set_defaults(deploy=False)
+
+  # by default, we only run mvn install and dont push anything repo
+  parser.set_defaults(deploy_sonatype=False)
+  parser.set_defaults(deploy_s3=False)
+  parser.set_defaults(deploy_s3_repos=False)
+  parser.set_defaults(no_install=False)
+  # other defaults
   parser.set_defaults(skip_doc_check=False)
-  parser.set_defaults(push=False)
-  parser.set_defaults(install_only=False)
-  parser.set_defaults(verbose=False)
+  parser.set_defaults(quiet=False)
+  parser.set_defaults(skip_tests=False)
+
   args = parser.parse_args()
-  install_and_deploy = args.deploy
   skip_doc_check = args.skip_doc_check
-  push = args.push
   gpg_key = args.gpg_key
-  install_only = args.install_only
-  VERBOSE = args.verbose
+  bucket = args.bucket
+  deploy_sonatype = args.deploy_sonatype
+  deploy_s3 = args.deploy_s3
+  deploy_s3_repos = args.deploy_s3_repos
+  run_mvn_install = not args.no_install
+  skip_tests = args.skip_tests
+
+  check_environment_and_commandline_tools(args.check)
+
+  if not run_mvn_install and deploy_sonatype:
+    print('Using --no-install and --deploy-sonatype together does not work. Exiting')
+    sys.exit(-1)
+
+  print('*** Preparing a release candidate: ', end='')
+  print('deploy sonatype: %s%s%s' % (COLOR_OK if deploy_sonatype else COLOR_FAIL, 'yes' if deploy_sonatype else 'no', COLOR_END), end='')
+  print(', deploy s3: %s%s%s' % (COLOR_OK if deploy_s3 else COLOR_FAIL, 'yes' if deploy_s3 else 'no', COLOR_END), end='')
+  print(', deploy s3 repos: %s%s%s' % (COLOR_OK if deploy_s3_repos else COLOR_FAIL, 'yes' if deploy_s3_repos else 'no', COLOR_END), end='')
+  print('')
 
-  check_environment_and_commandline_tools(args.check_only)
+  shortHash = subprocess.check_output('git log --pretty=format:"%h" -n 1', shell=True).decode('utf-8')
+  releaseDirectory = os.getenv('HOME') + '/elastic-releases'
+  release_version = find_release_version()
+  localRepo = '%s/elasticsearch-%s-%s' % (releaseDirectory, release_version, shortHash)
+  localRepoElasticsearch = localRepo + '/org/elasticsearch'
 
   ensure_checkout_is_clean()
-  release_version = find_release_version()
   if not re.match('(\d+\.\d+)\.*',release_version):
     raise RuntimeError('illegal release version format: %s' % (release_version))
   major_minor_version = re.match('(\d+\.\d+)\.*',release_version).group(1)
@@ -281,7 +310,6 @@ if __name__ == "__main__":
     if pending_files:
       raise RuntimeError('pending coming[%s] documentation changes found in %s' % (release_version, pending_files))
 
-
   run('cd dev-tools && mvn versions:set -DnewVersion=%s -DgenerateBackupPoms=false' % (release_version))
   run('cd rest-api-spec && mvn versions:set -DnewVersion=%s -DgenerateBackupPoms=false' % (release_version))
   run('mvn versions:set -DnewVersion=%s -DgenerateBackupPoms=false' % (release_version))
@@ -290,70 +318,69 @@ if __name__ == "__main__":
 
   print('*** Done removing snapshot version. DO NOT COMMIT THIS, WHEN CREATING A RELEASE CANDIDATE.')
 
-  shortHash = subprocess.check_output('git log --pretty=format:"%h" -n 1', shell=True).decode('utf-8')
-  releaseDirectory = os.getenv('HOME') + '/elastic-releases'
-  os.mkdir(releaseDirectory)
-  localRepo = '%s/elasticsearch-%s-%s' % (releaseDirectory, release_version, shortHash)
-  localRepoElasticsearch = localRepo + '/org/elasticsearch'
-  if os.path.exists(localRepoElasticsearch):
+  if not os.path.exists(releaseDirectory):
+    os.mkdir(releaseDirectory)
+  if os.path.exists(localRepoElasticsearch) and run_mvn_install:
     print('clean local repository %s' % localRepoElasticsearch)
     shutil.rmtree(localRepoElasticsearch)
 
-  if install_only:
-    mvn_target = 'install'
-  else:
-    mvn_target = 'deploy'
-  install_command = 'mvn clean %s -Prelease -Dskip.integ.tests=true -Dgpg.key="%s" -Dpackaging.rpm.rpmbuild=/usr/bin/rpmbuild -Drpm.sign=true -Dmaven.repo.local=%s -Dno.commit.pattern="\\bno(n|)commit\\b" -Dforbidden.test.signatures=""' % (mvn_target, gpg_key, localRepo)
+  mvn_target = 'deploy' if deploy_sonatype else 'install'
+  tests = '-DskipTests' if skip_tests else '-Dskip.integ.tests=true'
+  install_command = 'mvn clean %s -Prelease %s -Dgpg.key="%s" -Dpackaging.rpm.rpmbuild=/usr/bin/rpmbuild -Drpm.sign=true -Dmaven.repo.local=%s -Dno.commit.pattern="\\bno(n|)commit\\b" -Dforbidden.test.signatures=""' % (mvn_target, tests, gpg_key, localRepo)
   clean_repo_command = 'find %s -name _remote.repositories -exec rm {} \;' % (localRepoElasticsearch)
-  rename_metadata_files_command = 'for i in $(find %s -name "maven-metadata-local.xml*") ; do mv "$i" "${i/-local/}" ; done' % (localRepoElasticsearch)
-  if install_and_deploy:
-    for cmd in [install_command, clean_repo_command]:
-      run(cmd)
-    rename_local_meta_files(localRepoElasticsearch)
-  else:
+
+  if not run_mvn_install:
     print('')
-    print('*** To create a release candidate run: ')
+    print('*** By choosing --no-install we assume you ran the following commands successfully:')
     print('  %s' % (install_command))
     print('  1. Remove all _remote.repositories: %s' % (clean_repo_command))
+    rename_metadata_files_command = 'for i in $(find %s -name "maven-metadata-local.xml*") ; do mv "$i" "${i/-local/}" ; done' % (localRepoElasticsearch)
     print('  2. Rename all maven metadata files: %s' % (rename_metadata_files_command))
+  else:
+    for cmd in [install_command, clean_repo_command]:
+      run(cmd)
+    rename_local_meta_files(localRepoElasticsearch)
 
-  print('Ensuring that RPM has been signed')
   rpm = '%s/distribution/rpm/elasticsearch/%s/elasticsearch-%s.rpm' % (localRepoElasticsearch, release_version, release_version)
+  print('Ensuring that RPM has been signed')
   ensure_rpm_is_signed(rpm, gpg_key)
 
   # repository push commands
-  s3cmd_sync_to_staging_bucket_cmd = 's3cmd sync -P %s s3://download.elasticsearch.org/elasticsearch/staging/%s-%s/org/' % (localRepoElasticsearch, release_version, shortHash)
-  s3_bucket_sync_to = 'download.elasticsearch.org/elasticsearch/staging/%s-%s/repos' % (release_version, shortHash)
+  s3cmd_sync_to_staging_bucket_cmd = 's3cmd sync -P %s s3://%s/elasticsearch/staging/%s-%s/org/' % (localRepoElasticsearch, bucket, release_version, shortHash)
+  s3_bucket_sync_to = '%s/elasticsearch/staging/%s-%s/repos/' % (bucket, release_version, shortHash)
   s3cmd_sync_official_repo_cmd = 's3cmd sync s3://packages.elasticsearch.org/elasticsearch/%s s3://%s' % (major_minor_version, s3_bucket_sync_to)
 
-  debs3_prefix = 'elasticsearch/staging/%s-%s/repos/debian' % (release_version, shortHash)
-  debs3_upload_cmd = 'deb-s3 upload --preserve-versions %s/distribution/deb/elasticsearch/%s/elasticsearch-%s.deb -b download.elasticsearch.org --prefix %s --sign %s --arch amd64' % (localRepoElasticsearch, release_version, release_version, prefix, gpg_key)
-  debs3_list_cmd = 'deb-s3 list -b download.elasticsearch.org --prefix %s' % (debs3_prefix)
-  debs3_verify_cmd = 'deb-s3 verify -b download.elasticsearch.org --prefix %s' % (debs3_prefix)
-  rpms3_prefix = 'elasticsearch/staging/%s-%s/repos/centos' % (release_version, shortHash)
-  rpms3_upload_cmd = 'rpm-s3 -v -b download.elasticsearch.org -p %s --sign --visibility public-read -k 0 %s' % (rpms3_prefix, rpm)
+  debs3_prefix = 'elasticsearch/staging/%s-%s/repos/%s/debian' % (release_version, shortHash, major_minor_version)
+  debs3_upload_cmd = 'deb-s3 upload --preserve-versions %s/distribution/deb/elasticsearch/%s/elasticsearch-%s.deb -b %s --prefix %s --sign %s --arch amd64' % (localRepoElasticsearch, release_version, release_version, bucket, debs3_prefix, gpg_key)
+  debs3_list_cmd = 'deb-s3 list -b %s --prefix %s' % (bucket, debs3_prefix)
+  debs3_verify_cmd = 'deb-s3 verify -b %s --prefix %s' % (bucket, debs3_prefix)
+  rpms3_prefix = 'elasticsearch/staging/%s-%s/repos/%s/centos' % (release_version, shortHash, major_minor_version)
+  rpms3_upload_cmd = 'rpm-s3 -v -b %s -p %s --sign --visibility public-read -k 0 %s' % (bucket, rpms3_prefix, rpm)
 
-  if push:
+  if deploy_s3:
     run(s3cmd_sync_to_staging_bucket_cmd)
-    print('Syncing official package repository into staging s3 bucket')
+  else:
+    print('')
+    print('*** To push a release candidate to s3 run: ')
+    print('  1. Sync %s into S3 bucket' % (localRepoElasticsearch))
+    print ('    %s' % (s3cmd_sync_to_staging_bucket_cmd))
+
+  if deploy_s3_repos:
+    print('*** Syncing official package repository into staging s3 bucket')
     run(s3cmd_sync_official_repo_cmd)
-    print('Uploading debian package (you will be prompted for the passphrase!)')
+    print('*** Uploading debian package (you will be prompted for the passphrase!)')
     run(debs3_upload_cmd)
     run(debs3_list_cmd)
     run(debs3_verify_cmd)
-    print('Uploading rpm package (you will be prompted for the passphrase!)')
+    print('*** Uploading rpm package (you will be prompted for the passphrase!)')
     run(rpms3_upload_cmd)
   else:
-    print('')
-    print('*** To push a release candidate to s3 run: ')
-    print('  1. Sync %s into S3 bucket' % (localRepoElasticsearch))
-    print ('    %s' % (s3cmd_sync_to_staging_bucket_cmd))
-    print('  2. Create repositories: ')
-    print('     1. Sync existing repo into staging: %s' % s3cmd_sync_official_repo_cmd)
-    print('     2. Upload debian package (and sign it) %s' % debs3_upload_cmd)
-    print('     3. List all debian packages: %s' % debs3_list_cmd)
-    print('     4. Verify debian packages: %s' % debs3_verify_cmd)
-    print('     5. Upload RPM: %s' % rpms3_upload_cmd)
+    print('*** To create repositories on S3 run:')
+    print('    1. Sync existing repo into staging: %s' % s3cmd_sync_official_repo_cmd)
+    print('    2. Upload debian package (and sign it): %s' % debs3_upload_cmd)
+    print('    3. List all debian packages: %s' % debs3_list_cmd)
+    print('    4. Verify debian packages: %s' % debs3_verify_cmd)
+    print('    5. Upload RPM: %s' % rpms3_upload_cmd)
     print('')
     print('NOTE: the above mvn command will promt you several times for the GPG passphrase of the key you specified you can alternatively pass it via -Dgpg.passphrase=yourPassPhrase')
     print(' since RPM signing doesn\'t support gpg-agents the recommended way to set the password is to add a release profile to your settings.xml:')
@@ -368,18 +395,19 @@ if __name__ == "__main__":
   </profiles>
     """)
     print('NOTE: Running s3cmd might require you to create a config file with your credentials, if the s3cmd does not support suppliying them via the command line!')
+
   print('*** Once the release is deployed and published send out the following mail to dev@elastic.co:')
-  string_format_dict = {'version' : release_version, 'hash': shortHash, 'major_minor_version' : major_minor_version}
+  string_format_dict = {'version' : release_version, 'hash': shortHash, 'major_minor_version' : major_minor_version, 'bucket': bucket}
   print(MAIL_TEMPLATE % string_format_dict)
 
   print('')
   print('You can verify that pushing to the staging repository pushed all the artifacts by running (log into sonatype to find out the correct id):')
-  print(' python3 -B dev-tools/validate-maven-repository.py %s https://oss.sonatype.org/service/local/repositories/orgelasticsearch-IDTOFINDOUT/content/org/elasticsearch ' %(localElasticsearchRepo))
+  print(' python -B dev-tools/validate-maven-repository.py %s https://oss.sonatype.org/service/local/repositories/orgelasticsearch-IDTOFINDOUT/content/org/elasticsearch ' %(localRepoElasticsearch))
 
   print('')
   print('To publish the release and the repo on S3 execute the following commands:')
-  print('   s3cmd cp --recursive s3://download.elasticsearch.org/elasticsearch/staging/%(version)s-%(hash)s/repos/%(major_minor_version)s/ s3://packages.elasticsearch.org/elasticsearch/%(major_minor_version)s'  % string_format_dict)
-  print('   s3cmd cp --recursive s3://download.elasticsearch.org/elasticsearch/staging/%(version)s-%(hash)s/org/ s3://download.elasticsearch.org/elasticsearch/release/org'  % string_format_dict)
+  print('   s3cmd cp --recursive s3://%(bucket)s/elasticsearch/staging/%(version)s-%(hash)s/repos/%(major_minor_version)s/ s3://packages.elasticsearch.org/elasticsearch/%(major_minor_version)s'  % string_format_dict)
+  print('   s3cmd cp --recursive s3://%(bucket)s/elasticsearch/staging/%(version)s-%(hash)s/org/ s3://%(bucket)s/elasticsearch/release/org'  % string_format_dict)
   print('Now go ahead and tag the release:')
   print('   git tag -a v%(version)s %(hash)s'  % string_format_dict)
   print('   git push origin v%(version)s' % string_format_dict )
diff --git a/dev-tools/src/main/resources/forbidden/all-signatures.txt b/dev-tools/src/main/resources/forbidden/all-signatures.txt
index cd87da1..613ed07 100644
--- a/dev-tools/src/main/resources/forbidden/all-signatures.txt
+++ b/dev-tools/src/main/resources/forbidden/all-signatures.txt
@@ -97,9 +97,7 @@ com.google.common.base.Strings
 com.google.common.base.Throwables
 com.google.common.collect.Maps
 com.google.common.collect.Sets
-com.google.common.base.Preconditions#checkNotNull(java.lang.Object)
-com.google.common.base.Preconditions#checkNotNull(java.lang.Object, java.lang.Object)
-com.google.common.base.Preconditions#checkNotNull(java.lang.Object, java.lang.String, java.lang.Object[])
+com.google.common.base.Preconditions
 com.google.common.collect.ImmutableSortedSet
 com.google.common.collect.Queues
 com.google.common.util.concurrent.ListenableFuture
@@ -112,7 +110,22 @@ com.google.common.base.Function
 com.google.common.collect.Collections2
 com.google.common.cache.LoadingCache
 com.google.common.cache.CacheLoader
+com.google.common.collect.Iterables
+com.google.common.util.concurrent.UncheckedExecutionException
+com.google.common.util.concurrent.AtomicLongMap
+com.google.common.primitives.Longs
+com.google.common.io.ByteStreams
+com.google.common.collect.UnmodifiableIterator
+com.google.common.collect.ObjectArrays
+com.google.common.collect.Multimap
+com.google.common.collect.MultimapBuilder
+com.google.common.math.LongMath
+com.google.common.base.Joiner
+com.google.common.collect.ArrayListMultimap
+com.google.common.collect.HashMultimap
+com.google.common.collect.FluentIterable
+com.google.common.io.Files
 
 @defaultMessage Do not violate java's access system
 java.lang.reflect.AccessibleObject#setAccessible(boolean)
-java.lang.reflect.AccessibleObject#setAccessible(java.lang.reflect.AccessibleObject[], boolean)
\ No newline at end of file
+java.lang.reflect.AccessibleObject#setAccessible(java.lang.reflect.AccessibleObject[], boolean)
diff --git a/distribution/src/main/resources/bin/plugin b/distribution/src/main/resources/bin/plugin
index 973d2f6..d2d112c 100755
--- a/distribution/src/main/resources/bin/plugin
+++ b/distribution/src/main/resources/bin/plugin
@@ -108,4 +108,4 @@ fi
 HOSTNAME=`hostname | cut -d. -f1`
 export HOSTNAME
 
-eval "$JAVA" $JAVA_OPTS $ES_JAVA_OPTS -Xmx64m -Xms16m -Delasticsearch -Des.path.home="\"$ES_HOME\"" $properties -cp "\"$ES_HOME/lib/*\"" org.elasticsearch.plugins.PluginManagerCliParser $args
+eval "$JAVA" -client -Delasticsearch -Des.path.home="\"$ES_HOME\"" $properties -cp "\"$ES_HOME/lib/*\"" org.elasticsearch.plugins.PluginManagerCliParser $args
diff --git a/distribution/src/main/resources/bin/plugin.bat b/distribution/src/main/resources/bin/plugin.bat
index a5e593c..5984089 100644
--- a/distribution/src/main/resources/bin/plugin.bat
+++ b/distribution/src/main/resources/bin/plugin.bat
@@ -11,7 +11,7 @@ TITLE Elasticsearch Plugin Manager ${project.version}
 
 SET HOSTNAME=%COMPUTERNAME%
 
-"%JAVA_HOME%\bin\java" %JAVA_OPTS% %ES_JAVA_OPTS% -Xmx64m -Xms16m -Des.path.home="%ES_HOME%" -cp "%ES_HOME%/lib/*;" "org.elasticsearch.plugins.PluginManagerCliParser" %*
+"%JAVA_HOME%\bin\java" -client -Des.path.home="%ES_HOME%" -cp "%ES_HOME%/lib/*;" "org.elasticsearch.plugins.PluginManagerCliParser" %*
 goto finally
 
 
diff --git a/plugins/analysis-icu/src/test/java/org/elasticsearch/index/analysis/AnalysisICURestIT.java b/plugins/analysis-icu/src/test/java/org/elasticsearch/index/analysis/AnalysisICURestIT.java
index 8da56d5..bfb2b96 100644
--- a/plugins/analysis-icu/src/test/java/org/elasticsearch/index/analysis/AnalysisICURestIT.java
+++ b/plugins/analysis-icu/src/test/java/org/elasticsearch/index/analysis/AnalysisICURestIT.java
@@ -21,14 +21,22 @@ package org.elasticsearch.index.analysis;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.analysis.icu.AnalysisICUPlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class AnalysisICURestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(AnalysisICUPlugin.class);
+    }
+
     public AnalysisICURestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/analysis-kuromoji/src/test/java/org/elasticsearch/index/analysis/AnalysisKuromojiRestIT.java b/plugins/analysis-kuromoji/src/test/java/org/elasticsearch/index/analysis/AnalysisKuromojiRestIT.java
index ae51e49..cb9435e 100644
--- a/plugins/analysis-kuromoji/src/test/java/org/elasticsearch/index/analysis/AnalysisKuromojiRestIT.java
+++ b/plugins/analysis-kuromoji/src/test/java/org/elasticsearch/index/analysis/AnalysisKuromojiRestIT.java
@@ -21,14 +21,23 @@ package org.elasticsearch.index.analysis;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.analysis.kuromoji.AnalysisKuromojiPlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class AnalysisKuromojiRestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(AnalysisKuromojiPlugin.class);
+    }
+
+
     public AnalysisKuromojiRestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/analysis-phonetic/src/test/java/org/elasticsearch/index/analysis/AnalysisPhoneticRestIT.java b/plugins/analysis-phonetic/src/test/java/org/elasticsearch/index/analysis/AnalysisPhoneticRestIT.java
index 9d66bf2..98380a0 100644
--- a/plugins/analysis-phonetic/src/test/java/org/elasticsearch/index/analysis/AnalysisPhoneticRestIT.java
+++ b/plugins/analysis-phonetic/src/test/java/org/elasticsearch/index/analysis/AnalysisPhoneticRestIT.java
@@ -21,14 +21,22 @@ package org.elasticsearch.index.analysis;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.analysis.AnalysisPhoneticPlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class AnalysisPhoneticRestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(AnalysisPhoneticPlugin.class);
+    }
+
     public AnalysisPhoneticRestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/analysis-smartcn/src/test/java/org/elasticsearch/index/analysis/AnalysisSmartChineseRestIT.java b/plugins/analysis-smartcn/src/test/java/org/elasticsearch/index/analysis/AnalysisSmartChineseRestIT.java
index 16113b2..2a76c21 100644
--- a/plugins/analysis-smartcn/src/test/java/org/elasticsearch/index/analysis/AnalysisSmartChineseRestIT.java
+++ b/plugins/analysis-smartcn/src/test/java/org/elasticsearch/index/analysis/AnalysisSmartChineseRestIT.java
@@ -21,14 +21,22 @@ package org.elasticsearch.index.analysis;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.analysis.smartcn.AnalysisSmartChinesePlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class AnalysisSmartChineseRestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(AnalysisSmartChinesePlugin.class);
+    }
+
     public AnalysisSmartChineseRestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/analysis-stempel/src/test/java/org/elasticsearch/index/analysis/AnalysisPolishRestIT.java b/plugins/analysis-stempel/src/test/java/org/elasticsearch/index/analysis/AnalysisPolishRestIT.java
index 330ad87..c99ff75 100644
--- a/plugins/analysis-stempel/src/test/java/org/elasticsearch/index/analysis/AnalysisPolishRestIT.java
+++ b/plugins/analysis-stempel/src/test/java/org/elasticsearch/index/analysis/AnalysisPolishRestIT.java
@@ -21,14 +21,22 @@ package org.elasticsearch.index.analysis;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.analysis.stempel.AnalysisStempelPlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class AnalysisPolishRestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(AnalysisStempelPlugin.class);
+    }
+
     public AnalysisPolishRestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/CloudAzureRestIT.java b/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/CloudAzureRestIT.java
index aac8f9d..be74381 100644
--- a/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/CloudAzureRestIT.java
+++ b/plugins/cloud-azure/src/test/java/org/elasticsearch/cloud/azure/CloudAzureRestIT.java
@@ -21,14 +21,22 @@ package org.elasticsearch.cloud.azure;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.cloud.azure.CloudAzurePlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class CloudAzureRestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(CloudAzurePlugin.class);
+    }
+
     public CloudAzureRestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/cloud-gce/src/test/java/org/elasticsearch/cloud/gce/CloudGCERestIT.java b/plugins/cloud-gce/src/test/java/org/elasticsearch/cloud/gce/CloudGCERestIT.java
index 644a2e4..e209655 100644
--- a/plugins/cloud-gce/src/test/java/org/elasticsearch/cloud/gce/CloudGCERestIT.java
+++ b/plugins/cloud-gce/src/test/java/org/elasticsearch/cloud/gce/CloudGCERestIT.java
@@ -21,14 +21,22 @@ package org.elasticsearch.cloud.gce;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.cloud.gce.CloudGcePlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class CloudGCERestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(CloudGcePlugin.class);
+    }
+
     public CloudGCERestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/delete-by-query/src/test/java/org/elasticsearch/plugin/deletebyquery/test/rest/DeleteByQueryRestIT.java b/plugins/delete-by-query/src/test/java/org/elasticsearch/plugin/deletebyquery/test/rest/DeleteByQueryRestIT.java
index 9674d54..038f117 100644
--- a/plugins/delete-by-query/src/test/java/org/elasticsearch/plugin/deletebyquery/test/rest/DeleteByQueryRestIT.java
+++ b/plugins/delete-by-query/src/test/java/org/elasticsearch/plugin/deletebyquery/test/rest/DeleteByQueryRestIT.java
@@ -21,14 +21,22 @@ package org.elasticsearch.plugin.deletebyquery.test.rest;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.deletebyquery.DeleteByQueryPlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class DeleteByQueryRestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(DeleteByQueryPlugin.class);
+    }
+
     public DeleteByQueryRestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/discovery-ec2/src/test/java/org/elasticsearch/cloud/aws/DiscoveryEc2RestIT.java b/plugins/discovery-ec2/src/test/java/org/elasticsearch/cloud/aws/DiscoveryEc2RestIT.java
index 24ccf82..57021a0 100644
--- a/plugins/discovery-ec2/src/test/java/org/elasticsearch/cloud/aws/DiscoveryEc2RestIT.java
+++ b/plugins/discovery-ec2/src/test/java/org/elasticsearch/cloud/aws/DiscoveryEc2RestIT.java
@@ -21,14 +21,22 @@ package org.elasticsearch.cloud.aws;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.discovery.ec2.Ec2DiscoveryPlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class DiscoveryEc2RestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(Ec2DiscoveryPlugin.class);
+    }
+
     public DiscoveryEc2RestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/discovery-multicast/src/test/java/org/elasticsearch/plugin/discovery/multicast/MulticastDiscoveryRestIT.java b/plugins/discovery-multicast/src/test/java/org/elasticsearch/plugin/discovery/multicast/MulticastDiscoveryRestIT.java
index c6af20c..d75c038 100644
--- a/plugins/discovery-multicast/src/test/java/org/elasticsearch/plugin/discovery/multicast/MulticastDiscoveryRestIT.java
+++ b/plugins/discovery-multicast/src/test/java/org/elasticsearch/plugin/discovery/multicast/MulticastDiscoveryRestIT.java
@@ -21,14 +21,21 @@ package org.elasticsearch.plugin.discovery.multicast;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class MulticastDiscoveryRestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(MulticastDiscoveryPlugin.class);
+    }
+
     public MulticastDiscoveryRestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/jvm-example/src/test/java/org/elasticsearch/plugin/example/JvmExampleRestIT.java b/plugins/jvm-example/src/test/java/org/elasticsearch/plugin/example/JvmExampleRestIT.java
index 74573a7..2e9039e 100644
--- a/plugins/jvm-example/src/test/java/org/elasticsearch/plugin/example/JvmExampleRestIT.java
+++ b/plugins/jvm-example/src/test/java/org/elasticsearch/plugin/example/JvmExampleRestIT.java
@@ -21,14 +21,21 @@ package org.elasticsearch.plugin.example;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class JvmExampleRestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(JvmExamplePlugin.class);
+    }
+
     public JvmExampleRestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/LangJavaScriptRestIT.java b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/LangJavaScriptRestIT.java
index 8039715..18f1837 100644
--- a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/LangJavaScriptRestIT.java
+++ b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/LangJavaScriptRestIT.java
@@ -21,14 +21,22 @@ package org.elasticsearch.script.javascript;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.javascript.JavaScriptPlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class LangJavaScriptRestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(JavaScriptPlugin.class);
+    }
+
     public LangJavaScriptRestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/lang-python/src/test/java/org/elasticsearch/script/python/LangPythonScriptRestIT.java b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/LangPythonScriptRestIT.java
index ee0a707..d7d0ca6 100644
--- a/plugins/lang-python/src/test/java/org/elasticsearch/script/python/LangPythonScriptRestIT.java
+++ b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/LangPythonScriptRestIT.java
@@ -21,14 +21,22 @@ package org.elasticsearch.script.python;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.python.PythonPlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class LangPythonScriptRestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(PythonPlugin.class);
+    }
+
     public LangPythonScriptRestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/mapper-murmur3/src/test/java/org/elasticsearch/index/mapper/murmur3/MapperMurmur3RestIT.java b/plugins/mapper-murmur3/src/test/java/org/elasticsearch/index/mapper/murmur3/MapperMurmur3RestIT.java
index f440a34..5dfc485 100644
--- a/plugins/mapper-murmur3/src/test/java/org/elasticsearch/index/mapper/murmur3/MapperMurmur3RestIT.java
+++ b/plugins/mapper-murmur3/src/test/java/org/elasticsearch/index/mapper/murmur3/MapperMurmur3RestIT.java
@@ -22,14 +22,22 @@ package org.elasticsearch.index.mapper.murmur3;
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
 
+import org.elasticsearch.plugin.mapper.MapperMurmur3Plugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class MapperMurmur3RestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(MapperMurmur3Plugin.class);
+    }
+
     public MapperMurmur3RestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/mapper-size/src/test/java/org/elasticsearch/index/mapper/size/MapperSizeRestIT.java b/plugins/mapper-size/src/test/java/org/elasticsearch/index/mapper/size/MapperSizeRestIT.java
index ec7e000..c267160 100644
--- a/plugins/mapper-size/src/test/java/org/elasticsearch/index/mapper/size/MapperSizeRestIT.java
+++ b/plugins/mapper-size/src/test/java/org/elasticsearch/index/mapper/size/MapperSizeRestIT.java
@@ -22,14 +22,22 @@ package org.elasticsearch.index.mapper.size;
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
 
+import org.elasticsearch.plugin.mapper.MapperSizePlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class MapperSizeRestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(MapperSizePlugin.class);
+    }
+
     public MapperSizeRestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }
diff --git a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/RepositoryS3RestIT.java b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/RepositoryS3RestIT.java
index d8e436b..8521780 100644
--- a/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/RepositoryS3RestIT.java
+++ b/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/RepositoryS3RestIT.java
@@ -21,14 +21,22 @@ package org.elasticsearch.repositories.s3;
 
 import com.carrotsearch.randomizedtesting.annotations.Name;
 import com.carrotsearch.randomizedtesting.annotations.ParametersFactory;
+import org.elasticsearch.plugin.repository.s3.S3RepositoryPlugin;
+import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.rest.ESRestTestCase;
 import org.elasticsearch.test.rest.RestTestCandidate;
 import org.elasticsearch.test.rest.parser.RestTestParseException;
 
 import java.io.IOException;
+import java.util.Collection;
 
 public class RepositoryS3RestIT extends ESRestTestCase {
 
+    @Override
+    protected Collection<Class<? extends Plugin>> nodePlugins() {
+        return pluginList(S3RepositoryPlugin.class);
+    }
+
     public RepositoryS3RestIT(@Name("yaml") RestTestCandidate testCandidate) {
         super(testCandidate);
     }

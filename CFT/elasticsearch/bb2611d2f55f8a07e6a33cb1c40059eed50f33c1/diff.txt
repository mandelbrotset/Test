diff --git a/core/pom.xml b/core/pom.xml
index 97c9bee..2a5f6de 100644
--- a/core/pom.xml
+++ b/core/pom.xml
@@ -314,45 +314,6 @@
                     </execution>
                 </executions>
             </plugin>
-            <plugin>
-                <groupId>de.thetaphi</groupId>
-                <artifactId>forbiddenapis</artifactId>
-                <version>1.8</version>
-
-                <executions>
-                    <execution>
-                        <id>check-forbidden-apis-in-cluster</id>
-                            <configuration>
-                                 <targetVersion>${maven.compiler.target}</targetVersion>
-                                 <!-- disallow undocumented classes like sun.misc.Unsafe: -->
-                                 <internalRuntimeForbidden>true</internalRuntimeForbidden>
-                                 <!-- if the used Java version is too new, don't fail, just do nothing: -->
-                                 <failOnUnsupportedJava>false</failOnUnsupportedJava>
-                                 <bundledSignatures>
-                                     <!-- This will automatically choose the right signatures based on 'targetVersion': -->
-                                     <bundledSignature>jdk-unsafe</bundledSignature>
-                                     <bundledSignature>jdk-deprecated</bundledSignature>
-                                     <bundledSignature>jdk-system-out</bundledSignature>
-                                 </bundledSignatures>
-                                 <signaturesFiles>
-                                      <signaturesFile>${elasticsearch.tools.directory}/forbidden/core-signatures.txt</signaturesFile>
-                                      <signaturesFile>${elasticsearch.tools.directory}/forbidden/all-signatures.txt</signaturesFile>
-                                      <signaturesFile>${elasticsearch.tools.directory}/forbidden/third-party-signatures.txt</signaturesFile>
-                                      <signaturesFile>${elasticsearch.tools.directory}/forbidden/cluster-signatures.txt</signaturesFile>
-                                 </signaturesFiles>
-                                 <signatures>${forbidden.signatures}</signatures>
-                                 <includes>
-                                     <include>org/elasticsearch/cluster/**/*.class</include>
-                                 </includes>
-                                 <suppressAnnotations><annotation>**.SuppressForbidden</annotation></suppressAnnotations>
-                             </configuration>
-                         <phase>compile</phase>
-                         <goals>
-                             <goal>check</goal>
-                         </goals>
-                     </execution>
-                 </executions>
-             </plugin>
         </plugins>
       <pluginManagement>
         <plugins>
@@ -396,22 +357,5 @@
             </activation>
             <!-- not including license-maven-plugin is sufficent to expose default license -->
         </profile>
-        <profile>
-            <id>dev</id>
-            <build>
-                <plugins>
-                    <plugin>
-                        <groupId>de.thetaphi</groupId>
-                        <artifactId>forbiddenapis</artifactId>
-                        <executions>
-                            <execution>
-                                <id>check-forbidden-apis-in-cluster</id>
-                                <phase>none</phase>
-                            </execution>
-                        </executions>
-                    </plugin>
-                </plugins>
-            </build>
-        </profile>
     </profiles>
 </project>
diff --git a/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java b/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
index 3ef6e5a..ca1524f 100644
--- a/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
+++ b/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java
@@ -19,19 +19,14 @@
 
 package org.apache.lucene.queryparser.classic;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.DisjunctionMaxQuery;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.MatchNoDocsQuery;
-import org.apache.lucene.search.MultiPhraseQuery;
-import org.apache.lucene.search.PhraseQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.search.*;
 import org.apache.lucene.util.automaton.RegExp;
+import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.unit.Fuzziness;
 import org.elasticsearch.index.mapper.MappedFieldType;
@@ -43,12 +38,9 @@ import org.elasticsearch.index.query.support.QueryParsers;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collection;
-import java.util.HashMap;
 import java.util.List;
-import java.util.Map;
 import java.util.Objects;
 
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfNeeded;
 
 /**
@@ -60,13 +52,13 @@ import static org.elasticsearch.common.lucene.search.Queries.fixNegativeQueryIfN
  */
 public class MapperQueryParser extends QueryParser {
 
-    public static final Map<String, FieldQueryExtension> FIELD_QUERY_EXTENSIONS;
+    public static final ImmutableMap<String, FieldQueryExtension> fieldQueryExtensions;
 
     static {
-        Map<String, FieldQueryExtension> fieldQueryExtensions = new HashMap<>();
-        fieldQueryExtensions.put(ExistsFieldQueryExtension.NAME, new ExistsFieldQueryExtension());
-        fieldQueryExtensions.put(MissingFieldQueryExtension.NAME, new MissingFieldQueryExtension());
-        FIELD_QUERY_EXTENSIONS = unmodifiableMap(fieldQueryExtensions);
+        fieldQueryExtensions = ImmutableMap.<String, FieldQueryExtension>builder()
+                .put(ExistsFieldQueryExtension.NAME, new ExistsFieldQueryExtension())
+                .put(MissingFieldQueryExtension.NAME, new MissingFieldQueryExtension())
+                .build();
     }
 
     private final QueryShardContext context;
@@ -132,7 +124,7 @@ public class MapperQueryParser extends QueryParser {
 
     @Override
     public Query getFieldQuery(String field, String queryText, boolean quoted) throws ParseException {
-        FieldQueryExtension fieldQueryExtension = FIELD_QUERY_EXTENSIONS.get(field);
+        FieldQueryExtension fieldQueryExtension = fieldQueryExtensions.get(field);
         if (fieldQueryExtension != null) {
             return fieldQueryExtension.query(context, queryText);
         }
@@ -548,7 +540,7 @@ public class MapperQueryParser extends QueryParser {
                     return newMatchAllDocsQuery();
                 }
                 // effectively, we check if a field exists or not
-                return FIELD_QUERY_EXTENSIONS.get(ExistsFieldQueryExtension.NAME).query(context, actualField);
+                return fieldQueryExtensions.get(ExistsFieldQueryExtension.NAME).query(context, actualField);
             }
         }
         if (lowercaseExpandedTerms) {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodeInfo.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodeInfo.java
index 2d68385..908a25a 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodeInfo.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodeInfo.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.action.admin.cluster.node.info;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Build;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.support.nodes.BaseNodeResponse;
@@ -35,11 +36,8 @@ import org.elasticsearch.threadpool.ThreadPoolInfo;
 import org.elasticsearch.transport.TransportInfo;
 
 import java.io.IOException;
-import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * Node information (static, does not change over time).
  */
@@ -77,7 +75,7 @@ public class NodeInfo extends BaseNodeResponse {
     NodeInfo() {
     }
 
-    public NodeInfo(Version version, Build build, DiscoveryNode node, @Nullable Map<String, String> serviceAttributes, @Nullable Settings settings,
+    public NodeInfo(Version version, Build build, DiscoveryNode node, @Nullable ImmutableMap<String, String> serviceAttributes, @Nullable Settings settings,
                     @Nullable OsInfo os, @Nullable ProcessInfo process, @Nullable JvmInfo jvm, @Nullable ThreadPoolInfo threadPool,
                     @Nullable TransportInfo transport, @Nullable HttpInfo http, @Nullable PluginsInfo plugins) {
         super(node);
@@ -188,12 +186,12 @@ public class NodeInfo extends BaseNodeResponse {
         version = Version.readVersion(in);
         build = Build.readBuild(in);
         if (in.readBoolean()) {
-            Map<String, String> builder = new HashMap<>();
+            ImmutableMap.Builder<String, String> builder = ImmutableMap.builder();
             int size = in.readVInt();
             for (int i = 0; i < size; i++) {
                 builder.put(in.readString(), in.readString());
             }
-            serviceAttributes = unmodifiableMap(builder);
+            serviceAttributes = builder.build();
         }
         if (in.readBoolean()) {
             settings = Settings.readSettingsFromStream(in);
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodesInfoResponse.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodesInfoResponse.java
index 108bb31..65033f3 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodesInfoResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodesInfoResponse.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.action.admin.cluster.node.info;
 
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
 import org.elasticsearch.action.support.nodes.BaseNodesResponse;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.common.io.stream.StreamInput;
@@ -87,8 +85,8 @@ public class NodesInfoResponse extends BaseNodesResponse<NodeInfo> implements To
 
             if (!nodeInfo.getNode().attributes().isEmpty()) {
                 builder.startObject("attributes");
-                for (ObjectObjectCursor<String, String> attr : nodeInfo.getNode().attributes()) {
-                    builder.field(attr.key, attr.value, XContentBuilder.FieldCaseConversion.NONE);
+                for (Map.Entry<String, String> attr : nodeInfo.getNode().attributes().entrySet()) {
+                    builder.field(attr.getKey(), attr.getValue(), XContentBuilder.FieldCaseConversion.NONE);
                 }
                 builder.endObject();
             }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/NodeStats.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/NodeStats.java
index 4cd050c..c437a44 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/NodeStats.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/NodeStats.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.action.admin.cluster.node.stats;
 
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
 import org.elasticsearch.action.support.nodes.BaseNodeResponse;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.Nullable;
@@ -40,6 +38,7 @@ import org.elasticsearch.threadpool.ThreadPoolStats;
 import org.elasticsearch.transport.TransportStats;
 
 import java.io.IOException;
+import java.util.Map;
 
 /**
  * Node statistics (dynamic, changes depending on when created).
@@ -282,8 +281,8 @@ public class NodeStats extends BaseNodeResponse implements ToXContent {
 
             if (!getNode().attributes().isEmpty()) {
                 builder.startObject("attributes");
-                for (ObjectObjectCursor<String, String> attr : getNode().attributes()) {
-                    builder.field(attr.key, attr.value, XContentBuilder.FieldCaseConversion.NONE);
+                for (Map.Entry<String, String> attr : getNode().attributes().entrySet()) {
+                    builder.field(attr.getKey(), attr.getValue(), XContentBuilder.FieldCaseConversion.NONE);
                 }
                 builder.endObject();
             }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotIndexStatus.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotIndexStatus.java
index 5999fc3..961914e 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotIndexStatus.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotIndexStatus.java
@@ -19,18 +19,16 @@
 
 package org.elasticsearch.action.admin.cluster.snapshots.status;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentBuilderString;
 
 import java.io.IOException;
 import java.util.Collection;
-import java.util.HashMap;
 import java.util.Iterator;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * Represents snapshot status of all shards in the index
  */
@@ -47,14 +45,14 @@ public class SnapshotIndexStatus implements Iterable<SnapshotIndexShardStatus>,
     SnapshotIndexStatus(String index, Collection<SnapshotIndexShardStatus> shards) {
         this.index = index;
 
-        Map<Integer, SnapshotIndexShardStatus> indexShards = new HashMap<>();
+        ImmutableMap.Builder<Integer, SnapshotIndexShardStatus> builder = ImmutableMap.builder();
         stats = new SnapshotStats();
         for (SnapshotIndexShardStatus shard : shards) {
-            indexShards.put(shard.getShardId(), shard);
+            builder.put(shard.getShardId(), shard);
             stats.add(shard.getStats());
         }
         shardsStats = new SnapshotShardsStats(shards);
-        this.indexShards = unmodifiableMap(indexShards);
+        indexShards = builder.build();
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java
index 860b414..91b890b 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/SnapshotStatus.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.action.admin.cluster.snapshots.status;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.cluster.SnapshotsInProgress.State;
 import org.elasticsearch.cluster.metadata.SnapshotId;
 import org.elasticsearch.common.io.stream.StreamInput;
@@ -32,14 +33,11 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * Status of a snapshot
  */
@@ -51,7 +49,7 @@ public class SnapshotStatus implements ToXContent, Streamable {
 
     private List<SnapshotIndexShardStatus> shards;
 
-    private Map<String, SnapshotIndexStatus> indicesStatus;
+    private ImmutableMap<String, SnapshotIndexStatus> indicesStatus;
 
     private SnapshotShardsStats shardsStats;
 
@@ -102,7 +100,7 @@ public class SnapshotStatus implements ToXContent, Streamable {
             return this.indicesStatus;
         }
 
-        Map<String, SnapshotIndexStatus> indicesStatus = new HashMap<>();
+        ImmutableMap.Builder<String, SnapshotIndexStatus> indicesStatus = ImmutableMap.builder();
 
         Set<String> indices = new HashSet<>();
         for (SnapshotIndexShardStatus shard : shards) {
@@ -118,7 +116,7 @@ public class SnapshotStatus implements ToXContent, Streamable {
             }
             indicesStatus.put(index, new SnapshotIndexStatus(index, shards));
         }
-        this.indicesStatus = unmodifiableMap(indicesStatus);
+        this.indicesStatus = indicesStatus.build();
         return this.indicesStatus;
 
     }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java
index 0f9bd67..5af92dc 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/snapshots/status/TransportSnapshotsStatusAction.java
@@ -19,10 +19,7 @@
 
 package org.elasticsearch.action.admin.cluster.snapshots.status;
 
-import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
 import com.google.common.collect.ImmutableMap;
-
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.ActionFilters;
 import org.elasticsearch.action.support.master.TransportMasterNodeAction;
@@ -98,9 +95,9 @@ public class TransportSnapshotsStatusAction extends TransportMasterNodeAction<Sn
 
         Set<String> nodesIds = new HashSet<>();
         for (SnapshotsInProgress.Entry entry : currentSnapshots) {
-            for (ObjectCursor<SnapshotsInProgress.ShardSnapshotStatus> status : entry.shards().values()) {
-                if (status.value.nodeId() != null) {
-                    nodesIds.add(status.value.nodeId());
+            for (SnapshotsInProgress.ShardSnapshotStatus status : entry.shards().values()) {
+                if (status.nodeId() != null) {
+                    nodesIds.add(status.nodeId());
                 }
             }
         }
@@ -154,15 +151,15 @@ public class TransportSnapshotsStatusAction extends TransportMasterNodeAction<Sn
             for (SnapshotsInProgress.Entry entry : currentSnapshots) {
                 currentSnapshotIds.add(entry.snapshotId());
                 List<SnapshotIndexShardStatus> shardStatusBuilder = new ArrayList<>();
-                for (ObjectObjectCursor<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shardEntry : entry.shards()) {
-                    SnapshotsInProgress.ShardSnapshotStatus status = shardEntry.value;
+                for (ImmutableMap.Entry<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shardEntry : entry.shards().entrySet()) {
+                    SnapshotsInProgress.ShardSnapshotStatus status = shardEntry.getValue();
                     if (status.nodeId() != null) {
                         // We should have information about this shard from the shard:
                         TransportNodesSnapshotsStatus.NodeSnapshotStatus nodeStatus = nodeSnapshotStatusMap.get(status.nodeId());
                         if (nodeStatus != null) {
                             Map<ShardId, SnapshotIndexShardStatus> shardStatues = nodeStatus.status().get(entry.snapshotId());
                             if (shardStatues != null) {
-                                SnapshotIndexShardStatus shardStatus = shardStatues.get(shardEntry.key);
+                                SnapshotIndexShardStatus shardStatus = shardStatues.get(shardEntry.getKey());
                                 if (shardStatus != null) {
                                     // We have full information about this shard
                                     shardStatusBuilder.add(shardStatus);
@@ -172,7 +169,7 @@ public class TransportSnapshotsStatusAction extends TransportMasterNodeAction<Sn
                         }
                     }
                     final SnapshotIndexShardStage stage;
-                    switch (shardEntry.value.state()) {
+                    switch (shardEntry.getValue().state()) {
                         case FAILED:
                         case ABORTED:
                         case MISSING:
@@ -187,9 +184,9 @@ public class TransportSnapshotsStatusAction extends TransportMasterNodeAction<Sn
                             stage = SnapshotIndexShardStage.DONE;
                             break;
                         default:
-                            throw new IllegalArgumentException("Unknown snapshot state " + shardEntry.value.state());
+                            throw new IllegalArgumentException("Unknown snapshot state " + shardEntry.getValue().state());
                     }
-                    SnapshotIndexShardStatus shardStatus = new SnapshotIndexShardStatus(shardEntry.key, stage);
+                    SnapshotIndexShardStatus shardStatus = new SnapshotIndexShardStatus(shardEntry.getKey(), stage);
                     shardStatusBuilder.add(shardStatus);
                 }
                 builder.add(new SnapshotStatus(entry.snapshotId(), entry.state(), Collections.unmodifiableList(shardStatusBuilder)));
diff --git a/core/src/main/java/org/elasticsearch/action/admin/cluster/state/TransportClusterStateAction.java b/core/src/main/java/org/elasticsearch/action/admin/cluster/state/TransportClusterStateAction.java
index a3708f6..54ea5a9 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/cluster/state/TransportClusterStateAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/cluster/state/TransportClusterStateAction.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.action.admin.cluster.state;
 
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.support.ActionFilters;
 import org.elasticsearch.action.support.master.TransportMasterNodeReadAction;
@@ -90,7 +89,7 @@ public class TransportClusterStateAction extends TransportMasterNodeReadAction<C
                         routingTableBuilder.add(currentState.routingTable().getIndicesRouting().get(filteredIndex));
                     }
                 }
-                builder.routingTable(routingTableBuilder.build());
+                builder.routingTable(routingTableBuilder);
             } else {
                 builder.routingTable(currentState.routingTable());
             }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/GetFieldMappingsResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/GetFieldMappingsResponse.java
index 12ef72b..24820ba 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/GetFieldMappingsResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/GetFieldMappingsResponse.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.action.admin.indices.mapping.get;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.action.ActionResponse;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.bytes.BytesReference;
@@ -33,13 +35,12 @@ import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
 import static java.util.Collections.unmodifiableMap;
 
 /** Response object for {@link GetFieldMappingsRequest} API */
 public class GetFieldMappingsResponse extends ActionResponse implements ToXContent {
 
-    private Map<String, Map<String, Map<String, FieldMappingMetaData>>> mappings = emptyMap();
+    private Map<String, Map<String, Map<String, FieldMappingMetaData>>> mappings = ImmutableMap.of();
 
     GetFieldMappingsResponse(Map<String, Map<String, Map<String, FieldMappingMetaData>>> mappings) {
         this.mappings = mappings;
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsAction.java
index 82d6c21..060d94a 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsAction.java
@@ -25,18 +25,16 @@ import org.elasticsearch.action.support.HandledTransportAction;
 import org.elasticsearch.cluster.ClusterService;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
-import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicReferenceArray;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  */
 public class TransportGetFieldMappingsAction extends HandledTransportAction<GetFieldMappingsRequest, GetFieldMappingsResponse> {
@@ -90,7 +88,7 @@ public class TransportGetFieldMappingsAction extends HandledTransportAction<GetF
     }
 
     private GetFieldMappingsResponse merge(AtomicReferenceArray<Object> indexResponses) {
-        Map<String, Map<String, Map<String, GetFieldMappingsResponse.FieldMappingMetaData>>> mergedResponses = new HashMap<>();
+        MapBuilder<String, Map<String, Map<String, GetFieldMappingsResponse.FieldMappingMetaData>>> mergedResponses = MapBuilder.newMapBuilder();
         for (int i = 0; i < indexResponses.length(); i++) {
             Object element = indexResponses.get(i);
             if (element instanceof GetFieldMappingsResponse) {
@@ -98,6 +96,6 @@ public class TransportGetFieldMappingsAction extends HandledTransportAction<GetF
                 mergedResponses.putAll(response.mappings());
             }
         }
-        return new GetFieldMappingsResponse(unmodifiableMap(mergedResponses));
+        return new GetFieldMappingsResponse(mergedResponses.immutableMap());
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsIndexAction.java b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsIndexAction.java
index c71f60e..a7b780a 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsIndexAction.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/mapping/get/TransportGetFieldMappingsIndexAction.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.action.admin.indices.mapping.get;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.admin.indices.mapping.get.GetFieldMappingsResponse.FieldMappingMetaData;
 import org.elasticsearch.action.support.ActionFilters;
@@ -54,7 +56,6 @@ import java.util.Iterator;
 import java.util.Map;
 import java.util.stream.Collectors;
 
-import static java.util.Collections.singletonMap;
 import static org.elasticsearch.common.util.CollectionUtils.newLinkedList;
 
 /**
@@ -109,13 +110,13 @@ public class TransportGetFieldMappingsIndexAction extends TransportSingleShardAc
         MapBuilder<String, Map<String, FieldMappingMetaData>> typeMappings = new MapBuilder<>();
         for (String type : typeIntersection) {
             DocumentMapper documentMapper = indexService.mapperService().documentMapper(type);
-            Map<String, FieldMappingMetaData> fieldMapping = findFieldMappingsByType(documentMapper, request);
+            ImmutableMap<String, FieldMappingMetaData> fieldMapping = findFieldMappingsByType(documentMapper, request);
             if (!fieldMapping.isEmpty()) {
                 typeMappings.put(type, fieldMapping);
             }
         }
 
-        return new GetFieldMappingsResponse(singletonMap(shardId.getIndex(), typeMappings.immutableMap()));
+        return new GetFieldMappingsResponse(ImmutableMap.of(shardId.getIndex(), typeMappings.immutableMap()));
     }
 
     @Override
@@ -165,7 +166,7 @@ public class TransportGetFieldMappingsIndexAction extends TransportSingleShardAc
         }
     };
 
-    private Map<String, FieldMappingMetaData> findFieldMappingsByType(DocumentMapper documentMapper, GetFieldMappingsIndexRequest request) {
+    private ImmutableMap<String, FieldMappingMetaData> findFieldMappingsByType(DocumentMapper documentMapper, GetFieldMappingsIndexRequest request) {
         MapBuilder<String, FieldMappingMetaData> fieldMappings = new MapBuilder<>();
         final DocumentFieldMappers allFieldMappers = documentMapper.mappers();
         for (String field : request.fields()) {
diff --git a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java
index 4f427b5..5cb94b2 100644
--- a/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java
+++ b/core/src/main/java/org/elasticsearch/action/admin/indices/stats/IndicesStatsResponse.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.action.admin.indices.stats;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.action.ShardOperationFailedException;
 import org.elasticsearch.action.support.broadcast.BroadcastResponse;
 import org.elasticsearch.cluster.routing.ShardRouting;
@@ -37,15 +38,13 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  */
 public class IndicesStatsResponse extends BroadcastResponse implements ToXContent {
 
     private ShardStats[] shards;
 
-    private Map<ShardRouting, CommonStats> shardStatsMap;
+    private ImmutableMap<ShardRouting, CommonStats> shardStatsMap;
 
     IndicesStatsResponse() {
 
@@ -56,15 +55,16 @@ public class IndicesStatsResponse extends BroadcastResponse implements ToXConten
         this.shards = shards;
     }
 
-    public Map<ShardRouting, CommonStats> asMap() {
-        if (this.shardStatsMap == null) {
-            Map<ShardRouting, CommonStats> shardStatsMap = new HashMap<>();
+    public ImmutableMap<ShardRouting, CommonStats> asMap() {
+        if (shardStatsMap == null) {
+            ImmutableMap.Builder<ShardRouting, CommonStats> mb = ImmutableMap.builder();
             for (ShardStats ss : shards) {
-                shardStatsMap.put(ss.getShardRouting(), ss.getStats());
+                mb.put(ss.getShardRouting(), ss.getStats());
             }
-            this.shardStatsMap = unmodifiableMap(shardStatsMap);
+
+            shardStatsMap = mb.build();
         }
-        return this.shardStatsMap;
+        return shardStatsMap;
     }
 
     public ShardStats[] getShards() {
diff --git a/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java b/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java
index 2b99b6f..e4472c7 100644
--- a/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java
+++ b/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchHelper.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.action.search.type;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.elasticsearch.action.search.SearchRequest;
@@ -37,8 +38,6 @@ import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-
 /**
  *
  */
@@ -113,7 +112,7 @@ public abstract class TransportSearchHelper {
         Map<String, String> attributes;
         int attributesSize = Integer.parseInt(elements[index++]);
         if (attributesSize == 0) {
-            attributes = emptyMap();
+            attributes = ImmutableMap.of();
         } else {
             attributes = new HashMap<>(attributesSize);
             for (int i = 0; i < attributesSize; i++) {
diff --git a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
index 5b8c14a..542444b 100644
--- a/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
+++ b/core/src/main/java/org/elasticsearch/bootstrap/Bootstrap.java
@@ -195,7 +195,7 @@ final class Bootstrap {
     private static void setupLogging(Settings settings, Environment environment) {
         try {
             Class.forName("org.apache.log4j.Logger");
-            LogConfigurator.configure(settings);
+            LogConfigurator.configure(settings, true);
         } catch (ClassNotFoundException e) {
             // no log4j
         } catch (NoClassDefFoundError e) {
diff --git a/core/src/main/java/org/elasticsearch/client/node/NodeClient.java b/core/src/main/java/org/elasticsearch/client/node/NodeClient.java
index 1110839..deb3e5b 100644
--- a/core/src/main/java/org/elasticsearch/client/node/NodeClient.java
+++ b/core/src/main/java/org/elasticsearch/client/node/NodeClient.java
@@ -30,19 +30,17 @@ import org.elasticsearch.threadpool.ThreadPool;
 
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  *
  */
 public class NodeClient extends AbstractClient {
 
-    private final Map<GenericAction, TransportAction> actions;
+    private final ImmutableMap<GenericAction, TransportAction> actions;
 
     @Inject
     public NodeClient(Settings settings, ThreadPool threadPool, Headers headers, Map<GenericAction, TransportAction> actions) {
         super(settings, threadPool, headers);
-        this.actions = unmodifiableMap(actions);
+        this.actions = ImmutableMap.copyOf(actions);
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/client/transport/support/TransportProxyClient.java b/core/src/main/java/org/elasticsearch/client/transport/support/TransportProxyClient.java
index 9008764..89b3a04 100644
--- a/core/src/main/java/org/elasticsearch/client/transport/support/TransportProxyClient.java
+++ b/core/src/main/java/org/elasticsearch/client/transport/support/TransportProxyClient.java
@@ -19,42 +19,35 @@
 
 package org.elasticsearch.client.transport.support;
 
-import org.elasticsearch.action.Action;
-import org.elasticsearch.action.ActionListener;
-import org.elasticsearch.action.ActionRequest;
-import org.elasticsearch.action.ActionRequestBuilder;
-import org.elasticsearch.action.ActionResponse;
-import org.elasticsearch.action.GenericAction;
-import org.elasticsearch.action.TransportActionNodeProxy;
+import com.google.common.collect.ImmutableMap;
+import org.elasticsearch.action.*;
 import org.elasticsearch.client.transport.TransportClientNodesService;
 import org.elasticsearch.cluster.node.DiscoveryNode;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.transport.TransportService;
 
-import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  *
  */
 public class TransportProxyClient {
 
     private final TransportClientNodesService nodesService;
-    private final Map<Action, TransportActionNodeProxy> proxies;
+    private final ImmutableMap<Action, TransportActionNodeProxy> proxies;
 
     @Inject
     public TransportProxyClient(Settings settings, TransportService transportService, TransportClientNodesService nodesService, Map<String, GenericAction> actions) {
         this.nodesService = nodesService;
-        Map<Action, TransportActionNodeProxy> proxies = new HashMap<>();
+        MapBuilder<Action, TransportActionNodeProxy> actionsBuilder = new MapBuilder<>();
         for (GenericAction action : actions.values()) {
             if (action instanceof Action) {
-                proxies.put((Action) action, new TransportActionNodeProxy(settings, action, transportService));
+                actionsBuilder.put((Action) action, new TransportActionNodeProxy(settings, action, transportService));
             }
         }
-        this.proxies = unmodifiableMap(proxies);
+        this.proxies = actionsBuilder.immutableMap();
     }
 
     public <Request extends ActionRequest, Response extends ActionResponse, RequestBuilder extends ActionRequestBuilder<Request, Response, RequestBuilder>> void execute(final Action<Request, Response, RequestBuilder> action, final Request request, ActionListener<Response> listener) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/ClusterInfo.java b/core/src/main/java/org/elasticsearch/cluster/ClusterInfo.java
index 265ab0f..f10a40b 100644
--- a/core/src/main/java/org/elasticsearch/cluster/ClusterInfo.java
+++ b/core/src/main/java/org/elasticsearch/cluster/ClusterInfo.java
@@ -20,7 +20,9 @@
 package org.elasticsearch.cluster;
 
 import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
+
+import java.util.Collections;
+import java.util.Map;
 
 /**
  * ClusterInfo is an object representing a map of nodes to {@link DiskUsage}
@@ -29,14 +31,15 @@ import org.elasticsearch.common.collect.ImmutableOpenMap;
  * for the key used in the shardSizes map
  */
 public class ClusterInfo {
-    private final ImmutableOpenMap<String, DiskUsage> leastAvailableSpaceUsage;
-    private final ImmutableOpenMap<String, DiskUsage> mostAvailableSpaceUsage;
-    final ImmutableOpenMap<String, Long> shardSizes;
+
+    private final Map<String, DiskUsage> leastAvailableSpaceUsage;
+    private final Map<String, DiskUsage> mostAvailableSpaceUsage;
+    final Map<String, Long> shardSizes;
     public static final ClusterInfo EMPTY = new ClusterInfo();
-    private final ImmutableOpenMap<ShardRouting, String> routingToDataPath;
+    private final Map<ShardRouting, String> routingToDataPath;
 
     protected ClusterInfo() {
-       this(ImmutableOpenMap.of(), ImmutableOpenMap.of(), ImmutableOpenMap.of(), ImmutableOpenMap.of());
+       this(Collections.EMPTY_MAP, Collections.EMPTY_MAP, Collections.EMPTY_MAP, Collections.EMPTY_MAP);
     }
 
     /**
@@ -48,9 +51,7 @@ public class ClusterInfo {
      * @param routingToDataPath the shard routing to datapath mapping
      * @see #shardIdentifierFromRouting
      */
-    public ClusterInfo(ImmutableOpenMap<String, DiskUsage> leastAvailableSpaceUsage,
-            ImmutableOpenMap<String, DiskUsage> mostAvailableSpaceUsage, ImmutableOpenMap<String, Long> shardSizes,
-            ImmutableOpenMap<ShardRouting, String> routingToDataPath) {
+    public ClusterInfo(final Map<String, DiskUsage> leastAvailableSpaceUsage, final Map<String, DiskUsage> mostAvailableSpaceUsage, final Map<String, Long> shardSizes, Map<ShardRouting, String> routingToDataPath) {
         this.leastAvailableSpaceUsage = leastAvailableSpaceUsage;
         this.shardSizes = shardSizes;
         this.mostAvailableSpaceUsage = mostAvailableSpaceUsage;
@@ -60,14 +61,14 @@ public class ClusterInfo {
     /**
      * Returns a node id to disk usage mapping for the path that has the least available space on the node.
      */
-    public ImmutableOpenMap<String, DiskUsage> getNodeLeastAvailableDiskUsages() {
+    public Map<String, DiskUsage> getNodeLeastAvailableDiskUsages() {
         return this.leastAvailableSpaceUsage;
     }
 
     /**
      * Returns a node id to disk usage mapping for the path that has the most available space on the node.
      */
-    public ImmutableOpenMap<String, DiskUsage> getNodeMostAvailableDiskUsages() {
+    public Map<String, DiskUsage> getNodeMostAvailableDiskUsages() {
         return this.mostAvailableSpaceUsage;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/cluster/ClusterState.java b/core/src/main/java/org/elasticsearch/cluster/ClusterState.java
index b1bdf52..8167ecc 100644
--- a/core/src/main/java/org/elasticsearch/cluster/ClusterState.java
+++ b/core/src/main/java/org/elasticsearch/cluster/ClusterState.java
@@ -389,9 +389,9 @@ public class ClusterState implements ToXContent, Diffable<ClusterState> {
 
             if (!blocks().indices().isEmpty()) {
                 builder.startObject("indices");
-                for (ObjectObjectCursor<String, Set<ClusterBlock>> entry : blocks().indices()) {
-                    builder.startObject(entry.key);
-                    for (ClusterBlock block : entry.value) {
+                for (Map.Entry<String, Set<ClusterBlock>> entry : blocks().indices().entrySet()) {
+                    builder.startObject(entry.getKey());
+                    for (ClusterBlock block : entry.getValue()) {
                         block.toXContent(builder, params);
                     }
                     builder.endObject();
@@ -591,6 +591,10 @@ public class ClusterState implements ToXContent, Diffable<ClusterState> {
             return this;
         }
 
+        public Builder routingTable(RoutingTable.Builder routingTable) {
+            return routingTable(routingTable.build());
+        }
+
         public Builder routingResult(RoutingAllocation.Result routingResult) {
             this.routingTable = routingResult.routingTable();
             return this;
diff --git a/core/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java b/core/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java
index 039868d..019e245 100644
--- a/core/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/InternalClusterInfoService.java
@@ -33,7 +33,6 @@ import org.elasticsearch.cluster.block.ClusterBlockException;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.logging.ESLogger;
@@ -45,7 +44,10 @@ import org.elasticsearch.node.settings.NodeSettingsService;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.ReceiveTimeoutTransportException;
 
+import java.util.Collections;
+import java.util.HashMap;
 import java.util.List;
+import java.util.Map;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
@@ -68,10 +70,10 @@ public class InternalClusterInfoService extends AbstractComponent implements Clu
 
     private volatile TimeValue updateFrequency;
 
-    private volatile ImmutableOpenMap<String, DiskUsage> leastAvailableSpaceUsages;
-    private volatile ImmutableOpenMap<String, DiskUsage> mostAvailableSpaceUsages;
-    private volatile ImmutableOpenMap<ShardRouting, String> shardRoutingToDataPath;
-    private volatile ImmutableOpenMap<String, Long> shardSizes;
+    private volatile Map<String, DiskUsage> leastAvailableSpaceUsages;
+    private volatile Map<String, DiskUsage> mostAvailableSpaceUsages;
+    private volatile Map<ShardRouting, String> shardRoutingToDataPath;
+    private volatile Map<String, Long> shardSizes;
     private volatile boolean isMaster = false;
     private volatile boolean enabled;
     private volatile TimeValue fetchTimeout;
@@ -87,10 +89,10 @@ public class InternalClusterInfoService extends AbstractComponent implements Clu
                                       TransportIndicesStatsAction transportIndicesStatsAction, ClusterService clusterService,
                                       ThreadPool threadPool) {
         super(settings);
-        this.leastAvailableSpaceUsages = ImmutableOpenMap.of();
-        this.mostAvailableSpaceUsages = ImmutableOpenMap.of();
-        this.shardRoutingToDataPath = ImmutableOpenMap.of();
-        this.shardSizes = ImmutableOpenMap.of();
+        this.leastAvailableSpaceUsages = Collections.emptyMap();
+        this.mostAvailableSpaceUsages = Collections.emptyMap();
+        this.shardRoutingToDataPath = Collections.emptyMap();
+        this.shardSizes = Collections.emptyMap();
         this.transportNodesStatsAction = transportNodesStatsAction;
         this.transportIndicesStatsAction = transportIndicesStatsAction;
         this.clusterService = clusterService;
@@ -196,14 +198,14 @@ public class InternalClusterInfoService extends AbstractComponent implements Clu
                         logger.trace("Removing node from cluster info: {}", removedNode.getId());
                     }
                     if (leastAvailableSpaceUsages.containsKey(removedNode.getId())) {
-                        ImmutableOpenMap.Builder<String, DiskUsage> newMaxUsages = ImmutableOpenMap.builder(leastAvailableSpaceUsages);
+                        Map<String, DiskUsage> newMaxUsages = new HashMap<>(leastAvailableSpaceUsages);
                         newMaxUsages.remove(removedNode.getId());
-                        leastAvailableSpaceUsages = newMaxUsages.build();
+                        leastAvailableSpaceUsages = Collections.unmodifiableMap(newMaxUsages);
                     }
                     if (mostAvailableSpaceUsages.containsKey(removedNode.getId())) {
-                        ImmutableOpenMap.Builder<String, DiskUsage> newMinUsages = ImmutableOpenMap.builder(mostAvailableSpaceUsages);
+                        Map<String, DiskUsage> newMinUsages = new HashMap<>(mostAvailableSpaceUsages);
                         newMinUsages.remove(removedNode.getId());
-                        mostAvailableSpaceUsages = newMinUsages.build();
+                        mostAvailableSpaceUsages = Collections.unmodifiableMap(newMinUsages);
                     }
                 }
             }
@@ -307,11 +309,11 @@ public class InternalClusterInfoService extends AbstractComponent implements Clu
         final CountDownLatch nodeLatch = updateNodeStats(new ActionListener<NodesStatsResponse>() {
             @Override
             public void onResponse(NodesStatsResponse nodeStatses) {
-                ImmutableOpenMap.Builder<String, DiskUsage> newLeastAvaiableUsages = ImmutableOpenMap.builder();
-                ImmutableOpenMap.Builder<String, DiskUsage> newMostAvaiableUsages = ImmutableOpenMap.builder();
+                Map<String, DiskUsage> newLeastAvaiableUsages = new HashMap<>();
+                Map<String, DiskUsage> newMostAvaiableUsages = new HashMap<>();
                 fillDiskUsagePerNode(logger, nodeStatses.getNodes(), newLeastAvaiableUsages, newMostAvaiableUsages);
-                leastAvailableSpaceUsages = newLeastAvaiableUsages.build();
-                mostAvailableSpaceUsages = newMostAvaiableUsages.build();
+                leastAvailableSpaceUsages = Collections.unmodifiableMap(newLeastAvaiableUsages);
+                mostAvailableSpaceUsages = Collections.unmodifiableMap(newMostAvaiableUsages);
             }
 
             @Override
@@ -327,8 +329,8 @@ public class InternalClusterInfoService extends AbstractComponent implements Clu
                         logger.warn("Failed to execute NodeStatsAction for ClusterInfoUpdateJob", e);
                     }
                     // we empty the usages list, to be safe - we don't know what's going on.
-                    leastAvailableSpaceUsages = ImmutableOpenMap.of();
-                    mostAvailableSpaceUsages = ImmutableOpenMap.of();
+                    leastAvailableSpaceUsages = Collections.emptyMap();
+                    mostAvailableSpaceUsages = Collections.emptyMap();
                 }
             }
         });
@@ -337,11 +339,11 @@ public class InternalClusterInfoService extends AbstractComponent implements Clu
             @Override
             public void onResponse(IndicesStatsResponse indicesStatsResponse) {
                 ShardStats[] stats = indicesStatsResponse.getShards();
-                ImmutableOpenMap.Builder<String, Long> newShardSizes = ImmutableOpenMap.builder();
-                ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath = ImmutableOpenMap.builder();
+                final HashMap<String, Long> newShardSizes = new HashMap<>();
+                final HashMap<ShardRouting, String> newShardRoutingToDataPath = new HashMap<>();
                 buildShardLevelInfo(logger, stats, newShardSizes, newShardRoutingToDataPath);
-                shardSizes = newShardSizes.build();
-                shardRoutingToDataPath = newShardRoutingToDataPath.build();
+                shardSizes = Collections.unmodifiableMap(newShardSizes);
+                shardRoutingToDataPath = Collections.unmodifiableMap(newShardRoutingToDataPath);
             }
 
             @Override
@@ -357,8 +359,8 @@ public class InternalClusterInfoService extends AbstractComponent implements Clu
                         logger.warn("Failed to execute IndicesStatsAction for ClusterInfoUpdateJob", e);
                     }
                     // we empty the usages list, to be safe - we don't know what's going on.
-                    shardSizes = ImmutableOpenMap.of();
-                    shardRoutingToDataPath = ImmutableOpenMap.of();
+                    shardSizes = Collections.emptyMap();
+                    shardRoutingToDataPath = Collections.emptyMap();
                 }
             }
         });
@@ -387,8 +389,7 @@ public class InternalClusterInfoService extends AbstractComponent implements Clu
         return clusterInfo;
     }
 
-    static void buildShardLevelInfo(ESLogger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> newShardSizes,
-            ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath) {
+    static void buildShardLevelInfo(ESLogger logger, ShardStats[] stats, HashMap<String, Long> newShardSizes, HashMap<ShardRouting, String> newShardRoutingToDataPath) {
         for (ShardStats s : stats) {
             newShardRoutingToDataPath.put(s.getShardRouting(), s.getDataPath());
             long size = s.getStats().getStore().sizeInBytes();
@@ -400,9 +401,7 @@ public class InternalClusterInfoService extends AbstractComponent implements Clu
         }
     }
 
-    static void fillDiskUsagePerNode(ESLogger logger, NodeStats[] nodeStatsArray,
-            ImmutableOpenMap.Builder<String, DiskUsage> newLeastAvaiableUsages,
-            ImmutableOpenMap.Builder<String, DiskUsage> newMostAvaiableUsages) {
+    static void fillDiskUsagePerNode(ESLogger logger, NodeStats[] nodeStatsArray, Map<String, DiskUsage> newLeastAvaiableUsages, Map<String, DiskUsage> newMostAvaiableUsages) {
         for (NodeStats nodeStats : nodeStatsArray) {
             if (nodeStats.getFs() == null) {
                 logger.warn("Unable to retrieve node FS stats for {}", nodeStats.getNode().name());
diff --git a/core/src/main/java/org/elasticsearch/cluster/RestoreInProgress.java b/core/src/main/java/org/elasticsearch/cluster/RestoreInProgress.java
index dd7eb9f..82ba28d 100644
--- a/core/src/main/java/org/elasticsearch/cluster/RestoreInProgress.java
+++ b/core/src/main/java/org/elasticsearch/cluster/RestoreInProgress.java
@@ -19,11 +19,9 @@
 
 package org.elasticsearch.cluster;
 
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.cluster.ClusterState.Custom;
 import org.elasticsearch.cluster.metadata.SnapshotId;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.ToXContent;
@@ -35,6 +33,7 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
+import java.util.Map;
 
 /**
  * Meta data about restore processes that are currently executing
@@ -113,7 +112,7 @@ public class RestoreInProgress extends AbstractDiffable<Custom> implements Custo
     public static class Entry {
         private final State state;
         private final SnapshotId snapshotId;
-        private final ImmutableOpenMap<ShardId, ShardRestoreStatus> shards;
+        private final Map<ShardId, ShardRestoreStatus> shards;
         private final List<String> indices;
 
         /**
@@ -122,14 +121,14 @@ public class RestoreInProgress extends AbstractDiffable<Custom> implements Custo
          * @param snapshotId snapshot id
          * @param state      current state of the restore process
          * @param indices    list of indices being restored
-         * @param shards     map of shards being restored to their current restore status
+         * @param shards     list of shards being restored and thier current restore status
          */
-        public Entry(SnapshotId snapshotId, State state, List<String> indices, ImmutableOpenMap<ShardId, ShardRestoreStatus> shards) {
+        public Entry(SnapshotId snapshotId, State state, List<String> indices, ImmutableMap<ShardId, ShardRestoreStatus> shards) {
             this.snapshotId = snapshotId;
             this.state = state;
             this.indices = indices;
             if (shards == null) {
-                this.shards = ImmutableOpenMap.of();
+                this.shards = ImmutableMap.of();
             } else {
                 this.shards = shards;
             }
@@ -149,7 +148,7 @@ public class RestoreInProgress extends AbstractDiffable<Custom> implements Custo
          *
          * @return list of shards
          */
-        public ImmutableOpenMap<ShardId, ShardRestoreStatus> shards() {
+        public Map<ShardId, ShardRestoreStatus> shards() {
             return this.shards;
         }
 
@@ -417,7 +416,7 @@ public class RestoreInProgress extends AbstractDiffable<Custom> implements Custo
             for (int j = 0; j < indices; j++) {
                 indexBuilder.add(in.readString());
             }
-            ImmutableOpenMap.Builder<ShardId, ShardRestoreStatus> builder = ImmutableOpenMap.builder();
+            ImmutableMap.Builder<ShardId, ShardRestoreStatus> builder = ImmutableMap.<ShardId, ShardRestoreStatus>builder();
             int shards = in.readVInt();
             for (int j = 0; j < shards; j++) {
                 ShardId shardId = ShardId.readShardId(in);
@@ -443,9 +442,9 @@ public class RestoreInProgress extends AbstractDiffable<Custom> implements Custo
                 out.writeString(index);
             }
             out.writeVInt(entry.shards().size());
-            for (ObjectObjectCursor<ShardId, ShardRestoreStatus> shardEntry : entry.shards()) {
-                shardEntry.key.writeTo(out);
-                shardEntry.value.writeTo(out);
+            for (Map.Entry<ShardId, ShardRestoreStatus> shardEntry : entry.shards().entrySet()) {
+                shardEntry.getKey().writeTo(out);
+                shardEntry.getValue().writeTo(out);
             }
         }
     }
@@ -484,9 +483,9 @@ public class RestoreInProgress extends AbstractDiffable<Custom> implements Custo
         builder.endArray();
         builder.startArray("shards");
         {
-            for (ObjectObjectCursor<ShardId, ShardRestoreStatus> shardEntry : entry.shards) {
-                ShardId shardId = shardEntry.key;
-                ShardRestoreStatus status = shardEntry.value;
+            for (Map.Entry<ShardId, ShardRestoreStatus> shardEntry : entry.shards.entrySet()) {
+                ShardId shardId = shardEntry.getKey();
+                ShardRestoreStatus status = shardEntry.getValue();
                 builder.startObject();
                 {
                     builder.field("index", shardId.getIndex());
diff --git a/core/src/main/java/org/elasticsearch/cluster/SnapshotsInProgress.java b/core/src/main/java/org/elasticsearch/cluster/SnapshotsInProgress.java
index 821ab3c..83c663a 100644
--- a/core/src/main/java/org/elasticsearch/cluster/SnapshotsInProgress.java
+++ b/core/src/main/java/org/elasticsearch/cluster/SnapshotsInProgress.java
@@ -19,13 +19,9 @@
 
 package org.elasticsearch.cluster;
 
-import com.carrotsearch.hppc.ObjectContainer;
-import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.cluster.ClusterState.Custom;
 import org.elasticsearch.cluster.metadata.SnapshotId;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.ToXContent;
@@ -36,11 +32,14 @@ import org.elasticsearch.index.shard.ShardId;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
+import static java.util.Collections.unmodifiableMap;
+
 /**
  * Meta data about snapshots that are currently executing
  */
@@ -70,31 +69,31 @@ public class SnapshotsInProgress extends AbstractDiffable<Custom> implements Cus
         private final State state;
         private final SnapshotId snapshotId;
         private final boolean includeGlobalState;
-        private final ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards;
+        private final Map<ShardId, ShardSnapshotStatus> shards;
         private final List<String> indices;
-        private final ImmutableOpenMap<String, List<ShardId>> waitingIndices;
+        private final Map<String, List<ShardId>> waitingIndices;
         private final long startTime;
 
-        public Entry(SnapshotId snapshotId, boolean includeGlobalState, State state, List<String> indices, long startTime, ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards) {
+        public Entry(SnapshotId snapshotId, boolean includeGlobalState, State state, List<String> indices, long startTime, Map<ShardId, ShardSnapshotStatus> shards) {
             this.state = state;
             this.snapshotId = snapshotId;
             this.includeGlobalState = includeGlobalState;
             this.indices = indices;
             this.startTime = startTime;
             if (shards == null) {
-                this.shards = ImmutableOpenMap.of();
-                this.waitingIndices = ImmutableOpenMap.of();
+                this.shards = ImmutableMap.of();
+                this.waitingIndices = ImmutableMap.of();
             } else {
-                this.shards = shards;
+                this.shards = unmodifiableMap(shards);
                 this.waitingIndices = findWaitingIndices(shards);
             }
         }
 
-        public Entry(Entry entry, State state, ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards) {
+        public Entry(Entry entry, State state, Map<ShardId, ShardSnapshotStatus> shards) {
             this(entry.snapshotId, entry.includeGlobalState, state, entry.indices, entry.startTime, shards);
         }
 
-        public Entry(Entry entry, ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards) {
+        public Entry(Entry entry, Map<ShardId, ShardSnapshotStatus> shards) {
             this(entry, entry.state, shards);
         }
 
@@ -102,7 +101,7 @@ public class SnapshotsInProgress extends AbstractDiffable<Custom> implements Cus
             return this.snapshotId;
         }
 
-        public ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards() {
+        public Map<ShardId, ShardSnapshotStatus> shards() {
             return this.shards;
         }
 
@@ -114,7 +113,7 @@ public class SnapshotsInProgress extends AbstractDiffable<Custom> implements Cus
             return indices;
         }
 
-        public ImmutableOpenMap<String, List<ShardId>> waitingIndices() {
+        public Map<String, List<ShardId>> waitingIndices() {
             return waitingIndices;
         }
 
@@ -156,26 +155,28 @@ public class SnapshotsInProgress extends AbstractDiffable<Custom> implements Cus
             return result;
         }
 
-        private ImmutableOpenMap<String, List<ShardId>> findWaitingIndices(ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards) {
+        private ImmutableMap<String, List<ShardId>> findWaitingIndices(Map<ShardId, ShardSnapshotStatus> shards) {
             Map<String, List<ShardId>> waitingIndicesMap = new HashMap<>();
-            for (ObjectObjectCursor<ShardId, ShardSnapshotStatus> entry : shards) {
-                if (entry.value.state() == State.WAITING) {
-                    List<ShardId> waitingShards = waitingIndicesMap.get(entry.key.getIndex());
+            for (ImmutableMap.Entry<ShardId, ShardSnapshotStatus> entry : shards.entrySet()) {
+                if (entry.getValue().state() == State.WAITING) {
+                    List<ShardId> waitingShards = waitingIndicesMap.get(entry.getKey().getIndex());
                     if (waitingShards == null) {
                         waitingShards = new ArrayList<>();
-                        waitingIndicesMap.put(entry.key.getIndex(), waitingShards);
+                        waitingIndicesMap.put(entry.getKey().getIndex(), waitingShards);
                     }
-                    waitingShards.add(entry.key);
+                    waitingShards.add(entry.getKey());
                 }
             }
-            if (waitingIndicesMap.isEmpty()) {
-                return ImmutableOpenMap.of();
-            }
-            ImmutableOpenMap.Builder<String, List<ShardId>> waitingIndicesBuilder = ImmutableOpenMap.builder();
-            for (Map.Entry<String, List<ShardId>> entry : waitingIndicesMap.entrySet()) {
-                waitingIndicesBuilder.put(entry.getKey(), Collections.unmodifiableList(entry.getValue()));
+            if (!waitingIndicesMap.isEmpty()) {
+                ImmutableMap.Builder<String, List<ShardId>> waitingIndicesBuilder = ImmutableMap.builder();
+                for (Map.Entry<String, List<ShardId>> entry : waitingIndicesMap.entrySet()) {
+                    waitingIndicesBuilder.put(entry.getKey(), Collections.unmodifiableList(entry.getValue()));
+                }
+                return waitingIndicesBuilder.build();
+            } else {
+                return ImmutableMap.of();
             }
-            return waitingIndicesBuilder.build();
+
         }
 
     }
@@ -186,9 +187,9 @@ public class SnapshotsInProgress extends AbstractDiffable<Custom> implements Cus
      * @param shards list of shard statuses
      * @return true if all shards have completed (either successfully or failed), false otherwise
      */
-    public static boolean completed(ObjectContainer<ShardSnapshotStatus> shards) {
-        for (ObjectCursor<ShardSnapshotStatus> status : shards) {
-            if (status.value.state().completed() == false) {
+    public static boolean completed(Collection<ShardSnapshotStatus> shards) {
+        for (ShardSnapshotStatus status : shards) {
+            if (status.state().completed() == false) {
                 return false;
             }
         }
@@ -368,7 +369,7 @@ public class SnapshotsInProgress extends AbstractDiffable<Custom> implements Cus
                 indexBuilder.add(in.readString());
             }
             long startTime = in.readLong();
-            ImmutableOpenMap.Builder<ShardId, ShardSnapshotStatus> builder = ImmutableOpenMap.builder();
+            ImmutableMap.Builder<ShardId, ShardSnapshotStatus> builder = ImmutableMap.builder();
             int shards = in.readVInt();
             for (int j = 0; j < shards; j++) {
                 ShardId shardId = ShardId.readShardId(in);
@@ -394,10 +395,10 @@ public class SnapshotsInProgress extends AbstractDiffable<Custom> implements Cus
             }
             out.writeLong(entry.startTime());
             out.writeVInt(entry.shards().size());
-            for (ObjectObjectCursor<ShardId, ShardSnapshotStatus> shardEntry : entry.shards()) {
-                shardEntry.key.writeTo(out);
-                out.writeOptionalString(shardEntry.value.nodeId());
-                out.writeByte(shardEntry.value.state().value());
+            for (Map.Entry<ShardId, ShardSnapshotStatus> shardEntry : entry.shards().entrySet()) {
+                shardEntry.getKey().writeTo(out);
+                out.writeOptionalString(shardEntry.getValue().nodeId());
+                out.writeByte(shardEntry.getValue().state().value());
             }
         }
     }
@@ -443,9 +444,9 @@ public class SnapshotsInProgress extends AbstractDiffable<Custom> implements Cus
         builder.timeValueField(Fields.START_TIME_MILLIS, Fields.START_TIME, entry.startTime());
         builder.startArray(Fields.SHARDS);
         {
-            for (ObjectObjectCursor<ShardId, ShardSnapshotStatus> shardEntry : entry.shards) {
-                ShardId shardId = shardEntry.key;
-                ShardSnapshotStatus status = shardEntry.value;
+            for (Map.Entry<ShardId, ShardSnapshotStatus> shardEntry : entry.shards.entrySet()) {
+                ShardId shardId = shardEntry.getKey();
+                ShardSnapshotStatus status = shardEntry.getValue();
                 builder.startObject();
                 {
                     builder.field(Fields.INDEX, shardId.getIndex());
diff --git a/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java b/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
index cfe88af..ab5609c 100644
--- a/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
+++ b/core/src/main/java/org/elasticsearch/cluster/block/ClusterBlocks.java
@@ -19,12 +19,11 @@
 
 package org.elasticsearch.cluster.block;
 
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
+import com.google.common.collect.ImmutableMap;
 
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaDataIndexStateService;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.rest.RestStatus;
@@ -38,6 +37,7 @@ import java.util.function.Function;
 import java.util.function.Predicate;
 import java.util.stream.Stream;
 
+import static java.util.Collections.emptyMap;
 import static java.util.Collections.emptySet;
 import static java.util.Collections.unmodifiableSet;
 import static java.util.stream.Collectors.toSet;
@@ -47,17 +47,17 @@ import static java.util.stream.Stream.concat;
  * Represents current cluster level blocks to block dirty operations done against the cluster.
  */
 public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
-    public static final ClusterBlocks EMPTY_CLUSTER_BLOCK = new ClusterBlocks(emptySet(), ImmutableOpenMap.of());
+    public static final ClusterBlocks EMPTY_CLUSTER_BLOCK = new ClusterBlocks(emptySet(), emptyMap());
 
     public static final ClusterBlocks PROTO = EMPTY_CLUSTER_BLOCK;
 
     private final Set<ClusterBlock> global;
 
-    private final ImmutableOpenMap<String, Set<ClusterBlock>> indicesBlocks;
+    private final Map<String, Set<ClusterBlock>> indicesBlocks;
 
     private final ImmutableLevelHolder[] levelHolders;
 
-    ClusterBlocks(Set<ClusterBlock> global, ImmutableOpenMap<String, Set<ClusterBlock>> indicesBlocks) {
+    ClusterBlocks(Set<ClusterBlock> global, Map<String, Set<ClusterBlock>> indicesBlocks) {
         this.global = global;
         this.indicesBlocks = indicesBlocks;
 
@@ -68,9 +68,9 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
                     .filter(containsLevel)
                     .collect(toSet()));
 
-            ImmutableOpenMap.Builder<String, Set<ClusterBlock>> indicesBuilder = ImmutableOpenMap.builder();
-            for (ObjectObjectCursor<String, Set<ClusterBlock>> entry : indicesBlocks) {
-                indicesBuilder.put(entry.key, unmodifiableSet(entry.value.stream()
+            ImmutableMap.Builder<String, Set<ClusterBlock>> indicesBuilder = ImmutableMap.builder();
+            for (Map.Entry<String, Set<ClusterBlock>> entry : indicesBlocks.entrySet()) {
+                indicesBuilder.put(entry.getKey(), unmodifiableSet(entry.getValue().stream()
                         .filter(containsLevel)
                         .collect(toSet())));
             }
@@ -83,7 +83,7 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
         return global;
     }
 
-    public ImmutableOpenMap<String, Set<ClusterBlock>> indices() {
+    public Map<String, Set<ClusterBlock>> indices() {
         return indicesBlocks;
     }
 
@@ -91,7 +91,7 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
         return levelHolders[level.id()].global();
     }
 
-    public ImmutableOpenMap<String, Set<ClusterBlock>> indices(ClusterBlockLevel level) {
+    public Map<String, Set<ClusterBlock>> indices(ClusterBlockLevel level) {
         return levelHolders[level.id()].indices();
     }
 
@@ -203,9 +203,9 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
     public void writeTo(StreamOutput out) throws IOException {
         writeBlockSet(global, out);
         out.writeVInt(indicesBlocks.size());
-        for (ObjectObjectCursor<String, Set<ClusterBlock>> entry : indicesBlocks) {
-            out.writeString(entry.key);
-            writeBlockSet(entry.value, out);
+        for (Map.Entry<String, Set<ClusterBlock>> entry : indicesBlocks.entrySet()) {
+            out.writeString(entry.getKey());
+            writeBlockSet(entry.getValue(), out);
         }
     }
 
@@ -219,8 +219,8 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
     @Override
     public ClusterBlocks readFrom(StreamInput in) throws IOException {
         Set<ClusterBlock> global = readBlockSet(in);
+        ImmutableMap.Builder<String, Set<ClusterBlock>> indicesBuilder = ImmutableMap.builder();
         int size = in.readVInt();
-        ImmutableOpenMap.Builder<String, Set<ClusterBlock>> indicesBuilder = ImmutableOpenMap.builder(size);
         for (int j = 0; j < size; j++) {
             indicesBuilder.put(in.readString().intern(), readBlockSet(in));
         }
@@ -238,12 +238,12 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
 
     static class ImmutableLevelHolder {
 
-        static final ImmutableLevelHolder EMPTY = new ImmutableLevelHolder(emptySet(), ImmutableOpenMap.of());
+        static final ImmutableLevelHolder EMPTY = new ImmutableLevelHolder(emptySet(), ImmutableMap.of());
 
         private final Set<ClusterBlock> global;
-        private final ImmutableOpenMap<String, Set<ClusterBlock>> indices;
+        private final ImmutableMap<String, Set<ClusterBlock>> indices;
 
-        ImmutableLevelHolder(Set<ClusterBlock> global, ImmutableOpenMap<String, Set<ClusterBlock>> indices) {
+        ImmutableLevelHolder(Set<ClusterBlock> global, ImmutableMap<String, Set<ClusterBlock>> indices) {
             this.global = global;
             this.indices = indices;
         }
@@ -252,7 +252,7 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
             return global;
         }
 
-        public ImmutableOpenMap<String, Set<ClusterBlock>> indices() {
+        public ImmutableMap<String, Set<ClusterBlock>> indices() {
             return indices;
         }
     }
@@ -272,11 +272,11 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
 
         public Builder blocks(ClusterBlocks blocks) {
             global.addAll(blocks.global());
-            for (ObjectObjectCursor<String, Set<ClusterBlock>> entry : blocks.indices()) {
-                if (!indices.containsKey(entry.key)) {
-                    indices.put(entry.key, new HashSet<>());
+            for (Map.Entry<String, Set<ClusterBlock>> entry : blocks.indices().entrySet()) {
+                if (!indices.containsKey(entry.getKey())) {
+                    indices.put(entry.getKey(), new HashSet<>());
                 }
-                indices.get(entry.key).addAll(entry.value);
+                indices.get(entry.getKey()).addAll(entry.getValue());
             }
             return this;
         }
@@ -339,7 +339,7 @@ public class ClusterBlocks extends AbstractDiffable<ClusterBlocks> {
 
         public ClusterBlocks build() {
             // We copy the block sets here in case of the builder is modified after build is called
-            ImmutableOpenMap.Builder<String, Set<ClusterBlock>> indicesBuilder = ImmutableOpenMap.builder(indices.size());
+            ImmutableMap.Builder<String, Set<ClusterBlock>> indicesBuilder = ImmutableMap.builder();
             for (Map.Entry<String, Set<ClusterBlock>> entry : indices.entrySet()) {
                 indicesBuilder.put(entry.getKey(), unmodifiableSet(new HashSet<>(entry.getValue())));
             }
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java
index 049eadc..99ce095 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataCreateIndexService.java
@@ -21,7 +21,7 @@ package org.elasticsearch.cluster.metadata;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
+import java.nio.charset.StandardCharsets;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.Version;
@@ -76,7 +76,6 @@ import org.joda.time.DateTimeZone;
 import java.io.BufferedReader;
 import java.io.IOException;
 import java.io.UnsupportedEncodingException;
-import java.nio.charset.StandardCharsets;
 import java.nio.file.DirectoryStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
@@ -463,7 +462,7 @@ public class MetaDataCreateIndexService extends AbstractComponent {
                     if (request.state() == State.OPEN) {
                         RoutingTable.Builder routingTableBuilder = RoutingTable.builder(updatedState.routingTable())
                                 .addAsNew(updatedState.metaData().index(request.index()));
-                        RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(routingTableBuilder.build()).build());
+                        RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(routingTableBuilder).build());
                         updatedState = ClusterState.builder(updatedState).routingResult(routingResult).build();
                     }
                     removalReason = "cleaning up after validating index on master";
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataDeleteIndexService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataDeleteIndexService.java
index 88e1aad..d7b2e47 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataDeleteIndexService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataDeleteIndexService.java
@@ -128,7 +128,7 @@ public class MetaDataDeleteIndexService extends AbstractComponent {
                         .build();
 
                 RoutingAllocation.Result routingResult = allocationService.reroute(
-                        ClusterState.builder(currentState).routingTable(routingTableBuilder.build()).metaData(newMetaData).build());
+                        ClusterState.builder(currentState).routingTable(routingTableBuilder).metaData(newMetaData).build());
 
                 ClusterBlocks blocks = ClusterBlocks.builder().blocks(currentState.blocks()).removeIndexBlocks(request.index).build();
 
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexStateService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexStateService.java
index e4452e4..b5b3cb6 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexStateService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexStateService.java
@@ -124,7 +124,7 @@ public class MetaDataIndexStateService extends AbstractComponent {
                     rtBuilder.remove(index);
                 }
 
-                RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(rtBuilder.build()).build());
+                RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(rtBuilder).build());
                 //no explicit wait for other nodes needed as we use AckedClusterStateUpdateTask
                 return ClusterState.builder(updatedState).routingResult(routingResult).build();
             }
@@ -181,7 +181,7 @@ public class MetaDataIndexStateService extends AbstractComponent {
                     rtBuilder.addAsFromCloseToOpen(updatedState.metaData().index(index));
                 }
 
-                RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(rtBuilder.build()).build());
+                RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(rtBuilder).build());
                 //no explicit wait for other nodes needed as we use AckedClusterStateUpdateTask
                 return ClusterState.builder(updatedState).routingResult(routingResult).build();
             }
diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java
index 58dffd8..65d862c 100644
--- a/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataUpdateSettingsService.java
@@ -320,7 +320,7 @@ public class MetaDataUpdateSettingsService extends AbstractComponent implements
                 }
 
 
-                ClusterState updatedState = ClusterState.builder(currentState).metaData(metaDataBuilder).routingTable(routingTableBuilder.build()).blocks(blocks).build();
+                ClusterState updatedState = ClusterState.builder(currentState).metaData(metaDataBuilder).routingTable(routingTableBuilder).blocks(blocks).build();
 
                 // now, reroute in case things change that require it (like number of replicas)
                 RoutingAllocation.Result routingResult = allocationService.reroute(updatedState);
diff --git a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java
index 780f511..ebf1bcb 100644
--- a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java
+++ b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNode.java
@@ -19,15 +19,13 @@
 
 package org.elasticsearch.cluster.node;
 
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
+import com.google.common.collect.ImmutableMap;
 
 import org.elasticsearch.Version;
 import org.elasticsearch.common.Booleans;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
-import org.elasticsearch.common.io.stream.StreamInput;
-import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.io.stream.Streamable;
+import org.elasticsearch.common.io.stream.*;
+import org.elasticsearch.common.network.NetworkUtils;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.TransportAddress;
 import org.elasticsearch.common.transport.TransportAddressSerializers;
@@ -35,6 +33,7 @@ import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
+import java.net.InetAddress;
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
@@ -101,7 +100,7 @@ public class DiscoveryNode implements Streamable, ToXContent {
     private String hostName;
     private String hostAddress;
     private TransportAddress address;
-    private ImmutableOpenMap<String, String> attributes;
+    private Map<String, String> attributes;
     private Version version = Version.CURRENT;
 
     DiscoveryNode() {
@@ -144,7 +143,7 @@ public class DiscoveryNode implements Streamable, ToXContent {
     }
 
     /**
-     * Creates a new {@link DiscoveryNode}.
+     * Creates a new {@link DiscoveryNode}
      * <p>
      * <b>Note:</b> if the version of the node is unknown {@link #MINIMUM_DISCOVERY_NODE_VERSION} should be used.
      * it corresponds to the minimum version this elasticsearch version can communicate with. If a higher version is used
@@ -164,7 +163,7 @@ public class DiscoveryNode implements Streamable, ToXContent {
         if (nodeName != null) {
             this.nodeName = nodeName.intern();
         }
-        ImmutableOpenMap.Builder<String, String> builder = ImmutableOpenMap.builder();
+        ImmutableMap.Builder<String, String> builder = ImmutableMap.builder();
         for (Map.Entry<String, String> entry : attributes.entrySet()) {
             builder.put(entry.getKey().intern(), entry.getValue().intern());
         }
@@ -177,39 +176,6 @@ public class DiscoveryNode implements Streamable, ToXContent {
     }
 
     /**
-     * Creates a new {@link DiscoveryNode}.
-     * <p>
-     * <b>Note:</b> if the version of the node is unknown {@link #MINIMUM_DISCOVERY_NODE_VERSION} should be used.
-     * it corresponds to the minimum version this elasticsearch version can communicate with. If a higher version is used
-     * the node might not be able to communicate with the remove node. After initial handshakes node versions will be discovered
-     * and updated.
-     * </p>
-     *
-     * @param nodeName    the nodes name
-     * @param nodeId      the nodes unique id.
-     * @param hostName    the nodes hostname
-     * @param hostAddress the nodes host address
-     * @param address     the nodes transport address
-     * @param attributes  node attributes
-     * @param version     the version of the node.
-     */
-    public DiscoveryNode(String nodeName, String nodeId, String hostName, String hostAddress, TransportAddress address, ImmutableOpenMap<String, String> attributes, Version version) {
-        if (nodeName != null) {
-            this.nodeName = nodeName.intern();
-        }
-        ImmutableOpenMap.Builder<String, String> builder = ImmutableOpenMap.builder();
-        for (ObjectObjectCursor<String, String> entry : attributes) {
-            builder.put(entry.key.intern(), entry.value.intern());
-        }
-        this.attributes = builder.build();
-        this.nodeId = nodeId.intern();
-        this.hostName = hostName.intern();
-        this.hostAddress = hostAddress.intern();
-        this.address = address;
-        this.version = version;
-    }
-
-    /**
      * Should this node form a connection to the provided node.
      */
     public boolean shouldConnectTo(DiscoveryNode otherNode) {
@@ -264,14 +230,14 @@ public class DiscoveryNode implements Streamable, ToXContent {
     /**
      * The node attributes.
      */
-    public ImmutableOpenMap<String, String> attributes() {
+    public Map<String, String> attributes() {
         return this.attributes;
     }
 
     /**
      * The node attributes.
      */
-    public ImmutableOpenMap<String, String> getAttributes() {
+    public Map<String, String> getAttributes() {
         return attributes();
     }
 
@@ -353,11 +319,11 @@ public class DiscoveryNode implements Streamable, ToXContent {
         hostAddress = in.readString().intern();
         address = TransportAddressSerializers.addressFromStream(in);
         int size = in.readVInt();
-        ImmutableOpenMap.Builder<String, String> attributes = ImmutableOpenMap.builder(size);
+        ImmutableMap.Builder<String, String> builder = ImmutableMap.builder();
         for (int i = 0; i < size; i++) {
-            attributes.put(in.readString().intern(), in.readString().intern());
+            builder.put(in.readString().intern(), in.readString().intern());
         }
-        this.attributes = attributes.build();
+        attributes = builder.build();
         version = Version.readVersion(in);
     }
 
@@ -369,9 +335,9 @@ public class DiscoveryNode implements Streamable, ToXContent {
         out.writeString(hostAddress);
         addressToStream(out, address);
         out.writeVInt(attributes.size());
-        for (ObjectObjectCursor<String, String> entry : attributes) {
-            out.writeString(entry.key);
-            out.writeString(entry.value);
+        for (Map.Entry<String, String> entry : attributes.entrySet()) {
+            out.writeString(entry.getKey());
+            out.writeString(entry.getValue());
         }
         Version.writeVersion(version, out);
     }
@@ -419,8 +385,8 @@ public class DiscoveryNode implements Streamable, ToXContent {
         builder.field("transport_address", address().toString());
 
         builder.startObject("attributes");
-        for (ObjectObjectCursor<String, String> attr : attributes) {
-            builder.field(attr.key, attr.value);
+        for (Map.Entry<String, String> attr : attributes().entrySet()) {
+            builder.field(attr.getKey(), attr.getValue());
         }
         builder.endObject();
 
diff --git a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
index 16b7e9e..13b6471 100644
--- a/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
+++ b/core/src/main/java/org/elasticsearch/cluster/node/DiscoveryNodes.java
@@ -22,7 +22,6 @@ package org.elasticsearch.cluster.node;
 import com.carrotsearch.hppc.ObjectHashSet;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.common.Booleans;
@@ -34,12 +33,7 @@ import org.elasticsearch.common.regex.Regex;
 import org.elasticsearch.common.transport.TransportAddress;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 
 /**
  * This class holds all {@link DiscoveryNode} in the cluster and provides convenience methods to
@@ -380,9 +374,9 @@ public class DiscoveryNodes extends AbstractDiffable<DiscoveryNodes> implements
                             }
                         } else {
                             for (DiscoveryNode node : this) {
-                                for (ObjectObjectCursor<String, String> entry : node.attributes()) {
-                                    String attrName = entry.key;
-                                    String attrValue = entry.value;
+                                for (Map.Entry<String, String> entry : node.attributes().entrySet()) {
+                                    String attrName = entry.getKey();
+                                    String attrValue = entry.getValue();
                                     if (Regex.simpleMatch(matchAttrName, attrName) && Regex.simpleMatch(matchAttrValue, attrValue)) {
                                         resolvedNodesIds.add(node.id());
                                     }
@@ -569,7 +563,6 @@ public class DiscoveryNodes extends AbstractDiffable<DiscoveryNodes> implements
         }
     }
 
-    @Override
     public void writeTo(StreamOutput out) throws IOException {
         if (masterNodeId == null) {
             out.writeBoolean(false);
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java b/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
index 6512ee5..e740a4f 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.cluster.routing;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
 import org.elasticsearch.common.collect.MapBuilder;
@@ -38,8 +39,6 @@ import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ThreadLocalRandom;
 
-import static java.util.Collections.emptyMap;
-
 /**
  * {@link IndexShardRoutingTable} encapsulates all instances of a single shard.
  * Each Elasticsearch index consists of multiple shards, each shard encapsulates
@@ -61,10 +60,6 @@ public class IndexShardRoutingTable implements Iterable<ShardRouting> {
     final static List<ShardRouting> NO_SHARDS = Collections.emptyList();
     final boolean allShardsStarted;
 
-    private volatile Map<AttributesKey, AttributesRoutings> activeShardsByAttributes = emptyMap();
-    private volatile Map<AttributesKey, AttributesRoutings> initializingShardsByAttributes = emptyMap();
-    private final Object shardsByAttributeMutex = new Object();
-
     /**
      * The initializing list, including ones that are initializing on a target node because of relocation.
      * If we can come up with a better variable name, it would be nice...
@@ -481,6 +476,10 @@ public class IndexShardRoutingTable implements Iterable<ShardRouting> {
         }
     }
 
+    private volatile Map<AttributesKey, AttributesRoutings> activeShardsByAttributes = ImmutableMap.of();
+    private volatile Map<AttributesKey, AttributesRoutings> initializingShardsByAttributes = ImmutableMap.of();
+    private final Object shardsByAttributeMutex = new Object();
+
     private AttributesRoutings getActiveAttribute(AttributesKey key, DiscoveryNodes nodes) {
         AttributesRoutings shardRoutings = activeShardsByAttributes.get(key);
         if (shardRoutings == null) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
index f632428..227d59f 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingNodes.java
@@ -22,7 +22,6 @@ package org.elasticsearch.cluster.routing;
 import com.carrotsearch.hppc.ObjectIntHashMap;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.google.common.collect.Iterators;
-
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.block.ClusterBlocks;
@@ -31,15 +30,7 @@ import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.index.shard.ShardId;
 
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 import java.util.function.Predicate;
 
 /**
@@ -91,8 +82,8 @@ public class RoutingNodes implements Iterable<RoutingNode> {
 
         // fill in the inverse of node -> shards allocated
         // also fill replicaSet information
-        for (ObjectCursor<IndexRoutingTable> indexRoutingTable : routingTable.indicesRouting().values()) {
-            for (IndexShardRoutingTable indexShard : indexRoutingTable.value) {
+        for (IndexRoutingTable indexRoutingTable : routingTable.indicesRouting().values()) {
+            for (IndexShardRoutingTable indexShard : indexRoutingTable) {
                 for (ShardRouting shard : indexShard) {
                     // to get all the shards belonging to an index, including the replicas,
                     // we define a replica set and keep track of it. A replica set is identified
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
index 1cbf860..7a8c33e 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTable.java
@@ -20,15 +20,13 @@
 package org.elasticsearch.cluster.routing;
 
 import com.carrotsearch.hppc.IntSet;
-import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
+import com.google.common.collect.ImmutableMap;
 
 import org.elasticsearch.cluster.Diff;
 import org.elasticsearch.cluster.Diffable;
 import org.elasticsearch.cluster.DiffableUtils;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.util.iterable.Iterables;
@@ -43,6 +41,8 @@ import java.util.List;
 import java.util.Map;
 import java.util.function.Predicate;
 
+import static java.util.Collections.unmodifiableMap;
+
 /**
  * Represents a global cluster-wide routing table for all indices including the
  * version of the current routing state.
@@ -58,11 +58,11 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
     private final long version;
 
     // index to IndexRoutingTable map
-    private final ImmutableOpenMap<String, IndexRoutingTable> indicesRouting;
+    private final Map<String, IndexRoutingTable> indicesRouting;
 
-    RoutingTable(long version, ImmutableOpenMap<String, IndexRoutingTable> indicesRouting) {
+    RoutingTable(long version, Map<String, IndexRoutingTable> indicesRouting) {
         this.version = version;
-        this.indicesRouting = indicesRouting;
+        this.indicesRouting = unmodifiableMap(indicesRouting);
     }
 
     /**
@@ -76,7 +76,7 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
 
     @Override
     public Iterator<IndexRoutingTable> iterator() {
-        return indicesRouting.valuesIt();
+        return indicesRouting.values().iterator();
     }
 
     public boolean hasIndex(String index) {
@@ -87,11 +87,11 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
         return indicesRouting.get(index);
     }
 
-    public ImmutableOpenMap<String, IndexRoutingTable> indicesRouting() {
+    public Map<String, IndexRoutingTable> indicesRouting() {
         return indicesRouting;
     }
 
-    public ImmutableOpenMap<String, IndexRoutingTable> getIndicesRouting() {
+    public Map<String, IndexRoutingTable> getIndicesRouting() {
         return indicesRouting();
     }
 
@@ -126,7 +126,7 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
      */
     public List<ShardRouting> allShards() {
         List<ShardRouting> shards = new ArrayList<>();
-        String[] indices = indicesRouting.keys().toArray(String.class);
+        String[] indices = indicesRouting.keySet().toArray(new String[indicesRouting.keySet().size()]);
         for (String index : indices) {
             List<ShardRouting> allShardsIndex = allShards(index);
             shards.addAll(allShardsIndex);
@@ -303,8 +303,8 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
     public void writeTo(StreamOutput out) throws IOException {
         out.writeLong(version);
         out.writeVInt(indicesRouting.size());
-        for (ObjectCursor<IndexRoutingTable> index : indicesRouting.values()) {
-            index.value.writeTo(out);
+        for (IndexRoutingTable index : indicesRouting.values()) {
+            index.writeTo(out);
         }
     }
 
@@ -312,7 +312,7 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
 
         private final long version;
 
-        private final Diff<ImmutableOpenMap<String, IndexRoutingTable>> indicesRouting;
+        private final Diff<Map<String, IndexRoutingTable>> indicesRouting;
 
         public RoutingTableDiff(RoutingTable before, RoutingTable after) {
             version = after.version;
@@ -321,7 +321,7 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
 
         public RoutingTableDiff(StreamInput in) throws IOException {
             version = in.readLong();
-            indicesRouting = DiffableUtils.readImmutableOpenMapDiff(in, IndexRoutingTable.PROTO);
+            indicesRouting = DiffableUtils.readJdkMapDiff(in, IndexRoutingTable.PROTO);
         }
 
         @Override
@@ -344,13 +344,10 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
         return new Builder(routingTable);
     }
 
-    /**
-     * Builder for the routing table. Note that build can only be called one time.
-     */
     public static class Builder {
 
         private long version;
-        private final ImmutableOpenMap.Builder<String, IndexRoutingTable> indicesRouting = ImmutableOpenMap.builder();
+        private final Map<String, IndexRoutingTable> indicesRouting = new HashMap<>();
 
         public Builder() {
 
@@ -407,7 +404,7 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
 
         public Builder updateNumberOfReplicas(int numberOfReplicas, String... indices) {
             if (indices == null || indices.length == 0) {
-                indices = indicesRouting.keys().toArray(String.class);
+                indices = indicesRouting.keySet().toArray(new String[indicesRouting.keySet().size()]);
             }
             for (String index : indices) {
                 IndexRoutingTable indexRoutingTable = indicesRouting.get(index);
@@ -502,7 +499,7 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
             return this;
         }
 
-        public Builder indicesRouting(Map<String, IndexRoutingTable> indicesRouting) {
+        public Builder indicesRouting(ImmutableMap<String, IndexRoutingTable> indicesRouting) {
             this.indicesRouting.putAll(indicesRouting);
             return this;
         }
@@ -517,17 +514,12 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
             return this;
         }
 
-        /**
-         * Builds the routing table. Note that this can only be called one time.
-         * If you need to build a new RoutingTable as a copy of this one you'll
-         * need to build a new RoutingTable.Builder.
-         */
         public RoutingTable build() {
             // normalize the versions right before we build it...
-            for (ObjectCursor<IndexRoutingTable> indexRoutingTable : indicesRouting.values()) {
-                indicesRouting.put(indexRoutingTable.value.index(), indexRoutingTable.value.normalizeVersions());
+            for (IndexRoutingTable indexRoutingTable : indicesRouting.values()) {
+                indicesRouting.put(indexRoutingTable.index(), indexRoutingTable.normalizeVersions());
             }
-            return new RoutingTable(version, indicesRouting.build());
+            return new RoutingTable(version, indicesRouting);
         }
 
         public static RoutingTable readFrom(StreamInput in) throws IOException {
@@ -537,8 +529,8 @@ public class RoutingTable implements Iterable<IndexRoutingTable>, Diffable<Routi
 
     public String prettyPrint() {
         StringBuilder sb = new StringBuilder("routing_table (version ").append(version).append("):\n");
-        for (ObjectObjectCursor<String, IndexRoutingTable> entry : indicesRouting) {
-            sb.append(entry.value.prettyPrint()).append('\n');
+        for (Map.Entry<String, IndexRoutingTable> entry : indicesRouting.entrySet()) {
+            sb.append(entry.getValue().prettyPrint()).append('\n');
         }
         return sb.toString();
     }
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTableValidation.java b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTableValidation.java
index 472e73b..aec8bef 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTableValidation.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/RoutingTableValidation.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.cluster.routing;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.io.stream.Streamable;
@@ -30,8 +31,6 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-
 /**
  * Encapsulates the result of a routing table validation and provides access to
  * validation failures.
@@ -73,7 +72,7 @@ public class RoutingTableValidation implements Streamable {
 
     public Map<String, List<String>> indicesFailures() {
         if (indicesFailures == null) {
-            return emptyMap();
+            return ImmutableMap.of();
         }
         return indicesFailures;
     }
@@ -129,7 +128,7 @@ public class RoutingTableValidation implements Streamable {
         }
         size = in.readVInt();
         if (size == 0) {
-            indicesFailures = emptyMap();
+            indicesFailures = ImmutableMap.of();
         } else {
             indicesFailures = new HashMap<>();
             for (int i = 0; i < size; i++) {
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java
index b5ee313..b0ac162 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/allocator/BalancedShardsAllocator.java
@@ -21,10 +21,11 @@ package org.elasticsearch.cluster.routing.allocation.allocator;
 
 import org.apache.lucene.util.ArrayUtil;
 import org.apache.lucene.util.IntroSorter;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
+import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.RoutingNode;
 import org.elasticsearch.cluster.routing.RoutingNodes;
-import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.ShardRoutingState;
 import org.elasticsearch.cluster.routing.allocation.FailedRerouteAllocation;
 import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
@@ -39,20 +40,10 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.gateway.PriorityComparator;
 import org.elasticsearch.node.settings.NodeSettingsService;
 
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.IdentityHashMap;
-import java.util.Iterator;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 import java.util.function.Predicate;
 
 import static org.elasticsearch.cluster.routing.ShardRoutingState.RELOCATING;
-import static org.elasticsearch.common.util.CollectionUtils.addAll;
 
 /**
  * The {@link BalancedShardsAllocator} re-balances the nodes allocations
@@ -293,7 +284,7 @@ public class BalancedShardsAllocator extends AbstractComponent implements Shards
             if (logger.isTraceEnabled()) {
                 logger.trace("Start distributing Shards");
             }
-            addAll(indices, allocation.routingTable().indicesRouting().keys());
+            indices.addAll(allocation.routingTable().indicesRouting().keySet());
             buildModelFromAssigned(routing.shards(assignedFilter));
             return allocateUnassigned(unassigned);
         }
@@ -437,7 +428,7 @@ public class BalancedShardsAllocator extends AbstractComponent implements Shards
                 deltas[i] = sorter.delta();
             }
             new IntroSorter() {
-
+                
                 float pivotWeight;
 
                 @Override
@@ -563,10 +554,10 @@ public class BalancedShardsAllocator extends AbstractComponent implements Shards
                 return false;
             }
             boolean changed = false;
-
+          
             /*
              * TODO: We could be smarter here and group the shards by index and then
-             * use the sorter to save some iterations.
+             * use the sorter to save some iterations. 
              */
             final AllocationDeciders deciders = allocation.deciders();
             final PriorityComparator secondaryComparator = PriorityComparator.getAllocationComparator(allocation);
@@ -777,7 +768,7 @@ public class BalancedShardsAllocator extends AbstractComponent implements Shards
                 }
 
                 if (candidate != null) {
-
+                  
                     /* allocate on the model even if not throttled */
                     maxNode.removeShard(candidate);
                     minNode.addShard(candidate, decision);
diff --git a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
index f21ced8..e1a0b77 100644
--- a/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
+++ b/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java
@@ -19,10 +19,6 @@
 
 package org.elasticsearch.cluster.routing.allocation.decider;
 
-import com.carrotsearch.hppc.ObjectLookupContainer;
-import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.cluster.ClusterInfo;
@@ -34,7 +30,6 @@ import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.ShardRoutingState;
 import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.ByteSizeValue;
@@ -43,6 +38,7 @@ import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.set.Sets;
 import org.elasticsearch.node.settings.NodeSettingsService;
 
+import java.util.Map;
 import java.util.Set;
 
 /**
@@ -168,23 +164,23 @@ public class DiskThresholdDecider extends AllocationDecider {
 
         @Override
         public void onNewInfo(ClusterInfo info) {
-            ImmutableOpenMap<String, DiskUsage> usages = info.getNodeLeastAvailableDiskUsages();
+            Map<String, DiskUsage> usages = info.getNodeLeastAvailableDiskUsages();
             if (usages != null) {
                 boolean reroute = false;
                 String explanation = "";
 
                 // Garbage collect nodes that have been removed from the cluster
                 // from the map that tracks watermark crossing
-                ObjectLookupContainer<String> nodes = usages.keys();
+                Set<String> nodes = usages.keySet();
                 for (String node : nodeHasPassedWatermark) {
                     if (nodes.contains(node) == false) {
                         nodeHasPassedWatermark.remove(node);
                     }
                 }
 
-                for (ObjectObjectCursor<String, DiskUsage> entry : usages) {
-                    String node = entry.key;
-                    DiskUsage usage = entry.value;
+                for (Map.Entry<String, DiskUsage> entry : usages.entrySet()) {
+                    String node = entry.getKey();
+                    DiskUsage usage = entry.getValue();
                     warnAboutDiskIfNeeded(usage);
                     if (usage.getFreeBytes() < DiskThresholdDecider.this.freeBytesThresholdHigh.bytes() ||
                             usage.getFreeDiskAsPercentage() < DiskThresholdDecider.this.freeDiskThresholdHigh) {
@@ -340,7 +336,7 @@ public class DiskThresholdDecider extends AllocationDecider {
     @Override
     public Decision canAllocate(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) {
         ClusterInfo clusterInfo = allocation.clusterInfo();
-        ImmutableOpenMap<String, DiskUsage> usages = clusterInfo.getNodeMostAvailableDiskUsages();
+        Map<String, DiskUsage> usages = clusterInfo.getNodeMostAvailableDiskUsages();
         final Decision decision = earlyTerminate(allocation, usages);
         if (decision != null) {
             return decision;
@@ -455,7 +451,7 @@ public class DiskThresholdDecider extends AllocationDecider {
             throw new IllegalArgumentException("Shard [" + shardRouting + "] is not allocated on node: [" + node.nodeId() + "]");
         }
         final ClusterInfo clusterInfo = allocation.clusterInfo();
-        final ImmutableOpenMap<String, DiskUsage> usages = clusterInfo.getNodeLeastAvailableDiskUsages();
+        final Map<String, DiskUsage> usages = clusterInfo.getNodeLeastAvailableDiskUsages();
         final Decision decision = earlyTerminate(allocation, usages);
         if (decision != null) {
             return decision;
@@ -492,7 +488,7 @@ public class DiskThresholdDecider extends AllocationDecider {
         return allocation.decision(Decision.YES, NAME, "enough disk for shard to remain on node, free: [%s]", new ByteSizeValue(freeBytes));
     }
 
-    private DiskUsage getDiskUsage(RoutingNode node, RoutingAllocation allocation, ImmutableOpenMap<String, DiskUsage> usages) {
+    private DiskUsage getDiskUsage(RoutingNode node, RoutingAllocation allocation,  Map<String, DiskUsage> usages) {
         ClusterInfo clusterInfo = allocation.clusterInfo();
         DiskUsage usage = usages.get(node.nodeId());
         if (usage == null) {
@@ -525,15 +521,15 @@ public class DiskThresholdDecider extends AllocationDecider {
      * @param usages Map of nodeId to DiskUsage for all known nodes
      * @return DiskUsage representing given node using the average disk usage
      */
-    public DiskUsage averageUsage(RoutingNode node, ImmutableOpenMap<String, DiskUsage> usages) {
+    public DiskUsage averageUsage(RoutingNode node, Map<String, DiskUsage> usages) {
         if (usages.size() == 0) {
             return new DiskUsage(node.nodeId(), node.node().name(), "_na_", 0, 0);
         }
         long totalBytes = 0;
         long freeBytes = 0;
-        for (ObjectCursor<DiskUsage> du : usages.values()) {
-            totalBytes += du.value.getTotalBytes();
-            freeBytes += du.value.getFreeBytes();
+        for (DiskUsage du : usages.values()) {
+            totalBytes += du.getTotalBytes();
+            freeBytes += du.getFreeBytes();
         }
         return new DiskUsage(node.nodeId(), node.node().name(), "_na_", totalBytes / usages.size(), freeBytes / usages.size());
     }
@@ -596,7 +592,7 @@ public class DiskThresholdDecider extends AllocationDecider {
         }
     }
 
-    private Decision earlyTerminate(RoutingAllocation allocation, ImmutableOpenMap<String, DiskUsage> usages) {
+    private Decision earlyTerminate(RoutingAllocation allocation, final Map<String, DiskUsage> usages) {
         // Always allow allocation if the decider is disabled
         if (!enabled) {
             return allocation.decision(Decision.YES, NAME, "disk threshold decider disabled");
diff --git a/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java
index c230073..74bfac0 100644
--- a/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java
+++ b/core/src/main/java/org/elasticsearch/cluster/service/InternalClusterService.java
@@ -20,16 +20,8 @@
 package org.elasticsearch.cluster.service;
 
 import org.elasticsearch.Version;
-import org.elasticsearch.cluster.AckedClusterStateUpdateTask;
-import org.elasticsearch.cluster.ClusterChangedEvent;
-import org.elasticsearch.cluster.ClusterName;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
+import org.elasticsearch.cluster.*;
 import org.elasticsearch.cluster.ClusterState.Builder;
-import org.elasticsearch.cluster.ClusterStateListener;
-import org.elasticsearch.cluster.ClusterStateUpdateTask;
-import org.elasticsearch.cluster.LocalNodeMasterListener;
-import org.elasticsearch.cluster.TimeoutClusterStateListener;
 import org.elasticsearch.cluster.block.ClusterBlock;
 import org.elasticsearch.cluster.block.ClusterBlocks;
 import org.elasticsearch.cluster.metadata.MetaData;
@@ -49,13 +41,7 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.text.StringText;
 import org.elasticsearch.common.transport.TransportAddress;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.concurrent.ConcurrentCollections;
-import org.elasticsearch.common.util.concurrent.CountDown;
-import org.elasticsearch.common.util.concurrent.EsExecutors;
-import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;
-import org.elasticsearch.common.util.concurrent.FutureUtils;
-import org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor;
-import org.elasticsearch.common.util.concurrent.PrioritizedRunnable;
+import org.elasticsearch.common.util.concurrent.*;
 import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.discovery.Discovery;
 import org.elasticsearch.discovery.DiscoveryService;
@@ -63,18 +49,8 @@ import org.elasticsearch.node.settings.NodeSettingsService;
 import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Queue;
-import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.CopyOnWriteArrayList;
-import java.util.concurrent.Executor;
-import java.util.concurrent.Future;
-import java.util.concurrent.ScheduledFuture;
-import java.util.concurrent.TimeUnit;
+import java.util.*;
+import java.util.concurrent.*;
 
 import static org.elasticsearch.common.util.concurrent.EsExecutors.daemonThreadFactory;
 
@@ -437,7 +413,7 @@ public class InternalClusterService extends AbstractLifecycleComponent<ClusterSe
                     // only the master controls the version numbers
                     Builder builder = ClusterState.builder(newClusterState).incrementVersion();
                     if (previousClusterState.routingTable() != newClusterState.routingTable()) {
-                        builder.routingTable(RoutingTable.builder(newClusterState.routingTable()).version(newClusterState.routingTable().version() + 1).build());
+                        builder.routingTable(RoutingTable.builder(newClusterState.routingTable()).version(newClusterState.routingTable().version() + 1));
                     }
                     if (previousClusterState.metaData() != newClusterState.metaData()) {
                         builder.metaData(MetaData.builder(newClusterState.metaData()).version(newClusterState.metaData().version() + 1));
diff --git a/core/src/main/java/org/elasticsearch/cluster/settings/DynamicSettings.java b/core/src/main/java/org/elasticsearch/cluster/settings/DynamicSettings.java
index 1935a334..c4137fc 100644
--- a/core/src/main/java/org/elasticsearch/cluster/settings/DynamicSettings.java
+++ b/core/src/main/java/org/elasticsearch/cluster/settings/DynamicSettings.java
@@ -19,21 +19,23 @@
 
 package org.elasticsearch.cluster.settings;
 
-import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
 import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.regex.Regex;
 
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+
 /**
  * A container for setting names and validation methods for those settings.
  */
 public class DynamicSettings {
-    private final ImmutableOpenMap<String, Validator> dynamicSettings;
+
+    private final Map<String, Validator> dynamicSettings;
 
     public static class Builder {
-        private ImmutableOpenMap.Builder<String, Validator> settings = ImmutableOpenMap.builder();
+        private Map<String, Validator> settings = new HashMap<>();
 
         public void addSetting(String setting, Validator validator) {
             Validator old = settings.put(setting, validator);
@@ -43,12 +45,12 @@ public class DynamicSettings {
         }
 
         public DynamicSettings build() {
-            return new DynamicSettings(settings.build());
+            return new DynamicSettings(settings);
         }
     }
 
-    private DynamicSettings(ImmutableOpenMap<String, Validator> settings) {
-        this.dynamicSettings = settings;
+    private DynamicSettings(Map<String, Validator> settings) {
+        this.dynamicSettings = Collections.unmodifiableMap(settings);
     }
 
     public boolean isDynamicOrLoggingSetting(String key) {
@@ -56,8 +58,8 @@ public class DynamicSettings {
     }
 
     public boolean hasDynamicSetting(String key) {
-        for (ObjectCursor<String> dynamicSetting : dynamicSettings.keys()) {
-            if (Regex.simpleMatch(dynamicSetting.value, key)) {
+        for (String dynamicSetting : dynamicSettings.keySet()) {
+            if (Regex.simpleMatch(dynamicSetting, key)) {
                 return true;
             }
         }
@@ -65,9 +67,9 @@ public class DynamicSettings {
     }
 
     public String validateDynamicSetting(String dynamicSetting, String value, ClusterState clusterState) {
-        for (ObjectObjectCursor<String, Validator> setting : dynamicSettings) {
-            if (Regex.simpleMatch(setting.key, dynamicSetting)) {
-                return setting.value.validate(dynamicSetting, value, clusterState);
+        for (Map.Entry<String, Validator> setting : dynamicSettings.entrySet()) {
+            if (Regex.simpleMatch(setting.getKey(), dynamicSetting)) {
+                return setting.getValue().validate(dynamicSetting, value, clusterState);
             }
         }
         return null;
diff --git a/core/src/main/java/org/elasticsearch/common/Table.java b/core/src/main/java/org/elasticsearch/common/Table.java
index 6156cc2..fd979cf 100644
--- a/core/src/main/java/org/elasticsearch/common/Table.java
+++ b/core/src/main/java/org/elasticsearch/common/Table.java
@@ -19,13 +19,13 @@
 
 package org.elasticsearch.common;
 
+import com.google.common.collect.ImmutableMap;
+
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-
 /**
  */
 public class Table {
@@ -115,7 +115,7 @@ public class Table {
         Map<String, String> mAttr;
         if (attributes.length() == 0) {
             if (inHeaders) {
-                mAttr = emptyMap();
+                mAttr = ImmutableMap.of();
             } else {
                 // get the attributes of the header cell we are going to add to
                 mAttr = headers.get(currentCells.size()).attr;
diff --git a/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java
index 7039783..5b9a8bd 100644
--- a/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java
+++ b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java
@@ -19,27 +19,22 @@
 
 package org.elasticsearch.common.blobstore.fs;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.common.blobstore.BlobMetaData;
 import org.elasticsearch.common.blobstore.BlobPath;
 import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;
 import org.elasticsearch.common.blobstore.support.PlainBlobMetaData;
 import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.io.Streams;
 
-import java.io.BufferedInputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
+import java.io.*;
 import java.nio.file.DirectoryStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.StandardCopyOption;
 import java.nio.file.attribute.BasicFileAttributes;
-import java.util.HashMap;
-import java.util.Map;
-
-import static java.util.Collections.unmodifiableMap;
 
 /**
  *
@@ -57,14 +52,14 @@ public class FsBlobContainer extends AbstractBlobContainer {
     }
 
     @Override
-    public Map<String, BlobMetaData> listBlobs() throws IOException {
+    public ImmutableMap<String, BlobMetaData> listBlobs() throws IOException {
         return listBlobsByPrefix(null);
     }
 
     @Override
-    public Map<String, BlobMetaData> listBlobsByPrefix(String blobNamePrefix) throws IOException {
-        // If we get duplicate files we should just take the last entry
-        Map<String, BlobMetaData> builder = new HashMap<>();
+    public ImmutableMap<String, BlobMetaData> listBlobsByPrefix(String blobNamePrefix) throws IOException {
+        // using MapBuilder and not ImmutableMap.Builder as it seems like File#listFiles might return duplicate files!
+        MapBuilder<String, BlobMetaData> builder = MapBuilder.newMapBuilder();
 
         blobNamePrefix = blobNamePrefix == null ? "" : blobNamePrefix;
         try (DirectoryStream<Path> stream = Files.newDirectoryStream(path, blobNamePrefix + "*")) {
@@ -75,7 +70,7 @@ public class FsBlobContainer extends AbstractBlobContainer {
                 }
             }
         }
-        return unmodifiableMap(builder);
+        return builder.immutableMap();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/common/blobstore/url/URLBlobContainer.java b/core/src/main/java/org/elasticsearch/common/blobstore/url/URLBlobContainer.java
index 5bf5521..9dfaa9c 100644
--- a/core/src/main/java/org/elasticsearch/common/blobstore/url/URLBlobContainer.java
+++ b/core/src/main/java/org/elasticsearch/common/blobstore/url/URLBlobContainer.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.common.blobstore.url;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.blobstore.BlobMetaData;
 import org.elasticsearch.common.blobstore.BlobPath;
 import org.elasticsearch.common.blobstore.support.AbstractBlobContainer;
@@ -28,7 +29,6 @@ import java.io.BufferedInputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.net.URL;
-import java.util.Map;
 
 /**
  * URL blob implementation of {@link org.elasticsearch.common.blobstore.BlobContainer}
@@ -65,7 +65,7 @@ public class URLBlobContainer extends AbstractBlobContainer {
      * This operation is not supported by URLBlobContainer
      */
     @Override
-    public Map<String, BlobMetaData> listBlobs() throws IOException {
+    public ImmutableMap<String, BlobMetaData> listBlobs() throws IOException {
         throw new UnsupportedOperationException("URL repository doesn't support this operation");
     }
 
@@ -73,7 +73,7 @@ public class URLBlobContainer extends AbstractBlobContainer {
      * This operation is not supported by URLBlobContainer
      */
     @Override
-    public Map<String, BlobMetaData> listBlobsByPrefix(String blobNamePrefix) throws IOException {
+    public ImmutableMap<String, BlobMetaData> listBlobsByPrefix(String blobNamePrefix) throws IOException {
         throw new UnsupportedOperationException("URL repository doesn't support this operation");
     }
 
diff --git a/core/src/main/java/org/elasticsearch/common/collect/MapBuilder.java b/core/src/main/java/org/elasticsearch/common/collect/MapBuilder.java
index 2d11198..cafeaad4 100644
--- a/core/src/main/java/org/elasticsearch/common/collect/MapBuilder.java
+++ b/core/src/main/java/org/elasticsearch/common/collect/MapBuilder.java
@@ -19,11 +19,11 @@
 
 package org.elasticsearch.common.collect;
 
+import com.google.common.collect.ImmutableMap;
+
 import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  *
  */
@@ -83,15 +83,7 @@ public class MapBuilder<K, V> {
         return this.map;
     }
 
-    /**
-     * Build an immutable copy of the map under construction.
-     *
-     * @deprecated always copies the map under construction. prefer building a
-     *             HashMap by hand and wrapping it in an unmodifiableMap
-     */
-    @Deprecated
-    public Map<K, V> immutableMap() {
-        // Note that this whole method is going to have to go next but we're changing it like this here just to keep the commit smaller.
-        return unmodifiableMap(new HashMap<>(map));
+    public ImmutableMap<K, V> immutableMap() {
+        return ImmutableMap.copyOf(map);
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java
index 3837de8..ea5a664 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider.java
@@ -16,6 +16,8 @@
 
 package org.elasticsearch.common.inject.assistedinject;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.common.inject.ConfigurationException;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.Injector;
@@ -40,7 +42,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.emptyMap;
 import static java.util.Collections.singleton;
 import static java.util.Collections.unmodifiableSet;
 
@@ -222,7 +223,7 @@ public class FactoryProvider<F> implements Provider<F>, HasDependencies {
         }
 
         if (constructors.isEmpty()) {
-            return emptyMap();
+            return ImmutableMap.of();
         }
 
         Method[] factoryMethods = factoryType.getRawType().getMethods();
diff --git a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
index 1f0e05f..0c07e2a 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/assistedinject/FactoryProvider2.java
@@ -16,6 +16,8 @@
 
 package org.elasticsearch.common.inject.assistedinject;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.common.inject.AbstractModule;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Binding;
@@ -39,11 +41,9 @@ import java.lang.reflect.Proxy;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.inject.internal.Annotations.getKey;
 
 /**
@@ -91,7 +91,7 @@ public final class FactoryProvider2<F> implements InvocationHandler, Provider<F>
      */
     private final Key<?> producedType;
     private final Map<Method, Key<?>> returnTypesByMethod;
-    private final Map<Method, List<Key<?>>> paramTypes;
+    private final ImmutableMap<Method, List<Key<?>>> paramTypes;
 
     /**
      * the hosting injector, or null if we haven't been initialized yet
@@ -117,8 +117,9 @@ public final class FactoryProvider2<F> implements InvocationHandler, Provider<F>
                 Class<F> factoryRawType = (Class) factoryType.getRawType();
 
         try {
-            Map<Method, Key<?>> returnTypesBuilder = new HashMap<>();
-            Map<Method, List<Key<?>>> paramTypesBuilder = new HashMap<>();
+            ImmutableMap.Builder<Method, Key<?>> returnTypesBuilder = ImmutableMap.builder();
+            ImmutableMap.Builder<Method, List<Key<?>>> paramTypesBuilder
+                    = ImmutableMap.builder();
             // TODO: also grab methods from superinterfaces
             for (Method method : factoryRawType.getMethods()) {
                 Key<?> returnType = getKey(
@@ -134,8 +135,8 @@ public final class FactoryProvider2<F> implements InvocationHandler, Provider<F>
                 }
                 paramTypesBuilder.put(method, Collections.unmodifiableList(keys));
             }
-            returnTypesByMethod = unmodifiableMap(returnTypesBuilder);
-            paramTypes = unmodifiableMap(paramTypesBuilder);
+            returnTypesByMethod = returnTypesBuilder.build();
+            paramTypes = paramTypesBuilder.build();
         } catch (ErrorsException e) {
             throw new ConfigurationException(e.getErrors().getMessages());
         }
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java b/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
index 63d8e40..1b68f2c 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/MoreTypes.java
@@ -17,6 +17,8 @@
 
 package org.elasticsearch.common.inject.internal;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.common.inject.ConfigurationException;
 import org.elasticsearch.common.inject.TypeLiteral;
 import org.elasticsearch.common.inject.spi.Message;
@@ -33,13 +35,11 @@ import java.lang.reflect.Type;
 import java.lang.reflect.TypeVariable;
 import java.lang.reflect.WildcardType;
 import java.util.Arrays;
-import java.util.HashMap;
 import java.util.Map;
 import java.util.NoSuchElementException;
 import java.util.Objects;
 
 import static java.util.Collections.singleton;
-import static java.util.Collections.unmodifiableMap;
 
 /**
  * Static methods for working with types that we aren't publishing in the
@@ -54,20 +54,18 @@ public class MoreTypes {
     private MoreTypes() {
     }
 
-    private static final Map<TypeLiteral<?>, TypeLiteral<?>> PRIMITIVE_TO_WRAPPER;
-    static {
-        Map<TypeLiteral<?>, TypeLiteral<?>> primitiveToWrapper = new HashMap<>();
-        primitiveToWrapper.put(TypeLiteral.get(boolean.class), TypeLiteral.get(Boolean.class));
-        primitiveToWrapper.put(TypeLiteral.get(byte.class), TypeLiteral.get(Byte.class));
-        primitiveToWrapper.put(TypeLiteral.get(short.class), TypeLiteral.get(Short.class));
-        primitiveToWrapper.put(TypeLiteral.get(int.class), TypeLiteral.get(Integer.class));
-        primitiveToWrapper.put(TypeLiteral.get(long.class), TypeLiteral.get(Long.class));
-        primitiveToWrapper.put(TypeLiteral.get(float.class), TypeLiteral.get(Float.class));
-        primitiveToWrapper.put(TypeLiteral.get(double.class), TypeLiteral.get(Double.class));
-        primitiveToWrapper.put(TypeLiteral.get(char.class), TypeLiteral.get(Character.class));
-        primitiveToWrapper.put(TypeLiteral.get(void.class), TypeLiteral.get(Void.class));
-        PRIMITIVE_TO_WRAPPER = unmodifiableMap(primitiveToWrapper);
-    }
+    private static final Map<TypeLiteral<?>, TypeLiteral<?>> PRIMITIVE_TO_WRAPPER
+            = new ImmutableMap.Builder<TypeLiteral<?>, TypeLiteral<?>>()
+            .put(TypeLiteral.get(boolean.class), TypeLiteral.get(Boolean.class))
+            .put(TypeLiteral.get(byte.class), TypeLiteral.get(Byte.class))
+            .put(TypeLiteral.get(short.class), TypeLiteral.get(Short.class))
+            .put(TypeLiteral.get(int.class), TypeLiteral.get(Integer.class))
+            .put(TypeLiteral.get(long.class), TypeLiteral.get(Long.class))
+            .put(TypeLiteral.get(float.class), TypeLiteral.get(Float.class))
+            .put(TypeLiteral.get(double.class), TypeLiteral.get(Double.class))
+            .put(TypeLiteral.get(char.class), TypeLiteral.get(Character.class))
+            .put(TypeLiteral.get(void.class), TypeLiteral.get(Void.class))
+            .build();
 
     /**
      * Returns an equivalent type that's safe for use in a key. The returned type will be free of
diff --git a/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java b/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
index 34cb541..29f7886 100644
--- a/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
+++ b/core/src/main/java/org/elasticsearch/common/inject/internal/PrivateElementsImpl.java
@@ -16,6 +16,7 @@
 
 package org.elasticsearch.common.inject.internal;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.inject.Binder;
 import org.elasticsearch.common.inject.Injector;
 import org.elasticsearch.common.inject.Key;
@@ -24,15 +25,7 @@ import org.elasticsearch.common.inject.spi.Element;
 import org.elasticsearch.common.inject.spi.ElementVisitor;
 import org.elasticsearch.common.inject.spi.PrivateElements;
 
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Objects;
-import java.util.Set;
-
-import static java.util.Collections.unmodifiableMap;
+import java.util.*;
 
 /**
  * @author jessewilson@google.com (Jesse Wilson)
@@ -99,7 +92,7 @@ public final class PrivateElementsImpl implements PrivateElements {
             for (ExposureBuilder<?> exposureBuilder : exposureBuilders) {
                 exposedKeysToSourcesMutable.put(exposureBuilder.getKey(), exposureBuilder.getSource());
             }
-            exposedKeysToSources = unmodifiableMap(exposedKeysToSourcesMutable);
+            exposedKeysToSources = ImmutableMap.copyOf(exposedKeysToSourcesMutable);
             exposureBuilders = null;
         }
 
diff --git a/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java b/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java
index c195226..a715d34 100644
--- a/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java
+++ b/core/src/main/java/org/elasticsearch/common/logging/log4j/LogConfigurator.java
@@ -19,8 +19,10 @@
 
 package org.elasticsearch.common.logging.log4j;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.log4j.PropertyConfigurator;
 import org.elasticsearch.ElasticsearchException;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.settings.SettingsException;
 import org.elasticsearch.env.Environment;
@@ -34,12 +36,10 @@ import java.nio.file.SimpleFileVisitor;
 import java.nio.file.attribute.BasicFileAttributes;
 import java.util.Arrays;
 import java.util.EnumSet;
-import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Properties;
 
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.Strings.cleanPath;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 
@@ -50,51 +50,58 @@ public class LogConfigurator {
 
     static final List<String> ALLOWED_SUFFIXES = Arrays.asList(".yml", ".yaml", ".json", ".properties");
 
-    private static final Map<String, String> REPLACEMENTS;
-    static {
-        Map<String, String> replacements = new HashMap<>();
-        replacements.put("console", "org.elasticsearch.common.logging.log4j.ConsoleAppender");
-        replacements.put("async", "org.apache.log4j.AsyncAppender");
-        replacements.put("dailyRollingFile", "org.apache.log4j.DailyRollingFileAppender");
-        replacements.put("externallyRolledFile", "org.apache.log4j.ExternallyRolledFileAppender");
-        replacements.put("file", "org.apache.log4j.FileAppender");
-        replacements.put("jdbc", "org.apache.log4j.jdbc.JDBCAppender");
-        replacements.put("jms", "org.apache.log4j.net.JMSAppender");
-        replacements.put("lf5", "org.apache.log4j.lf5.LF5Appender");
-        replacements.put("ntevent", "org.apache.log4j.nt.NTEventLogAppender");
-        replacements.put("null", "org.apache.log4j.NullAppender");
-        replacements.put("rollingFile", "org.apache.log4j.RollingFileAppender");
-        replacements.put("extrasRollingFile", "org.apache.log4j.rolling.RollingFileAppender");
-        replacements.put("smtp", "org.apache.log4j.net.SMTPAppender");
-        replacements.put("socket", "org.apache.log4j.net.SocketAppender");
-        replacements.put("socketHub", "org.apache.log4j.net.SocketHubAppender");
-        replacements.put("syslog", "org.apache.log4j.net.SyslogAppender");
-        replacements.put("telnet", "org.apache.log4j.net.TelnetAppender");
-                // policies
-        replacements.put("timeBased", "org.apache.log4j.rolling.TimeBasedRollingPolicy");
-        replacements.put("sizeBased", "org.apache.log4j.rolling.SizeBasedTriggeringPolicy");
-                // layouts
-        replacements.put("simple", "org.apache.log4j.SimpleLayout");
-        replacements.put("html", "org.apache.log4j.HTMLLayout");
-        replacements.put("pattern", "org.apache.log4j.PatternLayout");
-        replacements.put("consolePattern", "org.apache.log4j.PatternLayout");
-        replacements.put("enhancedPattern", "org.apache.log4j.EnhancedPatternLayout");
-        replacements.put("ttcc", "org.apache.log4j.TTCCLayout");
-        replacements.put("xml", "org.apache.log4j.XMLLayout");
-        REPLACEMENTS = unmodifiableMap(replacements);
-    }
-
     private static boolean loaded;
 
-    public static void configure(Settings settings) {
+    private static ImmutableMap<String, String> replacements = new MapBuilder<String, String>()
+            .put("console", "org.elasticsearch.common.logging.log4j.ConsoleAppender")
+            .put("async", "org.apache.log4j.AsyncAppender")
+            .put("dailyRollingFile", "org.apache.log4j.DailyRollingFileAppender")
+            .put("externallyRolledFile", "org.apache.log4j.ExternallyRolledFileAppender")
+            .put("file", "org.apache.log4j.FileAppender")
+            .put("jdbc", "org.apache.log4j.jdbc.JDBCAppender")
+            .put("jms", "org.apache.log4j.net.JMSAppender")
+            .put("lf5", "org.apache.log4j.lf5.LF5Appender")
+            .put("ntevent", "org.apache.log4j.nt.NTEventLogAppender")
+            .put("null", "org.apache.log4j.NullAppender")
+            .put("rollingFile", "org.apache.log4j.RollingFileAppender")
+            .put("extrasRollingFile", "org.apache.log4j.rolling.RollingFileAppender")
+            .put("smtp", "org.apache.log4j.net.SMTPAppender")
+            .put("socket", "org.apache.log4j.net.SocketAppender")
+            .put("socketHub", "org.apache.log4j.net.SocketHubAppender")
+            .put("syslog", "org.apache.log4j.net.SyslogAppender")
+            .put("telnet", "org.apache.log4j.net.TelnetAppender")
+            .put("terminal", "org.elasticsearch.common.logging.log4j.TerminalAppender")
+                    // policies
+            .put("timeBased", "org.apache.log4j.rolling.TimeBasedRollingPolicy")
+            .put("sizeBased", "org.apache.log4j.rolling.SizeBasedTriggeringPolicy")
+                    // layouts
+            .put("simple", "org.apache.log4j.SimpleLayout")
+            .put("html", "org.apache.log4j.HTMLLayout")
+            .put("pattern", "org.apache.log4j.PatternLayout")
+            .put("consolePattern", "org.apache.log4j.PatternLayout")
+            .put("enhancedPattern", "org.apache.log4j.EnhancedPatternLayout")
+            .put("ttcc", "org.apache.log4j.TTCCLayout")
+            .put("xml", "org.apache.log4j.XMLLayout")
+            .immutableMap();
+
+    /**
+     * Consolidates settings and converts them into actual log4j settings, then initializes loggers and appenders.
+     *
+     * @param settings      custom settings that should be applied
+     * @param resolveConfig controls whether the logging conf file should be read too or not.
+     */
+    public static void configure(Settings settings, boolean resolveConfig) {
         if (loaded) {
             return;
         }
         loaded = true;
         // TODO: this is partly a copy of InternalSettingsPreparer...we should pass in Environment and not do all this...
         Environment environment = new Environment(settings);
+
         Settings.Builder settingsBuilder = settingsBuilder();
-        resolveConfig(environment, settingsBuilder);
+        if (resolveConfig) {
+            resolveConfig(environment, settingsBuilder);
+        }
         settingsBuilder
                 .putProperties("elasticsearch.", System.getProperties())
                 .putProperties("es.", System.getProperties());
@@ -105,7 +112,9 @@ public class LogConfigurator {
         for (Map.Entry<String, String> entry : settingsBuilder.build().getAsMap().entrySet()) {
             String key = "log4j." + entry.getKey();
             String value = entry.getValue();
-            value = REPLACEMENTS.getOrDefault(value, value);
+            if (replacements.containsKey(value)) {
+                value = replacements.get(value);
+            }
             if (key.endsWith(".value")) {
                 props.setProperty(key.substring(0, key.length() - ".value".length()), value);
             } else if (key.endsWith(".type")) {
diff --git a/core/src/main/java/org/elasticsearch/common/logging/log4j/TerminalAppender.java b/core/src/main/java/org/elasticsearch/common/logging/log4j/TerminalAppender.java
new file mode 100644
index 0000000..3c60c44
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/common/logging/log4j/TerminalAppender.java
@@ -0,0 +1,44 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+
+package org.elasticsearch.common.logging.log4j;
+
+import org.apache.log4j.AppenderSkeleton;
+import org.apache.log4j.spi.LoggingEvent;
+import org.elasticsearch.common.cli.Terminal;
+
+/**
+ * TerminalAppender logs event to Terminal.DEFAULT. It is used for example by the PluginManagerCliParser.
+ * */
+public class TerminalAppender extends AppenderSkeleton {
+    @Override
+    protected void append(LoggingEvent event) {
+        Terminal.DEFAULT.println(event.getRenderedMessage());
+    }
+
+    @Override
+    public void close() {
+    }
+
+    @Override
+    public boolean requiresLayout() {
+        return false;
+    }
+}
diff --git a/core/src/main/java/org/elasticsearch/common/path/PathTrie.java b/core/src/main/java/org/elasticsearch/common/path/PathTrie.java
index 2bee827..3bf2a9b 100644
--- a/core/src/main/java/org/elasticsearch/common/path/PathTrie.java
+++ b/core/src/main/java/org/elasticsearch/common/path/PathTrie.java
@@ -19,15 +19,14 @@
 
 package org.elasticsearch.common.path;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.Strings;
 
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
+import static org.elasticsearch.common.collect.MapBuilder.newMapBuilder;
 
 /**
  *
@@ -46,7 +45,7 @@ public class PathTrie<T> {
     };
 
     private final Decoder decoder;
-    private final TrieNode root;
+    private final TrieNode<T> root;
     private final char separator;
     private T rootValue;
 
@@ -61,10 +60,10 @@ public class PathTrie<T> {
     public PathTrie(char separator, String wildcard, Decoder decoder) {
         this.decoder = decoder;
         this.separator = separator;
-        root = new TrieNode(new String(new char[]{separator}), null, wildcard);
+        root = new TrieNode<>(new String(new char[]{separator}), null, null, wildcard);
     }
 
-    public class TrieNode {
+    public class TrieNode<T> {
         private transient String key;
         private transient T value;
         private boolean isWildcard;
@@ -72,14 +71,17 @@ public class PathTrie<T> {
 
         private transient String namedWildcard;
 
-        private Map<String, TrieNode> children;
+        private ImmutableMap<String, TrieNode<T>> children;
 
-        public TrieNode(String key, T value, String wildcard) {
+        private final TrieNode parent;
+
+        public TrieNode(String key, T value, TrieNode parent, String wildcard) {
             this.key = key;
             this.wildcard = wildcard;
             this.isWildcard = (key.equals(wildcard));
+            this.parent = parent;
             this.value = value;
-            this.children = emptyMap();
+            this.children = ImmutableMap.of();
             if (isNamedWildcard(key)) {
                 namedWildcard = key.substring(key.indexOf('{') + 1, key.indexOf('}'));
             } else {
@@ -96,14 +98,8 @@ public class PathTrie<T> {
             return isWildcard;
         }
 
-        public synchronized void addChild(TrieNode child) {
-            addInnerChild(child.key, child);
-        }
-
-        private void addInnerChild(String key, TrieNode child) {
-            Map<String, TrieNode> newChildren = new HashMap<>(children);
-            newChildren.put(key, child);
-            children = unmodifiableMap(newChildren);
+        public synchronized void addChild(TrieNode<T> child) {
+            children = newMapBuilder(children).put(child.key, child).immutableMap();
         }
 
         public TrieNode getChild(String key) {
@@ -119,11 +115,14 @@ public class PathTrie<T> {
             if (isNamedWildcard(token)) {
                 key = wildcard;
             }
-            TrieNode node = children.get(key);
+            TrieNode<T> node = children.get(key);
             if (node == null) {
-                T nodeValue = index == path.length - 1 ? value : null;
-                node = new TrieNode(token, nodeValue, wildcard);
-                addInnerChild(key, node);
+                if (index == (path.length - 1)) {
+                    node = new TrieNode<>(token, value, this, wildcard);
+                } else {
+                    node = new TrieNode<>(token, null, this, wildcard);
+                }
+                children = newMapBuilder(children).put(key, node).immutableMap();
             } else {
                 if (isNamedWildcard(token)) {
                     node.updateKeyWithNamedWildcard(token);
@@ -159,7 +158,7 @@ public class PathTrie<T> {
                 return null;
 
             String token = path[index];
-            TrieNode node = children.get(token);
+            TrieNode<T> node = children.get(token);
             boolean usedWildcard;
             if (node == null) {
                 node = children.get(wildcard);
@@ -196,16 +195,11 @@ public class PathTrie<T> {
             return res;
         }
 
-        private void put(Map<String, String> params, TrieNode node, String value) {
+        private void put(Map<String, String> params, TrieNode<T> node, String value) {
             if (params != null && node.isNamedWildcard()) {
                 params.put(node.namedWildcard(), value);
             }
         }
-
-        @Override
-        public String toString() {
-            return key;
-        }
     }
 
     public void insert(String path, T value) {
diff --git a/core/src/main/java/org/elasticsearch/common/settings/Settings.java b/core/src/main/java/org/elasticsearch/common/settings/Settings.java
index 663abd7..e368430 100644
--- a/core/src/main/java/org/elasticsearch/common/settings/Settings.java
+++ b/core/src/main/java/org/elasticsearch/common/settings/Settings.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.common.settings;
 
+import java.nio.charset.StandardCharsets;
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.Booleans;
 import org.elasticsearch.common.Strings;
@@ -28,40 +30,20 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.property.PropertyPlaceholder;
 import org.elasticsearch.common.settings.loader.SettingsLoader;
 import org.elasticsearch.common.settings.loader.SettingsLoaderFactory;
-import org.elasticsearch.common.unit.ByteSizeUnit;
-import org.elasticsearch.common.unit.ByteSizeValue;
-import org.elasticsearch.common.unit.MemorySizeValue;
-import org.elasticsearch.common.unit.RatioValue;
-import org.elasticsearch.common.unit.SizeValue;
-import org.elasticsearch.common.unit.TimeValue;
+import org.elasticsearch.common.unit.*;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
-import java.nio.charset.StandardCharsets;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Properties;
-import java.util.Set;
-import java.util.SortedMap;
-import java.util.TreeMap;
+import java.util.*;
 import java.util.concurrent.TimeUnit;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.Strings.toCamelCase;
 import static org.elasticsearch.common.unit.ByteSizeValue.parseBytesSizeValue;
 import static org.elasticsearch.common.unit.SizeValue.parseSizeValue;
@@ -88,8 +70,8 @@ public final class Settings implements ToXContent {
         return settingsRequireUnits;
     }
 
-    private final Map<String, String> forcedUnderscoreSettings;
     private SortedMap<String, String> settings;
+    private final ImmutableMap<String, String> forcedUnderscoreSettings;
 
     Settings(Map<String, String> settings) {
         // we use a sorted map for consistent serialization when using getAsMap()
@@ -104,7 +86,7 @@ public final class Settings implements ToXContent {
                 forcedUnderscoreSettings.put(toUnderscoreCase, entry.getValue());
             }
         }
-        this.forcedUnderscoreSettings = forcedUnderscoreSettings == null ? emptyMap() : unmodifiableMap(forcedUnderscoreSettings);
+        this.forcedUnderscoreSettings = forcedUnderscoreSettings == null ? ImmutableMap.<String, String>of() : ImmutableMap.copyOf(forcedUnderscoreSettings);
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/common/transport/TransportAddressSerializers.java b/core/src/main/java/org/elasticsearch/common/transport/TransportAddressSerializers.java
index 026f849..d8e121b 100644
--- a/core/src/main/java/org/elasticsearch/common/transport/TransportAddressSerializers.java
+++ b/core/src/main/java/org/elasticsearch/common/transport/TransportAddressSerializers.java
@@ -19,16 +19,16 @@
 
 package org.elasticsearch.common.transport;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 
 import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
+import java.lang.reflect.Constructor;
 
-import static java.util.Collections.unmodifiableMap;
+import static org.elasticsearch.common.collect.MapBuilder.newMapBuilder;
 
 /**
  * A global registry of all different types of {@link org.elasticsearch.common.transport.TransportAddress} allowing
@@ -42,25 +42,23 @@ public abstract class TransportAddressSerializers {
 
     private static final ESLogger logger = Loggers.getLogger(TransportAddressSerializers.class);
 
-    private static final Map<Short, TransportAddress> ADDRESS_REGISTRY;
+    private static ImmutableMap<Short, TransportAddress> ADDRESS_REGISTRY = ImmutableMap.of();
 
     static {
-        Map<Short, TransportAddress> registry = new HashMap<>();
         try {
-            addAddressType(registry, DummyTransportAddress.INSTANCE);
-            addAddressType(registry, InetSocketTransportAddress.PROTO);
-            addAddressType(registry, LocalTransportAddress.PROTO);
+            addAddressType(DummyTransportAddress.INSTANCE);
+            addAddressType(InetSocketTransportAddress.PROTO);
+            addAddressType(LocalTransportAddress.PROTO);
         } catch (Exception e) {
-            logger.warn("Failed to setup TransportAddresses", e);
+            logger.warn("Failed to add InetSocketTransportAddress", e);
         }
-        ADDRESS_REGISTRY = unmodifiableMap(registry);
     }
 
-    public static synchronized void addAddressType(Map<Short, TransportAddress> registry, TransportAddress address) throws Exception {
-        if (registry.containsKey(address.uniqueAddressTypeId())) {
+    public static synchronized void addAddressType(TransportAddress address) throws Exception {
+        if (ADDRESS_REGISTRY.containsKey(address.uniqueAddressTypeId())) {
             throw new IllegalStateException("Address [" + address.uniqueAddressTypeId() + "] already bound");
         }
-        registry.put(address.uniqueAddressTypeId(), address);
+        ADDRESS_REGISTRY = newMapBuilder(ADDRESS_REGISTRY).put(address.uniqueAddressTypeId(), address).immutableMap();
     }
 
     public static TransportAddress addressFromStream(StreamInput input) throws IOException {
diff --git a/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java b/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java
index d989a91..e4a074b 100644
--- a/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java
+++ b/core/src/main/java/org/elasticsearch/common/util/CollectionUtils.java
@@ -23,26 +23,10 @@ import com.carrotsearch.hppc.DoubleArrayList;
 import com.carrotsearch.hppc.FloatArrayList;
 import com.carrotsearch.hppc.LongArrayList;
 import com.carrotsearch.hppc.ObjectArrayList;
-import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.google.common.collect.Iterators;
+import org.apache.lucene.util.*;
 
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BytesRefArray;
-import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.InPlaceMergeSorter;
-import org.apache.lucene.util.IntroSorter;
-
-import java.util.AbstractList;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Objects;
-import java.util.RandomAccess;
+import java.util.*;
 
 /** Collections-related utility methods. */
 public enum CollectionUtils {
@@ -474,9 +458,4 @@ public enum CollectionUtils {
         return result;
     }
 
-    public static <E> void addAll(Collection<E> collection, Iterable<ObjectCursor<E>> iterable) {
-        for (ObjectCursor<E> c: iterable) {
-            collection.add(c.value);
-        }
-    }
 }
diff --git a/core/src/main/java/org/elasticsearch/gateway/DanglingIndicesState.java b/core/src/main/java/org/elasticsearch/gateway/DanglingIndicesState.java
index 0ebba04..e4285d2 100644
--- a/core/src/main/java/org/elasticsearch/gateway/DanglingIndicesState.java
+++ b/core/src/main/java/org/elasticsearch/gateway/DanglingIndicesState.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.gateway;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.common.component.AbstractComponent;
@@ -33,9 +34,6 @@ import java.util.HashMap;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * The dangling indices state is responsible for finding new dangling indices (indices that have
  * their state written on disk, but don't exists in the metadata of the cluster), and importing
@@ -75,8 +73,7 @@ public class DanglingIndicesState extends AbstractComponent {
      * The current set of dangling indices.
      */
     Map<String, IndexMetaData> getDanglingIndices() {
-        // This might be a good use case for CopyOnWriteHashMap
-        return unmodifiableMap(new HashMap<>(danglingIndices));
+        return ImmutableMap.copyOf(danglingIndices);
     }
 
     /**
@@ -110,7 +107,7 @@ public class DanglingIndicesState extends AbstractComponent {
             indices = nodeEnv.findAllIndices();
         } catch (Throwable e) {
             logger.warn("failed to list dangling indices", e);
-            return emptyMap();
+            return ImmutableMap.of();
         }
 
         Map<String, IndexMetaData>  newIndices = new HashMap<>();
diff --git a/core/src/main/java/org/elasticsearch/gateway/GatewayService.java b/core/src/main/java/org/elasticsearch/gateway/GatewayService.java
index 855b6ce..742f789 100644
--- a/core/src/main/java/org/elasticsearch/gateway/GatewayService.java
+++ b/core/src/main/java/org/elasticsearch/gateway/GatewayService.java
@@ -20,12 +20,7 @@
 package org.elasticsearch.gateway;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-
-import org.elasticsearch.cluster.ClusterChangedEvent;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.ClusterStateListener;
-import org.elasticsearch.cluster.ClusterStateUpdateTask;
+import org.elasticsearch.cluster.*;
 import org.elasticsearch.cluster.block.ClusterBlock;
 import org.elasticsearch.cluster.block.ClusterBlockLevel;
 import org.elasticsearch.cluster.block.ClusterBlocks;
@@ -258,7 +253,7 @@ public class GatewayService extends AbstractLifecycleComponent<GatewayService> i
                     routingTableBuilder.version(0);
 
                     // now, reroute
-                    RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(routingTableBuilder.build()).build());
+                    RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(routingTableBuilder).build());
 
                     return ClusterState.builder(updatedState).routingResult(routingResult).build();
                 }
diff --git a/core/src/main/java/org/elasticsearch/gateway/LocalAllocateDangledIndices.java b/core/src/main/java/org/elasticsearch/gateway/LocalAllocateDangledIndices.java
index b8491b9..1ab7a56 100644
--- a/core/src/main/java/org/elasticsearch/gateway/LocalAllocateDangledIndices.java
+++ b/core/src/main/java/org/elasticsearch/gateway/LocalAllocateDangledIndices.java
@@ -37,13 +37,7 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.discovery.MasterNotDiscoveredException;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.TransportChannel;
-import org.elasticsearch.transport.TransportException;
-import org.elasticsearch.transport.TransportRequest;
-import org.elasticsearch.transport.TransportRequestHandler;
-import org.elasticsearch.transport.TransportResponse;
-import org.elasticsearch.transport.TransportResponseHandler;
-import org.elasticsearch.transport.TransportService;
+import org.elasticsearch.transport.*;
 
 import java.io.IOException;
 import java.util.Arrays;
@@ -164,11 +158,10 @@ public class LocalAllocateDangledIndices extends AbstractComponent {
                     }
                     logger.info("auto importing dangled indices {} from [{}]", sb.toString(), request.fromNode);
 
-                    RoutingTable routingTable = routingTableBuilder.build();
-                    ClusterState updatedState = ClusterState.builder(currentState).metaData(metaData).blocks(blocks).routingTable(routingTable).build();
+                    ClusterState updatedState = ClusterState.builder(currentState).metaData(metaData).blocks(blocks).routingTable(routingTableBuilder).build();
 
                     // now, reroute
-                    RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(routingTable).build());
+                    RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(routingTableBuilder).build());
 
                     return ClusterState.builder(updatedState).routingResult(routingResult).build();
                 }
diff --git a/core/src/main/java/org/elasticsearch/http/HttpServer.java b/core/src/main/java/org/elasticsearch/http/HttpServer.java
index f3b8c3f..168ed06 100644
--- a/core/src/main/java/org/elasticsearch/http/HttpServer.java
+++ b/core/src/main/java/org/elasticsearch/http/HttpServer.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.http;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.io.FileSystemUtils;
@@ -26,29 +28,18 @@ import org.elasticsearch.common.io.Streams;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.env.Environment;
 import org.elasticsearch.node.service.NodeService;
-import org.elasticsearch.rest.BytesRestResponse;
-import org.elasticsearch.rest.RestChannel;
-import org.elasticsearch.rest.RestController;
-import org.elasticsearch.rest.RestFilter;
-import org.elasticsearch.rest.RestFilterChain;
-import org.elasticsearch.rest.RestRequest;
-import org.elasticsearch.rest.RestStatus;
+import org.elasticsearch.rest.*;
 
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
-import java.nio.file.Files;
-import java.nio.file.Path;
+import java.nio.file.*;
 import java.nio.file.attribute.BasicFileAttributes;
 import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-import static org.elasticsearch.rest.RestStatus.FORBIDDEN;
-import static org.elasticsearch.rest.RestStatus.INTERNAL_SERVER_ERROR;
-import static org.elasticsearch.rest.RestStatus.NOT_FOUND;
-import static org.elasticsearch.rest.RestStatus.OK;
+import static org.elasticsearch.rest.RestStatus.*;
 
 /**
  *
@@ -213,7 +204,7 @@ public class HttpServer extends AbstractLifecycleComponent<HttpServer> {
         final String separator = siteFile.getFileSystem().getSeparator();
         // Convert file separators.
         sitePath = sitePath.replace("/", separator);
-
+        
         Path file = siteFile.resolve(sitePath);
 
         // return not found instead of forbidden to prevent malicious requests to find out if files exist or dont exist
@@ -284,7 +275,7 @@ public class HttpServer extends AbstractLifecycleComponent<HttpServer> {
         mimeTypes.put("svg", "image/svg+xml");
         mimeTypes.put("ico", "image/vnd.microsoft.icon");
         mimeTypes.put("mp3", "audio/mpeg");
-        DEFAULT_MIME_TYPES = unmodifiableMap(mimeTypes);
+        DEFAULT_MIME_TYPES = ImmutableMap.copyOf(mimeTypes);
     }
 
     public static final Map<String, String> DEFAULT_MIME_TYPES;
diff --git a/core/src/main/java/org/elasticsearch/index/IndexService.java b/core/src/main/java/org/elasticsearch/index/IndexService.java
index 602ccc3..2fc7a24 100644
--- a/core/src/main/java/org/elasticsearch/index/IndexService.java
+++ b/core/src/main/java/org/elasticsearch/index/IndexService.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.ElasticsearchException;
@@ -41,11 +42,7 @@ import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.query.IndexQueryParserService;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.settings.IndexSettingsService;
-import org.elasticsearch.index.shard.IndexShard;
-import org.elasticsearch.index.shard.ShadowIndexShard;
-import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.shard.ShardNotFoundException;
-import org.elasticsearch.index.shard.ShardPath;
+import org.elasticsearch.index.shard.*;
 import org.elasticsearch.index.similarity.SimilarityService;
 import org.elasticsearch.index.store.IndexStore;
 import org.elasticsearch.index.store.Store;
@@ -62,8 +59,6 @@ import java.util.Set;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.collect.MapBuilder.newMapBuilder;
 
 /**
@@ -81,7 +76,7 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
     private final IndicesService indicesServices;
     private final IndexServicesProvider indexServicesProvider;
     private final IndexStore indexStore;
-    private volatile Map<Integer, IndexShard> shards = emptyMap();
+    private volatile ImmutableMap<Integer, IndexShard> shards = ImmutableMap.of();
     private final AtomicBoolean closed = new AtomicBoolean(false);
     private final AtomicBoolean deleted = new AtomicBoolean(false);
 
@@ -318,9 +313,9 @@ public class IndexService extends AbstractIndexComponent implements IndexCompone
             return;
         }
         logger.debug("[{}] closing... (reason: [{}])", shardId, reason);
-        HashMap<Integer, IndexShard> newShards = new HashMap<>(shards);
-        indexShard = newShards.remove(shardId);
-        shards = unmodifiableMap(newShards);
+        HashMap<Integer, IndexShard> tmpShardsMap = new HashMap<>(shards);
+        indexShard = tmpShardsMap.remove(shardId);
+        shards = ImmutableMap.copyOf(tmpShardsMap);
         closeShard(reason, sId, indexShard, indexShard.store());
         logger.debug("[{}] closed (reason: [{}])", shardId, reason);
     }
diff --git a/core/src/main/java/org/elasticsearch/index/analysis/Analysis.java b/core/src/main/java/org/elasticsearch/index/analysis/Analysis.java
index 861f070..1040a27 100644
--- a/core/src/main/java/org/elasticsearch/index/analysis/Analysis.java
+++ b/core/src/main/java/org/elasticsearch/index/analysis/Analysis.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.index.analysis;
 
+import java.nio.charset.StandardCharsets;
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.NumericTokenStream;
 import org.apache.lucene.analysis.TokenStream;
@@ -58,6 +60,7 @@ import org.apache.lucene.analysis.tr.TurkishAnalyzer;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.util.Version;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.io.FileSystemUtils;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.lucene.Lucene;
@@ -68,19 +71,15 @@ import org.elasticsearch.index.settings.IndexSettings;
 import java.io.BufferedReader;
 import java.io.IOException;
 import java.io.Reader;
-import java.nio.charset.StandardCharsets;
 import java.nio.file.Path;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
-import java.util.HashMap;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  *
  */
@@ -125,44 +124,40 @@ public class Analysis {
         }
     }
 
-    public static final Map<String, Set<?>> NAMED_STOP_WORDS;
-    static {
-        Map<String, Set<?>> namedStopWords = new HashMap<>();
-        namedStopWords.put("_arabic_", ArabicAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_armenian_", ArmenianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_basque_", BasqueAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_brazilian_", BrazilianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_bulgarian_", BulgarianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_catalan_", CatalanAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_czech_", CzechAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_danish_", DanishAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_dutch_", DutchAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_english_", EnglishAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_finnish_", FinnishAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_french_", FrenchAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_galician_", GalicianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_german_", GermanAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_greek_", GreekAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_hindi_", HindiAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_hungarian_", HungarianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_indonesian_", IndonesianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_irish_", IrishAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_italian_", ItalianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_latvian_", LatvianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_lithuanian_", LithuanianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_norwegian_", NorwegianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_persian_", PersianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_portuguese_", PortugueseAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_romanian_", RomanianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_russian_", RussianAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_sorani_", SoraniAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_spanish_", SpanishAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_swedish_", SwedishAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_thai_", ThaiAnalyzer.getDefaultStopSet());
-        namedStopWords.put("_turkish_", TurkishAnalyzer.getDefaultStopSet());
-
-        NAMED_STOP_WORDS = unmodifiableMap(namedStopWords);
-    }
+    public static final ImmutableMap<String, Set<?>> namedStopWords = MapBuilder.<String, Set<?>>newMapBuilder()
+            .put("_arabic_", ArabicAnalyzer.getDefaultStopSet())
+            .put("_armenian_", ArmenianAnalyzer.getDefaultStopSet())
+            .put("_basque_", BasqueAnalyzer.getDefaultStopSet())
+            .put("_brazilian_", BrazilianAnalyzer.getDefaultStopSet())
+            .put("_bulgarian_", BulgarianAnalyzer.getDefaultStopSet())
+            .put("_catalan_", CatalanAnalyzer.getDefaultStopSet())
+            .put("_czech_", CzechAnalyzer.getDefaultStopSet())
+            .put("_danish_", DanishAnalyzer.getDefaultStopSet())
+            .put("_dutch_", DutchAnalyzer.getDefaultStopSet())
+            .put("_english_", EnglishAnalyzer.getDefaultStopSet())
+            .put("_finnish_", FinnishAnalyzer.getDefaultStopSet())
+            .put("_french_", FrenchAnalyzer.getDefaultStopSet())
+            .put("_galician_", GalicianAnalyzer.getDefaultStopSet())
+            .put("_german_", GermanAnalyzer.getDefaultStopSet())
+            .put("_greek_", GreekAnalyzer.getDefaultStopSet())
+            .put("_hindi_", HindiAnalyzer.getDefaultStopSet())
+            .put("_hungarian_", HungarianAnalyzer.getDefaultStopSet())
+            .put("_indonesian_", IndonesianAnalyzer.getDefaultStopSet())
+            .put("_irish_", IrishAnalyzer.getDefaultStopSet())
+            .put("_italian_", ItalianAnalyzer.getDefaultStopSet())
+            .put("_latvian_", LatvianAnalyzer.getDefaultStopSet())
+            .put("_lithuanian_", LithuanianAnalyzer.getDefaultStopSet())
+            .put("_norwegian_", NorwegianAnalyzer.getDefaultStopSet())
+            .put("_persian_", PersianAnalyzer.getDefaultStopSet())
+            .put("_portuguese_", PortugueseAnalyzer.getDefaultStopSet())
+            .put("_romanian_", RomanianAnalyzer.getDefaultStopSet())
+            .put("_russian_", RussianAnalyzer.getDefaultStopSet())
+            .put("_sorani_", SoraniAnalyzer.getDefaultStopSet())
+            .put("_spanish_", SpanishAnalyzer.getDefaultStopSet())
+            .put("_swedish_", SwedishAnalyzer.getDefaultStopSet())
+            .put("_thai_", ThaiAnalyzer.getDefaultStopSet())
+            .put("_turkish_", TurkishAnalyzer.getDefaultStopSet())
+            .immutableMap();
 
     public static CharArraySet parseWords(Environment env, Settings settings, String name, CharArraySet defaultWords, Map<String, Set<?>> namedWords, boolean ignoreCase) {
         String value = settings.get(name);
@@ -181,7 +176,7 @@ public class Analysis {
     }
 
     public static CharArraySet parseCommonWords(Environment env, Settings settings, CharArraySet defaultCommonWords, boolean ignoreCase) {
-        return parseWords(env, settings, "common_words", defaultCommonWords, NAMED_STOP_WORDS, ignoreCase);
+        return parseWords(env, settings, "common_words", defaultCommonWords, namedStopWords, ignoreCase);
     }
 
     public static CharArraySet parseArticles(Environment env, Settings settings) {
@@ -193,7 +188,7 @@ public class Analysis {
     }
 
     public static CharArraySet parseStopWords(Environment env, Settings settings, CharArraySet defaultStopWords, boolean ignoreCase) {
-        return parseWords(env, settings, "stopwords", defaultStopWords, NAMED_STOP_WORDS, ignoreCase);
+        return parseWords(env, settings, "stopwords", defaultStopWords, namedStopWords, ignoreCase);
     }
 
     private static CharArraySet resolveNamedWords(Collection<String> words, Map<String, Set<?>> namedWords, boolean ignoreCase) {
diff --git a/core/src/main/java/org/elasticsearch/index/analysis/AnalysisService.java b/core/src/main/java/org/elasticsearch/index/analysis/AnalysisService.java
index c76446c..829f9db 100644
--- a/core/src/main/java/org/elasticsearch/index/analysis/AnalysisService.java
+++ b/core/src/main/java/org/elasticsearch/index/analysis/AnalysisService.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.analysis;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.analysis.Analyzer;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -36,17 +37,15 @@ import java.io.Closeable;
 import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  *
  */
 public class AnalysisService extends AbstractIndexComponent implements Closeable {
 
-    private final Map<String, NamedAnalyzer> analyzers;
-    private final Map<String, TokenizerFactory> tokenizers;
-    private final Map<String, CharFilterFactory> charFilters;
-    private final Map<String, TokenFilterFactory> tokenFilters;
+    private final ImmutableMap<String, NamedAnalyzer> analyzers;
+    private final ImmutableMap<String, TokenizerFactory> tokenizers;
+    private final ImmutableMap<String, CharFilterFactory> charFilters;
+    private final ImmutableMap<String, TokenFilterFactory> tokenFilters;
 
     private final NamedAnalyzer defaultAnalyzer;
     private final NamedAnalyzer defaultIndexAnalyzer;
@@ -99,7 +98,7 @@ public class AnalysisService extends AbstractIndexComponent implements Closeable
             }
         }
 
-        this.tokenizers = unmodifiableMap(tokenizers);
+        this.tokenizers = ImmutableMap.copyOf(tokenizers);
 
         Map<String, CharFilterFactory> charFilters = new HashMap<>();
         if (charFilterFactoryFactories != null) {
@@ -134,7 +133,7 @@ public class AnalysisService extends AbstractIndexComponent implements Closeable
             }
         }
 
-        this.charFilters = unmodifiableMap(charFilters);
+        this.charFilters = ImmutableMap.copyOf(charFilters);
 
         Map<String, TokenFilterFactory> tokenFilters = new HashMap<>();
         if (tokenFilterFactoryFactories != null) {
@@ -169,7 +168,7 @@ public class AnalysisService extends AbstractIndexComponent implements Closeable
                 }
             }
         }
-        this.tokenFilters = unmodifiableMap(tokenFilters);
+        this.tokenFilters = ImmutableMap.copyOf(tokenFilters);
 
         Map<String, AnalyzerProvider> analyzerProviders = new HashMap<>();
         if (analyzerFactoryFactories != null) {
@@ -276,7 +275,7 @@ public class AnalysisService extends AbstractIndexComponent implements Closeable
                 throw new IllegalArgumentException("analyzer name must not start with '_'. got \"" + analyzer.getKey() + "\"");
             }
         }
-        this.analyzers = unmodifiableMap(analyzers);
+        this.analyzers = ImmutableMap.copyOf(analyzers);
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/index/analysis/NGramTokenizerFactory.java b/core/src/main/java/org/elasticsearch/index/analysis/NGramTokenizerFactory.java
index f1ad1d5..b884095 100644
--- a/core/src/main/java/org/elasticsearch/index/analysis/NGramTokenizerFactory.java
+++ b/core/src/main/java/org/elasticsearch/index/analysis/NGramTokenizerFactory.java
@@ -19,10 +19,12 @@
 
 package org.elasticsearch.index.analysis;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.ngram.Lucene43NGramTokenizer;
 import org.apache.lucene.analysis.ngram.NGramTokenizer;
 import org.apache.lucene.util.Version;
+
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.assistedinject.Assisted;
 import org.elasticsearch.common.settings.Settings;
@@ -31,12 +33,9 @@ import org.elasticsearch.index.settings.IndexSettings;
 
 import java.lang.reflect.Field;
 import java.lang.reflect.Modifier;
-import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  *
  */
@@ -50,12 +49,12 @@ public class NGramTokenizerFactory extends AbstractTokenizerFactory {
     static final Map<String, CharMatcher> MATCHERS;
 
     static {
-        Map<String, CharMatcher> matchers = new HashMap<>();
-        matchers.put("letter", CharMatcher.Basic.LETTER);
-        matchers.put("digit", CharMatcher.Basic.DIGIT);
-        matchers.put("whitespace", CharMatcher.Basic.WHITESPACE);
-        matchers.put("punctuation", CharMatcher.Basic.PUNCTUATION);
-        matchers.put("symbol", CharMatcher.Basic.SYMBOL);
+        ImmutableMap.Builder<String, CharMatcher> builder = ImmutableMap.builder();
+        builder.put("letter", CharMatcher.Basic.LETTER);
+        builder.put("digit", CharMatcher.Basic.DIGIT);
+        builder.put("whitespace", CharMatcher.Basic.WHITESPACE);
+        builder.put("punctuation", CharMatcher.Basic.PUNCTUATION);
+        builder.put("symbol", CharMatcher.Basic.SYMBOL);
         // Populate with unicode categories from java.lang.Character
         for (Field field : Character.class.getFields()) {
             if (!field.getName().startsWith("DIRECTIONALITY")
@@ -63,14 +62,14 @@ public class NGramTokenizerFactory extends AbstractTokenizerFactory {
                     && Modifier.isStatic(field.getModifiers())
                     && field.getType() == byte.class) {
                 try {
-                    matchers.put(field.getName().toLowerCase(Locale.ROOT), CharMatcher.ByUnicodeCategory.of(field.getByte(null)));
+                    builder.put(field.getName().toLowerCase(Locale.ROOT), CharMatcher.ByUnicodeCategory.of(field.getByte(null)));
                 } catch (Exception e) {
                     // just ignore
                     continue;
                 }
             }
         }
-        MATCHERS = unmodifiableMap(matchers);
+        MATCHERS = builder.build();
     }
 
     static CharMatcher parseTokenChars(String[] characterClasses) {
diff --git a/core/src/main/java/org/elasticsearch/index/analysis/SnowballAnalyzerProvider.java b/core/src/main/java/org/elasticsearch/index/analysis/SnowballAnalyzerProvider.java
index a3f9004..39cf56b 100644
--- a/core/src/main/java/org/elasticsearch/index/analysis/SnowballAnalyzerProvider.java
+++ b/core/src/main/java/org/elasticsearch/index/analysis/SnowballAnalyzerProvider.java
@@ -18,11 +18,13 @@
  */
 package org.elasticsearch.index.analysis;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.analysis.core.StopAnalyzer;
 import org.apache.lucene.analysis.de.GermanAnalyzer;
 import org.apache.lucene.analysis.fr.FrenchAnalyzer;
 import org.apache.lucene.analysis.nl.DutchAnalyzer;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.assistedinject.Assisted;
 import org.elasticsearch.common.settings.Settings;
@@ -30,11 +32,6 @@ import org.elasticsearch.env.Environment;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.settings.IndexSettings;
 
-import java.util.HashMap;
-import java.util.Map;
-
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * Creates a SnowballAnalyzer initialized with stopwords and Snowball filter. Only
  * supports Dutch, English (default), French, German and German2 where stopwords
@@ -49,17 +46,14 @@ import static java.util.Collections.unmodifiableMap;
  *
  */
 public class SnowballAnalyzerProvider extends AbstractIndexAnalyzerProvider<SnowballAnalyzer> {
-    private static final Map<String, CharArraySet> DEFAULT_LANGUAGE_STOPWORDS;
 
-    static {
-        Map<String, CharArraySet> defaultLanguageStopwords = new HashMap<>();
-        defaultLanguageStopwords.put("English", StopAnalyzer.ENGLISH_STOP_WORDS_SET);
-        defaultLanguageStopwords.put("Dutch", DutchAnalyzer.getDefaultStopSet());
-        defaultLanguageStopwords.put("German", GermanAnalyzer.getDefaultStopSet());
-        defaultLanguageStopwords.put("German2", GermanAnalyzer.getDefaultStopSet());
-        defaultLanguageStopwords.put("French", FrenchAnalyzer.getDefaultStopSet());
-        DEFAULT_LANGUAGE_STOPWORDS = unmodifiableMap(defaultLanguageStopwords);
-    }
+    private static final ImmutableMap<String, CharArraySet> defaultLanguageStopwords = MapBuilder.<String, CharArraySet>newMapBuilder()
+            .put("English", StopAnalyzer.ENGLISH_STOP_WORDS_SET)
+            .put("Dutch", DutchAnalyzer.getDefaultStopSet())
+            .put("German", GermanAnalyzer.getDefaultStopSet())
+            .put("German2", GermanAnalyzer.getDefaultStopSet())
+            .put("French", FrenchAnalyzer.getDefaultStopSet())
+            .immutableMap();
 
     private final SnowballAnalyzer analyzer;
 
@@ -68,7 +62,7 @@ public class SnowballAnalyzerProvider extends AbstractIndexAnalyzerProvider<Snow
         super(index, indexSettings, name, settings);
 
         String language = settings.get("language", settings.get("name", "English"));
-        CharArraySet defaultStopwords = DEFAULT_LANGUAGE_STOPWORDS.getOrDefault(language, CharArraySet.EMPTY_SET);
+        CharArraySet defaultStopwords = defaultLanguageStopwords.containsKey(language) ? defaultLanguageStopwords.get(language) : CharArraySet.EMPTY_SET;
         CharArraySet stopWords = Analysis.parseStopWords(env, settings, defaultStopwords);
 
         analyzer = new SnowballAnalyzer(language, stopWords);
diff --git a/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java b/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java
index de3adbc..a9713ce 100644
--- a/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java
+++ b/core/src/main/java/org/elasticsearch/index/fielddata/IndexFieldDataService.java
@@ -19,8 +19,10 @@
 
 package org.elasticsearch.index.fielddata;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.util.Accountable;
 import org.elasticsearch.ExceptionsHelper;
+import org.elasticsearch.Version;
 import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.inject.Inject;
@@ -39,7 +41,6 @@ import org.elasticsearch.index.fielddata.plain.PackedArrayIndexFieldData;
 import org.elasticsearch.index.fielddata.plain.PagedBytesIndexFieldData;
 import org.elasticsearch.index.fielddata.plain.ParentChildIndexFieldData;
 import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.MappedFieldType.Names;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.index.mapper.core.BooleanFieldMapper;
 import org.elasticsearch.index.mapper.internal.IndexFieldMapper;
@@ -55,7 +56,7 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
+import static org.elasticsearch.index.mapper.MappedFieldType.Names;
 
 /**
  */
@@ -69,28 +70,26 @@ public class IndexFieldDataService extends AbstractIndexComponent {
     private static final String ARRAY_FORMAT = "array";
     private static final String PAGED_BYTES_FORMAT = "paged_bytes";
 
-    private final static Map<String, IndexFieldData.Builder> buildersByType;
-    private final static Map<String, IndexFieldData.Builder> docValuesBuildersByType;
-    private final static Map<Tuple<String, String>, IndexFieldData.Builder> buildersByTypeAndFormat;
+    private final static ImmutableMap<String, IndexFieldData.Builder> buildersByType;
+    private final static ImmutableMap<String, IndexFieldData.Builder> docValuesBuildersByType;
+    private final static ImmutableMap<Tuple<String, String>, IndexFieldData.Builder> buildersByTypeAndFormat;
     private final CircuitBreakerService circuitBreakerService;
 
     static {
-        Map<String, IndexFieldData.Builder> buildersByTypeBuilder = new HashMap<>();
-        buildersByTypeBuilder.put("string", new PagedBytesIndexFieldData.Builder());
-        buildersByTypeBuilder.put("float", new FloatArrayIndexFieldData.Builder());
-        buildersByTypeBuilder.put("double", new DoubleArrayIndexFieldData.Builder());
-        buildersByTypeBuilder.put("byte", new PackedArrayIndexFieldData.Builder().setNumericType(IndexNumericFieldData.NumericType.BYTE));
-        buildersByTypeBuilder.put("short", new PackedArrayIndexFieldData.Builder().setNumericType(IndexNumericFieldData.NumericType.SHORT));
-        buildersByTypeBuilder.put("int", new PackedArrayIndexFieldData.Builder().setNumericType(IndexNumericFieldData.NumericType.INT));
-        buildersByTypeBuilder.put("long", new PackedArrayIndexFieldData.Builder().setNumericType(IndexNumericFieldData.NumericType.LONG));
-        buildersByTypeBuilder.put("geo_point", new GeoPointDoubleArrayIndexFieldData.Builder());
-        buildersByTypeBuilder.put(ParentFieldMapper.NAME, new ParentChildIndexFieldData.Builder());
-        buildersByTypeBuilder.put(IndexFieldMapper.NAME, new IndexIndexFieldData.Builder());
-        buildersByTypeBuilder.put("binary", new DisabledIndexFieldData.Builder());
-        buildersByTypeBuilder.put(BooleanFieldMapper.CONTENT_TYPE,
-                new PackedArrayIndexFieldData.Builder().setNumericType(IndexNumericFieldData.NumericType.BOOLEAN));
-         buildersByType = unmodifiableMap(buildersByTypeBuilder);
-
+        buildersByType = MapBuilder.<String, IndexFieldData.Builder>newMapBuilder()
+                .put("string", new PagedBytesIndexFieldData.Builder())
+                .put("float", new FloatArrayIndexFieldData.Builder())
+                .put("double", new DoubleArrayIndexFieldData.Builder())
+                .put("byte", new PackedArrayIndexFieldData.Builder().setNumericType(IndexNumericFieldData.NumericType.BYTE))
+                .put("short", new PackedArrayIndexFieldData.Builder().setNumericType(IndexNumericFieldData.NumericType.SHORT))
+                .put("int", new PackedArrayIndexFieldData.Builder().setNumericType(IndexNumericFieldData.NumericType.INT))
+                .put("long", new PackedArrayIndexFieldData.Builder().setNumericType(IndexNumericFieldData.NumericType.LONG))
+                .put("geo_point", new GeoPointDoubleArrayIndexFieldData.Builder())
+                .put(ParentFieldMapper.NAME, new ParentChildIndexFieldData.Builder())
+                .put(IndexFieldMapper.NAME, new IndexIndexFieldData.Builder())
+                .put("binary", new DisabledIndexFieldData.Builder())
+                .put(BooleanFieldMapper.CONTENT_TYPE, new PackedArrayIndexFieldData.Builder().setNumericType(IndexNumericFieldData.NumericType.BOOLEAN))
+                .immutableMap();
 
         docValuesBuildersByType = MapBuilder.<String, IndexFieldData.Builder>newMapBuilder()
                 .put("string", new DocValuesIndexFieldData.Builder())
diff --git a/core/src/main/java/org/elasticsearch/index/fieldvisitor/FieldsVisitor.java b/core/src/main/java/org/elasticsearch/index/fieldvisitor/FieldsVisitor.java
index 899da8f..fa4b587 100644
--- a/core/src/main/java/org/elasticsearch/index/fieldvisitor/FieldsVisitor.java
+++ b/core/src/main/java/org/elasticsearch/index/fieldvisitor/FieldsVisitor.java
@@ -18,6 +18,8 @@
  */
 package org.elasticsearch.index.fieldvisitor;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.apache.lucene.index.FieldInfo;
 import org.apache.lucene.index.StoredFieldVisitor;
 import org.apache.lucene.index.StoredFieldVisitor;
@@ -45,7 +47,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.emptyMap;
 import static java.util.Collections.unmodifiableSet;
 import static org.elasticsearch.common.util.set.Sets.newHashSet;
 
@@ -190,7 +191,9 @@ public class FieldsVisitor extends StoredFieldVisitor {
     }
 
     public Map<String, List<Object>> fields() {
-        return fieldsValues != null ? fieldsValues : emptyMap();
+        return fieldsValues != null
+                ? fieldsValues
+                : ImmutableMap.<String, List<Object>>of();
     }
 
     public void reset() {
diff --git a/core/src/main/java/org/elasticsearch/index/get/GetResult.java b/core/src/main/java/org/elasticsearch/index/get/GetResult.java
index d243694..c788fcf 100644
--- a/core/src/main/java/org/elasticsearch/index/get/GetResult.java
+++ b/core/src/main/java/org/elasticsearch/index/get/GetResult.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.get;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.compress.CompressorFactory;
@@ -39,7 +40,6 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
 import static org.elasticsearch.index.get.GetField.readGetField;
 
 /**
@@ -68,7 +68,7 @@ public class GetResult implements Streamable, Iterable<GetField>, ToXContent {
         this.source = source;
         this.fields = fields;
         if (this.fields == null) {
-            this.fields = emptyMap();
+            this.fields = ImmutableMap.of();
         }
     }
 
@@ -286,7 +286,7 @@ public class GetResult implements Streamable, Iterable<GetField>, ToXContent {
             }
             int size = in.readVInt();
             if (size == 0) {
-                fields = emptyMap();
+                fields = ImmutableMap.of();
             } else {
                 fields = new HashMap<>(size);
                 for (int i = 0; i < size; i++) {
diff --git a/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java b/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java
index b61ba7f..4f0ea77 100644
--- a/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java
+++ b/core/src/main/java/org/elasticsearch/index/indexing/ShardIndexingService.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.indexing;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.metrics.CounterMetric;
 import org.elasticsearch.common.metrics.MeanMetric;
@@ -34,8 +35,6 @@ import java.util.Map;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.TimeUnit;
 
-import static java.util.Collections.emptyMap;
-
 /**
  */
 public class ShardIndexingService extends AbstractIndexShardComponent {
@@ -46,7 +45,7 @@ public class ShardIndexingService extends AbstractIndexShardComponent {
 
     private final CopyOnWriteArrayList<IndexingOperationListener> listeners = new CopyOnWriteArrayList<>();
 
-    private volatile Map<String, StatsHolder> typesStats = emptyMap();
+    private volatile Map<String, StatsHolder> typesStats = ImmutableMap.of();
 
     public ShardIndexingService(ShardId shardId, Settings indexSettings) {
         super(shardId, indexSettings);
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java
index 0314f8f..54b2c98 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapper.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.mapper;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
@@ -69,8 +70,6 @@ import java.util.Map;
 import java.util.Objects;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 
-import static java.util.Collections.emptyMap;
-
 /**
  *
  */
@@ -86,7 +85,7 @@ public class DocumentMapper implements ToXContent {
 
         private final RootObjectMapper rootObjectMapper;
 
-        private Map<String, Object> meta = emptyMap();
+        private ImmutableMap<String, Object> meta = ImmutableMap.of();
 
         private final Mapper.BuilderContext builderContext;
 
@@ -116,7 +115,7 @@ public class DocumentMapper implements ToXContent {
             this.rootMappers.put(FieldNamesFieldMapper.class, new FieldNamesFieldMapper(indexSettings, mapperService.fullName(FieldNamesFieldMapper.NAME)));
         }
 
-        public Builder meta(Map<String, Object> meta) {
+        public Builder meta(ImmutableMap<String, Object> meta) {
             this.meta = meta;
             return this;
         }
@@ -170,7 +169,7 @@ public class DocumentMapper implements ToXContent {
 
     public DocumentMapper(MapperService mapperService, @Nullable Settings indexSettings, DocumentMapperParser docMapperParser,
                           RootObjectMapper rootObjectMapper,
-                          Map<String, Object> meta,
+                          ImmutableMap<String, Object> meta,
                           Map<Class<? extends MetadataFieldMapper>, MetadataFieldMapper> rootMappers,
                           List<SourceTransform> sourceTransforms,
                           ReentrantReadWriteLock mappingLock) {
@@ -235,7 +234,7 @@ public class DocumentMapper implements ToXContent {
         return this.typeText;
     }
 
-    public Map<String, Object> meta() {
+    public ImmutableMap<String, Object> meta() {
         return mapping.meta;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java
index 65a6d3a..bb991ef 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/DocumentMapperParser.java
@@ -19,10 +19,12 @@
 
 package org.elasticsearch.index.mapper;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseFieldMatcher;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.compress.CompressedXContent;
 import org.elasticsearch.common.geo.ShapesAvailability;
@@ -33,33 +35,10 @@ import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentHelper;
 import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.analysis.AnalysisService;
-import org.elasticsearch.index.mapper.core.BinaryFieldMapper;
-import org.elasticsearch.index.mapper.core.BooleanFieldMapper;
-import org.elasticsearch.index.mapper.core.ByteFieldMapper;
-import org.elasticsearch.index.mapper.core.CompletionFieldMapper;
-import org.elasticsearch.index.mapper.core.DateFieldMapper;
-import org.elasticsearch.index.mapper.core.DoubleFieldMapper;
-import org.elasticsearch.index.mapper.core.FloatFieldMapper;
-import org.elasticsearch.index.mapper.core.IntegerFieldMapper;
-import org.elasticsearch.index.mapper.core.LongFieldMapper;
-import org.elasticsearch.index.mapper.core.ShortFieldMapper;
-import org.elasticsearch.index.mapper.core.StringFieldMapper;
-import org.elasticsearch.index.mapper.core.TokenCountFieldMapper;
-import org.elasticsearch.index.mapper.core.TypeParsers;
+import org.elasticsearch.index.mapper.core.*;
 import org.elasticsearch.index.mapper.geo.GeoPointFieldMapper;
 import org.elasticsearch.index.mapper.geo.GeoShapeFieldMapper;
-import org.elasticsearch.index.mapper.internal.AllFieldMapper;
-import org.elasticsearch.index.mapper.internal.FieldNamesFieldMapper;
-import org.elasticsearch.index.mapper.internal.IdFieldMapper;
-import org.elasticsearch.index.mapper.internal.IndexFieldMapper;
-import org.elasticsearch.index.mapper.internal.ParentFieldMapper;
-import org.elasticsearch.index.mapper.internal.RoutingFieldMapper;
-import org.elasticsearch.index.mapper.internal.SourceFieldMapper;
-import org.elasticsearch.index.mapper.internal.TTLFieldMapper;
-import org.elasticsearch.index.mapper.internal.TimestampFieldMapper;
-import org.elasticsearch.index.mapper.internal.TypeFieldMapper;
-import org.elasticsearch.index.mapper.internal.UidFieldMapper;
-import org.elasticsearch.index.mapper.internal.VersionFieldMapper;
+import org.elasticsearch.index.mapper.internal.*;
 import org.elasticsearch.index.mapper.ip.IpFieldMapper;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
 import org.elasticsearch.index.mapper.object.RootObjectMapper;
@@ -68,16 +47,8 @@ import org.elasticsearch.index.similarity.SimilarityLookupService;
 import org.elasticsearch.script.Script;
 import org.elasticsearch.script.ScriptService;
 
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.SortedMap;
-import java.util.TreeMap;
+import java.util.*;
 
-import static java.util.Collections.unmodifiableMap;
-import static java.util.Collections.unmodifiableSortedMap;
 import static org.elasticsearch.index.mapper.MapperBuilders.doc;
 
 public class DocumentMapperParser {
@@ -95,8 +66,8 @@ public class DocumentMapperParser {
     private final Version indexVersionCreated;
     private final ParseFieldMatcher parseFieldMatcher;
 
-    private volatile Map<String, Mapper.TypeParser> typeParsers;
-    private volatile Map<String, Mapper.TypeParser> rootTypeParsers;
+    private volatile ImmutableMap<String, Mapper.TypeParser> typeParsers;
+    private volatile ImmutableMap<String, Mapper.TypeParser> rootTypeParsers;
     private volatile SortedMap<String, Mapper.TypeParser> additionalRootMappers;
 
     public DocumentMapperParser(@IndexSettings Settings indexSettings, MapperService mapperService, AnalysisService analysisService,
@@ -107,65 +78,66 @@ public class DocumentMapperParser {
         this.analysisService = analysisService;
         this.similarityLookupService = similarityLookupService;
         this.scriptService = scriptService;
-        Map<String, Mapper.TypeParser> typeParsers = new HashMap<>();
-        typeParsers.put(ByteFieldMapper.CONTENT_TYPE, new ByteFieldMapper.TypeParser());
-        typeParsers.put(ShortFieldMapper.CONTENT_TYPE, new ShortFieldMapper.TypeParser());
-        typeParsers.put(IntegerFieldMapper.CONTENT_TYPE, new IntegerFieldMapper.TypeParser());
-        typeParsers.put(LongFieldMapper.CONTENT_TYPE, new LongFieldMapper.TypeParser());
-        typeParsers.put(FloatFieldMapper.CONTENT_TYPE, new FloatFieldMapper.TypeParser());
-        typeParsers.put(DoubleFieldMapper.CONTENT_TYPE, new DoubleFieldMapper.TypeParser());
-        typeParsers.put(BooleanFieldMapper.CONTENT_TYPE, new BooleanFieldMapper.TypeParser());
-        typeParsers.put(BinaryFieldMapper.CONTENT_TYPE, new BinaryFieldMapper.TypeParser());
-        typeParsers.put(DateFieldMapper.CONTENT_TYPE, new DateFieldMapper.TypeParser());
-        typeParsers.put(IpFieldMapper.CONTENT_TYPE, new IpFieldMapper.TypeParser());
-        typeParsers.put(StringFieldMapper.CONTENT_TYPE, new StringFieldMapper.TypeParser());
-        typeParsers.put(TokenCountFieldMapper.CONTENT_TYPE, new TokenCountFieldMapper.TypeParser());
-        typeParsers.put(ObjectMapper.CONTENT_TYPE, new ObjectMapper.TypeParser());
-        typeParsers.put(ObjectMapper.NESTED_CONTENT_TYPE, new ObjectMapper.TypeParser());
-        typeParsers.put(TypeParsers.MULTI_FIELD_CONTENT_TYPE, TypeParsers.multiFieldConverterTypeParser);
-        typeParsers.put(CompletionFieldMapper.CONTENT_TYPE, new CompletionFieldMapper.TypeParser());
-        typeParsers.put(GeoPointFieldMapper.CONTENT_TYPE, new GeoPointFieldMapper.TypeParser());
+        MapBuilder<String, Mapper.TypeParser> typeParsersBuilder = new MapBuilder<String, Mapper.TypeParser>()
+                .put(ByteFieldMapper.CONTENT_TYPE, new ByteFieldMapper.TypeParser())
+                .put(ShortFieldMapper.CONTENT_TYPE, new ShortFieldMapper.TypeParser())
+                .put(IntegerFieldMapper.CONTENT_TYPE, new IntegerFieldMapper.TypeParser())
+                .put(LongFieldMapper.CONTENT_TYPE, new LongFieldMapper.TypeParser())
+                .put(FloatFieldMapper.CONTENT_TYPE, new FloatFieldMapper.TypeParser())
+                .put(DoubleFieldMapper.CONTENT_TYPE, new DoubleFieldMapper.TypeParser())
+                .put(BooleanFieldMapper.CONTENT_TYPE, new BooleanFieldMapper.TypeParser())
+                .put(BinaryFieldMapper.CONTENT_TYPE, new BinaryFieldMapper.TypeParser())
+                .put(DateFieldMapper.CONTENT_TYPE, new DateFieldMapper.TypeParser())
+                .put(IpFieldMapper.CONTENT_TYPE, new IpFieldMapper.TypeParser())
+                .put(StringFieldMapper.CONTENT_TYPE, new StringFieldMapper.TypeParser())
+                .put(TokenCountFieldMapper.CONTENT_TYPE, new TokenCountFieldMapper.TypeParser())
+                .put(ObjectMapper.CONTENT_TYPE, new ObjectMapper.TypeParser())
+                .put(ObjectMapper.NESTED_CONTENT_TYPE, new ObjectMapper.TypeParser())
+                .put(TypeParsers.MULTI_FIELD_CONTENT_TYPE, TypeParsers.multiFieldConverterTypeParser)
+                .put(CompletionFieldMapper.CONTENT_TYPE, new CompletionFieldMapper.TypeParser())
+                .put(GeoPointFieldMapper.CONTENT_TYPE, new GeoPointFieldMapper.TypeParser());
 
         if (ShapesAvailability.JTS_AVAILABLE) {
-            typeParsers.put(GeoShapeFieldMapper.CONTENT_TYPE, new GeoShapeFieldMapper.TypeParser());
+            typeParsersBuilder.put(GeoShapeFieldMapper.CONTENT_TYPE, new GeoShapeFieldMapper.TypeParser());
         }
 
-        this.typeParsers = unmodifiableMap(typeParsers);
-
-        Map<String, Mapper.TypeParser> rootTypeParsers = new HashMap<>();
-        rootTypeParsers.put(IndexFieldMapper.NAME, new IndexFieldMapper.TypeParser());
-        rootTypeParsers.put(SourceFieldMapper.NAME, new SourceFieldMapper.TypeParser());
-        rootTypeParsers.put(TypeFieldMapper.NAME, new TypeFieldMapper.TypeParser());
-        rootTypeParsers.put(AllFieldMapper.NAME, new AllFieldMapper.TypeParser());
-        rootTypeParsers.put(ParentFieldMapper.NAME, new ParentFieldMapper.TypeParser());
-        rootTypeParsers.put(RoutingFieldMapper.NAME, new RoutingFieldMapper.TypeParser());
-        rootTypeParsers.put(TimestampFieldMapper.NAME, new TimestampFieldMapper.TypeParser());
-        rootTypeParsers.put(TTLFieldMapper.NAME, new TTLFieldMapper.TypeParser());
-        rootTypeParsers.put(UidFieldMapper.NAME, new UidFieldMapper.TypeParser());
-        rootTypeParsers.put(VersionFieldMapper.NAME, new VersionFieldMapper.TypeParser());
-        rootTypeParsers.put(IdFieldMapper.NAME, new IdFieldMapper.TypeParser());
-        rootTypeParsers.put(FieldNamesFieldMapper.NAME, new FieldNamesFieldMapper.TypeParser());
-        this.rootTypeParsers = unmodifiableMap(rootTypeParsers);
+        typeParsers = typeParsersBuilder.immutableMap();
+
+        rootTypeParsers = new MapBuilder<String, Mapper.TypeParser>()
+                .put(IndexFieldMapper.NAME, new IndexFieldMapper.TypeParser())
+                .put(SourceFieldMapper.NAME, new SourceFieldMapper.TypeParser())
+                .put(TypeFieldMapper.NAME, new TypeFieldMapper.TypeParser())
+                .put(AllFieldMapper.NAME, new AllFieldMapper.TypeParser())
+                .put(ParentFieldMapper.NAME, new ParentFieldMapper.TypeParser())
+                .put(RoutingFieldMapper.NAME, new RoutingFieldMapper.TypeParser())
+                .put(TimestampFieldMapper.NAME, new TimestampFieldMapper.TypeParser())
+                .put(TTLFieldMapper.NAME, new TTLFieldMapper.TypeParser())
+                .put(UidFieldMapper.NAME, new UidFieldMapper.TypeParser())
+                .put(VersionFieldMapper.NAME, new VersionFieldMapper.TypeParser())
+                .put(IdFieldMapper.NAME, new IdFieldMapper.TypeParser())
+                .put(FieldNamesFieldMapper.NAME, new FieldNamesFieldMapper.TypeParser())
+                .immutableMap();
         additionalRootMappers = Collections.emptySortedMap();
         indexVersionCreated = Version.indexCreated(indexSettings);
     }
 
     public void putTypeParser(String type, Mapper.TypeParser typeParser) {
         synchronized (typeParsersMutex) {
-            Map<String, Mapper.TypeParser> typeParsers = new HashMap<>(this.typeParsers);
-            typeParsers.put(type, typeParser);
-            this.typeParsers = unmodifiableMap(typeParsers);
+            typeParsers = new MapBuilder<>(typeParsers)
+                    .put(type, typeParser)
+                    .immutableMap();
         }
     }
 
     public void putRootTypeParser(String type, Mapper.TypeParser typeParser) {
         synchronized (typeParsersMutex) {
-            Map<String, Mapper.TypeParser> rootTypeParsers = new HashMap<>(this.rootTypeParsers);
-            rootTypeParsers.put(type, typeParser);
-            this.rootTypeParsers = rootTypeParsers;
-            SortedMap<String, Mapper.TypeParser> additionalRootMappers = new TreeMap<>(this.additionalRootMappers);
-            additionalRootMappers.put(type, typeParser);
-            this.additionalRootMappers = unmodifiableSortedMap(additionalRootMappers);
+            rootTypeParsers = new MapBuilder<>(rootTypeParsers)
+                    .put(type, typeParser)
+                    .immutableMap();
+            SortedMap<String, Mapper.TypeParser> newAdditionalRootMappers = new TreeMap<>();
+            newAdditionalRootMappers.putAll(additionalRootMappers);
+            newAdditionalRootMappers.put(type, typeParser);
+            additionalRootMappers = Collections.unmodifiableSortedMap(newAdditionalRootMappers);
         }
     }
 
@@ -268,12 +240,11 @@ public class DocumentMapperParser {
             }
         }
 
-        Map<String, Object> meta = (Map<String, Object>) mapping.remove("_meta");
-        if (meta != null) {
-            // It may not be required to copy meta here to maintain immutability
-            // but the cost is pretty low here.
-            docBuilder.meta(unmodifiableMap(new HashMap<>(meta)));
+        ImmutableMap<String, Object> attributes = ImmutableMap.of();
+        if (mapping.containsKey("_meta")) {
+            attributes = ImmutableMap.copyOf((Map<String, Object>) mapping.remove("_meta"));
         }
+        docBuilder.meta(attributes);
 
         checkNoRemainingFields(mapping, parserContext.indexVersionCreated(), "Root mapping definition has unsupported parameters: ");
 
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/Mapper.java b/core/src/main/java/org/elasticsearch/index/mapper/Mapper.java
index f55ca93c..ab56146 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/Mapper.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/Mapper.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.mapper;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseFieldMatcher;
@@ -88,14 +89,14 @@ public abstract class Mapper implements ToXContent, Iterable<Mapper> {
 
             private final MapperService mapperService;
 
-            private final Map<String, TypeParser> typeParsers;
+            private final ImmutableMap<String, TypeParser> typeParsers;
 
             private final Version indexVersionCreated;
 
             private final ParseFieldMatcher parseFieldMatcher;
 
             public ParserContext(String type, AnalysisService analysisService, SimilarityLookupService similarityLookupService,
-                                 MapperService mapperService, Map<String, TypeParser> typeParsers,
+                                 MapperService mapperService, ImmutableMap<String, TypeParser> typeParsers,
                                  Version indexVersionCreated, ParseFieldMatcher parseFieldMatcher) {
                 this.type = type;
                 this.analysisService = analysisService;
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
index 0357ef2..dd31c6e 100755
--- a/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/MapperService.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.index.mapper;
 
 import com.carrotsearch.hppc.ObjectHashSet;
+import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.Iterators;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -63,7 +64,6 @@ import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
@@ -73,9 +73,7 @@ import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 import java.util.function.Function;
 
-import static java.util.Collections.emptyMap;
 import static java.util.Collections.emptySet;
-import static java.util.Collections.unmodifiableMap;
 import static java.util.Collections.unmodifiableSet;
 import static org.elasticsearch.common.collect.MapBuilder.newMapBuilder;
 
@@ -100,7 +98,7 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
     private volatile String defaultMappingSource;
     private volatile String defaultPercolatorMappingSource;
 
-    private volatile Map<String, DocumentMapper> mappers = emptyMap();
+    private volatile Map<String, DocumentMapper> mappers = ImmutableMap.of();
 
     // A lock for mappings: modifications (put mapping) need to be performed
     // under the write lock and read operations (document parsing) need to be
@@ -120,7 +118,7 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
 
     private final List<DocumentTypeListener> typeListeners = new CopyOnWriteArrayList<>();
 
-    private volatile Map<String, MappedFieldType> unmappedFieldTypes = emptyMap();
+    private volatile ImmutableMap<String, MappedFieldType> unmappedFieldTypes = ImmutableMap.of();
 
     private volatile Set<String> parentTypes = emptySet();
 
@@ -540,23 +538,24 @@ public class MapperService extends AbstractIndexComponent implements Closeable {
      * Given a type (eg. long, string, ...), return an anonymous field mapper that can be used for search operations.
      */
     public MappedFieldType unmappedFieldType(String type) {
-        MappedFieldType fieldType = unmappedFieldTypes.get(type);
+        final ImmutableMap<String, MappedFieldType> unmappedFieldMappers = this.unmappedFieldTypes;
+        MappedFieldType fieldType = unmappedFieldMappers.get(type);
         if (fieldType == null) {
             final Mapper.TypeParser.ParserContext parserContext = documentMapperParser().parserContext(type);
             Mapper.TypeParser typeParser = parserContext.typeParser(type);
             if (typeParser == null) {
                 throw new IllegalArgumentException("No mapper found for type [" + type + "]");
             }
-            final Mapper.Builder<?, ?> builder = typeParser.parse("__anonymous_" + type, emptyMap(), parserContext);
+            final Mapper.Builder<?, ?> builder = typeParser.parse("__anonymous_" + type, ImmutableMap.<String, Object>of(), parserContext);
             final BuilderContext builderContext = new BuilderContext(indexSettings, new ContentPath(1));
             fieldType = ((FieldMapper)builder.build(builderContext)).fieldType();
 
             // There is no need to synchronize writes here. In the case of concurrent access, we could just
             // compute some mappers several times, which is not a big deal
-            Map<String, MappedFieldType> newUnmappedFieldTypes = new HashMap<>();
-            newUnmappedFieldTypes.putAll(unmappedFieldTypes);
-            newUnmappedFieldTypes.put(type, fieldType);
-            unmappedFieldTypes = unmodifiableMap(newUnmappedFieldTypes);
+            this.unmappedFieldTypes = ImmutableMap.<String, MappedFieldType>builder()
+                    .putAll(unmappedFieldMappers)
+                    .put(type, fieldType)
+                    .build();
         }
         return fieldType;
     }
diff --git a/core/src/main/java/org/elasticsearch/index/mapper/Mapping.java b/core/src/main/java/org/elasticsearch/index/mapper/Mapping.java
index 6eeb520..c3b22c6 100644
--- a/core/src/main/java/org/elasticsearch/index/mapper/Mapping.java
+++ b/core/src/main/java/org/elasticsearch/index/mapper/Mapping.java
@@ -19,7 +19,10 @@
 
 package org.elasticsearch.index.mapper;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.Version;
+import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.xcontent.ToXContent;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
@@ -28,13 +31,9 @@ import org.elasticsearch.index.mapper.object.RootObjectMapper;
 import java.io.IOException;
 import java.util.Arrays;
 import java.util.Comparator;
-import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * Wrapper around everything that defines a mapping, without references to
  * utility classes like MapperService, ...
@@ -58,20 +57,20 @@ public final class Mapping implements ToXContent {
     final Version indexCreated;
     final RootObjectMapper root;
     final MetadataFieldMapper[] metadataMappers;
-    final Map<Class<? extends MetadataFieldMapper>, MetadataFieldMapper> rootMappersMap;
+    final ImmutableMap<Class<? extends MetadataFieldMapper>, MetadataFieldMapper> rootMappersMap;
     final SourceTransform[] sourceTransforms;
-    volatile Map<String, Object> meta;
+    volatile ImmutableMap<String, Object> meta;
 
-    public Mapping(Version indexCreated, RootObjectMapper rootObjectMapper, MetadataFieldMapper[] metadataMappers, SourceTransform[] sourceTransforms, Map<String, Object> meta) {
+    public Mapping(Version indexCreated, RootObjectMapper rootObjectMapper, MetadataFieldMapper[] metadataMappers, SourceTransform[] sourceTransforms, ImmutableMap<String, Object> meta) {
         this.indexCreated = indexCreated;
         this.root = rootObjectMapper;
         this.metadataMappers = metadataMappers;
-        Map<Class<? extends MetadataFieldMapper>, MetadataFieldMapper> rootMappersMap = new HashMap<>();
+        ImmutableMap.Builder<Class<? extends MetadataFieldMapper>, MetadataFieldMapper> builder = ImmutableMap.builder();
         for (MetadataFieldMapper metadataMapper : metadataMappers) {
             if (indexCreated.before(Version.V_2_0_0_beta1) && LEGACY_INCLUDE_IN_OBJECT.contains(metadataMapper.name())) {
                 root.putMapper(metadataMapper);
             }
-            rootMappersMap.put(metadataMapper.getClass(), metadataMapper);
+            builder.put(metadataMapper.getClass(), metadataMapper);
         }
         // keep root mappers sorted for consistent serialization
         Arrays.sort(metadataMappers, new Comparator<Mapper>() {
@@ -80,7 +79,7 @@ public final class Mapping implements ToXContent {
                 return o1.name().compareTo(o2.name());
             }
         });
-        this.rootMappersMap = unmodifiableMap(rootMappersMap);
+        this.rootMappersMap = builder.build();
         this.sourceTransforms = sourceTransforms;
         this.meta = meta;
     }
@@ -120,7 +119,7 @@ public final class Mapping implements ToXContent {
             meta = mergeWith.meta;
         }
     }
-
+    
     @Override
     public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {
         root.toXContent(builder, params, new ToXContent() {
@@ -151,11 +150,22 @@ public final class Mapping implements ToXContent {
         return builder;
     }
 
+    /** Serialize to a {@link BytesReference}. */
+    public BytesReference toBytes() {
+        try {
+            XContentBuilder builder = XContentFactory.jsonBuilder().startObject();
+            toXContent(builder, new ToXContent.MapParams(ImmutableMap.<String, String>of()));
+            return builder.endObject().bytes();
+        } catch (IOException bogus) {
+            throw new AssertionError(bogus);
+        }
+    }
+
     @Override
     public String toString() {
         try {
             XContentBuilder builder = XContentFactory.jsonBuilder().startObject();
-            toXContent(builder, new ToXContent.MapParams(emptyMap()));
+            toXContent(builder, new ToXContent.MapParams(ImmutableMap.<String, String>of()));
             return builder.endObject().string();
         } catch (IOException bogus) {
             throw new AssertionError(bogus);
diff --git a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
index 31bc889..72c226f 100644
--- a/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
+++ b/core/src/main/java/org/elasticsearch/index/query/GeoShapeQueryBuilder.java
@@ -70,7 +70,7 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
     // and Equals so ShapeBuilder can be used here
     private BytesReference shapeBytes;
 
-    private SpatialStrategy strategy = null;
+    private SpatialStrategy strategy;
 
     private final String indexedShapeId;
     private final String indexedShapeType;
@@ -429,7 +429,9 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
             }
         }
         builder.relation = ShapeRelation.DISJOINT.readFrom(in);
-        builder.strategy = SpatialStrategy.RECURSIVE.readFrom(in);
+        if (in.readBoolean()) {
+            builder.strategy = SpatialStrategy.RECURSIVE.readFrom(in);
+        }
         return builder;
     }
 
@@ -447,7 +449,12 @@ public class GeoShapeQueryBuilder extends AbstractQueryBuilder<GeoShapeQueryBuil
             out.writeOptionalString(indexedShapePath);
         }
         relation.writeTo(out);
-        strategy.writeTo(out);
+        if (strategy == null) {
+            out.writeBoolean(false);
+        } else {
+            out.writeBoolean(true);
+            strategy.writeTo(out);
+        }
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/index/query/ParsedQuery.java b/core/src/main/java/org/elasticsearch/index/query/ParsedQuery.java
index 1c21926..d1a4ca5 100644
--- a/core/src/main/java/org/elasticsearch/index/query/ParsedQuery.java
+++ b/core/src/main/java/org/elasticsearch/index/query/ParsedQuery.java
@@ -19,31 +19,22 @@
 
 package org.elasticsearch.index.query;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.apache.lucene.search.Query;
 import org.elasticsearch.common.lucene.search.Queries;
 
-import java.util.Map;
-
-import static java.util.Collections.emptyMap;
-
 /**
  * The result of parsing a query.
+ *
+ *
  */
 public class ParsedQuery {
+
     private final Query query;
-    private final Map<String, Query> namedFilters;
+    private final ImmutableMap<String, Query> namedFilters;
 
-    /**
-     * Store the query and filters.
-     *
-     * @param query
-     *            the query
-     * @param namedFilters
-     *            an immutable Map containing the named filters. Good callers
-     *            use emptyMap or unmodifiableMap and copy the source to make
-     *            sure this is immutable.
-     */
-    public ParsedQuery(Query query, Map<String, Query> namedFilters) {
+    public ParsedQuery(Query query, ImmutableMap<String, Query> namedFilters) {
         this.query = query;
         this.namedFilters = namedFilters;
     }
@@ -55,7 +46,7 @@ public class ParsedQuery {
 
     public ParsedQuery(Query query) {
         this.query = query;
-        this.namedFilters = emptyMap();
+        this.namedFilters = ImmutableMap.of();
     }
 
     /**
@@ -65,11 +56,11 @@ public class ParsedQuery {
         return this.query;
     }
 
-    public Map<String, Query> namedFilters() {
-        return namedFilters;
+    public ImmutableMap<String, Query> namedFilters() {
+        return this.namedFilters;
     }
 
     public static ParsedQuery parsedMatchAllQuery() {
-        return new ParsedQuery(Queries.newMatchAllQuery(), emptyMap());
+        return new ParsedQuery(Queries.newMatchAllQuery(), ImmutableMap.<String, Query>of());
     }
 }
diff --git a/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java b/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
index 177ae9b..7862bb2 100644
--- a/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
+++ b/core/src/main/java/org/elasticsearch/index/query/QueryShardContext.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.query;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.queryparser.classic.MapperQueryParser;
 import org.apache.lucene.queryparser.classic.QueryParserSettings;
@@ -36,11 +37,7 @@ import org.elasticsearch.common.xcontent.XContentParser;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.analysis.AnalysisService;
 import org.elasticsearch.index.fielddata.IndexFieldData;
-import org.elasticsearch.index.mapper.ContentPath;
-import org.elasticsearch.index.mapper.MappedFieldType;
-import org.elasticsearch.index.mapper.Mapper;
-import org.elasticsearch.index.mapper.MapperBuilders;
-import org.elasticsearch.index.mapper.MapperService;
+import org.elasticsearch.index.mapper.*;
 import org.elasticsearch.index.mapper.core.StringFieldMapper;
 import org.elasticsearch.index.mapper.object.ObjectMapper;
 import org.elasticsearch.index.query.support.NestedScope;
@@ -57,8 +54,6 @@ import java.util.Collection;
 import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * Context object used to create lucene queries on the shard level.
  */
@@ -191,9 +186,8 @@ public class QueryShardContext {
         }
     }
 
-    public Map<String, Query> copyNamedQueries() {
-        // This might be a good use case for CopyOnWriteHashMap
-        return unmodifiableMap(new HashMap<>(namedQueries));
+    public ImmutableMap<String, Query> copyNamedQueries() {
+        return ImmutableMap.copyOf(namedQueries);
     }
 
     public void combineNamedQueries(QueryShardContext context) {
diff --git a/core/src/main/java/org/elasticsearch/index/search/stats/ShardSearchStats.java b/core/src/main/java/org/elasticsearch/index/search/stats/ShardSearchStats.java
index 829db9d..3ef5652 100644
--- a/core/src/main/java/org/elasticsearch/index/search/stats/ShardSearchStats.java
+++ b/core/src/main/java/org/elasticsearch/index/search/stats/ShardSearchStats.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.search.stats;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.metrics.CounterMetric;
 import org.elasticsearch.common.metrics.MeanMetric;
@@ -30,8 +31,6 @@ import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.TimeUnit;
 
-import static java.util.Collections.emptyMap;
-
 /**
  */
 public final class ShardSearchStats {
@@ -39,7 +38,7 @@ public final class ShardSearchStats {
     private final SearchSlowLog slowLogSearchService;
     private final StatsHolder totalStats = new StatsHolder();
     private final CounterMetric openContexts = new CounterMetric();
-    private volatile Map<String, StatsHolder> groupsStats = emptyMap();
+    private volatile Map<String, StatsHolder> groupsStats = ImmutableMap.of();
 
     public ShardSearchStats(Settings indexSettings) {
         this.slowLogSearchService = new SearchSlowLog(indexSettings);
diff --git a/core/src/main/java/org/elasticsearch/index/similarity/DFRSimilarityProvider.java b/core/src/main/java/org/elasticsearch/index/similarity/DFRSimilarityProvider.java
index 7858cb1..b5a5cdc 100644
--- a/core/src/main/java/org/elasticsearch/index/similarity/DFRSimilarityProvider.java
+++ b/core/src/main/java/org/elasticsearch/index/similarity/DFRSimilarityProvider.java
@@ -19,29 +19,13 @@
 
 package org.elasticsearch.index.similarity;
 
-import org.apache.lucene.search.similarities.AfterEffect;
-import org.apache.lucene.search.similarities.AfterEffectB;
-import org.apache.lucene.search.similarities.AfterEffectL;
-import org.apache.lucene.search.similarities.BasicModel;
-import org.apache.lucene.search.similarities.BasicModelBE;
-import org.apache.lucene.search.similarities.BasicModelD;
-import org.apache.lucene.search.similarities.BasicModelG;
-import org.apache.lucene.search.similarities.BasicModelIF;
-import org.apache.lucene.search.similarities.BasicModelIn;
-import org.apache.lucene.search.similarities.BasicModelIne;
-import org.apache.lucene.search.similarities.BasicModelP;
-import org.apache.lucene.search.similarities.DFRSimilarity;
-import org.apache.lucene.search.similarities.Normalization;
-import org.apache.lucene.search.similarities.Similarity;
+import com.google.common.collect.ImmutableMap;
+import org.apache.lucene.search.similarities.*;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.assistedinject.Assisted;
 import org.elasticsearch.common.settings.Settings;
 
-import java.util.HashMap;
-import java.util.Map;
-
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * {@link SimilarityProvider} for {@link DFRSimilarity}.
  * <p>
@@ -54,11 +38,12 @@ import static java.util.Collections.unmodifiableMap;
  * @see DFRSimilarity For more information about configuration
  */
 public class DFRSimilarityProvider extends AbstractSimilarityProvider {
-    private static final Map<String, BasicModel> MODEL_CACHE;
-    private static final Map<String, AfterEffect> EFFECT_CACHE;
+
+    private static final ImmutableMap<String, BasicModel> MODEL_CACHE;
+    private static final ImmutableMap<String, AfterEffect> EFFECT_CACHE;
 
     static {
-        Map<String, BasicModel> models = new HashMap<>();
+        MapBuilder<String, BasicModel> models = MapBuilder.newMapBuilder();
         models.put("be", new BasicModelBE());
         models.put("d", new BasicModelD());
         models.put("g", new BasicModelG());
@@ -66,13 +51,13 @@ public class DFRSimilarityProvider extends AbstractSimilarityProvider {
         models.put("in", new BasicModelIn());
         models.put("ine", new BasicModelIne());
         models.put("p", new BasicModelP());
-        MODEL_CACHE = unmodifiableMap(models);
+        MODEL_CACHE = models.immutableMap();
 
-        Map<String, AfterEffect> effects = new HashMap<>();
+        MapBuilder<String, AfterEffect> effects = MapBuilder.newMapBuilder();
         effects.put("no", new AfterEffect.NoAfterEffect());
         effects.put("b", new AfterEffectB());
         effects.put("l", new AfterEffectL());
-        EFFECT_CACHE = unmodifiableMap(effects);
+        EFFECT_CACHE = effects.immutableMap();
     }
 
     private final DFRSimilarity similarity;
diff --git a/core/src/main/java/org/elasticsearch/index/similarity/IBSimilarityProvider.java b/core/src/main/java/org/elasticsearch/index/similarity/IBSimilarityProvider.java
index 2f619c5..161ca9c 100644
--- a/core/src/main/java/org/elasticsearch/index/similarity/IBSimilarityProvider.java
+++ b/core/src/main/java/org/elasticsearch/index/similarity/IBSimilarityProvider.java
@@ -19,24 +19,13 @@
 
 package org.elasticsearch.index.similarity;
 
-import org.apache.lucene.search.similarities.Distribution;
-import org.apache.lucene.search.similarities.DistributionLL;
-import org.apache.lucene.search.similarities.DistributionSPL;
-import org.apache.lucene.search.similarities.IBSimilarity;
-import org.apache.lucene.search.similarities.Lambda;
-import org.apache.lucene.search.similarities.LambdaDF;
-import org.apache.lucene.search.similarities.LambdaTTF;
-import org.apache.lucene.search.similarities.Normalization;
-import org.apache.lucene.search.similarities.Similarity;
+import com.google.common.collect.ImmutableMap;
+import org.apache.lucene.search.similarities.*;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.assistedinject.Assisted;
 import org.elasticsearch.common.settings.Settings;
 
-import java.util.HashMap;
-import java.util.Map;
-
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * {@link SimilarityProvider} for {@link IBSimilarity}.
  * <p>
@@ -50,19 +39,19 @@ import static java.util.Collections.unmodifiableMap;
  */
 public class IBSimilarityProvider extends AbstractSimilarityProvider {
 
-    private static final Map<String, Distribution> DISTRIBUTIONS;
-    private static final Map<String, Lambda> LAMBDAS;
+    private static final ImmutableMap<String, Distribution> DISTRIBUTION_CACHE;
+    private static final ImmutableMap<String, Lambda> LAMBDA_CACHE;
 
     static {
-        Map<String, Distribution> distributions = new HashMap<>();
+        MapBuilder<String, Distribution> distributions = MapBuilder.newMapBuilder();
         distributions.put("ll", new DistributionLL());
         distributions.put("spl", new DistributionSPL());
-        DISTRIBUTIONS = unmodifiableMap(distributions);
+        DISTRIBUTION_CACHE = distributions.immutableMap();
 
-        Map<String, Lambda> lamdas = new HashMap<>();
+        MapBuilder<String, Lambda> lamdas = MapBuilder.newMapBuilder();
         lamdas.put("df", new LambdaDF());
         lamdas.put("ttf", new LambdaTTF());
-        LAMBDAS = unmodifiableMap(lamdas);
+        LAMBDA_CACHE = lamdas.immutableMap();
     }
 
     private final IBSimilarity similarity;
@@ -84,7 +73,7 @@ public class IBSimilarityProvider extends AbstractSimilarityProvider {
      */
     protected Distribution parseDistribution(Settings settings) {
         String rawDistribution = settings.get("distribution");
-        Distribution distribution = DISTRIBUTIONS.get(rawDistribution);
+        Distribution distribution = DISTRIBUTION_CACHE.get(rawDistribution);
         if (distribution == null) {
             throw new IllegalArgumentException("Unsupported Distribution [" + rawDistribution + "]");
         }
@@ -99,7 +88,7 @@ public class IBSimilarityProvider extends AbstractSimilarityProvider {
      */
     protected Lambda parseLambda(Settings settings) {
         String rawLambda = settings.get("lambda");
-        Lambda lambda = LAMBDAS.get(rawLambda);
+        Lambda lambda = LAMBDA_CACHE.get(rawLambda);
         if (lambda == null) {
             throw new IllegalArgumentException("Unsupported Lambda [" + rawLambda + "]");
         }
diff --git a/core/src/main/java/org/elasticsearch/index/similarity/Similarities.java b/core/src/main/java/org/elasticsearch/index/similarity/Similarities.java
index 3bbbc85..b40acb8 100644
--- a/core/src/main/java/org/elasticsearch/index/similarity/Similarities.java
+++ b/core/src/main/java/org/elasticsearch/index/similarity/Similarities.java
@@ -19,29 +19,27 @@
 
 package org.elasticsearch.index.similarity;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.search.similarities.BM25Similarity;
 import org.apache.lucene.search.similarities.DefaultSimilarity;
+import org.elasticsearch.common.collect.MapBuilder;
 
 import java.util.Collection;
-import java.util.HashMap;
-import java.util.Map;
-
-import static java.util.Collections.unmodifiableMap;
 
 /**
  * Cache of pre-defined Similarities
  */
 public class Similarities {
 
-    private static final Map<String, PreBuiltSimilarityProvider.Factory> PRE_BUILT_SIMILARITIES;
+    private static final ImmutableMap<String, PreBuiltSimilarityProvider.Factory> PRE_BUILT_SIMILARITIES;
 
     static {
-        Map<String, PreBuiltSimilarityProvider.Factory> similarities = new HashMap<>();
+        MapBuilder<String, PreBuiltSimilarityProvider.Factory> similarities = MapBuilder.newMapBuilder();
         similarities.put(SimilarityLookupService.DEFAULT_SIMILARITY,
                 new PreBuiltSimilarityProvider.Factory(SimilarityLookupService.DEFAULT_SIMILARITY, new DefaultSimilarity()));
         similarities.put("BM25", new PreBuiltSimilarityProvider.Factory("BM25", new BM25Similarity()));
 
-        PRE_BUILT_SIMILARITIES = unmodifiableMap(similarities);
+        PRE_BUILT_SIMILARITIES = similarities.immutableMap();
     }
 
     private Similarities() {
diff --git a/core/src/main/java/org/elasticsearch/index/similarity/SimilarityLookupService.java b/core/src/main/java/org/elasticsearch/index/similarity/SimilarityLookupService.java
index 903f0ea..8b8b688 100644
--- a/core/src/main/java/org/elasticsearch/index/similarity/SimilarityLookupService.java
+++ b/core/src/main/java/org/elasticsearch/index/similarity/SimilarityLookupService.java
@@ -19,18 +19,16 @@
 
 package org.elasticsearch.index.similarity;
 
+import com.google.common.collect.ImmutableMap;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.AbstractIndexComponent;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.settings.IndexSettings;
 
-import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * Service for looking up configured {@link SimilarityProvider} implementations by name.
  * <p>
@@ -41,17 +39,17 @@ public class SimilarityLookupService extends AbstractIndexComponent {
 
     public final static String DEFAULT_SIMILARITY = "default";
 
-    private final Map<String, SimilarityProvider> similarities;
+    private final ImmutableMap<String, SimilarityProvider> similarities;
 
     public SimilarityLookupService(Index index, Settings indexSettings) {
-        this(index, indexSettings, emptyMap());
+        this(index, indexSettings, ImmutableMap.<String, SimilarityProvider.Factory>of());
     }
 
     @Inject
     public SimilarityLookupService(Index index, @IndexSettings Settings indexSettings, Map<String, SimilarityProvider.Factory> similarities) {
         super(index, indexSettings);
 
-        Map<String, SimilarityProvider> providers = new HashMap<>();
+        MapBuilder<String, SimilarityProvider> providers = MapBuilder.newMapBuilder();
 
         Map<String, Settings> similaritySettings = indexSettings.getGroups(SimilarityModule.SIMILARITY_SETTINGS_PREFIX);
         for (Map.Entry<String, SimilarityProvider.Factory> entry : similarities.entrySet()) {
@@ -72,7 +70,7 @@ public class SimilarityLookupService extends AbstractIndexComponent {
             }
         }
 
-        this.similarities = unmodifiableMap(providers);
+        this.similarities = providers.immutableMap();
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
index d90a869..091985e 100644
--- a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
+++ b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardRepository.java
@@ -19,11 +19,7 @@
 
 package org.elasticsearch.index.snapshots.blobstore;
 
-import org.apache.lucene.index.CorruptIndexException;
-import org.apache.lucene.index.IndexCommit;
-import org.apache.lucene.index.IndexFormatTooNewException;
-import org.apache.lucene.index.IndexFormatTooOldException;
-import org.apache.lucene.index.SegmentInfos;
+import org.apache.lucene.index.*;
 import org.apache.lucene.store.IOContext;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.store.IndexOutput;
@@ -52,11 +48,7 @@ import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.snapshots.IndexShardRepository;
-import org.elasticsearch.index.snapshots.IndexShardRestoreFailedException;
-import org.elasticsearch.index.snapshots.IndexShardSnapshotException;
-import org.elasticsearch.index.snapshots.IndexShardSnapshotFailedException;
-import org.elasticsearch.index.snapshots.IndexShardSnapshotStatus;
+import org.elasticsearch.index.snapshots.*;
 import org.elasticsearch.index.snapshots.blobstore.BlobStoreIndexShardSnapshot.FileInfo;
 import org.elasticsearch.index.store.Store;
 import org.elasticsearch.index.store.StoreFileMetaData;
@@ -72,15 +64,8 @@ import org.elasticsearch.repositories.blobstore.LegacyBlobStoreFormat;
 import java.io.FilterInputStream;
 import java.io.IOException;
 import java.io.InputStream;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
+import java.util.*;
+
 import static org.elasticsearch.repositories.blobstore.BlobStoreRepository.testBlobPrefix;
 
 /**
@@ -827,7 +812,7 @@ public class BlobStoreIndexShardRepository extends AbstractComponent implements
                     snapshotMetaData.put(fileInfo.metadata().name(), fileInfo.metadata());
                     fileInfos.put(fileInfo.metadata().name(), fileInfo);
                 }
-                final Store.MetadataSnapshot sourceMetaData = new Store.MetadataSnapshot(unmodifiableMap(snapshotMetaData), emptyMap(), 0);
+                final Store.MetadataSnapshot sourceMetaData = new Store.MetadataSnapshot(snapshotMetaData, Collections.EMPTY_MAP, 0);
                 final Store.RecoveryDiff diff = sourceMetaData.recoveryDiff(recoveryTargetMetadata);
                 for (StoreFileMetaData md : diff.identical) {
                     FileInfo fileInfo = fileInfos.get(md.name());
diff --git a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshots.java b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshots.java
index 8f05572..ad3b9c9 100644
--- a/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshots.java
+++ b/core/src/main/java/org/elasticsearch/index/snapshots/blobstore/BlobStoreIndexShardSnapshots.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.snapshots.blobstore;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.ParseFieldMatcher;
@@ -37,8 +38,6 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * Contains information about all snapshot for the given shard in repository
  * <p>
@@ -78,15 +77,15 @@ public class BlobStoreIndexShardSnapshots implements Iterable<SnapshotFiles>, To
                 physicalFileList.add(newFiles.get(fileInfo.name()));
             }
         }
-        Map<String, List<FileInfo>> mapBuilder = new HashMap<>();
+        ImmutableMap.Builder<String, List<FileInfo>> mapBuilder = ImmutableMap.builder();
         for (Map.Entry<String, List<FileInfo>> entry : physicalFiles.entrySet()) {
             mapBuilder.put(entry.getKey(), Collections.unmodifiableList(new ArrayList<>(entry.getValue())));
         }
-        this.physicalFiles = unmodifiableMap(mapBuilder);
-        this.files = unmodifiableMap(newFiles);
+        this.physicalFiles = mapBuilder.build();
+        this.files = ImmutableMap.copyOf(newFiles);
     }
 
-    private BlobStoreIndexShardSnapshots(Map<String, FileInfo> files, List<SnapshotFiles> shardSnapshots) {
+    private BlobStoreIndexShardSnapshots(ImmutableMap<String, FileInfo> files, List<SnapshotFiles> shardSnapshots) {
         this.shardSnapshots = shardSnapshots;
         this.files = files;
         Map<String, List<FileInfo>> physicalFiles = new HashMap<>();
@@ -100,11 +99,11 @@ public class BlobStoreIndexShardSnapshots implements Iterable<SnapshotFiles>, To
                 physicalFileList.add(files.get(fileInfo.name()));
             }
         }
-        Map<String, List<FileInfo>> mapBuilder = new HashMap<>();
+        ImmutableMap.Builder<String, List<FileInfo>> mapBuilder = ImmutableMap.builder();
         for (Map.Entry<String, List<FileInfo>> entry : physicalFiles.entrySet()) {
             mapBuilder.put(entry.getKey(), Collections.unmodifiableList(new ArrayList<>(entry.getValue())));
         }
-        this.physicalFiles = unmodifiableMap(mapBuilder);
+        this.physicalFiles = mapBuilder.build();
     }
 
     private BlobStoreIndexShardSnapshots() {
@@ -233,14 +232,13 @@ public class BlobStoreIndexShardSnapshots implements Iterable<SnapshotFiles>, To
         return builder;
     }
 
-    @Override
     public BlobStoreIndexShardSnapshots fromXContent(XContentParser parser, ParseFieldMatcher parseFieldMatcher) throws IOException {
         XContentParser.Token token = parser.currentToken();
         if (token == null) { // New parser
             token = parser.nextToken();
         }
         Map<String, List<String>> snapshotsMap = new HashMap<>();
-        Map<String, FileInfo> files = new HashMap<>();
+        ImmutableMap.Builder<String, FileInfo> filesBuilder = ImmutableMap.builder();
         if (token == XContentParser.Token.START_OBJECT) {
             while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                 if (token != XContentParser.Token.FIELD_NAME) {
@@ -254,7 +252,7 @@ public class BlobStoreIndexShardSnapshots implements Iterable<SnapshotFiles>, To
                     }
                     while (parser.nextToken() != XContentParser.Token.END_ARRAY) {
                         FileInfo fileInfo = FileInfo.fromXContent(parser);
-                        files.put(fileInfo.name(), fileInfo);
+                        filesBuilder.put(fileInfo.name(), fileInfo);
                     }
                 } else if (token == XContentParser.Token.START_OBJECT) {
                     if (parseFieldMatcher.match(currentFieldName, ParseFields.SNAPSHOTS) == false) {
@@ -290,6 +288,7 @@ public class BlobStoreIndexShardSnapshots implements Iterable<SnapshotFiles>, To
             }
         }
 
+        ImmutableMap<String, FileInfo> files = filesBuilder.build();
         List<SnapshotFiles> snapshots = new ArrayList<>();
         for (Map.Entry<String, List<String>> entry : snapshotsMap.entrySet()) {
             List<FileInfo> fileInfosBuilder = new ArrayList<>();
diff --git a/core/src/main/java/org/elasticsearch/index/store/Store.java b/core/src/main/java/org/elasticsearch/index/store/Store.java
index c2b55ac..7fb1b40 100644
--- a/core/src/main/java/org/elasticsearch/index/store/Store.java
+++ b/core/src/main/java/org/elasticsearch/index/store/Store.java
@@ -19,34 +19,14 @@
 
 package org.elasticsearch.index.store;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.codecs.CodecUtil;
-import org.apache.lucene.index.CorruptIndexException;
-import org.apache.lucene.index.IndexCommit;
-import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.index.IndexFormatTooNewException;
-import org.apache.lucene.index.IndexFormatTooOldException;
-import org.apache.lucene.index.IndexNotFoundException;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.SegmentCommitInfo;
-import org.apache.lucene.index.SegmentInfos;
-import org.apache.lucene.store.AlreadyClosedException;
-import org.apache.lucene.store.BufferedChecksum;
-import org.apache.lucene.store.ByteArrayDataInput;
-import org.apache.lucene.store.ChecksumIndexInput;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.FilterDirectory;
-import org.apache.lucene.store.IOContext;
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.store.IndexOutput;
-import org.apache.lucene.store.Lock;
-import org.apache.lucene.store.SimpleFSDirectory;
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.Version;
+import org.apache.lucene.index.*;
+import org.apache.lucene.store.*;
+import org.apache.lucene.util.*;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.ExceptionsHelper;
+import org.apache.lucene.util.Version;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.collect.Tuple;
@@ -64,39 +44,26 @@ import org.elasticsearch.common.lucene.store.InputStreamIndexInput;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.Callback;
+import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.common.util.SingleObjectCache;
 import org.elasticsearch.common.util.concurrent.AbstractRefCounted;
 import org.elasticsearch.common.util.concurrent.RefCounted;
-import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.env.ShardLock;
 import org.elasticsearch.index.engine.Engine;
 import org.elasticsearch.index.settings.IndexSettings;
 import org.elasticsearch.index.shard.AbstractIndexShardComponent;
 import org.elasticsearch.index.shard.ShardId;
 
-import java.io.Closeable;
-import java.io.EOFException;
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.io.InputStream;
+import java.io.*;
 import java.nio.file.NoSuchFileException;
 import java.nio.file.Path;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 import java.util.zip.Adler32;
 import java.util.zip.CRC32;
 import java.util.zip.Checksum;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * A Store provides plain access to files written by an elasticsearch index shard. Each shard
  * has a dedicated store that is uses to access Lucene's Directory which represents the lowest level
@@ -767,7 +734,7 @@ public class Store extends AbstractIndexShardComponent implements Closeable, Ref
         private static final ESLogger logger = Loggers.getLogger(MetadataSnapshot.class);
         private static final Version FIRST_LUCENE_CHECKSUM_VERSION = Version.LUCENE_4_8;
 
-        private final Map<String, StoreFileMetaData> metadata;
+        private final ImmutableMap<String, StoreFileMetaData> metadata;
 
         public static final MetadataSnapshot EMPTY = new MetadataSnapshot();
 
@@ -776,14 +743,16 @@ public class Store extends AbstractIndexShardComponent implements Closeable, Ref
         private final long numDocs;
 
         public MetadataSnapshot(Map<String, StoreFileMetaData> metadata, Map<String, String> commitUserData, long numDocs) {
-            this.metadata = metadata;
-            this.commitUserData = commitUserData;
+            ImmutableMap.Builder<String, StoreFileMetaData> metaDataBuilder = ImmutableMap.builder();
+            this.metadata = metaDataBuilder.putAll(metadata).build();
+            ImmutableMap.Builder<String, String> commitUserDataBuilder = ImmutableMap.builder();
+            this.commitUserData = commitUserDataBuilder.putAll(commitUserData).build();
             this.numDocs = numDocs;
         }
 
         MetadataSnapshot() {
-            metadata = emptyMap();
-            commitUserData = emptyMap();
+            metadata = ImmutableMap.of();
+            commitUserData = ImmutableMap.of();
             numDocs = 0;
         }
 
@@ -797,19 +766,19 @@ public class Store extends AbstractIndexShardComponent implements Closeable, Ref
 
         public MetadataSnapshot(StreamInput in) throws IOException {
             final int size = in.readVInt();
-            Map<String, StoreFileMetaData> metadata = new HashMap<>();
+            final ImmutableMap.Builder<String, StoreFileMetaData> metadataBuilder = ImmutableMap.builder();
             for (int i = 0; i < size; i++) {
                 StoreFileMetaData meta = StoreFileMetaData.readStoreFileMetaData(in);
-                metadata.put(meta.name(), meta);
+                metadataBuilder.put(meta.name(), meta);
             }
-            Map<String, String> commitUserData = new HashMap<>();
+            final ImmutableMap.Builder<String, String> commitUserDataBuilder = ImmutableMap.builder();
             int num = in.readVInt();
             for (int i = num; i > 0; i--) {
-                commitUserData.put(in.readString(), in.readString());
+                commitUserDataBuilder.put(in.readString(), in.readString());
             }
 
-            this.metadata = unmodifiableMap(metadata);
-            this.commitUserData = unmodifiableMap(commitUserData);
+            this.commitUserData = commitUserDataBuilder.build();
+            this.metadata = metadataBuilder.build();
             this.numDocs = in.readLong();
             assert metadata.isEmpty() || numSegmentFiles() == 1 : "numSegmentFiles: " + numSegmentFiles();
         }
@@ -822,11 +791,11 @@ public class Store extends AbstractIndexShardComponent implements Closeable, Ref
         }
 
         static class LoadedMetadata {
-            final Map<String, StoreFileMetaData> fileMetadata;
-            final Map<String, String> userData;
+            final ImmutableMap<String, StoreFileMetaData> fileMetadata;
+            final ImmutableMap<String, String> userData;
             final long numDocs;
 
-            LoadedMetadata(Map<String, StoreFileMetaData> fileMetadata, Map<String, String> userData, long numDocs) {
+            LoadedMetadata(ImmutableMap<String, StoreFileMetaData> fileMetadata, ImmutableMap<String, String> userData, long numDocs) {
                 this.fileMetadata = fileMetadata;
                 this.userData = userData;
                 this.numDocs = numDocs;
@@ -835,9 +804,9 @@ public class Store extends AbstractIndexShardComponent implements Closeable, Ref
 
         static LoadedMetadata loadMetadata(IndexCommit commit, Directory directory, ESLogger logger) throws IOException {
             long numDocs;
-            Map<String, StoreFileMetaData> builder = new HashMap<>();
+            ImmutableMap.Builder<String, StoreFileMetaData> builder = ImmutableMap.builder();
             Map<String, String> checksumMap = readLegacyChecksums(directory).v1();
-            Map<String, String> commitUserDataBuilder = new HashMap<>();
+            ImmutableMap.Builder<String, String> commitUserDataBuilder = ImmutableMap.builder();
             try {
                 final SegmentInfos segmentCommitInfos = Store.readSegmentsInfo(commit, directory);
                 numDocs = Lucene.getNumDocs(segmentCommitInfos);
@@ -894,7 +863,7 @@ public class Store extends AbstractIndexShardComponent implements Closeable, Ref
 
                 throw ex;
             }
-            return new LoadedMetadata(unmodifiableMap(builder), unmodifiableMap(commitUserDataBuilder), numDocs);
+            return new LoadedMetadata(builder.build(), commitUserDataBuilder.build(), numDocs);
         }
 
         /**
@@ -951,8 +920,7 @@ public class Store extends AbstractIndexShardComponent implements Closeable, Ref
             }
         }
 
-        private static void checksumFromLuceneFile(Directory directory, String file, Map<String, StoreFileMetaData> builder,
-                ESLogger logger, Version version, boolean readFileAsHash) throws IOException {
+        private static void checksumFromLuceneFile(Directory directory, String file, ImmutableMap.Builder<String, StoreFileMetaData> builder, ESLogger logger, Version version, boolean readFileAsHash) throws IOException {
             final String checksum;
             final BytesRefBuilder fileHash = new BytesRefBuilder();
             try (final IndexInput in = directory.openInput(file, IOContext.READONCE)) {
diff --git a/core/src/main/java/org/elasticsearch/indices/IndicesService.java b/core/src/main/java/org/elasticsearch/indices/IndicesService.java
index ba160fc..ae69eee 100644
--- a/core/src/main/java/org/elasticsearch/indices/IndicesService.java
+++ b/core/src/main/java/org/elasticsearch/indices/IndicesService.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.indices;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.apache.lucene.store.LockObtainFailedException;
 import org.apache.lucene.util.CollectionUtil;
 import org.apache.lucene.util.IOUtils;
@@ -93,8 +95,6 @@ import java.util.concurrent.Executors;
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Stream;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.common.collect.MapBuilder.newMapBuilder;
@@ -118,8 +118,8 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
     private final NodeEnvironment nodeEnv;
     private final TimeValue shardsClosedTimeout;
 
-    private volatile Map<String, IndexServiceInjectorPair> indices = emptyMap();
-
+    private volatile Map<String, IndexServiceInjectorPair> indices = ImmutableMap.of();
+    
     static class IndexServiceInjectorPair {
         private final IndexService indexService;
         private final Injector injector;
@@ -137,7 +137,7 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
             return injector;
         }
     }
-
+    
     private final Map<Index, List<PendingDelete>> pendingDeletes = new HashMap<>();
 
     private final OldShardsStats oldShardsStats = new OldShardsStats();
@@ -341,6 +341,7 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
         modules.add(new SimilarityModule(indexSettings));
         modules.add(new IndexCacheModule(indexSettings));
         modules.add(new IndexModule());
+        
         pluginsService.processModules(modules);
 
         Injector indexInjector;
@@ -381,11 +382,11 @@ public class IndicesService extends AbstractLifecycleComponent<IndicesService> i
                 }
 
                 logger.debug("[{}] closing ... (reason [{}])", index, reason);
-                Map<String, IndexServiceInjectorPair> newIndices = new HashMap<>(indices);
-                IndexServiceInjectorPair remove = newIndices.remove(index);
+                Map<String, IndexServiceInjectorPair> tmpMap = new HashMap<>(indices);
+                IndexServiceInjectorPair remove = tmpMap.remove(index);
                 indexService = remove.getIndexService();
                 indexInjector = remove.getInjector();
-                indices = unmodifiableMap(newIndices);
+                indices = ImmutableMap.copyOf(tmpMap);
             }
 
             indicesLifecycle.beforeIndexClosed(indexService);
diff --git a/core/src/main/java/org/elasticsearch/indices/flush/IndicesSyncedFlushResult.java b/core/src/main/java/org/elasticsearch/indices/flush/IndicesSyncedFlushResult.java
index 435c0d1..54ec76e 100644
--- a/core/src/main/java/org/elasticsearch/indices/flush/IndicesSyncedFlushResult.java
+++ b/core/src/main/java/org/elasticsearch/indices/flush/IndicesSyncedFlushResult.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.indices.flush;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.common.util.iterable.Iterables;
 import org.elasticsearch.common.xcontent.ToXContent;
@@ -29,8 +30,6 @@ import java.io.IOException;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * The result of performing a sync flush operation on all shards of multiple indices
  */
@@ -41,10 +40,7 @@ public class IndicesSyncedFlushResult implements ToXContent {
 
 
     public IndicesSyncedFlushResult(Map<String, List<ShardsSyncedFlushResult>> shardsResultPerIndex) {
-        // shardsResultPerIndex is never modified after it is passed to this
-        // constructor so this is safe even though shardsResultPerIndex is a
-        // ConcurrentHashMap
-        this.shardsResultPerIndex = unmodifiableMap(shardsResultPerIndex);
+        this.shardsResultPerIndex = ImmutableMap.copyOf(shardsResultPerIndex);
         this.shardCounts = calculateShardCounts(Iterables.flatten(shardsResultPerIndex.values()));
     }
 
diff --git a/core/src/main/java/org/elasticsearch/indices/flush/ShardsSyncedFlushResult.java b/core/src/main/java/org/elasticsearch/indices/flush/ShardsSyncedFlushResult.java
index f7ae5f9..1388373 100644
--- a/core/src/main/java/org/elasticsearch/indices/flush/ShardsSyncedFlushResult.java
+++ b/core/src/main/java/org/elasticsearch/indices/flush/ShardsSyncedFlushResult.java
@@ -18,15 +18,13 @@
  */
 package org.elasticsearch.indices.flush;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.index.shard.ShardId;
 
 import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * Result for all copies of a shard
  */
@@ -51,7 +49,7 @@ public class ShardsSyncedFlushResult {
     public ShardsSyncedFlushResult(ShardId shardId, int totalShards, String failureReason) {
         this.syncId = null;
         this.failureReason = failureReason;
-        this.shardResponses = emptyMap();
+        this.shardResponses = ImmutableMap.of();
         this.shardId = shardId;
         this.totalShards = totalShards;
     }
@@ -61,7 +59,8 @@ public class ShardsSyncedFlushResult {
      */
     public ShardsSyncedFlushResult(ShardId shardId, String syncId, int totalShards, Map<ShardRouting, SyncedFlushService.SyncedFlushResponse> shardResponses) {
         this.failureReason = null;
-        this.shardResponses = unmodifiableMap(new HashMap<>(shardResponses));
+        ImmutableMap.Builder<ShardRouting, SyncedFlushService.SyncedFlushResponse> builder = ImmutableMap.builder();
+        this.shardResponses = builder.putAll(shardResponses).build();
         this.syncId = syncId;
         this.totalShards = totalShards;
         this.shardId = shardId;
diff --git a/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java b/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
index c0e5dcd..b6fc3cd 100644
--- a/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
+++ b/core/src/main/java/org/elasticsearch/indices/flush/SyncedFlushService.java
@@ -48,13 +48,7 @@ import org.elasticsearch.indices.IndexClosedException;
 import org.elasticsearch.indices.IndicesLifecycle;
 import org.elasticsearch.indices.IndicesService;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.BaseTransportResponseHandler;
-import org.elasticsearch.transport.TransportChannel;
-import org.elasticsearch.transport.TransportException;
-import org.elasticsearch.transport.TransportRequest;
-import org.elasticsearch.transport.TransportRequestHandler;
-import org.elasticsearch.transport.TransportResponse;
-import org.elasticsearch.transport.TransportService;
+import org.elasticsearch.transport.*;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -180,7 +174,7 @@ public class SyncedFlushService extends AbstractComponent {
     * be written on a primary if no write operation was executed between step 1 and step 3 and sync id will only be written on
     * the replica if it contains the same changes that the primary contains.
     *
-    * Synced flush is a best effort operation. The sync id may be written on all, some or none of the copies.
+    * Synced flush is a best effort operation. The sync id may be written on all, some or none of the copies. 
     **/
     public void attemptSyncedFlush(final ShardId shardId, final ActionListener<ShardsSyncedFlushResult> actionListener) {
         try {
@@ -347,7 +341,8 @@ public class SyncedFlushService extends AbstractComponent {
     }
 
     private void contDownAndSendResponseIfDone(String syncId, List<ShardRouting> shards, ShardId shardId, int totalShards,
-            ActionListener<ShardsSyncedFlushResult> listener, CountDown countDown, Map<ShardRouting, SyncedFlushResponse> results) {
+                                               ActionListener<ShardsSyncedFlushResult> listener, CountDown countDown, Map<ShardRouting,
+            SyncedFlushResponse> results) {
         if (countDown.countDown()) {
             assert results.size() == shards.size();
             listener.onResponse(new ShardsSyncedFlushResult(shardId, syncId, totalShards, results));
diff --git a/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java b/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
index 0cec415..b453503 100644
--- a/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
+++ b/core/src/main/java/org/elasticsearch/indices/query/IndicesQueriesRegistry.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.indices.query;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
@@ -31,10 +32,9 @@ import java.util.HashMap;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableMap;
-
 public class IndicesQueriesRegistry extends AbstractComponent {
-    private Map<String, QueryParser<?>> queryParsers;
+
+    private ImmutableMap<String, QueryParser<?>> queryParsers;
 
     @Inject
     public IndicesQueriesRegistry(Settings settings, Set<QueryParser> injectedQueryParsers, NamedWriteableRegistry namedWriteableRegistry) {
@@ -49,13 +49,13 @@ public class IndicesQueriesRegistry extends AbstractComponent {
         // EmptyQueryBuilder is not registered as query parser but used internally.
         // We need to register it with the NamedWriteableRegistry in order to serialize it
         namedWriteableRegistry.registerPrototype(QueryBuilder.class, EmptyQueryBuilder.PROTOTYPE);
-        this.queryParsers = unmodifiableMap(queryParsers);
+        this.queryParsers = ImmutableMap.copyOf(queryParsers);
     }
 
     /**
      * Returns all the registered query parsers
      */
-    public Map<String, QueryParser<?>> queryParsers() {
+    public ImmutableMap<String, QueryParser<?>> queryParsers() {
         return queryParsers;
     }
 }
\ No newline at end of file
diff --git a/core/src/main/java/org/elasticsearch/monitor/jvm/DeadlockAnalyzer.java b/core/src/main/java/org/elasticsearch/monitor/jvm/DeadlockAnalyzer.java
index 6956273..97b9730 100644
--- a/core/src/main/java/org/elasticsearch/monitor/jvm/DeadlockAnalyzer.java
+++ b/core/src/main/java/org/elasticsearch/monitor/jvm/DeadlockAnalyzer.java
@@ -19,17 +19,17 @@
 
 package org.elasticsearch.monitor.jvm;
 
+import com.google.common.collect.ImmutableMap;
+
 import java.lang.management.ManagementFactory;
 import java.lang.management.ThreadInfo;
 import java.lang.management.ThreadMXBean;
 import java.util.Arrays;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.LinkedHashSet;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableMap;
 import static java.util.Collections.unmodifiableSet;
 
 /**
@@ -55,7 +55,7 @@ public class DeadlockAnalyzer {
         if (deadlockedThreads == null || deadlockedThreads.length == 0) {
             return NULL_RESULT;
         }
-        Map<Long, ThreadInfo> threadInfoMap = createThreadInfoMap(deadlockedThreads);
+        ImmutableMap<Long, ThreadInfo> threadInfoMap = createThreadInfoMap(deadlockedThreads);
         Set<LinkedHashSet<ThreadInfo>> cycles = calculateCycles(threadInfoMap);
         Set<LinkedHashSet<ThreadInfo>> chains = calculateCycleDeadlockChains(threadInfoMap, cycles);
         cycles.addAll(chains);
@@ -89,7 +89,7 @@ public class DeadlockAnalyzer {
     }
 
 
-    private Set<LinkedHashSet<ThreadInfo>> calculateCycleDeadlockChains(Map<Long, ThreadInfo> threadInfoMap, Set<LinkedHashSet<ThreadInfo>> cycles) {
+    private Set<LinkedHashSet<ThreadInfo>> calculateCycleDeadlockChains(ImmutableMap<Long, ThreadInfo> threadInfoMap, Set<LinkedHashSet<ThreadInfo>> cycles) {
         ThreadInfo allThreads[] = threadBean.getThreadInfo(threadBean.getAllThreadIds());
         Set<LinkedHashSet<ThreadInfo>> deadlockChain = new HashSet<>();
         Set<Long> knownDeadlockedThreads = threadInfoMap.keySet();
@@ -113,13 +113,13 @@ public class DeadlockAnalyzer {
     }
 
 
-    private Map<Long, ThreadInfo> createThreadInfoMap(long threadIds[]) {
+    private ImmutableMap<Long, ThreadInfo> createThreadInfoMap(long threadIds[]) {
         ThreadInfo threadInfos[] = threadBean.getThreadInfo(threadIds);
-        Map<Long, ThreadInfo> threadInfoMap = new HashMap<>();
+        ImmutableMap.Builder<Long, ThreadInfo> threadInfoMap = ImmutableMap.builder();
         for (ThreadInfo threadInfo : threadInfos) {
             threadInfoMap.put(threadInfo.getThreadId(), threadInfo);
         }
-        return unmodifiableMap(threadInfoMap);
+        return threadInfoMap.build();
     }
 
     public static class Deadlock {
diff --git a/core/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java b/core/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java
index a11fc29..1efd3c7 100644
--- a/core/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java
+++ b/core/src/main/java/org/elasticsearch/monitor/jvm/JvmMonitorService.java
@@ -19,20 +19,20 @@
 
 package org.elasticsearch.monitor.jvm;
 
+import com.google.common.collect.ImmutableMap;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
 import org.elasticsearch.common.util.concurrent.FutureUtils;
-import org.elasticsearch.monitor.jvm.JvmStats.GarbageCollector;
 import org.elasticsearch.threadpool.ThreadPool;
 
-import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.ScheduledFuture;
 
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.unit.TimeValue.timeValueSeconds;
+import static org.elasticsearch.monitor.jvm.JvmStats.GarbageCollector;
 import static org.elasticsearch.monitor.jvm.JvmStats.jvmStats;
 
 /**
@@ -43,7 +43,7 @@ public class JvmMonitorService extends AbstractLifecycleComponent<JvmMonitorServ
     private final ThreadPool threadPool;
     private final boolean enabled;
     private final TimeValue interval;
-    private final Map<String, GcThreshold> gcThresholds;
+    private final ImmutableMap<String, GcThreshold> gcThresholds;
 
     private volatile ScheduledFuture scheduledFuture;
 
@@ -79,7 +79,7 @@ public class JvmMonitorService extends AbstractLifecycleComponent<JvmMonitorServ
         this.enabled = this.settings.getAsBoolean("monitor.jvm.enabled", true);
         this.interval = this.settings.getAsTime("monitor.jvm.interval", timeValueSeconds(1));
 
-        Map<String, GcThreshold> gcThresholds = new HashMap<>();
+        MapBuilder<String, GcThreshold> gcThresholds = MapBuilder.newMapBuilder();
         Map<String, Settings> gcThresholdGroups = this.settings.getGroups("monitor.jvm.gc");
         for (Map.Entry<String, Settings> entry : gcThresholdGroups.entrySet()) {
             String name = entry.getKey();
@@ -92,10 +92,17 @@ public class JvmMonitorService extends AbstractLifecycleComponent<JvmMonitorServ
                 gcThresholds.put(name, new GcThreshold(name, warn.millis(), info.millis(), debug.millis()));
             }
         }
-        gcThresholds.putIfAbsent(GcNames.YOUNG, new GcThreshold(GcNames.YOUNG, 1000, 700, 400));
-        gcThresholds.putIfAbsent(GcNames.OLD, new GcThreshold(GcNames.OLD, 10000, 5000, 2000));
-        gcThresholds.putIfAbsent("default", new GcThreshold("default", 10000, 5000, 2000));
-        this.gcThresholds = unmodifiableMap(gcThresholds);
+        if (!gcThresholds.containsKey(GcNames.YOUNG)) {
+            gcThresholds.put(GcNames.YOUNG, new GcThreshold(GcNames.YOUNG, 1000, 700, 400));
+        }
+        if (!gcThresholds.containsKey(GcNames.OLD)) {
+            gcThresholds.put(GcNames.OLD, new GcThreshold(GcNames.OLD, 10000, 5000, 2000));
+        }
+        if (!gcThresholds.containsKey("default")) {
+            gcThresholds.put("default", new GcThreshold("default", 10000, 5000, 2000));
+        }
+
+        this.gcThresholds = gcThresholds.immutableMap();
 
         logger.debug("enabled [{}], interval [{}], gc_threshold [{}]", enabled, interval, this.gcThresholds);
     }
diff --git a/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java b/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java
index bd15a6a..7aacde5 100644
--- a/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java
+++ b/core/src/main/java/org/elasticsearch/node/internal/InternalSettingsPreparer.java
@@ -73,7 +73,7 @@ public class InternalSettingsPreparer {
      * and then replacing all property placeholders. If a {@link Terminal} is provided and configuration settings are loaded,
      * settings with a value of <code>${prompt.text}</code> or <code>${prompt.secret}</code> will result in a prompt for
      * the setting to the user.
-     * @param input The initial settings to use
+     * @param input The custom settings to use. These are not overwritten by settings in the configuration file.
      * @param terminal the Terminal to use for input/output
      * @return the {@link Settings} and {@link Environment} as a {@link Tuple}
      */
diff --git a/core/src/main/java/org/elasticsearch/node/service/NodeService.java b/core/src/main/java/org/elasticsearch/node/service/NodeService.java
index fe57800..369f7e0 100644
--- a/core/src/main/java/org/elasticsearch/node/service/NodeService.java
+++ b/core/src/main/java/org/elasticsearch/node/service/NodeService.java
@@ -19,12 +19,15 @@
 
 package org.elasticsearch.node.service;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.Build;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.cluster.node.info.NodeInfo;
 import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
 import org.elasticsearch.action.admin.indices.stats.CommonStatsFlags;
 import org.elasticsearch.common.Nullable;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
@@ -39,12 +42,8 @@ import org.elasticsearch.threadpool.ThreadPool;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
-import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
-
 /**
  */
 public class NodeService extends AbstractComponent {
@@ -60,7 +59,7 @@ public class NodeService extends AbstractComponent {
     @Nullable
     private HttpServer httpServer;
 
-    private volatile Map<String, String> serviceAttributes = emptyMap();
+    private volatile ImmutableMap<String, String> serviceAttributes = ImmutableMap.of();
 
     private final Version version;
 
@@ -94,15 +93,11 @@ public class NodeService extends AbstractComponent {
     }
 
     public synchronized void putAttribute(String key, String value) {
-        Map<String, String> newServiceAttributes = new HashMap<>(serviceAttributes);
-        newServiceAttributes.put(key, value);
-        serviceAttributes = unmodifiableMap(newServiceAttributes);
+        serviceAttributes = new MapBuilder<>(serviceAttributes).put(key, value).immutableMap();
     }
 
     public synchronized void removeAttribute(String key) {
-        Map<String, String> newServiceAttributes = new HashMap<>(serviceAttributes);
-        newServiceAttributes.remove(key);
-        serviceAttributes = unmodifiableMap(newServiceAttributes);
+        serviceAttributes = new MapBuilder<>(serviceAttributes).remove(key).immutableMap();
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java b/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java
index db6afd1..5d83fa2 100644
--- a/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java
+++ b/core/src/main/java/org/elasticsearch/plugins/PluginManagerCliParser.java
@@ -24,7 +24,6 @@ import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.cli.CliTool;
 import org.elasticsearch.common.cli.CliToolConfig;
 import org.elasticsearch.common.cli.Terminal;
-import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.logging.log4j.LogConfigurator;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
@@ -39,7 +38,6 @@ import java.util.Locale;
 
 import static org.elasticsearch.common.cli.CliToolConfig.Builder.cmd;
 import static org.elasticsearch.common.cli.CliToolConfig.Builder.option;
-import static org.elasticsearch.common.settings.Settings.EMPTY;
 
 public class PluginManagerCliParser extends CliTool {
 
@@ -51,8 +49,21 @@ public class PluginManagerCliParser extends CliTool {
             .build();
 
     public static void main(String[] args) {
-        Environment env = InternalSettingsPreparer.prepareEnvironment(EMPTY, Terminal.DEFAULT);
-        LogConfigurator.configure(env.settings());
+        // initialize default for es.logger.level because we will not read the logging.yml
+        String loggerLevel = System.getProperty("es.logger.level", "INFO");
+        // Set the appender for all potential log files to terminal so that other components that use the logger print out the
+        // same terminal.
+        // The reason for this is that the plugin cli cannot be configured with a file appender because when the plugin command is
+        // executed there is no way of knowing where the logfiles should be placed. For example, if elasticsearch
+        // is run as service then the logs should be at /var/log/elasticsearch but when started from the tar they should be at es.home/logs.
+        // Therefore we print to Terminal.
+        Environment env = InternalSettingsPreparer.prepareEnvironment(Settings.builder()
+                .put("appender.terminal.type", "terminal")
+                .put("rootLogger", "${es.logger.level}, terminal")
+                .put("es.logger.level", loggerLevel)
+                .build(), Terminal.DEFAULT);
+        // configure but do not read the logging conf file
+        LogConfigurator.configure(env.settings(), false);
         int status = new PluginManagerCliParser().execute(args).status();
         System.exit(status);
     }
diff --git a/core/src/main/java/org/elasticsearch/repositories/RepositoriesService.java b/core/src/main/java/org/elasticsearch/repositories/RepositoriesService.java
index 6eb32cf..d485e47 100644
--- a/core/src/main/java/org/elasticsearch/repositories/RepositoriesService.java
+++ b/core/src/main/java/org/elasticsearch/repositories/RepositoriesService.java
@@ -19,12 +19,9 @@
 
 package org.elasticsearch.repositories;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.action.ActionListener;
-import org.elasticsearch.cluster.AckedClusterStateUpdateTask;
-import org.elasticsearch.cluster.ClusterChangedEvent;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.ClusterStateListener;
+import org.elasticsearch.cluster.*;
 import org.elasticsearch.cluster.ack.ClusterStateUpdateRequest;
 import org.elasticsearch.cluster.ack.ClusterStateUpdateResponse;
 import org.elasticsearch.cluster.metadata.MetaData;
@@ -43,15 +40,9 @@ import org.elasticsearch.snapshots.SnapshotsService;
 import org.elasticsearch.transport.TransportService;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
+import java.util.*;
 import java.util.stream.Collectors;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.settings.Settings.Builder.EMPTY_SETTINGS;
 
 /**
@@ -67,7 +58,7 @@ public class RepositoriesService extends AbstractComponent implements ClusterSta
 
     private final VerifyNodeRepositoryAction verifyAction;
 
-    private volatile Map<String, RepositoryHolder> repositories = emptyMap();
+    private volatile Map<String, RepositoryHolder> repositories = ImmutableMap.of();
 
     @Inject
     public RepositoriesService(Settings settings, ClusterService clusterService, TransportService transportService, RepositoryTypesRegistry typesRegistry, Injector injector) {
@@ -281,7 +272,7 @@ public class RepositoriesService extends AbstractComponent implements ClusterSta
                 }
             }
 
-            Map<String, RepositoryHolder> builder = new HashMap<>();
+            ImmutableMap.Builder<String, RepositoryHolder> builder = ImmutableMap.builder();
             if (newMetaData != null) {
                 // Now go through all repositories and update existing or create missing
                 for (RepositoryMetaData repositoryMetaData : newMetaData.repositories()) {
@@ -312,7 +303,7 @@ public class RepositoriesService extends AbstractComponent implements ClusterSta
                     }
                 }
             }
-            repositories = unmodifiableMap(builder);
+            repositories = builder.build();
         } catch (Throwable ex) {
             logger.warn("failure updating cluster state ", ex);
         }
@@ -377,6 +368,7 @@ public class RepositoriesService extends AbstractComponent implements ClusterSta
         }
         Map<String, RepositoryHolder> newRepositories = new HashMap<>(repositories);
         newRepositories.put(repositoryMetaData.name(), holder);
+        repositories = ImmutableMap.copyOf(newRepositories);
         return true;
     }
 
diff --git a/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodeAttrsAction.java b/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodeAttrsAction.java
index 2ac08fd..4193208 100644
--- a/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodeAttrsAction.java
+++ b/core/src/main/java/org/elasticsearch/rest/action/cat/RestNodeAttrsAction.java
@@ -18,8 +18,6 @@
  */
 
 package org.elasticsearch.rest.action.cat;
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
 import org.elasticsearch.action.admin.cluster.node.info.NodeInfo;
 import org.elasticsearch.action.admin.cluster.node.info.NodesInfoRequest;
 import org.elasticsearch.action.admin.cluster.node.info.NodesInfoResponse;
@@ -43,6 +41,8 @@ import org.elasticsearch.rest.action.support.RestActionListener;
 import org.elasticsearch.rest.action.support.RestResponseListener;
 import org.elasticsearch.rest.action.support.RestTable;
 
+import java.util.Map;
+
 import static org.elasticsearch.rest.RestRequest.Method.GET;
 
 public class RestNodeAttrsAction extends AbstractCatAction {
@@ -111,7 +111,8 @@ public class RestNodeAttrsAction extends AbstractCatAction {
 
         for (DiscoveryNode node : nodes) {
             NodeInfo info = nodesInfo.getNodesMap().get(node.id());
-            for(ObjectObjectCursor<String, String> att : node.attributes()) {
+            Map<String, String> attrs = node.getAttributes();
+            for(String att : attrs.keySet()) {
                 table.startRow();
                 table.addCell(node.name());
                 table.addCell(fullId ? node.id() : Strings.substring(node.getId(), 0, 4));
@@ -123,8 +124,8 @@ public class RestNodeAttrsAction extends AbstractCatAction {
                 } else {
                     table.addCell("-");
                 }
-                table.addCell(att.key);
-                table.addCell(att.value);
+                table.addCell(att);
+                table.addCell(attrs.containsKey(att) ? attrs.get(att) : null);
                 table.endRow();
             }
         }
diff --git a/core/src/main/java/org/elasticsearch/script/NativeScriptEngineService.java b/core/src/main/java/org/elasticsearch/script/NativeScriptEngineService.java
index 005e8f9..71154a5 100644
--- a/core/src/main/java/org/elasticsearch/script/NativeScriptEngineService.java
+++ b/core/src/main/java/org/elasticsearch/script/NativeScriptEngineService.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.script;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.apache.lucene.index.LeafReaderContext;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.component.AbstractComponent;
@@ -29,8 +31,6 @@ import org.elasticsearch.search.lookup.SearchLookup;
 import java.io.IOException;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * A native script engine service.
  */
@@ -38,12 +38,12 @@ public class NativeScriptEngineService extends AbstractComponent implements Scri
 
     public static final String NAME = "native";
 
-    private final Map<String, NativeScriptFactory> scripts;
+    private final ImmutableMap<String, NativeScriptFactory> scripts;
 
     @Inject
     public NativeScriptEngineService(Settings settings, Map<String, NativeScriptFactory> scripts) {
         super(settings);
-        this.scripts = unmodifiableMap(scripts);
+        this.scripts = ImmutableMap.copyOf(scripts);
     }
 
     @Override
@@ -94,16 +94,6 @@ public class NativeScriptEngineService extends AbstractComponent implements Scri
     }
 
     @Override
-    public Object execute(CompiledScript compiledScript, Map<String, Object> vars) {
-        return executable(compiledScript, vars).run();
-    }
-
-    @Override
-    public Object unwrap(Object value) {
-        return value;
-    }
-
-    @Override
     public void close() {
     }
 
diff --git a/core/src/main/java/org/elasticsearch/script/ScriptContextRegistry.java b/core/src/main/java/org/elasticsearch/script/ScriptContextRegistry.java
index 929575c..10a1c42 100644
--- a/core/src/main/java/org/elasticsearch/script/ScriptContextRegistry.java
+++ b/core/src/main/java/org/elasticsearch/script/ScriptContextRegistry.java
@@ -19,13 +19,10 @@
 
 package org.elasticsearch.script;
 
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.Set;
+import com.google.common.collect.ImmutableMap;
+
+import java.util.*;
 
-import static java.util.Collections.unmodifiableMap;
 import static java.util.Collections.unmodifiableSet;
 
 /**
@@ -36,7 +33,7 @@ import static java.util.Collections.unmodifiableSet;
 public final class ScriptContextRegistry {
     static final Set<String> RESERVED_SCRIPT_CONTEXTS = reservedScriptContexts();
 
-    private final Map<String, ScriptContext> scriptContexts;
+    private final ImmutableMap<String, ScriptContext> scriptContexts;
 
     public ScriptContextRegistry(Collection<ScriptContext.Plugin> customScriptContexts) {
         Map<String, ScriptContext> scriptContexts = new HashMap<>();
@@ -50,7 +47,7 @@ public final class ScriptContextRegistry {
                 throw new IllegalArgumentException("script context [" + customScriptContext.getKey() + "] cannot be registered twice");
             }
         }
-        this.scriptContexts = unmodifiableMap(scriptContexts);
+        this.scriptContexts = ImmutableMap.copyOf(scriptContexts);
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/script/ScriptEngineService.java b/core/src/main/java/org/elasticsearch/script/ScriptEngineService.java
index 9660857..993c95a 100644
--- a/core/src/main/java/org/elasticsearch/script/ScriptEngineService.java
+++ b/core/src/main/java/org/elasticsearch/script/ScriptEngineService.java
@@ -42,10 +42,6 @@ public interface ScriptEngineService extends Closeable {
 
     SearchScript search(CompiledScript compiledScript, SearchLookup lookup, @Nullable Map<String, Object> vars);
 
-    Object execute(CompiledScript compiledScript, Map<String, Object> vars);
-
-    Object unwrap(Object value);
-
     /**
      * Handler method called when a script is removed from the Guava cache.
      *
diff --git a/core/src/main/java/org/elasticsearch/script/ScriptModes.java b/core/src/main/java/org/elasticsearch/script/ScriptModes.java
index cfa3a59..897e69b 100644
--- a/core/src/main/java/org/elasticsearch/script/ScriptModes.java
+++ b/core/src/main/java/org/elasticsearch/script/ScriptModes.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.script;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.script.ScriptService.ScriptType;
@@ -28,8 +29,6 @@ import java.util.Map;
 import java.util.Set;
 import java.util.TreeMap;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * Holds the {@link org.elasticsearch.script.ScriptMode}s for each of the different scripting languages available,
  * each script source and each scripted operation.
@@ -39,7 +38,7 @@ public class ScriptModes {
     static final String SCRIPT_SETTINGS_PREFIX = "script.";
     static final String ENGINE_SETTINGS_PREFIX = "script.engine";
 
-    final Map<String, ScriptMode> scriptModes;
+    final ImmutableMap<String, ScriptMode> scriptModes;
 
     ScriptModes(Map<String, ScriptEngineService> scriptEngines, ScriptContextRegistry scriptContextRegistry, Settings settings) {
         //filter out the native engine as we don't want to apply fine grained settings to it.
@@ -49,7 +48,7 @@ public class ScriptModes {
         this.scriptModes = buildScriptModeSettingsMap(settings, filteredEngines, scriptContextRegistry);
     }
 
-    private static Map<String, ScriptMode> buildScriptModeSettingsMap(Settings settings, Map<String, ScriptEngineService> scriptEngines, ScriptContextRegistry scriptContextRegistry) {
+    private static ImmutableMap<String, ScriptMode> buildScriptModeSettingsMap(Settings settings, Map<String, ScriptEngineService> scriptEngines, ScriptContextRegistry scriptContextRegistry) {
         HashMap<String, ScriptMode> scriptModesMap = new HashMap<>();
 
         //file scripts are enabled by default, for any language
@@ -62,7 +61,7 @@ public class ScriptModes {
         processSourceBasedGlobalSettings(settings, scriptEngines, scriptContextRegistry, scriptModesMap);
         processOperationBasedGlobalSettings(settings, scriptEngines, scriptContextRegistry, scriptModesMap);
         processEngineSpecificSettings(settings, scriptEngines, scriptContextRegistry, scriptModesMap);
-        return unmodifiableMap(scriptModesMap);
+        return ImmutableMap.copyOf(scriptModesMap);
     }
 
     private static void processSourceBasedGlobalSettings(Settings settings, Map<String, ScriptEngineService> scriptEngines, ScriptContextRegistry scriptContextRegistry, Map<String, ScriptMode> scriptModes) {
diff --git a/core/src/main/java/org/elasticsearch/script/ScriptService.java b/core/src/main/java/org/elasticsearch/script/ScriptService.java
index 1095377..85769bc 100644
--- a/core/src/main/java/org/elasticsearch/script/ScriptService.java
+++ b/core/src/main/java/org/elasticsearch/script/ScriptService.java
@@ -19,10 +19,12 @@
 
 package org.elasticsearch.script;
 
+import java.nio.charset.StandardCharsets;
 import com.google.common.cache.Cache;
 import com.google.common.cache.CacheBuilder;
 import com.google.common.cache.RemovalListener;
 import com.google.common.cache.RemovalNotification;
+import com.google.common.collect.ImmutableMap;
 
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.action.ActionListener;
@@ -65,18 +67,14 @@ import org.elasticsearch.watcher.ResourceWatcherService;
 import java.io.Closeable;
 import java.io.IOException;
 import java.io.InputStreamReader;
-import java.nio.charset.StandardCharsets;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.util.HashMap;
 import java.util.Locale;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.TimeUnit;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  *
  */
@@ -95,8 +93,8 @@ public class ScriptService extends AbstractComponent implements Closeable {
     private final String defaultLang;
 
     private final Set<ScriptEngineService> scriptEngines;
-    private final Map<String, ScriptEngineService> scriptEnginesByLang;
-    private final Map<String, ScriptEngineService> scriptEnginesByExt;
+    private final ImmutableMap<String, ScriptEngineService> scriptEnginesByLang;
+    private final ImmutableMap<String, ScriptEngineService> scriptEnginesByExt;
 
     private final ConcurrentMap<String, CompiledScript> staticCache = ConcurrentCollections.newConcurrentMap();
 
@@ -164,8 +162,8 @@ public class ScriptService extends AbstractComponent implements Closeable {
         }
         this.cache = cacheBuilder.removalListener(new ScriptCacheRemovalListener()).build();
 
-        Map<String, ScriptEngineService> enginesByLangBuilder = new HashMap<>();
-        Map<String, ScriptEngineService> enginesByExtBuilder = new HashMap<>();
+        ImmutableMap.Builder<String, ScriptEngineService> enginesByLangBuilder = ImmutableMap.builder();
+        ImmutableMap.Builder<String, ScriptEngineService> enginesByExtBuilder = ImmutableMap.builder();
         for (ScriptEngineService scriptEngine : scriptEngines) {
             for (String type : scriptEngine.types()) {
                 enginesByLangBuilder.put(type, scriptEngine);
@@ -174,8 +172,8 @@ public class ScriptService extends AbstractComponent implements Closeable {
                 enginesByExtBuilder.put(ext, scriptEngine);
             }
         }
-        this.scriptEnginesByLang = unmodifiableMap(enginesByLangBuilder);
-        this.scriptEnginesByExt = unmodifiableMap(enginesByExtBuilder);
+        this.scriptEnginesByLang = enginesByLangBuilder.build();
+        this.scriptEnginesByExt = enginesByExtBuilder.build();
 
         this.scriptModes = new ScriptModes(this.scriptEnginesByLang, scriptContextRegistry, settings);
 
diff --git a/core/src/main/java/org/elasticsearch/script/mustache/MustacheScriptEngineService.java b/core/src/main/java/org/elasticsearch/script/mustache/MustacheScriptEngineService.java
index b5d4e96..3affd0c 100644
--- a/core/src/main/java/org/elasticsearch/script/mustache/MustacheScriptEngineService.java
+++ b/core/src/main/java/org/elasticsearch/script/mustache/MustacheScriptEngineService.java
@@ -19,7 +19,6 @@
 package org.elasticsearch.script.mustache;
 
 import com.github.mustachejava.Mustache;
-import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
@@ -34,7 +33,6 @@ import org.elasticsearch.script.ScriptException;
 import org.elasticsearch.script.SearchScript;
 import org.elasticsearch.search.lookup.SearchLookup;
 
-import java.io.IOException;
 import java.lang.ref.SoftReference;
 import java.util.Collections;
 import java.util.Map;
@@ -88,29 +86,6 @@ public class MustacheScriptEngineService extends AbstractComponent implements Sc
         return (new JsonEscapingMustacheFactory()).compile(new FastStringReader(template), "query-template");
     }
 
-    /**
-     * Execute a compiled template object (as retrieved from the compile method)
-     * and fill potential place holders with the variables given.
-     *
-     * @param template
-     *            compiled template object.
-     * @param vars
-     *            map of variables to use during substitution.
-     *
-     * @return the processed string with all given variables substitued.
-     * */
-    @Override
-    public Object execute(CompiledScript template, Map<String, Object> vars) {
-        BytesStreamOutput result = new BytesStreamOutput();
-        try (UTF8StreamWriter writer = utf8StreamWriter().setOutput(result)) {
-            ((Mustache) template.compiled()).execute(writer, vars);
-        } catch (Exception e) {
-            logger.error("Error executing " + template, e);
-            throw new ScriptException("Error executing " + template, e);
-        }
-        return result.bytes();
-    }
-
     @Override
     public String[] types() {
         return new String[] {NAME};
@@ -139,11 +114,6 @@ public class MustacheScriptEngineService extends AbstractComponent implements Sc
     }
 
     @Override
-    public Object unwrap(Object value) {
-        return value;
-    }
-
-    @Override
     public void close() {
         // Nothing to do here
     }
diff --git a/core/src/main/java/org/elasticsearch/search/SearchService.java b/core/src/main/java/org/elasticsearch/search/SearchService.java
index 57cecfc..403f4a5 100644
--- a/core/src/main/java/org/elasticsearch/search/SearchService.java
+++ b/core/src/main/java/org/elasticsearch/search/SearchService.java
@@ -22,6 +22,7 @@ package org.elasticsearch.search;
 import com.carrotsearch.hppc.ObjectHashSet;
 import com.carrotsearch.hppc.ObjectSet;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
+import com.google.common.collect.ImmutableMap;
 
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.LeafReaderContext;
@@ -111,7 +112,6 @@ import java.util.concurrent.Executor;
 import java.util.concurrent.ScheduledFuture;
 import java.util.concurrent.atomic.AtomicLong;
 
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.Strings.hasLength;
 import static org.elasticsearch.common.unit.TimeValue.timeValueMillis;
 import static org.elasticsearch.common.unit.TimeValue.timeValueMinutes;
@@ -160,7 +160,7 @@ public class SearchService extends AbstractLifecycleComponent<SearchService> {
 
     private final ConcurrentMapLong<SearchContext> activeContexts = ConcurrentCollections.newConcurrentMapLongWithAggressiveConcurrency();
 
-    private final Map<String, SearchParseElement> elementParsers;
+    private final ImmutableMap<String, SearchParseElement> elementParsers;
 
     private final ParseFieldMatcher parseFieldMatcher;
 
@@ -212,7 +212,7 @@ public class SearchService extends AbstractLifecycleComponent<SearchService> {
         elementParsers.putAll(queryPhase.parseElements());
         elementParsers.putAll(fetchPhase.parseElements());
         elementParsers.put("stats", new StatsGroupsParseElement());
-        this.elementParsers = unmodifiableMap(elementParsers);
+        this.elementParsers = ImmutableMap.copyOf(elementParsers);
 
         this.keepAliveReaper = threadPool.scheduleWithFixedDelay(new Reaper(), keepAliveInterval);
 
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/AggregationPhase.java b/core/src/main/java/org/elasticsearch/search/aggregations/AggregationPhase.java
index 742f678..123da5a 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/AggregationPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/AggregationPhase.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.search.aggregations;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Query;
@@ -34,33 +35,34 @@ import org.elasticsearch.search.query.QueryPhaseExecutionException;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  *
  */
 public class AggregationPhase implements SearchPhase {
-    private final Map<String, SearchParseElement> parseElements;
+
+    private final AggregationParseElement parseElement;
+
+    private final AggregationBinaryParseElement binaryParseElement;
 
     @Inject
     public AggregationPhase(AggregationParseElement parseElement, AggregationBinaryParseElement binaryParseElement) {
-        Map<String, SearchParseElement> parseElements = new HashMap<>();
-        parseElements.put("aggregations", parseElement);
-        parseElements.put("aggs", parseElement);
-        parseElements.put("aggregations_binary", binaryParseElement);
-        parseElements.put("aggregationsBinary", binaryParseElement);
-        parseElements.put("aggs_binary", binaryParseElement);
-        parseElements.put("aggsBinary", binaryParseElement);
-        this.parseElements = unmodifiableMap(parseElements);
+        this.parseElement = parseElement;
+        this.binaryParseElement = binaryParseElement;
     }
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        return parseElements;
+        return ImmutableMap.<String, SearchParseElement>builder()
+                .put("aggregations", parseElement)
+                .put("aggs", parseElement)
+                .put("aggregations_binary", binaryParseElement)
+                .put("aggregationsBinary", binaryParseElement)
+                .put("aggs_binary", binaryParseElement)
+                .put("aggsBinary", binaryParseElement)
+                .build();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/AggregationStreams.java b/core/src/main/java/org/elasticsearch/search/aggregations/AggregationStreams.java
index 2ebe2dd..97985f3 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/AggregationStreams.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/AggregationStreams.java
@@ -18,22 +18,20 @@
  */
 package org.elasticsearch.search.aggregations;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.io.stream.StreamInput;
 
 import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
 
 /**
  * A registry for all the dedicated streams in the aggregation module. This is to support dynamic addAggregation that
  * know how to stream themselves.
  */
 public class AggregationStreams {
-    private static Map<BytesReference, Stream> streams = emptyMap();
+
+    private static ImmutableMap<BytesReference, Stream> streams = ImmutableMap.of();
 
     /**
      * A stream that knows how to read an aggregation from the input.
@@ -49,11 +47,11 @@ public class AggregationStreams {
      * @param types     The types associated with the streams
      */
     public static synchronized void registerStream(Stream stream, BytesReference... types) {
-        Map<BytesReference, Stream> newStreams = new HashMap<>(streams);
+        MapBuilder<BytesReference, Stream> uStreams = MapBuilder.newMapBuilder(streams);
         for (BytesReference type : types) {
-            newStreams.put(type, stream);
+            uStreams.put(type, stream);
         }
-        streams = unmodifiableMap(newStreams);
+        streams = uStreams.immutableMap();
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorParsers.java b/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorParsers.java
index f38138f..257fef8 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorParsers.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/AggregatorParsers.java
@@ -18,6 +18,9 @@
  */
 package org.elasticsearch.search.aggregations;
 
+import com.google.common.collect.ImmutableMap;
+
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.common.xcontent.XContentParser;
@@ -27,22 +30,19 @@ import org.elasticsearch.search.aggregations.pipeline.PipelineAggregatorFactory;
 import org.elasticsearch.search.internal.SearchContext;
 
 import java.io.IOException;
-import java.util.HashMap;
 import java.util.Map;
 import java.util.Set;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * A registry for all the aggregator parser, also servers as the main parser for the aggregations module
  */
 public class AggregatorParsers {
-    public static final Pattern VALID_AGG_NAME = Pattern.compile("[^\\[\\]>]+");
 
-    private final Map<String, Aggregator.Parser> aggParsers;
-    private final Map<String, PipelineAggregator.Parser> pipelineAggregatorParsers;
+    public static final Pattern VALID_AGG_NAME = Pattern.compile("[^\\[\\]>]+");
+    private final ImmutableMap<String, Aggregator.Parser> aggParsers;
+    private final ImmutableMap<String, PipelineAggregator.Parser> pipelineAggregatorParsers;
 
 
     /**
@@ -55,16 +55,16 @@ public class AggregatorParsers {
      */
     @Inject
     public AggregatorParsers(Set<Aggregator.Parser> aggParsers, Set<PipelineAggregator.Parser> pipelineAggregatorParsers) {
-        Map<String, Aggregator.Parser> aggParsersBuilder = new HashMap<>(aggParsers.size());
+        MapBuilder<String, Aggregator.Parser> aggParsersBuilder = MapBuilder.newMapBuilder();
         for (Aggregator.Parser parser : aggParsers) {
             aggParsersBuilder.put(parser.type(), parser);
         }
-        this.aggParsers = unmodifiableMap(aggParsersBuilder);
-        Map<String, PipelineAggregator.Parser> pipelineAggregatorParsersBuilder = new HashMap<>(pipelineAggregatorParsers.size());
+        this.aggParsers = aggParsersBuilder.immutableMap();
+        MapBuilder<String, PipelineAggregator.Parser> pipelineAggregatorParsersBuilder = MapBuilder.newMapBuilder();
         for (PipelineAggregator.Parser parser : pipelineAggregatorParsers) {
             pipelineAggregatorParsersBuilder.put(parser.type(), parser);
         }
-        this.pipelineAggregatorParsers = unmodifiableMap(pipelineAggregatorParsersBuilder);
+        this.pipelineAggregatorParsers = pipelineAggregatorParsersBuilder.immutableMap();
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregations.java b/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregations.java
index 3841030..4297680 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregations.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/InternalAggregations.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.search.aggregations;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.bytes.BytesReference;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
@@ -36,9 +37,6 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.stream.Collectors;
-
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
 /**
  * An internal implementation of {@link Aggregations}.
  */
@@ -48,7 +46,7 @@ public class InternalAggregations implements Aggregations, ToXContent, Streamabl
 
     private List<InternalAggregation> aggregations = Collections.emptyList();
 
-    private Map<String, Aggregation> aggregationsAsMap;
+    private Map<String, InternalAggregation> aggregationsAsMap;
 
     private InternalAggregations() {
     }
@@ -90,13 +88,13 @@ public class InternalAggregations implements Aggregations, ToXContent, Streamabl
     @Override
     public Map<String, Aggregation> getAsMap() {
         if (aggregationsAsMap == null) {
-            Map<String, InternalAggregation> newAggregationsAsMap = new HashMap<>();
+            Map<String, InternalAggregation> aggregationsAsMap = new HashMap<>();
             for (InternalAggregation aggregation : aggregations) {
-                newAggregationsAsMap.put(aggregation.getName(), aggregation);
+                aggregationsAsMap.put(aggregation.getName(), aggregation);
             }
-            this.aggregationsAsMap = unmodifiableMap(newAggregationsAsMap);
+            this.aggregationsAsMap = aggregationsAsMap;
         }
-        return aggregationsAsMap;
+        return new HashMap<>(aggregationsAsMap);
     }
 
     /**
@@ -202,7 +200,7 @@ public class InternalAggregations implements Aggregations, ToXContent, Streamabl
         int size = in.readVInt();
         if (size == 0) {
             aggregations = Collections.emptyList();
-            aggregationsAsMap = emptyMap();
+            aggregationsAsMap = ImmutableMap.of();
         } else {
             aggregations = new ArrayList<>(size);
             for (int i = 0; i < size; i++) {
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketStreams.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketStreams.java
index ffbf826..aa489e0 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketStreams.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/BucketStreams.java
@@ -19,18 +19,16 @@
 
 package org.elasticsearch.search.aggregations.bucket;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.io.stream.StreamInput;
 
 import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
 
 public class BucketStreams {
-    private static Map<BytesReference, Stream> streams = emptyMap();
+
+    private static ImmutableMap<BytesReference, Stream> STREAMS = ImmutableMap.of();
 
     /**
      * A stream that knows how to read a bucket from the input.
@@ -47,11 +45,11 @@ public class BucketStreams {
      * @param types     The types associated with the streams
      */
     public static synchronized void registerStream(Stream stream, BytesReference... types) {
-        Map<BytesReference, Stream> newStreams = new HashMap<>(streams);
+        MapBuilder<BytesReference, Stream> uStreams = MapBuilder.newMapBuilder(STREAMS);
         for (BytesReference type : types) {
-            newStreams.put(type, stream);
+            uStreams.put(type, stream);
         }
-        streams = unmodifiableMap(newStreams);
+        STREAMS = uStreams.immutableMap();
     }
 
     /**
@@ -61,7 +59,7 @@ public class BucketStreams {
      * @return  The associated stream
      */
     public static Stream stream(BytesReference type) {
-        return streams.get(type);
+        return STREAMS.get(type);
     }
 
 }
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramParser.java b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramParser.java
index 694abf2..ae2ab8a 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramParser.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramParser.java
@@ -18,7 +18,10 @@
  */
 package org.elasticsearch.search.aggregations.bucket.histogram;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.common.ParseField;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.rounding.DateTimeUnit;
 import org.elasticsearch.common.rounding.Rounding;
 import org.elasticsearch.common.rounding.TimeZoneRounding;
@@ -31,12 +34,7 @@ import org.elasticsearch.search.aggregations.support.ValueType;
 import org.elasticsearch.search.aggregations.support.ValuesSourceConfig;
 import org.elasticsearch.search.aggregations.support.ValuesSourceParser;
 import org.elasticsearch.search.internal.SearchContext;
-
 import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static java.util.Collections.unmodifiableMap;
 
 /**
  *
@@ -47,27 +45,27 @@ public class DateHistogramParser implements Aggregator.Parser {
     static final ParseField OFFSET = new ParseField("offset");
     static final ParseField INTERVAL = new ParseField("interval");
 
-    public static final Map<String, DateTimeUnit> DATE_FIELD_UNITS;
+    public static final ImmutableMap<String, DateTimeUnit> DATE_FIELD_UNITS;
 
     static {
-        Map<String, DateTimeUnit> dateFieldUnits = new HashMap<>();
-        dateFieldUnits.put("year", DateTimeUnit.YEAR_OF_CENTURY);
-        dateFieldUnits.put("1y", DateTimeUnit.YEAR_OF_CENTURY);
-        dateFieldUnits.put("quarter", DateTimeUnit.QUARTER);
-        dateFieldUnits.put("1q", DateTimeUnit.QUARTER);
-        dateFieldUnits.put("month", DateTimeUnit.MONTH_OF_YEAR);
-        dateFieldUnits.put("1M", DateTimeUnit.MONTH_OF_YEAR);
-        dateFieldUnits.put("week", DateTimeUnit.WEEK_OF_WEEKYEAR);
-        dateFieldUnits.put("1w", DateTimeUnit.WEEK_OF_WEEKYEAR);
-        dateFieldUnits.put("day", DateTimeUnit.DAY_OF_MONTH);
-        dateFieldUnits.put("1d", DateTimeUnit.DAY_OF_MONTH);
-        dateFieldUnits.put("hour", DateTimeUnit.HOUR_OF_DAY);
-        dateFieldUnits.put("1h", DateTimeUnit.HOUR_OF_DAY);
-        dateFieldUnits.put("minute", DateTimeUnit.MINUTES_OF_HOUR);
-        dateFieldUnits.put("1m", DateTimeUnit.MINUTES_OF_HOUR);
-        dateFieldUnits.put("second", DateTimeUnit.SECOND_OF_MINUTE);
-        dateFieldUnits.put("1s", DateTimeUnit.SECOND_OF_MINUTE);
-        DATE_FIELD_UNITS = unmodifiableMap(dateFieldUnits);
+        DATE_FIELD_UNITS = MapBuilder.<String, DateTimeUnit>newMapBuilder()
+                .put("year", DateTimeUnit.YEAR_OF_CENTURY)
+                .put("1y", DateTimeUnit.YEAR_OF_CENTURY)
+                .put("quarter", DateTimeUnit.QUARTER)
+                .put("1q", DateTimeUnit.QUARTER)
+                .put("month", DateTimeUnit.MONTH_OF_YEAR)
+                .put("1M", DateTimeUnit.MONTH_OF_YEAR)
+                .put("week", DateTimeUnit.WEEK_OF_WEEKYEAR)
+                .put("1w", DateTimeUnit.WEEK_OF_WEEKYEAR)
+                .put("day", DateTimeUnit.DAY_OF_MONTH)
+                .put("1d", DateTimeUnit.DAY_OF_MONTH)
+                .put("hour", DateTimeUnit.HOUR_OF_DAY)
+                .put("1h", DateTimeUnit.HOUR_OF_DAY)
+                .put("minute", DateTimeUnit.MINUTES_OF_HOUR)
+                .put("1m", DateTimeUnit.MINUTES_OF_HOUR)
+                .put("second", DateTimeUnit.SECOND_OF_MINUTE)
+                .put("1s", DateTimeUnit.SECOND_OF_MINUTE)
+                .immutableMap();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/PipelineAggregatorStreams.java b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/PipelineAggregatorStreams.java
index 7104609..a633a3c 100644
--- a/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/PipelineAggregatorStreams.java
+++ b/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/PipelineAggregatorStreams.java
@@ -18,22 +18,21 @@
  */
 package org.elasticsearch.search.aggregations.pipeline;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.common.bytes.BytesReference;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.io.stream.StreamInput;
 
 import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
 
 /**
  * A registry for all the dedicated streams in the aggregation module. This is to support dynamic addAggregation that
  * know how to stream themselves.
  */
 public class PipelineAggregatorStreams {
-    private static Map<BytesReference, Stream> streams = emptyMap();
+
+    private static ImmutableMap<BytesReference, Stream> streams = ImmutableMap.of();
 
     /**
      * A stream that knows how to read an aggregation from the input.
@@ -49,11 +48,11 @@ public class PipelineAggregatorStreams {
      * @param types     The types associated with the streams
      */
     public static synchronized void registerStream(Stream stream, BytesReference... types) {
-        Map<BytesReference, Stream> newStreams = new HashMap<>(streams);
+        MapBuilder<BytesReference, Stream> uStreams = MapBuilder.newMapBuilder(streams);
         for (BytesReference type : types) {
-            newStreams.put(type, stream);
+            uStreams.put(type, stream);
         }
-        streams = unmodifiableMap(newStreams);
+        streams = uStreams.immutableMap();
     }
 
     /**
diff --git a/core/src/main/java/org/elasticsearch/search/dfs/DfsPhase.java b/core/src/main/java/org/elasticsearch/search/dfs/DfsPhase.java
index e1b98c4..f552292 100644
--- a/core/src/main/java/org/elasticsearch/search/dfs/DfsPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/dfs/DfsPhase.java
@@ -19,10 +19,10 @@
 
 package org.elasticsearch.search.dfs;
 
-import com.carrotsearch.hppc.ObjectHashSet;
 import com.carrotsearch.hppc.ObjectObjectHashMap;
+import com.carrotsearch.hppc.ObjectHashSet;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.index.IndexReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.TermContext;
@@ -39,8 +39,6 @@ import java.util.Collection;
 import java.util.Iterator;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-
 /**
  *
  */
@@ -48,7 +46,7 @@ public class DfsPhase implements SearchPhase {
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        return emptyMap();
+        return ImmutableMap.of();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java
index be3798e..e8e2e0e 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.search.fetch;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.ReaderUtil;
 import org.apache.lucene.search.DocIdSet;
@@ -63,7 +64,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.xcontent.XContentFactory.contentBuilder;
 
 /**
@@ -82,12 +82,12 @@ public class FetchPhase implements SearchPhase {
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        Map<String, SearchParseElement> parseElements = new HashMap<>();
+        ImmutableMap.Builder<String, SearchParseElement> parseElements = ImmutableMap.builder();
         parseElements.put("fields", new FieldsParseElement());
         for (FetchSubPhase fetchSubPhase : fetchSubPhases) {
             parseElements.putAll(fetchSubPhase.parseElements());
         }
-        return unmodifiableMap(parseElements);
+        return parseElements.build();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/explain/ExplainFetchSubPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/explain/ExplainFetchSubPhase.java
index 42eecb5..1c0eeaa 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/explain/ExplainFetchSubPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/explain/ExplainFetchSubPhase.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.search.fetch.explain;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.search.Explanation;
 import org.elasticsearch.search.SearchParseElement;
 import org.elasticsearch.search.fetch.FetchPhaseExecutionException;
@@ -29,8 +30,6 @@ import org.elasticsearch.search.rescore.RescoreSearchContext;
 import java.io.IOException;
 import java.util.Map;
 
-import static java.util.Collections.singletonMap;
-
 /**
  *
  */
@@ -38,7 +37,7 @@ public class ExplainFetchSubPhase implements FetchSubPhase {
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        return singletonMap("explain", new ExplainParseElement());
+        return ImmutableMap.of("explain", new ExplainParseElement());
     }
 
     @Override
@@ -60,7 +59,7 @@ public class ExplainFetchSubPhase implements FetchSubPhase {
         try {
             final int topLevelDocId = hitContext.hit().docId();
             Explanation explanation = context.searcher().explain(context.query(), topLevelDocId);
-
+            
             for (RescoreSearchContext rescore : context.rescore()) {
                 explanation = rescore.rescorer().explain(topLevelDocId, context, rescore, explanation);
             }
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/fielddata/FieldDataFieldsFetchSubPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/fielddata/FieldDataFieldsFetchSubPhase.java
index c74ef7b..1ec0a98 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/fielddata/FieldDataFieldsFetchSubPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/fielddata/FieldDataFieldsFetchSubPhase.java
@@ -18,13 +18,16 @@
  */
 package org.elasticsearch.search.fetch.fielddata;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.index.fielddata.AtomicFieldData;
 import org.elasticsearch.index.fielddata.ScriptDocValues;
+import org.elasticsearch.index.mapper.FieldMapper;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.search.SearchHitField;
 import org.elasticsearch.search.SearchParseElement;
 import org.elasticsearch.search.fetch.FetchSubPhase;
+import org.elasticsearch.search.fetch.FetchSubPhaseContext;
 import org.elasticsearch.search.internal.InternalSearchHit;
 import org.elasticsearch.search.internal.InternalSearchHitField;
 import org.elasticsearch.search.internal.SearchContext;
@@ -33,8 +36,6 @@ import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * Query sub phase which pulls data from field data (using the cache if
  * available, building it if not).
@@ -63,10 +64,10 @@ public class FieldDataFieldsFetchSubPhase implements FetchSubPhase {
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        Map<String, SearchParseElement> parseElements = new HashMap<>();
-        parseElements.put("fielddata_fields", new FieldDataFieldsParseElement());
-        parseElements.put("fielddataFields", new FieldDataFieldsParseElement());
-        return unmodifiableMap(parseElements);
+        ImmutableMap.Builder<String, SearchParseElement> parseElements = ImmutableMap.builder();
+        parseElements.put("fielddata_fields", new FieldDataFieldsParseElement())
+                .put("fielddataFields", new FieldDataFieldsParseElement());
+        return parseElements.build();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsFetchSubPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsFetchSubPhase.java
index 3557e55..2a36797 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsFetchSubPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/innerhits/InnerHitsFetchSubPhase.java
@@ -19,9 +19,11 @@
 
 package org.elasticsearch.search.fetch.innerhits;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.search.FieldDoc;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TopDocs;
+import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.search.SearchParseElement;
@@ -41,24 +43,32 @@ import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.singletonMap;
-
 /**
  */
 public class InnerHitsFetchSubPhase implements FetchSubPhase {
-    private final Map<String, ? extends SearchParseElement> parseElements;
+
+    private final SortParseElement sortParseElement;
+    private final FetchSourceParseElement sourceParseElement;
+    private final HighlighterParseElement highlighterParseElement;
+    private final FieldDataFieldsParseElement fieldDataFieldsParseElement;
+    private final ScriptFieldsParseElement scriptFieldsParseElement;
 
     private FetchPhase fetchPhase;
 
     @Inject
     public InnerHitsFetchSubPhase(SortParseElement sortParseElement, FetchSourceParseElement sourceParseElement, HighlighterParseElement highlighterParseElement, FieldDataFieldsParseElement fieldDataFieldsParseElement, ScriptFieldsParseElement scriptFieldsParseElement) {
-        parseElements = singletonMap("inner_hits", new InnerHitsParseElement(sortParseElement, sourceParseElement, highlighterParseElement,
-                fieldDataFieldsParseElement, scriptFieldsParseElement));
+        this.sortParseElement = sortParseElement;
+        this.sourceParseElement = sourceParseElement;
+        this.highlighterParseElement = highlighterParseElement;
+        this.fieldDataFieldsParseElement = fieldDataFieldsParseElement;
+        this.scriptFieldsParseElement = scriptFieldsParseElement;
     }
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        return parseElements;
+        return ImmutableMap.of("inner_hits", new InnerHitsParseElement(
+                sortParseElement, sourceParseElement, highlighterParseElement, fieldDataFieldsParseElement, scriptFieldsParseElement
+        ));
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/matchedqueries/MatchedQueriesFetchSubPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/matchedqueries/MatchedQueriesFetchSubPhase.java
index de5294f..2824bc1 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/matchedqueries/MatchedQueriesFetchSubPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/matchedqueries/MatchedQueriesFetchSubPhase.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.search.fetch.matchedqueries;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.TwoPhaseIterator;
@@ -34,8 +35,6 @@ import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-
 /**
  *
  */
@@ -43,7 +42,7 @@ public class MatchedQueriesFetchSubPhase implements FetchSubPhase {
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        return emptyMap();
+        return ImmutableMap.of();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/script/ScriptFieldsFetchSubPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/script/ScriptFieldsFetchSubPhase.java
index 8abcdfb..05ec51e 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/script/ScriptFieldsFetchSubPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/script/ScriptFieldsFetchSubPhase.java
@@ -18,6 +18,10 @@
  */
 package org.elasticsearch.search.fetch.script;
 
+import com.google.common.collect.ImmutableMap;
+
+import org.elasticsearch.ElasticsearchException;
+import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.script.LeafSearchScript;
 import org.elasticsearch.search.SearchHitField;
 import org.elasticsearch.search.SearchParseElement;
@@ -34,23 +38,21 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  *
  */
 public class ScriptFieldsFetchSubPhase implements FetchSubPhase {
-    private static final Map<String, SearchParseElement> PARSE_ELEMENTS;
-    static {
-        Map<String, SearchParseElement> parseElements = new HashMap<>();
-        parseElements.put("script_fields", new ScriptFieldsParseElement());
-        parseElements.put("scriptFields", new ScriptFieldsParseElement());
-        PARSE_ELEMENTS = unmodifiableMap(parseElements);
+
+    @Inject
+    public ScriptFieldsFetchSubPhase() {
     }
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        return PARSE_ELEMENTS;
+        ImmutableMap.Builder<String, SearchParseElement> parseElements = ImmutableMap.builder();
+        parseElements.put("script_fields", new ScriptFieldsParseElement())
+                .put("scriptFields", new ScriptFieldsParseElement());
+        return parseElements.build();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/source/FetchSourceSubPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/source/FetchSourceSubPhase.java
index 1ed4738..445d680 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/source/FetchSourceSubPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/source/FetchSourceSubPhase.java
@@ -19,9 +19,12 @@
 
 package org.elasticsearch.search.fetch.source;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.ElasticsearchException;
+import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentFactory;
 import org.elasticsearch.search.SearchParseElement;
 import org.elasticsearch.search.fetch.FetchSubPhase;
 import org.elasticsearch.search.internal.InternalSearchHit;
@@ -31,16 +34,20 @@ import org.elasticsearch.search.lookup.SourceLookup;
 import java.io.IOException;
 import java.util.Map;
 
-import static java.util.Collections.singletonMap;
-
 /**
  */
 public class FetchSourceSubPhase implements FetchSubPhase {
-    private static final Map<String, SearchParseElement> PARSE_ELEMENTS = singletonMap("_source", new FetchSourceParseElement());
+
+    @Inject
+    public FetchSourceSubPhase() {
+
+    }
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        return PARSE_ELEMENTS;
+        ImmutableMap.Builder<String, SearchParseElement> parseElements = ImmutableMap.builder();
+        parseElements.put("_source", new FetchSourceParseElement());
+        return parseElements.build();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/fetch/version/VersionFetchSubPhase.java b/core/src/main/java/org/elasticsearch/search/fetch/version/VersionFetchSubPhase.java
index ec36b78..6a5264d 100644
--- a/core/src/main/java/org/elasticsearch/search/fetch/version/VersionFetchSubPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/fetch/version/VersionFetchSubPhase.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.search.fetch.version;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.ElasticsearchException;
@@ -32,17 +33,14 @@ import org.elasticsearch.search.internal.SearchContext;
 import java.io.IOException;
 import java.util.Map;
 
-import static java.util.Collections.singletonMap;
-
 /**
  *
  */
 public class VersionFetchSubPhase implements FetchSubPhase {
-    private static final Map<String, ? extends SearchParseElement> PARSE_ELEMENTS = singletonMap("version", new VersionParseElement());
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        return PARSE_ELEMENTS;
+        return ImmutableMap.of("version", new VersionParseElement());
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java b/core/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java
index 5352af7..96e1988 100644
--- a/core/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/highlight/HighlightPhase.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.search.highlight;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
@@ -39,15 +40,12 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.singletonMap;
-
 /**
  *
  */
 public class HighlightPhase extends AbstractComponent implements FetchSubPhase {
+
     private static final List<String> STANDARD_HIGHLIGHTERS_BY_PRECEDENCE = Arrays.asList("fvh", "postings", "plain");
-    private static final Map<String, ? extends SearchParseElement> PARSE_ELEMENTS = singletonMap("highlight",
-            new HighlighterParseElement());
 
     private final Highlighters highlighters;
 
@@ -59,7 +57,7 @@ public class HighlightPhase extends AbstractComponent implements FetchSubPhase {
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        return PARSE_ELEMENTS;
+        return ImmutableMap.of("highlight", new HighlighterParseElement());
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java b/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java
index c1194f1..7c334a9 100644
--- a/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java
+++ b/core/src/main/java/org/elasticsearch/search/internal/InternalSearchHit.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.search.internal;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.search.Explanation;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.ElasticsearchParseException;
@@ -51,9 +52,6 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.singletonMap;
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.lucene.Lucene.readExplanation;
 import static org.elasticsearch.common.lucene.Lucene.writeExplanation;
 import static org.elasticsearch.search.SearchShardTarget.readSearchShardTarget;
@@ -80,7 +78,7 @@ public class InternalSearchHit implements SearchHit {
 
     private BytesReference source;
 
-    private Map<String, SearchHitField> fields = emptyMap();
+    private Map<String, SearchHitField> fields = ImmutableMap.of();
 
     private Map<String, HighlightField> highlightFields = null;
 
@@ -294,12 +292,15 @@ public class InternalSearchHit implements SearchHit {
 
     @Override
     public Map<String, SearchHitField> fields() {
-        return fields == null ? emptyMap() : fields;
+        if (fields == null) {
+            return ImmutableMap.of();
+        }
+        return fields;
     }
 
     // returns the fields without handling null cases
     public Map<String, SearchHitField> fieldsOrNull() {
-        return fields;
+        return this.fields;
     }
 
     @Override
@@ -317,7 +318,10 @@ public class InternalSearchHit implements SearchHit {
 
     @Override
     public Map<String, HighlightField> highlightFields() {
-        return highlightFields == null ? emptyMap() : highlightFields;
+        if (highlightFields == null) {
+            return ImmutableMap.of();
+        }
+        return this.highlightFields;
     }
 
     @Override
@@ -570,32 +574,69 @@ public class InternalSearchHit implements SearchHit {
         }
         int size = in.readVInt();
         if (size == 0) {
-            fields = emptyMap();
+            fields = ImmutableMap.of();
         } else if (size == 1) {
             SearchHitField hitField = readSearchHitField(in);
-            fields = singletonMap(hitField.name(), hitField);
+            fields = ImmutableMap.of(hitField.name(), hitField);
+        } else if (size == 2) {
+            SearchHitField hitField1 = readSearchHitField(in);
+            SearchHitField hitField2 = readSearchHitField(in);
+            fields = ImmutableMap.of(hitField1.name(), hitField1, hitField2.name(), hitField2);
+        } else if (size == 3) {
+            SearchHitField hitField1 = readSearchHitField(in);
+            SearchHitField hitField2 = readSearchHitField(in);
+            SearchHitField hitField3 = readSearchHitField(in);
+            fields = ImmutableMap.of(hitField1.name(), hitField1, hitField2.name(), hitField2, hitField3.name(), hitField3);
+        } else if (size == 4) {
+            SearchHitField hitField1 = readSearchHitField(in);
+            SearchHitField hitField2 = readSearchHitField(in);
+            SearchHitField hitField3 = readSearchHitField(in);
+            SearchHitField hitField4 = readSearchHitField(in);
+            fields = ImmutableMap.of(hitField1.name(), hitField1, hitField2.name(), hitField2, hitField3.name(), hitField3, hitField4.name(), hitField4);
+        } else if (size == 5) {
+            SearchHitField hitField1 = readSearchHitField(in);
+            SearchHitField hitField2 = readSearchHitField(in);
+            SearchHitField hitField3 = readSearchHitField(in);
+            SearchHitField hitField4 = readSearchHitField(in);
+            SearchHitField hitField5 = readSearchHitField(in);
+            fields = ImmutableMap.of(hitField1.name(), hitField1, hitField2.name(), hitField2, hitField3.name(), hitField3, hitField4.name(), hitField4, hitField5.name(), hitField5);
         } else {
-            Map<String, SearchHitField> fields = new HashMap<>();
+            ImmutableMap.Builder<String, SearchHitField> builder = ImmutableMap.builder();
             for (int i = 0; i < size; i++) {
                 SearchHitField hitField = readSearchHitField(in);
-                fields.put(hitField.name(), hitField);
+                builder.put(hitField.name(), hitField);
             }
-            this.fields = unmodifiableMap(fields);
+            fields = builder.build();
         }
 
         size = in.readVInt();
         if (size == 0) {
-            highlightFields = emptyMap();
+            highlightFields = ImmutableMap.of();
         } else if (size == 1) {
             HighlightField field = readHighlightField(in);
-            highlightFields = singletonMap(field.name(), field);
+            highlightFields = ImmutableMap.of(field.name(), field);
+        } else if (size == 2) {
+            HighlightField field1 = readHighlightField(in);
+            HighlightField field2 = readHighlightField(in);
+            highlightFields = ImmutableMap.of(field1.name(), field1, field2.name(), field2);
+        } else if (size == 3) {
+            HighlightField field1 = readHighlightField(in);
+            HighlightField field2 = readHighlightField(in);
+            HighlightField field3 = readHighlightField(in);
+            highlightFields = ImmutableMap.of(field1.name(), field1, field2.name(), field2, field3.name(), field3);
+        } else if (size == 4) {
+            HighlightField field1 = readHighlightField(in);
+            HighlightField field2 = readHighlightField(in);
+            HighlightField field3 = readHighlightField(in);
+            HighlightField field4 = readHighlightField(in);
+            highlightFields = ImmutableMap.of(field1.name(), field1, field2.name(), field2, field3.name(), field3, field4.name(), field4);
         } else {
-            Map<String, HighlightField> highlightFields = new HashMap<>();
+            ImmutableMap.Builder<String, HighlightField> builder = ImmutableMap.builder();
             for (int i = 0; i < size; i++) {
                 HighlightField field = readHighlightField(in);
-                highlightFields.put(field.name(), field);
+                builder.put(field.name(), field);
             }
-            this.highlightFields = unmodifiableMap(highlightFields);
+            highlightFields = builder.build();
         }
 
         size = in.readVInt();
diff --git a/core/src/main/java/org/elasticsearch/search/lookup/IndexLookup.java b/core/src/main/java/org/elasticsearch/search/lookup/IndexLookup.java
index 485c690..0150ef7 100644
--- a/core/src/main/java/org/elasticsearch/search/lookup/IndexLookup.java
+++ b/core/src/main/java/org/elasticsearch/search/lookup/IndexLookup.java
@@ -18,24 +18,12 @@
  */
 package org.elasticsearch.search.lookup;
 
-import org.apache.lucene.index.LeafReaderContext;
-
-import java.util.HashMap;
-import java.util.Map;
+import com.google.common.collect.ImmutableMap.Builder;
 
-import static java.util.Collections.unmodifiableMap;
+import org.apache.lucene.index.LeafReaderContext;
 
 public class IndexLookup {
-    public static final Map<String, Object> NAMES;
-    static {
-        Map<String, Object> names = new HashMap<>();
-        names.put("_FREQUENCIES", IndexLookup.FLAG_FREQUENCIES);
-        names.put("_POSITIONS", IndexLookup.FLAG_POSITIONS);
-        names.put("_OFFSETS", IndexLookup.FLAG_OFFSETS);
-        names.put("_PAYLOADS", IndexLookup.FLAG_PAYLOADS);
-        names.put("_CACHE", IndexLookup.FLAG_CACHE);
-        NAMES = unmodifiableMap(names);
-    }
+
     /**
      * Flag to pass to {@link IndexField#get(Object, int)} if you require
      * offsets in the returned {@link IndexFieldTerm}.
@@ -67,7 +55,15 @@ public class IndexLookup {
      */
     public static final int FLAG_CACHE = 32;
 
-    public static LeafIndexLookup getLeafIndexLookup(LeafReaderContext context) {
+    public IndexLookup(Builder<String, Object> builder) {
+        builder.put("_FREQUENCIES", IndexLookup.FLAG_FREQUENCIES);
+        builder.put("_POSITIONS", IndexLookup.FLAG_POSITIONS);
+        builder.put("_OFFSETS", IndexLookup.FLAG_OFFSETS);
+        builder.put("_PAYLOADS", IndexLookup.FLAG_PAYLOADS);
+        builder.put("_CACHE", IndexLookup.FLAG_CACHE);
+    }
+
+    public LeafIndexLookup getLeafIndexLookup(LeafReaderContext context) {
         return new LeafIndexLookup(context);
     }
 
diff --git a/core/src/main/java/org/elasticsearch/search/lookup/LeafFieldsLookup.java b/core/src/main/java/org/elasticsearch/search/lookup/LeafFieldsLookup.java
index e5295e8..d45067f 100644
--- a/core/src/main/java/org/elasticsearch/search/lookup/LeafFieldsLookup.java
+++ b/core/src/main/java/org/elasticsearch/search/lookup/LeafFieldsLookup.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.search.lookup;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.index.LeafReader;
 import org.elasticsearch.ElasticsearchParseException;
 import org.elasticsearch.common.Nullable;
@@ -32,8 +33,6 @@ import java.util.HashMap;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.singletonMap;
-
 /**
  *
  */
@@ -149,7 +148,7 @@ public class LeafFieldsLookup implements Map {
             try {
                 reader.document(docId, fieldVisitor);
                 fieldVisitor.postProcess(data.fieldType());
-                data.fields(singletonMap(name, fieldVisitor.fields().get(data.fieldType().names().indexName())));
+                data.fields(ImmutableMap.of(name, fieldVisitor.fields().get(data.fieldType().names().indexName())));
             } catch (IOException e) {
                 throw new ElasticsearchParseException("failed to load field [{}]", e, name);
             }
diff --git a/core/src/main/java/org/elasticsearch/search/lookup/SearchLookup.java b/core/src/main/java/org/elasticsearch/search/lookup/SearchLookup.java
index c9438fd..091a368 100644
--- a/core/src/main/java/org/elasticsearch/search/lookup/SearchLookup.java
+++ b/core/src/main/java/org/elasticsearch/search/lookup/SearchLookup.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.search.lookup;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.index.LeafReaderContext;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.index.fielddata.IndexFieldDataService;
@@ -35,10 +36,17 @@ public class SearchLookup {
 
     final FieldsLookup fieldsLookup;
 
+    final IndexLookup indexLookup;
+
+    final ImmutableMap<String, Object> asMap;
+
     public SearchLookup(MapperService mapperService, IndexFieldDataService fieldDataService, @Nullable String[] types) {
+        ImmutableMap.Builder<String, Object> builder = ImmutableMap.builder();
         docMap = new DocLookup(mapperService, fieldDataService, types);
         sourceLookup = new SourceLookup();
         fieldsLookup = new FieldsLookup(mapperService, types);
+        indexLookup = new IndexLookup(builder);
+        asMap = builder.build();
     }
 
     public LeafSearchLookup getLeafSearchLookup(LeafReaderContext context) {
@@ -46,8 +54,8 @@ public class SearchLookup {
                 docMap.getLeafDocLookup(context),
                 sourceLookup,
                 fieldsLookup.getLeafFieldsLookup(context),
-                IndexLookup.getLeafIndexLookup(context),
-                IndexLookup.NAMES);
+                indexLookup.getLeafIndexLookup(context),
+                asMap);
     }
 
     public DocLookup doc() {
diff --git a/core/src/main/java/org/elasticsearch/search/lookup/SourceLookup.java b/core/src/main/java/org/elasticsearch/search/lookup/SourceLookup.java
index 910f5da..c0ca2eb 100644
--- a/core/src/main/java/org/elasticsearch/search/lookup/SourceLookup.java
+++ b/core/src/main/java/org/elasticsearch/search/lookup/SourceLookup.java
@@ -18,6 +18,8 @@
  */
 package org.elasticsearch.search.lookup;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.elasticsearch.ElasticsearchParseException;
@@ -33,8 +35,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.emptyMap;
-
 /**
  *
  */
@@ -71,7 +71,7 @@ public class SourceLookup implements Map {
             reader.document(docId, sourceFieldVisitor);
             BytesReference source = sourceFieldVisitor.source();
             if (source == null) {
-                this.source = emptyMap();
+                this.source = ImmutableMap.of();
                 this.sourceContentType = null;
             } else {
                 Tuple<XContentType, Map<String, Object>> tuple = sourceAsMapAndType(source);
diff --git a/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java b/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java
index c4aa23f..d347897 100644
--- a/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/query/QueryPhase.java
@@ -19,28 +19,12 @@
 
 package org.elasticsearch.search.query;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.MinDocQuery;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Collector;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.FieldDoc;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.MultiCollector;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.Sort;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.TimeLimitingCollector;
-import org.apache.lucene.search.TopDocs;
-import org.apache.lucene.search.TopDocsCollector;
-import org.apache.lucene.search.TopFieldCollector;
-import org.apache.lucene.search.TopScoreDocCollector;
-import org.apache.lucene.search.TotalHitCountCollector;
-import org.apache.lucene.search.Weight;
+import org.apache.lucene.search.*;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.lucene.Lucene;
@@ -59,13 +43,10 @@ import org.elasticsearch.search.sort.TrackScoresParseElement;
 import org.elasticsearch.search.suggest.SuggestPhase;
 
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.Callable;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  *
  */
@@ -84,30 +65,29 @@ public class QueryPhase implements SearchPhase {
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        Map<String, SearchParseElement> parseElements = new HashMap<>();
-        parseElements.put("from", new FromParseElement());
-        parseElements.put("size", new SizeParseElement());
-        parseElements.put("indices_boost", new IndicesBoostParseElement());
-        parseElements.put("indicesBoost", new IndicesBoostParseElement());
-        parseElements.put("query", new QueryParseElement());
-        parseElements.put("queryBinary", new QueryBinaryParseElement());
-        parseElements.put("query_binary", new QueryBinaryParseElement());
-        parseElements.put("filter", new PostFilterParseElement()); // For bw comp reason, should be removed in version 1.1
-        parseElements.put("post_filter", new PostFilterParseElement());
-        parseElements.put("postFilter", new PostFilterParseElement());
-        parseElements.put("filterBinary", new FilterBinaryParseElement());
-        parseElements.put("filter_binary", new FilterBinaryParseElement());
-        parseElements.put("sort", new SortParseElement());
-        parseElements.put("trackScores", new TrackScoresParseElement());
-        parseElements.put("track_scores", new TrackScoresParseElement());
-        parseElements.put("min_score", new MinScoreParseElement());
-        parseElements.put("minScore", new MinScoreParseElement());
-        parseElements.put("timeout", new TimeoutParseElement());
-        parseElements.put("terminate_after", new TerminateAfterParseElement());
-        parseElements.putAll(aggregationPhase.parseElements());
-        parseElements.putAll(suggestPhase.parseElements());
-        parseElements.putAll(rescorePhase.parseElements());
-        return unmodifiableMap(parseElements);
+        ImmutableMap.Builder<String, SearchParseElement> parseElements = ImmutableMap.builder();
+        parseElements.put("from", new FromParseElement()).put("size", new SizeParseElement())
+                .put("indices_boost", new IndicesBoostParseElement())
+                .put("indicesBoost", new IndicesBoostParseElement())
+                .put("query", new QueryParseElement())
+                .put("queryBinary", new QueryBinaryParseElement())
+                .put("query_binary", new QueryBinaryParseElement())
+                .put("filter", new PostFilterParseElement()) // For bw comp reason, should be removed in version 1.1
+                .put("post_filter", new PostFilterParseElement())
+                .put("postFilter", new PostFilterParseElement())
+                .put("filterBinary", new FilterBinaryParseElement())
+                .put("filter_binary", new FilterBinaryParseElement())
+                .put("sort", new SortParseElement())
+                .put("trackScores", new TrackScoresParseElement())
+                .put("track_scores", new TrackScoresParseElement())
+                .put("min_score", new MinScoreParseElement())
+                .put("minScore", new MinScoreParseElement())
+                .put("timeout", new TimeoutParseElement())
+                .put("terminate_after", new TerminateAfterParseElement())
+                .putAll(aggregationPhase.parseElements())
+                .putAll(suggestPhase.parseElements())
+                .putAll(rescorePhase.parseElements());
+        return parseElements.build();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/rescore/RescorePhase.java b/core/src/main/java/org/elasticsearch/search/rescore/RescorePhase.java
index d1592aa..48d8407 100644
--- a/core/src/main/java/org/elasticsearch/search/rescore/RescorePhase.java
+++ b/core/src/main/java/org/elasticsearch/search/rescore/RescorePhase.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.search.rescore;
 
+import com.google.common.collect.ImmutableMap;
+import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.TopDocs;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.component.AbstractComponent;
@@ -31,13 +33,10 @@ import org.elasticsearch.search.internal.SearchContext;
 import java.io.IOException;
 import java.util.Map;
 
-import static java.util.Collections.singletonMap;
-
 /**
  */
 public class RescorePhase extends AbstractComponent implements SearchPhase {
-    private static final Map<String, SearchParseElement> PARSE_ELEMENTS = singletonMap("rescore", new RescoreParseElement());
-
+    
     @Inject
     public RescorePhase(Settings settings) {
         super(settings);
@@ -45,7 +44,9 @@ public class RescorePhase extends AbstractComponent implements SearchPhase {
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        return PARSE_ELEMENTS;
+        ImmutableMap.Builder<String, SearchParseElement> parseElements = ImmutableMap.builder();
+        parseElements.put("rescore", new RescoreParseElement());
+        return parseElements.build();
     }
 
     @Override
diff --git a/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java b/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java
index 8454537..f03ca7c 100644
--- a/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java
+++ b/core/src/main/java/org/elasticsearch/search/sort/SortParseElement.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.search.sort;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.Sort;
@@ -32,19 +34,17 @@ import org.elasticsearch.index.fielddata.IndexFieldData;
 import org.elasticsearch.index.fielddata.IndexFieldData.XFieldComparatorSource.Nested;
 import org.elasticsearch.index.mapper.MappedFieldType;
 import org.elasticsearch.index.mapper.core.LongFieldMapper;
+import org.elasticsearch.index.mapper.object.ObjectMapper;
 import org.elasticsearch.index.query.support.NestedInnerQueryParseSupport;
 import org.elasticsearch.search.MultiValueMode;
 import org.elasticsearch.search.SearchParseElement;
 import org.elasticsearch.search.SearchParseException;
 import org.elasticsearch.search.internal.SearchContext;
+import org.elasticsearch.search.internal.SubSearchContext;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.List;
-import java.util.Map;
-
-import static java.util.Collections.unmodifiableMap;
 
 /**
  *
@@ -62,16 +62,16 @@ public class SortParseElement implements SearchParseElement {
     public static final String SCORE_FIELD_NAME = "_score";
     public static final String DOC_FIELD_NAME = "_doc";
 
-    private static final Map<String, SortParser> PARSERS;
+    private final ImmutableMap<String, SortParser> parsers;
 
-    static {
-        Map<String, SortParser> parsers = new HashMap<>();
-        addParser(parsers, new ScriptSortParser());
-        addParser(parsers, new GeoDistanceSortParser());
-        PARSERS = unmodifiableMap(parsers);
+    public SortParseElement() {
+        ImmutableMap.Builder<String, SortParser> builder = ImmutableMap.builder();
+        addParser(builder, new ScriptSortParser());
+        addParser(builder, new GeoDistanceSortParser());
+        this.parsers = builder.build();
     }
 
-    private static void addParser(Map<String, SortParser> parsers, SortParser parser) {
+    private void addParser(ImmutableMap.Builder<String, SortParser> parsers, SortParser parser) {
         for (String name : parser.names()) {
             parsers.put(name, parser);
         }
@@ -140,8 +140,8 @@ public class SortParseElement implements SearchParseElement {
                     }
                     addSortField(context, sortFields, fieldName, reverse, unmappedType, missing, sortMode, nestedFilterParseHelper);
                 } else {
-                    if (PARSERS.containsKey(fieldName)) {
-                        sortFields.add(PARSERS.get(fieldName).parse(parser, context));
+                    if (parsers.containsKey(fieldName)) {
+                        sortFields.add(parsers.get(fieldName).parse(parser, context));
                     } else {
                         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                             if (token == XContentParser.Token.FIELD_NAME) {
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/SuggestPhase.java b/core/src/main/java/org/elasticsearch/search/suggest/SuggestPhase.java
index 541efa7..58a4502 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/SuggestPhase.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/SuggestPhase.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.search.suggest;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.elasticsearch.ElasticsearchException;
@@ -37,24 +38,23 @@ import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.singletonMap;
-
 /**
  */
 public class SuggestPhase extends AbstractComponent implements SearchPhase {
-    private final Map<String, SearchParseElement> parseElements;
+
     private final SuggestParseElement parseElement;
 
     @Inject
     public SuggestPhase(Settings settings, SuggestParseElement suggestParseElement) {
         super(settings);
         this.parseElement = suggestParseElement;
-        parseElements = singletonMap("suggest", parseElement);
     }
 
     @Override
     public Map<String, ? extends SearchParseElement> parseElements() {
-        return parseElements;
+        ImmutableMap.Builder<String, SearchParseElement> parseElements = ImmutableMap.builder();
+        parseElements.put("suggest", parseElement);
+        return parseElements.build();
     }
 
     public SuggestParseElement parseElement() {
diff --git a/core/src/main/java/org/elasticsearch/search/suggest/completion/Completion090PostingsFormat.java b/core/src/main/java/org/elasticsearch/search/suggest/completion/Completion090PostingsFormat.java
index 447b3fd..bbb3340 100644
--- a/core/src/main/java/org/elasticsearch/search/suggest/completion/Completion090PostingsFormat.java
+++ b/core/src/main/java/org/elasticsearch/search/suggest/completion/Completion090PostingsFormat.java
@@ -18,6 +18,8 @@
  */
 package org.elasticsearch.search.suggest.completion;
 
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.ImmutableMap.Builder;
 import org.apache.lucene.codecs.CodecUtil;
 import org.apache.lucene.codecs.FieldsConsumer;
 import org.apache.lucene.codecs.FieldsProducer;
@@ -57,8 +59,6 @@ import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.singletonMap;
-
 /**
  * This {@link PostingsFormat} is basically a T-Sink for a default postings
  * format that is used to store postings on disk fitting the lucene APIs and
@@ -75,12 +75,18 @@ public class Completion090PostingsFormat extends PostingsFormat {
     public static final int SUGGEST_VERSION_CURRENT = SUGGEST_CODEC_VERSION;
     public static final String EXTENSION = "cmp";
 
-    private static final ESLogger logger = Loggers.getLogger(Completion090PostingsFormat.class);
-    private static final CompletionLookupProvider LOOKUP_PROVIDER = new AnalyzingCompletionLookupProvider(true, false, true, false);
-    private static final Map<String, CompletionLookupProvider> PROVIDERS = singletonMap(LOOKUP_PROVIDER.getName(), LOOKUP_PROVIDER);
+    private final static ESLogger logger = Loggers.getLogger(Completion090PostingsFormat.class);
     private PostingsFormat delegatePostingsFormat;
+    private final static Map<String, CompletionLookupProvider> providers;
     private CompletionLookupProvider writeProvider;
 
+
+    static {
+        final CompletionLookupProvider provider = new AnalyzingCompletionLookupProvider(true, false, true, false);
+        final Builder<String, CompletionLookupProvider> builder = ImmutableMap.builder();
+        providers = builder.put(provider.getName(), provider).build();
+    }
+
     public Completion090PostingsFormat(PostingsFormat delegatePostingsFormat, CompletionLookupProvider provider) {
         super(CODEC_NAME);
         this.delegatePostingsFormat = delegatePostingsFormat;
@@ -167,11 +173,11 @@ public class Completion090PostingsFormat extends PostingsFormat {
             try {
                 PostingsFormat delegatePostingsFormat = PostingsFormat.forName(input.readString());
                 String providerName = input.readString();
-                CompletionLookupProvider completionLookupProvider = PROVIDERS.get(providerName);
+                CompletionLookupProvider completionLookupProvider = providers.get(providerName);
                 if (completionLookupProvider == null) {
                     throw new IllegalStateException("no provider with name [" + providerName + "] registered");
                 }
-                // TODO: we could clone the ReadState and make it always forward IOContext.MERGE to prevent unecessary heap usage?
+                // TODO: we could clone the ReadState and make it always forward IOContext.MERGE to prevent unecessary heap usage? 
                 delegateProducer = delegatePostingsFormat.fieldsProducer(state);
                 /*
                  * If we are merging we don't load the FSTs at all such that we
diff --git a/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java b/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
index c709daa..c4f379b 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java
@@ -22,6 +22,7 @@ import com.carrotsearch.hppc.IntHashSet;
 import com.carrotsearch.hppc.IntSet;
 import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
+import com.google.common.collect.ImmutableMap;
 
 import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
@@ -54,7 +55,6 @@ import org.elasticsearch.cluster.settings.ClusterDynamicSettings;
 import org.elasticsearch.cluster.settings.DynamicSettings;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.inject.Inject;
@@ -232,11 +232,11 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
                     MetaData.Builder mdBuilder = MetaData.builder(currentState.metaData());
                     ClusterBlocks.Builder blocks = ClusterBlocks.builder().blocks(currentState.blocks());
                     RoutingTable.Builder rtBuilder = RoutingTable.builder(currentState.routingTable());
-                    ImmutableOpenMap<ShardId, RestoreInProgress.ShardRestoreStatus> shards;
+                    final ImmutableMap<ShardId, RestoreInProgress.ShardRestoreStatus> shards;
                     Set<String> aliases = new HashSet<>();
                     if (!renamedIndices.isEmpty()) {
                         // We have some indices to restore
-                        ImmutableOpenMap.Builder<ShardId, RestoreInProgress.ShardRestoreStatus> shardsBuilder = ImmutableOpenMap.builder();
+                        ImmutableMap.Builder<ShardId, RestoreInProgress.ShardRestoreStatus> shardsBuilder = ImmutableMap.builder();
                         for (Map.Entry<String, String> indexEntry : renamedIndices.entrySet()) {
                             String index = indexEntry.getValue();
                             boolean partial = checkPartial(index);
@@ -311,7 +311,7 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
                         RestoreInProgress.Entry restoreEntry = new RestoreInProgress.Entry(snapshotId, RestoreInProgress.State.INIT, Collections.unmodifiableList(new ArrayList<>(renamedIndices.keySet())), shards);
                         builder.putCustom(RestoreInProgress.TYPE, new RestoreInProgress(restoreEntry));
                     } else {
-                        shards = ImmutableOpenMap.of();
+                        shards = ImmutableMap.of();
                     }
 
                     checkAliasNameConflicts(renamedIndices, aliases);
@@ -325,9 +325,8 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
                                 shards.size(), shards.size() - failedShards(shards));
                     }
 
-                    RoutingTable rt = rtBuilder.build();
-                    ClusterState updatedState = builder.metaData(mdBuilder).blocks(blocks).routingTable(rt).build();
-                    RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(rt).build());
+                    ClusterState updatedState = builder.metaData(mdBuilder).blocks(blocks).routingTable(rtBuilder).build();
+                    RoutingAllocation.Result routingResult = allocationService.reroute(ClusterState.builder(updatedState).routingTable(rtBuilder).build());
                     return ClusterState.builder(updatedState).routingResult(routingResult).build();
                 }
 
@@ -532,7 +531,7 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
 
         clusterService.submitStateUpdateTask("update snapshot state", new ClusterStateUpdateTask() {
             private final List<UpdateIndexShardRestoreStatusRequest> drainedRequests = new ArrayList<>();
-            private Map<SnapshotId, Tuple<RestoreInfo, ImmutableOpenMap<ShardId, ShardRestoreStatus>>> batchedRestoreInfo = null;
+            private Map<SnapshotId, Tuple<RestoreInfo, Map<ShardId, ShardRestoreStatus>>> batchedRestoreInfo = null;
 
             @Override
             public ClusterState execute(ClusterState currentState) {
@@ -555,7 +554,7 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
                     int changedCount = 0;
                     final List<RestoreInProgress.Entry> entries = new ArrayList<>();
                     for (RestoreInProgress.Entry entry : restore.entries()) {
-                        ImmutableOpenMap.Builder<ShardId, ShardRestoreStatus> shardsBuilder = null;
+                        Map<ShardId, ShardRestoreStatus> shards = null;
 
                         for (int i = 0; i < batchSize; i++) {
                             final UpdateIndexShardRestoreStatusRequest updateSnapshotState = drainedRequests.get(i);
@@ -563,18 +562,17 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
 
                             if (entry.snapshotId().equals(updateSnapshotState.snapshotId())) {
                                 logger.trace("[{}] Updating shard [{}] with status [{}]", updateSnapshotState.snapshotId(), updateSnapshotState.shardId(), updateSnapshotState.status().state());
-                                if (shardsBuilder == null) {
-                                    shardsBuilder = ImmutableOpenMap.builder(entry.shards());
+                                if (shards == null) {
+                                    shards = new HashMap<>(entry.shards());
                                 }
-                                shardsBuilder.put(updateSnapshotState.shardId(), updateSnapshotState.status());
+                                shards.put(updateSnapshotState.shardId(), updateSnapshotState.status());
                                 changedCount++;
                             }
                         }
 
-                        if (shardsBuilder != null) {
-                            ImmutableOpenMap<ShardId, ShardRestoreStatus> shards = shardsBuilder.build();
+                        if (shards != null) {
                             if (!completed(shards)) {
-                                entries.add(new RestoreInProgress.Entry(entry.snapshotId(), RestoreInProgress.State.STARTED, entry.indices(), shards));
+                                entries.add(new RestoreInProgress.Entry(entry.snapshotId(), RestoreInProgress.State.STARTED, entry.indices(), ImmutableMap.copyOf(shards)));
                             } else {
                                 logger.info("restore [{}] is done", entry.snapshotId());
                                 if (batchedRestoreInfo == null) {
@@ -611,15 +609,15 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
             @Override
             public void clusterStateProcessed(String source, ClusterState oldState, ClusterState newState) {
                 if (batchedRestoreInfo != null) {
-                    for (final Entry<SnapshotId, Tuple<RestoreInfo, ImmutableOpenMap<ShardId, ShardRestoreStatus>>> entry : batchedRestoreInfo.entrySet()) {
+                    for (final Entry<SnapshotId, Tuple<RestoreInfo, Map<ShardId, ShardRestoreStatus>>> entry : batchedRestoreInfo.entrySet()) {
                         final SnapshotId snapshotId = entry.getKey();
                         final RestoreInfo restoreInfo = entry.getValue().v1();
-                        final ImmutableOpenMap<ShardId, ShardRestoreStatus> shards = entry.getValue().v2();
+                        final Map<ShardId, ShardRestoreStatus> shards = entry.getValue().v2();
                         RoutingTable routingTable = newState.getRoutingTable();
                         final List<ShardId> waitForStarted = new ArrayList<>();
-                        for (ObjectObjectCursor<ShardId, ShardRestoreStatus> shard : shards) {
-                            if (shard.value.state() == RestoreInProgress.State.SUCCESS ) {
-                                ShardId shardId = shard.key;
+                        for (Map.Entry<ShardId, ShardRestoreStatus> shard : shards.entrySet()) {
+                            if (shard.getValue().state() == RestoreInProgress.State.SUCCESS ) {
+                                ShardId shardId = shard.getKey();
                                 ShardRouting shardRouting = findPrimaryShard(routingTable, shardId);
                                 if (shardRouting != null && !shardRouting.active()) {
                                     logger.trace("[{}][{}] waiting for the shard to start", snapshotId, shardId);
@@ -679,19 +677,19 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
         });
     }
 
-    private boolean completed(ImmutableOpenMap<ShardId, RestoreInProgress.ShardRestoreStatus> shards) {
-        for (ObjectCursor<RestoreInProgress.ShardRestoreStatus> status : shards.values()) {
-            if (!status.value.state().completed()) {
+    private boolean completed(Map<ShardId, RestoreInProgress.ShardRestoreStatus> shards) {
+        for (RestoreInProgress.ShardRestoreStatus status : shards.values()) {
+            if (!status.state().completed()) {
                 return false;
             }
         }
         return true;
     }
 
-    private int failedShards(ImmutableOpenMap<ShardId, RestoreInProgress.ShardRestoreStatus> shards) {
+    private int failedShards(Map<ShardId, RestoreInProgress.ShardRestoreStatus> shards) {
         int failedShards = 0;
-        for (ObjectCursor<RestoreInProgress.ShardRestoreStatus> status : shards.values()) {
-            if (status.value.state() == RestoreInProgress.State.FAILURE) {
+        for (RestoreInProgress.ShardRestoreStatus status : shards.values()) {
+            if (status.state() == RestoreInProgress.State.FAILURE) {
                 failedShards++;
             }
         }
@@ -746,13 +744,13 @@ public class RestoreService extends AbstractComponent implements ClusterStateLis
             // Some indices were deleted, let's make sure all indices that we are restoring still exist
             for (RestoreInProgress.Entry entry : restore.entries()) {
                 List<ShardId> shardsToFail = null;
-                for (ObjectObjectCursor<ShardId, ShardRestoreStatus> shard : entry.shards()) {
-                    if (!shard.value.state().completed()) {
-                        if (!event.state().metaData().hasIndex(shard.key.getIndex())) {
+                for (ImmutableMap.Entry<ShardId, ShardRestoreStatus> shard : entry.shards().entrySet()) {
+                    if (!shard.getValue().state().completed()) {
+                        if (!event.state().metaData().hasIndex(shard.getKey().getIndex())) {
                             if (shardsToFail == null) {
                                 shardsToFail = new ArrayList<>();
                             }
-                            shardsToFail.add(shard.key);
+                            shardsToFail.add(shard.getKey());
                         }
                     }
                 }
diff --git a/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java b/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
index 91cf2af..c751895 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/SnapshotShardsService.java
@@ -19,8 +19,7 @@
 
 package org.elasticsearch.snapshots;
 
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.index.IndexCommit;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.cluster.ClusterChangedEvent;
@@ -31,7 +30,6 @@ import org.elasticsearch.cluster.ClusterStateUpdateTask;
 import org.elasticsearch.cluster.SnapshotsInProgress;
 import org.elasticsearch.cluster.metadata.SnapshotId;
 import org.elasticsearch.cluster.node.DiscoveryNode;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.io.stream.StreamInput;
@@ -69,8 +67,6 @@ import java.util.concurrent.locks.Condition;
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReentrantLock;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.cluster.SnapshotsInProgress.completed;
 
 /**
@@ -95,7 +91,7 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
 
     private final Condition shutdownCondition = shutdownLock.newCondition();
 
-    private volatile Map<SnapshotId, SnapshotShards> shardSnapshots = emptyMap();
+    private volatile Map<SnapshotId, SnapshotShards> shardSnapshots = ImmutableMap.of();
 
     private final BlockingQueue<UpdateIndexShardSnapshotStatusRequest> updatedSnapshotStateQueue = ConcurrentCollections.newBlockingQueue();
 
@@ -214,12 +210,12 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
                 if (entry.state() == SnapshotsInProgress.State.STARTED) {
                     Map<ShardId, IndexShardSnapshotStatus> startedShards = new HashMap<>();
                     SnapshotShards snapshotShards = shardSnapshots.get(entry.snapshotId());
-                    for (ObjectObjectCursor<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shard : entry.shards()) {
+                    for (Map.Entry<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shard : entry.shards().entrySet()) {
                         // Add all new shards to start processing on
-                        if (localNodeId.equals(shard.value.nodeId())) {
-                            if (shard.value.state() == SnapshotsInProgress.State.INIT && (snapshotShards == null || !snapshotShards.shards.containsKey(shard.key))) {
-                                logger.trace("[{}] - Adding shard to the queue", shard.key);
-                                startedShards.put(shard.key, new IndexShardSnapshotStatus());
+                        if (localNodeId.equals(shard.getValue().nodeId())) {
+                            if (shard.getValue().state() == SnapshotsInProgress.State.INIT && (snapshotShards == null || !snapshotShards.shards.containsKey(shard.getKey()))) {
+                                logger.trace("[{}] - Adding shard to the queue", shard.getKey());
+                                startedShards.put(shard.getKey(), new IndexShardSnapshotStatus());
                             }
                         }
                     }
@@ -227,23 +223,23 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
                         newSnapshots.put(entry.snapshotId(), startedShards);
                         if (snapshotShards != null) {
                             // We already saw this snapshot but we need to add more started shards
-                            Map<ShardId, IndexShardSnapshotStatus> shards = new HashMap<>();
+                            ImmutableMap.Builder<ShardId, IndexShardSnapshotStatus> shards = ImmutableMap.builder();
                             // Put all shards that were already running on this node
                             shards.putAll(snapshotShards.shards);
                             // Put all newly started shards
                             shards.putAll(startedShards);
-                            survivors.put(entry.snapshotId(), new SnapshotShards(unmodifiableMap(shards)));
+                            survivors.put(entry.snapshotId(), new SnapshotShards(shards.build()));
                         } else {
                             // Brand new snapshot that we haven't seen before
-                            survivors.put(entry.snapshotId(), new SnapshotShards(unmodifiableMap(startedShards)));
+                            survivors.put(entry.snapshotId(), new SnapshotShards(ImmutableMap.copyOf(startedShards)));
                         }
                     }
                 } else if (entry.state() == SnapshotsInProgress.State.ABORTED) {
                     // Abort all running shards for this snapshot
                     SnapshotShards snapshotShards = shardSnapshots.get(entry.snapshotId());
                     if (snapshotShards != null) {
-                        for (ObjectObjectCursor<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shard : entry.shards()) {
-                            IndexShardSnapshotStatus snapshotStatus = snapshotShards.shards.get(shard.key);
+                        for (Map.Entry<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shard : entry.shards().entrySet()) {
+                            IndexShardSnapshotStatus snapshotStatus = snapshotShards.shards.get(shard.getKey());
                             if (snapshotStatus != null) {
                                 switch (snapshotStatus.stage()) {
                                     case INIT:
@@ -251,16 +247,16 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
                                         snapshotStatus.abort();
                                         break;
                                     case FINALIZE:
-                                        logger.debug("[{}] trying to cancel snapshot on shard [{}] that is finalizing, letting it finish", entry.snapshotId(), shard.key);
+                                        logger.debug("[{}] trying to cancel snapshot on shard [{}] that is finalizing, letting it finish", entry.snapshotId(), shard.getKey());
                                         break;
                                     case DONE:
-                                        logger.debug("[{}] trying to cancel snapshot on the shard [{}] that is already done, updating status on the master", entry.snapshotId(), shard.key);
-                                        updateIndexShardSnapshotStatus(entry.snapshotId(), shard.key,
+                                        logger.debug("[{}] trying to cancel snapshot on the shard [{}] that is already done, updating status on the master", entry.snapshotId(), shard.getKey());
+                                        updateIndexShardSnapshotStatus(entry.snapshotId(), shard.getKey(),
                                                 new SnapshotsInProgress.ShardSnapshotStatus(event.state().nodes().localNodeId(), SnapshotsInProgress.State.SUCCESS));
                                         break;
                                     case FAILURE:
-                                        logger.debug("[{}] trying to cancel snapshot on the shard [{}] that has already failed, updating status on the master", entry.snapshotId(), shard.key);
-                                        updateIndexShardSnapshotStatus(entry.snapshotId(), shard.key,
+                                        logger.debug("[{}] trying to cancel snapshot on the shard [{}] that has already failed, updating status on the master", entry.snapshotId(), shard.getKey());
+                                        updateIndexShardSnapshotStatus(entry.snapshotId(), shard.getKey(),
                                                 new SnapshotsInProgress.ShardSnapshotStatus(event.state().nodes().localNodeId(), SnapshotsInProgress.State.FAILED, snapshotStatus.failure()));
                                         break;
                                     default:
@@ -277,7 +273,7 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
         // If startup of these shards fails later, we don't want to try starting these shards again
         shutdownLock.lock();
         try {
-            shardSnapshots = unmodifiableMap(survivors);
+            shardSnapshots = ImmutableMap.copyOf(survivors);
             if (shardSnapshots.isEmpty()) {
                 // Notify all waiting threads that no more snapshots
                 shutdownCondition.signalAll();
@@ -372,7 +368,7 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
             if (snapshot.state() == SnapshotsInProgress.State.STARTED || snapshot.state() == SnapshotsInProgress.State.ABORTED) {
                 Map<ShardId, IndexShardSnapshotStatus> localShards = currentSnapshotShards(snapshot.snapshotId());
                 if (localShards != null) {
-                    ImmutableOpenMap<ShardId, SnapshotsInProgress.ShardSnapshotStatus> masterShards = snapshot.shards();
+                    Map<ShardId, SnapshotsInProgress.ShardSnapshotStatus> masterShards = snapshot.shards();
                     for(Map.Entry<ShardId, IndexShardSnapshotStatus> localShard : localShards.entrySet()) {
                         ShardId shardId = localShard.getKey();
                         IndexShardSnapshotStatus localShardStatus = localShard.getValue();
@@ -404,7 +400,7 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
     private static class SnapshotShards {
         private final Map<ShardId, IndexShardSnapshotStatus> shards;
 
-        private SnapshotShards(Map<ShardId, IndexShardSnapshotStatus> shards) {
+        private SnapshotShards(ImmutableMap<ShardId, IndexShardSnapshotStatus> shards) {
             this.shards = shards;
         }
     }
@@ -522,7 +518,7 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
                     int changedCount = 0;
                     final List<SnapshotsInProgress.Entry> entries = new ArrayList<>();
                     for (SnapshotsInProgress.Entry entry : snapshots.entries()) {
-                        ImmutableOpenMap.Builder<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shards = ImmutableOpenMap.builder();
+                        final Map<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shards = new HashMap<>();
                         boolean updated = false;
 
                         for (int i = 0; i < batchSize; i++) {
@@ -542,11 +538,11 @@ public class SnapshotShardsService extends AbstractLifecycleComponent<SnapshotSh
 
                         if (updated) {
                             if (completed(shards.values()) == false) {
-                                entries.add(new SnapshotsInProgress.Entry(entry, shards.build()));
+                                entries.add(new SnapshotsInProgress.Entry(entry, ImmutableMap.copyOf(shards)));
                             } else {
                                 // Snapshot is finished - mark it as done
                                 // TODO: Add PARTIAL_SUCCESS status?
-                                SnapshotsInProgress.Entry updatedEntry = new SnapshotsInProgress.Entry(entry, SnapshotsInProgress.State.SUCCESS, shards.build());
+                                SnapshotsInProgress.Entry updatedEntry = new SnapshotsInProgress.Entry(entry, SnapshotsInProgress.State.SUCCESS, ImmutableMap.copyOf(shards));
                                 entries.add(updatedEntry);
                                 // Finalize snapshot in the repository
                                 snapshotsService.endSnapshot(updatedEntry);
diff --git a/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java b/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
index 0b4d041..d89d260 100644
--- a/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
+++ b/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java
@@ -19,26 +19,15 @@
 
 package org.elasticsearch.snapshots;
 
-import com.carrotsearch.hppc.cursors.ObjectCursor;
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.util.CollectionUtil;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.action.search.ShardSearchFailure;
 import org.elasticsearch.action.support.IndicesOptions;
-import org.elasticsearch.cluster.ClusterChangedEvent;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.ClusterStateListener;
-import org.elasticsearch.cluster.ClusterStateUpdateTask;
-import org.elasticsearch.cluster.SnapshotsInProgress;
+import org.elasticsearch.cluster.*;
 import org.elasticsearch.cluster.SnapshotsInProgress.ShardSnapshotStatus;
 import org.elasticsearch.cluster.SnapshotsInProgress.State;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.cluster.metadata.RepositoriesMetaData;
-import org.elasticsearch.cluster.metadata.SnapshotId;
+import org.elasticsearch.cluster.metadata.*;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
 import org.elasticsearch.cluster.routing.IndexRoutingTable;
@@ -46,7 +35,6 @@ import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
 import org.elasticsearch.cluster.routing.RoutingTable;
 import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.Inject;
@@ -62,18 +50,9 @@ import org.elasticsearch.search.SearchShardTarget;
 import org.elasticsearch.threadpool.ThreadPool;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.CopyOnWriteArrayList;
 
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.cluster.SnapshotsInProgress.completed;
 
 /**
@@ -247,7 +226,7 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
         }
         validate(new SnapshotId(request.repository(), request.name()));
     }
-
+    
     private static void validate(SnapshotId snapshotId) {
         String name = snapshotId.getSnapshot();
         if (!Strings.hasLength(name)) {
@@ -318,7 +297,7 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                     for (SnapshotsInProgress.Entry entry : snapshots.entries()) {
                         if (entry.snapshotId().equals(snapshot.snapshotId())) {
                             // Replace the snapshot that was just created
-                            ImmutableOpenMap<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shards = shards(currentState, entry.indices());
+                            ImmutableMap<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shards = shards(currentState, entry.indices());
                             if (!partial) {
                                 Tuple<Set<String>, Set<String>> indicesWithMissingShards = indicesWithMissingShards(shards, currentState.metaData());
                                 Set<String> missing = indicesWithMissingShards.v1();
@@ -468,9 +447,9 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
      * @param snapshotId snapshot id
      * @return map of shard id to snapshot status
      */
-    public Map<ShardId, IndexShardSnapshotStatus> snapshotShards(SnapshotId snapshotId) throws IOException {
+    public ImmutableMap<ShardId, IndexShardSnapshotStatus> snapshotShards(SnapshotId snapshotId) throws IOException {
         validate(snapshotId);
-        Map<ShardId, IndexShardSnapshotStatus> shardStatus = new HashMap<>();
+        ImmutableMap.Builder<ShardId, IndexShardSnapshotStatus> shardStatusBuilder = ImmutableMap.builder();
         Repository repository = repositoriesService.repository(snapshotId.getRepository());
         IndexShardRepository indexShardRepository = repositoriesService.indexShardRepository(snapshotId.getRepository());
         Snapshot snapshot = repository.readSnapshot(snapshotId);
@@ -486,15 +465,15 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                         IndexShardSnapshotStatus shardSnapshotStatus = new IndexShardSnapshotStatus();
                         shardSnapshotStatus.updateStage(IndexShardSnapshotStatus.Stage.FAILURE);
                         shardSnapshotStatus.failure(shardFailure.reason());
-                        shardStatus.put(shardId, shardSnapshotStatus);
+                        shardStatusBuilder.put(shardId, shardSnapshotStatus);
                     } else {
                         IndexShardSnapshotStatus shardSnapshotStatus = indexShardRepository.snapshotStatus(snapshotId, snapshot.version(), shardId);
-                        shardStatus.put(shardId, shardSnapshotStatus);
+                        shardStatusBuilder.put(shardId, shardSnapshotStatus);
                     }
                 }
             }
         }
-        return unmodifiableMap(shardStatus);
+        return shardStatusBuilder.build();
     }
 
 
@@ -546,23 +525,23 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                         SnapshotsInProgress.Entry updatedSnapshot = snapshot;
                         boolean snapshotChanged = false;
                         if (snapshot.state() == State.STARTED || snapshot.state() == State.ABORTED) {
-                            ImmutableOpenMap.Builder<ShardId, ShardSnapshotStatus> shards = ImmutableOpenMap.builder();
-                            for (ObjectObjectCursor<ShardId, ShardSnapshotStatus> shardEntry : snapshot.shards()) {
-                                ShardSnapshotStatus shardStatus = shardEntry.value;
+                            ImmutableMap.Builder<ShardId, ShardSnapshotStatus> shards = ImmutableMap.builder();
+                            for (ImmutableMap.Entry<ShardId, ShardSnapshotStatus> shardEntry : snapshot.shards().entrySet()) {
+                                ShardSnapshotStatus shardStatus = shardEntry.getValue();
                                 if (!shardStatus.state().completed() && shardStatus.nodeId() != null) {
                                     if (nodes.nodeExists(shardStatus.nodeId())) {
-                                        shards.put(shardEntry.key, shardEntry.value);
+                                        shards.put(shardEntry);
                                     } else {
                                         // TODO: Restart snapshot on another node?
                                         snapshotChanged = true;
-                                        logger.warn("failing snapshot of shard [{}] on closed node [{}]", shardEntry.key, shardStatus.nodeId());
-                                        shards.put(shardEntry.key, new ShardSnapshotStatus(shardStatus.nodeId(), State.FAILED, "node shutdown"));
+                                        logger.warn("failing snapshot of shard [{}] on closed node [{}]", shardEntry.getKey(), shardStatus.nodeId());
+                                        shards.put(shardEntry.getKey(), new ShardSnapshotStatus(shardStatus.nodeId(), State.FAILED, "node shutdown"));
                                     }
                                 }
                             }
                             if (snapshotChanged) {
                                 changed = true;
-                                ImmutableOpenMap<ShardId, ShardSnapshotStatus> shardsMap = shards.build();
+                                ImmutableMap<ShardId, ShardSnapshotStatus> shardsMap = shards.build();
                                 if (!snapshot.state().completed() && completed(shardsMap.values())) {
                                     updatedSnapshot = new SnapshotsInProgress.Entry(snapshot, State.SUCCESS, shardsMap);
                                     endSnapshot(updatedSnapshot);
@@ -617,7 +596,7 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                         for (final SnapshotsInProgress.Entry snapshot : snapshots.entries()) {
                             SnapshotsInProgress.Entry updatedSnapshot = snapshot;
                             if (snapshot.state() == State.STARTED) {
-                                ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards = processWaitingShards(snapshot.shards(), routingTable);
+                                Map<ShardId, ShardSnapshotStatus> shards = processWaitingShards(snapshot.shards(), routingTable);
                                 if (shards != null) {
                                     changed = true;
                                     if (!snapshot.state().completed() && completed(shards.values())) {
@@ -646,14 +625,13 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
         }
     }
 
-    private ImmutableOpenMap<ShardId, ShardSnapshotStatus> processWaitingShards(
-            ImmutableOpenMap<ShardId, ShardSnapshotStatus> snapshotShards, RoutingTable routingTable) {
+    private Map<ShardId, ShardSnapshotStatus> processWaitingShards(Map<ShardId, ShardSnapshotStatus> snapshotShards, RoutingTable routingTable) {
         boolean snapshotChanged = false;
-        ImmutableOpenMap.Builder<ShardId, ShardSnapshotStatus> shards = ImmutableOpenMap.builder();
-        for (ObjectObjectCursor<ShardId, ShardSnapshotStatus> shardEntry : snapshotShards) {
-            ShardSnapshotStatus shardStatus = shardEntry.value;
-            ShardId shardId = shardEntry.key;
+        ImmutableMap.Builder<ShardId, ShardSnapshotStatus> shards = ImmutableMap.builder();
+        for (ImmutableMap.Entry<ShardId, ShardSnapshotStatus> shardEntry : snapshotShards.entrySet()) {
+            ShardSnapshotStatus shardStatus = shardEntry.getValue();
             if (shardStatus.state() == State.WAITING) {
+                ShardId shardId = shardEntry.getKey();
                 IndexRoutingTable indexShardRoutingTable = routingTable.index(shardId.getIndex());
                 if (indexShardRoutingTable != null) {
                     IndexShardRoutingTable shardRouting = indexShardRoutingTable.shard(shardId.id());
@@ -661,22 +639,22 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                         if (shardRouting.primaryShard().started()) {
                             // Shard that we were waiting for has started on a node, let's process it
                             snapshotChanged = true;
-                            logger.trace("starting shard that we were waiting for [{}] on node [{}]", shardId, shardStatus.nodeId());
-                            shards.put(shardId, new ShardSnapshotStatus(shardRouting.primaryShard().currentNodeId()));
+                            logger.trace("starting shard that we were waiting for [{}] on node [{}]", shardEntry.getKey(), shardStatus.nodeId());
+                            shards.put(shardEntry.getKey(), new ShardSnapshotStatus(shardRouting.primaryShard().currentNodeId()));
                             continue;
                         } else if (shardRouting.primaryShard().initializing() || shardRouting.primaryShard().relocating()) {
                             // Shard that we were waiting for hasn't started yet or still relocating - will continue to wait
-                            shards.put(shardId, shardStatus);
+                            shards.put(shardEntry);
                             continue;
                         }
                     }
                 }
                 // Shard that we were waiting for went into unassigned state or disappeared - giving up
                 snapshotChanged = true;
-                logger.warn("failing snapshot of shard [{}] on unassigned shard [{}]", shardId, shardStatus.nodeId());
-                shards.put(shardId, new ShardSnapshotStatus(shardStatus.nodeId(), State.FAILED, "shard is unassigned"));
+                logger.warn("failing snapshot of shard [{}] on unassigned shard [{}]", shardEntry.getKey(), shardStatus.nodeId());
+                shards.put(shardEntry.getKey(), new ShardSnapshotStatus(shardStatus.nodeId(), State.FAILED, "shard is unassigned"));
             } else {
-                shards.put(shardId, shardStatus);
+                shards.put(shardEntry);
             }
         }
         if (snapshotChanged) {
@@ -691,10 +669,10 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
         if (curr != null) {
             for (SnapshotsInProgress.Entry entry : curr.entries()) {
                 if (entry.state() == State.STARTED && !entry.waitingIndices().isEmpty()) {
-                    for (ObjectCursor<String> index : entry.waitingIndices().keys()) {
-                        if (event.indexRoutingTableChanged(index.value)) {
-                            IndexRoutingTable indexShardRoutingTable = event.state().getRoutingTable().index(index.value);
-                            for (ShardId shardId : entry.waitingIndices().get(index.value)) {
+                    for (String index : entry.waitingIndices().keySet()) {
+                        if (event.indexRoutingTableChanged(index)) {
+                            IndexRoutingTable indexShardRoutingTable = event.state().getRoutingTable().index(index);
+                            for (ShardId shardId : entry.waitingIndices().get(index)) {
                                 ShardRouting shardRouting = indexShardRoutingTable.shard(shardId.id()).primaryShard();
                                 if (shardRouting != null && (shardRouting.started() || shardRouting.unassigned())) {
                                     return true;
@@ -721,8 +699,8 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                 return true;
             }
             for (DiscoveryNode node : event.nodesDelta().removedNodes()) {
-                for (ObjectCursor<ShardSnapshotStatus> shardStatus : snapshot.shards().values()) {
-                    if (!shardStatus.value.state().completed() && node.getId().equals(shardStatus.value.nodeId())) {
+                for (ShardSnapshotStatus shardStatus : snapshot.shards().values()) {
+                    if (!shardStatus.state().completed() && node.getId().equals(shardStatus.nodeId())) {
                         // At least one shard was running on the removed node - we need to fail it
                         return true;
                     }
@@ -738,15 +716,15 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
      * @param shards list of shard statuses
      * @return list of failed and closed indices
      */
-    private Tuple<Set<String>, Set<String>> indicesWithMissingShards(ImmutableOpenMap<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shards, MetaData metaData) {
+    private Tuple<Set<String>, Set<String>> indicesWithMissingShards(Map<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shards, MetaData metaData) {
         Set<String> missing = new HashSet<>();
         Set<String> closed = new HashSet<>();
-        for (ObjectObjectCursor<ShardId, SnapshotsInProgress.ShardSnapshotStatus> entry : shards) {
-            if (entry.value.state() == State.MISSING) {
-                if (metaData.hasIndex(entry.key.getIndex()) && metaData.index(entry.key.getIndex()).getState() == IndexMetaData.State.CLOSE) {
-                    closed.add(entry.key.getIndex());
+        for (Map.Entry<ShardId, SnapshotsInProgress.ShardSnapshotStatus> entry : shards.entrySet()) {
+            if (entry.getValue().state() == State.MISSING) {
+                if (metaData.hasIndex(entry.getKey().getIndex()) && metaData.index(entry.getKey().getIndex()).getState() == IndexMetaData.State.CLOSE) {
+                    closed.add(entry.getKey().getIndex());
                 } else {
-                    missing.add(entry.key.getIndex());
+                    missing.add(entry.getKey().getIndex());
                 }
             }
         }
@@ -783,9 +761,9 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                     logger.trace("[{}] finalizing snapshot in repository, state: [{}], failure[{}]", snapshotId, entry.state(), failure);
                     ArrayList<ShardSearchFailure> failures = new ArrayList<>();
                     ArrayList<SnapshotShardFailure> shardFailures = new ArrayList<>();
-                    for (ObjectObjectCursor<ShardId, ShardSnapshotStatus> shardStatus : entry.shards()) {
-                        ShardId shardId = shardStatus.key;
-                        ShardSnapshotStatus status = shardStatus.value;
+                    for (Map.Entry<ShardId, ShardSnapshotStatus> shardStatus : entry.shards().entrySet()) {
+                        ShardId shardId = shardStatus.getKey();
+                        ShardSnapshotStatus status = shardStatus.getValue();
                         if (status.state().failed()) {
                             failures.add(new ShardSearchFailure(status.reason(), new SearchShardTarget(status.nodeId(), shardId.getIndex(), shardId.id())));
                             shardFailures.add(new SnapshotShardFailure(status.nodeId(), shardId.getIndex(), shardId.id(), status.reason()));
@@ -886,16 +864,16 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                 } else {
                     // This snapshot is currently running - stopping shards first
                     waitForSnapshot = true;
-                    ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards;
+                    Map<ShardId, ShardSnapshotStatus> shards;
                     if (snapshot.state() == State.STARTED && snapshot.shards() != null) {
                         // snapshot is currently running - stop started shards
-                        ImmutableOpenMap.Builder<ShardId, ShardSnapshotStatus> shardsBuilder = ImmutableOpenMap.builder();
-                        for (ObjectObjectCursor<ShardId, ShardSnapshotStatus> shardEntry : snapshot.shards()) {
-                            ShardSnapshotStatus status = shardEntry.value;
+                        ImmutableMap.Builder<ShardId, ShardSnapshotStatus> shardsBuilder = ImmutableMap.builder();
+                        for (ImmutableMap.Entry<ShardId, ShardSnapshotStatus> shardEntry : snapshot.shards().entrySet()) {
+                            ShardSnapshotStatus status = shardEntry.getValue();
                             if (!status.state().completed()) {
-                                shardsBuilder.put(shardEntry.key, new ShardSnapshotStatus(status.nodeId(), State.ABORTED));
+                                shardsBuilder.put(shardEntry.getKey(), new ShardSnapshotStatus(status.nodeId(), State.ABORTED));
                             } else {
-                                shardsBuilder.put(shardEntry.key, status);
+                                shardsBuilder.put(shardEntry.getKey(), status);
                             }
                         }
                         shards = shardsBuilder.build();
@@ -906,10 +884,9 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
                     } else {
                         boolean hasUncompletedShards = false;
                         // Cleanup in case a node gone missing and snapshot wasn't updated for some reason
-                        for (ObjectCursor<ShardSnapshotStatus> shardStatus : snapshot.shards().values()) {
+                        for (ShardSnapshotStatus shardStatus : snapshot.shards().values()) {
                             // Check if we still have shard running on existing nodes
-                            if (shardStatus.value.state().completed() == false && shardStatus.value.nodeId() != null
-                                    && currentState.nodes().get(shardStatus.value.nodeId()) != null) {
+                            if (shardStatus.state().completed() == false && shardStatus.nodeId() != null && currentState.nodes().get(shardStatus.nodeId()) != null) {
                                 hasUncompletedShards = true;
                                 break;
                             }
@@ -1014,8 +991,8 @@ public class SnapshotsService extends AbstractLifecycleComponent<SnapshotsServic
      * @param indices      list of indices to be snapshotted
      * @return list of shard to be included into current snapshot
      */
-    private ImmutableOpenMap<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shards(ClusterState clusterState, List<String> indices) {
-        ImmutableOpenMap.Builder<ShardId, SnapshotsInProgress.ShardSnapshotStatus> builder = ImmutableOpenMap.builder();
+    private ImmutableMap<ShardId, SnapshotsInProgress.ShardSnapshotStatus> shards(ClusterState clusterState, List<String> indices) {
+        ImmutableMap.Builder<ShardId, SnapshotsInProgress.ShardSnapshotStatus> builder = ImmutableMap.builder();
         MetaData metaData = clusterState.metaData();
         for (String index : indices) {
             IndexMetaData indexMetaData = metaData.index(index);
diff --git a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java
index d20f600..85de5f6 100644
--- a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java
+++ b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.threadpool;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.util.Counter;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.component.AbstractComponent;
@@ -56,7 +57,7 @@ import java.util.concurrent.ThreadFactory;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 
-import static java.util.Collections.unmodifiableMap;
+import static org.elasticsearch.common.collect.MapBuilder.newMapBuilder;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.unit.SizeValue.parseSizeValue;
 import static org.elasticsearch.common.unit.TimeValue.timeValueMinutes;
@@ -88,7 +89,7 @@ public class ThreadPool extends AbstractComponent {
 
     public static final String THREADPOOL_GROUP = "threadpool.";
 
-    private volatile Map<String, ExecutorHolder> executors;
+    private volatile ImmutableMap<String, ExecutorHolder> executors;
 
     private final Map<String, Settings> defaultExecutorTypeSettings;
 
@@ -117,38 +118,26 @@ public class ThreadPool extends AbstractComponent {
         int availableProcessors = EsExecutors.boundedNumberOfProcessors(settings);
         int halfProcMaxAt5 = Math.min(((availableProcessors + 1) / 2), 5);
         int halfProcMaxAt10 = Math.min(((availableProcessors + 1) / 2), 10);
-        Map<String, Settings> defaultExecutorTypeSettings = new HashMap<>();
-        defaultExecutorTypeSettings.put(Names.GENERIC, settingsBuilder().put("type", "cached").put("keep_alive", "30s").build());
-        defaultExecutorTypeSettings.put(Names.INDEX,
-                settingsBuilder().put("type", "fixed").put("size", availableProcessors).put("queue_size", 200).build());
-        defaultExecutorTypeSettings.put(Names.BULK,
-                settingsBuilder().put("type", "fixed").put("size", availableProcessors).put("queue_size", 50).build());
-        defaultExecutorTypeSettings.put(Names.GET,
-                settingsBuilder().put("type", "fixed").put("size", availableProcessors).put("queue_size", 1000).build());
-        defaultExecutorTypeSettings.put(Names.SEARCH,
-                settingsBuilder().put("type", "fixed").put("size", ((availableProcessors * 3) / 2) + 1).put("queue_size", 1000).build());
-        defaultExecutorTypeSettings.put(Names.SUGGEST,
-                settingsBuilder().put("type", "fixed").put("size", availableProcessors).put("queue_size", 1000).build());
-        defaultExecutorTypeSettings.put(Names.PERCOLATE,
-                settingsBuilder().put("type", "fixed").put("size", availableProcessors).put("queue_size", 1000).build());
-        defaultExecutorTypeSettings  .put(Names.MANAGEMENT, settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", 5).build());
-        // no queue as this means clients will need to handle rejections on listener queue even if the operation succeeded
-        // the assumption here is that the listeners should be very lightweight on the listeners side
-        defaultExecutorTypeSettings.put(Names.LISTENER, settingsBuilder().put("type", "fixed").put("size", halfProcMaxAt10).build());
-        defaultExecutorTypeSettings.put(Names.FLUSH,
-                settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", halfProcMaxAt5).build());
-        defaultExecutorTypeSettings.put(Names.REFRESH,
-                settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", halfProcMaxAt10).build());
-        defaultExecutorTypeSettings.put(Names.WARMER,
-                settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", halfProcMaxAt5).build());
-        defaultExecutorTypeSettings.put(Names.SNAPSHOT,
-                settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", halfProcMaxAt5).build());
-        defaultExecutorTypeSettings.put(Names.OPTIMIZE, settingsBuilder().put("type", "fixed").put("size", 1).build());
-        defaultExecutorTypeSettings.put(Names.FETCH_SHARD_STARTED,
-                settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", availableProcessors * 2).build());
-        defaultExecutorTypeSettings.put(Names.FETCH_SHARD_STORE,
-                settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", availableProcessors * 2).build());
-        this.defaultExecutorTypeSettings = unmodifiableMap(defaultExecutorTypeSettings);
+        defaultExecutorTypeSettings = ImmutableMap.<String, Settings>builder()
+                .put(Names.GENERIC, settingsBuilder().put("type", "cached").put("keep_alive", "30s").build())
+                .put(Names.INDEX, settingsBuilder().put("type", "fixed").put("size", availableProcessors).put("queue_size", 200).build())
+                .put(Names.BULK, settingsBuilder().put("type", "fixed").put("size", availableProcessors).put("queue_size", 50).build())
+                .put(Names.GET, settingsBuilder().put("type", "fixed").put("size", availableProcessors).put("queue_size", 1000).build())
+                .put(Names.SEARCH, settingsBuilder().put("type", "fixed").put("size", ((availableProcessors * 3) / 2) + 1).put("queue_size", 1000).build())
+                .put(Names.SUGGEST, settingsBuilder().put("type", "fixed").put("size", availableProcessors).put("queue_size", 1000).build())
+                .put(Names.PERCOLATE, settingsBuilder().put("type", "fixed").put("size", availableProcessors).put("queue_size", 1000).build())
+                .put(Names.MANAGEMENT, settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", 5).build())
+                // no queue as this means clients will need to handle rejections on listener queue even if the operation succeeded
+                // the assumption here is that the listeners should be very lightweight on the listeners side
+                .put(Names.LISTENER, settingsBuilder().put("type", "fixed").put("size", halfProcMaxAt10).build())
+                .put(Names.FLUSH, settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", halfProcMaxAt5).build())
+                .put(Names.REFRESH, settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", halfProcMaxAt10).build())
+                .put(Names.WARMER, settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", halfProcMaxAt5).build())
+                .put(Names.SNAPSHOT, settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", halfProcMaxAt5).build())
+                .put(Names.OPTIMIZE, settingsBuilder().put("type", "fixed").put("size", 1).build())
+                .put(Names.FETCH_SHARD_STARTED, settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", availableProcessors * 2).build())
+                .put(Names.FETCH_SHARD_STORE, settingsBuilder().put("type", "scaling").put("keep_alive", "5m").put("size", availableProcessors * 2).build())
+                .build();
 
         Map<String, ExecutorHolder> executors = new HashMap<>();
         for (Map.Entry<String, Settings> executor : defaultExecutorTypeSettings.entrySet()) {
@@ -167,7 +156,7 @@ public class ThreadPool extends AbstractComponent {
         if (!executors.get(Names.GENERIC).info.getType().equals("cached")) {
             throw new IllegalArgumentException("generic thread pool must be of type cached");
         }
-        this.executors = unmodifiableMap(executors);
+        this.executors = ImmutableMap.copyOf(executors);
         this.scheduler = new ScheduledThreadPoolExecutor(1, EsExecutors.daemonThreadFactory(settings, "scheduler"), new EsAbortPolicy());
         this.scheduler.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);
         this.scheduler.setContinueExistingPeriodicTasksAfterShutdownPolicy(false);
@@ -457,9 +446,7 @@ public class ThreadPool extends AbstractComponent {
             ExecutorHolder oldExecutorHolder = executors.get(executor.getKey());
             ExecutorHolder newExecutorHolder = rebuild(executor.getKey(), oldExecutorHolder, updatedSettings, executor.getValue());
             if (!oldExecutorHolder.equals(newExecutorHolder)) {
-                Map<String, ExecutorHolder> newExecutors = new HashMap<>(executors);
-                newExecutors.put(executor.getKey(), newExecutorHolder);
-                executors = unmodifiableMap(newExecutors);
+                executors = newMapBuilder(executors).put(executor.getKey(), newExecutorHolder).immutableMap();
                 if (!oldExecutorHolder.executor().equals(newExecutorHolder.executor()) && oldExecutorHolder.executor() instanceof EsThreadPoolExecutor) {
                     retiredExecutors.add(oldExecutorHolder);
                     ((EsThreadPoolExecutor) oldExecutorHolder.executor()).shutdown(new ExecutorShutdownListener(oldExecutorHolder));
@@ -479,9 +466,7 @@ public class ThreadPool extends AbstractComponent {
             // case the settings contains a thread pool not defined in the initial settings in the constructor. The if
             // statement will then fail and so this prevents the addition of new thread groups at runtime, which is desired.
             if (!newExecutorHolder.equals(oldExecutorHolder)) {
-                Map<String, ExecutorHolder> newExecutors = new HashMap<>(executors);
-                newExecutors.put(entry.getKey(), newExecutorHolder);
-                executors = unmodifiableMap(newExecutors);
+                executors = newMapBuilder(executors).put(entry.getKey(), newExecutorHolder).immutableMap();
                 if (!oldExecutorHolder.executor().equals(newExecutorHolder.executor()) && oldExecutorHolder.executor() instanceof EsThreadPoolExecutor) {
                     retiredExecutors.add(oldExecutorHolder);
                     ((EsThreadPoolExecutor) oldExecutorHolder.executor()).shutdown(new ExecutorShutdownListener(oldExecutorHolder));
diff --git a/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java b/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java
index 853497d..5cf9ed3 100644
--- a/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java
+++ b/core/src/main/java/org/elasticsearch/transport/netty/NettyTransport.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.transport.netty;
 
+import java.nio.charset.StandardCharsets;
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.node.DiscoveryNode;
@@ -91,7 +93,6 @@ import java.net.InetSocketAddress;
 import java.net.SocketAddress;
 import java.net.UnknownHostException;
 import java.nio.channels.CancelledKeyException;
-import java.nio.charset.StandardCharsets;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
@@ -114,7 +115,6 @@ import java.util.concurrent.locks.ReentrantReadWriteLock;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.network.NetworkService.TcpSettings.TCP_BLOCKING;
 import static org.elasticsearch.common.network.NetworkService.TcpSettings.TCP_BLOCKING_CLIENT;
 import static org.elasticsearch.common.network.NetworkService.TcpSettings.TCP_BLOCKING_SERVER;
@@ -340,7 +340,7 @@ public class NettyTransport extends AbstractLifecycleComponent<Transport> implem
 
     @Override
     public Map<String, BoundTransportAddress> profileBoundAddresses() {
-        return unmodifiableMap(new HashMap<>(profileBoundAddresses));
+        return ImmutableMap.copyOf(profileBoundAddresses);
     }
 
     private InetSocketAddress createPublishAddress(String publishHost, int publishPort) {
@@ -453,7 +453,7 @@ public class NettyTransport extends AbstractLifecycleComponent<Transport> implem
             bindServerBootstrap(name, hostAddress, settings);
         }
     }
-
+        
     private void bindServerBootstrap(final String name, final InetAddress hostAddress, Settings profileSettings) {
 
         String port = profileSettings.get("port");
@@ -657,15 +657,15 @@ public class NettyTransport extends AbstractLifecycleComponent<Transport> implem
 
     @Override
     public TransportAddress[] addressesFromString(String address, int perAddressLimit) throws Exception {
-        return parse(address, settings.get("transport.profiles.default.port",
-                              settings.get("transport.netty.port",
-                              settings.get("transport.tcp.port",
+        return parse(address, settings.get("transport.profiles.default.port", 
+                              settings.get("transport.netty.port", 
+                              settings.get("transport.tcp.port", 
                               DEFAULT_PORT_RANGE))), perAddressLimit);
     }
-
+    
     // this code is a take on guava's HostAndPort, like a HostAndPortRange
-
-    // pattern for validating ipv6 bracked addresses.
+    
+    // pattern for validating ipv6 bracked addresses. 
     // not perfect, but PortsRange should take care of any port range validation, not a regex
     private static final Pattern BRACKET_PATTERN = Pattern.compile("^\\[(.*:.*)\\](?::([\\d\\-]*))?$");
 
@@ -698,12 +698,12 @@ public class NettyTransport extends AbstractLifecycleComponent<Transport> implem
             }
           }
         }
-
+        
         // if port isn't specified, fill with the default
         if (portString == null || portString.isEmpty()) {
             portString = defaultPortRange;
         }
-
+        
         // generate address for each port in the range
         Set<InetAddress> addresses = new HashSet<>(Arrays.asList(InetAddress.getAllByName(host)));
         List<TransportAddress> transportAddresses = new ArrayList<>();
diff --git a/core/src/main/java/org/elasticsearch/tribe/TribeService.java b/core/src/main/java/org/elasticsearch/tribe/TribeService.java
index 75b8176..36ea7fc 100644
--- a/core/src/main/java/org/elasticsearch/tribe/TribeService.java
+++ b/core/src/main/java/org/elasticsearch/tribe/TribeService.java
@@ -19,15 +19,10 @@
 
 package org.elasticsearch.tribe;
 
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.support.master.TransportMasterNodeReadAction;
-import org.elasticsearch.cluster.ClusterChangedEvent;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.ClusterStateListener;
-import org.elasticsearch.cluster.ClusterStateUpdateTask;
+import org.elasticsearch.cluster.*;
 import org.elasticsearch.cluster.block.ClusterBlock;
 import org.elasticsearch.cluster.block.ClusterBlockLevel;
 import org.elasticsearch.cluster.block.ClusterBlocks;
@@ -38,6 +33,7 @@ import org.elasticsearch.cluster.node.DiscoveryNodes;
 import org.elasticsearch.cluster.routing.IndexRoutingTable;
 import org.elasticsearch.cluster.routing.RoutingTable;
 import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.component.AbstractLifecycleComponent;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.regex.Regex;
@@ -50,15 +46,9 @@ import org.elasticsearch.node.NodeBuilder;
 import org.elasticsearch.node.internal.InternalSettingsPreparer;
 import org.elasticsearch.rest.RestStatus;
 
-import java.util.EnumSet;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.CopyOnWriteArrayList;
 
-import static java.util.Collections.unmodifiableMap;
-
 /**
  * The tribe service holds a list of node clients connected to a list of tribe members, and uses their
  * cluster state events to update this local node cluster state with the merged view of it.
@@ -244,12 +234,8 @@ public class TribeService extends AbstractLifecycleComponent<TribeService> {
                     for (DiscoveryNode tribe : tribeState.nodes()) {
                         if (currentState.nodes().get(tribe.id()) == null) {
                             // a new node, add it, but also add the tribe name to the attributes
-                            Map<String, String> tribeAttr = new HashMap<>();
-                            for (ObjectObjectCursor<String, String> attr : tribe.attributes()) {
-                                tribeAttr.put(attr.key, attr.value);
-                            }
-                            tribeAttr.put(TRIBE_NAME, tribeName);
-                            DiscoveryNode discoNode = new DiscoveryNode(tribe.name(), tribe.id(), tribe.getHostName(), tribe.getHostAddress(), tribe.address(), unmodifiableMap(tribeAttr), tribe.version());
+                            ImmutableMap<String, String> tribeAttr = MapBuilder.newMapBuilder(tribe.attributes()).put(TRIBE_NAME, tribeName).immutableMap();
+                            DiscoveryNode discoNode = new DiscoveryNode(tribe.name(), tribe.id(), tribe.getHostName(), tribe.getHostAddress(), tribe.address(), tribeAttr, tribe.version());
                             logger.info("[{}] adding node [{}]", tribeName, discoNode);
                             nodes.put(discoNode);
                         }
@@ -315,7 +301,7 @@ public class TribeService extends AbstractLifecycleComponent<TribeService> {
                         }
                     }
 
-                    return ClusterState.builder(currentState).incrementVersion().blocks(blocks).nodes(nodes).metaData(metaData).routingTable(routingTable.build()).build();
+                    return ClusterState.builder(currentState).incrementVersion().blocks(blocks).nodes(nodes).metaData(metaData).routingTable(routingTable).build();
                 }
 
                 private void removeIndex(ClusterBlocks.Builder blocks, MetaData.Builder metaData, RoutingTable.Builder routingTable, IndexMetaData index) {
diff --git a/core/src/test/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponsesTests.java b/core/src/test/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponsesTests.java
index 86ead20..d66c1bc 100644
--- a/core/src/test/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponsesTests.java
+++ b/core/src/test/java/org/elasticsearch/action/admin/cluster/health/ClusterHealthResponsesTests.java
@@ -21,18 +21,17 @@ package org.elasticsearch.action.admin.cluster.health;
 
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.Version;
+import org.elasticsearch.action.admin.cluster.health.ClusterHealthResponse;
+import org.elasticsearch.action.admin.cluster.health.ClusterHealthStatus;
+import org.elasticsearch.action.admin.cluster.health.ClusterIndexHealth;
+import org.elasticsearch.action.admin.cluster.health.ClusterShardHealth;
 import org.elasticsearch.action.support.IndicesOptions;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;
 import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.cluster.routing.IndexRoutingTable;
-import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
-import org.elasticsearch.cluster.routing.RoutingTable;
-import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.cluster.routing.ShardRoutingState;
-import org.elasticsearch.cluster.routing.TestShardRouting;
+import org.elasticsearch.cluster.routing.*;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.settings.Settings;
@@ -47,10 +46,7 @@ import java.io.IOException;
 
 import static org.hamcrest.CoreMatchers.allOf;
 import static org.hamcrest.CoreMatchers.equalTo;
-import static org.hamcrest.Matchers.empty;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.lessThanOrEqualTo;
+import static org.hamcrest.Matchers.*;
 
 public class ClusterHealthResponsesTests extends ESTestCase {
 
@@ -213,7 +209,7 @@ public class ClusterHealthResponsesTests extends ESTestCase {
             metaData.put(indexMetaData, true);
             routingTable.add(indexRoutingTable);
         }
-        ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable.build()).build();
+        ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();
         int pendingTasks = randomIntBetween(0, 200);
         int inFlight = randomIntBetween(0, 200);
         int delayedUnassigned = randomIntBetween(0, 200);
@@ -253,7 +249,7 @@ public class ClusterHealthResponsesTests extends ESTestCase {
         MetaData.Builder metaData = MetaData.builder();
         metaData.put(indexMetaData, true);
         routingTable.add(indexRoutingTable);
-        ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable.build()).build();
+        ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();
         ClusterHealthResponse clusterHealth = new ClusterHealthResponse("bla", indexNameExpressionResolver.concreteIndices(clusterState, IndicesOptions.strictExpand(), (String[]) null), clusterState, 0, 0, 0, TimeValue.timeValueMillis(0));
         clusterHealth = maybeSerialize(clusterHealth);
         // currently we have no cluster level validation failures as index validation issues are reported per index.
diff --git a/core/src/test/java/org/elasticsearch/action/support/replication/ClusterStateCreationUtils.java b/core/src/test/java/org/elasticsearch/action/support/replication/ClusterStateCreationUtils.java
index 100f68f..e5143a3 100644
--- a/core/src/test/java/org/elasticsearch/action/support/replication/ClusterStateCreationUtils.java
+++ b/core/src/test/java/org/elasticsearch/action/support/replication/ClusterStateCreationUtils.java
@@ -27,12 +27,7 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.IndexRoutingTable;
-import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
-import org.elasticsearch.cluster.routing.RoutingTable;
-import org.elasticsearch.cluster.routing.ShardRoutingState;
-import org.elasticsearch.cluster.routing.TestShardRouting;
-import org.elasticsearch.cluster.routing.UnassignedInfo;
+import org.elasticsearch.cluster.routing.*;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.DummyTransportAddress;
 import org.elasticsearch.index.shard.ShardId;
@@ -40,10 +35,8 @@ import org.elasticsearch.index.shard.ShardId;
 import java.util.HashSet;
 import java.util.Set;
 
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_CREATION_DATE;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_VERSION_CREATED;
+import static org.elasticsearch.cluster.metadata.IndexMetaData.*;
+import static org.elasticsearch.test.ESTestCase.randomBoolean;
 import static org.elasticsearch.test.ESTestCase.randomFrom;
 import static org.elasticsearch.test.ESTestCase.randomIntBetween;
 
@@ -131,7 +124,7 @@ public class ClusterStateCreationUtils {
         ClusterState.Builder state = ClusterState.builder(new ClusterName("test"));
         state.nodes(discoBuilder);
         state.metaData(MetaData.builder().put(indexMetaData, false).generateClusterUuidIfNeeded());
-        state.routingTable(RoutingTable.builder().add(IndexRoutingTable.builder(index).addIndexShard(indexShardRoutingBuilder.build())).build());
+        state.routingTable(RoutingTable.builder().add(IndexRoutingTable.builder(index).addIndexShard(indexShardRoutingBuilder.build())));
         return state.build();
     }
 
@@ -165,7 +158,7 @@ public class ClusterStateCreationUtils {
             indexShardRoutingBuilder.addShard(TestShardRouting.newShardRouting(index, i, newNode(1).id(), null, null, false, ShardRoutingState.STARTED, 0, null));
             indexRoutingTableBuilder.addIndexShard(indexShardRoutingBuilder.build());
         }
-        state.routingTable(RoutingTable.builder().add(indexRoutingTableBuilder.build()).build());
+        state.routingTable(RoutingTable.builder().add(indexRoutingTableBuilder));
         return state.build();
     }
 
@@ -221,7 +214,7 @@ public class ClusterStateCreationUtils {
         ClusterState.Builder state = ClusterState.builder(new ClusterName("test"));
         state.nodes(discoBuilder);
         state.metaData(MetaData.builder().generateClusterUuidIfNeeded());
-        state.routingTable(RoutingTable.builder().build());
+        state.routingTable(RoutingTable.builder());
         return state.build();
     }
 
diff --git a/core/src/test/java/org/elasticsearch/benchmark/cluster/ClusterAllocationRerouteBenchmark.java b/core/src/test/java/org/elasticsearch/benchmark/cluster/ClusterAllocationRerouteBenchmark.java
index 6b2608c..9ec74c9 100644
--- a/core/src/test/java/org/elasticsearch/benchmark/cluster/ClusterAllocationRerouteBenchmark.java
+++ b/core/src/test/java/org/elasticsearch/benchmark/cluster/ClusterAllocationRerouteBenchmark.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.benchmark.cluster;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -34,7 +35,6 @@ import org.elasticsearch.test.ESAllocationTestCase;
 
 import java.util.Random;
 
-import static java.util.Collections.singletonMap;
 import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
 
 public class ClusterAllocationRerouteBenchmark {
@@ -64,7 +64,7 @@ public class ClusterAllocationRerouteBenchmark {
         RoutingTable routingTable = rb.build();
         DiscoveryNodes.Builder nb = DiscoveryNodes.builder();
         for (int i = 1; i <= numberOfNodes; i++) {
-            nb.put(ESAllocationTestCase.newNode("node" + i, singletonMap("tag", "tag_" + (i % numberOfTags))));
+            nb.put(ESAllocationTestCase.newNode("node" + i, numberOfTags == 0 ? ImmutableMap.<String, String>of() : ImmutableMap.of("tag", "tag_" + (i % numberOfTags))));
         }
         ClusterState initialClusterState = ClusterState.builder(ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).nodes(nb).build();
 
diff --git a/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java b/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java
index b00b677..0cf16b4 100644
--- a/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java
+++ b/core/src/test/java/org/elasticsearch/client/AbstractClientHeadersTestCase.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.client;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.GenericAction;
@@ -137,9 +138,10 @@ public abstract class AbstractClientHeadersTestCase extends ESTestCase {
     @Test
     public void testOverideHeader() throws Exception {
         String key1Val = randomAsciiOfLength(5);
-        Map<String, Object> expected = new HashMap<>();
-        expected.put("key1", key1Val);
-        expected.put("key2", "val 2");
+        Map<String, Object> expected = ImmutableMap.<String, Object>builder()
+                .put("key1", key1Val)
+                .put("key2", "val 2")
+                .build();
 
         client.prepareGet("idx", "type", "id")
                 .putHeader("key1", key1Val)
diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
index f938a78..f672b26 100644
--- a/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterInfoServiceIT.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.cluster;
 
-import com.carrotsearch.hppc.cursors.ObjectCursor;
-
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.ActionModule;
@@ -36,7 +34,6 @@ import org.elasticsearch.cluster.routing.RoutingNodes;
 import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.allocation.decider.EnableAllocationDecider;
 import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.IndexService;
@@ -56,6 +53,7 @@ import org.junit.Test;
 
 import java.io.IOException;
 import java.util.Collection;
+import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.atomic.AtomicBoolean;
@@ -151,24 +149,24 @@ public class ClusterInfoServiceIT extends ESIntegTestCase {
         final InternalClusterInfoService infoService = (InternalClusterInfoService) internalTestCluster.getInstance(ClusterInfoService.class, internalTestCluster.getMasterName());
         ClusterInfo info = infoService.refresh();
         assertNotNull("info should not be null", info);
-        ImmutableOpenMap<String, DiskUsage> leastUsages = info.getNodeLeastAvailableDiskUsages();
-        ImmutableOpenMap<String, DiskUsage> mostUsages = info.getNodeMostAvailableDiskUsages();
-        ImmutableOpenMap<String, Long> shardSizes = info.shardSizes;
+        final Map<String, DiskUsage> leastUsages = info.getNodeLeastAvailableDiskUsages();
+        final Map<String, DiskUsage> mostUsages = info.getNodeMostAvailableDiskUsages();
+        final Map<String, Long> shardSizes = info.shardSizes;
         assertNotNull(leastUsages);
         assertNotNull(shardSizes);
         assertThat("some usages are populated", leastUsages.values().size(), Matchers.equalTo(2));
         assertThat("some shard sizes are populated", shardSizes.values().size(), greaterThan(0));
-        for (ObjectCursor<DiskUsage> usage : leastUsages.values()) {
-            logger.info("--> usage: {}", usage.value);
-            assertThat("usage has be retrieved", usage.value.getFreeBytes(), greaterThan(0L));
+        for (DiskUsage usage : leastUsages.values()) {
+            logger.info("--> usage: {}", usage);
+            assertThat("usage has be retrieved", usage.getFreeBytes(), greaterThan(0L));
         }
-        for (ObjectCursor<DiskUsage> usage : mostUsages.values()) {
-            logger.info("--> usage: {}", usage.value);
-            assertThat("usage has be retrieved", usage.value.getFreeBytes(), greaterThan(0L));
+        for (DiskUsage usage : mostUsages.values()) {
+            logger.info("--> usage: {}", usage);
+            assertThat("usage has be retrieved", usage.getFreeBytes(), greaterThan(0L));
         }
-        for (ObjectCursor<Long> size : shardSizes.values()) {
-            logger.info("--> shard size: {}", size.value);
-            assertThat("shard size is greater than 0", size.value, greaterThanOrEqualTo(0L));
+        for (Long size : shardSizes.values()) {
+            logger.info("--> shard size: {}", size);
+            assertThat("shard size is greater than 0", size, greaterThanOrEqualTo(0L));
         }
         ClusterService clusterService = internalTestCluster.getInstance(ClusterService.class, internalTestCluster.getMasterName());
         ClusterState state = clusterService.state();
diff --git a/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java b/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java
index ac2182c..1aa1602 100644
--- a/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java
+++ b/core/src/test/java/org/elasticsearch/cluster/ClusterStateDiffIT.java
@@ -20,25 +20,14 @@
 package org.elasticsearch.cluster;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.block.ClusterBlock;
 import org.elasticsearch.cluster.block.ClusterBlocks;
-import org.elasticsearch.cluster.metadata.AliasMetaData;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.cluster.metadata.IndexTemplateMetaData;
-import org.elasticsearch.cluster.metadata.MetaData;
-import org.elasticsearch.cluster.metadata.RepositoriesMetaData;
-import org.elasticsearch.cluster.metadata.SnapshotId;
+import org.elasticsearch.cluster.metadata.*;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.IndexRoutingTable;
-import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
-import org.elasticsearch.cluster.routing.RoutingTable;
-import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.cluster.routing.ShardRoutingState;
-import org.elasticsearch.cluster.routing.TestShardRouting;
-import org.elasticsearch.cluster.routing.UnassignedInfo;
+import org.elasticsearch.cluster.routing.*;
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.bytes.BytesArray;
 import org.elasticsearch.common.collect.ImmutableOpenMap;
@@ -57,13 +46,12 @@ import org.junit.Test;
 import java.util.Collections;
 import java.util.List;
 
-import static java.util.Collections.emptyList;
 import static org.elasticsearch.cluster.metadata.AliasMetaData.newAliasMetaDataBuilder;
 import static org.elasticsearch.cluster.routing.RandomShardRoutingMutator.randomChange;
 import static org.elasticsearch.cluster.routing.RandomShardRoutingMutator.randomReason;
-import static org.elasticsearch.test.VersionUtils.randomVersion;
 import static org.elasticsearch.test.XContentTestUtils.convertToMap;
 import static org.elasticsearch.test.XContentTestUtils.differenceBetweenMapsIgnoringArrayOrder;
+import static org.elasticsearch.test.VersionUtils.randomVersion;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.is;
 
@@ -209,7 +197,7 @@ public class ClusterStateDiffIT extends ESIntegTestCase {
         RoutingTable.Builder builder = RoutingTable.builder(clusterState.routingTable());
         int numberOfIndices = clusterState.routingTable().indicesRouting().size();
         if (numberOfIndices > 0) {
-            List<String> randomIndices = randomSubsetOf(randomInt(numberOfIndices - 1), clusterState.routingTable().indicesRouting().keys().toArray(String.class));
+            List<String> randomIndices = randomSubsetOf(randomInt(numberOfIndices - 1), clusterState.routingTable().indicesRouting().keySet().toArray(new String[numberOfIndices]));
             for (String index : randomIndices) {
                 if (randomBoolean()) {
                     builder.remove(index);
@@ -673,13 +661,13 @@ public class ClusterStateDiffIT extends ESIntegTestCase {
                                 SnapshotsInProgress.State.fromValue((byte) randomIntBetween(0, 6)),
                                 Collections.<String>emptyList(),
                                 Math.abs(randomLong()),
-                                ImmutableOpenMap.of()));
+                                ImmutableMap.<ShardId, SnapshotsInProgress.ShardSnapshotStatus>of()));
                     case 1:
                         return new RestoreInProgress(new RestoreInProgress.Entry(
                                 new SnapshotId(randomName("repo"), randomName("snap")),
                                 RestoreInProgress.State.fromValue((byte) randomIntBetween(0, 3)),
-                                emptyList(),
-                                ImmutableOpenMap.of()));
+                                Collections.<String>emptyList(),
+                                ImmutableMap.<ShardId, RestoreInProgress.ShardRestoreStatus>of()));
                     default:
                         throw new IllegalArgumentException("Shouldn't be here");
                 }
diff --git a/core/src/test/java/org/elasticsearch/cluster/DiskUsageTests.java b/core/src/test/java/org/elasticsearch/cluster/DiskUsageTests.java
index 595dbc9..a427829 100644
--- a/core/src/test/java/org/elasticsearch/cluster/DiskUsageTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/DiskUsageTests.java
@@ -21,13 +21,13 @@ package org.elasticsearch.cluster;
 
 import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.cluster.node.stats.NodeStats;
+import org.elasticsearch.action.admin.cluster.node.stats.NodesStatsResponse;
 import org.elasticsearch.action.admin.indices.stats.CommonStats;
 import org.elasticsearch.action.admin.indices.stats.ShardStats;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.ShardRoutingHelper;
 import org.elasticsearch.cluster.routing.UnassignedInfo;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.transport.DummyTransportAddress;
 import org.elasticsearch.index.shard.ShardPath;
 import org.elasticsearch.index.store.StoreStats;
@@ -36,6 +36,8 @@ import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
 import java.nio.file.Path;
+import java.util.HashMap;
+import java.util.Map;
 
 import static org.hamcrest.Matchers.equalTo;
 
@@ -93,7 +95,7 @@ public class DiskUsageTests extends ESTestCase {
             }
         }
     }
-
+    
     public void testFillShardLevelInfo() {
         ShardRouting test_0 = ShardRouting.newUnassigned("test", 0, null, false, new UnassignedInfo(UnassignedInfo.Reason.INDEX_CREATED, "foo"));
         ShardRoutingHelper.initialize(test_0, "node1");
@@ -111,8 +113,8 @@ public class DiskUsageTests extends ESTestCase {
                 new ShardStats(test_0, new ShardPath(false, test0Path, test0Path, "0xdeadbeef", test_0.shardId()), commonStats0 , null),
                 new ShardStats(test_1, new ShardPath(false, test1Path, test1Path, "0xdeadbeef", test_1.shardId()), commonStats1 , null)
         };
-        ImmutableOpenMap.Builder<String, Long> shardSizes = ImmutableOpenMap.builder();
-        ImmutableOpenMap.Builder<ShardRouting, String> routingToPath = ImmutableOpenMap.builder();
+        HashMap<String, Long> shardSizes = new HashMap<>();
+        HashMap<ShardRouting, String> routingToPath = new HashMap<>();
         InternalClusterInfoService.buildShardLevelInfo(logger, stats, shardSizes, routingToPath);
         assertEquals(2, shardSizes.size());
         assertTrue(shardSizes.containsKey(ClusterInfo.shardIdentifierFromRouting(test_0)));
@@ -128,8 +130,8 @@ public class DiskUsageTests extends ESTestCase {
     }
 
     public void testFillDiskUsage() {
-        ImmutableOpenMap.Builder<String, DiskUsage> newLeastAvaiableUsages = ImmutableOpenMap.builder();
-        ImmutableOpenMap.Builder<String, DiskUsage> newMostAvaiableUsages = ImmutableOpenMap.builder();
+        Map<String, DiskUsage> newLeastAvaiableUsages = new HashMap<>();
+        Map<String, DiskUsage> newMostAvaiableUsages = new HashMap<>();
         FsInfo.Path[] node1FSInfo =  new FsInfo.Path[] {
                 new FsInfo.Path("/middle", "/dev/sda", 100, 90, 80),
                 new FsInfo.Path("/least", "/dev/sdb", 200, 190, 70),
diff --git a/core/src/test/java/org/elasticsearch/cluster/MockInternalClusterInfoService.java b/core/src/test/java/org/elasticsearch/cluster/MockInternalClusterInfoService.java
index dd1cb0b..eff22c8 100644
--- a/core/src/test/java/org/elasticsearch/cluster/MockInternalClusterInfoService.java
+++ b/core/src/test/java/org/elasticsearch/cluster/MockInternalClusterInfoService.java
@@ -27,7 +27,6 @@ import org.elasticsearch.action.admin.indices.stats.IndicesStatsResponse;
 import org.elasticsearch.action.admin.indices.stats.TransportIndicesStatsAction;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.DummyTransportAddress;
@@ -36,6 +35,10 @@ import org.elasticsearch.node.settings.NodeSettingsService;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.threadpool.ThreadPool;
 
+import java.util.AbstractMap;
+import java.util.Collections;
+import java.util.Map;
+import java.util.Set;
 import java.util.concurrent.CountDownLatch;
 
 /**
@@ -113,24 +116,30 @@ public class MockInternalClusterInfoService extends InternalClusterInfoService {
         return new CountDownLatch(0);
     }
 
-    @Override
     public ClusterInfo getClusterInfo() {
         ClusterInfo clusterInfo = super.getClusterInfo();
-        return new DevNullClusterInfo(clusterInfo.getNodeLeastAvailableDiskUsages(), clusterInfo.getNodeMostAvailableDiskUsages(), clusterInfo.shardSizes);
+        return new ClusterInfo(clusterInfo.getNodeLeastAvailableDiskUsages(), clusterInfo.getNodeMostAvailableDiskUsages(), clusterInfo.shardSizes, DEV_NULL_MAP);
     }
 
-    /**
-     * ClusterInfo that always points to DevNull.
-     */
-    public static class DevNullClusterInfo extends ClusterInfo {
-        public DevNullClusterInfo(ImmutableOpenMap<String, DiskUsage> leastAvailableSpaceUsage,
-            ImmutableOpenMap<String, DiskUsage> mostAvailableSpaceUsage, ImmutableOpenMap<String, Long> shardSizes) {
-            super(leastAvailableSpaceUsage, mostAvailableSpaceUsage, shardSizes, null);
+    public static final Map<ShardRouting, String> DEV_NULL_MAP = Collections.unmodifiableMap(new StaticValueMap("/dev/null"));
+
+    // a test only map that always returns the same value no matter what key is passed
+    private static final class StaticValueMap extends AbstractMap<ShardRouting, String> {
+
+        private final String value;
+
+        private StaticValueMap(String value) {
+            this.value = value;
+        }
+
+        @Override
+        public String get(Object key) {
+            return value;
         }
 
         @Override
-        public String getDataPath(ShardRouting shardRouting) {
-            return "/dev/null";
+        public Set<Entry<ShardRouting, String>> entrySet() {
+            throw new UnsupportedOperationException("this is a test-only map that only supports #get(Object key)");
         }
     }
 }
diff --git a/core/src/test/java/org/elasticsearch/cluster/node/DiscoveryNodeFiltersTests.java b/core/src/test/java/org/elasticsearch/cluster/node/DiscoveryNodeFiltersTests.java
index 2136d1e..b37495e 100644
--- a/core/src/test/java/org/elasticsearch/cluster/node/DiscoveryNodeFiltersTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/node/DiscoveryNodeFiltersTests.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.cluster.node;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.DummyTransportAddress;
@@ -32,12 +33,8 @@ import java.net.InetAddress;
 import java.net.UnknownHostException;
 import java.util.ArrayList;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.List;
-import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.singletonMap;
 import static org.elasticsearch.cluster.node.DiscoveryNodeFilters.OpType.AND;
 import static org.elasticsearch.cluster.node.DiscoveryNodeFilters.OpType.OR;
 import static org.hamcrest.Matchers.equalTo;
@@ -65,10 +62,10 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build();
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT);
+        DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
         assertThat(filters.match(node), equalTo(true));
 
-        node = new DiscoveryNode("name2", "id2", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT);
+        node = new DiscoveryNode("name2", "id2", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
         assertThat(filters.match(node), equalTo(false));
     }
 
@@ -79,10 +76,10 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build();
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT);
+        DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
         assertThat(filters.match(node), equalTo(true));
 
-        node = new DiscoveryNode("name2", "id2", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT);
+        node = new DiscoveryNode("name2", "id2", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
         assertThat(filters.match(node), equalTo(false));
     }
 
@@ -94,13 +91,13 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT);
+        DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
         assertThat(filters.match(node), equalTo(true));
 
-        node = new DiscoveryNode("name2", "id2", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT);
+        node = new DiscoveryNode("name2", "id2", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
         assertThat(filters.match(node), equalTo(true));
 
-        node = new DiscoveryNode("name3", "id3", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT);
+        node = new DiscoveryNode("name3", "id3", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
         assertThat(filters.match(node), equalTo(false));
     }
 
@@ -112,30 +109,19 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
 
-        Map<String, String> attributes = new HashMap<>();
-        attributes.put("tag", "A");
-        attributes.put("group", "B");
         DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE,
-                attributes, Version.CURRENT);
+                ImmutableMap.of("tag", "A", "group", "B"), Version.CURRENT);
         assertThat(filters.match(node), equalTo(true));
 
-        attributes = new HashMap<>();
-        attributes.put("tag", "A");
-        attributes.put("group", "B");
-        attributes.put("name", "X");
         node = new DiscoveryNode("name2", "id2", DummyTransportAddress.INSTANCE,
-                attributes, Version.CURRENT);
+                ImmutableMap.of("tag", "A", "group", "B", "name", "X"), Version.CURRENT);
         assertThat(filters.match(node), equalTo(true));
 
-        attributes = new HashMap<>();
-        attributes.put("tag", "A");
-        attributes.put("group", "F");
-        attributes.put("name", "X");
         node = new DiscoveryNode("name3", "id3", DummyTransportAddress.INSTANCE,
-                attributes, Version.CURRENT);
+                ImmutableMap.of("tag", "A", "group", "F", "name", "X"), Version.CURRENT);
         assertThat(filters.match(node), equalTo(false));
 
-        node = new DiscoveryNode("name4", "id4", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT);
+        node = new DiscoveryNode("name4", "id4", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
         assertThat(filters.match(node), equalTo(false));
     }
 
@@ -146,7 +132,7 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build();
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT);
+        DiscoveryNode node = new DiscoveryNode("name1", "id1", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT);
         assertThat(filters.match(node), equalTo(true));
     }
 
@@ -158,7 +144,7 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, singletonMap("tag", "A"), null);
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
         assertThat(filters.match(node), equalTo(true));
     }
 
@@ -170,7 +156,7 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, singletonMap("tag", "A"), null);
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
         assertThat(filters.match(node), equalTo(false));
     }
 
@@ -182,7 +168,7 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, singletonMap("tag", "A"), null);
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
         assertThat(filters.match(node), equalTo(false));
     }
 
@@ -194,7 +180,7 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, singletonMap("tag", "A"), null);
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
         assertThat(filters.match(node), equalTo(true));
     }
 
@@ -206,7 +192,7 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, singletonMap("tag", "A"), null);
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
         assertThat(filters.match(node), equalTo(true));
     }
 
@@ -218,7 +204,7 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, singletonMap("tag", "A"), null);
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
         assertThat(filters.match(node), equalTo(true));
     }
 
@@ -230,7 +216,7 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(AND, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, singletonMap("tag", "A"), null);
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
         assertThat(filters.match(node), equalTo(false));
     }
 
@@ -242,7 +228,7 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, singletonMap("tag", "A"), null);
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
         assertThat(filters.match(node), equalTo(true));
     }
 
@@ -254,7 +240,7 @@ public class DiscoveryNodeFiltersTests extends ESTestCase {
                 .build());
         DiscoveryNodeFilters filters = DiscoveryNodeFilters.buildFromSettings(OR, "xxx.", settings);
 
-        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, singletonMap("tag", "A"), null);
+        DiscoveryNode node = new DiscoveryNode("", "", "", "192.1.1.54", localAddress, ImmutableMap.of("tag", "A"), null);
         assertThat(filters.match(node), equalTo(true));
     }
 
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/RoutingServiceTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/RoutingServiceTests.java
index 9309fa7..c2ba1cb 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/RoutingServiceTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/RoutingServiceTests.java
@@ -36,6 +36,8 @@ import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
+import java.util.Collections;
+import java.util.Comparator;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicBoolean;
 
@@ -74,7 +76,7 @@ public class RoutingServiceTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test")).build()).build();
+                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test"))).build();
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode("node1")).put(newNode("node2")).localNodeId("node1").masterNodeId("node1")).build();
         clusterState = ClusterState.builder(clusterState).routingResult(allocation.reroute(clusterState)).build();
         // starting primaries
@@ -104,7 +106,7 @@ public class RoutingServiceTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test")).build()).build();
+                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test"))).build();
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode("node1")).put(newNode("node2")).localNodeId("node1").masterNodeId("node1")).build();
         clusterState = ClusterState.builder(clusterState).routingResult(allocation.reroute(clusterState)).build();
         // starting primaries
@@ -151,7 +153,7 @@ public class RoutingServiceTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test")).build()).build();
+                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test"))).build();
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode("node1")).put(newNode("node2")).localNodeId("node1").masterNodeId("node1")).build();
         clusterState = ClusterState.builder(clusterState).routingResult(allocation.reroute(clusterState)).build();
         // starting primaries
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/UnassignedInfoTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/UnassignedInfoTests.java
index fc7ce64..fdc1c52 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/UnassignedInfoTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/UnassignedInfoTests.java
@@ -21,7 +21,6 @@ package org.elasticsearch.cluster.routing;
 
 import com.carrotsearch.hppc.IntHashSet;
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.cluster.ClusterState;
@@ -41,15 +40,8 @@ import org.junit.Test;
 import java.util.Collections;
 import java.util.EnumSet;
 
-import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.STARTED;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.UNASSIGNED;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.lessThan;
-import static org.hamcrest.Matchers.lessThanOrEqualTo;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.elasticsearch.cluster.routing.ShardRoutingState.*;
+import static org.hamcrest.Matchers.*;
 
 /**
  */
@@ -97,7 +89,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test")).build()).build();
+                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test"))).build();
         for (ShardRouting shard : clusterState.getRoutingNodes().shardsWithState(UNASSIGNED)) {
             assertThat(shard.unassignedInfo().getReason(), equalTo(UnassignedInfo.Reason.INDEX_CREATED));
         }
@@ -110,7 +102,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsRecovery(metaData.index("test")).build()).build();
+                .routingTable(RoutingTable.builder().addAsRecovery(metaData.index("test"))).build();
         for (ShardRouting shard : clusterState.getRoutingNodes().shardsWithState(UNASSIGNED)) {
             assertThat(shard.unassignedInfo().getReason(), equalTo(UnassignedInfo.Reason.CLUSTER_RECOVERED));
         }
@@ -123,7 +115,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsFromCloseToOpen(metaData.index("test")).build()).build();
+                .routingTable(RoutingTable.builder().addAsFromCloseToOpen(metaData.index("test"))).build();
         for (ShardRouting shard : clusterState.getRoutingNodes().shardsWithState(UNASSIGNED)) {
             assertThat(shard.unassignedInfo().getReason(), equalTo(UnassignedInfo.Reason.INDEX_REOPENED));
         }
@@ -136,7 +128,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsNewRestore(metaData.index("test"), new RestoreSource(new SnapshotId("rep1", "snp1"), Version.CURRENT, "test"), new IntHashSet()).build()).build();
+                .routingTable(RoutingTable.builder().addAsNewRestore(metaData.index("test"), new RestoreSource(new SnapshotId("rep1", "snp1"), Version.CURRENT, "test"), new IntHashSet())).build();
         for (ShardRouting shard : clusterState.getRoutingNodes().shardsWithState(UNASSIGNED)) {
             assertThat(shard.unassignedInfo().getReason(), equalTo(UnassignedInfo.Reason.NEW_INDEX_RESTORED));
         }
@@ -149,7 +141,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsRestore(metaData.index("test"), new RestoreSource(new SnapshotId("rep1", "snp1"), Version.CURRENT, "test")).build()).build();
+                .routingTable(RoutingTable.builder().addAsRestore(metaData.index("test"), new RestoreSource(new SnapshotId("rep1", "snp1"), Version.CURRENT, "test"))).build();
         for (ShardRouting shard : clusterState.getRoutingNodes().shardsWithState(UNASSIGNED)) {
             assertThat(shard.unassignedInfo().getReason(), equalTo(UnassignedInfo.Reason.EXISTING_INDEX_RESTORED));
         }
@@ -162,7 +154,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsFromDangling(metaData.index("test")).build()).build();
+                .routingTable(RoutingTable.builder().addAsFromDangling(metaData.index("test"))).build();
         for (ShardRouting shard : clusterState.getRoutingNodes().shardsWithState(UNASSIGNED)) {
             assertThat(shard.unassignedInfo().getReason(), equalTo(UnassignedInfo.Reason.DANGLING_INDEX_IMPORTED));
         }
@@ -176,7 +168,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test")).build()).build();
+                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test"))).build();
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode("node1"))).build();
         clusterState = ClusterState.builder(clusterState).routingResult(allocation.reroute(clusterState)).build();
         // starting primaries
@@ -186,7 +178,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
             builder.addIndexShard(indexShardRoutingTable);
         }
         builder.addReplica();
-        clusterState = ClusterState.builder(clusterState).routingTable(RoutingTable.builder(clusterState.routingTable()).add(builder).build()).build();
+        clusterState = ClusterState.builder(clusterState).routingTable(RoutingTable.builder(clusterState.routingTable()).add(builder)).build();
         assertThat(clusterState.getRoutingNodes().shardsWithState(UNASSIGNED).size(), equalTo(1));
         assertThat(clusterState.getRoutingNodes().shardsWithState(UNASSIGNED).get(0).unassignedInfo(), notNullValue());
         assertThat(clusterState.getRoutingNodes().shardsWithState(UNASSIGNED).get(0).unassignedInfo().getReason(), equalTo(UnassignedInfo.Reason.REPLICA_ADDED));
@@ -219,7 +211,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test")).build()).build();
+                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test"))).build();
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode("node1")).put(newNode("node2"))).build();
         clusterState = ClusterState.builder(clusterState).routingResult(allocation.reroute(clusterState)).build();
         // starting primaries
@@ -249,7 +241,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test")).build()).build();
+                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test"))).build();
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode("node1")).put(newNode("node2"))).build();
         clusterState = ClusterState.builder(clusterState).routingResult(allocation.reroute(clusterState)).build();
         // starting primaries
@@ -313,7 +305,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test1")).addAsNew(metaData.index("test2")).build()).build();
+                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test1")).addAsNew(metaData.index("test2"))).build();
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode("node1")).put(newNode("node2"))).build();
         clusterState = ClusterState.builder(clusterState).routingResult(allocation.reroute(clusterState)).build();
         assertThat(UnassignedInfo.getNumberOfDelayedUnassigned(System.currentTimeMillis(),
@@ -339,7 +331,7 @@ public class UnassignedInfoTests extends ESAllocationTestCase {
                 .build();
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
                 .metaData(metaData)
-                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test1")).addAsNew(metaData.index("test2")).build()).build();
+                .routingTable(RoutingTable.builder().addAsNew(metaData.index("test1")).addAsNew(metaData.index("test2"))).build();
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode("node1")).put(newNode("node2"))).build();
         clusterState = ClusterState.builder(clusterState).routingResult(allocation.reroute(clusterState)).build();
         assertThat(UnassignedInfo.getNumberOfDelayedUnassigned(System.currentTimeMillis(),
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java
index 836422f..a35e9f4 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.cluster.routing.allocation;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -236,8 +235,8 @@ public class AddIncrementallyTests extends ESAllocationTestCase {
 
 
     private void assertNumIndexShardsPerNode(ClusterState state, Matcher<Integer> matcher) {
-        for (ObjectCursor<String> index : state.routingTable().indicesRouting().keys()) {
-            assertNumIndexShardsPerNode(state, index.value, matcher);
+        for (String index : state.routingTable().indicesRouting().keySet()) {
+            assertNumIndexShardsPerNode(state, index, matcher);
         }
     }
 
@@ -249,10 +248,10 @@ public class AddIncrementallyTests extends ESAllocationTestCase {
 
 
     private void assertAtLeastOneIndexShardPerNode(ClusterState state) {
-        for (ObjectCursor<String> index : state.routingTable().indicesRouting().keys()) {
+        for (String index : state.routingTable().indicesRouting().keySet()) {
 
             for (RoutingNode node : state.getRoutingNodes()) {
-                assertThat(node.shardsWithState(index.value, STARTED).size(), Matchers.greaterThanOrEqualTo(1));
+                assertThat(node.shardsWithState(index, STARTED).size(), Matchers.greaterThanOrEqualTo(1));
             }
         }
 
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationCommandsTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationCommandsTests.java
index 96cba27..a983d88 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationCommandsTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationCommandsTests.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.cluster.routing.allocation;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -42,10 +43,7 @@ import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.test.ESAllocationTestCase;
 import org.junit.Test;
 
-import static java.util.Collections.singletonMap;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.RELOCATING;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.STARTED;
+import static org.elasticsearch.cluster.routing.ShardRoutingState.*;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.hamcrest.Matchers.equalTo;
 
@@ -120,7 +118,7 @@ public class AllocationCommandsTests extends ESAllocationTestCase {
                 .put(newNode("node1"))
                 .put(newNode("node2"))
                 .put(newNode("node3"))
-                .put(newNode("node4", singletonMap("data", Boolean.FALSE.toString())))
+                .put(newNode("node4", ImmutableMap.of("data", Boolean.FALSE.toString())))
         ).build();
         RoutingAllocation.Result rerouteResult = allocation.reroute(clusterState);
         clusterState = ClusterState.builder(clusterState).routingTable(rerouteResult.routingTable()).build();
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AwarenessAllocationTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AwarenessAllocationTests.java
index e17ac30..7f050f3 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AwarenessAllocationTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/AwarenessAllocationTests.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.cluster.routing.allocation;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
@@ -37,15 +38,9 @@ import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.test.ESAllocationTestCase;
 import org.junit.Test;
 
-import static java.util.Collections.singletonMap;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.RELOCATING;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.STARTED;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.UNASSIGNED;
+import static org.elasticsearch.cluster.routing.ShardRoutingState.*;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.sameInstance;
+import static org.hamcrest.Matchers.*;
 
 /**
  */
@@ -75,8 +70,8 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes on same rack and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("rack_id", "1")))
-                .put(newNode("node2", singletonMap("rack_id", "1")))
+                .put(newNode("node1", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node2", ImmutableMap.of("rack_id", "1")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -94,7 +89,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add a new node with a new rack and reroute");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node3", singletonMap("rack_id", "2")))
+                .put(newNode("node3", ImmutableMap.of("rack_id", "2")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -114,7 +109,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add another node with a new rack, make sure nothing moves");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node4", singletonMap("rack_id", "3")))
+                .put(newNode("node4", ImmutableMap.of("rack_id", "3")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         assertThat(routingTable, sameInstance(clusterState.routingTable()));
@@ -144,9 +139,9 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes on same rack and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("rack_id", "1")))
-                .put(newNode("node2", singletonMap("rack_id", "1")))
-                .put(newNode("node3", singletonMap("rack_id", "1")))
+                .put(newNode("node1", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node2", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node3", ImmutableMap.of("rack_id", "1")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -164,7 +159,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add a new node with a new rack and reroute");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node4", singletonMap("rack_id", "2")))
+                .put(newNode("node4", ImmutableMap.of("rack_id", "2")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -184,7 +179,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add another node with a new rack, make sure nothing moves");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node5", singletonMap("rack_id", "3")))
+                .put(newNode("node5", ImmutableMap.of("rack_id", "3")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         assertThat(routingTable, sameInstance(clusterState.routingTable()));
@@ -219,8 +214,8 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes on same rack and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("rack_id", "1")))
-                .put(newNode("node2", singletonMap("rack_id", "1")))
+                .put(newNode("node1", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node2", ImmutableMap.of("rack_id", "1")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -252,7 +247,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add a new node with a new rack and reroute");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node3", singletonMap("rack_id", "2")))
+                .put(newNode("node3", ImmutableMap.of("rack_id", "2")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -277,7 +272,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add another node with a new rack, some more relocation should happen");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node4", singletonMap("rack_id", "3")))
+                .put(newNode("node4", ImmutableMap.of("rack_id", "3")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -319,8 +314,8 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes on same rack and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("rack_id", "1")))
-                .put(newNode("node2", singletonMap("rack_id", "1")))
+                .put(newNode("node1", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node2", ImmutableMap.of("rack_id", "1")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -338,7 +333,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add a new node with a new rack and reroute");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node3", singletonMap("rack_id", "2")))
+                .put(newNode("node3", ImmutableMap.of("rack_id", "2")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -367,7 +362,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add another node with a new rack, some more relocation should happen");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node4", singletonMap("rack_id", "3")))
+                .put(newNode("node4", ImmutableMap.of("rack_id", "3")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -411,8 +406,8 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes on same rack and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("rack_id", "1")))
-                .put(newNode("node2", singletonMap("rack_id", "1")))
+                .put(newNode("node1", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node2", ImmutableMap.of("rack_id", "1")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -430,7 +425,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add a new node with a new rack and reroute");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node3", singletonMap("rack_id", "2")))
+                .put(newNode("node3", ImmutableMap.of("rack_id", "2")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -450,7 +445,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add another node with a new rack, we will have another relocation");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node4", singletonMap("rack_id", "3")))
+                .put(newNode("node4", ImmutableMap.of("rack_id", "3")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -490,10 +485,10 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes on same rack and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("rack_id", "1")))
-                .put(newNode("node2", singletonMap("rack_id", "1")))
-                .put(newNode("node3", singletonMap("rack_id", "1")))
-                .put(newNode("node4", singletonMap("rack_id", "1")))
+                .put(newNode("node1", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node2", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node3", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node4", ImmutableMap.of("rack_id", "1")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -511,7 +506,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add a new node with a new rack and reroute");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node5", singletonMap("rack_id", "2")))
+                .put(newNode("node5", ImmutableMap.of("rack_id", "2")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -531,7 +526,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add another node with a new rack, we will have another relocation");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node6", singletonMap("rack_id", "3")))
+                .put(newNode("node6", ImmutableMap.of("rack_id", "3")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -572,8 +567,8 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes on same rack and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("rack_id", "1")))
-                .put(newNode("node2", singletonMap("rack_id", "1")))
+                .put(newNode("node1", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node2", ImmutableMap.of("rack_id", "1")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -589,7 +584,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add a new node with a new rack and reroute");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node3", singletonMap("rack_id", "2")))
+                .put(newNode("node3", ImmutableMap.of("rack_id", "2")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -609,7 +604,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add another node with a new rack, make sure nothing moves");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node4", singletonMap("rack_id", "3")))
+                .put(newNode("node4", ImmutableMap.of("rack_id", "3")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         assertThat(routingTable, sameInstance(clusterState.routingTable()));
@@ -640,9 +635,9 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes on same rack and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("rack_id", "1")))
-                .put(newNode("node2", singletonMap("rack_id", "1")))
-                .put(newNode("node3", singletonMap("rack_id", "1")))
+                .put(newNode("node1", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node2", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node3", ImmutableMap.of("rack_id", "1")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -658,7 +653,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add a new node with a new rack and reroute");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node4", singletonMap("rack_id", "2")))
+                .put(newNode("node4", ImmutableMap.of("rack_id", "2")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -678,7 +673,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add another node with a new rack, make sure nothing moves");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node5", singletonMap("rack_id", "3")))
+                .put(newNode("node5", ImmutableMap.of("rack_id", "3")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         assertThat(routingTable, sameInstance(clusterState.routingTable()));
@@ -716,8 +711,8 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes on same rack and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("rack_id", "1")))
-                .put(newNode("node2", singletonMap("rack_id", "1")))
+                .put(newNode("node1", ImmutableMap.of("rack_id", "1")))
+                .put(newNode("node2", ImmutableMap.of("rack_id", "1")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -731,7 +726,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add a new node with a new rack and reroute");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node3", singletonMap("rack_id", "2")))
+                .put(newNode("node3", ImmutableMap.of("rack_id", "2")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -755,7 +750,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add another node with a new rack, some more relocation should happen");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node4", singletonMap("rack_id", "3")))
+                .put(newNode("node4", ImmutableMap.of("rack_id", "3")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -796,8 +791,8 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes in different zones and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("A-0", singletonMap("zone", "a")))
-                .put(newNode("B-0", singletonMap("zone", "b")))
+                .put(newNode("A-0", ImmutableMap.of("zone", "a")))
+                .put(newNode("B-0", ImmutableMap.of("zone", "b")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -818,7 +813,7 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> add a new node in zone 'a' and reroute");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("A-1", singletonMap("zone", "a")))
+                .put(newNode("A-1", ImmutableMap.of("zone", "a")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -858,12 +853,12 @@ public class AwarenessAllocationTests extends ESAllocationTestCase {
 
         logger.info("--> adding 5 nodes in different zones and do rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                        .put(newNode("A-0", singletonMap("zone", "a")))
-                        .put(newNode("A-1", singletonMap("zone", "a")))
-                        .put(newNode("A-2", singletonMap("zone", "a")))
-                        .put(newNode("A-3", singletonMap("zone", "a")))
-                        .put(newNode("A-4", singletonMap("zone", "a")))
-                        .put(newNode("B-0", singletonMap("zone", "b")))
+                        .put(newNode("A-0", ImmutableMap.of("zone", "a")))
+                        .put(newNode("A-1", ImmutableMap.of("zone", "a")))
+                        .put(newNode("A-2", ImmutableMap.of("zone", "a")))
+                        .put(newNode("A-3", ImmutableMap.of("zone", "a")))
+                        .put(newNode("A-4", ImmutableMap.of("zone", "a")))
+                        .put(newNode("B-0", ImmutableMap.of("zone", "b")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/BalanceConfigurationTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/BalanceConfigurationTests.java
index 2bd18f8..e17fe47 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/BalanceConfigurationTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/BalanceConfigurationTests.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.cluster.routing.allocation;
 
 import com.carrotsearch.hppc.cursors.ObjectCursor;
-
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.EmptyClusterInfoService;
@@ -28,11 +27,7 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.RoutingNode;
-import org.elasticsearch.cluster.routing.RoutingNodes;
-import org.elasticsearch.cluster.routing.RoutingTable;
-import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.cluster.routing.ShardRoutingState;
+import org.elasticsearch.cluster.routing.*;
 import org.elasticsearch.cluster.routing.allocation.allocator.BalancedShardsAllocator;
 import org.elasticsearch.cluster.routing.allocation.allocator.ShardsAllocator;
 import org.elasticsearch.cluster.routing.allocation.allocator.ShardsAllocators;
@@ -40,9 +35,9 @@ import org.elasticsearch.cluster.routing.allocation.decider.ClusterRebalanceAllo
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.node.settings.NodeSettingsService;
 import org.elasticsearch.test.ESAllocationTestCase;
 import org.elasticsearch.test.gateway.NoopGatewayAllocator;
+import org.elasticsearch.node.settings.NodeSettingsService;
 import org.hamcrest.Matchers;
 import org.junit.Test;
 
@@ -251,11 +246,11 @@ public class BalanceConfigurationTests extends ESAllocationTestCase {
         final int minAvgNumberOfShards = Math.round(Math.round(Math.floor(avgNumShards - treshold)));
         final int maxAvgNumberOfShards = Math.round(Math.round(Math.ceil(avgNumShards + treshold)));
 
-        for (ObjectCursor<String> index : nodes.getRoutingTable().indicesRouting().keys()) {
+        for (String index : nodes.getRoutingTable().indicesRouting().keySet()) {
             for (RoutingNode node : nodes) {
 //              logger.info(node.nodeId() +":"+index+ ": " + node.shardsWithState(index, INITIALIZING, STARTED).size() + " shards ("+minAvgNumberOfShards+" to "+maxAvgNumberOfShards+")");
-                assertThat(node.shardsWithState(index.value, STARTED).size(), Matchers.greaterThanOrEqualTo(minAvgNumberOfShards));
-                assertThat(node.shardsWithState(index.value, STARTED).size(), Matchers.lessThanOrEqualTo(maxAvgNumberOfShards));
+                assertThat(node.shardsWithState(index, STARTED).size(), Matchers.greaterThanOrEqualTo(minAvgNumberOfShards));
+                assertThat(node.shardsWithState(index, STARTED).size(), Matchers.lessThanOrEqualTo(maxAvgNumberOfShards));
             }
         }
     }
@@ -267,10 +262,10 @@ public class BalanceConfigurationTests extends ESAllocationTestCase {
         final int minAvgNumberOfShards = Math.round(Math.round(Math.floor(avgNumShards - treshold)));
         final int maxAvgNumberOfShards = Math.round(Math.round(Math.ceil(avgNumShards + treshold)));
 
-        for (ObjectCursor<String> index : nodes.getRoutingTable().indicesRouting().keys()) {
+        for (String index : nodes.getRoutingTable().indicesRouting().keySet()) {
             for (RoutingNode node : nodes) {
                 int primaries = 0;
-                for (ShardRouting shard : node.shardsWithState(index.value, STARTED)) {
+                for (ShardRouting shard : node.shardsWithState(index, STARTED)) {
                     primaries += shard.primary() ? 1 : 0;
                 }
 //                logger.info(node.nodeId() + ": " + primaries + " primaries ("+minAvgNumberOfShards+" to "+maxAvgNumberOfShards+")");
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FilterRoutingTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FilterRoutingTests.java
index eb4d62a..e9a905d 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FilterRoutingTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/FilterRoutingTests.java
@@ -19,13 +19,14 @@
 
 package org.elasticsearch.cluster.routing.allocation;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.RoutingTable;
 import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.cluster.routing.RoutingTable;
 import org.elasticsearch.cluster.routing.ShardRoutingState;
 import org.elasticsearch.common.logging.ESLogger;
 import org.elasticsearch.common.logging.Loggers;
@@ -35,7 +36,6 @@ import org.junit.Test;
 
 import java.util.List;
 
-import static java.util.Collections.singletonMap;
 import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.hamcrest.Matchers.equalTo;
@@ -67,10 +67,10 @@ public class FilterRoutingTests extends ESAllocationTestCase {
 
         logger.info("--> adding four nodes and performing rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("tag1", "value1")))
-                .put(newNode("node2", singletonMap("tag1", "value2")))
-                .put(newNode("node3", singletonMap("tag1", "value3")))
-                .put(newNode("node4", singletonMap("tag1", "value4")))
+                .put(newNode("node1", ImmutableMap.of("tag1", "value1")))
+                .put(newNode("node2", ImmutableMap.of("tag1", "value2")))
+                .put(newNode("node3", ImmutableMap.of("tag1", "value3")))
+                .put(newNode("node4", ImmutableMap.of("tag1", "value4")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -116,10 +116,10 @@ public class FilterRoutingTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes and performing rerouting");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("tag1", "value1")))
-                .put(newNode("node2", singletonMap("tag1", "value2")))
-                .put(newNode("node3", singletonMap("tag1", "value3")))
-                .put(newNode("node4", singletonMap("tag1", "value4")))
+                .put(newNode("node1", ImmutableMap.of("tag1", "value1")))
+                .put(newNode("node2", ImmutableMap.of("tag1", "value2")))
+                .put(newNode("node3", ImmutableMap.of("tag1", "value3")))
+                .put(newNode("node4", ImmutableMap.of("tag1", "value4")))
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/PreferLocalPrimariesToRelocatingPrimariesTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/PreferLocalPrimariesToRelocatingPrimariesTests.java
index 616949e..f307b63 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/PreferLocalPrimariesToRelocatingPrimariesTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/PreferLocalPrimariesToRelocatingPrimariesTests.java
@@ -18,21 +18,18 @@
  */
 package org.elasticsearch.cluster.routing.allocation;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.RoutingTable;
 import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.cluster.routing.RoutingTable;
 import org.elasticsearch.test.ESAllocationTestCase;
 import org.junit.Test;
 
-import static java.util.Collections.singletonMap;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.RELOCATING;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.STARTED;
-import static org.elasticsearch.cluster.routing.ShardRoutingState.UNASSIGNED;
+import static org.elasticsearch.cluster.routing.ShardRoutingState.*;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.hamcrest.Matchers.equalTo;
 
@@ -68,8 +65,8 @@ public class PreferLocalPrimariesToRelocatingPrimariesTests extends ESAllocation
 
         logger.info("adding two nodes and performing rerouting till all are allocated");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", singletonMap("tag1", "value1")))
-                .put(newNode("node2", singletonMap("tag1", "value2")))).build();
+                .put(newNode("node1", ImmutableMap.of("tag1", "value1")))
+                .put(newNode("node2", ImmutableMap.of("tag1", "value2")))).build();
 
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
@@ -104,7 +101,7 @@ public class PreferLocalPrimariesToRelocatingPrimariesTests extends ESAllocation
 
         logger.info("start node back up");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(newNode("node1", singletonMap("tag1", "value1")))).build();
+                .put(newNode("node1", ImmutableMap.of("tag1", "value1")))).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
 
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SameShardRoutingTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SameShardRoutingTests.java
index 86369b9..5213797 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SameShardRoutingTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/SameShardRoutingTests.java
@@ -19,14 +19,15 @@
 
 package org.elasticsearch.cluster.routing.allocation;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.RoutingTable;
 import org.elasticsearch.cluster.routing.ShardRouting;
+import org.elasticsearch.cluster.routing.RoutingTable;
 import org.elasticsearch.cluster.routing.ShardRoutingState;
 import org.elasticsearch.cluster.routing.allocation.decider.SameShardAllocationDecider;
 import org.elasticsearch.common.logging.ESLogger;
@@ -35,7 +36,6 @@ import org.elasticsearch.common.transport.DummyTransportAddress;
 import org.elasticsearch.test.ESAllocationTestCase;
 import org.junit.Test;
 
-import static java.util.Collections.emptyMap;
 import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
 import static org.elasticsearch.cluster.routing.allocation.RoutingNodesUtils.numberOfShardsOfType;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
@@ -62,8 +62,8 @@ public class SameShardRoutingTests extends ESAllocationTestCase {
 
         logger.info("--> adding two nodes with the same host");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(new DiscoveryNode("node1", "node1", "test1", "test1", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT))
-                .put(new DiscoveryNode("node2", "node2", "test1", "test1", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT))).build();
+                .put(new DiscoveryNode("node1", "node1", "test1", "test1", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT))
+                .put(new DiscoveryNode("node2", "node2", "test1", "test1", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT))).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
 
@@ -78,7 +78,7 @@ public class SameShardRoutingTests extends ESAllocationTestCase {
 
         logger.info("--> add another node, with a different host, replicas will be allocating");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
-                .put(new DiscoveryNode("node3", "node3", "test2", "test2", DummyTransportAddress.INSTANCE, emptyMap(), Version.CURRENT))).build();
+                .put(new DiscoveryNode("node3", "node3", "test2", "test2", DummyTransportAddress.INSTANCE, ImmutableMap.<String, String>of(), Version.CURRENT))).build();
         routingTable = strategy.reroute(clusterState).routingTable();
         clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
 
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/StartedShardsRoutingTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/StartedShardsRoutingTests.java
index 1e8a5fb..dc23085 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/StartedShardsRoutingTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/StartedShardsRoutingTests.java
@@ -24,13 +24,7 @@ import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.AllocationId;
-import org.elasticsearch.cluster.routing.IndexRoutingTable;
-import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
-import org.elasticsearch.cluster.routing.RoutingTable;
-import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.cluster.routing.ShardRoutingState;
-import org.elasticsearch.cluster.routing.TestShardRouting;
+import org.elasticsearch.cluster.routing.*;
 import org.elasticsearch.test.ESAllocationTestCase;
 import org.junit.Test;
 
@@ -60,7 +54,7 @@ public class StartedShardsRoutingTests extends ESAllocationTestCase {
         stateBuilder.routingTable(RoutingTable.builder().add(IndexRoutingTable.builder("test")
                 .addIndexShard(new IndexShardRoutingTable.Builder(initShard.shardId()).addShard(initShard).build())
                 .addIndexShard(new IndexShardRoutingTable.Builder(startedShard.shardId()).addShard(startedShard).build())
-                .addIndexShard(new IndexShardRoutingTable.Builder(relocatingShard.shardId()).addShard(relocatingShard).build())).build());
+                .addIndexShard(new IndexShardRoutingTable.Builder(relocatingShard.shardId()).addShard(relocatingShard).build())));
 
         ClusterState state = stateBuilder.build();
 
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java
index 525c446..5852faf 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderTests.java
@@ -24,7 +24,7 @@ import org.elasticsearch.cluster.ClusterInfo;
 import org.elasticsearch.cluster.ClusterInfoService;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.DiskUsage;
-import org.elasticsearch.cluster.MockInternalClusterInfoService.DevNullClusterInfo;
+import org.elasticsearch.cluster.MockInternalClusterInfoService;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
@@ -43,7 +43,6 @@ import org.elasticsearch.cluster.routing.allocation.allocator.ShardsAllocators;
 import org.elasticsearch.cluster.routing.allocation.command.AllocationCommand;
 import org.elasticsearch.cluster.routing.allocation.command.AllocationCommands;
 import org.elasticsearch.cluster.routing.allocation.command.MoveAllocationCommand;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.LocalTransportAddress;
 import org.elasticsearch.index.shard.ShardId;
@@ -52,6 +51,7 @@ import org.elasticsearch.test.gateway.NoopGatewayAllocator;
 import org.junit.Test;
 
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Map;
@@ -78,18 +78,16 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK, 0.7)
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK, 0.8).build();
 
-        ImmutableOpenMap.Builder<String, DiskUsage> usagesBuilder = ImmutableOpenMap.builder();
-        usagesBuilder.put("node1", new DiskUsage("node1", "node1", "/dev/null", 100, 10)); // 90% used
-        usagesBuilder.put("node2", new DiskUsage("node2", "node2", "/dev/null", 100, 35)); // 65% used
-        usagesBuilder.put("node3", new DiskUsage("node3", "node3", "/dev/null", 100, 60)); // 40% used
-        usagesBuilder.put("node4", new DiskUsage("node4", "node4", "/dev/null", 100, 80)); // 20% used
-        ImmutableOpenMap<String, DiskUsage> usages = usagesBuilder.build();
+        Map<String, DiskUsage> usages = new HashMap<>();
+        usages.put("node1", new DiskUsage("node1", "node1", "/dev/null", 100, 10)); // 90% used
+        usages.put("node2", new DiskUsage("node2", "node2", "/dev/null", 100, 35)); // 65% used
+        usages.put("node3", new DiskUsage("node3", "node3", "/dev/null", 100, 60)); // 40% used
+        usages.put("node4", new DiskUsage("node4", "node4", "/dev/null", 100, 80)); // 20% used
 
-        ImmutableOpenMap.Builder<String, Long> shardSizesBuilder = ImmutableOpenMap.builder();
-        shardSizesBuilder.put("[test][0][p]", 10L); // 10 bytes
-        shardSizesBuilder.put("[test][0][r]", 10L);
-        ImmutableOpenMap<String, Long> shardSizes = shardSizesBuilder.build();
-        final ClusterInfo clusterInfo = new DevNullClusterInfo(usages, usages, shardSizes);
+        Map<String, Long> shardSizes = new HashMap<>();
+        shardSizes.put("[test][0][p]", 10L); // 10 bytes
+        shardSizes.put("[test][0][r]", 10L);
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         AllocationDeciders deciders = new AllocationDeciders(Settings.EMPTY,
                 new HashSet<>(Arrays.asList(
@@ -273,19 +271,17 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK, "30b")
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK, "9b").build();
 
-        ImmutableOpenMap.Builder<String, DiskUsage> usagesBuilder = ImmutableOpenMap.builder();
-        usagesBuilder.put("node1", new DiskUsage("node1", "n1", "/dev/null", 100, 10)); // 90% used
-        usagesBuilder.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 10)); // 90% used
-        usagesBuilder.put("node3", new DiskUsage("node3", "n3", "/dev/null", 100, 60)); // 40% used
-        usagesBuilder.put("node4", new DiskUsage("node4", "n4", "/dev/null", 100, 80)); // 20% used
-        usagesBuilder.put("node5", new DiskUsage("node5", "n5", "/dev/null", 100, 85)); // 15% used
-        ImmutableOpenMap<String, DiskUsage> usages = usagesBuilder.build();
+        Map<String, DiskUsage> usages = new HashMap<>();
+        usages.put("node1", new DiskUsage("node1", "n1", "/dev/null", 100, 10)); // 90% used
+        usages.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 10)); // 90% used
+        usages.put("node3", new DiskUsage("node3", "n3", "/dev/null", 100, 60)); // 40% used
+        usages.put("node4", new DiskUsage("node4", "n4", "/dev/null", 100, 80)); // 20% used
+        usages.put("node5", new DiskUsage("node5", "n5", "/dev/null", 100, 85)); // 15% used
 
-        ImmutableOpenMap.Builder<String, Long> shardSizesBuilder = ImmutableOpenMap.builder();
-        shardSizesBuilder.put("[test][0][p]", 10L); // 10 bytes
-        shardSizesBuilder.put("[test][0][r]", 10L);
-        ImmutableOpenMap<String, Long> shardSizes = shardSizesBuilder.build();
-        final ClusterInfo clusterInfo = new DevNullClusterInfo(usages, usages, shardSizes);
+        Map<String, Long> shardSizes = new HashMap<>();
+        shardSizes.put("[test][0][p]", 10L); // 10 bytes
+        shardSizes.put("[test][0][r]", 10L);
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         AllocationDeciders deciders = new AllocationDeciders(Settings.EMPTY,
                 new HashSet<>(Arrays.asList(
@@ -346,10 +342,8 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
         logger.info("--> nodeWithoutPrimary: {}", nodeWithoutPrimary);
 
         // Make node without the primary now habitable to replicas
-        usagesBuilder = ImmutableOpenMap.builder(usages);
-        usagesBuilder.put(nodeWithoutPrimary, new DiskUsage(nodeWithoutPrimary, "", "/dev/null", 100, 35)); // 65% used
-        usages = usagesBuilder.build();
-        final ClusterInfo clusterInfo2 = new DevNullClusterInfo(usages, usages, shardSizes);
+        usages.put(nodeWithoutPrimary, new DiskUsage(nodeWithoutPrimary, "", "/dev/null", 100, 35)); // 65% used
+        final ClusterInfo clusterInfo2 = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
         cis = new ClusterInfoService() {
             @Override
             public ClusterInfo getClusterInfo() {
@@ -542,15 +536,13 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK, 0.7)
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK, "71%").build();
 
-        ImmutableOpenMap.Builder<String, DiskUsage> usagesBuilder = ImmutableOpenMap.builder();
-        usagesBuilder.put("node1", new DiskUsage("node1", "n1", "/dev/null", 100, 31)); // 69% used
-        usagesBuilder.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 1));  // 99% used
-        ImmutableOpenMap<String, DiskUsage> usages = usagesBuilder.build();
+        Map<String, DiskUsage> usages = new HashMap<>();
+        usages.put("node1", new DiskUsage("node1", "n1", "/dev/null", 100, 31)); // 69% used
+        usages.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 1));  // 99% used
 
-        ImmutableOpenMap.Builder<String, Long> shardSizesBuilder = ImmutableOpenMap.builder();
-        shardSizesBuilder.put("[test][0][p]", 10L); // 10 bytes
-        ImmutableOpenMap<String, Long> shardSizes = shardSizesBuilder.build();
-        final ClusterInfo clusterInfo = new DevNullClusterInfo(usages, usages, shardSizes);
+        Map<String, Long> shardSizes = new HashMap<>();
+        shardSizes.put("[test][0][p]", 10L); // 10 bytes
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         AllocationDeciders deciders = new AllocationDeciders(Settings.EMPTY,
                 new HashSet<>(Arrays.asList(
@@ -610,16 +602,14 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK, 0.7)
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK, 0.85).build();
 
-        ImmutableOpenMap.Builder<String, DiskUsage> usagesBuilder = ImmutableOpenMap.builder();
-        usagesBuilder.put("node2", new DiskUsage("node2", "node2", "/dev/null", 100, 50)); // 50% used
-        usagesBuilder.put("node3", new DiskUsage("node3", "node3", "/dev/null", 100, 0));  // 100% used
-        ImmutableOpenMap<String, DiskUsage> usages = usagesBuilder.build();
+        Map<String, DiskUsage> usages = new HashMap<>();
+        usages.put("node2", new DiskUsage("node2", "node2", "/dev/null", 100, 50)); // 50% used
+        usages.put("node3", new DiskUsage("node3", "node3", "/dev/null", 100, 0));  // 100% used
 
-        ImmutableOpenMap.Builder<String, Long> shardSizesBuilder = ImmutableOpenMap.builder();
-        shardSizesBuilder.put("[test][0][p]", 10L); // 10 bytes
-        shardSizesBuilder.put("[test][0][r]", 10L); // 10 bytes
-        ImmutableOpenMap<String, Long> shardSizes = shardSizesBuilder.build();
-        final ClusterInfo clusterInfo = new DevNullClusterInfo(usages, usages, shardSizes);
+        Map<String, Long> shardSizes = new HashMap<>();
+        shardSizes.put("[test][0][p]", 10L); // 10 bytes
+        shardSizes.put("[test][0][r]", 10L); // 10 bytes
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         AllocationDeciders deciders = new AllocationDeciders(Settings.EMPTY,
                 new HashSet<>(Arrays.asList(
@@ -683,11 +673,11 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
         RoutingNode rn = new RoutingNode("node1", newNode("node1"));
         DiskThresholdDecider decider = new DiskThresholdDecider(Settings.EMPTY);
 
-        ImmutableOpenMap.Builder<String, DiskUsage> usages = ImmutableOpenMap.builder();
+        Map<String, DiskUsage> usages = new HashMap<>();
         usages.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 50)); // 50% used
         usages.put("node3", new DiskUsage("node3", "n3", "/dev/null", 100, 0));  // 100% used
 
-        DiskUsage node1Usage = decider.averageUsage(rn, usages.build());
+        DiskUsage node1Usage = decider.averageUsage(rn, usages);
         assertThat(node1Usage.getTotalBytes(), equalTo(100L));
         assertThat(node1Usage.getFreeBytes(), equalTo(25L));
     }
@@ -713,19 +703,17 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK, 0.7)
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK, 0.8).build();
 
-        ImmutableOpenMap.Builder<String, DiskUsage> usagesBuilder = ImmutableOpenMap.builder();
-        usagesBuilder.put("node1", new DiskUsage("node1", "n1", "/dev/null", 100, 40)); // 60% used
-        usagesBuilder.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 40)); // 60% used
-        usagesBuilder.put("node3", new DiskUsage("node3", "n3", "/dev/null", 100, 40)); // 60% used
-        ImmutableOpenMap<String, DiskUsage> usages = usagesBuilder.build();
+        Map<String, DiskUsage> usages = new HashMap<>();
+        usages.put("node1", new DiskUsage("node1", "n1", "/dev/null", 100, 40)); // 60% used
+        usages.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 40)); // 60% used
+        usages.put("node3", new DiskUsage("node3", "n3", "/dev/null", 100, 40)); // 60% used
 
-        ImmutableOpenMap.Builder<String, Long> shardSizesBuilder = ImmutableOpenMap.builder();
-        shardSizesBuilder.put("[test][0][p]", 14L); // 14 bytes
-        shardSizesBuilder.put("[test][0][r]", 14L);
-        shardSizesBuilder.put("[test2][0][p]", 1L); // 1 bytes
-        shardSizesBuilder.put("[test2][0][r]", 1L);
-        ImmutableOpenMap<String, Long> shardSizes = shardSizesBuilder.build();
-        final ClusterInfo clusterInfo = new DevNullClusterInfo(usages, usages, shardSizes);
+        Map<String, Long> shardSizes = new HashMap<>();
+        shardSizes.put("[test][0][p]", 14L); // 14 bytes
+        shardSizes.put("[test][0][r]", 14L);
+        shardSizes.put("[test2][0][p]", 1L); // 1 bytes
+        shardSizes.put("[test2][0][r]", 1L);
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         AllocationDeciders deciders = new AllocationDeciders(Settings.EMPTY,
                 new HashSet<>(Arrays.asList(
@@ -821,17 +809,14 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK, "70%").build();
 
         // We have an index with 2 primary shards each taking 40 bytes. Each node has 100 bytes available
-        ImmutableOpenMap.Builder<String, DiskUsage> usagesBuilder = ImmutableOpenMap.builder();
-        usagesBuilder.put("node1", new DiskUsage("node1", "n1", "/dev/null", 100, 20)); // 80% used
-        usagesBuilder.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 100)); // 0% used
-        ImmutableOpenMap<String, DiskUsage> usages = usagesBuilder.build();
-
-        ImmutableOpenMap.Builder<String, Long> shardSizesBuilder = ImmutableOpenMap.builder();
-        shardSizesBuilder.put("[test][0][p]", 40L);
-        shardSizesBuilder.put("[test][1][p]", 40L);
-        ImmutableOpenMap<String, Long> shardSizes = shardSizesBuilder.build();
+        Map<String, DiskUsage> usages = new HashMap<>();
+        usages.put("node1", new DiskUsage("node1", "n1", "/dev/null", 100, 20)); // 80% used
+        usages.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 100)); // 0% used
 
-        final ClusterInfo clusterInfo = new DevNullClusterInfo(usages, usages, shardSizes);
+        Map<String, Long> shardSizes = new HashMap<>();
+        shardSizes.put("[test][0][p]", 40L);
+        shardSizes.put("[test][1][p]", 40L);
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         DiskThresholdDecider diskThresholdDecider = new DiskThresholdDecider(diskSettings);
         MetaData metaData = MetaData.builder()
@@ -867,7 +852,7 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                                         .build()
                         )
         );
-        ClusterState clusterState = ClusterState.builder(baseClusterState).routingTable(builder.build()).build();
+        ClusterState clusterState = ClusterState.builder(baseClusterState).routingTable(builder).build();
         RoutingAllocation routingAllocation = new RoutingAllocation(null, new RoutingNodes(clusterState), discoveryNodes, clusterInfo);
         Decision decision = diskThresholdDecider.canRemain(firstRouting, firstRoutingNode, routingAllocation);
         assertThat(decision.type(), equalTo(Decision.Type.NO));
@@ -887,7 +872,7 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                                         .build()
                         )
         );
-        clusterState = ClusterState.builder(baseClusterState).routingTable(builder.build()).build();
+        clusterState = ClusterState.builder(baseClusterState).routingTable(builder).build();
         routingAllocation = new RoutingAllocation(null, new RoutingNodes(clusterState), discoveryNodes, clusterInfo);
         decision = diskThresholdDecider.canRemain(firstRouting, firstRoutingNode, routingAllocation);
         assertThat(decision.type(), equalTo(Decision.Type.YES));
@@ -932,17 +917,16 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK, "60%")
                 .put(DiskThresholdDecider.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK, "70%").build();
 
-        ImmutableOpenMap.Builder<String, DiskUsage> usagesBuilder = ImmutableOpenMap.builder();
-        usagesBuilder.put("node1", new DiskUsage("node1", "n1", "/dev/null", 100, 100)); // 0% used
-        usagesBuilder.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 20));  // 80% used
-        usagesBuilder.put("node3", new DiskUsage("node3", "n3", "/dev/null", 100, 100)); // 0% used
-        ImmutableOpenMap<String, DiskUsage> usages = usagesBuilder.build();
+        Map<String, DiskUsage> usages = new HashMap<>();
+        usages.put("node1", new DiskUsage("node1", "n1", "/dev/null", 100, 100)); // 0% used
+        usages.put("node2", new DiskUsage("node2", "n2", "/dev/null", 100, 20));  // 80% used
+        usages.put("node3", new DiskUsage("node3", "n3", "/dev/null", 100, 100)); // 0% used
 
         // We have an index with 1 primary shards each taking 40 bytes. Each node has 100 bytes available
-        ImmutableOpenMap.Builder<String, Long> shardSizes = ImmutableOpenMap.builder();
+        Map<String, Long> shardSizes = new HashMap<>();
         shardSizes.put("[test][0][p]", 40L);
         shardSizes.put("[test][1][p]", 40L);
-        final ClusterInfo clusterInfo = new DevNullClusterInfo(usages, usages, shardSizes.build());
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(usages), Collections.unmodifiableMap(usages), Collections.unmodifiableMap(shardSizes), MockInternalClusterInfoService.DEV_NULL_MAP);
 
         DiskThresholdDecider diskThresholdDecider = new DiskThresholdDecider(diskSettings);
         MetaData metaData = MetaData.builder()
@@ -986,7 +970,7 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                                         .build()
                         )
         );
-        ClusterState clusterState = ClusterState.builder(baseClusterState).routingTable(builder.build()).build();
+        ClusterState clusterState = ClusterState.builder(baseClusterState).routingTable(builder).build();
         RoutingAllocation routingAllocation = new RoutingAllocation(null, new RoutingNodes(clusterState), discoveryNodes, clusterInfo);
         Decision decision = diskThresholdDecider.canRemain(firstRouting, firstRoutingNode, routingAllocation);
 
@@ -1043,7 +1027,7 @@ public class DiskThresholdDeciderTests extends ESAllocationTestCase {
                         )
         );
 
-        clusterState = ClusterState.builder(updateClusterState).routingTable(builder.build()).build();
+        clusterState = ClusterState.builder(updateClusterState).routingTable(builder).build();
         routingAllocation = new RoutingAllocation(null, new RoutingNodes(clusterState), discoveryNodes, clusterInfo);
         decision = diskThresholdDecider.canRemain(firstRouting, firstRoutingNode, routingAllocation);
         assertThat(decision.type(), equalTo(Decision.Type.YES));
diff --git a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderUnitTests.java b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderUnitTests.java
index 128187a..6460664 100644
--- a/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderUnitTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderUnitTests.java
@@ -25,7 +25,7 @@ import org.elasticsearch.cluster.ClusterInfoService;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.DiskUsage;
 import org.elasticsearch.cluster.EmptyClusterInfoService;
-import org.elasticsearch.cluster.MockInternalClusterInfoService.DevNullClusterInfo;
+import org.elasticsearch.cluster.MockInternalClusterInfoService;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
@@ -36,7 +36,6 @@ import org.elasticsearch.cluster.routing.ShardRouting;
 import org.elasticsearch.cluster.routing.ShardRoutingHelper;
 import org.elasticsearch.cluster.routing.UnassignedInfo;
 import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
-import org.elasticsearch.common.collect.ImmutableOpenMap;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.DummyTransportAddress;
 import org.elasticsearch.common.transport.LocalTransportAddress;
@@ -46,6 +45,9 @@ import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
 import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
 
 import static org.hamcrest.CoreMatchers.equalTo;
 
@@ -121,17 +123,17 @@ public class DiskThresholdDeciderUnitTests extends ESTestCase {
         ).build();
 
         // actual test -- after all that bloat :)
-        ImmutableOpenMap.Builder<String, DiskUsage> leastAvailableUsages = ImmutableOpenMap.builder();
+        Map<String, DiskUsage> leastAvailableUsages = new HashMap<>();
         leastAvailableUsages.put("node_0", new DiskUsage("node_0", "node_0", "_na_", 100, 0)); // all full
         leastAvailableUsages.put("node_1", new DiskUsage("node_1", "node_1", "_na_", 100, 0)); // all full
 
-        ImmutableOpenMap.Builder<String, DiskUsage> mostAvailableUsage = ImmutableOpenMap.builder();
+        Map<String, DiskUsage> mostAvailableUsage = new HashMap<>();
         mostAvailableUsage.put("node_0", new DiskUsage("node_0", "node_0", "_na_", 100, randomIntBetween(20, 100))); // 20 - 99 percent since after allocation there must be at least 10% left and shard is 10byte
         mostAvailableUsage.put("node_1", new DiskUsage("node_1", "node_1", "_na_", 100, randomIntBetween(0, 10))); // this is weird and smells like a bug! it should be up to 20%?
 
-        ImmutableOpenMap.Builder<String, Long> shardSizes = ImmutableOpenMap.builder();
+        Map<String, Long> shardSizes = new HashMap<>();
         shardSizes.put("[test][0][p]", 10L); // 10 bytes
-        final ClusterInfo clusterInfo = new ClusterInfo(leastAvailableUsages.build(), mostAvailableUsage.build(), shardSizes.build(), ImmutableOpenMap.of());
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(leastAvailableUsages), Collections.unmodifiableMap(mostAvailableUsage), Collections.unmodifiableMap(shardSizes), Collections.EMPTY_MAP);
         RoutingAllocation allocation = new RoutingAllocation(new AllocationDeciders(Settings.EMPTY, new AllocationDecider[]{decider}), clusterState.getRoutingNodes(), clusterState.nodes(), clusterInfo);
         assertEquals(mostAvailableUsage.toString(), Decision.YES, decider.canAllocate(test_0, new RoutingNode("node_0", node_0), allocation));
         assertEquals(mostAvailableUsage.toString(), Decision.NO, decider.canAllocate(test_0, new RoutingNode("node_1", node_1), allocation));
@@ -141,7 +143,7 @@ public class DiskThresholdDeciderUnitTests extends ESTestCase {
         NodeSettingsService nss = new NodeSettingsService(Settings.EMPTY);
         ClusterInfoService cis = EmptyClusterInfoService.INSTANCE;
         DiskThresholdDecider decider = new DiskThresholdDecider(Settings.EMPTY, nss, cis, null);
-        ImmutableOpenMap.Builder<ShardRouting, String> shardRoutingMap = ImmutableOpenMap.builder();
+        Map<ShardRouting, String> shardRoutingMap = new HashMap<>();
 
         DiscoveryNode node_0 = new DiscoveryNode("node_0", DummyTransportAddress.INSTANCE, Version.CURRENT);
         DiscoveryNode node_1 = new DiscoveryNode("node_1", DummyTransportAddress.INSTANCE, Version.CURRENT);
@@ -173,20 +175,20 @@ public class DiskThresholdDeciderUnitTests extends ESTestCase {
         ).build();
 
         // actual test -- after all that bloat :)
-        ImmutableOpenMap.Builder<String, DiskUsage> leastAvailableUsages = ImmutableOpenMap.builder();
+        Map<String, DiskUsage> leastAvailableUsages = new HashMap<>();
         leastAvailableUsages.put("node_0", new DiskUsage("node_0", "node_0", "/node0/least", 100, 10)); // 90% used
         leastAvailableUsages.put("node_1", new DiskUsage("node_1", "node_1", "/node1/least", 100, 9)); // 91% used
 
-        ImmutableOpenMap.Builder<String, DiskUsage> mostAvailableUsage = ImmutableOpenMap.builder();
+        Map<String, DiskUsage> mostAvailableUsage = new HashMap<>();
         mostAvailableUsage.put("node_0", new DiskUsage("node_0", "node_0", "/node0/most", 100, 90)); // 10% used
         mostAvailableUsage.put("node_1", new DiskUsage("node_1", "node_1", "/node1/most", 100, 90)); // 10% used
 
-        ImmutableOpenMap.Builder<String, Long> shardSizes = ImmutableOpenMap.builder();
+        Map<String, Long> shardSizes = new HashMap<>();
         shardSizes.put("[test][0][p]", 10L); // 10 bytes
         shardSizes.put("[test][1][p]", 10L);
         shardSizes.put("[test][2][p]", 10L);
 
-        final ClusterInfo clusterInfo = new ClusterInfo(leastAvailableUsages.build(), mostAvailableUsage.build(), shardSizes.build(), shardRoutingMap.build());
+        final ClusterInfo clusterInfo = new ClusterInfo(Collections.unmodifiableMap(leastAvailableUsages), Collections.unmodifiableMap(mostAvailableUsage), Collections.unmodifiableMap(shardSizes), shardRoutingMap);
         RoutingAllocation allocation = new RoutingAllocation(new AllocationDeciders(Settings.EMPTY, new AllocationDecider[]{decider}), clusterState.getRoutingNodes(), clusterState.nodes(), clusterInfo);
         assertEquals(Decision.YES, decider.canRemain(test_0, new RoutingNode("node_0", node_0), allocation));
         assertEquals(Decision.NO, decider.canRemain(test_1, new RoutingNode("node_1", node_1), allocation));
@@ -206,6 +208,7 @@ public class DiskThresholdDeciderUnitTests extends ESTestCase {
         ShardRouting test_2 = ShardRouting.newUnassigned("test", 2, null, true, new UnassignedInfo(UnassignedInfo.Reason.INDEX_CREATED, "foo"));
         ShardRoutingHelper.initialize(test_2, node_1.getId());
         ShardRoutingHelper.moveToStarted(test_2);
+        shardRoutingMap.put(test_2, "/node1/most");
         assertEquals("can stay since allocated on a different path with enough space", Decision.YES, decider.canRemain(test_2, new RoutingNode("node_1", node_1), allocation));
 
         ShardRouting test_3 = ShardRouting.newUnassigned("test", 3, null, true, new UnassignedInfo(UnassignedInfo.Reason.INDEX_CREATED, "foo"));
@@ -216,12 +219,12 @@ public class DiskThresholdDeciderUnitTests extends ESTestCase {
 
 
     public void testShardSizeAndRelocatingSize() {
-        ImmutableOpenMap.Builder<String, Long> shardSizes = ImmutableOpenMap.builder();
+        Map<String, Long> shardSizes = new HashMap<>();
         shardSizes.put("[test][0][r]", 10L);
         shardSizes.put("[test][1][r]", 100L);
         shardSizes.put("[test][2][r]", 1000L);
         shardSizes.put("[other][0][p]", 10000L);
-        ClusterInfo info = new DevNullClusterInfo(ImmutableOpenMap.of(), ImmutableOpenMap.of(), shardSizes.build());
+        ClusterInfo info = new ClusterInfo(Collections.EMPTY_MAP, Collections.EMPTY_MAP, shardSizes, MockInternalClusterInfoService.DEV_NULL_MAP);
         ShardRouting test_0 = ShardRouting.newUnassigned("test", 0, null, false, new UnassignedInfo(UnassignedInfo.Reason.INDEX_CREATED, "foo"));
         ShardRoutingHelper.initialize(test_0, "node1");
         ShardRoutingHelper.moveToStarted(test_0);
diff --git a/core/src/test/java/org/elasticsearch/cluster/serialization/DiffableTests.java b/core/src/test/java/org/elasticsearch/cluster/serialization/DiffableTests.java
index 87280f6..fe782f1 100644
--- a/core/src/test/java/org/elasticsearch/cluster/serialization/DiffableTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/serialization/DiffableTests.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.cluster.serialization;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.cluster.AbstractDiffable;
 import org.elasticsearch.cluster.Diff;
 import org.elasticsearch.cluster.DiffableUtils;
@@ -35,24 +36,23 @@ import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.unmodifiableMap;
 import static org.hamcrest.CoreMatchers.equalTo;
 
 public class DiffableTests extends ESTestCase {
 
     @Test
     public void testJdkMapDiff() throws IOException {
-        Map<String, TestDiffable> before = new HashMap<>();
-        before.put("foo", new TestDiffable("1"));
-        before.put("bar", new TestDiffable("2"));
-        before.put("baz", new TestDiffable("3"));
-        before = unmodifiableMap(before);
+        ImmutableMap.Builder<String, TestDiffable> builder = ImmutableMap.builder();
+        builder.put("foo", new TestDiffable("1"));
+        builder.put("bar", new TestDiffable("2"));
+        builder.put("baz", new TestDiffable("3"));
+        ImmutableMap<String, TestDiffable> before = builder.build();
         Map<String, TestDiffable> map = new HashMap<>();
         map.putAll(before);
         map.remove("bar");
         map.put("baz", new TestDiffable("4"));
         map.put("new", new TestDiffable("5"));
-        Map<String, TestDiffable> after = unmodifiableMap(new HashMap<>(map));
+        ImmutableMap<String, TestDiffable> after = ImmutableMap.copyOf(map);
         Diff diff = DiffableUtils.diff(before, after);
         BytesStreamOutput out = new BytesStreamOutput();
         diff.writeTo(out);
diff --git a/core/src/test/java/org/elasticsearch/cluster/structure/RoutingIteratorTests.java b/core/src/test/java/org/elasticsearch/cluster/structure/RoutingIteratorTests.java
index 236378e..d405fb1 100644
--- a/core/src/test/java/org/elasticsearch/cluster/structure/RoutingIteratorTests.java
+++ b/core/src/test/java/org/elasticsearch/cluster/structure/RoutingIteratorTests.java
@@ -19,43 +19,28 @@
 
 package org.elasticsearch.cluster.structure;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.GroupShardsIterator;
-import org.elasticsearch.cluster.routing.OperationRouting;
-import org.elasticsearch.cluster.routing.PlainShardIterator;
-import org.elasticsearch.cluster.routing.RotationShardShuffler;
-import org.elasticsearch.cluster.routing.RoutingTable;
-import org.elasticsearch.cluster.routing.ShardIterator;
-import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.cluster.routing.ShardShuffler;
-import org.elasticsearch.cluster.routing.ShardsIterator;
+import org.elasticsearch.cluster.routing.*;
 import org.elasticsearch.cluster.routing.allocation.AllocationService;
 import org.elasticsearch.cluster.routing.allocation.decider.AwarenessAllocationDecider;
 import org.elasticsearch.cluster.routing.allocation.decider.ClusterRebalanceAllocationDecider;
+import org.elasticsearch.cluster.routing.OperationRouting;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.test.ESAllocationTestCase;
 import org.junit.Test;
 
 import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
 
-import static java.util.Collections.singletonMap;
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.cluster.routing.ShardRoutingState.INITIALIZING;
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.hamcrest.Matchers.anyOf;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
-import static org.hamcrest.Matchers.sameInstance;
+import static org.hamcrest.Matchers.*;
 
 public class RoutingIteratorTests extends ESAllocationTestCase {
 
@@ -246,15 +231,9 @@ public class RoutingIteratorTests extends ESAllocationTestCase {
 
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();
 
-        Map<String, String> node1Attributes = new HashMap<>();
-        node1Attributes.put("rack_id", "rack_1");
-        node1Attributes.put("zone", "zone1");
-        Map<String, String> node2Attributes = new HashMap<>();
-        node2Attributes.put("rack_id", "rack_2");
-        node2Attributes.put("zone", "zone2");
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                .put(newNode("node1", unmodifiableMap(node1Attributes)))
-                .put(newNode("node2", unmodifiableMap(node2Attributes)))
+                .put(newNode("node1", ImmutableMap.of("rack_id", "rack_1", "zone", "zone1")))
+                .put(newNode("node2", ImmutableMap.of("rack_id", "rack_2", "zone", "zone2")))
                 .localNodeId("node1")
         ).build();
         routingTable = strategy.reroute(clusterState).routingTable();
@@ -302,8 +281,8 @@ public class RoutingIteratorTests extends ESAllocationTestCase {
         ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();
 
         clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
-                        .put(newNode("fred","node1", singletonMap("disk", "ebs")))
-                        .put(newNode("barney","node2", singletonMap("disk", "ephemeral")))
+                        .put(newNode("fred","node1", ImmutableMap.of("disk", "ebs")))
+                        .put(newNode("barney","node2", ImmutableMap.of("disk", "ephemeral")))
                         .localNodeId("node1")
         ).build();
 
@@ -335,7 +314,7 @@ public class RoutingIteratorTests extends ESAllocationTestCase {
         } catch (IllegalArgumentException illegal) {
             //expected exception
         }
-
+        
         shardsIterator = clusterState.routingTable().index("test").shard(0).onlyNodeSelectorActiveInitializingShardsIt("fred",clusterState.nodes());
         assertThat(shardsIterator.size(), equalTo(1));
         assertThat(shardsIterator.nextOrNull().currentNodeId(),equalTo("node1"));
diff --git a/core/src/test/java/org/elasticsearch/common/cli/CliToolTests.java b/core/src/test/java/org/elasticsearch/common/cli/CliToolTests.java
index f275d1d..748e417 100644
--- a/core/src/test/java/org/elasticsearch/common/cli/CliToolTests.java
+++ b/core/src/test/java/org/elasticsearch/common/cli/CliToolTests.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.common.cli;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.commons.cli.CommandLine;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.common.Strings;
@@ -28,20 +29,14 @@ import org.elasticsearch.node.internal.InternalSettingsPreparer;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicReference;
 
-import static java.util.Collections.unmodifiableMap;
 import static org.elasticsearch.common.cli.CliTool.ExitStatus.OK;
 import static org.elasticsearch.common.cli.CliTool.ExitStatus.USAGE;
 import static org.elasticsearch.common.cli.CliToolConfig.Builder.cmd;
-import static org.hamcrest.Matchers.arrayContaining;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.hasItem;
-import static org.hamcrest.Matchers.hasSize;
-import static org.hamcrest.Matchers.is;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -392,11 +387,11 @@ public class CliToolTests extends CliToolTestCase {
             super(CliToolConfig.config(name, MultiCmdTool.class)
                     .cmds(cmds(commands))
                     .build(), terminal);
-            Map<String, Command> commandByName = new HashMap<>();
+            ImmutableMap.Builder<String, Command> commandByName = ImmutableMap.builder();
             for (int i = 0; i < commands.length; i++) {
                 commandByName.put(commands[i].name, commands[i]);
             }
-            this.commands = unmodifiableMap(commandByName);
+            this.commands = commandByName.build();
         }
 
         @Override
diff --git a/core/src/test/java/org/elasticsearch/common/collect/CopyOnWriteHashMapTests.java b/core/src/test/java/org/elasticsearch/common/collect/CopyOnWriteHashMapTests.java
index d35b540..f6372e5 100644
--- a/core/src/test/java/org/elasticsearch/common/collect/CopyOnWriteHashMapTests.java
+++ b/core/src/test/java/org/elasticsearch/common/collect/CopyOnWriteHashMapTests.java
@@ -19,13 +19,12 @@
 
 package org.elasticsearch.common.collect;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.test.ESTestCase;
 
 import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-
 public class CopyOnWriteHashMapTests extends ESTestCase {
 
     private static class O {
@@ -95,7 +94,7 @@ public class CopyOnWriteHashMapTests extends ESTestCase {
                 map = newMap;
             }
             assertEquals(ref, CopyOnWriteHashMap.copyOf(ref));
-            assertEquals(emptyMap(), CopyOnWriteHashMap.copyOf(ref).copyAndRemoveAll(ref.keySet()));
+            assertEquals(ImmutableMap.of(), CopyOnWriteHashMap.copyOf(ref).copyAndRemoveAll(ref.keySet()));
         }
     }
 
@@ -141,7 +140,7 @@ public class CopyOnWriteHashMapTests extends ESTestCase {
         } catch (IllegalArgumentException e) {
             // expected
         }
-
+        
         try {
             new CopyOnWriteHashMap<>().copyAndPut(null, "b");
             fail();
diff --git a/core/src/test/java/org/elasticsearch/common/logging/log4j/Log4jESLoggerTests.java b/core/src/test/java/org/elasticsearch/common/logging/log4j/Log4jESLoggerTests.java
index c1bdf00..d0cd387 100644
--- a/core/src/test/java/org/elasticsearch/common/logging/log4j/Log4jESLoggerTests.java
+++ b/core/src/test/java/org/elasticsearch/common/logging/log4j/Log4jESLoggerTests.java
@@ -57,7 +57,7 @@ public class Log4jESLoggerTests extends ESTestCase {
                 .put("path.conf", configDir.toAbsolutePath())
                 .put("path.home", createTempDir().toString())
                 .build();
-        LogConfigurator.configure(settings);
+        LogConfigurator.configure(settings, true);
 
         esTestLogger = Log4jESLoggerFactory.getLogger("test");
         Logger testLogger = ((Log4jESLogger) esTestLogger).logger();
diff --git a/core/src/test/java/org/elasticsearch/common/logging/log4j/LoggingConfigurationTests.java b/core/src/test/java/org/elasticsearch/common/logging/log4j/LoggingConfigurationTests.java
index 199f94c..2b84bec 100644
--- a/core/src/test/java/org/elasticsearch/common/logging/log4j/LoggingConfigurationTests.java
+++ b/core/src/test/java/org/elasticsearch/common/logging/log4j/LoggingConfigurationTests.java
@@ -32,8 +32,10 @@ import org.junit.Test;
 
 import java.nio.charset.StandardCharsets;
 import java.nio.file.Files;
+import java.nio.file.OpenOption;
 import java.nio.file.Path;
 import java.nio.file.StandardOpenOption;
+import java.util.Arrays;
 
 import static org.hamcrest.Matchers.*;
 
@@ -56,7 +58,7 @@ public class LoggingConfigurationTests extends ESTestCase {
                     .put("path.conf", configDir.toAbsolutePath())
                     .put("path.home", createTempDir().toString())
                     .build();
-            LogConfigurator.configure(settings);
+            LogConfigurator.configure(settings, true);
 
             ESLogger esLogger = Log4jESLoggerFactory.getLogger("test");
             Logger logger = ((Log4jESLogger) esLogger).logger();
@@ -157,20 +159,20 @@ public class LoggingConfigurationTests extends ESTestCase {
     public void testResolveOrder() throws Exception {
         Path tmpDir = createTempDir();
         Path loggingConf = tmpDir.resolve(loggingConfiguration("yaml"));
-        Files.write(loggingConf, "logger.test: INFO, file\n".getBytes(StandardCharsets.UTF_8));
+        Files.write(loggingConf, "logger.test_resolve_order: INFO, file\n".getBytes(StandardCharsets.UTF_8));
         Files.write(loggingConf, "appender.file.type: file\n".getBytes(StandardCharsets.UTF_8), StandardOpenOption.APPEND);
         Environment environment = InternalSettingsPreparer.prepareEnvironment(
                 Settings.builder()
                         .put("path.conf", tmpDir.toAbsolutePath())
                         .put("path.home", createTempDir().toString())
-                        .put("logger.test", "TRACE, console")
+                        .put("logger.test_resolve_order", "TRACE, console")
                         .put("appender.console.type", "console")
                         .put("appender.console.layout.type", "consolePattern")
                         .put("appender.console.layout.conversionPattern", "[%d{ISO8601}][%-5p][%-25c] %m%n")
                         .build(), new CliToolTestCase.MockTerminal());
-        LogConfigurator.configure(environment.settings());
+        LogConfigurator.configure(environment.settings(), true);
         // args should overwrite whatever is in the config
-        ESLogger esLogger = Log4jESLoggerFactory.getLogger("test");
+        ESLogger esLogger = Log4jESLoggerFactory.getLogger("test_resolve_order");
         Logger logger = ((Log4jESLogger) esLogger).logger();
         Appender appender = logger.getAppender("console");
         assertThat(appender, notNullValue());
@@ -179,6 +181,31 @@ public class LoggingConfigurationTests extends ESTestCase {
         assertThat(appender, nullValue());
     }
 
+    // tests that config file is not read when we call LogConfigurator.configure(Settings, false)
+    @Test
+    public void testConfigNotRead() throws Exception {
+        Path tmpDir = createTempDir();
+        Path loggingConf = tmpDir.resolve(loggingConfiguration("yaml"));
+        Files.write(loggingConf,
+                Arrays.asList(
+                        "logger.test_config_not_read: INFO, console",
+                        "appender.console.type: console"),
+                StandardCharsets.UTF_8);
+        Environment environment = InternalSettingsPreparer.prepareEnvironment(
+                Settings.builder()
+                        .put("path.conf", tmpDir.toAbsolutePath())
+                        .put("path.home", createTempDir().toString())
+                        .build(), new CliToolTestCase.MockTerminal());
+        LogConfigurator.configure(environment.settings(), false);
+        ESLogger esLogger = Log4jESLoggerFactory.getLogger("test_config_not_read");
+
+        assertNotNull(esLogger);
+        Logger logger = ((Log4jESLogger) esLogger).logger();
+        Appender appender = logger.getAppender("console");
+        // config was not read
+        assertNull(appender);
+    }
+
     private static String loggingConfiguration(String suffix) {
         return "logging." + randomAsciiOfLength(randomIntBetween(0, 10)) + "." + suffix;
     }
diff --git a/core/src/test/java/org/elasticsearch/common/lucene/uid/VersionsTests.java b/core/src/test/java/org/elasticsearch/common/lucene/uid/VersionsTests.java
index 98a4364..290af55 100644
--- a/core/src/test/java/org/elasticsearch/common/lucene/uid/VersionsTests.java
+++ b/core/src/test/java/org/elasticsearch/common/lucene/uid/VersionsTests.java
@@ -18,25 +18,16 @@
  */
 package org.elasticsearch.common.lucene.uid;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.core.KeywordAnalyzer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
+import org.apache.lucene.document.*;
 import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.NumericDocValuesField;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexOptions;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.NumericDocValues;
-import org.apache.lucene.index.SlowCompositeReaderWrapper;
-import org.apache.lucene.index.Term;
+import org.apache.lucene.index.*;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.Numbers;
@@ -50,17 +41,13 @@ import org.junit.Test;
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.*;
 
 public class VersionsTests extends ESTestCase {
-
+    
     public static DirectoryReader reopen(DirectoryReader reader) throws IOException {
         return reopen(reader, true);
     }
@@ -112,7 +99,7 @@ public class VersionsTests extends ESTestCase {
         doc.add(uid);
         doc.add(version);
         writer.updateDocument(new Term(UidFieldMapper.NAME, "1"), doc);
-
+        
         directoryReader = reopen(directoryReader);
         assertThat(Versions.loadVersion(directoryReader, new Term(UidFieldMapper.NAME, "1")), equalTo(3l));
         assertThat(Versions.loadDocIdAndVersion(directoryReader, new Term(UidFieldMapper.NAME, "1")).version, equalTo(3l));
@@ -274,13 +261,8 @@ public class VersionsTests extends ESTestCase {
         iw.addDocument(document);
         iw.commit();
 
-        Map<String, Long> expectedVersions = new HashMap<>();
-        expectedVersions.put("1", 0L);
-        expectedVersions.put("2", 0L);
-        expectedVersions.put("3", 0L);
-        expectedVersions.put("4", 4L);
-        expectedVersions.put("5", 5L);
-        expectedVersions.put("6", 6L);
+        final Map<String, Long> expectedVersions = ImmutableMap.<String, Long>builder()
+                .put("1", 0L).put("2", 0L).put("3", 0L).put("4", 4L).put("5", 5L).put("6", 6L).build();
 
         // Force merge and check versions
         iw.forceMerge(1, true);
diff --git a/core/src/test/java/org/elasticsearch/common/path/PathTrieTests.java b/core/src/test/java/org/elasticsearch/common/path/PathTrieTests.java
index 1309b58..aec4fb2 100644
--- a/core/src/test/java/org/elasticsearch/common/path/PathTrieTests.java
+++ b/core/src/test/java/org/elasticsearch/common/path/PathTrieTests.java
@@ -20,6 +20,7 @@
 package org.elasticsearch.common.path;
 
 import org.elasticsearch.test.ESTestCase;
+import org.junit.Test;
 
 import java.util.HashMap;
 import java.util.Map;
diff --git a/core/src/test/java/org/elasticsearch/common/xcontent/support/XContentMapValuesTests.java b/core/src/test/java/org/elasticsearch/common/xcontent/support/XContentMapValuesTests.java
index abce42b..ba34812 100644
--- a/core/src/test/java/org/elasticsearch/common/xcontent/support/XContentMapValuesTests.java
+++ b/core/src/test/java/org/elasticsearch/common/xcontent/support/XContentMapValuesTests.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.common.xcontent.support;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.common.Strings;
 import org.elasticsearch.common.collect.Tuple;
 import org.elasticsearch.common.xcontent.XContentBuilder;
@@ -37,12 +39,7 @@ import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.singletonMap;
-import static org.hamcrest.Matchers.hasEntry;
-import static org.hamcrest.Matchers.hasKey;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.*;
 import static org.hamcrest.core.IsEqual.equalTo;
 
 /**
@@ -564,7 +561,7 @@ public class XContentMapValuesTests extends ESTestCase {
                 assertEquals(XContentParser.Token.START_ARRAY, parser.nextToken());
             }
             assertEquals(
-                    Arrays.asList(singletonMap("foo", "bar"), emptyMap()),
+                    Arrays.asList(ImmutableMap.of("foo", "bar"), Collections.<String, Object>emptyMap()),
                     parser.list());
         }
     }
diff --git a/core/src/test/java/org/elasticsearch/discovery/ZenFaultDetectionTests.java b/core/src/test/java/org/elasticsearch/discovery/ZenFaultDetectionTests.java
index 9d1ce5c..a39b154 100644
--- a/core/src/test/java/org/elasticsearch/discovery/ZenFaultDetectionTests.java
+++ b/core/src/test/java/org/elasticsearch/discovery/ZenFaultDetectionTests.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.discovery;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterName;
 import org.elasticsearch.cluster.ClusterState;
@@ -44,7 +45,6 @@ import org.junit.Test;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
-import static java.util.Collections.emptyMap;
 import static org.hamcrest.Matchers.equalTo;
 
 public class ZenFaultDetectionTests extends ESTestCase {
@@ -65,9 +65,9 @@ public class ZenFaultDetectionTests extends ESTestCase {
         super.setUp();
         threadPool = new ThreadPool(getClass().getName());
         serviceA = build(Settings.builder().put("name", "TS_A").build(), version0);
-        nodeA = new DiscoveryNode("TS_A", "TS_A", serviceA.boundAddress().publishAddress(), emptyMap(), version0);
+        nodeA = new DiscoveryNode("TS_A", "TS_A", serviceA.boundAddress().publishAddress(), ImmutableMap.<String, String>of(), version0);
         serviceB = build(Settings.builder().put("name", "TS_B").build(), version1);
-        nodeB = new DiscoveryNode("TS_B", "TS_B", serviceB.boundAddress().publishAddress(), emptyMap(), version1);
+        nodeB = new DiscoveryNode("TS_B", "TS_B", serviceB.boundAddress().publishAddress(), ImmutableMap.<String, String>of(), version1);
 
         // wait till all nodes are properly connected and the event has been sent, so tests in this class
         // will not get this callback called on the connections done in this setup
diff --git a/core/src/test/java/org/elasticsearch/gateway/ReplicaShardAllocatorTests.java b/core/src/test/java/org/elasticsearch/gateway/ReplicaShardAllocatorTests.java
index e692b62..2b4ccf7 100644
--- a/core/src/test/java/org/elasticsearch/gateway/ReplicaShardAllocatorTests.java
+++ b/core/src/test/java/org/elasticsearch/gateway/ReplicaShardAllocatorTests.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.gateway;
 
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
-
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.ClusterInfo;
 import org.elasticsearch.cluster.ClusterState;
@@ -28,15 +27,7 @@ import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MetaData;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import org.elasticsearch.cluster.routing.IndexRoutingTable;
-import org.elasticsearch.cluster.routing.IndexShardRoutingTable;
-import org.elasticsearch.cluster.routing.RoutingNode;
-import org.elasticsearch.cluster.routing.RoutingNodes;
-import org.elasticsearch.cluster.routing.RoutingTable;
-import org.elasticsearch.cluster.routing.ShardRouting;
-import org.elasticsearch.cluster.routing.ShardRoutingState;
-import org.elasticsearch.cluster.routing.TestShardRouting;
-import org.elasticsearch.cluster.routing.UnassignedInfo;
+import org.elasticsearch.cluster.routing.*;
 import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;
 import org.elasticsearch.cluster.routing.allocation.decider.AllocationDecider;
 import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;
@@ -58,7 +49,6 @@ import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicBoolean;
 
-import static java.util.Collections.unmodifiableMap;
 import static org.hamcrest.Matchers.equalTo;
 
 /**
@@ -368,8 +358,7 @@ public class ReplicaShardAllocatorTests extends ESAllocationTestCase {
             if (syncId != null) {
                 commitData.put(Engine.SYNC_COMMIT_ID, syncId);
             }
-            data.put(node, new TransportNodesListShardStoreMetaData.StoreFilesMetaData(allocated, shardId,
-                    new Store.MetadataSnapshot(unmodifiableMap(filesAsMap), unmodifiableMap(commitData), randomInt())));
+            data.put(node, new TransportNodesListShardStoreMetaData.StoreFilesMetaData(allocated, shardId, new Store.MetadataSnapshot(filesAsMap, commitData, randomInt())));
             return this;
         }
 
diff --git a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
index e603254..4b7de9b 100644
--- a/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.engine;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.log4j.AppenderSkeleton;
 import org.apache.log4j.Level;
 import org.apache.log4j.LogManager;
@@ -28,16 +29,7 @@ import org.apache.lucene.codecs.Codec;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.TextField;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.KeepOnlyLastCommitDeletionPolicy;
-import org.apache.lucene.index.LiveIndexWriterConfig;
-import org.apache.lucene.index.LogByteSizeMergePolicy;
-import org.apache.lucene.index.MergePolicy;
-import org.apache.lucene.index.NoMergePolicy;
-import org.apache.lucene.index.SnapshotDeletionPolicy;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.index.TieredMergePolicy;
+import org.apache.lucene.index.*;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.TermQuery;
@@ -69,17 +61,9 @@ import org.elasticsearch.index.analysis.AnalysisService;
 import org.elasticsearch.index.codec.CodecService;
 import org.elasticsearch.index.engine.Engine.Searcher;
 import org.elasticsearch.index.indexing.ShardIndexingService;
-import org.elasticsearch.index.mapper.ContentPath;
-import org.elasticsearch.index.mapper.DocumentMapper;
-import org.elasticsearch.index.mapper.DocumentMapperForType;
-import org.elasticsearch.index.mapper.DocumentMapperParser;
+import org.elasticsearch.index.mapper.*;
 import org.elasticsearch.index.mapper.Mapper.BuilderContext;
-import org.elasticsearch.index.mapper.MapperBuilders;
-import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.mapper.Mapping;
-import org.elasticsearch.index.mapper.MetadataFieldMapper;
 import org.elasticsearch.index.mapper.ParseContext.Document;
-import org.elasticsearch.index.mapper.ParsedDocument;
 import org.elasticsearch.index.mapper.internal.SourceFieldMapper;
 import org.elasticsearch.index.mapper.internal.UidFieldMapper;
 import org.elasticsearch.index.mapper.object.RootObjectMapper;
@@ -105,13 +89,7 @@ import java.nio.charset.Charset;
 import java.nio.file.DirectoryStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
+import java.util.*;
 import java.util.concurrent.BrokenBarrierException;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.CyclicBarrier;
@@ -120,16 +98,10 @@ import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.regex.Pattern;
 
-import static java.util.Collections.emptyMap;
 import static org.elasticsearch.common.settings.Settings.Builder.EMPTY_SETTINGS;
 import static org.elasticsearch.index.engine.Engine.Operation.Origin.PRIMARY;
 import static org.elasticsearch.index.engine.Engine.Operation.Origin.REPLICA;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.hasKey;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.*;
 
 public class InternalEngineTests extends ESTestCase {
 
@@ -1048,7 +1020,6 @@ public class InternalEngineTests extends ESTestCase {
                 final CountDownLatch indexed = new CountDownLatch(1);
 
                 Thread thread = new Thread() {
-                    @Override
                     public void run() {
                         try {
                             try {
@@ -1717,7 +1688,7 @@ public class InternalEngineTests extends ESTestCase {
     private Mapping dynamicUpdate() {
         BuilderContext context = new BuilderContext(Settings.EMPTY, new ContentPath());
         final RootObjectMapper root = MapperBuilders.rootObject("some_type").build(context);
-        return new Mapping(Version.CURRENT, root, new MetadataFieldMapper[0], new Mapping.SourceTransform[0], emptyMap());
+        return new Mapping(Version.CURRENT, root, new MetadataFieldMapper[0], new Mapping.SourceTransform[0], ImmutableMap.<String, Object>of());
     }
 
     public void testUpgradeOldIndex() throws IOException {
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/DynamicMappingTests.java b/core/src/test/java/org/elasticsearch/index/mapper/DynamicMappingTests.java
index 8326287..f989467 100644
--- a/core/src/test/java/org/elasticsearch/index/mapper/DynamicMappingTests.java
+++ b/core/src/test/java/org/elasticsearch/index/mapper/DynamicMappingTests.java
@@ -18,15 +18,12 @@
  */
 package org.elasticsearch.index.mapper;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.action.admin.indices.mapping.get.GetMappingsResponse;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.ToXContent;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.common.xcontent.XContentHelper;
-import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.mapper.core.IntegerFieldMapper;
 import org.elasticsearch.index.mapper.core.StringFieldMapper;
@@ -34,7 +31,6 @@ import org.elasticsearch.test.ESSingleNodeTestCase;
 
 import java.io.IOException;
 
-import static java.util.Collections.emptyMap;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.nullValue;
@@ -190,7 +186,7 @@ public class DynamicMappingTests extends ESSingleNodeTestCase {
 
     private String serialize(ToXContent mapper) throws Exception {
         XContentBuilder builder = XContentFactory.jsonBuilder().startObject();
-        mapper.toXContent(builder, new ToXContent.MapParams(emptyMap()));
+        mapper.toXContent(builder, new ToXContent.MapParams(ImmutableMap.<String, String>of()));
         return builder.endObject().string();
     }
 
@@ -325,7 +321,7 @@ public class DynamicMappingTests extends ESSingleNodeTestCase {
         String mapping = XContentFactory.jsonBuilder().startObject().startObject("type") .startObject("properties")
                 .startObject("foo").field("type", "object").endObject()
                 .endObject().endObject().endObject().string();
-
+        
         DocumentMapper mapper = parser.parse(mapping);
         assertEquals(mapping, serialize(mapper));
 
diff --git a/core/src/test/java/org/elasticsearch/index/mapper/string/SimpleStringMappingTests.java b/core/src/test/java/org/elasticsearch/index/mapper/string/SimpleStringMappingTests.java
index a54b63d..e6b08fb 100644
--- a/core/src/test/java/org/elasticsearch/index/mapper/string/SimpleStringMappingTests.java
+++ b/core/src/test/java/org/elasticsearch/index/mapper/string/SimpleStringMappingTests.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.index.mapper.string;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.index.DocValuesType;
 import org.apache.lucene.index.IndexOptions;
 import org.apache.lucene.index.IndexableField;
@@ -43,7 +44,6 @@ import org.elasticsearch.index.mapper.MergeResult;
 import org.elasticsearch.index.mapper.ParseContext.Document;
 import org.elasticsearch.index.mapper.ParsedDocument;
 import org.elasticsearch.index.mapper.core.StringFieldMapper;
-import org.elasticsearch.index.mapper.core.StringFieldMapper.Builder;
 import org.elasticsearch.test.ESSingleNodeTestCase;
 import org.elasticsearch.test.VersionUtils;
 import org.junit.Before;
@@ -52,11 +52,8 @@ import org.junit.Test;
 import java.util.Arrays;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.elasticsearch.index.mapper.core.StringFieldMapper.Builder;
+import static org.hamcrest.Matchers.*;
 
 /**
  */
@@ -124,7 +121,7 @@ public class SimpleStringMappingTests extends ESSingleNodeTestCase {
     }
 
     private void assertParseIdemPotent(IndexableFieldType expected, DocumentMapper mapper) throws Exception {
-        String mapping = mapper.toXContent(XContentFactory.jsonBuilder().startObject(), new ToXContent.MapParams(emptyMap())).endObject().string();
+        String mapping = mapper.toXContent(XContentFactory.jsonBuilder().startObject(), new ToXContent.MapParams(ImmutableMap.<String, String>of())).endObject().string();
         mapper = parser.parse(mapping);
         ParsedDocument doc = mapper.parse("test", "type", "1", XContentFactory.jsonBuilder()
                 .startObject()
@@ -217,7 +214,7 @@ public class SimpleStringMappingTests extends ESSingleNodeTestCase {
         assertThat(fieldType.omitNorms(), equalTo(false));
         assertParseIdemPotent(fieldType, defaultMapper);
     }
-
+    
     @Test
     public void testSearchQuoteAnalyzerSerialization() throws Exception {
         // Cases where search_quote_analyzer should not be added to the mapping.
@@ -253,7 +250,7 @@ public class SimpleStringMappingTests extends ESSingleNodeTestCase {
             Map<String, Object> serializedMap = getSerializedMap(fieldName, mapper);
             assertFalse(fieldName, serializedMap.containsKey("search_quote_analyzer"));
         }
-
+        
         // Cases where search_quote_analyzer should be present.
         mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                 .startObject("properties")
@@ -271,20 +268,20 @@ public class SimpleStringMappingTests extends ESSingleNodeTestCase {
                 .endObject()
                 .endObject()
                 .endObject().endObject().string();
-
+        
         mapper = parser.parse(mapping);
         for (String fieldName : Arrays.asList("field1", "field2")) {
             Map<String, Object> serializedMap = getSerializedMap(fieldName, mapper);
             assertEquals(serializedMap.get("search_quote_analyzer"), "simple");
         }
     }
-
+    
     private Map<String, Object> getSerializedMap(String fieldName, DocumentMapper mapper) throws Exception {
         FieldMapper fieldMapper = mapper.mappers().smartNameFieldMapper(fieldName);
         XContentBuilder builder = JsonXContent.contentBuilder().startObject();
         fieldMapper.toXContent(builder, ToXContent.EMPTY_PARAMS).endObject();
         builder.close();
-
+        
         Map<String, Object> fieldMap;
         try (XContentParser parser = JsonXContent.jsonXContent.createParser(builder.bytes())) {
             fieldMap = parser.map();
@@ -467,7 +464,7 @@ public class SimpleStringMappingTests extends ESSingleNodeTestCase {
         assertEquals(DocValuesType.NONE, docValuesType(doc, "str3"));
         assertEquals(DocValuesType.NONE, docValuesType(doc, "str4"));
         assertEquals(DocValuesType.SORTED_SET, docValuesType(doc, "str5"));
-
+        
     }
 
     // TODO: this function shouldn't be necessary.  parsing should just add a single field that is indexed and dv
diff --git a/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java b/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java
index a4ac66c..0a2034d 100644
--- a/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java
+++ b/core/src/test/java/org/elasticsearch/index/query/GeoShapeQueryBuilderTests.java
@@ -77,10 +77,12 @@ public class GeoShapeQueryBuilderTests extends AbstractQueryTestCase<GeoShapeQue
                 builder.indexedShapePath(indexedShapePath);
             }
         }
-        SpatialStrategy strategy = randomFrom(SpatialStrategy.values());
-        builder.strategy(strategy);
-        if (strategy != SpatialStrategy.TERM) {
-            builder.relation(randomFrom(ShapeRelation.values()));
+        if (randomBoolean()) {
+            SpatialStrategy strategy = randomFrom(SpatialStrategy.values());
+            builder.strategy(strategy);
+            if (strategy != SpatialStrategy.TERM) {
+                builder.relation(randomFrom(ShapeRelation.values()));
+            }
         }
         return builder;
     }
@@ -105,9 +107,7 @@ public class GeoShapeQueryBuilderTests extends AbstractQueryTestCase<GeoShapeQue
         } catch (IOException ex) {
             throw new ElasticsearchException("boom", ex);
         }
-        GetResponse response = new GetResponse(new GetResult(indexedShapeIndex, indexedShapeType, indexedShapeId, 0, true, new BytesArray(
-                json), null));
-        return response;
+        return new GetResponse(new GetResult(indexedShapeIndex, indexedShapeType, indexedShapeId, 0, true, new BytesArray(json), null));
     }
 
     @After
@@ -149,7 +149,7 @@ public class GeoShapeQueryBuilderTests extends AbstractQueryTestCase<GeoShapeQue
     @Test
     public void testNoShape() throws IOException {
         try {
-            GeoShapeQueryBuilder builder = new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, (ShapeBuilder) null);
+            new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, (ShapeBuilder) null);
             fail("exception expected");
         } catch (IllegalArgumentException e) {
             // expected
@@ -158,12 +158,12 @@ public class GeoShapeQueryBuilderTests extends AbstractQueryTestCase<GeoShapeQue
 
     @Test(expected = IllegalArgumentException.class)
     public void testNoIndexedShape() throws IOException {
-        new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, (String) null, "type");
+        new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, null, "type");
     }
 
     @Test(expected = IllegalArgumentException.class)
     public void testNoIndexedShapeType() throws IOException {
-        new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, "id", (String) null);
+        new GeoShapeQueryBuilder(GEO_SHAPE_FIELD_NAME, "id", null);
     }
 
     @Test(expected=IllegalArgumentException.class)
diff --git a/core/src/test/java/org/elasticsearch/index/store/StoreTests.java b/core/src/test/java/org/elasticsearch/index/store/StoreTests.java
index 123e4e0..11d01c9 100644
--- a/core/src/test/java/org/elasticsearch/index/store/StoreTests.java
+++ b/core/src/test/java/org/elasticsearch/index/store/StoreTests.java
@@ -24,35 +24,9 @@ import org.apache.lucene.codecs.FilterCodec;
 import org.apache.lucene.codecs.SegmentInfoFormat;
 import org.apache.lucene.codecs.lucene50.Lucene50SegmentInfoFormat;
 import org.apache.lucene.codecs.lucene53.Lucene53Codec;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.SortedDocValuesField;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.document.TextField;
-import org.apache.lucene.index.CorruptIndexException;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexFileNames;
-import org.apache.lucene.index.IndexFormatTooNewException;
-import org.apache.lucene.index.IndexFormatTooOldException;
-import org.apache.lucene.index.IndexNotFoundException;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.KeepOnlyLastCommitDeletionPolicy;
-import org.apache.lucene.index.NoDeletionPolicy;
-import org.apache.lucene.index.NoMergePolicy;
-import org.apache.lucene.index.SegmentInfo;
-import org.apache.lucene.index.SegmentInfos;
-import org.apache.lucene.index.SnapshotDeletionPolicy;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.store.AlreadyClosedException;
-import org.apache.lucene.store.BaseDirectoryWrapper;
-import org.apache.lucene.store.ChecksumIndexInput;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.IOContext;
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.store.IndexOutput;
-import org.apache.lucene.store.MockDirectoryWrapper;
-import org.apache.lucene.store.RAMDirectory;
+import org.apache.lucene.document.*;
+import org.apache.lucene.index.*;
+import org.apache.lucene.store.*;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.TestUtil;
@@ -81,30 +55,14 @@ import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.nio.file.NoSuchFileException;
 import java.nio.file.Path;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Date;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.zip.Adler32;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.unmodifiableMap;
+import static org.elasticsearch.common.settings.Settings.Builder.EMPTY_SETTINGS;
 import static org.elasticsearch.test.VersionUtils.randomVersion;
-import static org.hamcrest.Matchers.empty;
-import static org.hamcrest.Matchers.endsWith;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.hamcrest.Matchers.*;
 
 public class StoreTests extends ESTestCase {
 
@@ -848,9 +806,9 @@ public class StoreTests extends ESTestCase {
         Map<String, StoreFileMetaData> metaDataMap = new HashMap<>();
         metaDataMap.put("segments_1", new StoreFileMetaData("segments_1", 50, null, null, new BytesRef(new byte[]{1})));
         metaDataMap.put("_0_1.del", new StoreFileMetaData("_0_1.del", 42, "foobarbaz", null, new BytesRef()));
-        Store.MetadataSnapshot first = new Store.MetadataSnapshot(unmodifiableMap(new HashMap<>(metaDataMap)), emptyMap(), 0);
+        Store.MetadataSnapshot first = new Store.MetadataSnapshot(metaDataMap, Collections.EMPTY_MAP, 0);
 
-        Store.MetadataSnapshot second = new Store.MetadataSnapshot(unmodifiableMap(new HashMap<>(metaDataMap)), emptyMap(), 0);
+        Store.MetadataSnapshot second = new Store.MetadataSnapshot(metaDataMap, Collections.EMPTY_MAP, 0);
         Store.RecoveryDiff recoveryDiff = first.recoveryDiff(second);
         assertEquals(recoveryDiff.toString(), recoveryDiff.different.size(), 2);
     }
@@ -1116,7 +1074,7 @@ public class StoreTests extends ESTestCase {
         Map<String, StoreFileMetaData> metaDataMap = new HashMap<>();
         metaDataMap.put("segments_1", new StoreFileMetaData("segments_1", 50, null, null, new BytesRef(new byte[]{1})));
         metaDataMap.put("_0_1.del", new StoreFileMetaData("_0_1.del", 42, "foobarbaz", null, new BytesRef()));
-        Store.MetadataSnapshot snapshot = new Store.MetadataSnapshot(unmodifiableMap(metaDataMap), emptyMap(), 0);
+        Store.MetadataSnapshot snapshot = new Store.MetadataSnapshot(metaDataMap, Collections.EMPTY_MAP, 0);
 
         final ShardId shardId = new ShardId(new Index("index"), 1);
         DirectoryService directoryService = new LuceneManagedDirectoryService(random());
@@ -1250,7 +1208,7 @@ public class StoreTests extends ESTestCase {
         Map<String, String> commitUserData = new HashMap<>();
         commitUserData.put("userdata_1", "test");
         commitUserData.put("userdata_2", "test");
-        return new Store.MetadataSnapshot(unmodifiableMap(storeFileMetaDataMap), unmodifiableMap(commitUserData), 0);
+        return new Store.MetadataSnapshot(storeFileMetaDataMap, commitUserData, 0);
     }
 
     @Test
diff --git a/core/src/test/java/org/elasticsearch/indices/IndicesLifecycleListenerIT.java b/core/src/test/java/org/elasticsearch/indices/IndicesLifecycleListenerIT.java
index 1526df3..3e95685 100644
--- a/core/src/test/java/org/elasticsearch/indices/IndicesLifecycleListenerIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/IndicesLifecycleListenerIT.java
@@ -35,8 +35,6 @@ import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.shard.IndexShardState;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.test.ESIntegTestCase;
-import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
-import org.elasticsearch.test.ESIntegTestCase.Scope;
 import org.hamcrest.Matchers;
 import org.junit.Test;
 
@@ -57,6 +55,8 @@ import static org.elasticsearch.index.shard.IndexShardState.CREATED;
 import static org.elasticsearch.index.shard.IndexShardState.POST_RECOVERY;
 import static org.elasticsearch.index.shard.IndexShardState.RECOVERING;
 import static org.elasticsearch.index.shard.IndexShardState.STARTED;
+import static org.elasticsearch.test.ESIntegTestCase.ClusterScope;
+import static org.elasticsearch.test.ESIntegTestCase.Scope;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.hamcrest.CoreMatchers.equalTo;
 import static org.hamcrest.Matchers.greaterThanOrEqualTo;
@@ -105,7 +105,7 @@ public class IndicesLifecycleListenerIT extends ESIntegTestCase {
         } catch (Exception e) {
             assertTrue(e.getMessage().contains("failing on purpose"));
             ClusterStateResponse resp = client().admin().cluster().prepareState().get();
-            assertFalse(resp.getState().routingTable().indicesRouting().keys().contains("failed"));
+            assertFalse(resp.getState().routingTable().indicesRouting().keySet().contains("failed"));
         }
     }
 
@@ -149,7 +149,7 @@ public class IndicesLifecycleListenerIT extends ESIntegTestCase {
         } catch (ElasticsearchException e) {
             assertTrue(e.getMessage().contains("failing on purpose"));
             ClusterStateResponse resp = client().admin().cluster().prepareState().get();
-            assertFalse(resp.getState().routingTable().indicesRouting().keys().contains("failed"));
+            assertFalse(resp.getState().routingTable().indicesRouting().keySet().contains("failed"));
         }
 
 
diff --git a/core/src/test/java/org/elasticsearch/indices/state/RareClusterStateIT.java b/core/src/test/java/org/elasticsearch/indices/state/RareClusterStateIT.java
index dbdfc2b..a1b2508 100644
--- a/core/src/test/java/org/elasticsearch/indices/state/RareClusterStateIT.java
+++ b/core/src/test/java/org/elasticsearch/indices/state/RareClusterStateIT.java
@@ -23,10 +23,7 @@ import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.action.admin.indices.mapping.put.PutMappingResponse;
 import org.elasticsearch.action.index.IndexResponse;
-import org.elasticsearch.cluster.ClusterInfo;
-import org.elasticsearch.cluster.ClusterService;
-import org.elasticsearch.cluster.ClusterState;
-import org.elasticsearch.cluster.ClusterStateUpdateTask;
+import org.elasticsearch.cluster.*;
 import org.elasticsearch.cluster.block.ClusterBlocks;
 import org.elasticsearch.cluster.metadata.IndexMetaData;
 import org.elasticsearch.cluster.metadata.MappingMetaData;
@@ -57,19 +54,12 @@ import org.elasticsearch.test.junit.annotations.TestLogging;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.Arrays;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.atomic.AtomicReference;
 
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.hasItem;
-import static org.hamcrest.Matchers.hasSize;
-import static org.hamcrest.Matchers.instanceOf;
+import static org.hamcrest.Matchers.*;
 
 /**
  */
@@ -98,7 +88,7 @@ public class RareClusterStateIT extends ESIntegTestCase {
         AllocationDeciders allocationDeciders = new AllocationDeciders(Settings.EMPTY, new AllocationDecider[0]);
         RoutingNodes routingNodes = new RoutingNodes(
                 ClusterState.builder(current)
-                        .routingTable(RoutingTable.builder(current.routingTable()).remove("a").addAsRecovery(current.metaData().index("a")).build())
+                        .routingTable(RoutingTable.builder(current.routingTable()).remove("a").addAsRecovery(current.metaData().index("a")))
                         .nodes(DiscoveryNodes.EMPTY_NODES)
                         .build(), false
         );
@@ -137,7 +127,7 @@ public class RareClusterStateIT extends ESIntegTestCase {
 
                 RoutingTable.Builder routingTable = RoutingTable.builder(updatedState.routingTable());
                 routingTable.addAsRecovery(updatedState.metaData().index(index));
-                updatedState = ClusterState.builder(updatedState).routingTable(routingTable.build()).build();
+                updatedState = ClusterState.builder(updatedState).routingTable(routingTable).build();
 
                 RoutingAllocation.Result result = allocationService.reroute(updatedState);
                 return ClusterState.builder(updatedState).routingResult(result).build();
diff --git a/core/src/test/java/org/elasticsearch/routing/AliasRoutingIT.java b/core/src/test/java/org/elasticsearch/routing/AliasRoutingIT.java
new file mode 100644
index 0000000..c418f68
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/routing/AliasRoutingIT.java
@@ -0,0 +1,354 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.routing;
+
+import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.action.search.SearchType;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.index.query.QueryBuilders;
+import org.elasticsearch.test.ESIntegTestCase;
+import org.junit.Test;
+
+import static org.elasticsearch.cluster.metadata.AliasAction.newAddAliasAction;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
+import static org.hamcrest.Matchers.equalTo;
+
+/**
+ *
+ */
+public class AliasRoutingIT extends ESIntegTestCase {
+
+    @Override
+    protected int minimumNumberOfShards() {
+        return 2;
+    }
+
+    @Test
+    public void testAliasCrudRouting() throws Exception {
+        createIndex("test");
+        ensureGreen();
+        assertAcked(admin().indices().prepareAliases().addAliasAction(newAddAliasAction("test", "alias0").routing("0")));
+
+        logger.info("--> indexing with id [1], and routing [0] using alias");
+        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+        logger.info("--> verifying get with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
+        }
+
+        logger.info("--> verifying get with routing alias, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+
+        logger.info("--> updating with id [1] and routing through alias");
+        client().prepareUpdate("alias0", "type1", "1")
+                .setUpsert(XContentFactory.jsonBuilder().startObject().field("field", 1).endObject())
+                .setDoc("field", "value2")
+                .execute().actionGet();
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().getSourceAsMap().get("field").toString(), equalTo("value2"));
+        }
+
+
+        logger.info("--> deleting with no routing, should not delete anything");
+        client().prepareDelete("test", "type1", "1").setRefresh(true).execute().actionGet();
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+
+        logger.info("--> deleting with routing alias, should delete");
+        client().prepareDelete("alias0", "type1", "1").setRefresh(true).execute().actionGet();
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(false));
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+
+        logger.info("--> indexing with id [1], and routing [0] using alias");
+        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+        logger.info("--> verifying get with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+    }
+
+    @Test
+    public void testAliasSearchRouting() throws Exception {
+        createIndex("test");
+        ensureGreen();
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("test", "alias"))
+                .addAliasAction(newAddAliasAction("test", "alias0").routing("0"))
+                .addAliasAction(newAddAliasAction("test", "alias1").routing("1"))
+                .addAliasAction(newAddAliasAction("test", "alias01").searchRouting("0,1")));
+
+        logger.info("--> indexing with id [1], and routing [0] using alias");
+        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+        logger.info("--> verifying get with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+
+        logger.info("--> search with no routing, should fine one");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+        }
+
+        logger.info("--> search with wrong routing, should not find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
+            assertThat(client().prepareCount().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
+            assertThat(client().prepareSearch("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
+            assertThat(client().prepareCount("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
+        }
+
+        logger.info("--> search with correct routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+            assertThat(client().prepareSearch("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+        }
+
+        logger.info("--> indexing with id [2], and routing [1] using alias");
+        client().prepareIndex("alias1", "type1", "2").setSource("field", "value1").setRefresh(true).execute().actionGet();
+
+        logger.info("--> search with no routing, should fine two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+        logger.info("--> search with 0 routing, should find one");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+            assertThat(client().prepareSearch("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+        }
+
+        logger.info("--> search with 1 routing, should find one");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+            assertThat(client().prepareSearch("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+        }
+
+        logger.info("--> search with 0,1 routings , should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch().setRouting("0", "1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount().setRouting("0", "1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+            assertThat(client().prepareSearch("alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+        logger.info("--> search with two routing aliases , should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+        logger.info("--> search with alias0, alias1 and alias01, should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias0", "alias1", "alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias0", "alias1", "alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+        logger.info("--> search with test, alias0 and alias1, should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("test", "alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("test", "alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+    }
+
+    @Test
+    public void testAliasSearchRoutingWithTwoIndices() throws Exception {
+        createIndex("test-a");
+        createIndex("test-b");
+        ensureGreen();
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("test-a", "alias-a0").routing("0"))
+                .addAliasAction(newAddAliasAction("test-a", "alias-a1").routing("1"))
+                .addAliasAction(newAddAliasAction("test-b", "alias-b0").routing("0"))
+                .addAliasAction(newAddAliasAction("test-b", "alias-b1").routing("1"))
+                .addAliasAction(newAddAliasAction("test-a", "alias-ab").searchRouting("0"))
+                .addAliasAction(newAddAliasAction("test-b", "alias-ab").searchRouting("1")));
+        ensureGreen(); // wait for events again to make sure we got the aliases on all nodes
+        logger.info("--> indexing with id [1], and routing [0] using alias to test-a");
+        client().prepareIndex("alias-a0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test-a", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+        logger.info("--> verifying get with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("alias-a0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+
+        logger.info("--> indexing with id [0], and routing [1] using alias to test-b");
+        client().prepareIndex("alias-b1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test-a", "type1", "1").execute().actionGet().isExists(), equalTo(false));
+        }
+        logger.info("--> verifying get with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("alias-b1", "type1", "1").execute().actionGet().isExists(), equalTo(true));
+        }
+
+
+        logger.info("--> search with alias-a1,alias-b0, should not find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias-a1", "alias-b0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
+            assertThat(client().prepareCount("alias-a1", "alias-b0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
+        }
+
+        logger.info("--> search with alias-ab, should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias-ab").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias-ab").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+
+        logger.info("--> search with alias-a0,alias-b1 should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias-a0", "alias-b1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias-a0", "alias-b1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+    }
+
+    /*
+    See https://github.com/elasticsearch/elasticsearch/issues/2682
+    Searching on more than one index, if one of those is an alias with configured routing, the shards that belonged
+    to the other indices (without routing) were not taken into account in PlainOperationRouting#searchShards.
+    That affected the number of shards that we executed the search on, thus some documents were missing in the search results.
+     */
+    @Test
+    public void testAliasSearchRoutingWithConcreteAndAliasedIndices_issue2682() throws Exception {
+        createIndex("index", "index_2");
+        ensureGreen();
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("index", "index_1").routing("1")));
+
+        logger.info("--> indexing on index_1 which is an alias for index with routing [1]");
+        client().prepareIndex("index_1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> indexing on index_2 which is a concrete index");
+        client().prepareIndex("index_2", "type2", "2").setSource("field", "value2").setRefresh(true).execute().actionGet();
+
+
+        logger.info("--> search all on index_* should find two");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("index_*").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+        }
+    }
+
+    /*
+    See https://github.com/elasticsearch/elasticsearch/pull/3268
+    Searching on more than one index, if one of those is an alias with configured routing, the shards that belonged
+    to the other indices (without routing) were not taken into account in PlainOperationRouting#searchShardsCount.
+    That could cause returning 1, which led to forcing the QUERY_AND_FETCH mode.
+    As a result, (size * number of hit shards) results were returned and no reduce phase was taking place.
+     */
+    @Test
+    public void testAliasSearchRoutingWithConcreteAndAliasedIndices_issue3268() throws Exception {
+        createIndex("index", "index_2");
+        ensureGreen();
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("index", "index_1").routing("1")));
+
+        logger.info("--> indexing on index_1 which is an alias for index with routing [1]");
+        client().prepareIndex("index_1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> indexing on index_2 which is a concrete index");
+        client().prepareIndex("index_2", "type2", "2").setSource("field", "value2").setRefresh(true).execute().actionGet();
+
+        SearchResponse searchResponse = client().prepareSearch("index_*").setSearchType(SearchType.QUERY_THEN_FETCH).setSize(1).setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();
+
+        logger.info("--> search all on index_* should find two");
+        assertThat(searchResponse.getHits().totalHits(), equalTo(2L));
+        //Let's make sure that, even though 2 docs are available, only one is returned according to the size we set in the request
+        //Therefore the reduce phase has taken place, which proves that the QUERY_AND_FETCH search type wasn't erroneously forced.
+        assertThat(searchResponse.getHits().getHits().length, equalTo(1));
+    }
+
+    @Test
+    public void testIndexingAliasesOverTime() throws Exception {
+        createIndex("test");
+        ensureGreen();
+        logger.info("--> creating alias with routing [3]");
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("test", "alias").routing("3")));
+
+        logger.info("--> indexing with id [0], and routing [3]");
+        client().prepareIndex("alias", "type1", "0").setSource("field", "value1").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+
+        logger.info("--> verifying get and search with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "0").setRouting("3").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
+            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
+        }
+
+        logger.info("--> creating alias with routing [4]");
+        assertAcked(admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("test", "alias").routing("4")));
+
+        logger.info("--> verifying search with wrong routing should not find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
+            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
+        }
+
+        logger.info("--> creating alias with search routing [3,4] and index routing 4");
+        assertAcked(client().admin().indices().prepareAliases()
+                .addAliasAction(newAddAliasAction("test", "alias").searchRouting("3,4").indexRouting("4")));
+
+        logger.info("--> indexing with id [1], and routing [4]");
+        client().prepareIndex("alias", "type1", "1").setSource("field", "value2").setRefresh(true).execute().actionGet();
+        logger.info("--> verifying get with no routing, should not find anything");
+
+        logger.info("--> verifying get and search with routing, should find");
+        for (int i = 0; i < 5; i++) {
+            assertThat(client().prepareGet("test", "type1", "0").setRouting("3").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareGet("test", "type1", "1").setRouting("4").execute().actionGet().isExists(), equalTo(true));
+            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
+            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
+        }
+    }
+
+}
diff --git a/core/src/test/java/org/elasticsearch/script/MockScriptEngine.java b/core/src/test/java/org/elasticsearch/script/MockScriptEngine.java
index aa7cd45..1cdac14 100644
--- a/core/src/test/java/org/elasticsearch/script/MockScriptEngine.java
+++ b/core/src/test/java/org/elasticsearch/script/MockScriptEngine.java
@@ -104,16 +104,6 @@ public class MockScriptEngine implements ScriptEngineService {
     }
 
     @Override
-    public Object execute(CompiledScript compiledScript, Map<String, Object> vars) {
-        return null;
-    }
-
-    @Override
-    public Object unwrap(Object value) {
-        return null;
-    }
-
-    @Override
     public void scriptRemoved(@Nullable CompiledScript script) {
     }
 
diff --git a/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java b/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java
index 014f41a..efda8d2 100644
--- a/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java
+++ b/core/src/test/java/org/elasticsearch/script/ScriptModesTests.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.script;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.script.ScriptService.ScriptType;
@@ -36,7 +38,6 @@ import java.util.Map;
 import java.util.Set;
 
 import static java.util.Collections.singleton;
-import static java.util.Collections.unmodifiableMap;
 import static java.util.Collections.unmodifiableSet;
 import static org.elasticsearch.common.util.set.Sets.newHashSet;
 import static org.hamcrest.CoreMatchers.equalTo;
@@ -243,14 +244,14 @@ public class ScriptModesTests extends ESTestCase {
         return ScriptModes.ENGINE_SETTINGS_PREFIX + "." + lang + "." + scriptType + "." + scriptContext.getKey();
     }
 
-    static Map<String, ScriptEngineService> buildScriptEnginesByLangMap(Set<ScriptEngineService> scriptEngines) {
-        Map<String, ScriptEngineService> builder = new HashMap<>();
+    static ImmutableMap<String, ScriptEngineService> buildScriptEnginesByLangMap(Set<ScriptEngineService> scriptEngines) {
+        ImmutableMap.Builder<String, ScriptEngineService> builder = ImmutableMap.builder();
         for (ScriptEngineService scriptEngine : scriptEngines) {
             for (String type : scriptEngine.types()) {
                 builder.put(type, scriptEngine);
             }
         }
-        return unmodifiableMap(builder);
+        return builder.build();
     }
 
     private static class CustomScriptEngineService implements ScriptEngineService {
@@ -285,16 +286,6 @@ public class ScriptModesTests extends ESTestCase {
         }
 
         @Override
-        public Object execute(CompiledScript compiledScript, Map<String, Object> vars) {
-            return null;
-        }
-
-        @Override
-        public Object unwrap(Object value) {
-            return null;
-        }
-
-        @Override
         public void close() {
 
         }
diff --git a/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java b/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java
index a0afe8f..26ba580 100644
--- a/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java
+++ b/core/src/test/java/org/elasticsearch/script/ScriptServiceTests.java
@@ -497,16 +497,6 @@ public class ScriptServiceTests extends ESTestCase {
         }
 
         @Override
-        public Object execute(CompiledScript compiledScript, Map<String, Object> vars) {
-            return null;
-        }
-
-        @Override
-        public Object unwrap(Object value) {
-            return null;
-        }
-
-        @Override
         public void close() {
 
         }
diff --git a/core/src/test/java/org/elasticsearch/script/mustache/MustacheScriptEngineTests.java b/core/src/test/java/org/elasticsearch/script/mustache/MustacheScriptEngineTests.java
index b44d180..28ae808 100644
--- a/core/src/test/java/org/elasticsearch/script/mustache/MustacheScriptEngineTests.java
+++ b/core/src/test/java/org/elasticsearch/script/mustache/MustacheScriptEngineTests.java
@@ -54,7 +54,7 @@ public class MustacheScriptEngineTests extends ESTestCase {
                     + "\"negative\": {\"term\": {\"body\": {\"value\": \"solr\"}" + "}}, \"negative_boost\": {{boost_val}} } }}";
             Map<String, Object> vars = new HashMap<>();
             vars.put("boost_val", "0.3");
-            BytesReference o = (BytesReference) qe.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "", "mustache", qe.compile(template)), vars);
+            BytesReference o = (BytesReference) qe.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "", "mustache", qe.compile(template)), vars).run();
             assertEquals("GET _search {\"query\": {\"boosting\": {\"positive\": {\"match\": {\"body\": \"gift\"}},"
                     + "\"negative\": {\"term\": {\"body\": {\"value\": \"solr\"}}}, \"negative_boost\": 0.3 } }}",
                     new String(o.toBytes(), Charset.forName("UTF-8")));
@@ -65,7 +65,7 @@ public class MustacheScriptEngineTests extends ESTestCase {
             Map<String, Object> vars = new HashMap<>();
             vars.put("boost_val", "0.3");
             vars.put("body_val", "\"quick brown\"");
-            BytesReference o = (BytesReference) qe.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "", "mustache", qe.compile(template)), vars);
+            BytesReference o = (BytesReference) qe.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "", "mustache", qe.compile(template)), vars).run();
             assertEquals("GET _search {\"query\": {\"boosting\": {\"positive\": {\"match\": {\"body\": \"gift\"}},"
                     + "\"negative\": {\"term\": {\"body\": {\"value\": \"\\\"quick brown\\\"\"}}}, \"negative_boost\": 0.3 } }}",
                     new String(o.toBytes(), Charset.forName("UTF-8")));
diff --git a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/ShardSizeTermsIT.java b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/ShardSizeTermsIT.java
index e76f48a..d045705 100644
--- a/core/src/test/java/org/elasticsearch/search/aggregations/bucket/ShardSizeTermsIT.java
+++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/ShardSizeTermsIT.java
@@ -18,13 +18,14 @@
  */
 package org.elasticsearch.search.aggregations.bucket;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.action.search.SearchResponse;
 import org.elasticsearch.search.aggregations.Aggregator.SubAggCollectionMode;
 import org.elasticsearch.search.aggregations.bucket.terms.Terms;
 import org.junit.Test;
 
 import java.util.Collection;
-import java.util.HashMap;
 import java.util.Map;
 
 import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
@@ -48,15 +49,16 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms  terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3));
-        Map<String, Long> expected = new HashMap<>();
-        expected.put("1", 8l);
-        expected.put("3", 8l);
-        expected.put("2", 5l);
+        Map<String, Long> expected = ImmutableMap.<String, Long>builder()
+                .put("1", 8l)
+                .put("3", 8l)
+                .put("2", 5l)
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsString())));
         }
     }
-
+    
     @Test
     public void shardSizeEqualsSize_string() throws Exception {
         createIdx("type=string,index=not_analyzed");
@@ -72,10 +74,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms  terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3));
-        Map<String, Long> expected = new HashMap<>();
-        expected.put("1", 8l);
-        expected.put("3", 8l);
-        expected.put("2", 4l);
+        Map<String, Long> expected = ImmutableMap.<String, Long>builder()
+                .put("1", 8l)
+                .put("3", 8l)
+                .put("2", 4l)
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsString())));
         }
@@ -97,10 +100,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3)); // we still only return 3 entries (based on the 'size' param)
-        Map<String, Long> expected = new HashMap<>();
-        expected.put("1", 8l);
-        expected.put("3", 8l);
-        expected.put("2", 5l); // <-- count is now fixed
+        Map<String, Long> expected = ImmutableMap.<String, Long>builder()
+                .put("1", 8l)
+                .put("3", 8l)
+                .put("2", 5l) // <-- count is now fixed
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsString())));
         }
@@ -122,15 +126,16 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3)); // we still only return 3 entries (based on the 'size' param)
-        Map<String, Long> expected = new HashMap<>();
-        expected.put("1", 5l);
-        expected.put("2", 4l);
-        expected.put("3", 3l); // <-- count is now fixed
+        Map<String, Long> expected = ImmutableMap.<String, Long>builder()
+                .put("1", 5l)
+                .put("2", 4l)
+                .put("3", 3l) // <-- count is now fixed
+                .build();
         for (Terms.Bucket bucket: buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKey())));
         }
     }
-
+    
     @Test
     public void noShardSizeTermOrder_string() throws Exception {
         createIdx("type=string,index=not_analyzed");
@@ -146,10 +151,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms  terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3));
-        Map<String, Long> expected = new HashMap<>();
-        expected.put("1", 8l);
-        expected.put("2", 5l);
-        expected.put("3", 8l);
+        Map<String, Long> expected = ImmutableMap.<String, Long>builder()
+                .put("1", 8l)
+                .put("2", 5l)
+                .put("3", 8l)
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsString())));
         }
@@ -171,10 +177,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3));
-        Map<Integer, Long> expected = new HashMap<>();
-        expected.put(1, 8l);
-        expected.put(3, 8l);
-        expected.put(2, 5l);
+        Map<Integer, Long> expected = ImmutableMap.<Integer, Long>builder()
+                .put(1, 8l)
+                .put(3, 8l)
+                .put(2, 5l)
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsNumber().intValue())));
         }
@@ -196,10 +203,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3));
-        Map<Integer, Long> expected = new HashMap<>();
-        expected.put(1, 8l);
-        expected.put(3, 8l);
-        expected.put(2, 4l);
+        Map<Integer, Long> expected = ImmutableMap.<Integer, Long>builder()
+                .put(1, 8l)
+                .put(3, 8l)
+                .put(2, 4l)
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsNumber().intValue())));
         }
@@ -221,10 +229,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3)); // we still only return 3 entries (based on the 'size' param)
-        Map<Integer, Long> expected = new HashMap<>();
-        expected.put(1, 8l);
-        expected.put(3, 8l);
-        expected.put(2, 5l); // <-- count is now fixed
+        Map<Integer, Long> expected = ImmutableMap.<Integer, Long>builder()
+                .put(1, 8l)
+                .put(3, 8l)
+                .put(2, 5l) // <-- count is now fixed
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsNumber().intValue())));
         }
@@ -246,10 +255,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3)); // we still only return 3 entries (based on the 'size' param)
-        Map<Integer, Long> expected = new HashMap<>();
-        expected.put(1, 5l);
-        expected.put(2, 4l);
-        expected.put(3, 3l);
+        Map<Integer, Long> expected = ImmutableMap.<Integer, Long>builder()
+                .put(1, 5l)
+                .put(2, 4l)
+                .put(3, 3l)
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsNumber().intValue())));
         }
@@ -271,10 +281,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3));
-        Map<Integer, Long> expected = new HashMap<>();
-        expected.put(1, 8l);
-        expected.put(2, 5l);
-        expected.put(3, 8l);
+        Map<Integer, Long> expected = ImmutableMap.<Integer, Long>builder()
+                .put(1, 8l)
+                .put(2, 5l)
+                .put(3, 8l)
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsNumber().intValue())));
         }
@@ -296,10 +307,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3));
-        Map<Integer, Long> expected = new HashMap<>();
-        expected.put(1, 8l);
-        expected.put(3, 8l);
-        expected.put(2, 5l);
+        Map<Integer, Long> expected = ImmutableMap.<Integer, Long>builder()
+                .put(1, 8l)
+                .put(3, 8l)
+                .put(2, 5l)
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsNumber().intValue())));
         }
@@ -321,10 +333,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3));
-        Map<Integer, Long> expected = new HashMap<>();
-        expected.put(1, 8l);
-        expected.put(3, 8l);
-        expected.put(2, 4l);
+        Map<Integer, Long> expected = ImmutableMap.<Integer, Long>builder()
+                .put(1, 8l)
+                .put(3, 8l)
+                .put(2, 4l)
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsNumber().intValue())));
         }
@@ -346,10 +359,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3));
-        Map<Integer, Long> expected = new HashMap<>();
-        expected.put(1, 8l);
-        expected.put(3, 8l);
-        expected.put(2, 5l); // <-- count is now fixed
+        Map<Integer, Long> expected = ImmutableMap.<Integer, Long>builder()
+                .put(1, 8l)
+                .put(3, 8l)
+                .put(2, 5l) // <-- count is now fixed
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsNumber().intValue())));
         }
@@ -371,10 +385,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3));
-        Map<Integer, Long> expected = new HashMap<>();
-        expected.put(1, 5l);
-        expected.put(2, 4l);
-        expected.put(3, 3l);
+        Map<Integer, Long> expected = ImmutableMap.<Integer, Long>builder()
+                .put(1, 5l)
+                .put(2, 4l)
+                .put(3, 3l)
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsNumber().intValue())));
         }
@@ -396,10 +411,11 @@ public class ShardSizeTermsIT extends ShardSizeTestCase {
         Terms terms = response.getAggregations().get("keys");
         Collection<Terms.Bucket> buckets = terms.getBuckets();
         assertThat(buckets.size(), equalTo(3));
-        Map<Integer, Long> expected = new HashMap<>();
-        expected.put(1, 8l);
-        expected.put(2, 5l);
-        expected.put(3, 8l);
+        Map<Integer, Long> expected = ImmutableMap.<Integer, Long>builder()
+                .put(1, 8l)
+                .put(2, 5l)
+                .put(3, 8l)
+                .build();
         for (Terms.Bucket bucket : buckets) {
             assertThat(bucket.getDocCount(), equalTo(expected.get(bucket.getKeyAsNumber().intValue())));
         }
diff --git a/core/src/test/java/org/elasticsearch/search/fetch/FetchSubPhasePluginIT.java b/core/src/test/java/org/elasticsearch/search/fetch/FetchSubPhasePluginIT.java
index 4804842..f3aff00 100644
--- a/core/src/test/java/org/elasticsearch/search/fetch/FetchSubPhasePluginIT.java
+++ b/core/src/test/java/org/elasticsearch/search/fetch/FetchSubPhasePluginIT.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.search.fetch;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.util.BytesRef;
@@ -27,7 +28,10 @@ import org.elasticsearch.action.termvectors.TermVectorsRequest;
 import org.elasticsearch.action.termvectors.TermVectorsResponse;
 import org.elasticsearch.common.Priority;
 import org.elasticsearch.common.bytes.BytesArray;
+import org.elasticsearch.common.inject.Inject;
+import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.index.termvectors.TermVectorsService;
 import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.search.SearchHitField;
 import org.elasticsearch.search.SearchModule;
@@ -46,8 +50,8 @@ import java.util.Collection;
 import java.util.HashMap;
 import java.util.Map;
 
-import static java.util.Collections.singletonMap;
 import static org.elasticsearch.client.Requests.indexRequest;
+import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
 import static org.hamcrest.Matchers.equalTo;
@@ -135,7 +139,7 @@ public class FetchSubPhasePluginIT extends ESIntegTestCase {
 
         @Override
         public Map<String, ? extends SearchParseElement> parseElements() {
-            return singletonMap("term_vectors_fetch", new TermVectorsFetchParseElement());
+            return ImmutableMap.of("term_vectors_fetch", new TermVectorsFetchParseElement());
         }
 
         @Override
diff --git a/core/src/test/java/org/elasticsearch/search/functionscore/QueryRescorerIT.java b/core/src/test/java/org/elasticsearch/search/functionscore/QueryRescorerIT.java
new file mode 100644
index 0000000..e906ac6
--- /dev/null
+++ b/core/src/test/java/org/elasticsearch/search/functionscore/QueryRescorerIT.java
@@ -0,0 +1,753 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.search.functionscore;
+
+
+
+import org.apache.lucene.search.Explanation;
+import org.apache.lucene.util.English;
+import org.elasticsearch.action.index.IndexRequestBuilder;
+import org.elasticsearch.action.search.SearchRequestBuilder;
+import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.action.search.SearchType;
+import org.elasticsearch.common.lucene.search.function.CombineFunction;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.settings.Settings.Builder;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.index.query.Operator;
+import org.elasticsearch.index.query.QueryBuilders;
+import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
+import org.elasticsearch.search.SearchHit;
+import org.elasticsearch.search.SearchHits;
+import org.elasticsearch.search.rescore.RescoreBuilder;
+import org.elasticsearch.search.rescore.RescoreBuilder.QueryRescorer;
+import org.elasticsearch.test.ESIntegTestCase;
+import org.junit.Test;
+
+import java.util.Arrays;
+import java.util.Comparator;
+
+import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
+import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
+
+/**
+ *
+ */
+public class QueryRescorerIT extends ESIntegTestCase {
+
+    @Test
+    public void testEnforceWindowSize() {
+        createIndex("test");
+        // this
+        int iters = scaledRandomIntBetween(10, 20);
+        for (int i = 0; i < iters; i ++) {
+            client().prepareIndex("test", "type", Integer.toString(i)).setSource("f", Integer.toString(i)).execute().actionGet();
+        }
+        ensureYellow();
+        refresh();
+
+        int numShards = getNumShards("test").numPrimaries;
+        for (int j = 0 ; j < iters; j++) {
+            SearchResponse searchResponse = client().prepareSearch()
+                    .setQuery(QueryBuilders.matchAllQuery())
+                    .setRescorer(RescoreBuilder.queryRescorer(
+                            QueryBuilders.functionScoreQuery(QueryBuilders.matchAllQuery(),
+                                    ScoreFunctionBuilders.weightFactorFunction(100)).boostMode(CombineFunction.REPLACE)).setQueryWeight(0.0f).setRescoreQueryWeight(1.0f))
+                    .setRescoreWindow(1).setSize(randomIntBetween(2, 10)).execute().actionGet();
+            assertSearchResponse(searchResponse);
+            assertFirstHit(searchResponse, hasScore(100.f));
+            int numDocsWith100AsAScore = 0;
+            for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
+                float score = searchResponse.getHits().hits()[i].getScore();
+                if  (score == 100f) {
+                    numDocsWith100AsAScore += 1;
+                }
+            }
+            // we cannot assert that they are equal since some shards might not have docs at all
+            assertThat(numDocsWith100AsAScore, lessThanOrEqualTo(numShards));
+        }
+    }
+
+    @Test
+    public void testRescorePhrase() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping(
+                        "type1",
+                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
+                                .field("analyzer", "whitespace").field("type", "string").endObject().endObject().endObject().endObject())
+                .setSettings(Settings.settingsBuilder().put(indexSettings()).put("index.number_of_shards", 1)));
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox").execute().actionGet();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree ").get();
+        client().prepareIndex("test", "type1", "3")
+                .setSource("field1", "quick huge brown", "field2", "the quick lazy huge brown fox jumps over the tree").get();
+        ensureYellow();
+        refresh();
+        SearchResponse searchResponse = client().prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "quick brown").slop(2).boost(4.0f)).setRescoreQueryWeight(2))
+                .setRescoreWindow(5).execute().actionGet();
+
+        assertThat(searchResponse.getHits().totalHits(), equalTo(3l));
+        assertThat(searchResponse.getHits().getHits()[0].getId(), equalTo("1"));
+        assertThat(searchResponse.getHits().getHits()[1].getId(), equalTo("3"));
+        assertThat(searchResponse.getHits().getHits()[2].getId(), equalTo("2"));
+
+        searchResponse = client().prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(3)))
+                .setRescoreWindow(5).execute().actionGet();
+
+        assertHitCount(searchResponse, 3);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client().prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                .setRescorer(RescoreBuilder.queryRescorer((QueryBuilders.matchPhraseQuery("field1", "the quick brown"))))
+                .setRescoreWindow(5).execute().actionGet();
+
+        assertHitCount(searchResponse, 3);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+    }
+
+    @Test
+    public void testMoreDocs() throws Exception {
+        Builder builder = Settings.builder();
+        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
+        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
+        builder.put("index.analysis.filter.synonym.type", "synonym");
+        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
+
+        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
+                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
+                .endObject().endObject().endObject().endObject();
+
+        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "massachusetts avenue boston massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "3").setSource("field1", "boston avenue lexington massachusetts").execute().actionGet();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        client().prepareIndex("test", "type1", "4").setSource("field1", "boston road lexington massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "5").setSource("field1", "lexington street lexington massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "7").setSource("field1", "bosten street san franciso california").execute().actionGet();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        client().prepareIndex("test", "type1", "8").setSource("field1", "hollywood boulevard los angeles california").execute().actionGet();
+        client().prepareIndex("test", "type1", "9").setSource("field1", "1st street boston massachussetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "10").setSource("field1", "1st street boston massachusetts").execute().actionGet();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        client().prepareIndex("test", "type1", "11").setSource("field1", "2st street boston massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "12").setSource("field1", "3st street boston massachusetts").execute().actionGet();
+        ensureYellow();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        SearchResponse searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setFrom(0)
+                .setSize(5)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
+
+        assertThat(searchResponse.getHits().hits().length, equalTo(5));
+        assertHitCount(searchResponse, 9);
+        assertFirstHit(searchResponse, hasId("2"));
+        assertSecondHit(searchResponse, hasId("6"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setFrom(0)
+                .setSize(5)
+                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
+
+        assertThat(searchResponse.getHits().hits().length, equalTo(5));
+        assertHitCount(searchResponse, 9);
+        assertFirstHit(searchResponse, hasId("2"));
+        assertSecondHit(searchResponse, hasId("6"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        // Make sure non-zero from works:
+        searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
+                .setFrom(2)
+                .setSize(5)
+                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
+
+        assertThat(searchResponse.getHits().hits().length, equalTo(5));
+        assertHitCount(searchResponse, 9);
+        assertFirstHit(searchResponse, hasId("3"));
+    }
+
+    // Tests a rescore window smaller than number of hits:
+    @Test
+    public void testSmallRescoreWindow() throws Exception {
+        Builder builder = Settings.builder();
+        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
+        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
+        builder.put("index.analysis.filter.synonym.type", "synonym");
+        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
+
+        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
+                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
+                .endObject().endObject().endObject().endObject();
+
+        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
+
+        client().prepareIndex("test", "type1", "3").setSource("field1", "massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        client().prepareIndex("test", "type1", "1").setSource("field1", "lexington massachusetts avenue").execute().actionGet();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts road").execute().actionGet();
+        ensureYellow();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+
+        SearchResponse searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
+                .setFrom(0)
+            .setSize(5).execute().actionGet();
+        assertThat(searchResponse.getHits().hits().length, equalTo(4));
+        assertHitCount(searchResponse, 4);
+        assertFirstHit(searchResponse, hasId("3"));
+        assertSecondHit(searchResponse, hasId("6"));
+        assertThirdHit(searchResponse, hasId("1"));
+        assertFourthHit(searchResponse, hasId("2"));
+
+        // Now, rescore only top 2 hits w/ proximity:
+        searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
+                .setFrom(0)
+                .setSize(5)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(2).execute().actionGet();
+        // Only top 2 hits were re-ordered:
+        assertThat(searchResponse.getHits().hits().length, equalTo(4));
+        assertHitCount(searchResponse, 4);
+        assertFirstHit(searchResponse, hasId("6"));
+        assertSecondHit(searchResponse, hasId("3"));
+        assertThirdHit(searchResponse, hasId("1"));
+        assertFourthHit(searchResponse, hasId("2"));
+
+        // Now, rescore only top 3 hits w/ proximity:
+        searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
+                .setFrom(0)
+                .setSize(5)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(3).execute().actionGet();
+
+        // Only top 3 hits were re-ordered:
+        assertThat(searchResponse.getHits().hits().length, equalTo(4));
+        assertHitCount(searchResponse, 4);
+        assertFirstHit(searchResponse, hasId("6"));
+        assertSecondHit(searchResponse, hasId("1"));
+        assertThirdHit(searchResponse, hasId("3"));
+        assertFourthHit(searchResponse, hasId("2"));
+    }
+
+    // Tests a rescorer that penalizes the scores:
+    @Test
+    public void testRescorerMadeScoresWorse() throws Exception {
+        Builder builder = Settings.builder();
+        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
+        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
+        builder.put("index.analysis.filter.synonym.type", "synonym");
+        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
+
+        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
+                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
+                .endObject().endObject().endObject().endObject();
+
+        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
+
+        client().prepareIndex("test", "type1", "3").setSource("field1", "massachusetts").execute().actionGet();
+        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+        client().prepareIndex("test", "type1", "1").setSource("field1", "lexington massachusetts avenue").execute().actionGet();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts road").execute().actionGet();
+        ensureYellow();
+        client().admin().indices().prepareRefresh("test").execute().actionGet();
+
+        SearchResponse searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
+                .setFrom(0)
+            .setSize(5).execute().actionGet();
+        assertThat(searchResponse.getHits().hits().length, equalTo(4));
+        assertHitCount(searchResponse, 4);
+        assertFirstHit(searchResponse, hasId("3"));
+        assertSecondHit(searchResponse, hasId("6"));
+        assertThirdHit(searchResponse, hasId("1"));
+        assertFourthHit(searchResponse, hasId("2"));
+
+        // Now, penalizing rescore (nothing matches the rescore query):
+        searchResponse = client()
+                .prepareSearch()
+                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
+                .setFrom(0)
+                .setSize(5)
+                .setRescorer(
+                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
+                                .setQueryWeight(1.0f).setRescoreQueryWeight(-1f)).setRescoreWindow(3).execute().actionGet();
+
+        // 6 and 1 got worse, and then the hit (2) outside the rescore window were sorted ahead:
+        assertFirstHit(searchResponse, hasId("3"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("6"));
+        assertFourthHit(searchResponse, hasId("1"));
+    }
+
+    // Comparator that sorts hits and rescored hits in the same way.
+    // The rescore uses the docId as tie, while regular search uses the slot the hit is in as a tie if score
+    // and shard id are equal during merging shard results.
+    // This comparator uses a custom tie in case the scores are equal, so that both regular hits and rescored hits
+    // are sorted equally. This is fine since tests only care about the fact the scores should be equal, not ordering.
+    private final static Comparator<SearchHit> searchHitsComparator = new Comparator<SearchHit>() {
+        @Override
+        public int compare(SearchHit hit1, SearchHit hit2) {
+            int cmp = Float.compare(hit2.getScore(), hit1.getScore());
+            if (cmp == 0) {
+                return hit1.id().compareTo(hit2.id());
+            } else {
+                return cmp;
+            }
+        }
+    };
+
+    private static void assertEquivalent(String query, SearchResponse plain, SearchResponse rescored) {
+        assertNoFailures(plain);
+        assertNoFailures(rescored);
+        SearchHits leftHits = plain.getHits();
+        SearchHits rightHits = rescored.getHits();
+        assertThat(leftHits.getTotalHits(), equalTo(rightHits.getTotalHits()));
+        assertThat(leftHits.getHits().length, equalTo(rightHits.getHits().length));
+        SearchHit[] hits = leftHits.getHits();
+        SearchHit[] rHits = rightHits.getHits();
+        Arrays.sort(hits, searchHitsComparator);
+        Arrays.sort(rHits, searchHitsComparator);
+        for (int i = 0; i < hits.length; i++) {
+            assertThat("query: " + query, hits[i].getScore(), equalTo(rHits[i].getScore()));
+        }
+        for (int i = 0; i < hits.length; i++) {
+            if (hits[i].getScore() == hits[hits.length-1].getScore()) {
+                return; // we need to cut off here since this is the tail of the queue and we might not have fetched enough docs
+            }
+            assertThat("query: " + query,hits[i].getId(), equalTo(rHits[i].getId()));
+        }
+    }
+
+    private static void assertEquivalentOrSubstringMatch(String query, SearchResponse plain, SearchResponse rescored) {
+        assertNoFailures(plain);
+        assertNoFailures(rescored);
+        SearchHits leftHits = plain.getHits();
+        SearchHits rightHits = rescored.getHits();
+        assertThat(leftHits.getTotalHits(), equalTo(rightHits.getTotalHits()));
+        assertThat(leftHits.getHits().length, equalTo(rightHits.getHits().length));
+        SearchHit[] hits = leftHits.getHits();
+        SearchHit[] otherHits = rightHits.getHits();
+        if (!hits[0].getId().equals(otherHits[0].getId())) {
+            assertThat(((String) otherHits[0].sourceAsMap().get("field1")).contains(query), equalTo(true));
+        } else {
+            Arrays.sort(hits, searchHitsComparator);
+            Arrays.sort(otherHits, searchHitsComparator);
+            for (int i = 0; i < hits.length; i++) {
+                if (hits[i].getScore() == hits[hits.length-1].getScore()) {
+                    return; // we need to cut off here since this is the tail of the queue and we might not have fetched enough docs
+                }
+                assertThat(query, hits[i].getId(), equalTo(rightHits.getHits()[i].getId()));
+            }
+        }
+    }
+
+    @Test
+    // forces QUERY_THEN_FETCH because of https://github.com/elasticsearch/elasticsearch/issues/4829
+    public void testEquivalence() throws Exception {
+        // no dummy docs since merges can change scores while we run queries.
+        int numDocs = indexRandomNumbers("whitespace", -1, false);
+
+        final int iters = scaledRandomIntBetween(50, 100);
+        for (int i = 0; i < iters; i++) {
+            int resultSize = numDocs;
+            int rescoreWindow = between(1, 3) * resultSize;
+            String intToEnglish = English.intToEnglish(between(0, numDocs-1));
+            String query = intToEnglish.split(" ")[0];
+            SearchResponse rescored = client()
+                    .prepareSearch()
+                    .setSearchType(SearchType.QUERY_THEN_FETCH)
+                    .setPreference("test") // ensure we hit the same shards for tie-breaking
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setFrom(0)
+                    .setSize(resultSize)
+                    .setRescorer(
+                            RescoreBuilder
+                                    .queryRescorer(
+                                            QueryBuilders
+                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery("field1", intToEnglish).slop(3)))
+                                    .setQueryWeight(1.0f)
+                                    .setRescoreQueryWeight(0.0f)) // no weight - so we basically use the same score as the actual query
+                    .setRescoreWindow(rescoreWindow).execute().actionGet();
+
+            SearchResponse plain = client().prepareSearch()
+                    .setSearchType(SearchType.QUERY_THEN_FETCH)
+                    .setPreference("test") // ensure we hit the same shards for tie-breaking
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR)).setFrom(0).setSize(resultSize)
+                    .execute().actionGet();
+            
+            // check equivalence
+            assertEquivalent(query, plain, rescored);
+
+            rescored = client()
+                    .prepareSearch()
+                    .setSearchType(SearchType.QUERY_THEN_FETCH)
+                    .setPreference("test") // ensure we hit the same shards for tie-breaking
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setFrom(0)
+                    .setSize(resultSize)
+                    .setRescorer(
+                            RescoreBuilder
+                                    .queryRescorer(
+                                            QueryBuilders
+                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery("field1", "not in the index").slop(3)))
+                                    .setQueryWeight(1.0f)
+                                    .setRescoreQueryWeight(1.0f))
+                    .setRescoreWindow(rescoreWindow).execute().actionGet();
+            // check equivalence
+            assertEquivalent(query, plain, rescored);
+
+            rescored = client()
+                    .prepareSearch()
+                    .setSearchType(SearchType.QUERY_THEN_FETCH)
+                    .setPreference("test") // ensure we hit the same shards for tie-breaking
+                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
+                    .setFrom(0)
+                    .setSize(resultSize)
+                    .setRescorer(
+                            RescoreBuilder
+                                    .queryRescorer(
+                                            QueryBuilders.matchPhraseQuery("field1", intToEnglish).slop(0))
+                                    .setQueryWeight(1.0f).setRescoreQueryWeight(1.0f)).setRescoreWindow(2 * rescoreWindow).execute().actionGet();
+            // check equivalence or if the first match differs we check if the phrase is a substring of the top doc
+            assertEquivalentOrSubstringMatch(intToEnglish, plain, rescored);
+        }
+    }
+
+    @Test
+    public void testExplain() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping(
+                        "type1",
+                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
+                                .field("analyzer", "whitespace").field("type", "string").endObject().endObject().endObject().endObject())
+        );
+        ensureGreen();
+        client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox").execute().actionGet();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree").execute()
+                .actionGet();
+        client().prepareIndex("test", "type1", "3")
+                .setSource("field1", "quick huge brown", "field2", "the quick lazy huge brown fox jumps over the tree").execute()
+                .actionGet();
+        ensureYellow();
+        refresh();
+
+        {
+            SearchResponse searchResponse = client()
+                    .prepareSearch()
+                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                    .setRescorer(
+                            RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(2).boost(4.0f))
+                                    .setQueryWeight(0.5f).setRescoreQueryWeight(0.4f)).setRescoreWindow(5).setExplain(true).execute()
+                    .actionGet();
+            assertHitCount(searchResponse, 3);
+            assertFirstHit(searchResponse, hasId("1"));
+            assertSecondHit(searchResponse, hasId("2"));
+            assertThirdHit(searchResponse, hasId("3"));
+
+            for (int i = 0; i < 3; i++) {
+                assertThat(searchResponse.getHits().getAt(i).explanation(), notNullValue());
+                assertThat(searchResponse.getHits().getAt(i).explanation().isMatch(), equalTo(true));
+                assertThat(searchResponse.getHits().getAt(i).explanation().getDetails().length, equalTo(2));
+                assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[0].isMatch(), equalTo(true));
+                if (i == 2) {
+                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[1].getValue(), equalTo(0.5f));
+                } else {
+                    assertThat(searchResponse.getHits().getAt(i).explanation().getDescription(), equalTo("sum of:"));
+                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[0].getDetails()[1].getValue(), equalTo(0.5f));
+                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[1].getDetails()[1].getValue(), equalTo(0.4f));
+                }
+            }
+        }
+
+        String[] scoreModes = new String[]{ "max", "min", "avg", "total", "multiply", "" };
+        String[] descriptionModes = new String[]{ "max of:", "min of:", "avg of:", "sum of:", "product of:", "sum of:" };
+        for (int innerMode = 0; innerMode < scoreModes.length; innerMode++) {
+            QueryRescorer innerRescoreQuery = RescoreBuilder.queryRescorer(QueryBuilders.matchQuery("field1", "the quick brown").boost(4.0f))
+                .setQueryWeight(0.5f).setRescoreQueryWeight(0.4f);
+
+            if (!"".equals(scoreModes[innerMode])) {
+                innerRescoreQuery.setScoreMode(scoreModes[innerMode]);
+            }
+
+            SearchResponse searchResponse = client()
+                    .prepareSearch()
+                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                    .setRescorer(innerRescoreQuery).setRescoreWindow(5).setExplain(true).execute()
+                    .actionGet();
+            assertHitCount(searchResponse, 3);
+            assertFirstHit(searchResponse, hasId("1"));
+            assertSecondHit(searchResponse, hasId("2"));
+            assertThirdHit(searchResponse, hasId("3"));
+
+            for (int j = 0; j < 3; j++) {
+                assertThat(searchResponse.getHits().getAt(j).explanation().getDescription(), equalTo(descriptionModes[innerMode]));
+            }
+
+            for (int outerMode = 0; outerMode < scoreModes.length; outerMode++) {
+                QueryRescorer outerRescoreQuery = RescoreBuilder.queryRescorer(QueryBuilders.matchQuery("field1", "the quick brown")
+                        .boost(4.0f)).setQueryWeight(0.5f).setRescoreQueryWeight(0.4f);
+
+                if (!"".equals(scoreModes[outerMode])) {
+                    outerRescoreQuery.setScoreMode(scoreModes[outerMode]);
+                }
+
+                searchResponse = client()
+                        .prepareSearch()
+                        .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                        .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
+                        .addRescorer(innerRescoreQuery).setRescoreWindow(5)
+                        .addRescorer(outerRescoreQuery).setRescoreWindow(10)
+                        .setExplain(true).get();
+                assertHitCount(searchResponse, 3);
+                assertFirstHit(searchResponse, hasId("1"));
+                assertSecondHit(searchResponse, hasId("2"));
+                assertThirdHit(searchResponse, hasId("3"));
+
+                for (int j = 0; j < 3; j++) {
+                    Explanation explanation = searchResponse.getHits().getAt(j).explanation();
+                    assertThat(explanation.getDescription(), equalTo(descriptionModes[outerMode]));
+                    assertThat(explanation.getDetails()[0].getDetails()[0].getDescription(), equalTo(descriptionModes[innerMode]));
+                }
+            }
+        }
+    }
+
+    @Test
+    public void testScoring() throws Exception {
+        int numDocs = indexRandomNumbers("keyword");
+
+        String[] scoreModes = new String[]{ "max", "min", "avg", "total", "multiply", "" };
+        float primaryWeight = 1.1f;
+        float secondaryWeight = 1.6f;
+
+        for (String scoreMode : scoreModes) {
+            for (int i = 0; i < numDocs - 4; i++) {
+                String[] intToEnglish = new String[] { English.intToEnglish(i), English.intToEnglish(i + 1), English.intToEnglish(i + 2), English.intToEnglish(i + 3) };
+
+                QueryRescorer rescoreQuery = RescoreBuilder
+                        .queryRescorer(
+                                QueryBuilders.boolQuery()
+                                        .disableCoord(true)
+                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]),
+                                                ScoreFunctionBuilders.weightFactorFunction(5.0f)).boostMode(CombineFunction.REPLACE))
+                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]),
+                                                ScoreFunctionBuilders.weightFactorFunction(7.0f)).boostMode(CombineFunction.REPLACE))
+                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]),
+                                                ScoreFunctionBuilders.weightFactorFunction(0.0f)).boostMode(CombineFunction.REPLACE)))
+                        .setQueryWeight(primaryWeight)
+                        .setRescoreQueryWeight(secondaryWeight);
+
+                if (!"".equals(scoreMode)) {
+                    rescoreQuery.setScoreMode(scoreMode);
+                }
+
+                SearchResponse rescored = client()
+                        .prepareSearch()
+                        .setPreference("test") // ensure we hit the same shards for tie-breaking
+                        .setQuery(QueryBuilders.boolQuery()
+                                .disableCoord(true)
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]),
+                                        ScoreFunctionBuilders.weightFactorFunction(2.0f)).boostMode(CombineFunction.REPLACE))
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]),
+                                        ScoreFunctionBuilders.weightFactorFunction(3.0f)).boostMode(CombineFunction.REPLACE))
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[2]),
+                                        ScoreFunctionBuilders.weightFactorFunction(5.0f)).boostMode(CombineFunction.REPLACE))
+                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]),
+                                        ScoreFunctionBuilders.weightFactorFunction(0.2f)).boostMode(CombineFunction.REPLACE)))
+                                .setFrom(0)
+                                .setSize(10)
+                                .setRescorer(rescoreQuery)
+                                .setRescoreWindow(50).execute().actionGet();
+
+                assertHitCount(rescored, 4);
+
+                if ("total".equals(scoreMode) || "".equals(scoreMode)) {
+                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
+                    assertSecondHit(rescored, hasId(String.valueOf(i)));
+                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
+                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight + 7.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight + 5.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight + 0.0f * secondaryWeight));
+                } else if ("max".equals(scoreMode)) {
+                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
+                    assertSecondHit(rescored, hasId(String.valueOf(i)));
+                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
+                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(7.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight));
+                } else if ("min".equals(scoreMode)) {
+                    assertFirstHit(rescored, hasId(String.valueOf(i + 2)));
+                    assertSecondHit(rescored, hasId(String.valueOf(i + 1)));
+                    assertThirdHit(rescored, hasId(String.valueOf(i)));
+                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(5.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(3.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(2.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.0f * secondaryWeight));
+                } else if ("avg".equals(scoreMode)) {
+                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
+                    assertSecondHit(rescored, hasId(String.valueOf(i + 2)));
+                    assertThirdHit(rescored, hasId(String.valueOf(i)));
+                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo((3.0f * primaryWeight + 7.0f * secondaryWeight) / 2.0f));
+                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo((2.0f * primaryWeight + 5.0f * secondaryWeight) / 2.0f));
+                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo((0.2f * primaryWeight) / 2.0f));
+                } else if ("multiply".equals(scoreMode)) {
+                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
+                    assertSecondHit(rescored, hasId(String.valueOf(i)));
+                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
+                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight * 7.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight * 5.0f * secondaryWeight));
+                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
+                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight * 0.0f * secondaryWeight));
+                }
+            }
+        }
+    }
+
+    @Test
+    public void testMultipleRescores() throws Exception {
+        int numDocs = indexRandomNumbers("keyword", 1, true);
+        QueryRescorer eightIsGreat = RescoreBuilder.queryRescorer(
+                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(8)),
+                        ScoreFunctionBuilders.weightFactorFunction(1000.0f)).boostMode(CombineFunction.REPLACE)).setScoreMode("total");
+        QueryRescorer sevenIsBetter = RescoreBuilder.queryRescorer(
+                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(7)),
+                        ScoreFunctionBuilders.weightFactorFunction(10000.0f)).boostMode(CombineFunction.REPLACE))
+                .setScoreMode("total");
+
+        // First set the rescore window large enough that both rescores take effect
+        SearchRequestBuilder request = client().prepareSearch().setRescoreWindow(numDocs);
+        request.addRescorer(eightIsGreat).addRescorer(sevenIsBetter);
+        SearchResponse response = request.get();
+        assertFirstHit(response, hasId("7"));
+        assertSecondHit(response, hasId("8"));
+
+        // Now squash the second rescore window so it never gets to see a seven
+        response = request.setSize(1).clearRescorers().addRescorer(eightIsGreat).addRescorer(sevenIsBetter, 1).get();
+        assertFirstHit(response, hasId("8"));
+        // We have no idea what the second hit will be because we didn't get a chance to look for seven
+
+        // Now use one rescore to drag the number we're looking for into the window of another
+        QueryRescorer ninetyIsGood = RescoreBuilder.queryRescorer(
+                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*ninety*"), ScoreFunctionBuilders.weightFactorFunction(1000.0f))
+                        .boostMode(CombineFunction.REPLACE)).setScoreMode("total");
+        QueryRescorer oneToo = RescoreBuilder.queryRescorer(
+                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*one*"), ScoreFunctionBuilders.weightFactorFunction(1000.0f))
+                        .boostMode(CombineFunction.REPLACE)).setScoreMode("total");
+        request.clearRescorers().addRescorer(ninetyIsGood).addRescorer(oneToo, 10);
+        response = request.setSize(2).get();
+        assertFirstHit(response, hasId("91"));
+        assertFirstHit(response, hasScore(2001.0f));
+        assertSecondHit(response, hasScore(1001.0f)); // Not sure which one it is but it is ninety something
+    }
+
+    private int indexRandomNumbers(String analyzer) throws Exception {
+        return indexRandomNumbers(analyzer, -1, true);
+    }
+
+    private int indexRandomNumbers(String analyzer, int shards, boolean dummyDocs) throws Exception {
+        Builder builder = Settings.settingsBuilder().put(indexSettings());
+
+        if (shards > 0) {
+            builder.put(SETTING_NUMBER_OF_SHARDS, shards);
+        }
+
+        assertAcked(prepareCreate("test")
+                .addMapping(
+                        "type1",
+                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
+                                .field("analyzer", analyzer).field("type", "string").endObject().endObject().endObject().endObject())
+                .setSettings(builder));
+        int numDocs = randomIntBetween(100, 150);
+        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
+        for (int i = 0; i < numDocs; i++) {
+            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource("field1", English.intToEnglish(i));
+        }
+
+        indexRandom(true, dummyDocs, docs);
+        ensureGreen();
+        return numDocs;
+    }
+
+    // #11277
+    public void testFromSize() throws Exception {
+        Builder settings = Settings.builder();
+        settings.put(SETTING_NUMBER_OF_SHARDS, 1);
+        settings.put(SETTING_NUMBER_OF_REPLICAS, 0);
+        assertAcked(prepareCreate("test").setSettings(settings));
+        for(int i=0;i<5;i++) {
+            client().prepareIndex("test", "type", ""+i).setSource("text", "hello world").get();
+        }
+        refresh();
+
+        SearchRequestBuilder request = client().prepareSearch();
+        request.setQuery(QueryBuilders.termQuery("text", "hello"));
+        request.setFrom(1);
+        request.setSize(4);
+        request.addRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchAllQuery()));
+        request.setRescoreWindow(50);
+
+        assertEquals(4, request.get().getHits().hits().length);
+    }
+}
diff --git a/core/src/test/java/org/elasticsearch/search/query/ExistsMissingIT.java b/core/src/test/java/org/elasticsearch/search/query/ExistsMissingIT.java
index 349197d..4d85f8b 100644
--- a/core/src/test/java/org/elasticsearch/search/query/ExistsMissingIT.java
+++ b/core/src/test/java/org/elasticsearch/search/query/ExistsMissingIT.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.search.query;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.elasticsearch.action.explain.ExplainResponse;
 import org.elasticsearch.action.index.IndexRequestBuilder;
 import org.elasticsearch.action.search.SearchResponse;
@@ -30,14 +32,11 @@ import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.test.ESIntegTestCase;
 
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
 
-import static java.util.Collections.emptyMap;
-import static java.util.Collections.singletonMap;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchHits;
@@ -91,17 +90,14 @@ public class ExistsMissingIT extends ESIntegTestCase {
 
         assertAcked(client().admin().indices().prepareCreate("idx").addMapping("type", mapping));
         @SuppressWarnings("unchecked")
-        Map<String, Object> barObject = new HashMap<>();
-        barObject.put("foo", "bar");
-        barObject.put("bar", singletonMap("bar", "foo"));
         final Map<String, Object>[] sources = new Map[] {
                 // simple property
-                singletonMap("foo", "bar"),
+                ImmutableMap.of("foo", "bar"),
                 // object fields
-                singletonMap("bar", barObject),
-                singletonMap("bar", singletonMap("baz", 42)),
+                ImmutableMap.of("bar", ImmutableMap.of("foo", "bar", "bar", ImmutableMap.of("bar", "foo"))),
+                ImmutableMap.of("bar", ImmutableMap.of("baz", 42)),
                 // empty doc
-                emptyMap()
+                ImmutableMap.of()
         };
         List<IndexRequestBuilder> reqs = new ArrayList<IndexRequestBuilder>();
         for (Map<String, Object> source : sources) {
diff --git a/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java b/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java
index 7f38715..206dfee 100644
--- a/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java
+++ b/core/src/test/java/org/elasticsearch/snapshots/SharedClusterSnapshotRestoreIT.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.snapshots;
 
+import com.google.common.collect.ImmutableMap;
 import org.apache.lucene.util.IOUtils;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.Version;
@@ -28,11 +29,7 @@ import org.elasticsearch.action.admin.cluster.snapshots.create.CreateSnapshotRes
 import org.elasticsearch.action.admin.cluster.snapshots.delete.DeleteSnapshotResponse;
 import org.elasticsearch.action.admin.cluster.snapshots.get.GetSnapshotsResponse;
 import org.elasticsearch.action.admin.cluster.snapshots.restore.RestoreSnapshotResponse;
-import org.elasticsearch.action.admin.cluster.snapshots.status.SnapshotIndexShardStage;
-import org.elasticsearch.action.admin.cluster.snapshots.status.SnapshotIndexShardStatus;
-import org.elasticsearch.action.admin.cluster.snapshots.status.SnapshotIndexStatus;
-import org.elasticsearch.action.admin.cluster.snapshots.status.SnapshotStatus;
-import org.elasticsearch.action.admin.cluster.snapshots.status.SnapshotsStatusResponse;
+import org.elasticsearch.action.admin.cluster.snapshots.status.*;
 import org.elasticsearch.action.admin.cluster.state.ClusterStateResponse;
 import org.elasticsearch.action.admin.indices.flush.FlushResponse;
 import org.elasticsearch.action.admin.indices.settings.get.GetSettingsResponse;
@@ -82,24 +79,8 @@ import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF
 import static org.elasticsearch.common.settings.Settings.settingsBuilder;
 import static org.elasticsearch.index.query.QueryBuilders.matchQuery;
 import static org.elasticsearch.index.shard.IndexShard.INDEX_REFRESH_INTERVAL;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAliasesExist;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAliasesMissing;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAllSuccessful;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertBlocked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertIndexTemplateExists;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertIndexTemplateMissing;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertThrows;
-import static org.hamcrest.Matchers.allOf;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.lessThan;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
-import static org.hamcrest.Matchers.startsWith;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
 
 public class SharedClusterSnapshotRestoreIT extends AbstractSnapshotIntegTestCase {
 
@@ -1843,7 +1824,7 @@ public class SharedClusterSnapshotRestoreIT extends AbstractSnapshotIntegTestCas
             @Override
             public ClusterState execute(ClusterState currentState) {
                 // Simulate orphan snapshot
-                ImmutableOpenMap.Builder<ShardId, ShardSnapshotStatus> shards = ImmutableOpenMap.builder();
+                ImmutableMap.Builder<ShardId, ShardSnapshotStatus> shards = ImmutableMap.builder();
                 shards.put(new ShardId("test-idx", 0), new ShardSnapshotStatus("unknown-node", State.ABORTED));
                 shards.put(new ShardId("test-idx", 1), new ShardSnapshotStatus("unknown-node", State.ABORTED));
                 shards.put(new ShardId("test-idx", 2), new ShardSnapshotStatus("unknown-node", State.ABORTED));
diff --git a/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java b/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java
index da6c0b3..852d71c 100644
--- a/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java
+++ b/core/src/test/java/org/elasticsearch/test/rest/section/ApiCallSection.java
@@ -18,13 +18,9 @@
  */
 package org.elasticsearch.test.rest.section;
 
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
+import com.google.common.collect.ImmutableMap;
 
-import static java.util.Collections.unmodifiableMap;
+import java.util.*;
 
 /**
  * Represents a test fragment that contains the information needed to call an api
@@ -45,7 +41,7 @@ public class ApiCallSection {
 
     public Map<String, String> getParams() {
         //make sure we never modify the parameters once returned
-        return unmodifiableMap(params);
+        return ImmutableMap.copyOf(params);
     }
 
     public void addParam(String key, String value) {
diff --git a/core/src/test/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java b/core/src/test/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java
index c423fb7..50cb00a 100644
--- a/core/src/test/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java
+++ b/core/src/test/java/org/elasticsearch/transport/AbstractSimpleTransportTestCase.java
@@ -19,6 +19,7 @@
 
 package org.elasticsearch.transport;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
@@ -41,12 +42,8 @@ import java.util.concurrent.Semaphore;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicReference;
 
-import static java.util.Collections.emptyMap;
 import static org.elasticsearch.transport.TransportRequestOptions.options;
-import static org.hamcrest.Matchers.endsWith;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.instanceOf;
-import static org.hamcrest.Matchers.notNullValue;
+import static org.hamcrest.Matchers.*;
 
 /**
  *
@@ -74,12 +71,12 @@ public abstract class AbstractSimpleTransportTestCase extends ESTestCase {
                 Settings.builder().put("name", "TS_A", TransportService.SETTING_TRACE_LOG_INCLUDE, "", TransportService.SETTING_TRACE_LOG_EXCLUDE, "NOTHING").build(),
                 version0, new NamedWriteableRegistry()
         );
-        nodeA = new DiscoveryNode("TS_A", "TS_A", serviceA.boundAddress().publishAddress(), emptyMap(), version0);
+        nodeA = new DiscoveryNode("TS_A", "TS_A", serviceA.boundAddress().publishAddress(), ImmutableMap.<String, String>of(), version0);
         serviceB = build(
                 Settings.builder().put("name", "TS_B", TransportService.SETTING_TRACE_LOG_INCLUDE, "", TransportService.SETTING_TRACE_LOG_EXCLUDE, "NOTHING").build(),
                 version1, new NamedWriteableRegistry()
         );
-        nodeB = new DiscoveryNode("TS_B", "TS_B", serviceB.boundAddress().publishAddress(), emptyMap(), version1);
+        nodeB = new DiscoveryNode("TS_B", "TS_B", serviceB.boundAddress().publishAddress(), ImmutableMap.<String, String>of(), version1);
 
         // wait till all nodes are properly connected and the event has been sent, so tests in this class
         // will not get this callback called on the connections done in this setup
diff --git a/core/src/test/java/org/elasticsearch/transport/netty/NettyScheduledPingTests.java b/core/src/test/java/org/elasticsearch/transport/netty/NettyScheduledPingTests.java
index 4e03b8e..d268907 100644
--- a/core/src/test/java/org/elasticsearch/transport/netty/NettyScheduledPingTests.java
+++ b/core/src/test/java/org/elasticsearch/transport/netty/NettyScheduledPingTests.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.transport.netty;
 
+import com.google.common.collect.ImmutableMap;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
@@ -28,19 +29,11 @@ import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.test.ESTestCase;
 import org.elasticsearch.test.transport.MockTransportService;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.BaseTransportResponseHandler;
-import org.elasticsearch.transport.TransportChannel;
-import org.elasticsearch.transport.TransportException;
-import org.elasticsearch.transport.TransportRequest;
-import org.elasticsearch.transport.TransportRequestHandler;
-import org.elasticsearch.transport.TransportRequestOptions;
-import org.elasticsearch.transport.TransportResponse;
-import org.elasticsearch.transport.TransportResponseOptions;
+import org.elasticsearch.transport.*;
 import org.junit.Test;
 
 import java.io.IOException;
 
-import static java.util.Collections.emptyMap;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.greaterThan;
 
@@ -64,8 +57,8 @@ public class NettyScheduledPingTests extends ESTestCase {
         MockTransportService serviceB = new MockTransportService(settings, nettyB, threadPool);
         serviceB.start();
 
-        DiscoveryNode nodeA = new DiscoveryNode("TS_A", "TS_A", serviceA.boundAddress().publishAddress(), emptyMap(), Version.CURRENT);
-        DiscoveryNode nodeB = new DiscoveryNode("TS_B", "TS_B", serviceB.boundAddress().publishAddress(), emptyMap(), Version.CURRENT);
+        DiscoveryNode nodeA = new DiscoveryNode("TS_A", "TS_A", serviceA.boundAddress().publishAddress(), ImmutableMap.<String, String>of(), Version.CURRENT);
+        DiscoveryNode nodeB = new DiscoveryNode("TS_B", "TS_B", serviceB.boundAddress().publishAddress(), ImmutableMap.<String, String>of(), Version.CURRENT);
 
         serviceA.connectToNode(nodeB);
         serviceB.connectToNode(nodeA);
diff --git a/dev-tools/src/main/resources/forbidden/all-signatures.txt b/dev-tools/src/main/resources/forbidden/all-signatures.txt
index 836c324..e57a862 100644
--- a/dev-tools/src/main/resources/forbidden/all-signatures.txt
+++ b/dev-tools/src/main/resources/forbidden/all-signatures.txt
@@ -133,8 +133,6 @@ com.google.common.io.Resources
 com.google.common.hash.HashCode
 com.google.common.hash.HashFunction
 com.google.common.hash.Hashing
-com.google.common.collect.ImmutableMap
-com.google.common.collect.ImmutableMap$Builder
 
 @defaultMessage Do not violate java's access system
 java.lang.reflect.AccessibleObject#setAccessible(boolean)
diff --git a/dev-tools/src/main/resources/forbidden/cluster-signatures.txt b/dev-tools/src/main/resources/forbidden/cluster-signatures.txt
deleted file mode 100644
index e3da53f..0000000
--- a/dev-tools/src/main/resources/forbidden/cluster-signatures.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-@defaultMessage Prefer ImmutableOpenMap for cluster state
-java.util.Collections#unmodifiableMap(java.util.Map)
diff --git a/docs/plugins/discovery-ec2.asciidoc b/docs/plugins/discovery-ec2.asciidoc
index fa1ac07..5ac2085 100644
--- a/docs/plugins/discovery-ec2.asciidoc
+++ b/docs/plugins/discovery-ec2.asciidoc
@@ -165,6 +165,37 @@ The following are a list of settings (prefixed with `discovery.ec2`) that can fu
     Defaults to `3s`. If no unit like `ms`, `s` or `m` is specified,
     milliseconds are used.
 
+
+[IMPORTANT]
+.Binding the network host
+==============================================
+
+It's important to define `network.host` as by default it's bound to `localhost`.
+
+You can use {ref}/modules-network.html[core network host settings] or
+<<discovery-ec2-network-host,ec2 specific host settings>>:
+
+==============================================
+
+[[discovery-ec2-network-host]]
+===== EC2 Network Host
+
+When the `discovery-ec2` plugin is installed, the following are also allowed
+as valid network host settings:
+
+[cols="<,<",options="header",]
+|==================================================================
+|EC2 Host Value |Description
+|`_ec2:privateIpv4_` |The private IP address (ipv4) of the machine.
+|`_ec2:privateDns_` |The private host of the machine.
+|`_ec2:publicIpv4_` |The public IP address (ipv4) of the machine.
+|`_ec2:publicDns_` |The public host of the machine.
+|`_ec2:privateIp_` |equivalent to _ec2:privateIpv4_.
+|`_ec2:publicIp_` |equivalent to _ec2:publicIpv4_.
+|`_ec2_` |equivalent to _ec2:privateIpv4_.
+|==================================================================
+
+
 [[discovery-ec2-permissions]]
 ===== Recommended EC2 Permissions
 
diff --git a/docs/reference/modules/network.asciidoc b/docs/reference/modules/network.asciidoc
index dc6aca7..70b4d8c 100644
--- a/docs/reference/modules/network.asciidoc
+++ b/docs/reference/modules/network.asciidoc
@@ -51,20 +51,8 @@ provided network interface. For example `_en0:ipv4_`.
 provided network interface. For example `_en0:ipv6_`.
 |=======================================================================
 
-When the `discovery-ec2` plugin is installed, the following are also allowed
-as valid network host settings:
-
-[cols="<,<",options="header",]
-|==================================================================
-|EC2 Host Value |Description
-|`_ec2:privateIpv4_` |The private IP address (ipv4) of the machine.
-|`_ec2:privateDns_` |The private host of the machine.
-|`_ec2:publicIpv4_` |The public IP address (ipv4) of the machine.
-|`_ec2:publicDns_` |The public host of the machine.
-|`_ec2_` |Less verbose option for the private ip address.
-|`_ec2:privateIp_` |Less verbose option for the private ip address.
-|`_ec2:publicIp_` |Less verbose option for the public ip address.
-|==================================================================
+When the `discovery-ec2` plugin is installed, you can use
+{plugins}/discovery-ec2-discovery.html#discovery-ec2-network-host[ec2 specific host settings].
 
 [float]
 [[tcp-settings]]
diff --git a/plugins/analysis-kuromoji/src/main/java/org/elasticsearch/index/analysis/JapaneseStopTokenFilterFactory.java b/plugins/analysis-kuromoji/src/main/java/org/elasticsearch/index/analysis/JapaneseStopTokenFilterFactory.java
index 9515971..433d03d 100644
--- a/plugins/analysis-kuromoji/src/main/java/org/elasticsearch/index/analysis/JapaneseStopTokenFilterFactory.java
+++ b/plugins/analysis-kuromoji/src/main/java/org/elasticsearch/index/analysis/JapaneseStopTokenFilterFactory.java
@@ -25,6 +25,7 @@ import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.ja.JapaneseAnalyzer;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.search.suggest.analyzing.SuggestStopFilter;
+import org.elasticsearch.common.collect.MapBuilder;
 import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.inject.assistedinject.Assisted;
 import org.elasticsearch.common.settings.Settings;
@@ -35,10 +36,8 @@ import org.elasticsearch.index.settings.IndexSettings;
 import java.util.Map;
 import java.util.Set;
 
-import static java.util.Collections.singletonMap;
-
 public class JapaneseStopTokenFilterFactory extends AbstractTokenFilterFactory{
-    private static final Map<String, Set<?>> NAMED_STOP_WORDS = singletonMap("_japanese_", JapaneseAnalyzer.getDefaultStopSet());
+
 
     private final CharArraySet stopWords;
 
@@ -51,7 +50,10 @@ public class JapaneseStopTokenFilterFactory extends AbstractTokenFilterFactory{
         super(index, indexSettings, name, settings);
         this.ignoreCase = settings.getAsBoolean("ignore_case", false);
         this.removeTrailing = settings.getAsBoolean("remove_trailing", true);
-        this.stopWords = Analysis.parseWords(env, settings, "stopwords", JapaneseAnalyzer.getDefaultStopSet(), NAMED_STOP_WORDS, ignoreCase);
+        Map<String, Set<?>> namedStopWords = MapBuilder.<String, Set<?>>newMapBuilder()
+            .put("_japanese_", JapaneseAnalyzer.getDefaultStopSet())
+            .immutableMap();
+        this.stopWords = Analysis.parseWords(env, settings, "stopwords", JapaneseAnalyzer.getDefaultStopSet(), namedStopWords, ignoreCase);
     }
 
     @Override
diff --git a/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java b/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java
index e05fc31..5b61787 100644
--- a/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java
+++ b/plugins/discovery-multicast/src/main/java/org/elasticsearch/plugin/discovery/multicast/MulticastZenPing.java
@@ -19,8 +19,6 @@
 
 package org.elasticsearch.plugin.discovery.multicast;
 
-import com.carrotsearch.hppc.cursors.ObjectObjectCursor;
-
 import org.apache.lucene.util.Constants;
 import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.Version;
@@ -46,13 +44,7 @@ import org.elasticsearch.common.xcontent.XContentType;
 import org.elasticsearch.discovery.zen.ping.PingContextProvider;
 import org.elasticsearch.discovery.zen.ping.ZenPing;
 import org.elasticsearch.threadpool.ThreadPool;
-import org.elasticsearch.transport.EmptyTransportResponseHandler;
-import org.elasticsearch.transport.TransportChannel;
-import org.elasticsearch.transport.TransportException;
-import org.elasticsearch.transport.TransportRequest;
-import org.elasticsearch.transport.TransportRequestHandler;
-import org.elasticsearch.transport.TransportResponse;
-import org.elasticsearch.transport.TransportService;
+import org.elasticsearch.transport.*;
 
 import java.io.IOException;
 import java.net.SocketAddress;
@@ -491,8 +483,8 @@ public class MulticastZenPing extends AbstractLifecycleComponent<ZenPing> implem
                 }
 
                 builder.startObject("attributes");
-                for (ObjectObjectCursor<String, String> attr : localNode.attributes()) {
-                    builder.field(attr.key, attr.value);
+                for (Map.Entry<String, String> attr : localNode.attributes().entrySet()) {
+                    builder.field(attr.getKey(), attr.getValue());
                 }
                 builder.endObject();
 
diff --git a/plugins/lang-expression/src/main/java/org/elasticsearch/script/expression/ExpressionScriptEngineService.java b/plugins/lang-expression/src/main/java/org/elasticsearch/script/expression/ExpressionScriptEngineService.java
index 71668c4..72a1dd7 100644
--- a/plugins/lang-expression/src/main/java/org/elasticsearch/script/expression/ExpressionScriptEngineService.java
+++ b/plugins/lang-expression/src/main/java/org/elasticsearch/script/expression/ExpressionScriptEngineService.java
@@ -237,17 +237,6 @@ public class ExpressionScriptEngineService extends AbstractComponent implements
     }
 
     @Override
-    public Object execute(CompiledScript compiledScript, Map<String, Object> vars) {
-        ExpressionExecutableScript expressionExecutableScript = new ExpressionExecutableScript(compiledScript, vars);
-        return expressionExecutableScript.run();
-    }
-
-    @Override
-    public Object unwrap(Object value) {
-        return value;
-    }
-
-    @Override
     public void close() {}
 
     @Override
diff --git a/plugins/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java b/plugins/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java
index 1644eff..d1e7160 100644
--- a/plugins/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java
+++ b/plugins/lang-groovy/src/main/java/org/elasticsearch/script/groovy/GroovyScriptEngineService.java
@@ -38,7 +38,6 @@ import org.codehaus.groovy.control.customizers.CompilationCustomizer;
 import org.codehaus.groovy.control.customizers.ImportCustomizer;
 import org.elasticsearch.SpecialPermission;
 import org.elasticsearch.bootstrap.BootstrapInfo;
-import org.elasticsearch.ExceptionsHelper;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.component.AbstractComponent;
 import org.elasticsearch.common.hash.MessageDigests;
@@ -245,25 +244,6 @@ public class GroovyScriptEngineService extends AbstractComponent implements Scri
         };
     }
 
-    @Override
-    public Object execute(CompiledScript compiledScript, Map<String, Object> vars) {
-        try {
-            Map<String, Object> allVars = new HashMap<>();
-            if (vars != null) {
-                allVars.putAll(vars);
-            }
-            Script scriptObject = createScript(compiledScript.compiled(), allVars);
-            return scriptObject.run();
-        } catch (Exception e) {
-            throw new ScriptException("failed to execute " + compiledScript, e);
-        }
-    }
-
-    @Override
-    public Object unwrap(Object value) {
-        return value;
-    }
-
     public static final class GroovyScript implements ExecutableScript, LeafSearchScript {
 
         private final CompiledScript compiledScript;
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/AliasRoutingTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/AliasRoutingTests.java
deleted file mode 100644
index 347d3c7..0000000
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/AliasRoutingTests.java
+++ /dev/null
@@ -1,366 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.messy.tests;
-
-import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.action.search.SearchType;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.plugins.Plugin;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.script.ScriptService;
-import org.elasticsearch.script.groovy.GroovyPlugin;
-import org.elasticsearch.test.ESIntegTestCase;
-import org.junit.Test;
-
-import java.util.Collection;
-import java.util.Collections;
-
-import static org.elasticsearch.cluster.metadata.AliasAction.newAddAliasAction;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.hamcrest.Matchers.equalTo;
-
-/**
- *
- */
-public class AliasRoutingTests extends ESIntegTestCase {
-
-    @Override
-    protected Collection<Class<? extends Plugin>> nodePlugins() {
-        return Collections.singleton(GroovyPlugin.class);
-    }
-    
-    @Override
-    protected int minimumNumberOfShards() {
-        return 2;
-    }
-
-    @Test
-    public void testAliasCrudRouting() throws Exception {
-        createIndex("test");
-        ensureGreen();
-        assertAcked(admin().indices().prepareAliases().addAliasAction(newAddAliasAction("test", "alias0").routing("0")));
-
-        logger.info("--> indexing with id [1], and routing [0] using alias");
-        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-        logger.info("--> verifying get with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
-        }
-
-        logger.info("--> verifying get with routing alias, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-
-        logger.info("--> updating with id [1] and routing through alias");
-        client().prepareUpdate("alias0", "type1", "1")
-                .setUpsert(XContentFactory.jsonBuilder().startObject().field("field", 1).endObject())
-                .setScript(new Script("ctx._source.field = 'value2'", ScriptService.ScriptType.INLINE, null, null))
-                .execute().actionGet();
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().getSourceAsMap().get("field").toString(), equalTo("value2"));
-        }
-
-
-        logger.info("--> deleting with no routing, should not delete anything");
-        client().prepareDelete("test", "type1", "1").setRefresh(true).execute().actionGet();
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-
-        logger.info("--> deleting with routing alias, should delete");
-        client().prepareDelete("alias0", "type1", "1").setRefresh(true).execute().actionGet();
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(false));
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-
-        logger.info("--> indexing with id [1], and routing [0] using alias");
-        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-        logger.info("--> verifying get with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").setRouting("0").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-    }
-
-    @Test
-    public void testAliasSearchRouting() throws Exception {
-        createIndex("test");
-        ensureGreen();
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("test", "alias"))
-                .addAliasAction(newAddAliasAction("test", "alias0").routing("0"))
-                .addAliasAction(newAddAliasAction("test", "alias1").routing("1"))
-                .addAliasAction(newAddAliasAction("test", "alias01").searchRouting("0,1")));
-
-        logger.info("--> indexing with id [1], and routing [0] using alias");
-        client().prepareIndex("alias0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-        logger.info("--> verifying get with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("alias0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-
-        logger.info("--> search with no routing, should fine one");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-        }
-
-        logger.info("--> search with wrong routing, should not find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
-            assertThat(client().prepareCount().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
-            assertThat(client().prepareSearch("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
-            assertThat(client().prepareCount("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
-        }
-
-        logger.info("--> search with correct routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-            assertThat(client().prepareSearch("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-        }
-
-        logger.info("--> indexing with id [2], and routing [1] using alias");
-        client().prepareIndex("alias1", "type1", "2").setSource("field", "value1").setRefresh(true).execute().actionGet();
-
-        logger.info("--> search with no routing, should fine two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount().setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-        logger.info("--> search with 0 routing, should find one");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount().setRouting("0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-            assertThat(client().prepareSearch("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount("alias0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-        }
-
-        logger.info("--> search with 1 routing, should find one");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount().setRouting("1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-            assertThat(client().prepareSearch("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount("alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-        }
-
-        logger.info("--> search with 0,1 routings , should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch().setRouting("0", "1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount().setRouting("0", "1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-            assertThat(client().prepareSearch("alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-        logger.info("--> search with two routing aliases , should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-        logger.info("--> search with alias0, alias1 and alias01, should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias0", "alias1", "alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias0", "alias1", "alias01").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-        logger.info("--> search with test, alias0 and alias1, should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("test", "alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("test", "alias0", "alias1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-    }
-
-    @Test
-    public void testAliasSearchRoutingWithTwoIndices() throws Exception {
-        createIndex("test-a");
-        createIndex("test-b");
-        ensureGreen();
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("test-a", "alias-a0").routing("0"))
-                .addAliasAction(newAddAliasAction("test-a", "alias-a1").routing("1"))
-                .addAliasAction(newAddAliasAction("test-b", "alias-b0").routing("0"))
-                .addAliasAction(newAddAliasAction("test-b", "alias-b1").routing("1"))
-                .addAliasAction(newAddAliasAction("test-a", "alias-ab").searchRouting("0"))
-                .addAliasAction(newAddAliasAction("test-b", "alias-ab").searchRouting("1")));
-        ensureGreen(); // wait for events again to make sure we got the aliases on all nodes
-        logger.info("--> indexing with id [1], and routing [0] using alias to test-a");
-        client().prepareIndex("alias-a0", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test-a", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-        logger.info("--> verifying get with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("alias-a0", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-
-        logger.info("--> indexing with id [0], and routing [1] using alias to test-b");
-        client().prepareIndex("alias-b1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test-a", "type1", "1").execute().actionGet().isExists(), equalTo(false));
-        }
-        logger.info("--> verifying get with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("alias-b1", "type1", "1").execute().actionGet().isExists(), equalTo(true));
-        }
-
-
-        logger.info("--> search with alias-a1,alias-b0, should not find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias-a1", "alias-b0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
-            assertThat(client().prepareCount("alias-a1", "alias-b0").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
-        }
-
-        logger.info("--> search with alias-ab, should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias-ab").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias-ab").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-
-        logger.info("--> search with alias-a0,alias-b1 should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias-a0", "alias-b1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias-a0", "alias-b1").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-    }
-
-    /*
-    See https://github.com/elasticsearch/elasticsearch/issues/2682
-    Searching on more than one index, if one of those is an alias with configured routing, the shards that belonged
-    to the other indices (without routing) were not taken into account in PlainOperationRouting#searchShards.
-    That affected the number of shards that we executed the search on, thus some documents were missing in the search results.
-     */
-    @Test
-    public void testAliasSearchRoutingWithConcreteAndAliasedIndices_issue2682() throws Exception {
-        createIndex("index", "index_2");
-        ensureGreen();
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("index", "index_1").routing("1")));
-
-        logger.info("--> indexing on index_1 which is an alias for index with routing [1]");
-        client().prepareIndex("index_1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> indexing on index_2 which is a concrete index");
-        client().prepareIndex("index_2", "type2", "2").setSource("field", "value2").setRefresh(true).execute().actionGet();
-
-
-        logger.info("--> search all on index_* should find two");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("index_*").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-        }
-    }
-
-    /*
-    See https://github.com/elasticsearch/elasticsearch/pull/3268
-    Searching on more than one index, if one of those is an alias with configured routing, the shards that belonged
-    to the other indices (without routing) were not taken into account in PlainOperationRouting#searchShardsCount.
-    That could cause returning 1, which led to forcing the QUERY_AND_FETCH mode.
-    As a result, (size * number of hit shards) results were returned and no reduce phase was taking place.
-     */
-    @Test
-    public void testAliasSearchRoutingWithConcreteAndAliasedIndices_issue3268() throws Exception {
-        createIndex("index", "index_2");
-        ensureGreen();
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("index", "index_1").routing("1")));
-
-        logger.info("--> indexing on index_1 which is an alias for index with routing [1]");
-        client().prepareIndex("index_1", "type1", "1").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> indexing on index_2 which is a concrete index");
-        client().prepareIndex("index_2", "type2", "2").setSource("field", "value2").setRefresh(true).execute().actionGet();
-
-        SearchResponse searchResponse = client().prepareSearch("index_*").setSearchType(SearchType.QUERY_THEN_FETCH).setSize(1).setQuery(QueryBuilders.matchAllQuery()).execute().actionGet();
-
-        logger.info("--> search all on index_* should find two");
-        assertThat(searchResponse.getHits().totalHits(), equalTo(2L));
-        //Let's make sure that, even though 2 docs are available, only one is returned according to the size we set in the request
-        //Therefore the reduce phase has taken place, which proves that the QUERY_AND_FETCH search type wasn't erroneously forced.
-        assertThat(searchResponse.getHits().getHits().length, equalTo(1));
-    }
-
-    @Test
-    public void testIndexingAliasesOverTime() throws Exception {
-        createIndex("test");
-        ensureGreen();
-        logger.info("--> creating alias with routing [3]");
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("test", "alias").routing("3")));
-
-        logger.info("--> indexing with id [0], and routing [3]");
-        client().prepareIndex("alias", "type1", "0").setSource("field", "value1").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-
-        logger.info("--> verifying get and search with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "0").setRouting("3").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(1l));
-            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(1l));
-        }
-
-        logger.info("--> creating alias with routing [4]");
-        assertAcked(admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("test", "alias").routing("4")));
-
-        logger.info("--> verifying search with wrong routing should not find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(0l));
-            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(0l));
-        }
-
-        logger.info("--> creating alias with search routing [3,4] and index routing 4");
-        assertAcked(client().admin().indices().prepareAliases()
-                .addAliasAction(newAddAliasAction("test", "alias").searchRouting("3,4").indexRouting("4")));
-
-        logger.info("--> indexing with id [1], and routing [4]");
-        client().prepareIndex("alias", "type1", "1").setSource("field", "value2").setRefresh(true).execute().actionGet();
-        logger.info("--> verifying get with no routing, should not find anything");
-
-        logger.info("--> verifying get and search with routing, should find");
-        for (int i = 0; i < 5; i++) {
-            assertThat(client().prepareGet("test", "type1", "0").setRouting("3").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareGet("test", "type1", "1").setRouting("4").execute().actionGet().isExists(), equalTo(true));
-            assertThat(client().prepareSearch("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().totalHits(), equalTo(2l));
-            assertThat(client().prepareCount("alias").setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getCount(), equalTo(2l));
-        }
-    }
-
-}
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/QueryRescorerTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/QueryRescorerTests.java
deleted file mode 100644
index f437009..0000000
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/QueryRescorerTests.java
+++ /dev/null
@@ -1,763 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.messy.tests;
-
-
-
-import org.apache.lucene.search.Explanation;
-import org.apache.lucene.util.English;
-import org.elasticsearch.action.index.IndexRequestBuilder;
-import org.elasticsearch.action.search.SearchRequestBuilder;
-import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.action.search.SearchType;
-import org.elasticsearch.common.lucene.search.function.CombineFunction;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.settings.Settings.Builder;
-import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.query.Operator;
-import org.elasticsearch.index.query.QueryBuilders;
-import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
-import org.elasticsearch.plugins.Plugin;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.script.groovy.GroovyPlugin;
-import org.elasticsearch.search.SearchHit;
-import org.elasticsearch.search.SearchHits;
-import org.elasticsearch.search.rescore.RescoreBuilder;
-import org.elasticsearch.search.rescore.RescoreBuilder.QueryRescorer;
-import org.elasticsearch.test.ESIntegTestCase;
-import org.junit.Test;
-
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_REPLICAS;
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
-import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
-import static org.hamcrest.Matchers.*;
-
-/**
- *
- */
-public class QueryRescorerTests extends ESIntegTestCase {
-
-    @Override
-    protected Collection<Class<? extends Plugin>> nodePlugins() {
-        return Collections.singleton(GroovyPlugin.class);
-    }
-
-    @Test
-    public void testEnforceWindowSize() {
-        createIndex("test");
-        // this
-        int iters = scaledRandomIntBetween(10, 20);
-        for (int i = 0; i < iters; i ++) {
-            client().prepareIndex("test", "type", Integer.toString(i)).setSource("f", Integer.toString(i)).execute().actionGet();
-        }
-        ensureYellow();
-        refresh();
-
-        int numShards = getNumShards("test").numPrimaries;
-        for (int j = 0 ; j < iters; j++) {
-            SearchResponse searchResponse = client().prepareSearch()
-                    .setQuery(QueryBuilders.matchAllQuery())
-                    .setRescorer(RescoreBuilder.queryRescorer(
-                            QueryBuilders.functionScoreQuery(QueryBuilders.matchAllQuery(),
-                                    ScoreFunctionBuilders.weightFactorFunction(100)).boostMode(CombineFunction.REPLACE)).setQueryWeight(0.0f).setRescoreQueryWeight(1.0f))
-                    .setRescoreWindow(1).setSize(randomIntBetween(2, 10)).execute().actionGet();
-            assertSearchResponse(searchResponse);
-            assertFirstHit(searchResponse, hasScore(100.f));
-            int numDocsWith100AsAScore = 0;
-            for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
-                float score = searchResponse.getHits().hits()[i].getScore();
-                if  (score == 100f) {
-                    numDocsWith100AsAScore += 1;
-                }
-            }
-            // we cannot assert that they are equal since some shards might not have docs at all
-            assertThat(numDocsWith100AsAScore, lessThanOrEqualTo(numShards));
-        }
-    }
-
-    @Test
-    public void testRescorePhrase() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping(
-                        "type1",
-                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
-                                .field("analyzer", "whitespace").field("type", "string").endObject().endObject().endObject().endObject())
-                .setSettings(Settings.settingsBuilder().put(indexSettings()).put("index.number_of_shards", 1)));
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox").execute().actionGet();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree ").get();
-        client().prepareIndex("test", "type1", "3")
-                .setSource("field1", "quick huge brown", "field2", "the quick lazy huge brown fox jumps over the tree").get();
-        ensureYellow();
-        refresh();
-        SearchResponse searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "quick brown").slop(2).boost(4.0f)).setRescoreQueryWeight(2))
-                .setRescoreWindow(5).execute().actionGet();
-
-        assertThat(searchResponse.getHits().totalHits(), equalTo(3l));
-        assertThat(searchResponse.getHits().getHits()[0].getId(), equalTo("1"));
-        assertThat(searchResponse.getHits().getHits()[1].getId(), equalTo("3"));
-        assertThat(searchResponse.getHits().getHits()[2].getId(), equalTo("2"));
-
-        searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                .setRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(3)))
-                .setRescoreWindow(5).execute().actionGet();
-
-        assertHitCount(searchResponse, 3);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client().prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                .setRescorer(RescoreBuilder.queryRescorer((QueryBuilders.matchPhraseQuery("field1", "the quick brown"))))
-                .setRescoreWindow(5).execute().actionGet();
-
-        assertHitCount(searchResponse, 3);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-    }
-
-    @Test
-    public void testMoreDocs() throws Exception {
-        Builder builder = Settings.builder();
-        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
-        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
-        builder.put("index.analysis.filter.synonym.type", "synonym");
-        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
-
-        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
-                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
-                .endObject().endObject().endObject().endObject();
-
-        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "massachusetts avenue boston massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "3").setSource("field1", "boston avenue lexington massachusetts").execute().actionGet();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        client().prepareIndex("test", "type1", "4").setSource("field1", "boston road lexington massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "5").setSource("field1", "lexington street lexington massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "7").setSource("field1", "bosten street san franciso california").execute().actionGet();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        client().prepareIndex("test", "type1", "8").setSource("field1", "hollywood boulevard los angeles california").execute().actionGet();
-        client().prepareIndex("test", "type1", "9").setSource("field1", "1st street boston massachussetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "10").setSource("field1", "1st street boston massachusetts").execute().actionGet();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        client().prepareIndex("test", "type1", "11").setSource("field1", "2st street boston massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "12").setSource("field1", "3st street boston massachusetts").execute().actionGet();
-        ensureYellow();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        SearchResponse searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
-                .setFrom(0)
-                .setSize(5)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
-
-        assertThat(searchResponse.getHits().hits().length, equalTo(5));
-        assertHitCount(searchResponse, 9);
-        assertFirstHit(searchResponse, hasId("2"));
-        assertSecondHit(searchResponse, hasId("6"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
-                .setFrom(0)
-                .setSize(5)
-                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
-
-        assertThat(searchResponse.getHits().hits().length, equalTo(5));
-        assertHitCount(searchResponse, 9);
-        assertFirstHit(searchResponse, hasId("2"));
-        assertSecondHit(searchResponse, hasId("6"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        // Make sure non-zero from works:
-        searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "lexington avenue massachusetts").operator(Operator.OR))
-                .setFrom(2)
-                .setSize(5)
-                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(20).execute().actionGet();
-
-        assertThat(searchResponse.getHits().hits().length, equalTo(5));
-        assertHitCount(searchResponse, 9);
-        assertFirstHit(searchResponse, hasId("3"));
-    }
-
-    // Tests a rescore window smaller than number of hits:
-    @Test
-    public void testSmallRescoreWindow() throws Exception {
-        Builder builder = Settings.builder();
-        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
-        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
-        builder.put("index.analysis.filter.synonym.type", "synonym");
-        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
-
-        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
-                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
-                .endObject().endObject().endObject().endObject();
-
-        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
-
-        client().prepareIndex("test", "type1", "3").setSource("field1", "massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        client().prepareIndex("test", "type1", "1").setSource("field1", "lexington massachusetts avenue").execute().actionGet();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts road").execute().actionGet();
-        ensureYellow();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-
-        SearchResponse searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
-                .setFrom(0)
-            .setSize(5).execute().actionGet();
-        assertThat(searchResponse.getHits().hits().length, equalTo(4));
-        assertHitCount(searchResponse, 4);
-        assertFirstHit(searchResponse, hasId("3"));
-        assertSecondHit(searchResponse, hasId("6"));
-        assertThirdHit(searchResponse, hasId("1"));
-        assertFourthHit(searchResponse, hasId("2"));
-
-        // Now, rescore only top 2 hits w/ proximity:
-        searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
-                .setFrom(0)
-                .setSize(5)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(2).execute().actionGet();
-        // Only top 2 hits were re-ordered:
-        assertThat(searchResponse.getHits().hits().length, equalTo(4));
-        assertHitCount(searchResponse, 4);
-        assertFirstHit(searchResponse, hasId("6"));
-        assertSecondHit(searchResponse, hasId("3"));
-        assertThirdHit(searchResponse, hasId("1"));
-        assertFourthHit(searchResponse, hasId("2"));
-
-        // Now, rescore only top 3 hits w/ proximity:
-        searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts"))
-                .setFrom(0)
-                .setSize(5)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(0.6f).setRescoreQueryWeight(2.0f)).setRescoreWindow(3).execute().actionGet();
-
-        // Only top 3 hits were re-ordered:
-        assertThat(searchResponse.getHits().hits().length, equalTo(4));
-        assertHitCount(searchResponse, 4);
-        assertFirstHit(searchResponse, hasId("6"));
-        assertSecondHit(searchResponse, hasId("1"));
-        assertThirdHit(searchResponse, hasId("3"));
-        assertFourthHit(searchResponse, hasId("2"));
-    }
-
-    // Tests a rescorer that penalizes the scores:
-    @Test
-    public void testRescorerMadeScoresWorse() throws Exception {
-        Builder builder = Settings.builder();
-        builder.put("index.analysis.analyzer.synonym.tokenizer", "whitespace");
-        builder.putArray("index.analysis.analyzer.synonym.filter", "synonym", "lowercase");
-        builder.put("index.analysis.filter.synonym.type", "synonym");
-        builder.putArray("index.analysis.filter.synonym.synonyms", "ave => ave, avenue", "street => str, street");
-
-        XContentBuilder mapping = XContentFactory.jsonBuilder().startObject().startObject("type1").startObject("properties")
-                .startObject("field1").field("type", "string").field("analyzer", "whitespace").field("search_analyzer", "synonym")
-                .endObject().endObject().endObject().endObject();
-
-        assertAcked(client().admin().indices().prepareCreate("test").addMapping("type1", mapping).setSettings(builder.put("index.number_of_shards", 1)));
-
-        client().prepareIndex("test", "type1", "3").setSource("field1", "massachusetts").execute().actionGet();
-        client().prepareIndex("test", "type1", "6").setSource("field1", "massachusetts avenue lexington massachusetts").execute().actionGet();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-        client().prepareIndex("test", "type1", "1").setSource("field1", "lexington massachusetts avenue").execute().actionGet();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "lexington avenue boston massachusetts road").execute().actionGet();
-        ensureYellow();
-        client().admin().indices().prepareRefresh("test").execute().actionGet();
-
-        SearchResponse searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
-                .setFrom(0)
-            .setSize(5).execute().actionGet();
-        assertThat(searchResponse.getHits().hits().length, equalTo(4));
-        assertHitCount(searchResponse, 4);
-        assertFirstHit(searchResponse, hasId("3"));
-        assertSecondHit(searchResponse, hasId("6"));
-        assertThirdHit(searchResponse, hasId("1"));
-        assertFourthHit(searchResponse, hasId("2"));
-
-        // Now, penalizing rescore (nothing matches the rescore query):
-        searchResponse = client()
-                .prepareSearch()
-                .setQuery(QueryBuilders.matchQuery("field1", "massachusetts").operator(Operator.OR))
-                .setFrom(0)
-                .setSize(5)
-                .setRescorer(
-                        RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "lexington avenue massachusetts").slop(3))
-                                .setQueryWeight(1.0f).setRescoreQueryWeight(-1f)).setRescoreWindow(3).execute().actionGet();
-
-        // 6 and 1 got worse, and then the hit (2) outside the rescore window were sorted ahead:
-        assertFirstHit(searchResponse, hasId("3"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("6"));
-        assertFourthHit(searchResponse, hasId("1"));
-    }
-
-    // Comparator that sorts hits and rescored hits in the same way.
-    // The rescore uses the docId as tie, while regular search uses the slot the hit is in as a tie if score
-    // and shard id are equal during merging shard results.
-    // This comparator uses a custom tie in case the scores are equal, so that both regular hits and rescored hits
-    // are sorted equally. This is fine since tests only care about the fact the scores should be equal, not ordering.
-    private final static Comparator<SearchHit> searchHitsComparator = new Comparator<SearchHit>() {
-        @Override
-        public int compare(SearchHit hit1, SearchHit hit2) {
-            int cmp = Float.compare(hit2.getScore(), hit1.getScore());
-            if (cmp == 0) {
-                return hit1.id().compareTo(hit2.id());
-            } else {
-                return cmp;
-            }
-        }
-    };
-
-    private static void assertEquivalent(String query, SearchResponse plain, SearchResponse rescored) {
-        assertNoFailures(plain);
-        assertNoFailures(rescored);
-        SearchHits leftHits = plain.getHits();
-        SearchHits rightHits = rescored.getHits();
-        assertThat(leftHits.getTotalHits(), equalTo(rightHits.getTotalHits()));
-        assertThat(leftHits.getHits().length, equalTo(rightHits.getHits().length));
-        SearchHit[] hits = leftHits.getHits();
-        SearchHit[] rHits = rightHits.getHits();
-        Arrays.sort(hits, searchHitsComparator);
-        Arrays.sort(rHits, searchHitsComparator);
-        for (int i = 0; i < hits.length; i++) {
-            assertThat("query: " + query, hits[i].getScore(), equalTo(rHits[i].getScore()));
-        }
-        for (int i = 0; i < hits.length; i++) {
-            if (hits[i].getScore() == hits[hits.length-1].getScore()) {
-                return; // we need to cut off here since this is the tail of the queue and we might not have fetched enough docs
-            }
-            assertThat("query: " + query,hits[i].getId(), equalTo(rHits[i].getId()));
-        }
-    }
-
-    private static void assertEquivalentOrSubstringMatch(String query, SearchResponse plain, SearchResponse rescored) {
-        assertNoFailures(plain);
-        assertNoFailures(rescored);
-        SearchHits leftHits = plain.getHits();
-        SearchHits rightHits = rescored.getHits();
-        assertThat(leftHits.getTotalHits(), equalTo(rightHits.getTotalHits()));
-        assertThat(leftHits.getHits().length, equalTo(rightHits.getHits().length));
-        SearchHit[] hits = leftHits.getHits();
-        SearchHit[] otherHits = rightHits.getHits();
-        if (!hits[0].getId().equals(otherHits[0].getId())) {
-            assertThat(((String) otherHits[0].sourceAsMap().get("field1")).contains(query), equalTo(true));
-        } else {
-            Arrays.sort(hits, searchHitsComparator);
-            Arrays.sort(otherHits, searchHitsComparator);
-            for (int i = 0; i < hits.length; i++) {
-                if (hits[i].getScore() == hits[hits.length-1].getScore()) {
-                    return; // we need to cut off here since this is the tail of the queue and we might not have fetched enough docs
-                }
-                assertThat(query, hits[i].getId(), equalTo(rightHits.getHits()[i].getId()));
-            }
-        }
-    }
-
-    @Test
-    // forces QUERY_THEN_FETCH because of https://github.com/elasticsearch/elasticsearch/issues/4829
-    public void testEquivalence() throws Exception {
-        // no dummy docs since merges can change scores while we run queries.
-        int numDocs = indexRandomNumbers("whitespace", -1, false);
-
-        final int iters = scaledRandomIntBetween(50, 100);
-        for (int i = 0; i < iters; i++) {
-            int resultSize = numDocs;
-            int rescoreWindow = between(1, 3) * resultSize;
-            String intToEnglish = English.intToEnglish(between(0, numDocs-1));
-            String query = intToEnglish.split(" ")[0];
-            SearchResponse rescored = client()
-                    .prepareSearch()
-                    .setSearchType(SearchType.QUERY_THEN_FETCH)
-                    .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
-                    .setFrom(0)
-                    .setSize(resultSize)
-                    .setRescorer(
-                            RescoreBuilder
-                                    .queryRescorer(
-                                            QueryBuilders
-                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery("field1", intToEnglish).slop(3)))
-                                    .setQueryWeight(1.0f)
-                                    .setRescoreQueryWeight(0.0f)) // no weight - so we basically use the same score as the actual query
-                    .setRescoreWindow(rescoreWindow).execute().actionGet();
-
-            SearchResponse plain = client().prepareSearch()
-                    .setSearchType(SearchType.QUERY_THEN_FETCH)
-                    .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR)).setFrom(0).setSize(resultSize)
-                    .execute().actionGet();
-            
-            // check equivalence
-            assertEquivalent(query, plain, rescored);
-
-            rescored = client()
-                    .prepareSearch()
-                    .setSearchType(SearchType.QUERY_THEN_FETCH)
-                    .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
-                    .setFrom(0)
-                    .setSize(resultSize)
-                    .setRescorer(
-                            RescoreBuilder
-                                    .queryRescorer(
-                                            QueryBuilders
-                                                    .constantScoreQuery(QueryBuilders.matchPhraseQuery("field1", "not in the index").slop(3)))
-                                    .setQueryWeight(1.0f)
-                                    .setRescoreQueryWeight(1.0f))
-                    .setRescoreWindow(rescoreWindow).execute().actionGet();
-            // check equivalence
-            assertEquivalent(query, plain, rescored);
-
-            rescored = client()
-                    .prepareSearch()
-                    .setSearchType(SearchType.QUERY_THEN_FETCH)
-                    .setPreference("test") // ensure we hit the same shards for tie-breaking
-                    .setQuery(QueryBuilders.matchQuery("field1", query).operator(Operator.OR))
-                    .setFrom(0)
-                    .setSize(resultSize)
-                    .setRescorer(
-                            RescoreBuilder
-                                    .queryRescorer(
-                                            QueryBuilders.matchPhraseQuery("field1", intToEnglish).slop(0))
-                                    .setQueryWeight(1.0f).setRescoreQueryWeight(1.0f)).setRescoreWindow(2 * rescoreWindow).execute().actionGet();
-            // check equivalence or if the first match differs we check if the phrase is a substring of the top doc
-            assertEquivalentOrSubstringMatch(intToEnglish, plain, rescored);
-        }
-    }
-
-    @Test
-    public void testExplain() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping(
-                        "type1",
-                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
-                                .field("analyzer", "whitespace").field("type", "string").endObject().endObject().endObject().endObject())
-        );
-        ensureGreen();
-        client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox").execute().actionGet();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree").execute()
-                .actionGet();
-        client().prepareIndex("test", "type1", "3")
-                .setSource("field1", "quick huge brown", "field2", "the quick lazy huge brown fox jumps over the tree").execute()
-                .actionGet();
-        ensureYellow();
-        refresh();
-
-        {
-            SearchResponse searchResponse = client()
-                    .prepareSearch()
-                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                    .setRescorer(
-                            RescoreBuilder.queryRescorer(QueryBuilders.matchPhraseQuery("field1", "the quick brown").slop(2).boost(4.0f))
-                                    .setQueryWeight(0.5f).setRescoreQueryWeight(0.4f)).setRescoreWindow(5).setExplain(true).execute()
-                    .actionGet();
-            assertHitCount(searchResponse, 3);
-            assertFirstHit(searchResponse, hasId("1"));
-            assertSecondHit(searchResponse, hasId("2"));
-            assertThirdHit(searchResponse, hasId("3"));
-
-            for (int i = 0; i < 3; i++) {
-                assertThat(searchResponse.getHits().getAt(i).explanation(), notNullValue());
-                assertThat(searchResponse.getHits().getAt(i).explanation().isMatch(), equalTo(true));
-                assertThat(searchResponse.getHits().getAt(i).explanation().getDetails().length, equalTo(2));
-                assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[0].isMatch(), equalTo(true));
-                if (i == 2) {
-                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[1].getValue(), equalTo(0.5f));
-                } else {
-                    assertThat(searchResponse.getHits().getAt(i).explanation().getDescription(), equalTo("sum of:"));
-                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[0].getDetails()[1].getValue(), equalTo(0.5f));
-                    assertThat(searchResponse.getHits().getAt(i).explanation().getDetails()[1].getDetails()[1].getValue(), equalTo(0.4f));
-                }
-            }
-        }
-
-        String[] scoreModes = new String[]{ "max", "min", "avg", "total", "multiply", "" };
-        String[] descriptionModes = new String[]{ "max of:", "min of:", "avg of:", "sum of:", "product of:", "sum of:" };
-        for (int innerMode = 0; innerMode < scoreModes.length; innerMode++) {
-            QueryRescorer innerRescoreQuery = RescoreBuilder.queryRescorer(QueryBuilders.matchQuery("field1", "the quick brown").boost(4.0f))
-                .setQueryWeight(0.5f).setRescoreQueryWeight(0.4f);
-
-            if (!"".equals(scoreModes[innerMode])) {
-                innerRescoreQuery.setScoreMode(scoreModes[innerMode]);
-            }
-
-            SearchResponse searchResponse = client()
-                    .prepareSearch()
-                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                    .setRescorer(innerRescoreQuery).setRescoreWindow(5).setExplain(true).execute()
-                    .actionGet();
-            assertHitCount(searchResponse, 3);
-            assertFirstHit(searchResponse, hasId("1"));
-            assertSecondHit(searchResponse, hasId("2"));
-            assertThirdHit(searchResponse, hasId("3"));
-
-            for (int j = 0; j < 3; j++) {
-                assertThat(searchResponse.getHits().getAt(j).explanation().getDescription(), equalTo(descriptionModes[innerMode]));
-            }
-
-            for (int outerMode = 0; outerMode < scoreModes.length; outerMode++) {
-                QueryRescorer outerRescoreQuery = RescoreBuilder.queryRescorer(QueryBuilders.matchQuery("field1", "the quick brown")
-                        .boost(4.0f)).setQueryWeight(0.5f).setRescoreQueryWeight(0.4f);
-
-                if (!"".equals(scoreModes[outerMode])) {
-                    outerRescoreQuery.setScoreMode(scoreModes[outerMode]);
-                }
-
-                searchResponse = client()
-                        .prepareSearch()
-                        .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                        .setQuery(QueryBuilders.matchQuery("field1", "the quick brown").operator(Operator.OR))
-                        .addRescorer(innerRescoreQuery).setRescoreWindow(5)
-                        .addRescorer(outerRescoreQuery).setRescoreWindow(10)
-                        .setExplain(true).get();
-                assertHitCount(searchResponse, 3);
-                assertFirstHit(searchResponse, hasId("1"));
-                assertSecondHit(searchResponse, hasId("2"));
-                assertThirdHit(searchResponse, hasId("3"));
-
-                for (int j = 0; j < 3; j++) {
-                    Explanation explanation = searchResponse.getHits().getAt(j).explanation();
-                    assertThat(explanation.getDescription(), equalTo(descriptionModes[outerMode]));
-                    assertThat(explanation.getDetails()[0].getDetails()[0].getDescription(), equalTo(descriptionModes[innerMode]));
-                }
-            }
-        }
-    }
-
-    @Test
-    public void testScoring() throws Exception {
-        int numDocs = indexRandomNumbers("keyword");
-
-        String[] scoreModes = new String[]{ "max", "min", "avg", "total", "multiply", "" };
-        float primaryWeight = 1.1f;
-        float secondaryWeight = 1.6f;
-
-        for (String scoreMode : scoreModes) {
-            for (int i = 0; i < numDocs - 4; i++) {
-                String[] intToEnglish = new String[] { English.intToEnglish(i), English.intToEnglish(i + 1), English.intToEnglish(i + 2), English.intToEnglish(i + 3) };
-
-                QueryRescorer rescoreQuery = RescoreBuilder
-                        .queryRescorer(
-                                QueryBuilders.boolQuery()
-                                        .disableCoord(true)
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]),
-                                                ScoreFunctionBuilders.scriptFunction(new Script("5.0f"))).boostMode(CombineFunction.REPLACE))
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]),
-                                                ScoreFunctionBuilders.scriptFunction(new Script("7.0f"))).boostMode(CombineFunction.REPLACE))
-                                        .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]),
-                                                ScoreFunctionBuilders.scriptFunction(new Script("0.0f"))).boostMode(CombineFunction.REPLACE)))
-                        .setQueryWeight(primaryWeight)
-                        .setRescoreQueryWeight(secondaryWeight);
-
-                if (!"".equals(scoreMode)) {
-                    rescoreQuery.setScoreMode(scoreMode);
-                }
-
-                SearchResponse rescored = client()
-                        .prepareSearch()
-                        .setPreference("test") // ensure we hit the same shards for tie-breaking
-                        .setQuery(QueryBuilders.boolQuery()
-                                .disableCoord(true)
-                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[0]),
-                                        ScoreFunctionBuilders.scriptFunction(new Script("2.0f"))).boostMode(CombineFunction.REPLACE))
-                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[1]),
-                                        ScoreFunctionBuilders.scriptFunction(new Script("3.0f"))).boostMode(CombineFunction.REPLACE))
-                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[2]),
-                                        ScoreFunctionBuilders.scriptFunction(new Script("5.0f"))).boostMode(CombineFunction.REPLACE))
-                                .should(QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", intToEnglish[3]),
-                                        ScoreFunctionBuilders.scriptFunction(new Script("0.2f"))).boostMode(CombineFunction.REPLACE)))
-                                .setFrom(0)
-                                .setSize(10)
-                                .setRescorer(rescoreQuery)
-                                .setRescoreWindow(50).execute().actionGet();
-
-                assertHitCount(rescored, 4);
-
-                if ("total".equals(scoreMode) || "".equals(scoreMode)) {
-                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
-                    assertSecondHit(rescored, hasId(String.valueOf(i)));
-                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
-                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight + 7.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight + 5.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight + 0.0f * secondaryWeight));
-                } else if ("max".equals(scoreMode)) {
-                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
-                    assertSecondHit(rescored, hasId(String.valueOf(i)));
-                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
-                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(7.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight));
-                } else if ("min".equals(scoreMode)) {
-                    assertFirstHit(rescored, hasId(String.valueOf(i + 2)));
-                    assertSecondHit(rescored, hasId(String.valueOf(i + 1)));
-                    assertThirdHit(rescored, hasId(String.valueOf(i)));
-                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(5.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(3.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(2.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.0f * secondaryWeight));
-                } else if ("avg".equals(scoreMode)) {
-                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
-                    assertSecondHit(rescored, hasId(String.valueOf(i + 2)));
-                    assertThirdHit(rescored, hasId(String.valueOf(i)));
-                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo((3.0f * primaryWeight + 7.0f * secondaryWeight) / 2.0f));
-                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(5.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo((2.0f * primaryWeight + 5.0f * secondaryWeight) / 2.0f));
-                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo((0.2f * primaryWeight) / 2.0f));
-                } else if ("multiply".equals(scoreMode)) {
-                    assertFirstHit(rescored, hasId(String.valueOf(i + 1)));
-                    assertSecondHit(rescored, hasId(String.valueOf(i)));
-                    assertThirdHit(rescored, hasId(String.valueOf(i + 2)));
-                    assertThat(rescored.getHits().getHits()[0].getScore(), equalTo(3.0f * primaryWeight * 7.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[1].getScore(), equalTo(2.0f * primaryWeight * 5.0f * secondaryWeight));
-                    assertThat(rescored.getHits().getHits()[2].getScore(), equalTo(5.0f * primaryWeight));
-                    assertThat(rescored.getHits().getHits()[3].getScore(), equalTo(0.2f * primaryWeight * 0.0f * secondaryWeight));
-                }
-            }
-        }
-    }
-
-    @Test
-    public void testMultipleRescores() throws Exception {
-        int numDocs = indexRandomNumbers("keyword", 1, true);
-        QueryRescorer eightIsGreat = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(8)),
-                        ScoreFunctionBuilders.scriptFunction(new Script("1000.0f"))).boostMode(CombineFunction.REPLACE)).setScoreMode("total");
-        QueryRescorer sevenIsBetter = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.termQuery("field1", English.intToEnglish(7)),
-                        ScoreFunctionBuilders.scriptFunction(new Script("10000.0f"))).boostMode(CombineFunction.REPLACE))
-                .setScoreMode("total");
-
-        // First set the rescore window large enough that both rescores take effect
-        SearchRequestBuilder request = client().prepareSearch().setRescoreWindow(numDocs);
-        request.addRescorer(eightIsGreat).addRescorer(sevenIsBetter);
-        SearchResponse response = request.get();
-        assertFirstHit(response, hasId("7"));
-        assertSecondHit(response, hasId("8"));
-
-        // Now squash the second rescore window so it never gets to see a seven
-        response = request.setSize(1).clearRescorers().addRescorer(eightIsGreat).addRescorer(sevenIsBetter, 1).get();
-        assertFirstHit(response, hasId("8"));
-        // We have no idea what the second hit will be because we didn't get a chance to look for seven
-
-        // Now use one rescore to drag the number we're looking for into the window of another
-        QueryRescorer ninetyIsGood = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*ninety*"), ScoreFunctionBuilders.scriptFunction(new Script("1000.0f")))
-                        .boostMode(CombineFunction.REPLACE)).setScoreMode("total");
-        QueryRescorer oneToo = RescoreBuilder.queryRescorer(
-                QueryBuilders.functionScoreQuery(QueryBuilders.queryStringQuery("*one*"), ScoreFunctionBuilders.scriptFunction(new Script("1000.0f")))
-                        .boostMode(CombineFunction.REPLACE)).setScoreMode("total");
-        request.clearRescorers().addRescorer(ninetyIsGood).addRescorer(oneToo, 10);
-        response = request.setSize(2).get();
-        assertFirstHit(response, hasId("91"));
-        assertFirstHit(response, hasScore(2001.0f));
-        assertSecondHit(response, hasScore(1001.0f)); // Not sure which one it is but it is ninety something
-    }
-
-    private int indexRandomNumbers(String analyzer) throws Exception {
-        return indexRandomNumbers(analyzer, -1, true);
-    }
-
-    private int indexRandomNumbers(String analyzer, int shards, boolean dummyDocs) throws Exception {
-        Builder builder = Settings.settingsBuilder().put(indexSettings());
-
-        if (shards > 0) {
-            builder.put(SETTING_NUMBER_OF_SHARDS, shards);
-        }
-
-        assertAcked(prepareCreate("test")
-                .addMapping(
-                        "type1",
-                        jsonBuilder().startObject().startObject("type1").startObject("properties").startObject("field1")
-                                .field("analyzer", analyzer).field("type", "string").endObject().endObject().endObject().endObject())
-                .setSettings(builder));
-        int numDocs = randomIntBetween(100, 150);
-        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
-        for (int i = 0; i < numDocs; i++) {
-            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource("field1", English.intToEnglish(i));
-        }
-
-        indexRandom(true, dummyDocs, docs);
-        ensureGreen();
-        return numDocs;
-    }
-
-    // #11277
-    public void testFromSize() throws Exception {
-        Builder settings = Settings.builder();
-        settings.put(SETTING_NUMBER_OF_SHARDS, 1);
-        settings.put(SETTING_NUMBER_OF_REPLICAS, 0);
-        assertAcked(prepareCreate("test").setSettings(settings));
-        for(int i=0;i<5;i++) {
-            client().prepareIndex("test", "type", ""+i).setSource("text", "hello world").get();
-        }
-        refresh();
-
-        SearchRequestBuilder request = client().prepareSearch();
-        request.setQuery(QueryBuilders.termQuery("text", "hello"));
-        request.setFrom(1);
-        request.setSize(4);
-        request.addRescorer(RescoreBuilder.queryRescorer(QueryBuilders.matchAllQuery()));
-        request.setRescoreWindow(50);
-
-        assertEquals(4, request.get().getHits().hits().length);
-    }
-}
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchQueryTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchQueryTests.java
deleted file mode 100644
index 7b8ea71..0000000
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchQueryTests.java
+++ /dev/null
@@ -1,2218 +0,0 @@
-/*
- * Licensed to Elasticsearch under one or more contributor
- * license agreements. See the NOTICE file distributed with
- * this work for additional information regarding copyright
- * ownership. Elasticsearch licenses this file to you under
- * the Apache License, Version 2.0 (the "License"); you may
- * not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.elasticsearch.messy.tests;
-
-import org.apache.lucene.util.English;
-import org.elasticsearch.Version;
-import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
-import org.elasticsearch.action.index.IndexRequestBuilder;
-import org.elasticsearch.action.search.SearchPhaseExecutionException;
-import org.elasticsearch.action.search.SearchResponse;
-import org.elasticsearch.action.search.SearchType;
-import org.elasticsearch.action.search.ShardSearchFailure;
-import org.elasticsearch.cluster.metadata.IndexMetaData;
-import org.elasticsearch.common.Strings;
-import org.elasticsearch.common.settings.Settings;
-import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.index.mapper.MapperParsingException;
-import org.elasticsearch.index.query.*;
-import org.elasticsearch.index.search.MatchQuery.Type;
-import org.elasticsearch.index.search.MatchQuery;
-import org.elasticsearch.indices.cache.query.terms.TermsLookup;
-import org.elasticsearch.plugins.Plugin;
-import org.elasticsearch.rest.RestStatus;
-import org.elasticsearch.script.Script;
-import org.elasticsearch.script.groovy.GroovyPlugin;
-import org.elasticsearch.search.SearchHit;
-import org.elasticsearch.search.SearchHits;
-import org.elasticsearch.search.aggregations.AggregationBuilders;
-import org.elasticsearch.test.ESIntegTestCase;
-import org.joda.time.DateTime;
-import org.joda.time.DateTimeZone;
-import org.joda.time.format.ISODateTimeFormat;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Random;
-import java.util.concurrent.ExecutionException;
-
-import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
-import static org.elasticsearch.common.settings.Settings.settingsBuilder;
-import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.*;
-import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
-import static org.elasticsearch.test.VersionUtils.randomVersion;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
-import static org.hamcrest.Matchers.*;
-
-public class SearchQueryTests extends ESIntegTestCase {
-
-    @Override
-    protected Collection<Class<? extends Plugin>> nodePlugins() {
-        return Collections.singleton(GroovyPlugin.class);
-    }
-    
-    @Override
-    protected int maximumNumberOfShards() {
-        return 7;
-    }
-
-    @Override
-    protected int maximumNumberOfReplicas() {
-        return Math.min(2, cluster().numDataNodes() - 1);
-    }
-
-    @Test
-    public void testOmitNormsOnAll() throws ExecutionException, InterruptedException, IOException {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
-                        .startObject("_all").field("omit_norms", true).endObject()
-                        .endObject().endObject())
-                .setSettings(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)); // only one shard otherwise IDF might be different for comparing scores
-
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
-                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
-
-        assertHitCount(client().prepareSearch().setQuery(matchQuery("_all", "quick")).get(), 3l);
-        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("_all", "quick")).setExplain(true).get();
-        SearchHit[] hits = searchResponse.getHits().hits();
-        assertThat(hits.length, equalTo(3));
-        assertThat(hits[0].score(), allOf(equalTo(hits[1].getScore()), equalTo(hits[2].getScore())));
-        cluster().wipeIndices("test");
-
-        createIndex("test");
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
-                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
-
-        assertHitCount(client().prepareSearch().setQuery(matchQuery("_all", "quick")).get(), 3l);
-        searchResponse = client().prepareSearch().setQuery(matchQuery("_all", "quick")).get();
-        hits = searchResponse.getHits().hits();
-        assertThat(hits.length, equalTo(3));
-        assertThat(hits[0].score(), allOf(greaterThan(hits[1].getScore()), greaterThan(hits[2].getScore())));
-
-    }
-    @Test // see #3952
-    public void testEmptyQueryString() throws ExecutionException, InterruptedException, IOException {
-        createIndex("test");
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
-                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
-
-        assertHitCount(client().prepareSearch().setQuery(queryStringQuery("quick")).get(), 3l);
-        assertHitCount(client().prepareSearch().setQuery(queryStringQuery("")).get(), 0l); // return no docs
-    }
-
-    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3177
-    public void testIssue3177() {
-        createIndex("test");
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "value2").get();
-        client().prepareIndex("test", "type1", "3").setSource("field1", "value3").get();
-        ensureGreen();
-        waitForRelocation();
-        optimize();
-        refresh();
-        assertHitCount(
-                client().prepareSearch()
-                        .setQuery(matchAllQuery())
-                        .setPostFilter(
-                                boolQuery().must(
-                                        matchAllQuery()).must(
-                                        notQuery(boolQuery().must(termQuery("field1", "value1")).must(
-                                                termQuery("field1", "value2"))))).get(),
-                3l);
-        assertHitCount(
-                client().prepareSearch()
-                        .setQuery(
-                                boolQuery().must(
-                                        boolQuery().should(termQuery("field1", "value1")).should(termQuery("field1", "value2"))
-                                                .should(termQuery("field1", "value3"))).filter(
-                                        notQuery(boolQuery().must(termQuery("field1", "value1")).must(
-                                                termQuery("field1", "value2"))))).get(),
-                3l);
-        assertHitCount(
-                client().prepareSearch().setQuery(matchAllQuery()).setPostFilter(notQuery(termQuery("field1", "value3"))).get(),
-                2l);
-    }
-
-    @Test
-    public void passQueryAsStringTest() throws Exception {
-        createIndex("test");
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1_1", "field2", "value2_1").setRefresh(true).get();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery("{ \"term\" : { \"field1\" : \"value1_1\" }}").get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testIndexOptions() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1", "field1", "type=string,index_options=docs"));
-        indexRandom(true,
-                client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(Type.PHRASE).slop(0)).get();
-        assertHitCount(searchResponse, 1l);
-
-        assertFailures(client().prepareSearch().setQuery(matchQuery("field1", "quick brown").type(Type.PHRASE).slop(0)),
-                    RestStatus.INTERNAL_SERVER_ERROR,
-                    containsString("field \"field1\" was indexed without position data; cannot run PhraseQuery"));
-    }
-
-    @Test // see #3521
-    public void testConstantScoreQuery() throws Exception {
-        Random random = getRandom();
-        createIndex("test");
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"), client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("field1", "quick"))).get();
-        assertHitCount(searchResponse, 2l);
-        for (SearchHit searchHit : searchResponse.getHits().hits()) {
-            assertSearchHit(searchHit, hasScore(1.0f));
-        }
-
-        searchResponse = client().prepareSearch("test").setQuery(
-                boolQuery().must(matchAllQuery()).must(
-                constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + getRandom().nextFloat()))).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
-
-        client().prepareSearch("test").setQuery(constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + getRandom().nextFloat())).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
-
-        searchResponse = client().prepareSearch("test").setQuery(
-                constantScoreQuery(boolQuery().must(matchAllQuery()).must(
-                constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + (random.nextBoolean()? 0.0f : random.nextFloat()))))).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
-        for (SearchHit searchHit : searchResponse.getHits().hits()) {
-            assertSearchHit(searchHit, hasScore(1.0f));
-        }
-
-        int num = scaledRandomIntBetween(100, 200);
-        IndexRequestBuilder[] builders = new IndexRequestBuilder[num];
-        for (int i = 0; i < builders.length; i++) {
-            builders[i] = client().prepareIndex("test", "type", "" + i).setSource("f", English.intToEnglish(i));
-        }
-        createIndex("test_1");
-        indexRandom(true, builders);
-
-        int queryRounds = scaledRandomIntBetween(10, 20);
-        for (int i = 0; i < queryRounds; i++) {
-            MatchQueryBuilder matchQuery = matchQuery("f", English.intToEnglish(between(0, num)));
-            searchResponse = client().prepareSearch("test_1").setQuery(matchQuery).setSize(num).get();
-            long totalHits = searchResponse.getHits().totalHits();
-            SearchHits hits = searchResponse.getHits();
-            for (SearchHit searchHit : hits) {
-                assertSearchHit(searchHit, hasScore(1.0f));
-            }
-            searchResponse = client().prepareSearch("test_1").setQuery(
-                    boolQuery().must(matchAllQuery()).must(
-                    constantScoreQuery(matchQuery).boost(1.0f + (random.nextBoolean()? 0.0f : random.nextFloat())))).setSize(num).get();
-            hits = searchResponse.getHits();
-            assertThat(hits.totalHits(), equalTo(totalHits));
-            if (totalHits > 1) {
-                float expected = hits.getAt(0).score();
-                for (SearchHit searchHit : hits) {
-                    assertSearchHit(searchHit, hasScore(expected));
-                }
-            }
-        }
-    }
-
-    @Test // see #3521
-    public void testAllDocsQueryString() throws InterruptedException, ExecutionException {
-        createIndex("test");
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("foo", "bar"),
-                client().prepareIndex("test", "type1", "2").setSource("foo", "bar")
-        );
-
-        int iters = scaledRandomIntBetween(100, 200);
-        for (int i = 0; i < iters; i++) {
-            SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("*:*^10.0").boost(10.0f)).get();
-            assertHitCount(searchResponse, 2l);
-
-            searchResponse = client().prepareSearch("test").setQuery(
-                    boolQuery().must(matchAllQuery()).must(constantScoreQuery(matchAllQuery()))).get();
-            assertHitCount(searchResponse, 2l);
-            assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(Math.sqrt(2), 0.1));
-            assertThat((double)searchResponse.getHits().getAt(1).score(),closeTo(Math.sqrt(2), 0.1));
-        }
-    }
-
-    @Test
-    public void testCommonTermsQueryOnAllField() throws Exception {
-        client().admin().indices().prepareCreate("test")
-                .addMapping("type1", "message", "type=string", "comment", "type=string,boost=5.0")
-                .setSettings(SETTING_NUMBER_OF_SHARDS, 1).get();
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("message", "test message", "comment", "whatever"),
-                client().prepareIndex("test", "type1", "2").setSource("message", "hello world", "comment", "test comment"));
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("_all", "test")).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("2"));
-        assertSecondHit(searchResponse, hasId("1"));
-        assertThat(searchResponse.getHits().getHits()[0].getScore(), greaterThan(searchResponse.getHits().getHits()[1].getScore()));
-    }
-
-    @Test
-    public void testCommonTermsQuery() throws Exception {
-        client().admin().indices().prepareCreate("test")
-                .addMapping("type1", "field1", "type=string,analyzer=whitespace")
-                .setSettings(SETTING_NUMBER_OF_SHARDS, 1).get();
-        indexRandom(true, client().prepareIndex("test", "type1", "3").setSource("field1", "quick lazy huge brown pidgin", "field2", "the quick lazy huge brown fox jumps over the tree"),
-                client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree") );
-
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).lowFreqOperator(Operator.OR)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).lowFreqOperator(Operator.AND)).get();
-        assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        // Default
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the huge fox").lowFreqMinimumShouldMatch("2")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("3")).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("4")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 4 } } } }").get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        // Default
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).analyzer("stop")).get();
-        assertHitCount(searchResponse, 3l);
-        // stop drops "the" since its a stopword
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("3"));
-        assertThirdHit(searchResponse, hasId("2"));
-
-        // try the same with match query
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.OR)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
-        assertHitCount(searchResponse, 3l);
-        // stop drops "the" since its a stopword
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("3"));
-        assertThirdHit(searchResponse, hasId("2"));
-
-        // try the same with multi match query
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the quick brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
-        assertSecondHit(searchResponse, hasId("1"));
-        assertThirdHit(searchResponse, hasId("2"));
-    }
-
-    @Test
-    public void testCommonTermsQueryStackedTokens() throws Exception {
-        assertAcked(prepareCreate("test")
-                .setSettings(settingsBuilder()
-                        .put(indexSettings())
-                        .put(SETTING_NUMBER_OF_SHARDS,1)
-                        .put("index.analysis.filter.syns.type","synonym")
-                        .putArray("index.analysis.filter.syns.synonyms","quick,fast")
-                        .put("index.analysis.analyzer.syns.tokenizer","whitespace")
-                        .put("index.analysis.analyzer.syns.filter","syns")
-                        )
-                .addMapping("type1", "field1", "type=string,analyzer=syns", "field2", "type=string,analyzer=syns"));
-
-        indexRandom(true, client().prepareIndex("test", "type1", "3").setSource("field1", "quick lazy huge brown pidgin", "field2", "the quick lazy huge brown fox jumps over the tree"),
-                client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree") );
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3).lowFreqOperator(Operator.OR)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3).lowFreqOperator(Operator.AND)).get();
-        assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        // Default
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast huge fox").lowFreqMinimumShouldMatch("3")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("5")).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("6")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the fast lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 6 } } } }").get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        // Default
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).analyzer("stop")).get();
-        assertHitCount(searchResponse, 3l);
-        // stop drops "the" since its a stopword
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("3"));
-        assertThirdHit(searchResponse, hasId("2"));
-
-        // try the same with match query
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.OR)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThirdHit(searchResponse, hasId("3"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
-        assertHitCount(searchResponse, 3l);
-        // stop drops "the" since its a stopword
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("3"));
-        assertThirdHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).minimumShouldMatch("3")).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        // try the same with multi match query
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the fast brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 3l);
-        assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
-        assertSecondHit(searchResponse, hasId("1"));
-        assertThirdHit(searchResponse, hasId("2"));
-    }
-
-    @Test
-    public void testOmitTermFreqsAndPositions() throws Exception {
-        cluster().wipeTemplates(); // no randomized template for this test -- we are testing bwc compat and set version explicitly this might cause failures if an unsupported feature
-                                   // is added randomly via an index template.
-        Version version = Version.CURRENT;
-        int iters = scaledRandomIntBetween(10, 20);
-        for (int i = 0; i < iters; i++) {
-            try {
-                // backwards compat test!
-                assertAcked(client().admin().indices().prepareCreate("test")
-                        .addMapping("type1", "field1", "type=string,omit_term_freq_and_positions=true")
-                        .setSettings(settings(version).put(SETTING_NUMBER_OF_SHARDS, 1)));
-                assertThat(version.onOrAfter(Version.V_1_0_0_RC2), equalTo(false));
-                indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"),
-                        client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
-
-
-                SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(Type.PHRASE).slop(0)).get();
-                assertHitCount(searchResponse, 1l);
-                try {
-                    client().prepareSearch().setQuery(matchQuery("field1", "quick brown").type(Type.PHRASE).slop(0)).get();
-                    fail("SearchPhaseExecutionException should have been thrown");
-                } catch (SearchPhaseExecutionException e) {
-                    assertTrue(e.toString().contains("IllegalStateException[field \"field1\" was indexed without position data; cannot run PhraseQuery"));
-                }
-                cluster().wipeIndices("test");
-            } catch (MapperParsingException ex) {
-                assertThat(version.toString(), version.onOrAfter(Version.V_1_0_0_RC2), equalTo(true));
-                assertThat(ex.getCause().getMessage(), equalTo("'omit_term_freq_and_positions' is not supported anymore - use ['index_options' : 'docs']  instead"));
-            }
-            version = randomVersion(random());
-        }
-    }
-
-    @Test
-    public void queryStringAnalyzedWildcard() throws Exception {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value_1", "field2", "value_2").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("value*").analyzeWildcard(true)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("*ue*").analyzeWildcard(true)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("*ue_1").analyzeWildcard(true)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("val*e_1").analyzeWildcard(true)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("v?l*e?1").analyzeWildcard(true)).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testLowercaseExpandedTerms() {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value_1", "field2", "value_2").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("VALUE_3~1").lowercaseExpandedTerms(true)).get();
-        assertHitCount(searchResponse, 1l);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("VALUE_3~1").lowercaseExpandedTerms(false)).get();
-        assertHitCount(searchResponse, 0l);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("ValUE_*").lowercaseExpandedTerms(true)).get();
-        assertHitCount(searchResponse, 1l);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("vAl*E_1")).get();
-        assertHitCount(searchResponse, 1l);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("[VALUE_1 TO VALUE_3]")).get();
-        assertHitCount(searchResponse, 1l);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("[VALUE_1 TO VALUE_3]").lowercaseExpandedTerms(false)).get();
-        assertHitCount(searchResponse, 0l);
-    }
-
-    @Test //https://github.com/elasticsearch/elasticsearch/issues/3540
-    public void testDateRangeInQueryString() {
-        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
-        //as with dynamic mappings some shards might be lacking behind and parse a different query
-        assertAcked(prepareCreate("test").addMapping(
-                "type", "past", "type=date", "future", "type=date"
-        ));
-
-        String aMonthAgo = ISODateTimeFormat.yearMonthDay().print(new DateTime(DateTimeZone.UTC).minusMonths(1));
-        String aMonthFromNow = ISODateTimeFormat.yearMonthDay().print(new DateTime(DateTimeZone.UTC).plusMonths(1));
-        client().prepareIndex("test", "type", "1").setSource("past", aMonthAgo, "future", aMonthFromNow).get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("past:[now-2M/d TO now/d]")).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("future:[now/d TO now+2M/d]").lowercaseExpandedTerms(false)).get();
-        assertHitCount(searchResponse, 1l);
-
-        try {
-            client().prepareSearch().setQuery(queryStringQuery("future:[now/D TO now+2M/d]").lowercaseExpandedTerms(false)).get();
-            fail("expected SearchPhaseExecutionException (total failure)");
-        } catch (SearchPhaseExecutionException e) {
-            assertThat(e.status(), equalTo(RestStatus.BAD_REQUEST));
-            assertThat(e.toString(), containsString("unit [D] not supported for date math"));
-        }
-    }
-
-    @Test // https://github.com/elasticsearch/elasticsearch/issues/7880
-    public void testDateRangeInQueryStringWithTimeZone_7880() {
-        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
-        //as with dynamic mappings some shards might be lacking behind and parse a different query
-        assertAcked(prepareCreate("test").addMapping(
-                "type", "past", "type=date"
-        ));
-
-        DateTimeZone timeZone = randomDateTimeZone();
-        String now = ISODateTimeFormat.dateTime().print(new DateTime(timeZone));
-        logger.info(" --> Using time_zone [{}], now is [{}]", timeZone.getID(), now);
-        client().prepareIndex("test", "type", "1").setSource("past", now).get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("past:[now-1m/m TO now+1m/m]")
-                .timeZone(timeZone.getID())).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test // https://github.com/elasticsearch/elasticsearch/issues/10477
-    public void testDateRangeInQueryStringWithTimeZone_10477() {
-        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
-        //as with dynamic mappings some shards might be lacking behind and parse a different query
-        assertAcked(prepareCreate("test").addMapping(
-                "type", "past", "type=date"
-        ));
-
-        client().prepareIndex("test", "type", "1").setSource("past", "2015-04-05T23:00:00+0000").get();
-        client().prepareIndex("test", "type", "2").setSource("past", "2015-04-06T00:00:00+0000").get();
-        refresh();
-
-        // Timezone set with dates
-        SearchResponse searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00+0200 TO 2015-04-06T23:00:00+0200]"))
-                .get();
-        assertHitCount(searchResponse, 2l);
-
-        // Same timezone set with time_zone
-        searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00 TO 2015-04-06T23:00:00]").timeZone("+0200"))
-                .get();
-        assertHitCount(searchResponse, 2l);
-
-        // We set a timezone which will give no result
-        searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00-0200 TO 2015-04-06T23:00:00-0200]"))
-                .get();
-        assertHitCount(searchResponse, 0l);
-
-        // Same timezone set with time_zone but another timezone is set directly within dates which has the precedence
-        searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00-0200 TO 2015-04-06T23:00:00-0200]").timeZone("+0200"))
-                .get();
-        assertHitCount(searchResponse, 0l);
-    }
-
-    @Test
-    public void typeFilterTypeIndexedTests() throws Exception {
-        typeFilterTests("not_analyzed");
-    }
-
-    @Test
-    public void typeFilterTypeNotIndexedTests() throws Exception {
-        typeFilterTests("no");
-    }
-
-    private void typeFilterTests(String index) throws Exception {
-        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
-        assertAcked(prepareCreate("test").setSettings(indexSettings)
-                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
-                        .startObject("_type").field("index", index).endObject()
-                        .endObject().endObject())
-                .addMapping("type2", jsonBuilder().startObject().startObject("type2")
-                        .startObject("_type").field("index", index).endObject()
-                        .endObject().endObject())
-                .setUpdateAllTypes(true));
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "value1"),
-                client().prepareIndex("test", "type2", "1").setSource("field1", "value1"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "value1"),
-                client().prepareIndex("test", "type2", "2").setSource("field1", "value1"),
-                client().prepareIndex("test", "type2", "3").setSource("field1", "value1"));
-
-        assertHitCount(client().prepareSearch().setQuery(typeQuery("type1")).get(), 2l);
-        assertHitCount(client().prepareSearch().setQuery(typeQuery("type2")).get(), 3l);
-
-        assertHitCount(client().prepareSearch().setTypes("type1").setQuery(matchAllQuery()).get(), 2l);
-        assertHitCount(client().prepareSearch().setTypes("type2").setQuery(matchAllQuery()).get(), 3l);
-
-        assertHitCount(client().prepareSearch().setTypes("type1", "type2").setQuery(matchAllQuery()).get(), 5l);
-    }
-
-    @Test
-    public void idsQueryTestsIdIndexed() throws Exception {
-        idsQueryTests("not_analyzed");
-    }
-
-    @Test
-    public void idsQueryTestsIdNotIndexed() throws Exception {
-        idsQueryTests("no");
-    }
-
-    private void idsQueryTests(String index) throws Exception {
-        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
-        assertAcked(client().admin().indices().prepareCreate("test").setSettings(indexSettings)
-                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
-                        .startObject("_id").field("index", index).endObject()
-                        .endObject().endObject()));
-
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "value1"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "value2"),
-                client().prepareIndex("test", "type1", "3").setSource("field1", "value3"));
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery("type1").addIds("1", "3"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        // no type
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery().addIds("1", "3"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").addIds("1", "3")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        // no type
-        searchResponse = client().prepareSearch().setQuery(idsQuery().addIds("1", "3")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").addIds("7", "10")).get();
-        assertHitCount(searchResponse, 0l);
-
-        // repeat..., with terms
-        searchResponse = client().prepareSearch().setTypes("type1").setQuery(constantScoreQuery(termsQuery("_id", "1", "3"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-    }
-
-    @Test
-    public void term_indexQueryTestsIndexed() throws Exception {
-        term_indexQueryTests("not_analyzed");
-    }
-
-    @Test
-    public void term_indexQueryTestsNotIndexed() throws Exception {
-        term_indexQueryTests("no");
-    }
-
-    private void term_indexQueryTests(String index) throws Exception {
-        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
-        String[] indexNames = { "test1", "test2" };
-        for (String indexName : indexNames) {
-            assertAcked(client()
-                    .admin()
-                    .indices()
-                    .prepareCreate(indexName)
-                    .setSettings(indexSettings)
-                    .addMapping(
-                            "type1",
-                            jsonBuilder().startObject().startObject("type1").startObject("_index").field("index", index).endObject()
-                                    .endObject().endObject()));
-
-            indexRandom(true, client().prepareIndex(indexName, "type1", indexName + "1").setSource("field1", "value1"));
-
-        }
-
-        for (String indexName : indexNames) {
-            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termQuery("_index", indexName))).get();
-            SearchResponse searchResponse = assertSearchResponse(request);
-            assertHitCount(searchResponse, 1l);
-            assertSearchHits(searchResponse, indexName + "1");
-        }
-        for (String indexName : indexNames) {
-            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termsQuery("_index", indexName))).get();
-            SearchResponse searchResponse = assertSearchResponse(request);
-            assertHitCount(searchResponse, 1l);
-            assertSearchHits(searchResponse, indexName + "1");
-        }
-        for (String indexName : indexNames) {
-            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("_index", indexName))).get();
-            SearchResponse searchResponse = assertSearchResponse(request);
-            assertHitCount(searchResponse, 1l);
-            assertSearchHits(searchResponse, indexName + "1");
-        }
-        {
-            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termsQuery("_index", indexNames))).get();
-            SearchResponse searchResponse = assertSearchResponse(request);
-            assertHitCount(searchResponse, indexNames.length);
-        }
-    }
-
-    @Test
-    public void filterExistsMissingTests() throws Exception {
-        createIndex("test");
-
-        indexRandom(true,
-                client().prepareIndex("test", "type1", "1").setSource(jsonBuilder().startObject().startObject("obj1").field("obj1_val", "1").endObject().field("x1", "x_1").field("field1", "value1_1").field("field2", "value2_1").endObject()),
-                client().prepareIndex("test", "type1", "2").setSource(jsonBuilder().startObject().startObject("obj1").field("obj1_val", "1").endObject().field("x2", "x_2").field("field1", "value1_2").endObject()),
-                client().prepareIndex("test", "type1", "3").setSource(jsonBuilder().startObject().startObject("obj2").field("obj2_val", "1").endObject().field("y1", "y_1").field("field2", "value2_3").endObject()),
-                client().prepareIndex("test", "type1", "4").setSource(jsonBuilder().startObject().startObject("obj2").field("obj2_val", "1").endObject().field("y2", "y_2").field("field3", "value3_4").endObject()) );
-
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(existsQuery("field1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(existsQuery("field1"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("_exists_:field1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        searchResponse = client().prepareSearch().setQuery(existsQuery("field2")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch().setQuery(existsQuery("field3")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("4"));
-
-        // wildcard check
-        searchResponse = client().prepareSearch().setQuery(existsQuery("x*")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        // object check
-        searchResponse = client().prepareSearch().setQuery(existsQuery("obj1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        searchResponse = client().prepareSearch().setQuery(missingQuery("field1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-
-        searchResponse = client().prepareSearch().setQuery(missingQuery("field1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-
-        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(missingQuery("field1"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("_missing_:field1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-
-        // wildcard check
-        searchResponse = client().prepareSearch().setQuery(missingQuery("x*")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-
-        // object check
-        searchResponse = client().prepareSearch().setQuery(missingQuery("obj1")).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "4");
-    }
-
-    @Test
-    public void passQueryOrFilterAsJSONStringTest() throws Exception {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1_1", "field2", "value2_1").setRefresh(true).get();
-
-        WrapperQueryBuilder wrapper = new WrapperQueryBuilder("{ \"term\" : { \"field1\" : \"value1_1\" } }");
-        assertHitCount(client().prepareSearch().setQuery(wrapper).get(), 1l);
-
-        BoolQueryBuilder bool = boolQuery().must(wrapper).must(new TermQueryBuilder("field2", "value2_1"));
-        assertHitCount(client().prepareSearch().setQuery(bool).get(), 1l);
-
-        WrapperQueryBuilder wrapperFilter = wrapperQuery("{ \"term\" : { \"field1\" : \"value1_1\" } }");
-        assertHitCount(client().prepareSearch().setPostFilter(wrapperFilter).get(), 1l);
-    }
-
-    @Test
-    public void testFiltersWithCustomCacheKey() throws Exception {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
-        refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testMatchQueryNumeric() throws Exception {
-        assertAcked(prepareCreate("test").addMapping("type1", "long", "type=long", "double", "type=double"));
-
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("long", 1l, "double", 1.0d),
-                client().prepareIndex("test", "type1", "2").setSource("long", 2l, "double", 2.0d),
-                client().prepareIndex("test", "type1", "3").setSource("long", 3l, "double", 3.0d));
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("long", "1")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        searchResponse = client().prepareSearch().setQuery(matchQuery("double", "2")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-        try {
-            client().prepareSearch().setQuery(matchQuery("double", "2 3 4")).get();
-            fail("SearchPhaseExecutionException should have been thrown");
-        } catch (SearchPhaseExecutionException ex) {
-            // number format exception
-        }
-    }
-
-    @Test
-    public void testMultiMatchQuery() throws Exception {
-        createIndex("test");
-
-        indexRandom(true,
-                client().prepareIndex("test", "type1", "1").setSource("field1", "value1", "field2", "value4", "field3", "value3"),
-                client().prepareIndex("test", "type1", "2").setSource("field1", "value2", "field2", "value5", "field3", "value2"),
-                client().prepareIndex("test", "type1", "3").setSource("field1", "value3", "field2", "value6", "field3", "value1") );
-
-        MultiMatchQueryBuilder builder = multiMatchQuery("value1 value2 value4", "field1", "field2");
-        SearchResponse searchResponse = client().prepareSearch().setQuery(builder)
-                .addAggregation(AggregationBuilders.terms("field1").field("field1")).get();
-
-        assertHitCount(searchResponse, 2l);
-        // this uses dismax so scores are equal and the order can be arbitrary
-        assertSearchHits(searchResponse, "1", "2");
-
-        builder.useDisMax(false);
-        searchResponse = client().prepareSearch()
-                .setQuery(builder)
-                .get();
-
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        client().admin().indices().prepareRefresh("test").get();
-        builder = multiMatchQuery("value1", "field1", "field2")
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
-        searchResponse = client().prepareSearch()
-                .setQuery(builder)
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        refresh();
-        builder = multiMatchQuery("value1", "field1").field("field3", 1.5f)
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
-        searchResponse = client().prepareSearch().setQuery(builder).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "1");
-
-        client().admin().indices().prepareRefresh("test").get();
-        builder = multiMatchQuery("value1").field("field1").field("field3", 1.5f)
-                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
-        searchResponse = client().prepareSearch().setQuery(builder).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "3", "1");
-
-        // Test lenient
-        client().prepareIndex("test", "type1", "3").setSource("field1", "value7", "field2", "value8", "field4", 5).get();
-        refresh();
-
-        builder = multiMatchQuery("value1", "field1", "field2", "field4");
-
-        assertFailures(client().prepareSearch().setQuery(builder),
-                RestStatus.BAD_REQUEST,
-                containsString("NumberFormatException[For input string: \"value1\"]"));
-
-        builder.lenient(true);
-        searchResponse = client().prepareSearch().setQuery(builder).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-    }
-
-    @Test
-    public void testMatchQueryZeroTermsQuery() {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1", "field1", "type=string,analyzer=classic", "field2", "type=string,analyzer=classic"));
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "value2").get();
-        refresh();
-
-        BoolQueryBuilder boolQuery = boolQuery()
-                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE))
-                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE));
-        SearchResponse searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 0l);
-
-        boolQuery = boolQuery()
-                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL))
-                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
-        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 1l);
-
-        boolQuery = boolQuery().must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
-        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 2l);
-    }
-
-    public void testMultiMatchQueryZeroTermsQuery() {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1", "field1", "type=string,analyzer=classic", "field2", "type=string,analyzer=classic"));
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1", "field2", "value2").get();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "value3", "field2", "value4").get();
-        refresh();
-
-
-        BoolQueryBuilder boolQuery = boolQuery()
-                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE))
-                .must(multiMatchQuery("value1", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE)); // Fields are ORed together
-        SearchResponse searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 0l);
-
-        boolQuery = boolQuery()
-                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL))
-                .must(multiMatchQuery("value4", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
-        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 1l);
-
-        boolQuery = boolQuery().must(multiMatchQuery("a", "field1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
-        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
-        assertHitCount(searchResponse, 2l);
-    }
-
-    @Test
-    public void testMultiMatchQueryMinShouldMatch() {
-        createIndex("test");
-        client().prepareIndex("test", "type1", "1").setSource("field1", new String[]{"value1", "value2", "value3"}).get();
-        client().prepareIndex("test", "type1", "2").setSource("field2", "value1").get();
-        refresh();
-
-        MultiMatchQueryBuilder multiMatchQuery = multiMatchQuery("value1 value2 foo", "field1", "field2");
-
-        multiMatchQuery.useDisMax(true);
-        multiMatchQuery.minimumShouldMatch("70%");
-        SearchResponse searchResponse = client().prepareSearch()
-                .setQuery(multiMatchQuery)
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        multiMatchQuery.minimumShouldMatch("30%");
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        multiMatchQuery.useDisMax(false);
-        multiMatchQuery.minimumShouldMatch("70%");
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        multiMatchQuery.minimumShouldMatch("30%");
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-
-        multiMatchQuery = multiMatchQuery("value1 value2 bar", "field1");
-        multiMatchQuery.minimumShouldMatch("100%");
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
-        assertHitCount(searchResponse, 0l);
-
-        multiMatchQuery.minimumShouldMatch("70%");
-        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-    }
-
-    @Test
-    public void testFuzzyQueryString() {
-        createIndex("test");
-        client().prepareIndex("test", "type1", "1").setSource("str", "kimchy", "date", "2012-02-01", "num", 12).get();
-        client().prepareIndex("test", "type1", "2").setSource("str", "shay", "date", "2012-02-05", "num", 20).get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("str:kimcy~1")).get();
-        assertNoFailures(searchResponse);
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:11~1")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("date:2012-02-02~1d")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-    }
-
-    @Test
-    public void testQuotedQueryStringWithBoost() throws InterruptedException, ExecutionException {
-        float boost = 10.0f;
-        assertAcked(prepareCreate("test").setSettings(SETTING_NUMBER_OF_SHARDS, 1));
-        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("important", "phrase match", "less_important", "nothing important"),
-                client().prepareIndex("test", "type1", "2").setSource("important", "nothing important", "less_important", "phrase match")
-        );
-
-
-        SearchResponse searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("\"phrase match\"").field("important", boost).field("less_important")).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(boost * searchResponse.getHits().getAt(1).score(), .1));
-
-        searchResponse = client().prepareSearch()
-                .setQuery(queryStringQuery("\"phrase match\"").field("important", boost).field("less_important").useDisMax(false)).get();
-        assertHitCount(searchResponse, 2l);
-        assertFirstHit(searchResponse, hasId("1"));
-        assertSecondHit(searchResponse, hasId("2"));
-        assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(boost * searchResponse.getHits().getAt(1).score(), .1));
-    }
-
-    @Test
-    public void testSpecialRangeSyntaxInQueryString() {
-        createIndex("test");
-        client().prepareIndex("test", "type1", "1").setSource("str", "kimchy", "date", "2012-02-01", "num", 12).get();
-        client().prepareIndex("test", "type1", "2").setSource("str", "shay", "date", "2012-02-05", "num", 20).get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>19")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>20")).get();
-        assertHitCount(searchResponse, 0l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>=20")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>11")).get();
-        assertHitCount(searchResponse, 2l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:<20")).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:<=20")).get();
-        assertHitCount(searchResponse, 2l);
-
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("+num:>11 +num:<20")).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testEmptytermsQuery() throws Exception {
-        assertAcked(prepareCreate("test").addMapping("type", "term", "type=string"));
-
-        indexRandom(true, client().prepareIndex("test", "type", "1").setSource("term", "1"),
-                client().prepareIndex("test", "type", "2").setSource("term", "2"),
-                client().prepareIndex("test", "type", "3").setSource("term", "3"),
-                client().prepareIndex("test", "type", "4").setSource("term", "4") );
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("term", new String[0]))).get();
-        assertHitCount(searchResponse, 0l);
-
-        searchResponse = client().prepareSearch("test").setQuery(idsQuery()).get();
-        assertHitCount(searchResponse, 0l);
-    }
-
-    @Test
-    public void testTermsQuery() throws Exception {
-        assertAcked(prepareCreate("test").addMapping("type", "str", "type=string", "lng", "type=long", "dbl", "type=double"));
-
-        indexRandom(true,
-                client().prepareIndex("test", "type", "1").setSource("str", "1", "lng", 1l, "dbl", 1.0d),
-                client().prepareIndex("test", "type", "2").setSource("str", "2", "lng", 2l, "dbl", 2.0d),
-                client().prepareIndex("test", "type", "3").setSource("str", "3", "lng", 3l, "dbl", 3.0d),
-                client().prepareIndex("test", "type", "4").setSource("str", "4", "lng", 4l, "dbl", 4.0d));
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("str", "1", "4"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "4");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {2, 3}))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "2", "3");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("dbl", new double[]{2, 3}))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "2", "3");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("lng", new int[] {1, 3}))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("dbl", new float[] {2, 4}))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "2", "4");
-
-        // test partial matching
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("str", "2", "5"))).get();
-        assertNoFailures(searchResponse);
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("dbl", new double[] {2, 5}))).get();
-        assertNoFailures(searchResponse);
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {2, 5}))).get();
-        assertNoFailures(searchResponse);
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        // test valid type, but no matching terms
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("str", "5", "6"))).get();
-        assertHitCount(searchResponse, 0l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("dbl", new double[] {5, 6}))).get();
-        assertHitCount(searchResponse, 0l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {5, 6}))).get();
-        assertHitCount(searchResponse, 0l);
-    }
-
-    @Test
-    public void testTermsLookupFilter() throws Exception {
-        assertAcked(prepareCreate("lookup").addMapping("type", "terms","type=string", "other", "type=string"));
-        assertAcked(prepareCreate("lookup2").addMapping("type",
-                jsonBuilder().startObject().startObject("type").startObject("properties")
-                        .startObject("arr").startObject("properties").startObject("term").field("type", "string")
-                        .endObject().endObject().endObject().endObject().endObject().endObject()));
-        assertAcked(prepareCreate("test").addMapping("type", "term", "type=string"));
-
-        indexRandom(true,
-                client().prepareIndex("lookup", "type", "1").setSource("terms", new String[]{"1", "3"}),
-                client().prepareIndex("lookup", "type", "2").setSource("terms", new String[]{"2"}),
-                client().prepareIndex("lookup", "type", "3").setSource("terms", new String[]{"2", "4"}),
-                client().prepareIndex("lookup", "type", "4").setSource("other", "value"),
-                client().prepareIndex("lookup2", "type", "1").setSource(XContentFactory.jsonBuilder().startObject()
-                        .startArray("arr")
-                        .startObject().field("term", "1").endObject()
-                        .startObject().field("term", "3").endObject()
-                        .endArray()
-                        .endObject()),
-                client().prepareIndex("lookup2", "type", "2").setSource(XContentFactory.jsonBuilder().startObject()
-                        .startArray("arr")
-                        .startObject().field("term", "2").endObject()
-                        .endArray()
-                        .endObject()),
-                client().prepareIndex("lookup2", "type", "3").setSource(XContentFactory.jsonBuilder().startObject()
-                        .startArray("arr")
-                        .startObject().field("term", "2").endObject()
-                        .startObject().field("term", "4").endObject()
-                        .endArray()
-                        .endObject()),
-                client().prepareIndex("test", "type", "1").setSource("term", "1"),
-                client().prepareIndex("test", "type", "2").setSource("term", "2"),
-                client().prepareIndex("test", "type", "3").setSource("term", "3"),
-                client().prepareIndex("test", "type", "4").setSource("term", "4") );
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term" , new TermsLookup("lookup", "type", "1", "terms"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        // same as above, just on the _id...
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("_id", new TermsLookup("lookup", "type", "1", "terms"))
-                ).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        // another search with same parameters...
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "1", "terms"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "2", "terms"))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "3", "terms"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "2", "4");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "4", "terms"))).get();
-        assertHitCount(searchResponse, 0l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "1", "arr.term"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "3");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "2", "arr.term"))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("2"));
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "3", "arr.term"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "2", "4");
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termsLookupQuery("not_exists", new TermsLookup("lookup2", "type", "3", "arr.term"))).get();
-        assertHitCount(searchResponse, 0l);
-    }
-
-    @Test
-    public void testBasicQueryById() throws Exception {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
-        client().prepareIndex("test", "type2", "2").setSource("field1", "value2").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(idsQuery("type1", "type2").addIds("1", "2")).get();
-        assertHitCount(searchResponse, 2l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(2));
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery().addIds("1")).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery().addIds("1", "2")).get();
-        assertHitCount(searchResponse, 2l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(2));
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").addIds("1", "2")).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery(Strings.EMPTY_ARRAY).addIds("1")).get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(1));
-
-        searchResponse = client().prepareSearch().setQuery(idsQuery("type1", "type2", "type3").addIds("1", "2", "3", "4")).get();
-        assertHitCount(searchResponse, 2l);
-        assertThat(searchResponse.getHits().hits().length, equalTo(2));
-    }
-
-    @Test
-    public void testNumericTermsAndRanges() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1",
-                        "num_byte", "type=byte", "num_short", "type=short",
-                        "num_integer", "type=integer", "num_long", "type=long",
-                        "num_float", "type=float", "num_double", "type=double"));
-
-        client().prepareIndex("test", "type1", "1").setSource("num_byte", 1, "num_short", 1, "num_integer", 1,
-                "num_long", 1, "num_float", 1, "num_double", 1).get();
-
-        client().prepareIndex("test", "type1", "2").setSource("num_byte", 2, "num_short", 2, "num_integer", 2,
-                "num_long", 2, "num_float", 2, "num_double", 2).get();
-
-        client().prepareIndex("test", "type1", "17").setSource("num_byte", 17, "num_short", 17, "num_integer", 17,
-                "num_long", 17, "num_float", 17, "num_double", 17).get();
-        refresh();
-
-        SearchResponse searchResponse;
-        logger.info("--> term query on 1");
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_byte", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_short", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_integer", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_long", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_float", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_double", 1)).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        logger.info("--> terms query on 1");
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_byte", new int[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_short", new int[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_integer", new int[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_long", new int[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_float", new double[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_double", new double[]{1})).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        logger.info("--> term filter on 1");
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_byte", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_short", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_integer", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_long", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_float", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_double", 1))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-
-        logger.info("--> terms filter on 1");
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_byte", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_short", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_integer", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_long", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_float", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_double", new int[]{1}))).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-    }
-
-    @Test
-    public void testNumericRangeFilter_2826() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1",
-                        "num_byte", "type=byte", "num_short", "type=short",
-                        "num_integer", "type=integer", "num_long", "type=long",
-                        "num_float", "type=float", "num_double", "type=double"));
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "test1", "num_long", 1).get();
-        client().prepareIndex("test", "type1", "2").setSource("field1", "test1", "num_long", 2).get();
-        client().prepareIndex("test", "type1", "3").setSource("field1", "test2", "num_long", 3).get();
-        client().prepareIndex("test", "type1", "4").setSource("field1", "test2", "num_long", 4).get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch("test").setPostFilter(
-                boolQuery()
-                        .should(rangeQuery("num_long").from(1).to(2))
-                        .should(rangeQuery("num_long").from(3).to(4))
-        ).get();
-        assertHitCount(searchResponse, 4l);
-
-        // This made 2826 fail! (only with bit based filters)
-        searchResponse = client().prepareSearch("test").setPostFilter(
-                boolQuery()
-                        .should(rangeQuery("num_long").from(1).to(2))
-                        .should(rangeQuery("num_long").from(3).to(4))
-        ).get();
-        assertHitCount(searchResponse, 4l);
-
-        // This made #2979 fail!
-        searchResponse = client().prepareSearch("test").setPostFilter(
-                boolQuery()
-                        .must(termQuery("field1", "test1"))
-                        .should(rangeQuery("num_long").from(1).to(2))
-                        .should(rangeQuery("num_long").from(3).to(4))
-        ).get();
-        assertHitCount(searchResponse, 2l);
-    }
-
-    @Test
-    public void testEmptyTopLevelFilter() {
-        client().prepareIndex("test", "type", "1").setSource("field", "value").setRefresh(true).get();
-
-        SearchResponse searchResponse = client().prepareSearch().setPostFilter("{}").get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test // see #2926
-    public void testMustNot() throws IOException, ExecutionException, InterruptedException {
-        assertAcked(prepareCreate("test")
-                //issue manifested only with shards>=2
-                .setSettings(SETTING_NUMBER_OF_SHARDS, between(2, DEFAULT_MAX_NUM_SHARDS)));
-
-
-        indexRandom(true, client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar"),
-                client().prepareIndex("test", "test", "2").setSource("description", "foo other anything"),
-                client().prepareIndex("test", "test", "3").setSource("description", "foo other"),
-                client().prepareIndex("test", "test", "4").setSource("description", "foo"));
-
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchAllQuery())
-                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH).get();
-        assertHitCount(searchResponse, 4l);
-
-        searchResponse = client().prepareSearch("test").setQuery(
-                boolQuery()
-                        .mustNot(matchQuery("description", "anything").type(Type.BOOLEAN))
-        ).setSearchType(SearchType.DFS_QUERY_THEN_FETCH).get();
-        assertHitCount(searchResponse, 2l);
-    }
-
-    @Test // see #2994
-    public void testSimpleSpan() throws IOException, ExecutionException, InterruptedException {
-        createIndex("test");
-
-
-        indexRandom(true, client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar"),
-                client().prepareIndex("test", "test", "2").setSource("description", "foo other anything"),
-                client().prepareIndex("test", "test", "3").setSource("description", "foo other"),
-                client().prepareIndex("test", "test", "4").setSource("description", "foo"));
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanTermQuery("description", "bar"))).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test").setQuery(
-                spanNearQuery(spanTermQuery("description", "foo"), 3)
-                        .clause(spanTermQuery("description", "other"))).get();
-        assertHitCount(searchResponse, 3l);
-    }
-
-    @Test
-    public void testSpanMultiTermQuery() throws IOException {
-        createIndex("test");
-
-        client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar", "count", 1).get();
-        client().prepareIndex("test", "test", "2").setSource("description", "foo other anything", "count", 2).get();
-        client().prepareIndex("test", "test", "3").setSource("description", "foo other", "count", 3).get();
-        client().prepareIndex("test", "test", "4").setSource("description", "fop", "count", 4).get();
-        refresh();
-
-        SearchResponse response = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(fuzzyQuery("description", "fop")))).get();
-        assertHitCount(response, 4);
-
-        response = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(prefixQuery("description", "fo")))).get();
-        assertHitCount(response, 4);
-
-        response = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(wildcardQuery("description", "oth*")))).get();
-        assertHitCount(response, 3);
-
-        response = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(QueryBuilders.rangeQuery("description").from("ffa").to("foo"))))
-                .execute().actionGet();
-        assertHitCount(response, 3);
-
-        response = client().prepareSearch("test")
-                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(regexpQuery("description", "fo{2}")))).get();
-        assertHitCount(response, 3);
-    }
-
-    @Test
-    public void testSpanNot() throws IOException, ExecutionException, InterruptedException {
-        createIndex("test");
-
-        client().prepareIndex("test", "test", "1").setSource("description", "the quick brown fox jumped over the lazy dog").get();
-        client().prepareIndex("test", "test", "2").setSource("description", "the quick black fox leaped over the sleeping dog").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "brown"))).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "sleeping")).dist(5)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
-                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "jumped")).pre(1).post(1)).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testSimpleDFSQuery() throws IOException {
-        assertAcked(prepareCreate("test")
-            .addMapping("s", jsonBuilder()
-                .startObject()
-                .startObject("s")
-                .startObject("_routing")
-                .field("required", true)
-                .endObject()
-                .startObject("properties")
-                .startObject("online")
-                .field("type", "boolean")
-                .endObject()
-                .startObject("ts")
-                .field("type", "date")
-                .field("ignore_malformed", false)
-                .field("format", "epoch_millis")
-                .endObject()
-                .startObject("bs")
-                .field("type", "string")
-                .field("index", "not_analyzed")
-                .endObject()
-                .endObject()
-                .endObject()
-                .endObject())
-            .addMapping("bs", "online", "type=boolean", "ts", "type=date,ignore_malformed=false,format=epoch_millis"));
-
-
-        client().prepareIndex("test", "s", "1").setRouting("Y").setSource("online", false, "bs", "Y", "ts", System.currentTimeMillis() - 100).get();
-        client().prepareIndex("test", "s", "2").setRouting("X").setSource("online", true, "bs", "X", "ts", System.currentTimeMillis() - 10000000).get();
-        client().prepareIndex("test", "bs", "3").setSource("online", false, "ts", System.currentTimeMillis() - 100).get();
-        client().prepareIndex("test", "bs", "4").setSource("online", true, "ts", System.currentTimeMillis() - 123123).get();
-        refresh();
-
-        SearchResponse response = client().prepareSearch("test")
-                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                .setQuery(
-                        boolQuery()
-                                .must(termQuery("online", true))
-                                .must(boolQuery()
-                                        .should(boolQuery()
-                                                .must(rangeQuery("ts").lt(System.currentTimeMillis() - (15 * 1000)))
-                                                .must(termQuery("_type", "bs"))
-                                        )
-                                        .should(boolQuery()
-                                                .must(rangeQuery("ts").lt(System.currentTimeMillis() - (15 * 1000)))
-                                                .must(termQuery("_type", "s"))
-                                        )
-                                )
-                )
-                .setVersion(true)
-                .setFrom(0).setSize(100).setExplain(true).get();
-        assertNoFailures(response);
-    }
-
-    @Test
-    public void testMultiFieldQueryString() {
-        client().prepareIndex("test", "s", "1").setSource("field1", "value1", "field2", "value2").setRefresh(true).get();
-
-        logger.info("regular");
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value1").field("field1").field("field2")).get(), 1);
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value1")).get(), 1);
-        logger.info("prefix");
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value*").field("field1").field("field2")).get(), 1);
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value*")).get(), 1);
-        logger.info("wildcard");
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("v?lue*").field("field1").field("field2")).get(), 1);
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:v?lue*")).get(), 1);
-        logger.info("fuzzy");
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value~").field("field1").field("field2")).get(), 1);
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value~")).get(), 1);
-        logger.info("regexp");
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("/value[01]/").field("field1").field("field2")).get(), 1);
-        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:/value[01]/")).get(), 1);
-    }
-
-    // see #3881 - for extensive description of the issue
-    @Test
-    public void testMatchQueryWithSynonyms() throws IOException {
-        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
-                .put(indexSettings())
-                .put("index.analysis.analyzer.index.type", "custom")
-                .put("index.analysis.analyzer.index.tokenizer", "standard")
-                .put("index.analysis.analyzer.index.filter", "lowercase")
-                .put("index.analysis.analyzer.search.type", "custom")
-                .put("index.analysis.analyzer.search.tokenizer", "standard")
-                .putArray("index.analysis.analyzer.search.filter", "lowercase", "synonym")
-                .put("index.analysis.filter.synonym.type", "synonym")
-                .putArray("index.analysis.filter.synonym.synonyms", "fast, quick"));
-        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
-
-        client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
-        refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fast").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-
-        client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
-        refresh();
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2);
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2);
-    }
-
-    @Test
-    public void testMatchQueryWithStackedStems() throws IOException {
-        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
-                .put(indexSettings())
-                .put("index.analysis.analyzer.index.type", "custom")
-                .put("index.analysis.analyzer.index.tokenizer", "standard")
-                .put("index.analysis.analyzer.index.filter", "lowercase")
-                .put("index.analysis.analyzer.search.type", "custom")
-                .put("index.analysis.analyzer.search.tokenizer", "standard")
-                .putArray("index.analysis.analyzer.search.filter", "lowercase", "keyword_repeat", "porterStem", "unique_stem")
-                .put("index.analysis.filter.unique_stem.type", "unique")
-                .put("index.analysis.filter.unique_stem.only_on_same_position", true));
-        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
-
-        client().prepareIndex("test", "test", "1").setSource("text", "the fox runs across the street").get();
-        refresh();
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-
-        client().prepareIndex("test", "test", "2").setSource("text", "run fox run").get();
-        refresh();
-        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2);
-    }
-
-    @Test
-    public void testQueryStringWithSynonyms() throws IOException {
-        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
-                .put(indexSettings())
-                .put("index.analysis.analyzer.index.type", "custom")
-                .put("index.analysis.analyzer.index.tokenizer", "standard")
-                .put("index.analysis.analyzer.index.filter", "lowercase")
-                .put("index.analysis.analyzer.search.type", "custom")
-                .put("index.analysis.analyzer.search.tokenizer", "standard")
-                .putArray("index.analysis.analyzer.search.filter", "lowercase", "synonym")
-                .put("index.analysis.filter.synonym.type", "synonym")
-                .putArray("index.analysis.filter.synonym.synonyms", "fast, quick"));
-        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
-
-        client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-        searchResponse = client().prepareSearch().setQuery(queryStringQuery("fast").defaultField("text").defaultOperator(Operator.AND)).get();
-        assertHitCount(searchResponse, 1);
-
-        client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
-        refresh();
-
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2);
-        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
-        assertHitCount(searchResponse, 2);
-    }
-
-    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3898
-    public void testCustomWordDelimiterQueryString() {
-        assertAcked(client().admin().indices().prepareCreate("test")
-                .setSettings("analysis.analyzer.my_analyzer.type", "custom",
-                        "analysis.analyzer.my_analyzer.tokenizer", "whitespace",
-                        "analysis.analyzer.my_analyzer.filter", "custom_word_delimiter",
-                        "analysis.filter.custom_word_delimiter.type", "word_delimiter",
-                        "analysis.filter.custom_word_delimiter.generate_word_parts", "true",
-                        "analysis.filter.custom_word_delimiter.generate_number_parts", "false",
-                        "analysis.filter.custom_word_delimiter.catenate_numbers", "true",
-                        "analysis.filter.custom_word_delimiter.catenate_words", "false",
-                        "analysis.filter.custom_word_delimiter.split_on_case_change", "false",
-                        "analysis.filter.custom_word_delimiter.split_on_numerics", "false",
-                        "analysis.filter.custom_word_delimiter.stem_english_possessive", "false")
-                .addMapping("type1", "field1", "type=string,analyzer=my_analyzer", "field2", "type=string,analyzer=my_analyzer"));
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", "foo bar baz", "field2", "not needed").get();
-        refresh();
-
-        SearchResponse response = client()
-                .prepareSearch("test")
-                .setQuery(
-                        queryStringQuery("foo.baz").useDisMax(false).defaultOperator(Operator.AND)
-                                .field("field1").field("field2")).get();
-        assertHitCount(response, 1l);
-    }
-
-    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3797
-    public void testMultiMatchLenientIssue3797() {
-        createIndex("test");
-
-        client().prepareIndex("test", "type1", "1").setSource("field1", 123, "field2", "value2").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(multiMatchQuery("value2", "field2").field("field1", 2).lenient(true).useDisMax(false)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(multiMatchQuery("value2", "field2").field("field1", 2).lenient(true).useDisMax(true)).get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(multiMatchQuery("value2").field("field2", 2).lenient(true)).get();
-        assertHitCount(searchResponse, 1l);
-    }
-
-    @Test
-    public void testAllFieldEmptyMapping() throws Exception {
-        client().prepareIndex("myindex", "mytype").setId("1").setSource("{}").setRefresh(true).get();
-        SearchResponse response = client().prepareSearch("myindex").setQuery(matchQuery("_all", "foo")).get();
-        assertNoFailures(response);
-    }
-
-    @Test
-    public void testAllDisabledButQueried() throws Exception {
-        createIndex("myindex");
-        assertAcked(client().admin().indices().preparePutMapping("myindex").setType("mytype").setSource(
-                jsonBuilder().startObject().startObject("mytype").startObject("_all").field("enabled", false)));
-        client().prepareIndex("myindex", "mytype").setId("1").setSource("bar", "foo").setRefresh(true).get();
-        SearchResponse response = client().prepareSearch("myindex").setQuery(matchQuery("_all", "foo")).get();
-        assertNoFailures(response);
-        assertHitCount(response, 0);
-    }
-
-    @Test
-    public void testIndicesQuery() throws Exception {
-        createIndex("index1", "index2", "index3");
-
-
-        client().prepareIndex("index1", "type1").setId("1").setSource("text", "value1").get();
-        client().prepareIndex("index2", "type2").setId("2").setSource("text", "value2").get();
-        client().prepareIndex("index3", "type3").setId("3").setSource("text", "value3").get();
-        refresh();
-
-        SearchResponse searchResponse = client().prepareSearch("index1", "index2", "index3")
-                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
-                        .noMatchQuery(matchQuery("text", "value2"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-
-        //default no match query is match_all
-        searchResponse = client().prepareSearch("index1", "index2", "index3")
-                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")).get();
-        assertHitCount(searchResponse, 3l);
-        assertSearchHits(searchResponse, "1", "2", "3");
-        searchResponse = client().prepareSearch("index1", "index2", "index3")
-                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
-                        .noMatchQuery(QueryBuilders.matchAllQuery())).get();
-        assertHitCount(searchResponse, 3l);
-        assertSearchHits(searchResponse, "1", "2", "3");
-
-        searchResponse = client().prepareSearch("index1", "index2", "index3")
-                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
-                        .noMatchQuery("none")).get();
-        assertHitCount(searchResponse, 1l);
-        assertFirstHit(searchResponse, hasId("1"));
-    }
-
-    @Test // https://github.com/elasticsearch/elasticsearch/issues/2416
-    public void testIndicesQuerySkipParsing() throws Exception {
-        createIndex("simple");
-        assertAcked(prepareCreate("related")
-                .addMapping("child", jsonBuilder().startObject().startObject("child").startObject("_parent").field("type", "parent")
-                        .endObject().endObject().endObject()));
-
-        client().prepareIndex("simple", "lone").setId("1").setSource("text", "value1").get();
-        client().prepareIndex("related", "parent").setId("2").setSource("text", "parent").get();
-        client().prepareIndex("related", "child").setId("3").setParent("2").setSource("text", "value2").get();
-        refresh();
-
-        //has_child fails if executed on "simple" index
-        try {
-            client().prepareSearch("simple")
-                    .setQuery(hasChildQuery("child", matchQuery("text", "value"))).get();
-            fail("Should have failed as has_child query can only be executed against parent-child types");
-        } catch (SearchPhaseExecutionException e) {
-            assertThat(e.shardFailures().length, greaterThan(0));
-            for (ShardSearchFailure shardSearchFailure : e.shardFailures()) {
-                assertThat(shardSearchFailure.reason(), containsString("no mapping found for type [child]"));
-            }
-        }
-
-        //has_child doesn't get parsed for "simple" index
-        SearchResponse searchResponse = client().prepareSearch("related", "simple")
-                .setQuery(indicesQuery(hasChildQuery("child", matchQuery("text", "value2")), "related")
-                        .noMatchQuery(matchQuery("text", "value1"))).get();
-        assertHitCount(searchResponse, 2l);
-        assertSearchHits(searchResponse, "1", "2");
-    }
-
-    @Test
-    public void testIndicesQueryMissingIndices() throws IOException, ExecutionException, InterruptedException {
-        createIndex("index1");
-        createIndex("index2");
-
-        indexRandom(true,
-                client().prepareIndex("index1", "type1", "1").setSource("field", "match"),
-                client().prepareIndex("index1", "type1", "2").setSource("field", "no_match"),
-                client().prepareIndex("index2", "type1", "10").setSource("field", "match"),
-                client().prepareIndex("index2", "type1", "20").setSource("field", "no_match"),
-                client().prepareIndex("index3", "type1", "100").setSource("field", "match"),
-                client().prepareIndex("index3", "type1", "200").setSource("field", "no_match"));
-
-        //all indices are missing
-        SearchResponse searchResponse = client().prepareSearch().setQuery(
-                indicesQuery(termQuery("field", "missing"), "test1", "test2", "test3")
-                        .noMatchQuery(termQuery("field", "match"))).get();
-
-        assertHitCount(searchResponse, 3l);
-
-        for (SearchHit hit : searchResponse.getHits().getHits()) {
-            if ("index1".equals(hit.index())) {
-                assertThat(hit, hasId("1"));
-            } else if ("index2".equals(hit.index())) {
-                assertThat(hit, hasId("10"));
-            } else if ("index3".equals(hit.index())) {
-                assertThat(hit, hasId("100"));
-            } else {
-                fail("Returned documents should belong to either index1, index2 or index3");
-            }
-        }
-
-        //only one index specified, which is missing
-        searchResponse = client().prepareSearch().setQuery(
-                indicesQuery(termQuery("field", "missing"), "test1")
-                        .noMatchQuery(termQuery("field", "match"))).get();
-
-        assertHitCount(searchResponse, 3l);
-
-        for (SearchHit hit : searchResponse.getHits().getHits()) {
-            if ("index1".equals(hit.index())) {
-                assertThat(hit, hasId("1"));
-            } else if ("index2".equals(hit.index())) {
-                assertThat(hit, hasId("10"));
-            } else if ("index3".equals(hit.index())) {
-                assertThat(hit, hasId("100"));
-            } else {
-                fail("Returned documents should belong to either index1, index2 or index3");
-            }
-        }
-
-        //more than one index specified, one of them is missing
-        searchResponse = client().prepareSearch().setQuery(
-                indicesQuery(termQuery("field", "missing"), "index1", "test1")
-                        .noMatchQuery(termQuery("field", "match"))).get();
-
-        assertHitCount(searchResponse, 2l);
-
-        for (SearchHit hit : searchResponse.getHits().getHits()) {
-            if ("index2".equals(hit.index())) {
-                assertThat(hit, hasId("10"));
-            } else if ("index3".equals(hit.index())) {
-                assertThat(hit, hasId("100"));
-            } else {
-                fail("Returned documents should belong to either index2 or index3");
-            }
-        }
-    }
-
-    @Test
-    public void testMinScore() throws ExecutionException, InterruptedException {
-        createIndex("test");
-
-        indexRandom(true,
-                client().prepareIndex("test", "test", "1").setSource("score", 1.5),
-                client().prepareIndex("test", "test", "2").setSource("score", 1.0),
-                client().prepareIndex("test", "test", "3").setSource("score", 2.0),
-                client().prepareIndex("test", "test", "4").setSource("score", 0.5));
-
-        SearchResponse searchResponse = client().prepareSearch("test").setQuery(
-functionScoreQuery(scriptFunction(new Script("_doc['score'].value")))).setMinScore(1.5f).get();
-        assertHitCount(searchResponse, 2);
-        assertFirstHit(searchResponse, hasId("3"));
-        assertSecondHit(searchResponse, hasId("1"));
-    }
-
-    @Test
-    public void testQueryStringWithSlopAndFields() {
-        createIndex("test");
-
-        client().prepareIndex("test", "customer", "1").setSource("desc", "one two three").get();
-        client().prepareIndex("test", "product", "2").setSource("desc", "one two three").get();
-        refresh();
-        {
-            SearchResponse searchResponse = client().prepareSearch("test").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
-            assertHitCount(searchResponse, 2);
-        }
-        {
-            SearchResponse searchResponse = client().prepareSearch("test").setTypes("product").setQuery(QueryBuilders.queryStringQuery("\"one two\"").field("desc")).get();
-            assertHitCount(searchResponse, 1);
-        }
-        {
-            SearchResponse searchResponse = client().prepareSearch("test").setTypes("product").setQuery(QueryBuilders.queryStringQuery("\"one three\"~5").field("desc")).get();
-            assertHitCount(searchResponse, 1);
-        }
-        {
-            SearchResponse searchResponse = client().prepareSearch("test").setTypes("customer").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
-            assertHitCount(searchResponse, 1);
-        }
-        {
-            SearchResponse searchResponse = client().prepareSearch("test").setTypes("customer").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
-            assertHitCount(searchResponse, 1);
-        }
-    }
-
-    @Test
-    public void testDateProvidedAsNumber() throws ExecutionException, InterruptedException {
-        createIndex("test");
-        assertAcked(client().admin().indices().preparePutMapping("test").setType("type").setSource("field", "type=date,format=epoch_millis").get());
-        indexRandom(true, client().prepareIndex("test", "type", "1").setSource("field", -1000000000001L),
-                client().prepareIndex("test", "type", "2").setSource("field", -1000000000000L),
-                client().prepareIndex("test", "type", "3").setSource("field", -999999999999L));
-
-
-        assertHitCount(client().prepareCount("test").setQuery(rangeQuery("field").lte(-1000000000000L)).get(), 2);
-        assertHitCount(client().prepareCount("test").setQuery(rangeQuery("field").lte(-999999999999L)).get(), 3);
-    }
-
-    @Test
-    public void testRangeQueryWithTimeZone() throws Exception {
-        assertAcked(prepareCreate("test")
-                .addMapping("type1", "date", "type=date", "num", "type=integer"));
-
-        indexRandom(true,
-                client().prepareIndex("test", "type1", "1").setSource("date", "2014-01-01", "num", 1),
-                client().prepareIndex("test", "type1", "2").setSource("date", "2013-12-31T23:00:00", "num", 2),
-                client().prepareIndex("test", "type1", "3").setSource("date", "2014-01-01T01:00:00", "num", 3),
-                // Now in UTC+1
-                client().prepareIndex("test", "type1", "4").setSource("date", DateTime.now(DateTimeZone.forOffsetHours(1)).getMillis(), "num", 4));
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T00:00:00").to("2014-01-01T00:59:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2013-12-31T23:00:00").to("2013-12-31T23:59:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T01:00:00").to("2014-01-01T01:59:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
-
-        // We explicitly define a time zone in the from/to dates so whatever the time zone is, it won't be used
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T00:00:00Z").to("2014-01-01T00:59:00Z").timeZone("+10:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2013-12-31T23:00:00Z").to("2013-12-31T23:59:00Z").timeZone("+10:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T01:00:00Z").to("2014-01-01T01:59:00Z").timeZone("+10:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
-
-        // We define a time zone to be applied to the filter and from/to have no time zone
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T03:00:00").to("2014-01-01T03:59:00").timeZone("+03:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T02:00:00").to("2014-01-01T02:59:00").timeZone("+03:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T04:00:00").to("2014-01-01T04:59:00").timeZone("+03:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
-
-        // When we use long values, it means we have ms since epoch UTC based so we don't apply any transformation
-        try {
-            client().prepareSearch("test")
-                    .setQuery(QueryBuilders.rangeQuery("date").from(1388534400000L).to(1388537940999L).timeZone("+01:00"))
-                    .get();
-            fail("A Range Filter using ms since epoch with a TimeZone should raise a ParsingException");
-        } catch (SearchPhaseExecutionException e) {
-            // We expect it
-        }
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01").to("2014-01-01T00:59:00").timeZone("-01:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(QueryBuilders.rangeQuery("date").from("now/d-1d").timeZone("+01:00"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-        assertThat(searchResponse.getHits().getAt(0).getId(), is("4"));
-
-        // A Range Filter on a numeric field with a TimeZone should raise an exception
-        try {
-            client().prepareSearch("test")
-                    .setQuery(QueryBuilders.rangeQuery("num").from("0").to("4").timeZone("-01:00"))
-                    .get();
-            fail("A Range Filter on a numeric field with a TimeZone should raise a ParsingException");
-        } catch (SearchPhaseExecutionException e) {
-            // We expect it
-        }
-    }
-
-    @Test
-    public void testSearchEmptyDoc() {
-        assertAcked(prepareCreate("test").setSettings("{\"index.analysis.analyzer.default.type\":\"keyword\"}"));
-        client().prepareIndex("test", "type1", "1").setSource("{}").get();
-
-        refresh();
-        assertHitCount(client().prepareSearch().setQuery(matchAllQuery()).get(), 1l);
-    }
-
-    @Test  // see #5120
-    public void testNGramCopyField() {
-        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
-                .put(indexSettings())
-                .put("index.analysis.analyzer.my_ngram_analyzer.type", "custom")
-                .put("index.analysis.analyzer.my_ngram_analyzer.tokenizer", "my_ngram_tokenizer")
-                .put("index.analysis.tokenizer.my_ngram_tokenizer.type", "nGram")
-                .put("index.analysis.tokenizer.my_ngram_tokenizer.min_gram", "1")
-                .put("index.analysis.tokenizer.my_ngram_tokenizer.max_gram", "10")
-                .putArray("index.analysis.tokenizer.my_ngram_tokenizer.token_chars", new String[0]));
-        assertAcked(builder.addMapping("test", "origin", "type=string,copy_to=meta", "meta", "type=string,analyzer=my_ngram_analyzer"));
-        // we only have ngrams as the index analyzer so searches will get standard analyzer
-
-
-        client().prepareIndex("test", "test", "1").setSource("origin", "C.A1234.5678")
-                .setRefresh(true)
-                .get();
-
-        SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(matchQuery("meta", "1234"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(matchQuery("meta", "1234.56"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termQuery("meta", "A1234"))
-                .get();
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(termQuery("meta", "a1234"))
-                .get();
-        assertHitCount(searchResponse, 0l); // it's upper case
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(matchQuery("meta", "A1234").analyzer("my_ngram_analyzer"))
-                .get(); // force ngram analyzer
-        assertHitCount(searchResponse, 1l);
-
-        searchResponse = client().prepareSearch("test")
-                .setQuery(matchQuery("meta", "a1234").analyzer("my_ngram_analyzer"))
-                .get(); // this one returns a hit since it's default operator is OR
-        assertHitCount(searchResponse, 1l);
-    }
-
-    public void testMatchPhrasePrefixQuery() throws ExecutionException, InterruptedException {
-        createIndex("test1");
-        indexRandom(true, client().prepareIndex("test1", "type1", "1").setSource("field", "Johnnie Walker Black Label"),
-        client().prepareIndex("test1", "type1", "2").setSource("field", "trying out Elasticsearch"));
-
-
-        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field", "Johnnie la").slop(between(2,5)).type(Type.PHRASE_PREFIX)).get();
-        assertHitCount(searchResponse, 1l);
-        assertSearchHits(searchResponse, "1");
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field", "trying").type(Type.PHRASE_PREFIX)).get();
-        assertHitCount(searchResponse, 1l);
-        assertSearchHits(searchResponse, "2");
-        searchResponse = client().prepareSearch().setQuery(matchQuery("field", "try").type(Type.PHRASE_PREFIX)).get();
-        assertHitCount(searchResponse, 1l);
-        assertSearchHits(searchResponse, "2");
-    }
-
-    @Test
-    public void testQueryStringParserCache() throws Exception {
-        createIndex("test");
-        indexRandom(true, false, client().prepareIndex("test", "type", "1").setSource("nameTokens", "xyz"));
-
-
-        SearchResponse response = client().prepareSearch("test")
-                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                .setQuery(QueryBuilders.queryStringQuery("xyz").boost(100))
-                .get();
-        assertThat(response.getHits().totalHits(), equalTo(1l));
-        assertThat(response.getHits().getAt(0).id(), equalTo("1"));
-
-        float first = response.getHits().getAt(0).getScore();
-        for (int i = 0; i < 100; i++) {
-            response = client().prepareSearch("test")
-                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
-                    .setQuery(QueryBuilders.queryStringQuery("xyz").boost(100))
-                    .get();
-
-            assertThat(response.getHits().totalHits(), equalTo(1l));
-            assertThat(response.getHits().getAt(0).id(), equalTo("1"));
-            float actual = response.getHits().getAt(0).getScore();
-            assertThat(i + " expected: " + first + " actual: " + actual, Float.compare(first, actual), equalTo(0));
-        }
-    }
-
-    @Test // see #7686.
-    public void testIdsQueryWithInvalidValues() throws Exception {
-        createIndex("test");
-        indexRandom(true, false, client().prepareIndex("test", "type", "1").setSource("body", "foo"));
-
-        try {
-            client().prepareSearch("test")
-                    .setTypes("type")
-                    .setQuery("{\n" +
-                            "  \"ids\": {\n" +
-                            "    \"values\": [[\"1\"]]\n" +
-                            "  }\n" +
-                            "}")
-                    .get();
-            fail("query is invalid and should have produced a parse exception");
-        } catch (Exception e) {
-            assertThat("query could not be parsed due to bad format: " + e.toString(),
-                    e.toString().contains("Illegal value for id, expecting a string or number, got: START_ARRAY"),
-                    equalTo(true));
-        }
-    }
-}
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java
index ca3a9df..47bfb49 100644
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java
+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SimpleSortTests.java
@@ -46,56 +46,23 @@ import org.elasticsearch.script.Script;
 import org.elasticsearch.script.groovy.GroovyPlugin;
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHitField;
-import org.elasticsearch.search.sort.FieldSortBuilder;
-import org.elasticsearch.search.sort.GeoDistanceSortBuilder;
-import org.elasticsearch.search.sort.ScriptSortBuilder;
-import org.elasticsearch.search.sort.SortBuilders;
-import org.elasticsearch.search.sort.SortOrder;
+import org.elasticsearch.search.sort.*;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.junit.annotations.TestLogging;
 import org.hamcrest.Matchers;
 import org.junit.Test;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Locale;
+import java.util.*;
 import java.util.Map.Entry;
-import java.util.Random;
-import java.util.Set;
-import java.util.TreeMap;
 import java.util.concurrent.ExecutionException;
 
 import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
-import static org.elasticsearch.index.query.QueryBuilders.functionScoreQuery;
-import static org.elasticsearch.index.query.QueryBuilders.matchAllQuery;
-import static org.elasticsearch.index.query.QueryBuilders.termQuery;
-import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.scriptFunction;
+import static org.elasticsearch.index.query.QueryBuilders.*;
+import static org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders.fieldValueFactorFunction;
 import static org.elasticsearch.search.sort.SortBuilders.fieldSort;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertFirstHit;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertHitCount;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertNoFailures;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertOrderedSearchHits;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSearchResponse;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSecondHit;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertSortValues;
-import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.hasId;
-import static org.hamcrest.Matchers.closeTo;
-import static org.hamcrest.Matchers.containsString;
-import static org.hamcrest.Matchers.equalTo;
-import static org.hamcrest.Matchers.greaterThan;
-import static org.hamcrest.Matchers.greaterThanOrEqualTo;
-import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.lessThan;
-import static org.hamcrest.Matchers.lessThanOrEqualTo;
-import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
-import static org.hamcrest.Matchers.nullValue;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
 
 
 /**
@@ -107,7 +74,7 @@ public class SimpleSortTests extends ESIntegTestCase {
     protected Collection<Class<? extends Plugin>> nodePlugins() {
         return Collections.singleton(GroovyPlugin.class);
     }
-    
+
     @TestLogging("action.search.type:TRACE")
     @LuceneTestCase.AwaitsFix(bugUrl = "https://github.com/elasticsearch/elasticsearch/issues/9421")
     public void testIssue8226() {
@@ -391,7 +358,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         SearchResponse searchResponse = client()
                 .prepareSearch("test")
                 .setQuery(
-                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.scriptFunction(new Script("_source.field"))))
+                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.fieldValueFactorFunction("field")))
                 .execute().actionGet();
         assertThat(searchResponse.getHits().getAt(0).getId(), equalTo("1"));
         assertThat(searchResponse.getHits().getAt(1).score(), Matchers.lessThan(searchResponse.getHits().getAt(0).score()));
@@ -402,7 +369,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         searchResponse = client()
                 .prepareSearch("test")
                 .setQuery(
-                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.scriptFunction(new Script("_source.field"))))
+                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.fieldValueFactorFunction("field")))
                 .addSort("_score", SortOrder.DESC).execute().actionGet();
         assertThat(searchResponse.getHits().getAt(0).getId(), equalTo("1"));
         assertThat(searchResponse.getHits().getAt(1).score(), Matchers.lessThan(searchResponse.getHits().getAt(0).score()));
@@ -413,7 +380,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         searchResponse = client()
                 .prepareSearch("test")
                 .setQuery(
-                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.scriptFunction(new Script("_source.field"))))
+                        QueryBuilders.functionScoreQuery(matchAllQuery(), ScoreFunctionBuilders.fieldValueFactorFunction("field")))
                 .addSort("_score", SortOrder.DESC).execute().actionGet();
         assertThat(searchResponse.getHits().getAt(2).getId(), equalTo("3"));
         assertThat(searchResponse.getHits().getAt(1).getId(), equalTo("2"));
@@ -433,7 +400,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         refresh();
 
         SearchResponse searchResponse = client().prepareSearch("test")
-                .setQuery(functionScoreQuery(matchAllQuery(), scriptFunction(new Script("_source.field")))).execute().actionGet();
+                .setQuery(functionScoreQuery(matchAllQuery(), fieldValueFactorFunction("field"))).execute().actionGet();
         assertThat(searchResponse.getHits().getAt(0).getId(), equalTo("1"));
         assertThat(searchResponse.getHits().getAt(1).score(), Matchers.lessThan(searchResponse.getHits().getAt(0).score()));
         assertThat(searchResponse.getHits().getAt(1).getId(), equalTo("2"));
@@ -441,7 +408,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertThat(searchResponse.getHits().getAt(2).getId(), equalTo("3"));
 
         searchResponse = client().prepareSearch("test")
-                .setQuery(functionScoreQuery(matchAllQuery(), scriptFunction(new Script("_source.field"))))
+                .setQuery(functionScoreQuery(matchAllQuery(), fieldValueFactorFunction("field")))
                 .addSort("_score", SortOrder.DESC).execute().actionGet();
         assertThat(searchResponse.getHits().getAt(0).getId(), equalTo("1"));
         assertThat(searchResponse.getHits().getAt(1).score(), Matchers.lessThan(searchResponse.getHits().getAt(0).score()));
@@ -450,7 +417,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertThat(searchResponse.getHits().getAt(2).getId(), equalTo("3"));
 
         searchResponse = client().prepareSearch("test")
-                .setQuery(functionScoreQuery(matchAllQuery(), scriptFunction(new Script("_source.field"))))
+                .setQuery(functionScoreQuery(matchAllQuery(), fieldValueFactorFunction("field")))
                 .addSort("_score", SortOrder.DESC).execute().actionGet();
         assertThat(searchResponse.getHits().getAt(2).getId(), equalTo("3"));
         assertThat(searchResponse.getHits().getAt(1).getId(), equalTo("2"));
@@ -907,9 +874,9 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertNoFailures(searchResponse);
 
         assertThat(searchResponse.getHits().getTotalHits(), equalTo(3l));
-        assertThat((String) searchResponse.getHits().getAt(0).field("id").value(), equalTo("1"));
-        assertThat((String) searchResponse.getHits().getAt(1).field("id").value(), equalTo("3"));
-        assertThat((String) searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
+        assertThat(searchResponse.getHits().getAt(0).field("id").value(), equalTo("1"));
+        assertThat(searchResponse.getHits().getAt(1).field("id").value(), equalTo("3"));
+        assertThat(searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
 
         searchResponse = client().prepareSearch()
                 .setQuery(matchAllQuery())
@@ -920,9 +887,9 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertNoFailures(searchResponse);
 
         assertThat(searchResponse.getHits().getTotalHits(), equalTo(3l));
-        assertThat((String) searchResponse.getHits().getAt(0).field("id").value(), equalTo("1"));
-        assertThat((String) searchResponse.getHits().getAt(1).field("id").value(), equalTo("3"));
-        assertThat((String) searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
+        assertThat(searchResponse.getHits().getAt(0).field("id").value(), equalTo("1"));
+        assertThat(searchResponse.getHits().getAt(1).field("id").value(), equalTo("3"));
+        assertThat(searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
 
         searchResponse = client().prepareSearch()
                 .setQuery(matchAllQuery())
@@ -939,9 +906,9 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertThat(searchResponse.getFailedShards(), equalTo(0));
 
         assertThat(searchResponse.getHits().getTotalHits(), equalTo(3l));
-        assertThat((String) searchResponse.getHits().getAt(0).field("id").value(), equalTo("3"));
-        assertThat((String) searchResponse.getHits().getAt(1).field("id").value(), equalTo("1"));
-        assertThat((String) searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
+        assertThat(searchResponse.getHits().getAt(0).field("id").value(), equalTo("3"));
+        assertThat(searchResponse.getHits().getAt(1).field("id").value(), equalTo("1"));
+        assertThat(searchResponse.getHits().getAt(2).field("id").value(), equalTo("2"));
 
         // a query with docs just with null values
         searchResponse = client().prepareSearch()
@@ -959,7 +926,7 @@ public class SimpleSortTests extends ESIntegTestCase {
         assertThat(searchResponse.getFailedShards(), equalTo(0));
 
         assertThat(searchResponse.getHits().getTotalHits(), equalTo(1l));
-        assertThat((String) searchResponse.getHits().getAt(0).field("id").value(), equalTo("2"));
+        assertThat(searchResponse.getHits().getAt(0).field("id").value(), equalTo("2"));
     }
 
     @Test
@@ -1782,32 +1749,32 @@ public class SimpleSortTests extends ESIntegTestCase {
                 .addSort(new GeoDistanceSortBuilder("location").points(q).sortMode("min").order(SortOrder.ASC).geoDistance(GeoDistance.PLANE).unit(DistanceUnit.KILOMETERS))
                 .execute().actionGet();
         assertOrderedSearchHits(searchResponse, "d1", "d2");
-        assertThat((Double) searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 3, 2, DistanceUnit.KILOMETERS)));
-        assertThat((Double) searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 5, 1, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 3, 2, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 5, 1, DistanceUnit.KILOMETERS)));
 
         searchResponse = client().prepareSearch()
                 .setQuery(matchAllQuery())
                 .addSort(new GeoDistanceSortBuilder("location").points(q).sortMode("min").order(SortOrder.DESC).geoDistance(GeoDistance.PLANE).unit(DistanceUnit.KILOMETERS))
                 .execute().actionGet();
         assertOrderedSearchHits(searchResponse, "d2", "d1");
-        assertThat((Double) searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 5, 1, DistanceUnit.KILOMETERS)));
-        assertThat((Double) searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 3, 2, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 5, 1, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 3, 2, DistanceUnit.KILOMETERS)));
 
         searchResponse = client().prepareSearch()
                 .setQuery(matchAllQuery())
                 .addSort(new GeoDistanceSortBuilder("location").points(q).sortMode("max").order(SortOrder.ASC).geoDistance(GeoDistance.PLANE).unit(DistanceUnit.KILOMETERS))
                 .execute().actionGet();
         assertOrderedSearchHits(searchResponse, "d1", "d2");
-        assertThat((Double) searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 4, 1, DistanceUnit.KILOMETERS)));
-        assertThat((Double) searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 6, 2, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 4, 1, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 6, 2, DistanceUnit.KILOMETERS)));
 
         searchResponse = client().prepareSearch()
                 .setQuery(matchAllQuery())
                 .addSort(new GeoDistanceSortBuilder("location").points(q).sortMode("max").order(SortOrder.DESC).geoDistance(GeoDistance.PLANE).unit(DistanceUnit.KILOMETERS))
                 .execute().actionGet();
         assertOrderedSearchHits(searchResponse, "d2", "d1");
-        assertThat((Double) searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 6, 2, DistanceUnit.KILOMETERS)));
-        assertThat((Double) searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 4, 1, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(0).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 1, 6, 2, DistanceUnit.KILOMETERS)));
+        assertThat(searchResponse.getHits().getAt(1).getSortValues()[0], equalTo(GeoDistance.PLANE.calculate(2, 2, 4, 1, DistanceUnit.KILOMETERS)));
     }
 
     protected void createShuffeldJSONArray(XContentBuilder builder, GeoPoint[] pointsArray) throws IOException {
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/TransformOnIndexMapperTests.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/TransformOnIndexMapperTests.java
index 69da9c7..ace6f68 100644
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/TransformOnIndexMapperTests.java
+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/TransformOnIndexMapperTests.java
@@ -19,6 +19,8 @@
 
 package org.elasticsearch.messy.tests;
 
+import com.google.common.collect.ImmutableMap;
+
 import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import org.elasticsearch.action.get.GetResponse;
 import org.elasticsearch.action.search.SearchResponse;
@@ -40,7 +42,6 @@ import java.util.Collections;
 import java.util.Map;
 import java.util.concurrent.ExecutionException;
 
-import static java.util.Collections.singletonMap;
 import static org.elasticsearch.index.query.QueryBuilders.termQuery;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;
 import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertExists;
@@ -57,12 +58,12 @@ import static org.hamcrest.Matchers.not;
  */
 @SuppressCodecs("*") // requires custom completion format
 public class TransformOnIndexMapperTests extends ESIntegTestCase {
-
+    
     @Override
     protected Collection<Class<? extends Plugin>> nodePlugins() {
         return Collections.singleton(GroovyPlugin.class);
     }
-
+    
     @Test
     public void searchOnTransformed() throws Exception {
         setup(true);
@@ -170,7 +171,7 @@ public class TransformOnIndexMapperTests extends ESIntegTestCase {
         if (getRandom().nextBoolean()) {
             script = script.replace("sourceField", "'content'");
         } else {
-            builder.field("params", singletonMap("sourceField", "content"));
+            builder.field("params", ImmutableMap.of("sourceField", "content"));
         }
         builder.field("script", script);
     }
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/package-info.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/package-info.java
index 4767ada..c4d9366 100644
--- a/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/package-info.java
+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/package-info.java
@@ -35,7 +35,6 @@
  * </ul>
  */
 /* List of renames that took place:
-  renamed:    core/src/test/java/org/elasticsearch/routing/AliasRoutingIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/AliasRoutingTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/metrics/AvgIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/AvgTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/BucketScriptTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketSelectorIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/BucketSelectorTests.java
@@ -63,14 +62,12 @@
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/bucket/MinDocCountIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinDocCountTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/metrics/MinIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java
   renamed:    core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/PercolatorTests.java
-  renamed:    core/src/test/java/org/elasticsearch/search/rescore/QueryRescorerIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/QueryRescorerTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/functionscore/RandomScoreFunctionIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/RandomScoreFunctionTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/bucket/RangeIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/RangeTests.java
   renamed:    core/src/test/java/org/elasticsearch/script/ScriptIndexSettingsIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptIndexSettingsTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/scriptfilter/ScriptQuerySearchIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptQuerySearchTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/metrics/ScriptedMetricIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/ScriptedMetricTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/fields/SearchFieldsIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchFieldsTests.java
-  renamed:    core/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchQueryTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/stats/SearchStatsIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchStatsTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/timeout/SearchTimeoutIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SearchTimeoutTests.java
   renamed:    core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsSignificanceScoreIT.java -> plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/SignificantTermsSignificanceScoreTests.java
diff --git a/plugins/lang-groovy/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java b/plugins/lang-groovy/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
new file mode 100644
index 0000000..008a83e
--- /dev/null
+++ b/plugins/lang-groovy/src/test/java/org/elasticsearch/search/query/SearchQueryIT.java
@@ -0,0 +1,2209 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the "License"); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.search.query;
+
+import org.apache.lucene.util.English;
+import org.elasticsearch.Version;
+import org.elasticsearch.action.admin.indices.create.CreateIndexRequestBuilder;
+import org.elasticsearch.action.index.IndexRequestBuilder;
+import org.elasticsearch.action.search.SearchPhaseExecutionException;
+import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.action.search.SearchType;
+import org.elasticsearch.action.search.ShardSearchFailure;
+import org.elasticsearch.cluster.metadata.IndexMetaData;
+import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.xcontent.XContentFactory;
+import org.elasticsearch.index.mapper.MapperParsingException;
+import org.elasticsearch.index.query.*;
+import org.elasticsearch.index.query.functionscore.ScoreFunctionBuilders;
+import org.elasticsearch.index.search.MatchQuery;
+import org.elasticsearch.index.search.MatchQuery.Type;
+import org.elasticsearch.indices.cache.query.terms.TermsLookup;
+import org.elasticsearch.rest.RestStatus;
+import org.elasticsearch.search.SearchHit;
+import org.elasticsearch.search.SearchHits;
+import org.elasticsearch.search.aggregations.AggregationBuilders;
+import org.elasticsearch.test.ESIntegTestCase;
+import org.joda.time.DateTime;
+import org.joda.time.DateTimeZone;
+import org.joda.time.format.ISODateTimeFormat;
+import org.junit.Test;
+
+import java.io.IOException;
+import java.util.Random;
+import java.util.concurrent.ExecutionException;
+
+import static org.elasticsearch.cluster.metadata.IndexMetaData.SETTING_NUMBER_OF_SHARDS;
+import static org.elasticsearch.common.settings.Settings.settingsBuilder;
+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
+import static org.elasticsearch.index.query.QueryBuilders.*;
+import static org.elasticsearch.test.VersionUtils.randomVersion;
+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.*;
+import static org.hamcrest.Matchers.*;
+
+public class SearchQueryIT extends ESIntegTestCase {
+
+    @Override
+    protected int maximumNumberOfShards() {
+        return 7;
+    }
+
+    @Override
+    protected int maximumNumberOfReplicas() {
+        return Math.min(2, cluster().numDataNodes() - 1);
+    }
+
+    @Test
+    public void testOmitNormsOnAll() throws ExecutionException, InterruptedException, IOException {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
+                        .startObject("_all").field("omit_norms", true).endObject()
+                        .endObject().endObject())
+                .setSettings(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)); // only one shard otherwise IDF might be different for comparing scores
+
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
+                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
+
+        assertHitCount(client().prepareSearch().setQuery(matchQuery("_all", "quick")).get(), 3l);
+        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("_all", "quick")).setExplain(true).get();
+        SearchHit[] hits = searchResponse.getHits().hits();
+        assertThat(hits.length, equalTo(3));
+        assertThat(hits[0].score(), allOf(equalTo(hits[1].getScore()), equalTo(hits[2].getScore())));
+        cluster().wipeIndices("test");
+
+        createIndex("test");
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
+                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
+
+        assertHitCount(client().prepareSearch().setQuery(matchQuery("_all", "quick")).get(), 3l);
+        searchResponse = client().prepareSearch().setQuery(matchQuery("_all", "quick")).get();
+        hits = searchResponse.getHits().hits();
+        assertThat(hits.length, equalTo(3));
+        assertThat(hits[0].score(), allOf(greaterThan(hits[1].getScore()), greaterThan(hits[2].getScore())));
+
+    }
+
+    @Test // see #3952
+    public void testEmptyQueryString() throws ExecutionException, InterruptedException, IOException {
+        createIndex("test");
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox jumps"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "quick brown"),
+                client().prepareIndex("test", "type1", "3").setSource("field1", "quick"));
+
+        assertHitCount(client().prepareSearch().setQuery(queryStringQuery("quick")).get(), 3l);
+        assertHitCount(client().prepareSearch().setQuery(queryStringQuery("")).get(), 0l); // return no docs
+    }
+
+    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3177
+    public void testIssue3177() {
+        createIndex("test");
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "value2").get();
+        client().prepareIndex("test", "type1", "3").setSource("field1", "value3").get();
+        ensureGreen();
+        waitForRelocation();
+        optimize();
+        refresh();
+        assertHitCount(
+                client().prepareSearch()
+                        .setQuery(matchAllQuery())
+                        .setPostFilter(
+                                boolQuery().must(
+                                        matchAllQuery()).must(
+                                        notQuery(boolQuery().must(termQuery("field1", "value1")).must(
+                                                termQuery("field1", "value2"))))).get(),
+                3l);
+        assertHitCount(
+                client().prepareSearch()
+                        .setQuery(
+                                boolQuery().must(
+                                        boolQuery().should(termQuery("field1", "value1")).should(termQuery("field1", "value2"))
+                                                .should(termQuery("field1", "value3"))).filter(
+                                        notQuery(boolQuery().must(termQuery("field1", "value1")).must(
+                                                termQuery("field1", "value2"))))).get(),
+                3l);
+        assertHitCount(
+                client().prepareSearch().setQuery(matchAllQuery()).setPostFilter(notQuery(termQuery("field1", "value3"))).get(),
+                2l);
+    }
+
+    @Test
+    public void passQueryAsStringTest() throws Exception {
+        createIndex("test");
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1_1", "field2", "value2_1").setRefresh(true).get();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery("{ \"term\" : { \"field1\" : \"value1_1\" }}").get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testIndexOptions() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1", "field1", "type=string,index_options=docs"));
+        indexRandom(true,
+                client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(Type.PHRASE).slop(0)).get();
+        assertHitCount(searchResponse, 1l);
+
+        assertFailures(client().prepareSearch().setQuery(matchQuery("field1", "quick brown").type(Type.PHRASE).slop(0)),
+                    RestStatus.INTERNAL_SERVER_ERROR,
+                    containsString("field \"field1\" was indexed without position data; cannot run PhraseQuery"));
+    }
+
+    @Test // see #3521
+    public void testConstantScoreQuery() throws Exception {
+        Random random = getRandom();
+        createIndex("test");
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"), client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("field1", "quick"))).get();
+        assertHitCount(searchResponse, 2l);
+        for (SearchHit searchHit : searchResponse.getHits().hits()) {
+            assertSearchHit(searchHit, hasScore(1.0f));
+        }
+
+        searchResponse = client().prepareSearch("test").setQuery(
+                boolQuery().must(matchAllQuery()).must(
+                constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + getRandom().nextFloat()))).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
+
+        client().prepareSearch("test").setQuery(constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + getRandom().nextFloat())).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
+
+        searchResponse = client().prepareSearch("test").setQuery(
+                constantScoreQuery(boolQuery().must(matchAllQuery()).must(
+                constantScoreQuery(matchQuery("field1", "quick")).boost(1.0f + (random.nextBoolean()? 0.0f : random.nextFloat()))))).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasScore(searchResponse.getHits().getAt(1).score()));
+        for (SearchHit searchHit : searchResponse.getHits().hits()) {
+            assertSearchHit(searchHit, hasScore(1.0f));
+        }
+
+        int num = scaledRandomIntBetween(100, 200);
+        IndexRequestBuilder[] builders = new IndexRequestBuilder[num];
+        for (int i = 0; i < builders.length; i++) {
+            builders[i] = client().prepareIndex("test", "type", "" + i).setSource("f", English.intToEnglish(i));
+        }
+        createIndex("test_1");
+        indexRandom(true, builders);
+
+        int queryRounds = scaledRandomIntBetween(10, 20);
+        for (int i = 0; i < queryRounds; i++) {
+            MatchQueryBuilder matchQuery = matchQuery("f", English.intToEnglish(between(0, num)));
+            searchResponse = client().prepareSearch("test_1").setQuery(matchQuery).setSize(num).get();
+            long totalHits = searchResponse.getHits().totalHits();
+            SearchHits hits = searchResponse.getHits();
+            for (SearchHit searchHit : hits) {
+                assertSearchHit(searchHit, hasScore(1.0f));
+            }
+            searchResponse = client().prepareSearch("test_1").setQuery(
+                    boolQuery().must(matchAllQuery()).must(
+                    constantScoreQuery(matchQuery).boost(1.0f + (random.nextBoolean()? 0.0f : random.nextFloat())))).setSize(num).get();
+            hits = searchResponse.getHits();
+            assertThat(hits.totalHits(), equalTo(totalHits));
+            if (totalHits > 1) {
+                float expected = hits.getAt(0).score();
+                for (SearchHit searchHit : hits) {
+                    assertSearchHit(searchHit, hasScore(expected));
+                }
+            }
+        }
+    }
+
+    @Test // see #3521
+    public void testAllDocsQueryString() throws InterruptedException, ExecutionException {
+        createIndex("test");
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("foo", "bar"),
+                client().prepareIndex("test", "type1", "2").setSource("foo", "bar")
+        );
+
+        int iters = scaledRandomIntBetween(100, 200);
+        for (int i = 0; i < iters; i++) {
+            SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("*:*^10.0").boost(10.0f)).get();
+            assertHitCount(searchResponse, 2l);
+
+            searchResponse = client().prepareSearch("test").setQuery(
+                    boolQuery().must(matchAllQuery()).must(constantScoreQuery(matchAllQuery()))).get();
+            assertHitCount(searchResponse, 2l);
+            assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(Math.sqrt(2), 0.1));
+            assertThat((double)searchResponse.getHits().getAt(1).score(),closeTo(Math.sqrt(2), 0.1));
+        }
+    }
+
+    @Test
+    public void testCommonTermsQueryOnAllField() throws Exception {
+        client().admin().indices().prepareCreate("test")
+                .addMapping("type1", "message", "type=string", "comment", "type=string,boost=5.0")
+                .setSettings(SETTING_NUMBER_OF_SHARDS, 1).get();
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("message", "test message", "comment", "whatever"),
+                client().prepareIndex("test", "type1", "2").setSource("message", "hello world", "comment", "test comment"));
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("_all", "test")).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("2"));
+        assertSecondHit(searchResponse, hasId("1"));
+        assertThat(searchResponse.getHits().getHits()[0].getScore(), greaterThan(searchResponse.getHits().getHits()[1].getScore()));
+    }
+
+    @Test
+    public void testCommonTermsQuery() throws Exception {
+        client().admin().indices().prepareCreate("test")
+                .addMapping("type1", "field1", "type=string,analyzer=whitespace")
+                .setSettings(SETTING_NUMBER_OF_SHARDS, 1).get();
+        indexRandom(true, client().prepareIndex("test", "type1", "3").setSource("field1", "quick lazy huge brown pidgin", "field2", "the quick lazy huge brown fox jumps over the tree"),
+                client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree") );
+
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).lowFreqOperator(Operator.OR)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).lowFreqOperator(Operator.AND)).get();
+        assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        // Default
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the huge fox").lowFreqMinimumShouldMatch("2")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("3")).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("4")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 4 } } } }").get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        // Default
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the lazy fox brown").cutoffFrequency(1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).analyzer("stop")).get();
+        assertHitCount(searchResponse, 3l);
+        // stop drops "the" since its a stopword
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("3"));
+        assertThirdHit(searchResponse, hasId("2"));
+
+        // try the same with match query
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.OR)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the quick brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
+        assertHitCount(searchResponse, 3l);
+        // stop drops "the" since its a stopword
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("3"));
+        assertThirdHit(searchResponse, hasId("2"));
+
+        // try the same with multi match query
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the quick brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
+        assertSecondHit(searchResponse, hasId("1"));
+        assertThirdHit(searchResponse, hasId("2"));
+    }
+
+    @Test
+    public void testCommonTermsQueryStackedTokens() throws Exception {
+        assertAcked(prepareCreate("test")
+                .setSettings(settingsBuilder()
+                        .put(indexSettings())
+                        .put(SETTING_NUMBER_OF_SHARDS,1)
+                        .put("index.analysis.filter.syns.type","synonym")
+                        .putArray("index.analysis.filter.syns.synonyms","quick,fast")
+                        .put("index.analysis.analyzer.syns.tokenizer","whitespace")
+                        .put("index.analysis.analyzer.syns.filter","syns")
+                        )
+                .addMapping("type1", "field1", "type=string,analyzer=syns", "field2", "type=string,analyzer=syns"));
+
+        indexRandom(true, client().prepareIndex("test", "type1", "3").setSource("field1", "quick lazy huge brown pidgin", "field2", "the quick lazy huge brown fox jumps over the tree"),
+                client().prepareIndex("test", "type1", "1").setSource("field1", "the quick brown fox"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "the quick lazy huge brown fox jumps over the tree") );
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3).lowFreqOperator(Operator.OR)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3).lowFreqOperator(Operator.AND)).get();
+        assertThat(searchResponse.getHits().totalHits(), equalTo(2l));
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        // Default
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast brown").cutoffFrequency(3)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast huge fox").lowFreqMinimumShouldMatch("3")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("5")).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1).highFreqMinimumShouldMatch("6")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery("{ \"common\" : { \"field1\" : { \"query\" : \"the fast lazy fox brown\", \"cutoff_frequency\" : 1, \"minimum_should_match\" : { \"high_freq\" : 6 } } } }").get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        // Default
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the fast lazy fox brown").cutoffFrequency(1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(commonTermsQuery("field1", "the quick brown").cutoffFrequency(3).analyzer("stop")).get();
+        assertHitCount(searchResponse, 3l);
+        // stop drops "the" since its a stopword
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("3"));
+        assertThirdHit(searchResponse, hasId("2"));
+
+        // try the same with match query
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.OR)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThirdHit(searchResponse, hasId("3"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).operator(Operator.AND).analyzer("stop")).get();
+        assertHitCount(searchResponse, 3l);
+        // stop drops "the" since its a stopword
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("3"));
+        assertThirdHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field1", "the fast brown").cutoffFrequency(3).minimumShouldMatch("3")).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        // try the same with multi match query
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery("the fast brown", "field1", "field2").cutoffFrequency(3).operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 3l);
+        assertFirstHit(searchResponse, hasId("3")); // better score due to different query stats
+        assertSecondHit(searchResponse, hasId("1"));
+        assertThirdHit(searchResponse, hasId("2"));
+    }
+
+    @Test
+    public void testOmitTermFreqsAndPositions() throws Exception {
+        cluster().wipeTemplates(); // no randomized template for this test -- we are testing bwc compat and set version explicitly this might cause failures if an unsupported feature
+                                   // is added randomly via an index template.
+        Version version = Version.CURRENT;
+        int iters = scaledRandomIntBetween(10, 20);
+        for (int i = 0; i < iters; i++) {
+            try {
+                // backwards compat test!
+                assertAcked(client().admin().indices().prepareCreate("test")
+                        .addMapping("type1", "field1", "type=string,omit_term_freq_and_positions=true")
+                        .setSettings(settings(version).put(SETTING_NUMBER_OF_SHARDS, 1)));
+                assertThat(version.onOrAfter(Version.V_1_0_0_RC2), equalTo(false));
+                indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "quick brown fox", "field2", "quick brown fox"),
+                        client().prepareIndex("test", "type1", "2").setSource("field1", "quick lazy huge brown fox", "field2", "quick lazy huge brown fox"));
+
+
+                SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field2", "quick brown").type(Type.PHRASE).slop(0)).get();
+                assertHitCount(searchResponse, 1l);
+                try {
+                    client().prepareSearch().setQuery(matchQuery("field1", "quick brown").type(Type.PHRASE).slop(0)).get();
+                    fail("SearchPhaseExecutionException should have been thrown");
+                } catch (SearchPhaseExecutionException e) {
+                    assertTrue(e.toString().contains("IllegalStateException[field \"field1\" was indexed without position data; cannot run PhraseQuery"));
+                }
+                cluster().wipeIndices("test");
+            } catch (MapperParsingException ex) {
+                assertThat(version.toString(), version.onOrAfter(Version.V_1_0_0_RC2), equalTo(true));
+                assertThat(ex.getCause().getMessage(), equalTo("'omit_term_freq_and_positions' is not supported anymore - use ['index_options' : 'docs']  instead"));
+            }
+            version = randomVersion(random());
+        }
+    }
+
+    @Test
+    public void queryStringAnalyzedWildcard() throws Exception {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value_1", "field2", "value_2").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("value*").analyzeWildcard(true)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("*ue*").analyzeWildcard(true)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("*ue_1").analyzeWildcard(true)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("val*e_1").analyzeWildcard(true)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("v?l*e?1").analyzeWildcard(true)).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testLowercaseExpandedTerms() {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value_1", "field2", "value_2").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("VALUE_3~1").lowercaseExpandedTerms(true)).get();
+        assertHitCount(searchResponse, 1l);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("VALUE_3~1").lowercaseExpandedTerms(false)).get();
+        assertHitCount(searchResponse, 0l);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("ValUE_*").lowercaseExpandedTerms(true)).get();
+        assertHitCount(searchResponse, 1l);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("vAl*E_1")).get();
+        assertHitCount(searchResponse, 1l);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("[VALUE_1 TO VALUE_3]")).get();
+        assertHitCount(searchResponse, 1l);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("[VALUE_1 TO VALUE_3]").lowercaseExpandedTerms(false)).get();
+        assertHitCount(searchResponse, 0l);
+    }
+
+    @Test //https://github.com/elasticsearch/elasticsearch/issues/3540
+    public void testDateRangeInQueryString() {
+        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
+        //as with dynamic mappings some shards might be lacking behind and parse a different query
+        assertAcked(prepareCreate("test").addMapping(
+                "type", "past", "type=date", "future", "type=date"
+        ));
+
+        String aMonthAgo = ISODateTimeFormat.yearMonthDay().print(new DateTime(DateTimeZone.UTC).minusMonths(1));
+        String aMonthFromNow = ISODateTimeFormat.yearMonthDay().print(new DateTime(DateTimeZone.UTC).plusMonths(1));
+        client().prepareIndex("test", "type", "1").setSource("past", aMonthAgo, "future", aMonthFromNow).get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("past:[now-2M/d TO now/d]")).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("future:[now/d TO now+2M/d]").lowercaseExpandedTerms(false)).get();
+        assertHitCount(searchResponse, 1l);
+
+        try {
+            client().prepareSearch().setQuery(queryStringQuery("future:[now/D TO now+2M/d]").lowercaseExpandedTerms(false)).get();
+            fail("expected SearchPhaseExecutionException (total failure)");
+        } catch (SearchPhaseExecutionException e) {
+            assertThat(e.status(), equalTo(RestStatus.BAD_REQUEST));
+            assertThat(e.toString(), containsString("unit [D] not supported for date math"));
+        }
+    }
+
+    @Test // https://github.com/elasticsearch/elasticsearch/issues/7880
+    public void testDateRangeInQueryStringWithTimeZone_7880() {
+        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
+        //as with dynamic mappings some shards might be lacking behind and parse a different query
+        assertAcked(prepareCreate("test").addMapping(
+                "type", "past", "type=date"
+        ));
+
+        DateTimeZone timeZone = randomDateTimeZone();
+        String now = ISODateTimeFormat.dateTime().print(new DateTime(timeZone));
+        logger.info(" --> Using time_zone [{}], now is [{}]", timeZone.getID(), now);
+        client().prepareIndex("test", "type", "1").setSource("past", now).get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("past:[now-1m/m TO now+1m/m]")
+                .timeZone(timeZone.getID())).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test // https://github.com/elasticsearch/elasticsearch/issues/10477
+    public void testDateRangeInQueryStringWithTimeZone_10477() {
+        //the mapping needs to be provided upfront otherwise we are not sure how many failures we get back
+        //as with dynamic mappings some shards might be lacking behind and parse a different query
+        assertAcked(prepareCreate("test").addMapping(
+                "type", "past", "type=date"
+        ));
+
+        client().prepareIndex("test", "type", "1").setSource("past", "2015-04-05T23:00:00+0000").get();
+        client().prepareIndex("test", "type", "2").setSource("past", "2015-04-06T00:00:00+0000").get();
+        refresh();
+
+        // Timezone set with dates
+        SearchResponse searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00+0200 TO 2015-04-06T23:00:00+0200]"))
+                .get();
+        assertHitCount(searchResponse, 2l);
+
+        // Same timezone set with time_zone
+        searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00 TO 2015-04-06T23:00:00]").timeZone("+0200"))
+                .get();
+        assertHitCount(searchResponse, 2l);
+
+        // We set a timezone which will give no result
+        searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00-0200 TO 2015-04-06T23:00:00-0200]"))
+                .get();
+        assertHitCount(searchResponse, 0l);
+
+        // Same timezone set with time_zone but another timezone is set directly within dates which has the precedence
+        searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("past:[2015-04-06T00:00:00-0200 TO 2015-04-06T23:00:00-0200]").timeZone("+0200"))
+                .get();
+        assertHitCount(searchResponse, 0l);
+    }
+
+    @Test
+    public void typeFilterTypeIndexedTests() throws Exception {
+        typeFilterTests("not_analyzed");
+    }
+
+    @Test
+    public void typeFilterTypeNotIndexedTests() throws Exception {
+        typeFilterTests("no");
+    }
+
+    private void typeFilterTests(String index) throws Exception {
+        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
+        assertAcked(prepareCreate("test").setSettings(indexSettings)
+                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
+                        .startObject("_type").field("index", index).endObject()
+                        .endObject().endObject())
+                .addMapping("type2", jsonBuilder().startObject().startObject("type2")
+                        .startObject("_type").field("index", index).endObject()
+                        .endObject().endObject())
+                .setUpdateAllTypes(true));
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "value1"),
+                client().prepareIndex("test", "type2", "1").setSource("field1", "value1"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "value1"),
+                client().prepareIndex("test", "type2", "2").setSource("field1", "value1"),
+                client().prepareIndex("test", "type2", "3").setSource("field1", "value1"));
+
+        assertHitCount(client().prepareSearch().setQuery(typeQuery("type1")).get(), 2l);
+        assertHitCount(client().prepareSearch().setQuery(typeQuery("type2")).get(), 3l);
+
+        assertHitCount(client().prepareSearch().setTypes("type1").setQuery(matchAllQuery()).get(), 2l);
+        assertHitCount(client().prepareSearch().setTypes("type2").setQuery(matchAllQuery()).get(), 3l);
+
+        assertHitCount(client().prepareSearch().setTypes("type1", "type2").setQuery(matchAllQuery()).get(), 5l);
+    }
+
+    @Test
+    public void idsQueryTestsIdIndexed() throws Exception {
+        idsQueryTests("not_analyzed");
+    }
+
+    @Test
+    public void idsQueryTestsIdNotIndexed() throws Exception {
+        idsQueryTests("no");
+    }
+
+    private void idsQueryTests(String index) throws Exception {
+        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
+        assertAcked(client().admin().indices().prepareCreate("test").setSettings(indexSettings)
+                .addMapping("type1", jsonBuilder().startObject().startObject("type1")
+                        .startObject("_id").field("index", index).endObject()
+                        .endObject().endObject()));
+
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("field1", "value1"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "value2"),
+                client().prepareIndex("test", "type1", "3").setSource("field1", "value3"));
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery("type1").addIds("1", "3"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        // no type
+        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(idsQuery().addIds("1", "3"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").addIds("1", "3")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        // no type
+        searchResponse = client().prepareSearch().setQuery(idsQuery().addIds("1", "3")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").addIds("7", "10")).get();
+        assertHitCount(searchResponse, 0l);
+
+        // repeat..., with terms
+        searchResponse = client().prepareSearch().setTypes("type1").setQuery(constantScoreQuery(termsQuery("_id", "1", "3"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+    }
+
+    @Test
+    public void term_indexQueryTestsIndexed() throws Exception {
+        term_indexQueryTests("not_analyzed");
+    }
+
+    @Test
+    public void term_indexQueryTestsNotIndexed() throws Exception {
+        term_indexQueryTests("no");
+    }
+
+    private void term_indexQueryTests(String index) throws Exception {
+        Settings indexSettings = Settings.builder().put(IndexMetaData.SETTING_VERSION_CREATED, Version.V_1_4_2.id).build();
+        String[] indexNames = { "test1", "test2" };
+        for (String indexName : indexNames) {
+            assertAcked(client()
+                    .admin()
+                    .indices()
+                    .prepareCreate(indexName)
+                    .setSettings(indexSettings)
+                    .addMapping(
+                            "type1",
+                            jsonBuilder().startObject().startObject("type1").startObject("_index").field("index", index).endObject()
+                                    .endObject().endObject()));
+
+            indexRandom(true, client().prepareIndex(indexName, "type1", indexName + "1").setSource("field1", "value1"));
+
+        }
+
+        for (String indexName : indexNames) {
+            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termQuery("_index", indexName))).get();
+            SearchResponse searchResponse = assertSearchResponse(request);
+            assertHitCount(searchResponse, 1l);
+            assertSearchHits(searchResponse, indexName + "1");
+        }
+        for (String indexName : indexNames) {
+            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termsQuery("_index", indexName))).get();
+            SearchResponse searchResponse = assertSearchResponse(request);
+            assertHitCount(searchResponse, 1l);
+            assertSearchHits(searchResponse, indexName + "1");
+        }
+        for (String indexName : indexNames) {
+            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(matchQuery("_index", indexName))).get();
+            SearchResponse searchResponse = assertSearchResponse(request);
+            assertHitCount(searchResponse, 1l);
+            assertSearchHits(searchResponse, indexName + "1");
+        }
+        {
+            SearchResponse request = client().prepareSearch().setQuery(constantScoreQuery(termsQuery("_index", indexNames))).get();
+            SearchResponse searchResponse = assertSearchResponse(request);
+            assertHitCount(searchResponse, indexNames.length);
+        }
+    }
+
+    @Test
+    public void filterExistsMissingTests() throws Exception {
+        createIndex("test");
+
+        indexRandom(true,
+                client().prepareIndex("test", "type1", "1").setSource(jsonBuilder().startObject().startObject("obj1").field("obj1_val", "1").endObject().field("x1", "x_1").field("field1", "value1_1").field("field2", "value2_1").endObject()),
+                client().prepareIndex("test", "type1", "2").setSource(jsonBuilder().startObject().startObject("obj1").field("obj1_val", "1").endObject().field("x2", "x_2").field("field1", "value1_2").endObject()),
+                client().prepareIndex("test", "type1", "3").setSource(jsonBuilder().startObject().startObject("obj2").field("obj2_val", "1").endObject().field("y1", "y_1").field("field2", "value2_3").endObject()),
+                client().prepareIndex("test", "type1", "4").setSource(jsonBuilder().startObject().startObject("obj2").field("obj2_val", "1").endObject().field("y2", "y_2").field("field3", "value3_4").endObject()) );
+
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(existsQuery("field1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(existsQuery("field1"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("_exists_:field1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        searchResponse = client().prepareSearch().setQuery(existsQuery("field2")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch().setQuery(existsQuery("field3")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("4"));
+
+        // wildcard check
+        searchResponse = client().prepareSearch().setQuery(existsQuery("x*")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        // object check
+        searchResponse = client().prepareSearch().setQuery(existsQuery("obj1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        searchResponse = client().prepareSearch().setQuery(missingQuery("field1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+
+        searchResponse = client().prepareSearch().setQuery(missingQuery("field1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+
+        searchResponse = client().prepareSearch().setQuery(constantScoreQuery(missingQuery("field1"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("_missing_:field1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+
+        // wildcard check
+        searchResponse = client().prepareSearch().setQuery(missingQuery("x*")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+
+        // object check
+        searchResponse = client().prepareSearch().setQuery(missingQuery("obj1")).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "4");
+    }
+
+    @Test
+    public void passQueryOrFilterAsJSONStringTest() throws Exception {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1_1", "field2", "value2_1").setRefresh(true).get();
+
+        WrapperQueryBuilder wrapper = new WrapperQueryBuilder("{ \"term\" : { \"field1\" : \"value1_1\" } }");
+        assertHitCount(client().prepareSearch().setQuery(wrapper).get(), 1l);
+
+        BoolQueryBuilder bool = boolQuery().must(wrapper).must(new TermQueryBuilder("field2", "value2_1"));
+        assertHitCount(client().prepareSearch().setQuery(bool).get(), 1l);
+
+        WrapperQueryBuilder wrapperFilter = wrapperQuery("{ \"term\" : { \"field1\" : \"value1_1\" } }");
+        assertHitCount(client().prepareSearch().setPostFilter(wrapperFilter).get(), 1l);
+    }
+
+    @Test
+    public void testFiltersWithCustomCacheKey() throws Exception {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
+        refresh();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("field1", "value1"))).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testMatchQueryNumeric() throws Exception {
+        assertAcked(prepareCreate("test").addMapping("type1", "long", "type=long", "double", "type=double"));
+
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("long", 1l, "double", 1.0d),
+                client().prepareIndex("test", "type1", "2").setSource("long", 2l, "double", 2.0d),
+                client().prepareIndex("test", "type1", "3").setSource("long", 3l, "double", 3.0d));
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("long", "1")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        searchResponse = client().prepareSearch().setQuery(matchQuery("double", "2")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+        try {
+            client().prepareSearch().setQuery(matchQuery("double", "2 3 4")).get();
+            fail("SearchPhaseExecutionException should have been thrown");
+        } catch (SearchPhaseExecutionException ex) {
+            // number format exception
+        }
+    }
+
+    @Test
+    public void testMultiMatchQuery() throws Exception {
+        createIndex("test");
+
+        indexRandom(true,
+                client().prepareIndex("test", "type1", "1").setSource("field1", "value1", "field2", "value4", "field3", "value3"),
+                client().prepareIndex("test", "type1", "2").setSource("field1", "value2", "field2", "value5", "field3", "value2"),
+                client().prepareIndex("test", "type1", "3").setSource("field1", "value3", "field2", "value6", "field3", "value1") );
+
+        MultiMatchQueryBuilder builder = multiMatchQuery("value1 value2 value4", "field1", "field2");
+        SearchResponse searchResponse = client().prepareSearch().setQuery(builder)
+                .addAggregation(AggregationBuilders.terms("field1").field("field1")).get();
+
+        assertHitCount(searchResponse, 2l);
+        // this uses dismax so scores are equal and the order can be arbitrary
+        assertSearchHits(searchResponse, "1", "2");
+
+        builder.useDisMax(false);
+        searchResponse = client().prepareSearch()
+                .setQuery(builder)
+                .get();
+
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        client().admin().indices().prepareRefresh("test").get();
+        builder = multiMatchQuery("value1", "field1", "field2")
+                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+        searchResponse = client().prepareSearch()
+                .setQuery(builder)
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        refresh();
+        builder = multiMatchQuery("value1", "field1").field("field3", 1.5f)
+                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+        searchResponse = client().prepareSearch().setQuery(builder).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "1");
+
+        client().admin().indices().prepareRefresh("test").get();
+        builder = multiMatchQuery("value1").field("field1").field("field3", 1.5f)
+                .operator(Operator.AND); // Operator only applies on terms inside a field! Fields are always OR-ed together.
+        searchResponse = client().prepareSearch().setQuery(builder).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "3", "1");
+
+        // Test lenient
+        client().prepareIndex("test", "type1", "3").setSource("field1", "value7", "field2", "value8", "field4", 5).get();
+        refresh();
+
+        builder = multiMatchQuery("value1", "field1", "field2", "field4");
+
+        assertFailures(client().prepareSearch().setQuery(builder),
+                RestStatus.BAD_REQUEST,
+                containsString("NumberFormatException[For input string: \"value1\"]"));
+
+        builder.lenient(true);
+        searchResponse = client().prepareSearch().setQuery(builder).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+    }
+
+    @Test
+    public void testMatchQueryZeroTermsQuery() {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1", "field1", "type=string,analyzer=classic", "field2", "type=string,analyzer=classic"));
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "value2").get();
+        refresh();
+
+        BoolQueryBuilder boolQuery = boolQuery()
+                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE))
+                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE));
+        SearchResponse searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 0l);
+
+        boolQuery = boolQuery()
+                .must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL))
+                .must(matchQuery("field1", "value1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 1l);
+
+        boolQuery = boolQuery().must(matchQuery("field1", "a").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 2l);
+    }
+
+    public void testMultiMatchQueryZeroTermsQuery() {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1", "field1", "type=string,analyzer=classic", "field2", "type=string,analyzer=classic"));
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1", "field2", "value2").get();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "value3", "field2", "value4").get();
+        refresh();
+
+
+        BoolQueryBuilder boolQuery = boolQuery()
+                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE))
+                .must(multiMatchQuery("value1", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.NONE)); // Fields are ORed together
+        SearchResponse searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 0l);
+
+        boolQuery = boolQuery()
+                .must(multiMatchQuery("a", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL))
+                .must(multiMatchQuery("value4", "field1", "field2").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 1l);
+
+        boolQuery = boolQuery().must(multiMatchQuery("a", "field1").zeroTermsQuery(MatchQuery.ZeroTermsQuery.ALL));
+        searchResponse = client().prepareSearch().setQuery(boolQuery).get();
+        assertHitCount(searchResponse, 2l);
+    }
+
+    @Test
+    public void testMultiMatchQueryMinShouldMatch() {
+        createIndex("test");
+        client().prepareIndex("test", "type1", "1").setSource("field1", new String[]{"value1", "value2", "value3"}).get();
+        client().prepareIndex("test", "type1", "2").setSource("field2", "value1").get();
+        refresh();
+
+        MultiMatchQueryBuilder multiMatchQuery = multiMatchQuery("value1 value2 foo", "field1", "field2");
+
+        multiMatchQuery.useDisMax(true);
+        multiMatchQuery.minimumShouldMatch("70%");
+        SearchResponse searchResponse = client().prepareSearch()
+                .setQuery(multiMatchQuery)
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        multiMatchQuery.minimumShouldMatch("30%");
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        multiMatchQuery.useDisMax(false);
+        multiMatchQuery.minimumShouldMatch("70%");
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        multiMatchQuery.minimumShouldMatch("30%");
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+
+        multiMatchQuery = multiMatchQuery("value1 value2 bar", "field1");
+        multiMatchQuery.minimumShouldMatch("100%");
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
+        assertHitCount(searchResponse, 0l);
+
+        multiMatchQuery.minimumShouldMatch("70%");
+        searchResponse = client().prepareSearch().setQuery(multiMatchQuery).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+    }
+
+    @Test
+    public void testFuzzyQueryString() {
+        createIndex("test");
+        client().prepareIndex("test", "type1", "1").setSource("str", "kimchy", "date", "2012-02-01", "num", 12).get();
+        client().prepareIndex("test", "type1", "2").setSource("str", "shay", "date", "2012-02-05", "num", 20).get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("str:kimcy~1")).get();
+        assertNoFailures(searchResponse);
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:11~1")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("date:2012-02-02~1d")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+    }
+
+    @Test
+    public void testQuotedQueryStringWithBoost() throws InterruptedException, ExecutionException {
+        float boost = 10.0f;
+        assertAcked(prepareCreate("test").setSettings(SETTING_NUMBER_OF_SHARDS, 1));
+        indexRandom(true, client().prepareIndex("test", "type1", "1").setSource("important", "phrase match", "less_important", "nothing important"),
+                client().prepareIndex("test", "type1", "2").setSource("important", "nothing important", "less_important", "phrase match")
+        );
+
+
+        SearchResponse searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("\"phrase match\"").field("important", boost).field("less_important")).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(boost * searchResponse.getHits().getAt(1).score(), .1));
+
+        searchResponse = client().prepareSearch()
+                .setQuery(queryStringQuery("\"phrase match\"").field("important", boost).field("less_important").useDisMax(false)).get();
+        assertHitCount(searchResponse, 2l);
+        assertFirstHit(searchResponse, hasId("1"));
+        assertSecondHit(searchResponse, hasId("2"));
+        assertThat((double)searchResponse.getHits().getAt(0).score(), closeTo(boost * searchResponse.getHits().getAt(1).score(), .1));
+    }
+
+    @Test
+    public void testSpecialRangeSyntaxInQueryString() {
+        createIndex("test");
+        client().prepareIndex("test", "type1", "1").setSource("str", "kimchy", "date", "2012-02-01", "num", 12).get();
+        client().prepareIndex("test", "type1", "2").setSource("str", "shay", "date", "2012-02-05", "num", 20).get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>19")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>20")).get();
+        assertHitCount(searchResponse, 0l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>=20")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:>11")).get();
+        assertHitCount(searchResponse, 2l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:<20")).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("num:<=20")).get();
+        assertHitCount(searchResponse, 2l);
+
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("+num:>11 +num:<20")).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testEmptytermsQuery() throws Exception {
+        assertAcked(prepareCreate("test").addMapping("type", "term", "type=string"));
+
+        indexRandom(true, client().prepareIndex("test", "type", "1").setSource("term", "1"),
+                client().prepareIndex("test", "type", "2").setSource("term", "2"),
+                client().prepareIndex("test", "type", "3").setSource("term", "3"),
+                client().prepareIndex("test", "type", "4").setSource("term", "4") );
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("term", new String[0]))).get();
+        assertHitCount(searchResponse, 0l);
+
+        searchResponse = client().prepareSearch("test").setQuery(idsQuery()).get();
+        assertHitCount(searchResponse, 0l);
+    }
+
+    @Test
+    public void testTermsQuery() throws Exception {
+        assertAcked(prepareCreate("test").addMapping("type", "str", "type=string", "lng", "type=long", "dbl", "type=double"));
+
+        indexRandom(true,
+                client().prepareIndex("test", "type", "1").setSource("str", "1", "lng", 1l, "dbl", 1.0d),
+                client().prepareIndex("test", "type", "2").setSource("str", "2", "lng", 2l, "dbl", 2.0d),
+                client().prepareIndex("test", "type", "3").setSource("str", "3", "lng", 3l, "dbl", 3.0d),
+                client().prepareIndex("test", "type", "4").setSource("str", "4", "lng", 4l, "dbl", 4.0d));
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("str", "1", "4"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "4");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {2, 3}))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "2", "3");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("dbl", new double[]{2, 3}))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "2", "3");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("lng", new int[] {1, 3}))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("dbl", new float[] {2, 4}))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "2", "4");
+
+        // test partial matching
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("str", "2", "5"))).get();
+        assertNoFailures(searchResponse);
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("dbl", new double[] {2, 5}))).get();
+        assertNoFailures(searchResponse);
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {2, 5}))).get();
+        assertNoFailures(searchResponse);
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        // test valid type, but no matching terms
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("str", "5", "6"))).get();
+        assertHitCount(searchResponse, 0l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("dbl", new double[] {5, 6}))).get();
+        assertHitCount(searchResponse, 0l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(constantScoreQuery(termsQuery("lng", new long[] {5, 6}))).get();
+        assertHitCount(searchResponse, 0l);
+    }
+
+    @Test
+    public void testTermsLookupFilter() throws Exception {
+        assertAcked(prepareCreate("lookup").addMapping("type", "terms","type=string", "other", "type=string"));
+        assertAcked(prepareCreate("lookup2").addMapping("type",
+                jsonBuilder().startObject().startObject("type").startObject("properties")
+                        .startObject("arr").startObject("properties").startObject("term").field("type", "string")
+                        .endObject().endObject().endObject().endObject().endObject().endObject()));
+        assertAcked(prepareCreate("test").addMapping("type", "term", "type=string"));
+
+        indexRandom(true,
+                client().prepareIndex("lookup", "type", "1").setSource("terms", new String[]{"1", "3"}),
+                client().prepareIndex("lookup", "type", "2").setSource("terms", new String[]{"2"}),
+                client().prepareIndex("lookup", "type", "3").setSource("terms", new String[]{"2", "4"}),
+                client().prepareIndex("lookup", "type", "4").setSource("other", "value"),
+                client().prepareIndex("lookup2", "type", "1").setSource(XContentFactory.jsonBuilder().startObject()
+                        .startArray("arr")
+                        .startObject().field("term", "1").endObject()
+                        .startObject().field("term", "3").endObject()
+                        .endArray()
+                        .endObject()),
+                client().prepareIndex("lookup2", "type", "2").setSource(XContentFactory.jsonBuilder().startObject()
+                        .startArray("arr")
+                        .startObject().field("term", "2").endObject()
+                        .endArray()
+                        .endObject()),
+                client().prepareIndex("lookup2", "type", "3").setSource(XContentFactory.jsonBuilder().startObject()
+                        .startArray("arr")
+                        .startObject().field("term", "2").endObject()
+                        .startObject().field("term", "4").endObject()
+                        .endArray()
+                        .endObject()),
+                client().prepareIndex("test", "type", "1").setSource("term", "1"),
+                client().prepareIndex("test", "type", "2").setSource("term", "2"),
+                client().prepareIndex("test", "type", "3").setSource("term", "3"),
+                client().prepareIndex("test", "type", "4").setSource("term", "4") );
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term" , new TermsLookup("lookup", "type", "1", "terms"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        // same as above, just on the _id...
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("_id", new TermsLookup("lookup", "type", "1", "terms"))
+                ).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        // another search with same parameters...
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "1", "terms"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "2", "terms"))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "3", "terms"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "2", "4");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup", "type", "4", "terms"))).get();
+        assertHitCount(searchResponse, 0l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "1", "arr.term"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "3");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "2", "arr.term"))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("2"));
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("term", new TermsLookup("lookup2", "type", "3", "arr.term"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "2", "4");
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termsLookupQuery("not_exists", new TermsLookup("lookup2", "type", "3", "arr.term"))).get();
+        assertHitCount(searchResponse, 0l);
+    }
+
+    @Test
+    public void testBasicQueryById() throws Exception {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "value1").get();
+        client().prepareIndex("test", "type2", "2").setSource("field1", "value2").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(idsQuery("type1", "type2").addIds("1", "2")).get();
+        assertHitCount(searchResponse, 2l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(2));
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery().addIds("1")).get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(1));
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery().addIds("1", "2")).get();
+        assertHitCount(searchResponse, 2l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(2));
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery("type1").addIds("1", "2")).get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(1));
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery(Strings.EMPTY_ARRAY).addIds("1")).get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(1));
+
+        searchResponse = client().prepareSearch().setQuery(idsQuery("type1", "type2", "type3").addIds("1", "2", "3", "4")).get();
+        assertHitCount(searchResponse, 2l);
+        assertThat(searchResponse.getHits().hits().length, equalTo(2));
+    }
+
+    @Test
+    public void testNumericTermsAndRanges() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1",
+                        "num_byte", "type=byte", "num_short", "type=short",
+                        "num_integer", "type=integer", "num_long", "type=long",
+                        "num_float", "type=float", "num_double", "type=double"));
+
+        client().prepareIndex("test", "type1", "1").setSource("num_byte", 1, "num_short", 1, "num_integer", 1,
+                "num_long", 1, "num_float", 1, "num_double", 1).get();
+
+        client().prepareIndex("test", "type1", "2").setSource("num_byte", 2, "num_short", 2, "num_integer", 2,
+                "num_long", 2, "num_float", 2, "num_double", 2).get();
+
+        client().prepareIndex("test", "type1", "17").setSource("num_byte", 17, "num_short", 17, "num_integer", 17,
+                "num_long", 17, "num_float", 17, "num_double", 17).get();
+        refresh();
+
+        SearchResponse searchResponse;
+        logger.info("--> term query on 1");
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_byte", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_short", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_integer", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_long", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_float", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termQuery("num_double", 1)).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        logger.info("--> terms query on 1");
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_byte", new int[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_short", new int[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_integer", new int[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_long", new int[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_float", new double[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(termsQuery("num_double", new double[]{1})).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        logger.info("--> term filter on 1");
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_byte", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_short", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_integer", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_long", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_float", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termQuery("num_double", 1))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+
+        logger.info("--> terms filter on 1");
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_byte", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_short", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_integer", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_long", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_float", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+        searchResponse = client().prepareSearch("test").setQuery(constantScoreQuery(termsQuery("num_double", new int[]{1}))).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+    }
+
+    @Test
+    public void testNumericRangeFilter_2826() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1",
+                        "num_byte", "type=byte", "num_short", "type=short",
+                        "num_integer", "type=integer", "num_long", "type=long",
+                        "num_float", "type=float", "num_double", "type=double"));
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "test1", "num_long", 1).get();
+        client().prepareIndex("test", "type1", "2").setSource("field1", "test1", "num_long", 2).get();
+        client().prepareIndex("test", "type1", "3").setSource("field1", "test2", "num_long", 3).get();
+        client().prepareIndex("test", "type1", "4").setSource("field1", "test2", "num_long", 4).get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch("test").setPostFilter(
+                boolQuery()
+                        .should(rangeQuery("num_long").from(1).to(2))
+                        .should(rangeQuery("num_long").from(3).to(4))
+        ).get();
+        assertHitCount(searchResponse, 4l);
+
+        // This made 2826 fail! (only with bit based filters)
+        searchResponse = client().prepareSearch("test").setPostFilter(
+                boolQuery()
+                        .should(rangeQuery("num_long").from(1).to(2))
+                        .should(rangeQuery("num_long").from(3).to(4))
+        ).get();
+        assertHitCount(searchResponse, 4l);
+
+        // This made #2979 fail!
+        searchResponse = client().prepareSearch("test").setPostFilter(
+                boolQuery()
+                        .must(termQuery("field1", "test1"))
+                        .should(rangeQuery("num_long").from(1).to(2))
+                        .should(rangeQuery("num_long").from(3).to(4))
+        ).get();
+        assertHitCount(searchResponse, 2l);
+    }
+
+    @Test
+    public void testEmptyTopLevelFilter() {
+        client().prepareIndex("test", "type", "1").setSource("field", "value").setRefresh(true).get();
+
+        SearchResponse searchResponse = client().prepareSearch().setPostFilter("{}").get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test // see #2926
+    public void testMustNot() throws IOException, ExecutionException, InterruptedException {
+        assertAcked(prepareCreate("test")
+                //issue manifested only with shards>=2
+                .setSettings(SETTING_NUMBER_OF_SHARDS, between(2, DEFAULT_MAX_NUM_SHARDS)));
+
+
+        indexRandom(true, client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar"),
+                client().prepareIndex("test", "test", "2").setSource("description", "foo other anything"),
+                client().prepareIndex("test", "test", "3").setSource("description", "foo other"),
+                client().prepareIndex("test", "test", "4").setSource("description", "foo"));
+
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchAllQuery())
+                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH).get();
+        assertHitCount(searchResponse, 4l);
+
+        searchResponse = client().prepareSearch("test").setQuery(
+                boolQuery()
+                        .mustNot(matchQuery("description", "anything").type(Type.BOOLEAN))
+        ).setSearchType(SearchType.DFS_QUERY_THEN_FETCH).get();
+        assertHitCount(searchResponse, 2l);
+    }
+
+    @Test // see #2994
+    public void testSimpleSpan() throws IOException, ExecutionException, InterruptedException {
+        createIndex("test");
+
+
+        indexRandom(true, client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar"),
+                client().prepareIndex("test", "test", "2").setSource("description", "foo other anything"),
+                client().prepareIndex("test", "test", "3").setSource("description", "foo other"),
+                client().prepareIndex("test", "test", "4").setSource("description", "foo"));
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanTermQuery("description", "bar"))).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test").setQuery(
+                spanNearQuery(spanTermQuery("description", "foo"), 3)
+                        .clause(spanTermQuery("description", "other"))).get();
+        assertHitCount(searchResponse, 3l);
+    }
+
+    @Test
+    public void testSpanMultiTermQuery() throws IOException {
+        createIndex("test");
+
+        client().prepareIndex("test", "test", "1").setSource("description", "foo other anything bar", "count", 1).get();
+        client().prepareIndex("test", "test", "2").setSource("description", "foo other anything", "count", 2).get();
+        client().prepareIndex("test", "test", "3").setSource("description", "foo other", "count", 3).get();
+        client().prepareIndex("test", "test", "4").setSource("description", "fop", "count", 4).get();
+        refresh();
+
+        SearchResponse response = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(fuzzyQuery("description", "fop")))).get();
+        assertHitCount(response, 4);
+
+        response = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(prefixQuery("description", "fo")))).get();
+        assertHitCount(response, 4);
+
+        response = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(wildcardQuery("description", "oth*")))).get();
+        assertHitCount(response, 3);
+
+        response = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(QueryBuilders.rangeQuery("description").from("ffa").to("foo"))))
+                .execute().actionGet();
+        assertHitCount(response, 3);
+
+        response = client().prepareSearch("test")
+                .setQuery(spanOrQuery(spanMultiTermQueryBuilder(regexpQuery("description", "fo{2}")))).get();
+        assertHitCount(response, 3);
+    }
+
+    @Test
+    public void testSpanNot() throws IOException, ExecutionException, InterruptedException {
+        createIndex("test");
+
+        client().prepareIndex("test", "test", "1").setSource("description", "the quick brown fox jumped over the lazy dog").get();
+        client().prepareIndex("test", "test", "2").setSource("description", "the quick black fox leaped over the sleeping dog").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "brown"))).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "sleeping")).dist(5)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(spanNotQuery(spanNearQuery(QueryBuilders.spanTermQuery("description", "quick"), 1)
+                        .clause(QueryBuilders.spanTermQuery("description", "fox")), spanTermQuery("description", "jumped")).pre(1).post(1)).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testSimpleDFSQuery() throws IOException {
+        assertAcked(prepareCreate("test")
+            .addMapping("s", jsonBuilder()
+                .startObject()
+                .startObject("s")
+                .startObject("_routing")
+                .field("required", true)
+                .endObject()
+                .startObject("properties")
+                .startObject("online")
+                .field("type", "boolean")
+                .endObject()
+                .startObject("ts")
+                .field("type", "date")
+                .field("ignore_malformed", false)
+                .field("format", "epoch_millis")
+                .endObject()
+                .startObject("bs")
+                .field("type", "string")
+                .field("index", "not_analyzed")
+                .endObject()
+                .endObject()
+                .endObject()
+                .endObject())
+            .addMapping("bs", "online", "type=boolean", "ts", "type=date,ignore_malformed=false,format=epoch_millis"));
+
+
+        client().prepareIndex("test", "s", "1").setRouting("Y").setSource("online", false, "bs", "Y", "ts", System.currentTimeMillis() - 100).get();
+        client().prepareIndex("test", "s", "2").setRouting("X").setSource("online", true, "bs", "X", "ts", System.currentTimeMillis() - 10000000).get();
+        client().prepareIndex("test", "bs", "3").setSource("online", false, "ts", System.currentTimeMillis() - 100).get();
+        client().prepareIndex("test", "bs", "4").setSource("online", true, "ts", System.currentTimeMillis() - 123123).get();
+        refresh();
+
+        SearchResponse response = client().prepareSearch("test")
+                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                .setQuery(
+                        boolQuery()
+                                .must(termQuery("online", true))
+                                .must(boolQuery()
+                                        .should(boolQuery()
+                                                .must(rangeQuery("ts").lt(System.currentTimeMillis() - (15 * 1000)))
+                                                .must(termQuery("_type", "bs"))
+                                        )
+                                        .should(boolQuery()
+                                                .must(rangeQuery("ts").lt(System.currentTimeMillis() - (15 * 1000)))
+                                                .must(termQuery("_type", "s"))
+                                        )
+                                )
+                )
+                .setVersion(true)
+                .setFrom(0).setSize(100).setExplain(true).get();
+        assertNoFailures(response);
+    }
+
+    @Test
+    public void testMultiFieldQueryString() {
+        client().prepareIndex("test", "s", "1").setSource("field1", "value1", "field2", "value2").setRefresh(true).get();
+
+        logger.info("regular");
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value1").field("field1").field("field2")).get(), 1);
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value1")).get(), 1);
+        logger.info("prefix");
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value*").field("field1").field("field2")).get(), 1);
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value*")).get(), 1);
+        logger.info("wildcard");
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("v?lue*").field("field1").field("field2")).get(), 1);
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:v?lue*")).get(), 1);
+        logger.info("fuzzy");
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("value~").field("field1").field("field2")).get(), 1);
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:value~")).get(), 1);
+        logger.info("regexp");
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("/value[01]/").field("field1").field("field2")).get(), 1);
+        assertHitCount(client().prepareSearch("test").setQuery(queryStringQuery("field\\*:/value[01]/")).get(), 1);
+    }
+
+    // see #3881 - for extensive description of the issue
+    @Test
+    public void testMatchQueryWithSynonyms() throws IOException {
+        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
+                .put(indexSettings())
+                .put("index.analysis.analyzer.index.type", "custom")
+                .put("index.analysis.analyzer.index.tokenizer", "standard")
+                .put("index.analysis.analyzer.index.filter", "lowercase")
+                .put("index.analysis.analyzer.search.type", "custom")
+                .put("index.analysis.analyzer.search.tokenizer", "standard")
+                .putArray("index.analysis.analyzer.search.filter", "lowercase", "synonym")
+                .put("index.analysis.filter.synonym.type", "synonym")
+                .putArray("index.analysis.filter.synonym.synonyms", "fast, quick"));
+        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
+
+        client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
+        refresh();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fast").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+
+        client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
+        refresh();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2);
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "quick brown").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2);
+    }
+
+    @Test
+    public void testMatchQueryWithStackedStems() throws IOException {
+        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
+                .put(indexSettings())
+                .put("index.analysis.analyzer.index.type", "custom")
+                .put("index.analysis.analyzer.index.tokenizer", "standard")
+                .put("index.analysis.analyzer.index.filter", "lowercase")
+                .put("index.analysis.analyzer.search.type", "custom")
+                .put("index.analysis.analyzer.search.tokenizer", "standard")
+                .putArray("index.analysis.analyzer.search.filter", "lowercase", "keyword_repeat", "porterStem", "unique_stem")
+                .put("index.analysis.filter.unique_stem.type", "unique")
+                .put("index.analysis.filter.unique_stem.only_on_same_position", true));
+        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
+
+        client().prepareIndex("test", "test", "1").setSource("text", "the fox runs across the street").get();
+        refresh();
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+
+        client().prepareIndex("test", "test", "2").setSource("text", "run fox run").get();
+        refresh();
+        searchResponse = client().prepareSearch("test").setQuery(matchQuery("text", "fox runs").operator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2);
+    }
+
+    @Test
+    public void testQueryStringWithSynonyms() throws IOException {
+        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
+                .put(indexSettings())
+                .put("index.analysis.analyzer.index.type", "custom")
+                .put("index.analysis.analyzer.index.tokenizer", "standard")
+                .put("index.analysis.analyzer.index.filter", "lowercase")
+                .put("index.analysis.analyzer.search.type", "custom")
+                .put("index.analysis.analyzer.search.tokenizer", "standard")
+                .putArray("index.analysis.analyzer.search.filter", "lowercase", "synonym")
+                .put("index.analysis.filter.synonym.type", "synonym")
+                .putArray("index.analysis.filter.synonym.synonyms", "fast, quick"));
+        assertAcked(builder.addMapping("test", "text", "type=string,analyzer=index,search_analyzer=search"));
+
+        client().prepareIndex("test", "test", "1").setSource("text", "quick brown fox").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+        searchResponse = client().prepareSearch().setQuery(queryStringQuery("fast").defaultField("text").defaultOperator(Operator.AND)).get();
+        assertHitCount(searchResponse, 1);
+
+        client().prepareIndex("test", "test", "2").setSource("text", "fast brown fox").get();
+        refresh();
+
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick").defaultField("text").defaultOperator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2);
+        searchResponse = client().prepareSearch("test").setQuery(queryStringQuery("quick brown").defaultField("text").defaultOperator(Operator.AND)).get();
+        assertHitCount(searchResponse, 2);
+    }
+
+    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3898
+    public void testCustomWordDelimiterQueryString() {
+        assertAcked(client().admin().indices().prepareCreate("test")
+                .setSettings("analysis.analyzer.my_analyzer.type", "custom",
+                        "analysis.analyzer.my_analyzer.tokenizer", "whitespace",
+                        "analysis.analyzer.my_analyzer.filter", "custom_word_delimiter",
+                        "analysis.filter.custom_word_delimiter.type", "word_delimiter",
+                        "analysis.filter.custom_word_delimiter.generate_word_parts", "true",
+                        "analysis.filter.custom_word_delimiter.generate_number_parts", "false",
+                        "analysis.filter.custom_word_delimiter.catenate_numbers", "true",
+                        "analysis.filter.custom_word_delimiter.catenate_words", "false",
+                        "analysis.filter.custom_word_delimiter.split_on_case_change", "false",
+                        "analysis.filter.custom_word_delimiter.split_on_numerics", "false",
+                        "analysis.filter.custom_word_delimiter.stem_english_possessive", "false")
+                .addMapping("type1", "field1", "type=string,analyzer=my_analyzer", "field2", "type=string,analyzer=my_analyzer"));
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", "foo bar baz", "field2", "not needed").get();
+        refresh();
+
+        SearchResponse response = client()
+                .prepareSearch("test")
+                .setQuery(
+                        queryStringQuery("foo.baz").useDisMax(false).defaultOperator(Operator.AND)
+                                .field("field1").field("field2")).get();
+        assertHitCount(response, 1l);
+    }
+
+    @Test // see https://github.com/elasticsearch/elasticsearch/issues/3797
+    public void testMultiMatchLenientIssue3797() {
+        createIndex("test");
+
+        client().prepareIndex("test", "type1", "1").setSource("field1", 123, "field2", "value2").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(multiMatchQuery("value2", "field2").field("field1", 2).lenient(true).useDisMax(false)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(multiMatchQuery("value2", "field2").field("field1", 2).lenient(true).useDisMax(true)).get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(multiMatchQuery("value2").field("field2", 2).lenient(true)).get();
+        assertHitCount(searchResponse, 1l);
+    }
+
+    @Test
+    public void testAllFieldEmptyMapping() throws Exception {
+        client().prepareIndex("myindex", "mytype").setId("1").setSource("{}").setRefresh(true).get();
+        SearchResponse response = client().prepareSearch("myindex").setQuery(matchQuery("_all", "foo")).get();
+        assertNoFailures(response);
+    }
+
+    @Test
+    public void testAllDisabledButQueried() throws Exception {
+        createIndex("myindex");
+        assertAcked(client().admin().indices().preparePutMapping("myindex").setType("mytype").setSource(
+                jsonBuilder().startObject().startObject("mytype").startObject("_all").field("enabled", false)));
+        client().prepareIndex("myindex", "mytype").setId("1").setSource("bar", "foo").setRefresh(true).get();
+        SearchResponse response = client().prepareSearch("myindex").setQuery(matchQuery("_all", "foo")).get();
+        assertNoFailures(response);
+        assertHitCount(response, 0);
+    }
+
+    @Test
+    public void testIndicesQuery() throws Exception {
+        createIndex("index1", "index2", "index3");
+
+
+        client().prepareIndex("index1", "type1").setId("1").setSource("text", "value1").get();
+        client().prepareIndex("index2", "type2").setId("2").setSource("text", "value2").get();
+        client().prepareIndex("index3", "type3").setId("3").setSource("text", "value3").get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch("index1", "index2", "index3")
+                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
+                        .noMatchQuery(matchQuery("text", "value2"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+
+        //default no match query is match_all
+        searchResponse = client().prepareSearch("index1", "index2", "index3")
+                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")).get();
+        assertHitCount(searchResponse, 3l);
+        assertSearchHits(searchResponse, "1", "2", "3");
+        searchResponse = client().prepareSearch("index1", "index2", "index3")
+                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
+                        .noMatchQuery(QueryBuilders.matchAllQuery())).get();
+        assertHitCount(searchResponse, 3l);
+        assertSearchHits(searchResponse, "1", "2", "3");
+
+        searchResponse = client().prepareSearch("index1", "index2", "index3")
+                .setQuery(indicesQuery(matchQuery("text", "value1"), "index1")
+                        .noMatchQuery("none")).get();
+        assertHitCount(searchResponse, 1l);
+        assertFirstHit(searchResponse, hasId("1"));
+    }
+
+    @Test // https://github.com/elasticsearch/elasticsearch/issues/2416
+    public void testIndicesQuerySkipParsing() throws Exception {
+        createIndex("simple");
+        assertAcked(prepareCreate("related")
+                .addMapping("child", jsonBuilder().startObject().startObject("child").startObject("_parent").field("type", "parent")
+                        .endObject().endObject().endObject()));
+
+        client().prepareIndex("simple", "lone").setId("1").setSource("text", "value1").get();
+        client().prepareIndex("related", "parent").setId("2").setSource("text", "parent").get();
+        client().prepareIndex("related", "child").setId("3").setParent("2").setSource("text", "value2").get();
+        refresh();
+
+        //has_child fails if executed on "simple" index
+        try {
+            client().prepareSearch("simple")
+                    .setQuery(hasChildQuery("child", matchQuery("text", "value"))).get();
+            fail("Should have failed as has_child query can only be executed against parent-child types");
+        } catch (SearchPhaseExecutionException e) {
+            assertThat(e.shardFailures().length, greaterThan(0));
+            for (ShardSearchFailure shardSearchFailure : e.shardFailures()) {
+                assertThat(shardSearchFailure.reason(), containsString("no mapping found for type [child]"));
+            }
+        }
+
+        //has_child doesn't get parsed for "simple" index
+        SearchResponse searchResponse = client().prepareSearch("related", "simple")
+                .setQuery(indicesQuery(hasChildQuery("child", matchQuery("text", "value2")), "related")
+                        .noMatchQuery(matchQuery("text", "value1"))).get();
+        assertHitCount(searchResponse, 2l);
+        assertSearchHits(searchResponse, "1", "2");
+    }
+
+    @Test
+    public void testIndicesQueryMissingIndices() throws IOException, ExecutionException, InterruptedException {
+        createIndex("index1");
+        createIndex("index2");
+
+        indexRandom(true,
+                client().prepareIndex("index1", "type1", "1").setSource("field", "match"),
+                client().prepareIndex("index1", "type1", "2").setSource("field", "no_match"),
+                client().prepareIndex("index2", "type1", "10").setSource("field", "match"),
+                client().prepareIndex("index2", "type1", "20").setSource("field", "no_match"),
+                client().prepareIndex("index3", "type1", "100").setSource("field", "match"),
+                client().prepareIndex("index3", "type1", "200").setSource("field", "no_match"));
+
+        //all indices are missing
+        SearchResponse searchResponse = client().prepareSearch().setQuery(
+                indicesQuery(termQuery("field", "missing"), "test1", "test2", "test3")
+                        .noMatchQuery(termQuery("field", "match"))).get();
+
+        assertHitCount(searchResponse, 3l);
+
+        for (SearchHit hit : searchResponse.getHits().getHits()) {
+            if ("index1".equals(hit.index())) {
+                assertThat(hit, hasId("1"));
+            } else if ("index2".equals(hit.index())) {
+                assertThat(hit, hasId("10"));
+            } else if ("index3".equals(hit.index())) {
+                assertThat(hit, hasId("100"));
+            } else {
+                fail("Returned documents should belong to either index1, index2 or index3");
+            }
+        }
+
+        //only one index specified, which is missing
+        searchResponse = client().prepareSearch().setQuery(
+                indicesQuery(termQuery("field", "missing"), "test1")
+                        .noMatchQuery(termQuery("field", "match"))).get();
+
+        assertHitCount(searchResponse, 3l);
+
+        for (SearchHit hit : searchResponse.getHits().getHits()) {
+            if ("index1".equals(hit.index())) {
+                assertThat(hit, hasId("1"));
+            } else if ("index2".equals(hit.index())) {
+                assertThat(hit, hasId("10"));
+            } else if ("index3".equals(hit.index())) {
+                assertThat(hit, hasId("100"));
+            } else {
+                fail("Returned documents should belong to either index1, index2 or index3");
+            }
+        }
+
+        //more than one index specified, one of them is missing
+        searchResponse = client().prepareSearch().setQuery(
+                indicesQuery(termQuery("field", "missing"), "index1", "test1")
+                        .noMatchQuery(termQuery("field", "match"))).get();
+
+        assertHitCount(searchResponse, 2l);
+
+        for (SearchHit hit : searchResponse.getHits().getHits()) {
+            if ("index2".equals(hit.index())) {
+                assertThat(hit, hasId("10"));
+            } else if ("index3".equals(hit.index())) {
+                assertThat(hit, hasId("100"));
+            } else {
+                fail("Returned documents should belong to either index2 or index3");
+            }
+        }
+    }
+
+    @Test
+    public void testMinScore() throws ExecutionException, InterruptedException {
+        createIndex("test");
+
+        client().prepareIndex("test", "test", "1").setSource("score", 1.5).get();
+        client().prepareIndex("test", "test", "2").setSource("score", 1.0).get();
+        client().prepareIndex("test", "test", "3").setSource("score", 2.0).get();
+        client().prepareIndex("test", "test", "4").setSource("score", 0.5).get();
+        refresh();
+
+        SearchResponse searchResponse = client().prepareSearch("test").setQuery(
+                functionScoreQuery(ScoreFunctionBuilders.fieldValueFactorFunction("score").missing(1.0)).setMinScore(1.5f)).get();
+        assertHitCount(searchResponse, 2);
+        assertFirstHit(searchResponse, hasId("3"));
+        assertSecondHit(searchResponse, hasId("1"));
+    }
+
+    @Test
+    public void testQueryStringWithSlopAndFields() {
+        createIndex("test");
+
+        client().prepareIndex("test", "customer", "1").setSource("desc", "one two three").get();
+        client().prepareIndex("test", "product", "2").setSource("desc", "one two three").get();
+        refresh();
+        {
+            SearchResponse searchResponse = client().prepareSearch("test").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
+            assertHitCount(searchResponse, 2);
+        }
+        {
+            SearchResponse searchResponse = client().prepareSearch("test").setTypes("product").setQuery(QueryBuilders.queryStringQuery("\"one two\"").field("desc")).get();
+            assertHitCount(searchResponse, 1);
+        }
+        {
+            SearchResponse searchResponse = client().prepareSearch("test").setTypes("product").setQuery(QueryBuilders.queryStringQuery("\"one three\"~5").field("desc")).get();
+            assertHitCount(searchResponse, 1);
+        }
+        {
+            SearchResponse searchResponse = client().prepareSearch("test").setTypes("customer").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
+            assertHitCount(searchResponse, 1);
+        }
+        {
+            SearchResponse searchResponse = client().prepareSearch("test").setTypes("customer").setQuery(QueryBuilders.queryStringQuery("\"one two\"").defaultField("desc")).get();
+            assertHitCount(searchResponse, 1);
+        }
+    }
+
+    @Test
+    public void testDateProvidedAsNumber() throws ExecutionException, InterruptedException {
+        createIndex("test");
+        assertAcked(client().admin().indices().preparePutMapping("test").setType("type").setSource("field", "type=date,format=epoch_millis").get());
+        indexRandom(true, client().prepareIndex("test", "type", "1").setSource("field", -1000000000001L),
+                client().prepareIndex("test", "type", "2").setSource("field", -1000000000000L),
+                client().prepareIndex("test", "type", "3").setSource("field", -999999999999L));
+
+
+        assertHitCount(client().prepareCount("test").setQuery(rangeQuery("field").lte(-1000000000000L)).get(), 2);
+        assertHitCount(client().prepareCount("test").setQuery(rangeQuery("field").lte(-999999999999L)).get(), 3);
+    }
+
+    @Test
+    public void testRangeQueryWithTimeZone() throws Exception {
+        assertAcked(prepareCreate("test")
+                .addMapping("type1", "date", "type=date", "num", "type=integer"));
+
+        indexRandom(true,
+                client().prepareIndex("test", "type1", "1").setSource("date", "2014-01-01", "num", 1),
+                client().prepareIndex("test", "type1", "2").setSource("date", "2013-12-31T23:00:00", "num", 2),
+                client().prepareIndex("test", "type1", "3").setSource("date", "2014-01-01T01:00:00", "num", 3),
+                // Now in UTC+1
+                client().prepareIndex("test", "type1", "4").setSource("date", DateTime.now(DateTimeZone.forOffsetHours(1)).getMillis(), "num", 4));
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T00:00:00").to("2014-01-01T00:59:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2013-12-31T23:00:00").to("2013-12-31T23:59:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T01:00:00").to("2014-01-01T01:59:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
+
+        // We explicitly define a time zone in the from/to dates so whatever the time zone is, it won't be used
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T00:00:00Z").to("2014-01-01T00:59:00Z").timeZone("+10:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2013-12-31T23:00:00Z").to("2013-12-31T23:59:00Z").timeZone("+10:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T01:00:00Z").to("2014-01-01T01:59:00Z").timeZone("+10:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
+
+        // We define a time zone to be applied to the filter and from/to have no time zone
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T03:00:00").to("2014-01-01T03:59:00").timeZone("+03:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("1"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T02:00:00").to("2014-01-01T02:59:00").timeZone("+03:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("2"));
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01T04:00:00").to("2014-01-01T04:59:00").timeZone("+03:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
+
+        // When we use long values, it means we have ms since epoch UTC based so we don't apply any transformation
+        try {
+            client().prepareSearch("test")
+                    .setQuery(QueryBuilders.rangeQuery("date").from(1388534400000L).to(1388537940999L).timeZone("+01:00"))
+                    .get();
+            fail("A Range Filter using ms since epoch with a TimeZone should raise a ParsingException");
+        } catch (SearchPhaseExecutionException e) {
+            // We expect it
+        }
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("2014-01-01").to("2014-01-01T00:59:00").timeZone("-01:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("3"));
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(QueryBuilders.rangeQuery("date").from("now/d-1d").timeZone("+01:00"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+        assertThat(searchResponse.getHits().getAt(0).getId(), is("4"));
+
+        // A Range Filter on a numeric field with a TimeZone should raise an exception
+        try {
+            client().prepareSearch("test")
+                    .setQuery(QueryBuilders.rangeQuery("num").from("0").to("4").timeZone("-01:00"))
+                    .get();
+            fail("A Range Filter on a numeric field with a TimeZone should raise a ParsingException");
+        } catch (SearchPhaseExecutionException e) {
+            // We expect it
+        }
+    }
+
+    @Test
+    public void testSearchEmptyDoc() {
+        assertAcked(prepareCreate("test").setSettings("{\"index.analysis.analyzer.default.type\":\"keyword\"}"));
+        client().prepareIndex("test", "type1", "1").setSource("{}").get();
+
+        refresh();
+        assertHitCount(client().prepareSearch().setQuery(matchAllQuery()).get(), 1l);
+    }
+
+    @Test  // see #5120
+    public void testNGramCopyField() {
+        CreateIndexRequestBuilder builder = prepareCreate("test").setSettings(settingsBuilder()
+                .put(indexSettings())
+                .put("index.analysis.analyzer.my_ngram_analyzer.type", "custom")
+                .put("index.analysis.analyzer.my_ngram_analyzer.tokenizer", "my_ngram_tokenizer")
+                .put("index.analysis.tokenizer.my_ngram_tokenizer.type", "nGram")
+                .put("index.analysis.tokenizer.my_ngram_tokenizer.min_gram", "1")
+                .put("index.analysis.tokenizer.my_ngram_tokenizer.max_gram", "10")
+                .putArray("index.analysis.tokenizer.my_ngram_tokenizer.token_chars", new String[0]));
+        assertAcked(builder.addMapping("test", "origin", "type=string,copy_to=meta", "meta", "type=string,analyzer=my_ngram_analyzer"));
+        // we only have ngrams as the index analyzer so searches will get standard analyzer
+
+
+        client().prepareIndex("test", "test", "1").setSource("origin", "C.A1234.5678")
+                .setRefresh(true)
+                .get();
+
+        SearchResponse searchResponse = client().prepareSearch("test")
+                .setQuery(matchQuery("meta", "1234"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(matchQuery("meta", "1234.56"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termQuery("meta", "A1234"))
+                .get();
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(termQuery("meta", "a1234"))
+                .get();
+        assertHitCount(searchResponse, 0l); // it's upper case
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(matchQuery("meta", "A1234").analyzer("my_ngram_analyzer"))
+                .get(); // force ngram analyzer
+        assertHitCount(searchResponse, 1l);
+
+        searchResponse = client().prepareSearch("test")
+                .setQuery(matchQuery("meta", "a1234").analyzer("my_ngram_analyzer"))
+                .get(); // this one returns a hit since it's default operator is OR
+        assertHitCount(searchResponse, 1l);
+    }
+
+    public void testMatchPhrasePrefixQuery() throws ExecutionException, InterruptedException {
+        createIndex("test1");
+        indexRandom(true, client().prepareIndex("test1", "type1", "1").setSource("field", "Johnnie Walker Black Label"),
+        client().prepareIndex("test1", "type1", "2").setSource("field", "trying out Elasticsearch"));
+
+
+        SearchResponse searchResponse = client().prepareSearch().setQuery(matchQuery("field", "Johnnie la").slop(between(2,5)).type(Type.PHRASE_PREFIX)).get();
+        assertHitCount(searchResponse, 1l);
+        assertSearchHits(searchResponse, "1");
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field", "trying").type(Type.PHRASE_PREFIX)).get();
+        assertHitCount(searchResponse, 1l);
+        assertSearchHits(searchResponse, "2");
+        searchResponse = client().prepareSearch().setQuery(matchQuery("field", "try").type(Type.PHRASE_PREFIX)).get();
+        assertHitCount(searchResponse, 1l);
+        assertSearchHits(searchResponse, "2");
+    }
+
+    @Test
+    public void testQueryStringParserCache() throws Exception {
+        createIndex("test");
+        indexRandom(true, false, client().prepareIndex("test", "type", "1").setSource("nameTokens", "xyz"));
+
+
+        SearchResponse response = client().prepareSearch("test")
+                .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                .setQuery(QueryBuilders.queryStringQuery("xyz").boost(100))
+                .get();
+        assertThat(response.getHits().totalHits(), equalTo(1l));
+        assertThat(response.getHits().getAt(0).id(), equalTo("1"));
+
+        float first = response.getHits().getAt(0).getScore();
+        for (int i = 0; i < 100; i++) {
+            response = client().prepareSearch("test")
+                    .setSearchType(SearchType.DFS_QUERY_THEN_FETCH)
+                    .setQuery(QueryBuilders.queryStringQuery("xyz").boost(100))
+                    .get();
+
+            assertThat(response.getHits().totalHits(), equalTo(1l));
+            assertThat(response.getHits().getAt(0).id(), equalTo("1"));
+            float actual = response.getHits().getAt(0).getScore();
+            assertThat(i + " expected: " + first + " actual: " + actual, Float.compare(first, actual), equalTo(0));
+        }
+    }
+
+    @Test // see #7686.
+    public void testIdsQueryWithInvalidValues() throws Exception {
+        createIndex("test");
+        indexRandom(true, false, client().prepareIndex("test", "type", "1").setSource("body", "foo"));
+
+        try {
+            client().prepareSearch("test")
+                    .setTypes("type")
+                    .setQuery("{\n" +
+                            "  \"ids\": {\n" +
+                            "    \"values\": [[\"1\"]]\n" +
+                            "  }\n" +
+                            "}")
+                    .get();
+            fail("query is invalid and should have produced a parse exception");
+        } catch (Exception e) {
+            assertThat("query could not be parsed due to bad format: " + e.toString(),
+                    e.toString().contains("Illegal value for id, expecting a string or number, got: START_ARRAY"),
+                    equalTo(true));
+        }
+    }
+}
diff --git a/plugins/lang-javascript/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java b/plugins/lang-javascript/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java
index 0adf9ca..70fc5f4 100644
--- a/plugins/lang-javascript/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java
+++ b/plugins/lang-javascript/src/main/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineService.java
@@ -178,31 +178,6 @@ public class JavaScriptScriptEngineService extends AbstractComponent implements
         }
     }
 
-    @Override
-    public Object execute(CompiledScript compiledScript, Map<String, Object> vars) {
-        Context ctx = Context.enter();
-        ctx.setWrapFactory(wrapFactory);
-        try {
-            Script script = (Script) compiledScript.compiled();
-            Scriptable scope = ctx.newObject(globalScope);
-            scope.setPrototype(globalScope);
-            scope.setParentScope(null);
-
-            for (Map.Entry<String, Object> entry : vars.entrySet()) {
-                ScriptableObject.putProperty(scope, entry.getKey(), entry.getValue());
-            }
-            Object ret = script.exec(ctx, scope);
-            return ScriptValueConverter.unwrapValue(ret);
-        } finally {
-            Context.exit();
-        }
-    }
-
-    @Override
-    public Object unwrap(Object value) {
-        return ScriptValueConverter.unwrapValue(value);
-    }
-
     private String generateScriptName() {
         return "Script" + counter.incrementAndGet() + ".js";
     }
diff --git a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineTests.java b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineTests.java
index 13fe237..f0a3181 100644
--- a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineTests.java
+++ b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineTests.java
@@ -57,7 +57,7 @@ public class JavaScriptScriptEngineTests extends ESTestCase {
     @Test
     public void testSimpleEquation() {
         Map<String, Object> vars = new HashMap<String, Object>();
-        Object o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testSimpleEquation", "js", se.compile("1 + 2")), vars);
+        Object o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testSimpleEquation", "js", se.compile("1 + 2")), vars).run();
         assertThat(((Number) o).intValue(), equalTo(3));
     }
 
@@ -68,21 +68,21 @@ public class JavaScriptScriptEngineTests extends ESTestCase {
         Map<String, Object> obj2 = MapBuilder.<String, Object>newMapBuilder().put("prop2", "value2").map();
         Map<String, Object> obj1 = MapBuilder.<String, Object>newMapBuilder().put("prop1", "value1").put("obj2", obj2).put("l", Arrays.asList("2", "1")).map();
         vars.put("obj1", obj1);
-        Object o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testMapAccess", "js", se.compile("obj1")), vars);
+        Object o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testMapAccess", "js", se.compile("obj1")), vars).run();
         assertThat(o, instanceOf(Map.class));
         obj1 = (Map<String, Object>) o;
         assertThat((String) obj1.get("prop1"), equalTo("value1"));
         assertThat((String) ((Map<String, Object>) obj1.get("obj2")).get("prop2"), equalTo("value2"));
 
-        o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testMapAccess", "js", se.compile("obj1.l[0]")), vars);
+        o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testMapAccess", "js", se.compile("obj1.l[0]")), vars).run();
         assertThat(((String) o), equalTo("2"));
     }
 
     @Test
     public void testJavaScriptObjectToMap() {
         Map<String, Object> vars = new HashMap<String, Object>();
-        Object o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testJavaScriptObjectToMap", "js",
-                se.compile("var obj1 = {}; obj1.prop1 = 'value1'; obj1.obj2 = {}; obj1.obj2.prop2 = 'value2'; obj1")), vars);
+        Object o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testJavaScriptObjectToMap", "js",
+                se.compile("var obj1 = {}; obj1.prop1 = 'value1'; obj1.obj2 = {}; obj1.obj2.prop2 = 'value2'; obj1")), vars).run();
         Map obj1 = (Map) o;
         assertThat((String) obj1.get("prop1"), equalTo("value1"));
         assertThat((String) ((Map<String, Object>) obj1.get("obj2")).get("prop2"), equalTo("value2"));
@@ -97,9 +97,10 @@ public class JavaScriptScriptEngineTests extends ESTestCase {
         ctx.put("obj1", obj1);
         vars.put("ctx", ctx);
 
-        se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testJavaScriptObjectMapInter", "js",
+        ExecutableScript executable = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testJavaScriptObjectMapInter", "js",
                 se.compile("ctx.obj2 = {}; ctx.obj2.prop2 = 'value2'; ctx.obj1.prop1 = 'uvalue1'")), vars);
-        ctx = (Map<String, Object>) se.unwrap(vars.get("ctx"));
+        executable.run();
+        ctx = (Map<String, Object>) executable.unwrap(vars.get("ctx"));
         assertThat(ctx.containsKey("obj1"), equalTo(true));
         assertThat((String) ((Map<String, Object>) ctx.get("obj1")).get("prop1"), equalTo("uvalue1"));
         assertThat(ctx.containsKey("obj2"), equalTo(true));
@@ -130,22 +131,22 @@ public class JavaScriptScriptEngineTests extends ESTestCase {
         Map<String, Object> obj1 = MapBuilder.<String, Object>newMapBuilder().put("prop1", "value1").put("obj2", obj2).map();
         vars.put("l", Arrays.asList("1", "2", "3", obj1));
 
-        Object o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessInScript", "js",
-                se.compile("l.length")), vars);
+        Object o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessInScript", "js",
+                se.compile("l.length")), vars).run();
         assertThat(((Number) o).intValue(), equalTo(4));
 
-        o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessInScript", "js",
-                se.compile("l[0]")), vars);
+        o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessInScript", "js",
+                se.compile("l[0]")), vars).run();
         assertThat(((String) o), equalTo("1"));
 
-        o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessInScript", "js",
-                se.compile("l[3]")), vars);
+        o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessInScript", "js",
+                se.compile("l[3]")), vars).run();
         obj1 = (Map<String, Object>) o;
         assertThat((String) obj1.get("prop1"), equalTo("value1"));
         assertThat((String) ((Map<String, Object>) obj1.get("obj2")).get("prop2"), equalTo("value2"));
 
-        o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessInScript", "js",
-                se.compile("l[3].prop1")), vars);
+        o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessInScript", "js",
+                se.compile("l[3].prop1")), vars).run();
         assertThat(((String) o), equalTo("value1"));
     }
 
diff --git a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptMultiThreadedTests.java b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptMultiThreadedTests.java
index 1d9090d..b639ed9 100644
--- a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptMultiThreadedTests.java
+++ b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptMultiThreadedTests.java
@@ -149,7 +149,7 @@ public class JavaScriptScriptMultiThreadedTests extends ESTestCase {
                             long addition = x + y;
                             runtimeVars.put("x", x);
                             runtimeVars.put("y", y);
-                            long result = ((Number) se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testExecutableNoRuntimeParams", "js", compiled), runtimeVars)).longValue();
+                            long result = ((Number) se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testExecutableNoRuntimeParams", "js", compiled), runtimeVars).run()).longValue();
                             assertThat(result, equalTo(addition));
                         }
                     } catch (Throwable t) {
diff --git a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptSecurityTests.java b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptSecurityTests.java
index 36636eb..887317f 100644
--- a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptSecurityTests.java
+++ b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptSecurityTests.java
@@ -50,7 +50,7 @@ public class JavaScriptSecurityTests extends ESTestCase {
     /** runs a script */
     private void doTest(String script) {
         Map<String, Object> vars = new HashMap<String, Object>();
-        se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "test", "js", se.compile(script)), vars);
+        se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "test", "js", se.compile(script)), vars).run();
     }
     
     /** asserts that a script runs without exception */
diff --git a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/SimpleBench.java b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/SimpleBench.java
index 9cb44ef..bb7eb31 100644
--- a/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/SimpleBench.java
+++ b/plugins/lang-javascript/src/test/java/org/elasticsearch/script/javascript/SimpleBench.java
@@ -43,14 +43,14 @@ public class SimpleBench {
         for (int i = 0; i < 1000; i++) {
             vars.put("x", i);
             vars.put("y", i + 1);
-            se.execute(compiledScript, vars);
+            se.executable(compiledScript, vars).run();
         }
 
         final long ITER = 100000;
 
         StopWatch stopWatch = new StopWatch().start();
         for (long i = 0; i < ITER; i++) {
-            se.execute(compiledScript, vars);
+            se.executable(compiledScript, vars).run();
         }
         System.out.println("Execute Took: " + stopWatch.stop().lastTaskTime());
 
diff --git a/plugins/lang-python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java b/plugins/lang-python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java
index 87bfbb5..3dfa4bc 100644
--- a/plugins/lang-python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java
+++ b/plugins/lang-python/src/main/java/org/elasticsearch/script/python/PythonScriptEngineService.java
@@ -125,23 +125,6 @@ public class PythonScriptEngineService extends AbstractComponent implements Scri
     }
 
     @Override
-    public Object execute(CompiledScript compiledScript, Map<String, Object> vars) {
-        PyObject pyVars = Py.java2py(vars);
-        interp.setLocals(pyVars);
-        // eval the script with reduced privileges
-        PyObject ret = evalRestricted((PyCode) compiledScript.compiled());
-        if (ret == null) {
-            return null;
-        }
-        return ret.__tojava__(Object.class);
-    }
-
-    @Override
-    public Object unwrap(Object value) {
-        return unwrapValue(value);
-    }
-
-    @Override
     public void close() {
         interp.cleanup();
     }
diff --git a/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonScriptEngineTests.java b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonScriptEngineTests.java
index 5634ec3..979da65 100644
--- a/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonScriptEngineTests.java
+++ b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonScriptEngineTests.java
@@ -59,7 +59,7 @@ public class PythonScriptEngineTests extends ESTestCase {
     @Test
     public void testSimpleEquation() {
         Map<String, Object> vars = new HashMap<String, Object>();
-        Object o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testSimpleEquation", "python", se.compile("1 + 2")), vars);
+        Object o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testSimpleEquation", "python", se.compile("1 + 2")), vars).run();
         assertThat(((Number) o).intValue(), equalTo(3));
     }
 
@@ -70,13 +70,13 @@ public class PythonScriptEngineTests extends ESTestCase {
         Map<String, Object> obj2 = MapBuilder.<String, Object>newMapBuilder().put("prop2", "value2").map();
         Map<String, Object> obj1 = MapBuilder.<String, Object>newMapBuilder().put("prop1", "value1").put("obj2", obj2).put("l", Arrays.asList("2", "1")).map();
         vars.put("obj1", obj1);
-        Object o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testMapAccess", "python", se.compile("obj1")), vars);
+        Object o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testMapAccess", "python", se.compile("obj1")), vars).run();
         assertThat(o, instanceOf(Map.class));
         obj1 = (Map<String, Object>) o;
         assertThat((String) obj1.get("prop1"), equalTo("value1"));
         assertThat((String) ((Map<String, Object>) obj1.get("obj2")).get("prop2"), equalTo("value2"));
 
-        o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testMapAccess", "python", se.compile("obj1['l'][0]")), vars);
+        o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testMapAccess", "python", se.compile("obj1['l'][0]")), vars).run();
         assertThat(((String) o), equalTo("2"));
     }
 
@@ -89,9 +89,10 @@ public class PythonScriptEngineTests extends ESTestCase {
         ctx.put("obj1", obj1);
         vars.put("ctx", ctx);
 
-        se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testObjectInterMap", "python",
+        ExecutableScript executable = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testObjectInterMap", "python",
                 se.compile("ctx['obj2'] = { 'prop2' : 'value2' }; ctx['obj1']['prop1'] = 'uvalue1'")), vars);
-        ctx = (Map<String, Object>) se.unwrap(vars.get("ctx"));
+        executable.run();
+        ctx = (Map<String, Object>) executable.unwrap(vars.get("ctx"));
         assertThat(ctx.containsKey("obj1"), equalTo(true));
         assertThat((String) ((Map<String, Object>) ctx.get("obj1")).get("prop1"), equalTo("uvalue1"));
         assertThat(ctx.containsKey("obj2"), equalTo(true));
@@ -109,15 +110,15 @@ public class PythonScriptEngineTests extends ESTestCase {
 //        Object o = se.execute(se.compile("l.length"), vars);
 //        assertThat(((Number) o).intValue(), equalTo(4));
 
-        Object o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessListInScript", "python", se.compile("l[0]")), vars);
+        Object o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessListInScript", "python", se.compile("l[0]")), vars).run();
         assertThat(((String) o), equalTo("1"));
 
-        o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessListInScript", "python", se.compile("l[3]")), vars);
+        o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessListInScript", "python", se.compile("l[3]")), vars).run();
         obj1 = (Map<String, Object>) o;
         assertThat((String) obj1.get("prop1"), equalTo("value1"));
         assertThat((String) ((Map<String, Object>) obj1.get("obj2")).get("prop2"), equalTo("value2"));
 
-        o = se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessListInScript", "python", se.compile("l[3]['prop1']")), vars);
+        o = se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "testAccessListInScript", "python", se.compile("l[3]['prop1']")), vars).run();
         assertThat(((String) o), equalTo("value1"));
     }
 
diff --git a/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonScriptMultiThreadedTests.java b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonScriptMultiThreadedTests.java
index 6798dab..81ebf69 100644
--- a/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonScriptMultiThreadedTests.java
+++ b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonScriptMultiThreadedTests.java
@@ -158,7 +158,7 @@ public class PythonScriptMultiThreadedTests extends ESTestCase {
                             long addition = x + y;
                             runtimeVars.put("x", x);
                             runtimeVars.put("y", y);
-                            long result = ((Number) se.execute(compiledScript, runtimeVars)).longValue();
+                            long result = ((Number) se.executable(compiledScript, runtimeVars).run()).longValue();
                             assertThat(result, equalTo(addition));
                         }
                     } catch (Throwable t) {
diff --git a/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonSecurityTests.java b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonSecurityTests.java
index 745a109..a753ffa 100644
--- a/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonSecurityTests.java
+++ b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/PythonSecurityTests.java
@@ -53,7 +53,7 @@ public class PythonSecurityTests extends ESTestCase {
     /** runs a script */
     private void doTest(String script) {
         Map<String, Object> vars = new HashMap<String, Object>();
-        se.execute(new CompiledScript(ScriptService.ScriptType.INLINE, "test", "python", se.compile(script)), vars);
+        se.executable(new CompiledScript(ScriptService.ScriptType.INLINE, "test", "python", se.compile(script)), vars).run();
     }
     
     /** asserts that a script runs without exception */
diff --git a/plugins/lang-python/src/test/java/org/elasticsearch/script/python/SimpleBench.java b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/SimpleBench.java
index 4fab7dd..60e792c 100644
--- a/plugins/lang-python/src/test/java/org/elasticsearch/script/python/SimpleBench.java
+++ b/plugins/lang-python/src/test/java/org/elasticsearch/script/python/SimpleBench.java
@@ -44,14 +44,14 @@ public class SimpleBench {
         for (int i = 0; i < 1000; i++) {
             vars.put("x", i);
             vars.put("y", i + 1);
-            se.execute(compiledScript, vars);
+            se.executable(compiledScript, vars).run();
         }
 
         final long ITER = 100000;
 
         StopWatch stopWatch = new StopWatch().start();
         for (long i = 0; i < ITER; i++) {
-            se.execute(compiledScript, vars);
+            se.executable(compiledScript, vars).run();
         }
         System.out.println("Execute Took: " + stopWatch.stop().lastTaskTime());
 
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/20_tar_package.bats b/qa/vagrant/src/test/resources/packaging/scripts/20_tar_package.bats
index 2ceeb2a..383375f 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/20_tar_package.bats
+++ b/qa/vagrant/src/test/resources/packaging/scripts/20_tar_package.bats
@@ -31,6 +31,7 @@
 # Load test utilities
 load packaging_test_utils
 load tar
+load plugins
 
 setup() {
     skip_not_tar_gz
@@ -91,12 +92,9 @@ setup() {
     # starting Elasticsearch so we don't have to wait for elasticsearch to scan for
     # them.
     install_elasticsearch_test_scripts
-
+    ESPLUGIN_COMMAND_USER=elasticsearch install_and_check_plugin lang groovy
     start_elasticsearch_service
-
     run_elasticsearch_tests
-
     stop_elasticsearch_service
-
     rm -rf "/tmp/elasticsearch"
 }
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats b/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats
index d0a6921..553f867 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats
+++ b/qa/vagrant/src/test/resources/packaging/scripts/30_deb_package.bats
@@ -32,6 +32,7 @@
 # Load test utilities
 load packaging_test_utils
 load os_package
+load plugins
 
 # Cleans everything for the 1st execution
 setup() {
@@ -85,6 +86,7 @@ setup() {
     # starting Elasticsearch so we don't have to wait for elasticsearch to scan for
     # them.
     install_elasticsearch_test_scripts
+    ESPLUGIN_COMMAND_USER=root install_and_check_plugin lang groovy
     start_elasticsearch_service
     run_elasticsearch_tests
 }
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats b/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats
index 91b6d8c..7f447e5 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats
+++ b/qa/vagrant/src/test/resources/packaging/scripts/40_rpm_package.bats
@@ -31,6 +31,7 @@
 # Load test utilities
 load packaging_test_utils
 load os_package
+load plugins
 
 # Cleans everything for the 1st execution
 setup() {
@@ -80,6 +81,7 @@ setup() {
     # starting Elasticsearch so we don't have to wait for elasticsearch to scan for
     # them.
     install_elasticsearch_test_scripts
+    ESPLUGIN_COMMAND_USER=root install_and_check_plugin lang groovy
     start_elasticsearch_service
     run_elasticsearch_tests
 }
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/60_systemd.bats b/qa/vagrant/src/test/resources/packaging/scripts/60_systemd.bats
index 76487fc..6558a38 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/60_systemd.bats
+++ b/qa/vagrant/src/test/resources/packaging/scripts/60_systemd.bats
@@ -31,6 +31,7 @@
 # Load test utilities
 load packaging_test_utils
 load os_package
+load plugins
 
 # Cleans everything for the 1st execution
 setup() {
@@ -67,6 +68,7 @@ setup() {
     # starting Elasticsearch so we don't have to wait for elasticsearch to scan for
     # them.
     install_elasticsearch_test_scripts
+    ESPLUGIN_COMMAND_USER=root install_and_check_plugin lang groovy
     systemctl start elasticsearch.service
     wait_for_elasticsearch_status
     assert_file_exist "/var/run/elasticsearch/elasticsearch.pid"
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/70_sysv_initd.bats b/qa/vagrant/src/test/resources/packaging/scripts/70_sysv_initd.bats
index bb6e44c..1c5cce5 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/70_sysv_initd.bats
+++ b/qa/vagrant/src/test/resources/packaging/scripts/70_sysv_initd.bats
@@ -31,6 +31,7 @@
 # Load test utilities
 load packaging_test_utils
 load os_package
+load plugins
 
 # Cleans everything for the 1st execution
 setup() {
@@ -69,6 +70,7 @@ setup() {
     # Install scripts used to test script filters and search templates before
     # starting Elasticsearch so we don't have to wait for elasticsearch to scan for
     # them.
+    ESPLUGIN_COMMAND_USER=root install_and_check_plugin lang groovy
     install_elasticsearch_test_scripts
     service elasticsearch start
     wait_for_elasticsearch_status
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/plugin_test_cases.bash b/qa/vagrant/src/test/resources/packaging/scripts/plugin_test_cases.bash
index ec2f177..a199cb9 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/plugin_test_cases.bash
+++ b/qa/vagrant/src/test/resources/packaging/scripts/plugin_test_cases.bash
@@ -352,3 +352,26 @@ fi
 @test "[$GROUP] stop elasticsearch" {
     stop_elasticsearch_service
 }
+
+@test "[$GROUP] install jvm-example with different logging modes and check output" {
+    local relativePath=${1:-$(readlink -m jvm-example-*.zip)}
+    sudo -E -u $ESPLUGIN_COMMAND_USER "$ESHOME/bin/plugin" install "file://$relativePath" > /tmp/plugin-cli-output
+    local loglines=$(cat /tmp/plugin-cli-output | wc -l)
+    [ "$loglines" = "6" ] || {
+        echo "Expected 6 lines but the output was:"
+        cat /tmp/plugin-cli-output
+        false
+    }
+    remove_jvm_example
+
+    local relativePath=${1:-$(readlink -m jvm-example-*.zip)}
+    sudo -E -u $ESPLUGIN_COMMAND_USER "$ESHOME/bin/plugin" install "file://$relativePath" -Des.logger.level=DEBUG > /tmp/plugin-cli-output
+    local loglines=$(cat /tmp/plugin-cli-output | wc -l)
+    [ "$loglines" -gt "6" ] || {
+        echo "Expected more than 6 lines but the output was:"
+        cat /tmp/plugin-cli-output
+        false
+    }
+    remove_jvm_example
+}
+
diff --git a/qa/vagrant/src/test/resources/packaging/scripts/plugins.bash b/qa/vagrant/src/test/resources/packaging/scripts/plugins.bash
index 2af60c8..31e302c 100644
--- a/qa/vagrant/src/test/resources/packaging/scripts/plugins.bash
+++ b/qa/vagrant/src/test/resources/packaging/scripts/plugins.bash
@@ -36,6 +36,8 @@ install_plugin() {
 
     assert_file_exist "$ESPLUGINS/$name"
     assert_file_exist "$ESPLUGINS/$name/plugin-descriptor.properties"
+    #check we did not accidentially create a log file as root as /usr/share/elasticsearch
+    assert_file_not_exist "/usr/share/elasticsearch/logs"
 
     # At some point installing or removing plugins caused elasticsearch's logs
     # to be owned by root. This is bad so we want to make sure it doesn't
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/api/cluster.health.json b/rest-api-spec/src/main/resources/rest-api-spec/api/cluster.health.json
index c361318..b622d01 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/api/cluster.health.json
+++ b/rest-api-spec/src/main/resources/rest-api-spec/api/cluster.health.json
@@ -7,7 +7,7 @@
       "paths": ["/_cluster/health", "/_cluster/health/{index}"],
       "parts": {
         "index": {
-          "type" : "string",
+          "type" : "list",
           "description" : "Limit the information returned to a specific index"
         }
       },
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/api/delete_template.json b/rest-api-spec/src/main/resources/rest-api-spec/api/delete_template.json
index 9e92834..1dbc40a 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/api/delete_template.json
+++ b/rest-api-spec/src/main/resources/rest-api-spec/api/delete_template.json
@@ -8,7 +8,8 @@
       "parts": {
         "id": {
           "type" : "string",
-          "description" : "Template ID"
+          "description" : "Template ID",
+          "required" : true
         }
       },
       "params" : {
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.close.json b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.close.json
index 3a9bc59..4eaa930 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.close.json
+++ b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.close.json
@@ -7,9 +7,9 @@
       "paths": ["/{index}/_close"],
       "parts": {
         "index": {
-          "type" : "string",
+          "type" : "list",
           "required" : true,
-          "description" : "The name of the index"
+          "description" : "A comma separated list of indices to close"
         }
       },
       "params": {
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.get_field_mapping.json b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.get_field_mapping.json
index 28d103a..3d5a629 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.get_field_mapping.json
+++ b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.get_field_mapping.json
@@ -3,8 +3,8 @@
     "documentation": "http://www.elastic.co/guide/en/elasticsearch/reference/master/indices-get-field-mapping.html",
     "methods": ["GET"],
     "url": {
-      "path": "/_mapping/field/{field}",
-      "paths": ["/_mapping/field/{field}", "/{index}/_mapping/field/{field}", "/_mapping/{type}/field/{field}", "/{index}/_mapping/{type}/field/{field}"],
+      "path": "/_mapping/field/{fields}",
+      "paths": ["/_mapping/field/{fields}", "/{index}/_mapping/field/{fields}", "/_mapping/{type}/field/{fields}", "/{index}/_mapping/{type}/field/{fields}"],
       "parts": {
         "index": {
           "type" : "list",
@@ -14,7 +14,7 @@
           "type" : "list",
           "description" : "A comma-separated list of document types"
         },
-        "field": {
+        "fields": {
           "type" : "list",
           "description" : "A comma-separated list of fields",
           "required" : true
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.get_template.json b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.get_template.json
index e948cad..e3a97ee 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.get_template.json
+++ b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.get_template.json
@@ -10,9 +10,9 @@
       ],
       "parts": {
         "name": {
-          "type": "string",
+          "type": "list",
           "required": false,
-          "description": "The name of the template"
+          "description": "The comma separated names of the index templates"
         }
       },
       "params": {
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.open.json b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.open.json
index 3c2cb1c..879ce5a 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/api/indices.open.json
+++ b/rest-api-spec/src/main/resources/rest-api-spec/api/indices.open.json
@@ -7,9 +7,9 @@
       "paths": ["/{index}/_open"],
       "parts": {
         "index": {
-          "type" : "string",
+          "type" : "list",
           "required" : true,
-          "description" : "The name of the index"
+          "description" : "A comma separated list of indices to open"
         }
       },
       "params": {
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/10_basic.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/10_basic.yaml
index 0b63631..7df0734 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/10_basic.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/10_basic.yaml
@@ -18,7 +18,7 @@ setup:
 
   - do:
       indices.get_field_mapping:
-        field: text
+        fields: text
 
   - match: {test_index.mappings.test_type.text.mapping.text.type:     string}
 
@@ -27,7 +27,7 @@ setup:
   - do:
       indices.get_field_mapping:
         index: test_index
-        field: text
+        fields: text
 
   - match: {test_index.mappings.test_type.text.mapping.text.type:     string}
 
@@ -38,7 +38,7 @@ setup:
       indices.get_field_mapping:
         index: test_index
         type: test_type
-        field: text
+        fields: text
 
   - match: {test_index.mappings.test_type.text.mapping.text.type:     string}
 
@@ -49,7 +49,7 @@ setup:
       indices.get_field_mapping:
         index: test_index
         type: test_type
-        field: [ text , text1 ]
+        fields: [ text , text1 ]
 
   - match: {test_index.mappings.test_type.text.mapping.text.type:     string}
   - is_false: test_index.mappings.test_type.text1
@@ -61,19 +61,19 @@ setup:
       indices.get_field_mapping:
         index: test_index
         type: test_type
-        field: text
+        fields: text
         include_defaults: true
 
   - match: {test_index.mappings.test_type.text.mapping.text.type:     string}
   - match: {test_index.mappings.test_type.text.mapping.text.analyzer: default}
 
 ---
-"Get field mapping should work without index specifying type and field": 
+"Get field mapping should work without index specifying type and fields":
 
   - do:
       indices.get_field_mapping:
         type: test_type
-        field: text
+        fields: text
 
   - match: {test_index.mappings.test_type.text.mapping.text.type:     string}
 
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/20_missing_field.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/20_missing_field.yaml
index 1eae257..d39fcc5 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/20_missing_field.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/20_missing_field.yaml
@@ -19,6 +19,6 @@
       indices.get_field_mapping:
         index: test_index
         type: test_type
-        field: not_existent
+        fields: not_existent
   
   - match: { '': {}}
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/30_missing_type.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/30_missing_type.yaml
index 7c16d51..6f8e9d2 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/30_missing_type.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/30_missing_type.yaml
@@ -20,5 +20,5 @@
       indices.get_field_mapping:
         index: test_index
         type: not_test_type
-        field: text
+        fields: text
   
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/40_missing_index.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/40_missing_index.yaml
index ab2d985..7da516e 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/40_missing_index.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/40_missing_index.yaml
@@ -6,6 +6,6 @@
       indices.get_field_mapping:
         index: test_index
         type: type
-        field: field
+        fields: field
 
 
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/50_field_wildcards.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/50_field_wildcards.yaml
index cc53689..78af1b3 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/50_field_wildcards.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/indices.get_field_mapping/50_field_wildcards.yaml
@@ -49,7 +49,7 @@ setup:
 
   - do:
       indices.get_field_mapping:
-        field: "*"
+        fields: "*"
 
   - match: {test_index.mappings.test_type.t1.full_name:     t1     }
   - match: {test_index.mappings.test_type.t2.full_name:     t2     }
@@ -63,7 +63,7 @@ setup:
   - do:
       indices.get_field_mapping:
         index: test_index
-        field: "t*"
+        fields: "t*"
 
   - match:  {test_index.mappings.test_type.t1.full_name:     t1       }
   - match:  {test_index.mappings.test_type.t2.full_name:     t2       }
@@ -75,7 +75,7 @@ setup:
   - do:
       indices.get_field_mapping:
         index: test_index
-        field: "*t1"
+        fields: "*t1"
   - match:  {test_index.mappings.test_type.t1.full_name:        t1       }
   - match:  {test_index.mappings.test_type.obj\.t1.full_name:   obj.t1   }
   - match:  {test_index.mappings.test_type.obj\.i_t1.full_name: obj.i_t1 }
@@ -87,7 +87,7 @@ setup:
   - do:
       indices.get_field_mapping:
         index: test_index
-        field: "obj.i_*"
+        fields: "obj.i_*"
   - match:  {test_index.mappings.test_type.obj\.i_t1.full_name: obj.i_t1 }
   - match:  {test_index.mappings.test_type.obj\.i_t3.full_name: obj.i_t3 }
   - length: {test_index.mappings.test_type: 2}
@@ -99,7 +99,7 @@ setup:
       indices.get_field_mapping:
         index: _all
         type: _all
-        field: "t*"
+        fields: "t*"
   - match:  {test_index.mappings.test_type.t1.full_name: t1 }
   - match:  {test_index.mappings.test_type.t2.full_name: t2 }
   - length: {test_index.mappings.test_type: 2}
@@ -114,7 +114,7 @@ setup:
       indices.get_field_mapping:
         index: '*'
         type: '*'
-        field: "t*"
+        fields: "t*"
   - match:  {test_index.mappings.test_type.t1.full_name: t1 }
   - match:  {test_index.mappings.test_type.t2.full_name: t2 }
   - length: {test_index.mappings.test_type: 2}
@@ -129,7 +129,7 @@ setup:
       indices.get_field_mapping:
         index: 'test_index,test_index_2'
         type: 'test_type,test_type_2'
-        field: "t*"
+        fields: "t*"
   - match:  {test_index.mappings.test_type.t1.full_name: t1 }
   - match:  {test_index.mappings.test_type.t2.full_name: t2 }
   - length: {test_index.mappings.test_type: 2}
diff --git a/rest-api-spec/src/main/resources/rest-api-spec/test/search/80_date_math_index_names.yaml b/rest-api-spec/src/main/resources/rest-api-spec/test/search/80_date_math_index_names.yaml
index 233b41c..2f2cf6a 100644
--- a/rest-api-spec/src/main/resources/rest-api-spec/test/search/80_date_math_index_names.yaml
+++ b/rest-api-spec/src/main/resources/rest-api-spec/test/search/80_date_math_index_names.yaml
@@ -2,6 +2,6 @@
 "Missing index with catch":
 
   - do:
-      catch:   /index=logstash-\d{4}\.\d{2}\.\d{2}/
+      catch:   /logstash-\d{4}\.\d{2}\.\d{2}/
       search:
         index: <logstash-{now/M}>
